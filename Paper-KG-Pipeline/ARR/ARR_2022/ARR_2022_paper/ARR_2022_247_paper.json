{
  "name" : "ARR_2022_247_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "NLU++: A Multi-Label, Slot-Rich, Generalisable Dataset for Natural Language Understanding in Task-Oriented Dialogue",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Research on task-oriented dialogue (ToD) systems (Levin and Pieraccini, 1995; Young et al., 2002) has become a key aspect in industry: e.g., ToD is used to automate telephone customer service tasks ranging from hospitality over healthcare to banking (Raux et al., 2003; Young, 2010; El Asri et al., 2017). Typical ToD systems still rely on a modular design: (i) the Natural Language Understanding (NLU) module maps user utterances into a domainspecific set of intent labels and values (Rastogi et al., 2019; Heck et al., 2020; Dai et al., 2021), followed by (ii) the policy module, which makes decisions based on the information extracted by the NLU (Lubis et al., 2020; Wang et al., 2020a)\nThe NLU module is a critical part of any ToD system, as it must extract the relevant information from the user’s utterances. The information relevance is denoted by the structured dialogue domain ontology, which enables the policy module to make decisions about next system actions. The domain ontology covers the information on 1) intents and 2) slots, see Figure 1. The former is aimed at extracting general conversational ideas (i.e., the user’s intents) and corresponds to the standard NLU task of intent detection (ID); the latter extracts specific slot values and corresponds to the NLU task of slot labeling (SL) (Gupta et al., 2019).1\nIn order to make the policy operational and tractable, NLU should extract only the minimal information required by the policy. Therefore, the ontologies differ for each domain of ToD application and are typically built from scratch for each domain. Consequently, this makes domain-relevant NLU data extremely expensive to collect and annotate, and prevents its reusability (Budzianowski et al., 2018). Due to this, NLU research in recent years has heavily focused on very data-efficient models that can effectively operate in low-data regimes. Current state-of-the-art (SotA) NLU models leverage large pretrained language models (PLMs) (De-\n1Slot labeling is also known under other names such as slot filling or value extraction.\nvlin et al., 2019; Liu et al., 2019c; Henderson et al., 2020) and fine-tune them with small task-specific datasets (Larson et al., 2019b; Casanueva et al., 2020; Coucke et al., 2018)\nAt the same time, the progress in creation of NLU datasets has not kept up with the impressive pace of NLU methodology development. However, designing domain ontologies and NLU datasets is also critical for steering further progress in NLU, both from methodology and application perspective. Put simply, current publicly available NLU datasets do not keep up to date with current industry/application requirements for many reasons. 1) They are usually crowdsourced by untrained annotators (thus typically optimised for quantity rather than quality), yielding examples with low lexical diversity and prone to annotation errors. 2) They typically assume one intent per example, and thus enable only much simpler single-label ID experiments; such setups are not realistic in more complex industry settings (see Figure 1 again) and lead to unnecessarily large intent sets. 3) Their ontologies are tied to specific domains, making it difficult to reuse already available annotated data in other domains. 4) The complexity of the defined tasks and ontologies is limited; the undesired artefact is that current NLU datasets might overestimate the NLU models’ abilities, and are not able to separate models any more performance-wise.2\nIn order to address all these gaps, we introduce NLU++, a novel NLU dataset which provides highquality NLU data annotated by dialogue experts. NLU++ provides multi-intent, slot-rich and semantically varied NLU data, and is inspired by a number of NLU challenges which ToD systems typically face in production environments. Unlike previous ID datasets, examples are annotated with multiple labels, with some examples naturally obtaining even up to 6-7 labels. NLU++ defines a rich set of slots which are combined with multi-intent sentences. NLU++ is divided into two domains (BANKING and HOTELS) where the two domain ontologies blend a set of domain-specific intents and slots with a set of generic (i.e., domain-universal) intents and slots. This design makes a crucial step towards generalisation and data reusability in NLU.\n2For instance, for some standard and commonly used NLU datasets such as ATIS (Hemphill et al., 1990; Xu et al., 2020) and SNIPS (Coucke et al., 2018), the results of SotA models are all in the region of 97-98 F1, with new models getting statistically insignificant gains which might be due to overfitting to the test set or even some remaining annotation errors.\nFinally, we run a series of experiments on NLU++ with current SotA ID and SL models, demonstrating the challenging nature of NLU++ and ample room for future improvement, especially in lowdata setups. Our benchmark comparisons also demonstrate strong performance and shed new light on the (ability of) recently emerging QA-based NLU models, and warrant further research on ToD NLU. The NLU++ dataset is available at: [URL] under CC BY 4.0 license."
    }, {
      "heading" : "2 Background and Motivation",
      "text" : "A Brief History of NLU Datasets. As a core module of ToD systems, NLU has been researched since the early 1990s, when the Airline Travel Information System (ATIS) project was started (Hemphill et al., 1990), consisting of spoken queries on flightrelated information.3 Over the next two decades, very few NLU resources were released.4\nThe lack of ToD NLU resources ended in 2013, with the beginning of the ‘dialogue state tracking (DST) era’ (Williams et al., 2013; Henderson et al., 2014; Kim et al., 2016). Instead of just classifying each turn of the user, DST deals with keeping track of the user’s goal over the entire dialogue history, i.e., all the previous user and system turns. Several datasets where released during the DST challenges, all of them comprising simple intent sets (usually tagged as dialogue acts).\nTo adapt to the increasing data requirements of deep learning models, increasingly larger dialogue datasets have been released in recent years (Budzianowski et al., 2018; Wei et al., 2018; Rastogi et al., 2019; Peskov et al., 2019). However, the design of ToD datasets comes with some profound differences to datasets for e.g. machine translation or speech recognition, which affect current ToD datasets. 1) The domain-specific nature of ToD datasets made the data tied to its ontologies, not allowing data reusability across different domains. 2) The domain-specific ontologies required a lot of expertise for annotation, therefore many annotation mistakes were made (Eric et al., 2019; Zang et al.,\n3Remarkably, ATIS is still considered at present as one of the main go-to datasets in NLU reserach. This is also reflected in the fact that the recent most popular dataset for multilingual dialogue NLU was obtained by simply translating English ATIS to 8 more languages (Xu et al., 2020, MultiATIS++).\n4We note that some Question Classification (Hovy et al., 2001), Paraphrasing (Dolan and Brockett, 2005) and Semantic Text Similarity(Agirre et al., 2012) datasets could be seen as the seed of modern ID datasets, but were not initially built for that purpose.\n2020). 3) Collecting datasets of that size is unfeasible for development cycles in production, where new domains and models for them need to be very quickly developed and deployed.\nCurrent NLU Trends, inspired by such production requirements, thus deviate from previous DSToriented NLU research in two main aspects. First, the models went back to focusing on single-turn utterances, which 1) simplifies the NLU design and 2) renders the NLU tasks more tractable.5The requirement of fast development cycles also instigated more research on NLU (i.e., ID and SL tasks) in low-data scenarios. This way, systems can be developed and maintained faster by reducing the data collection and annotation effort. In addition, the NLU focus shifted from ontologies with only a handful of simple intents and slots (Coucke et al., 2018) to complex ontologies with much larger intent sets (Larson et al., 2019b; Liu et al., 2019b; Casanueva et al., 2020, inter alia).\nInspired by these NLU datasets and empowered by transfer learning with PLMs and sentence encoders (Devlin et al., 2019; Liu et al., 2019a; Henderson et al., 2020), there have been great improvements in single-turn NLU systems recently, especially in low-data scenarios (Coope et al., 2020; Mehri et al., 2020; Wu et al., 2020b,a; Krone et al., 2020; Henderson and Vulić, 2021; Namazifar et al., 2021; Dopierre et al., 2021; Zhang et al., 2021a,b).\nCurrent Gaps in NLU Datasets. However, existing NLU datasets are still not up to the current industry requirements. 1) They use crowdworkers for data collection and annotation, often through simple rephrasings; they thus suffer from low lexical diversity and annotation errors (Larson et al., 2019a). 2) ID datasets always assume a single intent per sentence,6 which does not support modern production\n5While DST is theoretically more accurate, it requires amounts of data that grow exponentially with the number of turns; moreover, rule-based trackers have proven to be on par with the learned/statistical ones and require no data (Wang and Lemon, 2013).\n6There has been some work on multi-label ID on ATIS, MultiWOZ and DSTC4 as multi-intent datasets; however, their multi-label examples remain very limited, simple, and span a small number of intents (Gangadharaiah and Narayanaswamy,\nrequirements. 3) The ontologies of these datasets are very domain-specific (i.e., they thus do not allow data reusability) and narrow (i.e., they tend to overestimate abilities of the current SotA NLU models). 4) Current NLU datasets do not combine a large set of fine-grained intents (again, with multiintent examples) and a large set of fine-grained slots, which prevents proper and more insightful evaluations of joint NLU models (Chen et al., 2019; Gangadharaiah and Narayanaswamy, 2019)."
    }, {
      "heading" : "3 NLU++ Dataset",
      "text" : "The NLU++ dataset has been designed with the aim of addressing some of the major shortcomings of the current NLU datasets. In what follows, we describe the main improvements and new evaluation opportunities offered by NLU++."
    }, {
      "heading" : "3.1 Ontology",
      "text" : "NLU++ comprises two domains: BANKING and HOTELS. The former represents a banking services task (e.g., making transfers, depositing cheques, reporting lost cards, requesting mortgage information) and the latter is a hotel ‘bell desk’ reception task (e.g., booking rooms, asking about pools or gyms, requesting room service). Both domains combine a large set of intents with a rich set of slots, with the ontologies inspired by requirements in production. A large number of intents and slots is shared between the two domains, in an attempt to increase data reusability/transferability. Table 1 provides the main statistics of the NLU++ dataset, while the full ontology is presented in Appendix A."
    }, {
      "heading" : "3.2 Multi-Intent Examples",
      "text" : "One of the main contributions of this work is the design of the intent space, defined in a highly modular manner that natively supports intent recombinations and multi-intent annotations. For instance, Table 2 shows several multi-intent examples based\n2019). Further, synthetic multi-intent datasets have been created by concatenating single-intent sentences, but such datasets also do not capture the complexity of true and natural multi-intent sentences (Qin et al., 2020).\non the intent sets (termed intent modules) from Table 8 in Appendix A. This design brings several benefits. 1) The modular nature of the ontology allows for expressing a much more complex set of ideas through different combinations of intent modules (see Table 2), while reducing the overall size of the intent set compared to previous ID datasets7 (see Table 4). 2) It allows for the definition of partial intents (e.g. “The savings one”). This is crucial in multi-turn interactions, where the user often has to answer disambiguation questions (e.g. “Which account would you like to close?”). 3) The modular approach allows the models to generalise to unseen combinations of intent modules.8 4) The design also allows us to distinguish between domain-specific versus generic intent modules.9\nFinally, the modular design also allows us to study semantic variation of intent modules. Some intents (e.g., especially the domain-specific ones) can only be expressed in a few ways (e.g. overdraft, direct_debit, swimming_pool), while others can have much more varied surface semantic realisations, (e.g. make, not_working). Table 8 in Appendix A provides an estimation of the semantic variability of each intent (module)."
    }, {
      "heading" : "3.3 Slots",
      "text" : "NLU++ further includes a rich set of 17 slots, defined in Table 9 in Appendix A. Table 3 displays several NLU++ examples where complex combi-\n7(Zhang et al., 2020) proposed a similar way of annotating intents categorising them in four predefined factors.\n8For instance, if (i) examples with the intents change and booking, and (ii) examples with the intents cancel and account exist in the training data, (iii) an unseen example with the intents cancel and booking could be properly predicted, as all the single intents/modules have already been seen by the ID model. Note that in single-label ID setups, all possible intent combinations must be covered (Bi and Kwok, 2013; Hou et al., 2020), which leads to unnecessarily large intent sets and larger data requirements.\n9For example, the module/concept overdraft is clearly related to BANKING, but the concept change is much more generic, likely to occur in several different domains.\nnations of intents and slots occur, showcasing how NLU++ might provide a much more challenging environment for the evaluation of joint ID and SL models in future research.\nFollowing the design of previous standard SL datasets (Hemphill et al., 1990; Coucke et al., 2018; Coope et al., 2020), we provide span annotations for slots. On top of of this, to also support training and evaluation of SL models which are not span-based, we also provide value annotations (or canonical values as named by Rastogi et al. (2019)) for times, dates, and numeric values.\nSimilarly to intent modules, slots can also be divided into the generic ones (e.g. time, date) and the domain-specific ones (e.g company_name, rooms, kids) (see Table 9). Again, this distinction allows for the cross-domain reusability of annotated data."
    }, {
      "heading" : "3.4 Data Collection and Annotation",
      "text" : "Previous NLU datasets have usually relied on crowdworkers, aiming to collect a large numbers of examples, and typically optimising for quantity over quality. However, even with much simpler ontologies, workers are prone to make annotation mistakes, leading to very noisy datasets (Eric et al., 2019). In addition, when workers are asked to rephrase a sentence, they often change its semantic meaning or tend to provide rephrasings with extremely low lexical variability (Kang et al., 2018).\nNLU++ reflects true production requirements and focuses on data quality. Instead of relying on crowdworkers, 4 highly skilled annotators with dialogue and NLP expertise, also familiar with production environments, collected, annotated, and corrected the data. The process started by defining the ontology for BANKING and HOTELS. Then, real user examples were fully anonymised and reannotated following the defined ontology. Finally, new examples were created in order to cover less frequent intents and slots, aiming at creating realistic and semantically varied sentences with new\n.\ncombinations of intents and slots."
    }, {
      "heading" : "3.5 Comparison with Other NLU Datasets",
      "text" : "Aiming to reflect the differences between NLU++ and the most popular ToD NLU datasets, Table 4 compares their general statistics. Since the focus of NLU++ is on curated high-quality data, NLU++ covers a fewer number of examples than the other datasets, but it is evident that NLU++ is the only real multi-intent dataset: it averages 2.01 intents per example with a high standard deviation. In addition, NLU++ is the only dataset that combines a large set of intents with a large set of slots.\nIn order to asses the quality and diversity of the NLU data, we include two additional metrics: 1) Type-Token Ratio (TTR) (Jurafsky and Martin, 2000) which measures lexical diversity) and semantic diversity. Both metrics are computed for the set of examples sharing an intent, weighted by the frequency of that intent10 and finally averaged over intents. The semantic diversity per intent is computed as follows: (i) sentence encodings, obtained by the ConveRT sentence encoder (Henderson et al., 2020),11 are computed for the set of sentences sharing the same intent; (ii) the centroid of these encodings is then computed; (iii) finally, the average cosine distance from each encoding to the centroid is computed. The overall scores clearly indicate that NLU++ offers a much higher lexical and semantic diversity than previous\n10Note that ATIS has some intents with a single example: for these intents the TTR score would be 1. Weighting by the intent frequency avoids these intents dominating the metric.\n11See Appendix B for a short description of ConveRT.\ndatasets, which should also render it more challenging for current SotA NLU models.12"
    }, {
      "heading" : "4 Experiments and Results",
      "text" : "In hope to establish NLU++ as a more challenging production-oriented testbed for dialogue NLU, especially in low-data scenarios, we evaluate a series of current cutting-edge models for both NLU tasks: intent detection (§4.1) and slot labeling (§4.2). Our aim is to assess and analyse their performance across different setups, and provide solid baseline reference points for future evaluations on NLU++.\nData Setups. Unless noted otherwise, for both tasks we adopt the standard K-fold cross-validation as done e.g. by Liu et al. (2019b). Through such folding evaluation, (i) we avoid overfitting to any particular test set and (ii) we ensure more stable results with smaller training and test data (i.e., when simulating low-data regimes typically met in production) through averaging over different folds.13\nThe experiments are run with K = 20 (20-Fold) and K = 10 (10-Fold), where we train on 1 fold and evalute on the remaining K − 1 folds. These setups simulate different degrees of data scarcity: e.g., the average training fold comprises ≈ 100 examples for BANKING and ≈ 50 for HOTELS for 20-Fold experiments, and twice as much for 10- Fold experiments. Besides these low-data training\n12SNIPS also shows high semantic diversity, but this is mostly due to its coverage of 7 very diverse domains, ranging from Restaurants over Books and Music to Weather.\n13Due to folding, variations in results with different random seeds were negligible, even in lowest-data setups.\nsetups, we also run experiments in a Large-data setup, where we train the models on merged 9 folds, and evaluate on the single held-out fold.14 The key questions we aim to answer with these data setups are: Which NLU models are better adapted to low-data scenarios? How much does NLU performance improve with the increase of annotated NLU data? How challenging is NLU++ in low-data versus large-data scenarios?\nDomain Setups. Further, experiments are run in the following domain setups: (i) single-domain experiments where we only use the BANKING or the HOTELS portion of the entire dataset; (ii) bothdomain experiments (termed ALL) where we use the entire dataset and combine the two domain ontologies (see Table 1); (iii) cross-domain experiments where we train on the examples associated with one domain and test on the examples from the other domain, keeping only shared intents and slots for evaluation. The key questions we aim to answer are: Are there major performance differences between the two domains and can they be merged into a single (and more complex) domain? Is it possible to use examples labeled with generic intents from one domain to boost another domain, effectively increasing reusability of data annotations and reducing data scarcity? F1 (micro) is the main evaluation measure in all ID and SL experiments."
    }, {
      "heading" : "4.1 Intent Detection: Experimental Setup",
      "text" : "We evaluate two groups of SotA intent detection models: (i) MLP-Based, and (ii) QA-Based ones.\nMLP-Based ID Baselines. Casanueva et al. (2020) and Gerz et al. (2021) have recently shown that, for the ID task, full and expensive fine-tuning of large pretrained models such as BERT (Devlin et al., 2019) or RoBERTa (Liu et al., 2019a) is not needed to reach strong ID performance. As an alternative, they propose a much more efficient MLP-based approach to intent detection which works on par or even outperforms full fine-tuning on the ID task.15 In a nutshell, the idea is to use fixed/frozen “offthe-shelf” universal sentence encoders such as ConveRT (Henderson et al., 2020) or Sentence-BERT (Reimers and Gurevych, 2019) models to encode\n14Effectively, Large-data experiments can be seen as 10- Fold experiments with swapped training and test data.\n15Our preliminary results on the NLU++ dataset corroborated these findings from prior work; due to a large number of experiments, we thus opt for this more efficient yet also very effective approach to ID.\ninput sentences. A standard multi-layer perceptron (MLP) classifier is then learnt on top of the sentence encodings.\nTwo core differences to the previous work stem from the fact that we now deal with the multi-label ID task: 1) to this end, we replace the output softmax layer with the sigmoid layer; and 2) we define a threshold θ which determines the final classification: only intents with probability scores ≥ θ are taken as positives. This way, the hyper-parameter θ effectively controls the trade-off between precision and recall of the multi-label classifier.\nWe comparatively evaluate several widely used state-of-the-art (SotA) sentence encoders, but remind the reader that this decoupling of the MLP classification layers from the fixed encoder allows for a much wider empirical comparison of sentence encoders in future work. The evalauted sentence encoders are: 1) CONVERT (Henderson et al., 2020), which produces 1,024-dimensional sentence encodings; 2) LABSE (Feng et al., 2020) (768-dim); 3) ROBL-1B (1,024-dim) and 4) LM12-1B (384- dim) (Reimers and Gurevych, 2019; Thakur et al., 2021). For completeness, we provide brief descriptions of each encoder in our evaluation, along with their public URLs, in Appendix B, and refer the reader to the original work for more details about each sentence encoder.\nQA-Based ID Baselines. Another group of SotA ID baselines reformulates the ID task into the (extractive) question-answering (QA) problem (Namazifar et al., 2021). This QA-oriented reformatting then allows for additional specialised QA-tuning of large PLMs. In a nutshell, the idea is to (i) fine-tune the original PLM such as BERT/RoBERTa on readily available large generalpurpose QA data such as SQuAD (Rajpurkar et al., 2016), and then (ii) further fine-tune this general QA model with in-domain ID data. This strategy has recently shown very strong performance on single-label ATIS data (Namazifar et al., 2021).\nThe main ‘trick’ is to reformat the input ID examples into the following format: “yes. no. [SENTENCE]” and pose a question such as: “is the intent to ask about [INTENT]?” (see Appendix A for the actual questions associated with each intent, also shared with the dataset). Here, [SENTENCE] is the placeholder for the actual input sentence, and [INTENT] is the placeholder for a short manually defined text (akin to language modeling prompts (Liu et al., 2021), see again Appendix A) which\nbriefly describes the intent. The QA formulation lends itself naturally to the multi-label ID setup as each ‘intent-related’ question is posed separately. In other words, for each input example and for each of the L intents in the ontology the QA model must extract yes or no as the answer, where correct intent labels are the ones for which the answer is yes.16 We note that our work is the first to apply and evaluate the QA approach on multi-label ID.\nWe experiment with two pretrained language models, both fine-tuned on the SQuAD2.0 dataset (Rajpurkar et al., 2018) before additional QAtuning on NLU++ examples converted to the aforementioned QA format: ROBB-QA uses RoBERTaBase as the underlying LM, while ALB-QA relies on the more compact ALBERT (Lan et al., 2019).\nID: Training and Evaluation. All MLP-based baselines rely on the same training protocol and hyper-parameters in all data and domain setups. The MLP classifier consists of 1 hidden layer of size 512, and is trained via binary cross-entropy loss for 500 epochs with the batch size of 32 and the dropout rate is 0.6. We use the standard AdamW optimizer (Loshchilov and Hutter, 2018) with the learning rate of 0.003 and linear decay; weight decay is 0.02. The threshold θ is set to 0.4.17\nFor QA models, we largely follow Namazifar et al. (2021) and fine-tune all models for 5 epochs, using AdamW; the learning rate of 2e−5 with linear decay; weight decay is 0; batch size is 32.17"
    }, {
      "heading" : "4.2 Slot Labeling: Experimental Setup",
      "text" : "For slot labeling, we benchmark two current SotA models: (i) ConvEx (Henderson and Vulić, 2021), as a SotA span-extraction SL model and (ii) the QA-based SL model (Namazifar et al., 2021) based on ROBB-QA, which operates similarly to QAbased ID baselines discussed in §4.1, and relies on the same fine-tuning regime as our QA-based ID baselines. Again, we refer the reader to the original work for further details, and provide brief\n16For instance, for the input sentence “I need to increase my overdraft” from the BANKING domain, we would pose all 48 questions associated with each of the L = 48 intents in BANKING, where the QA model should extract yes as the answer for intents change, overdraft and more_higher_after, and extract no for the remaining 45 intents in BANKING.\n17These hyper-parameters were selected based on preliminary experiments with a single (most efficient) sentence encoder LM12-1B and training only on Fold 0 of the 10-Fold BANKING setup; they were then propagated without change to all other MLP-based experiments with other encoders and in other setups. We repeated the similar hyper-parameter search procedure for QA-based models, using ALB-QA.\ndescriptions in Appendix D."
    }, {
      "heading" : "4.3 Results and Discussion",
      "text" : "Main results with all the evaluated baselines are summarised in Table 5 (for ID) and Table 6 (SL).\nID: MLP versus QA Models. First, the comparisons among only MLP-based models reveal that 1) all sentence encoders offer ID performance in similar, reasonably narrow score intervals (e.g., the variations in F1 scores between all sentence encoders are typically below 4-6 F1 points in all setups), and 2) that CONVERT is the best-performing sentence encoder on average, which corroborates findings from prior work on other ID datasets (Casanueva et al., 2020; Wu and Xiong, 2020).\nOne very apparent and important indication in the reported results is the superiority of QA-based ID models over their MLP-based competitors. QAbased models largely outperform MLP-Based baselines in all domain setups, as well as in all data setups. The gains are visible even in Large-data setups, but the benefits of QA-based ID are immense in the lowest-data 20-Fold setups: e.g., 12 F1 points over the strongest MLP ID model on HOTELS and 20 F1 points on BANKING.\nMoreover, the use of larger underlying LMs might push the scores with QA even further: using SQuAD-tuned Roberta-Large (ROBL-QA) instead of Base (ROBB) yields further gains – e.g., F1 rises from 85.6 to 87.8 on 10-Fold BANKING, and similar trends are observed in other low-data setups.\nSlot Labeling. In the SL task, the QA-based model also demonstrates its superiority, again with huge gains in low-data 20-Fold and 10-Fold setups, confirming that such QA-based or prompt-based methods (Liu et al., 2021; Gao et al., 2021) are especially well suited for low-data setups. The use of manually defined questions/prompts, which are typically easy to write by humans, combined with the expressive power of QA-based task formatting yields immense gains on low-resource dialogue NLU.\nGiven these very promising ID and SL results on NLU++, our work also calls for further and more intensive future research on QA-based models for dialogue NLU. However, we note that QA-based ID and SL methods do come with efficiency detriments, especially with larger intent and slot sets: the model must copy the input utterance and run a separate answer extraction for each intent/slot from the set, which is by several order of magnitudes more costly at both training and inference than\nMLP-based models. A promising future research avenue is thus to investigate combined approaches that could combine and trade off the performance benefits of QA-based models and the efficiency advantages of, e.g., MLP-based ID.\nLow-Data vs. Large-Data. We also note that scores on both tasks, as reported in Tables 5- 6, leave ample room for improvement in NLU methodology in future work, especially on SL (even in Large-data setups), and in low-data setups.\nCross-Domain Experiments. We also verify potential reusability of annotated data across domains with a simple ID experiment, where we train ID models on BANKING and evaluate on HOTELS, and vice versa. The results are summarised in Table 7. Besides (again) indicating that QA-based models outscore MLP-based ID, the results also suggest that for some generic intents it is possible to meet\nhigh ID performance without any in-domain annotations. For instance, we observe particularly high scores for highly generic and reusable intent modules such as change, how, how_much, thank, when, and affirm, all with per-intent F1 scores ≥ 90. We hope that these preliminary results might inspire similar ontology (re)designs in future work."
    }, {
      "heading" : "5 Conclusion",
      "text" : "We have presented NLU++, a novel dataset for task-oriented dialogue (ToD) NLU that overcomes the shortcomings of previous NLU evaluation sets. NLU++ presents a multi-intent and slot-rich ontology, defines generic and domain-specific intents and slots to promote data reusability, and it focuses on the creation of high-quality complex examples and annotations collected by dialogue experts. Experimental results show that NLU++ raises the bar with respect to current NLU benchmarks, helping better discriminate and compare the performance of current state-of-the-art NLU models, particularly in low-data setups. We hope that NLU++ will be valuable in guiding future modeling efforts for ToD NLU, both in academia and in industry.\nLimitations and Future Work. This work has shown that a better design of the intent set can improve data reusability. However, the current ontology does not cover generic sets of intents exhaustively, and we acknowledge a (sometimes) fine line between truly generic intents versus intents ‘anecdotally’ shared by two domains (e.g., refund). Further, NLU++ currently provides fine-grained slots such as date_from, date_to and date to enable more complex scenarios, but such a design might slow down annotation process and make it cumbersome. Future work should also look into alternatives to fine-grained slot annotations for such slots.\nEthical Considerations\n[INSTITUTION-ANONYMOUS] (further INSTITUTION) is ISO27k-certified and fully GDPRcompliant.\nBefore data collection: all the data has been collected by workers of the aforementioned INSTITUTION and all the annotators are also employees of the same INSTITUTION.\nDuring data collection: we did not include any personal information (e.g. personal names or addresses) and all the examples that included any had been fully anonymised or removed from the dataset. All the names in the dataset are created by randomly concatenating names and surnames from the list of the top 10K names from the US registry. Upon collection, the dataset has undergone an additional check by the internal Ethics committee. It is licensed under CC BY 4.0."
    }, {
      "heading" : "A Appendix: Ontology",
      "text" : "The complete ontology of NLU++ is provided in Table 8 and Table 9."
    }, {
      "heading" : "B Appendix: Sentence Encoders in Intent Detection Experiments",
      "text" : "CONVERT (Henderson et al., 2020) is trained with the conversational response selection objective (Henderson et al., 2019b) on large Reddit data (Al-Rfou et al., 2016; Henderson et al., 2019a), spanning more than 700M (context, response) sentence pairs. Thanks to its naturally conversational pretraining objective, it has been shown to be especially well-suited for conversational tasks such as intent detection (Casanueva et al., 2020) and slot labelling (Coope et al., 2020). It outputs 1,024-dim sentence encodings. - github.com/davidalami/ConveRT\nLABSE. Language-agnostic BERT Sentence Embedding (LaBSE) (Feng et al., 2020) adapts pretrained multilingual BERT (mBERT) (Devlin et al., 2019) using a dual-encoder framework (Yang et al., 2019) with larger embedding capacity (i.e., a shared multilingual vocabulary of 500k subwords). While LaBSE is the current state-of-the-art multilingual encoder, it also displays very strong monolingual English performance (Feng et al., 2020). It produces 768-dim sentence encodings. - huggingface.co/sentence-transformers/ LaBSE\nROBL-1B and LM12-1B (Reimers and Gurevych, 2019; Thakur et al., 2021) are sentence encoders which fine-tune the pretrained RobertaLarge (ROBL) language model (Liu et al., 2019a) and the 12-layer MiniLM (Wang et al., 2020b), respectively, again using a contrastive dual-encoder framework (Reimers and Gurevych, 2019). The models are fine-tuned on a set of more than 1B sentence pairs: this set comprises various data such as Reddit 2015-2018 comments (Henderson et al., 2019a), Natural Questions (Kwiatkowski et al., 2019), PAQ (question, answer) pairs (Lewis et al., 2021), to name only a few.18 ROBL-1B outputs\n18In a nutshell, the contrastive fine-tuning task which combines all the heterogeneous datasets is as follows: given a ‘query’ sentence from each sentence pair, and a set of R randomly sampled negatives plus 1 true positive (the sentence from the same pair), the model should predict which sentence from the set of R + 1 sentences is actually paired with the query sentence in the dataset. The full list of all datasets along with the exact model specifications is at:\n1,024-dim encodings, while LM12-1B produces 384-dim encodings.\nWe opted for those two models in particular as one represents a class of large sentence encoders (ROBL-1B), and the other is lightweight (LM12-1B), while both display very strong performance in a myriad of sentence similarity and semantic search tasks, see www.sbert.net/docs/ pretrained_models.html. - huggingface.co/sentence-transformers/ all-roberta-large-v1 - huggingface.co/sentence-transformers/ all-MiniLM-L12-v1"
    }, {
      "heading" : "C Appendix: QA-Pretrained Models",
      "text" : "We rely on the same SQuAD-tuned language models as Namazifar et al. (2021). ROBB-QA can be found online at: https://huggingface. co/deepset/roberta-base-squad2; ALB-QA is available at: https://huggingface.co/twmkn9/ albert-base-v2-squad2"
    }, {
      "heading" : "D Appendix: Slot Labeling Baselines",
      "text" : "CONVEX (Henderson and Vulić, 2021) demonstrates strong SL performance, especially in fewshot settings. It is pretrained on a pairwise cloze task extracted from the Reddit examples (Henderson et al., 2019a), and the majority of the pretrained model’s parameters in CONVEX are kept frozen during fine-tuning, making it an extremely efficient model. We adopt the suggested hyper-parameters from Henderson and Vulić (2021).\nQA-Based: Namazifar et al. (2021) train an extractive QA-based model to extract the spans of the slots from the input user utterance as answers to manually defined natural language questions (one per slot). It follows the same idea as QA-based ID models. We also provide such questions for each slot along with NLU++ for model training and inference: see the questions in Table 9.\nhuggingface.co/sentence-transformers/ all-roberta-large-v1."
    } ],
    "references" : [ {
      "title" : "SemEval-2012 Task 6: A pilot on semantic textual similarity",
      "author" : [ "Eneko Agirre", "Daniel Cer", "Mona Diab", "Aitor Gonzalez-Agirre." ],
      "venue" : "Proceedings of *SEM, pages 385–393.",
      "citeRegEx" : "Agirre et al\\.,? 2012",
      "shortCiteRegEx" : "Agirre et al\\.",
      "year" : 2012
    }, {
      "title" : "Conversational contextual cues: The case of personalization and history for response ranking",
      "author" : [ "Rami Al-Rfou", "Marc Pickett", "Javier Snaider", "Yun-Hsuan Sung", "Brian Strope", "Ray Kurzweil." ],
      "venue" : "CoRR, abs/1606.00372.",
      "citeRegEx" : "Al.Rfou et al\\.,? 2016",
      "shortCiteRegEx" : "Al.Rfou et al\\.",
      "year" : 2016
    }, {
      "title" : "Efficient multilabel classification with many labels",
      "author" : [ "Wei Bi", "James Tin-Yau Kwok." ],
      "venue" : "Proceedings of the 30th International Conference on Machine Learning, ICML 2013, Atlanta, GA, USA, 16-21 June 2013, volume 28 of JMLR Workshop and Conference",
      "citeRegEx" : "Bi and Kwok.,? 2013",
      "shortCiteRegEx" : "Bi and Kwok.",
      "year" : 2013
    }, {
      "title" : "MultiWOZ - A large-scale multi-domain wizard-of-oz dataset for task-oriented dialogue modelling",
      "author" : [ "Paweł Budzianowski", "Tsung-Hsien Wen", "Bo-Hsiang Tseng", "Iñigo Casanueva", "Stefan Ultes", "Osman Ramadan", "Milica Gašić." ],
      "venue" : "Proceedings of",
      "citeRegEx" : "Budzianowski et al\\.,? 2018",
      "shortCiteRegEx" : "Budzianowski et al\\.",
      "year" : 2018
    }, {
      "title" : "Efficient intent detection with dual sentence encoders",
      "author" : [ "Iñigo Casanueva", "Tadas Temcinas", "Daniela Gerz", "Matthew Henderson", "Ivan Vulić." ],
      "venue" : "Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI, pages 38–45.",
      "citeRegEx" : "Casanueva et al\\.,? 2020",
      "shortCiteRegEx" : "Casanueva et al\\.",
      "year" : 2020
    }, {
      "title" : "Bert for joint intent classification and slot filling",
      "author" : [ "Qian Chen", "Zhu Zhuo", "Wen Wang." ],
      "venue" : "arXiv preprint arXiv:1902.10909.",
      "citeRegEx" : "Chen et al\\.,? 2019",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2019
    }, {
      "title" : "Span-ConveRT: Fewshot span extraction for dialog with pretrained",
      "author" : [ "Sam Coope", "Tyler Farghly", "Daniela Gerz", "Ivan Vulić", "Matthew Henderson" ],
      "venue" : null,
      "citeRegEx" : "Coope et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Coope et al\\.",
      "year" : 2020
    }, {
      "title" : "Snips Voice Platform: An embedded spoken language understanding",
      "author" : [ "Alice Coucke", "Alaa Saade", "Adrien Ball", "Théodore Bluche", "Alexandre Caulier", "David Leroy", "Clément Doumouro", "Thibault Gisselbrecht", "Francesco Caltagirone", "Thibaut Lavril" ],
      "venue" : null,
      "citeRegEx" : "Coucke et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Coucke et al\\.",
      "year" : 2018
    }, {
      "title" : "Preview, attend and review: Schema-aware curriculum learning for multi-domain dialog state tracking",
      "author" : [ "Yinpei Dai", "Hangyu Li", "Yongbin Li", "Jian Sun", "Fei Huang", "Luo Si", "Xiaodan Zhu." ],
      "venue" : "arXiv preprint arXiv:2106.00291.",
      "citeRegEx" : "Dai et al\\.,? 2021",
      "shortCiteRegEx" : "Dai et al\\.",
      "year" : 2021
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of NAACL-HLT 2019, pages 4171–4186.",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Automatically constructing a corpus of sentential paraphrases",
      "author" : [ "William B Dolan", "Chris Brockett." ],
      "venue" : "Proceedings of the Third International Workshop on Paraphrasing (IWP2005).",
      "citeRegEx" : "Dolan and Brockett.,? 2005",
      "shortCiteRegEx" : "Dolan and Brockett.",
      "year" : 2005
    }, {
      "title" : "PROTAUGMENT: Unsupervised diverse short-texts paraphrasing for intent detection meta-learning",
      "author" : [ "Thomas Dopierre", "Christophe Gravier", "Wilfried Logerais." ],
      "venue" : "Proceedings of the 59th Annual Meeting of the Association for Computational Lin-",
      "citeRegEx" : "Dopierre et al\\.,? 2021",
      "shortCiteRegEx" : "Dopierre et al\\.",
      "year" : 2021
    }, {
      "title" : "Frames: A corpus for adding memory to goal-oriented dialogue systems",
      "author" : [ "Layla El Asri", "Hannes Schulz", "Shikhar Sharma", "Jeremie Zumer", "Justin Harris", "Emery Fine", "Rahul Mehrotra", "Kaheer Suleman." ],
      "venue" : "Proceedings of SIGDIAL, pages 207–219.",
      "citeRegEx" : "Asri et al\\.,? 2017",
      "shortCiteRegEx" : "Asri et al\\.",
      "year" : 2017
    }, {
      "title" : "Multiwoz 2.1: Multi-domain dialogue state corrections and state tracking baselines. CoRR, abs/1907.01669",
      "author" : [ "Mihail Eric", "Rahul Goel", "Shachi Paul", "Abhishek Sethi", "Sanchit Agarwal", "Shuyang Gao", "Dilek HakkaniTür" ],
      "venue" : null,
      "citeRegEx" : "Eric et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Eric et al\\.",
      "year" : 2019
    }, {
      "title" : "Language-agnostic BERT sentence embedding",
      "author" : [ "Fangxiaoyu Feng", "Yinfei Yang", "Daniel Cer", "Naveen Arivazhagan", "Wei Wang." ],
      "venue" : "CoRR, abs/2007.01852.",
      "citeRegEx" : "Feng et al\\.,? 2020",
      "shortCiteRegEx" : "Feng et al\\.",
      "year" : 2020
    }, {
      "title" : "Joint multiple intent detection and slot labeling for goal-oriented dialog",
      "author" : [ "Rashmi Gangadharaiah", "Balakrishnan Narayanaswamy." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Gangadharaiah and Narayanaswamy.,? 2019",
      "shortCiteRegEx" : "Gangadharaiah and Narayanaswamy.",
      "year" : 2019
    }, {
      "title" : "Making pre-trained language models better few-shot learners",
      "author" : [ "Tianyu Gao", "Adam Fisch", "Danqi Chen." ],
      "venue" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natu-",
      "citeRegEx" : "Gao et al\\.,? 2021",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2021
    }, {
      "title" : "Multilingual and cross-lingual intent detection from spoken data",
      "author" : [ "Daniela Gerz", "Pei-Hao Su", "Razvan Kusztos", "Avishek Mondal", "Michal Lis", "Eshan Singhal", "Nikola Mrkšić", "Tsung-Hsien Wen", "Ivan Vulić." ],
      "venue" : "Proceedings of EMNLP 2021.",
      "citeRegEx" : "Gerz et al\\.,? 2021",
      "shortCiteRegEx" : "Gerz et al\\.",
      "year" : 2021
    }, {
      "title" : "Simple, fast, accurate intent classification and slot labeling for goal-oriented dialogue systems",
      "author" : [ "Arshit Gupta", "John Hewitt", "Katrin Kirchhoff." ],
      "venue" : "Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue, pages 46–55.",
      "citeRegEx" : "Gupta et al\\.,? 2019",
      "shortCiteRegEx" : "Gupta et al\\.",
      "year" : 2019
    }, {
      "title" : "Trippy: A triple copy strategy for value independent neural dialog state tracking",
      "author" : [ "Michael Heck", "Carel van Niekerk", "Nurul Lubis", "Christian Geishauser", "Hsien-Chin Lin", "Marco Moresi", "Milica Gašić." ],
      "venue" : "arXiv preprint arXiv:2005.02877.",
      "citeRegEx" : "Heck et al\\.,? 2020",
      "shortCiteRegEx" : "Heck et al\\.",
      "year" : 2020
    }, {
      "title" : "The ATIS Spoken Language Systems Pilot Corpus",
      "author" : [ "Charles T. Hemphill", "John J. Godfrey", "George R. Doddington." ],
      "venue" : "Proceedings of the Workshop on Speech and Natural Language, HLT ’90, pages 96–101.",
      "citeRegEx" : "Hemphill et al\\.,? 1990",
      "shortCiteRegEx" : "Hemphill et al\\.",
      "year" : 1990
    }, {
      "title" : "A repository of conversational datasets",
      "author" : [ "Matthew Henderson", "Pawel Budzianowski", "Iñigo Casanueva", "Sam Coope", "Daniela Gerz", "Girish Kumar", "Nikola Mrkšić", "Georgios Spithourakis", "Pei-Hao Su", "Ivan Vulić", "Tsung-Hsien Wen." ],
      "venue" : "Proceedings",
      "citeRegEx" : "Henderson et al\\.,? 2019a",
      "shortCiteRegEx" : "Henderson et al\\.",
      "year" : 2019
    }, {
      "title" : "ConveRT: Efficient and accurate conversational representations from transformers",
      "author" : [ "Matthew Henderson", "Iñigo Casanueva", "Nikola Mrkšić", "Pei-Hao Su", "Tsung-Hsien Wen", "Ivan Vulić." ],
      "venue" : "Findings of EMNLP 2020, pages 2161–2174.",
      "citeRegEx" : "Henderson et al\\.,? 2020",
      "shortCiteRegEx" : "Henderson et al\\.",
      "year" : 2020
    }, {
      "title" : "The Second Dialog State Tracking Challenge",
      "author" : [ "Matthew Henderson", "Blaise Thomson", "Jason D. Wiliams." ],
      "venue" : "Proceedings of SIGDIAL, pages 263– 272.",
      "citeRegEx" : "Henderson et al\\.,? 2014",
      "shortCiteRegEx" : "Henderson et al\\.",
      "year" : 2014
    }, {
      "title" : "ConVEx: Data-efficient and few-shot slot labeling",
      "author" : [ "Matthew Henderson", "Ivan Vulić." ],
      "venue" : "Proceedings of NAACL-HLT 2021.",
      "citeRegEx" : "Henderson and Vulić.,? 2021",
      "shortCiteRegEx" : "Henderson and Vulić.",
      "year" : 2021
    }, {
      "title" : "Training neural response selection for task-oriented dialogue systems",
      "author" : [ "Matthew Henderson", "Ivan Vulić", "Daniela Gerz", "Iñigo Casanueva", "Paweł Budzianowski", "Sam Coope", "Georgios Spithourakis", "Tsung-Hsien Wen", "Nikola Mrkšić", "Pei-Hao Su." ],
      "venue" : "Pro-",
      "citeRegEx" : "Henderson et al\\.,? 2019b",
      "shortCiteRegEx" : "Henderson et al\\.",
      "year" : 2019
    }, {
      "title" : "Few-shot learning for multilabel intent detection",
      "author" : [ "Yutai Hou", "Yongkui Lai", "Yushan Wu", "Wanxiang Che", "Ting Liu." ],
      "venue" : "CoRR, abs/2010.05256.",
      "citeRegEx" : "Hou et al\\.,? 2020",
      "shortCiteRegEx" : "Hou et al\\.",
      "year" : 2020
    }, {
      "title" : "The use of external knowledge in factoid qa",
      "author" : [ "Eduard Hovy", "Ulf Hermjakob", "Chin-Yew Lin" ],
      "venue" : "In TREC,",
      "citeRegEx" : "Hovy et al\\.,? \\Q2001\\E",
      "shortCiteRegEx" : "Hovy et al\\.",
      "year" : 2001
    }, {
      "title" : "Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition, 1st edition",
      "author" : [ "Daniel Jurafsky", "James H. Martin." ],
      "venue" : "Prentice Hall PTR, USA.",
      "citeRegEx" : "Jurafsky and Martin.,? 2000",
      "shortCiteRegEx" : "Jurafsky and Martin.",
      "year" : 2000
    }, {
      "title" : "Data collection for dialogue system: A startup perspective",
      "author" : [ "Yiping Kang", "Yunqi Zhang", "Jonathan K. Kummerfeld", "Lingjia Tang", "Jason Mars." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Kang et al\\.,? 2018",
      "shortCiteRegEx" : "Kang et al\\.",
      "year" : 2018
    }, {
      "title" : "The Fourth Dialog State Tracking Challenge",
      "author" : [ "Seokhwan Kim", "Luis Fernando D’Haro", "Rafael E. Banchs", "Jason Williams", "Matthew Henderson" ],
      "venue" : "In Proceedings of IWSDS",
      "citeRegEx" : "Kim et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2016
    }, {
      "title" : "Learning to classify intents and slot labels given a handful of examples",
      "author" : [ "Jason Krone", "Yi Zhang", "Mona Diab." ],
      "venue" : "Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI, pages 96–108, Online. Association for Computa-",
      "citeRegEx" : "Krone et al\\.,? 2020",
      "shortCiteRegEx" : "Krone et al\\.",
      "year" : 2020
    }, {
      "title" : "Natural questions: A benchmark for question answering research",
      "author" : [ "Uszkoreit", "Quoc Le", "Slav Petrov." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 7:452–466.",
      "citeRegEx" : "Uszkoreit et al\\.,? 2019",
      "shortCiteRegEx" : "Uszkoreit et al\\.",
      "year" : 2019
    }, {
      "title" : "Albert: A Lite BERT for selfsupervised learning of language representations",
      "author" : [ "Zhenzhong Lan", "Mingda Chen", "Sebastian Goodman", "Kevin Gimpel", "Piyush Sharma", "Radu Soricut." ],
      "venue" : "CoRR, abs/1909.11942.",
      "citeRegEx" : "Lan et al\\.,? 2019",
      "shortCiteRegEx" : "Lan et al\\.",
      "year" : 2019
    }, {
      "title" : "Outlier detection for improved data quality and diversity in dialog systems",
      "author" : [ "Stefan Larson", "Anish Mahendran", "Andrew Lee", "Jonathan K Kummerfeld", "Parker Hill", "Michael A Laurenzano", "Johann Hauswald", "Lingjia Tang", "Jason Mars." ],
      "venue" : "arXiv",
      "citeRegEx" : "Larson et al\\.,? 2019a",
      "shortCiteRegEx" : "Larson et al\\.",
      "year" : 2019
    }, {
      "title" : "An evaluation dataset for intent classification",
      "author" : [ "Stefan Larson", "Anish Mahendran", "Joseph J. Peper", "Christopher Clarke", "Andrew Lee", "Parker Hill", "Jonathan K. Kummerfeld", "Kevin Leach", "Michael A. Laurenzano", "Lingjia Tang", "Jason Mars" ],
      "venue" : null,
      "citeRegEx" : "Larson et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Larson et al\\.",
      "year" : 2019
    }, {
      "title" : "Chronus, the next generation",
      "author" : [ "E. Levin", "R. Pieraccini." ],
      "venue" : "Proceedings of the ARPA Workshop on Spoken Language Technology. 10",
      "citeRegEx" : "Levin and Pieraccini.,? 1995",
      "shortCiteRegEx" : "Levin and Pieraccini.",
      "year" : 1995
    }, {
      "title" : "PAQ: 65 Million Probably-Asked Questions and What You Can Do With Them",
      "author" : [ "Patrick Lewis", "Yuxiang Wu", "Linqing Liu", "Pasquale Minervini", "Heinrich Küttler", "Aleksandra Piktus", "Pontus Stenetorp", "Sebastian Riedel." ],
      "venue" : "Transactions of the Association for",
      "citeRegEx" : "Lewis et al\\.,? 2021",
      "shortCiteRegEx" : "Lewis et al\\.",
      "year" : 2021
    }, {
      "title" : "Pretrain, prompt, and predict: A systematic survey of prompting methods in Natural Language Processing",
      "author" : [ "Pengfei Liu", "Weizhe Yuan", "Jinlan Fu", "Zhengbao Jiang", "Hiroaki Hayashi", "Graham Neubig." ],
      "venue" : "CoRR, abs/2107.13586.",
      "citeRegEx" : "Liu et al\\.,? 2021",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2021
    }, {
      "title" : "Multi-task deep neural networks for natural language understanding",
      "author" : [ "Xiaodong Liu", "Pengcheng He", "Weizhu Chen", "Jianfeng Gao." ],
      "venue" : "CoRR, abs/1901.11504.",
      "citeRegEx" : "Liu et al\\.,? 2019a",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Benchmarking natural language understanding services for building conversational agents",
      "author" : [ "Xingkun Liu", "Arash Eshghi", "Pawel Swietojanski", "Verena Rieser." ],
      "venue" : "Proceedings of IWSDS 2019.",
      "citeRegEx" : "Liu et al\\.,? 2019b",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "RoBERTa: A robustly optimized BERT pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "CoRR, abs/1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019c",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Decoupled weight decay regularization",
      "author" : [ "Ilya Loshchilov", "Frank Hutter." ],
      "venue" : "Proceedings of ICLR 2018.",
      "citeRegEx" : "Loshchilov and Hutter.,? 2018",
      "shortCiteRegEx" : "Loshchilov and Hutter.",
      "year" : 2018
    }, {
      "title" : "Lava: Latent action spaces via variational auto-encoding for dialogue policy optimization",
      "author" : [ "Nurul Lubis", "Christian Geishauser", "Michael Heck", "Hsien-chin Lin", "Marco Moresi", "Carel van Niekerk", "Milica Gasic." ],
      "venue" : "Proceedings of the 28th International",
      "citeRegEx" : "Lubis et al\\.,? 2020",
      "shortCiteRegEx" : "Lubis et al\\.",
      "year" : 2020
    }, {
      "title" : "Example-driven intent prediction with observers",
      "author" : [ "Shikib Mehri", "Mihail Eric", "Dilek Hakkani-Tur." ],
      "venue" : "arXiv preprint arXiv:2010.08684.",
      "citeRegEx" : "Mehri et al\\.,? 2020",
      "shortCiteRegEx" : "Mehri et al\\.",
      "year" : 2020
    }, {
      "title" : "Language model is all you need: Natural language understanding as question answering",
      "author" : [ "Mahdi Namazifar", "Alexandros Papangelis", "Gokhan Tur", "Dilek Hakkani-Tür." ],
      "venue" : "Proceedings of ICASSP 2021, pages 7803–7807.",
      "citeRegEx" : "Namazifar et al\\.,? 2021",
      "shortCiteRegEx" : "Namazifar et al\\.",
      "year" : 2021
    }, {
      "title" : "Multi-domain goal-oriented dialogues (multidogo): Strategies toward curating and annotating large scale dialogue data",
      "author" : [ "Denis Peskov", "Nancy Clarke", "Jason Krone", "Brigi Fodor", "Yi Zhang", "Adel Youssef", "Mona Diab." ],
      "venue" : "Proceedings of the 2019 Confer-",
      "citeRegEx" : "Peskov et al\\.,? 2019",
      "shortCiteRegEx" : "Peskov et al\\.",
      "year" : 2019
    }, {
      "title" : "Agif: An adaptive graph-interactive framework for joint multiple intent detection and slot filling",
      "author" : [ "Libo Qin", "Xiao Xu", "Wanxiang Che", "Ting Liu." ],
      "venue" : "pages 1807–1816.",
      "citeRegEx" : "Qin et al\\.,? 2020",
      "shortCiteRegEx" : "Qin et al\\.",
      "year" : 2020
    }, {
      "title" : "Know what you don’t know: Unanswerable questions for SQuAD",
      "author" : [ "Pranav Rajpurkar", "Robin Jia", "Percy Liang." ],
      "venue" : "Proceedings of ACL 2018, pages 784– 789.",
      "citeRegEx" : "Rajpurkar et al\\.,? 2018",
      "shortCiteRegEx" : "Rajpurkar et al\\.",
      "year" : 2018
    }, {
      "title" : "SQuAD: 100,000+ questions for Machine Comprehension of Text",
      "author" : [ "Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang." ],
      "venue" : "Proceedings of EMNLP.",
      "citeRegEx" : "Rajpurkar et al\\.,? 2016",
      "shortCiteRegEx" : "Rajpurkar et al\\.",
      "year" : 2016
    }, {
      "title" : "Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset",
      "author" : [ "Abhinav Rastogi", "Xiaoxue Zang", "Srinivas Sunkara", "Raghav Gupta", "Pranav Khaitan." ],
      "venue" : "arXiv preprint arXiv:1909.05855.",
      "citeRegEx" : "Rastogi et al\\.,? 2019",
      "shortCiteRegEx" : "Rastogi et al\\.",
      "year" : 2019
    }, {
      "title" : "LET’s GO: Improving spoken dialog systems for the elderly and non-natives",
      "author" : [ "Antoine Raux", "Brian Langner", "Alan W. Black", "Maxine Eskénazi." ],
      "venue" : "Proceedings of EUROSPEECH.",
      "citeRegEx" : "Raux et al\\.,? 2003",
      "shortCiteRegEx" : "Raux et al\\.",
      "year" : 2003
    }, {
      "title" : "SentenceBERT: Sentence embeddings using Siamese BERTnetworks",
      "author" : [ "Nils Reimers", "Iryna Gurevych." ],
      "venue" : "Proceedings of EMNLP 2019, pages 3982–3992.",
      "citeRegEx" : "Reimers and Gurevych.,? 2019",
      "shortCiteRegEx" : "Reimers and Gurevych.",
      "year" : 2019
    }, {
      "title" : "Augmented SBERT: Data augmentation method for improving bi-encoders for pairwise sentence scoring tasks",
      "author" : [ "Nandan Thakur", "Nils Reimers", "Johannes Daxenberger", "Iryna Gurevych." ],
      "venue" : "Proceedings of the 2021 Conference of the North American Chap-",
      "citeRegEx" : "Thakur et al\\.,? 2021",
      "shortCiteRegEx" : "Thakur et al\\.",
      "year" : 2021
    }, {
      "title" : "Multi-domain dialogue acts and response co-generation",
      "author" : [ "Kai Wang", "Junfeng Tian", "Rui Wang", "Xiaojun Quan", "Jianxing Yu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7125–7134.",
      "citeRegEx" : "Wang et al\\.,? 2020a",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "2020b. MiniLM: Deep selfattention distillation for task-agnostic compression of pre-trained Transformers",
      "author" : [ "Wenhui Wang", "Furu Wei", "Li Dong", "Hangbo Bao", "Nan Yang", "Ming Zhou" ],
      "venue" : null,
      "citeRegEx" : "Wang et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "A Simple and Generic Belief Tracking Mechanism for the Dialog State Tracking Challenge: On the believability of observed information",
      "author" : [ "Zhuoran Wang", "Oliver Lemon." ],
      "venue" : "Proceedings of SIGDIAL.",
      "citeRegEx" : "Wang and Lemon.,? 2013",
      "shortCiteRegEx" : "Wang and Lemon.",
      "year" : 2013
    }, {
      "title" : "Airdialogue: An environment for goal-oriented dialogue research",
      "author" : [ "Wei Wei", "Quoc Le", "Andrew Dai", "Jia Li." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3844–3854.",
      "citeRegEx" : "Wei et al\\.,? 2018",
      "shortCiteRegEx" : "Wei et al\\.",
      "year" : 2018
    }, {
      "title" : "The Dialogue State Tracking Challenge",
      "author" : [ "Jason D. Williams", "Antoine Raux", "Deepak Ramachandran", "Alan W. Black." ],
      "venue" : "Proceedings of SIGDIAL.",
      "citeRegEx" : "Williams et al\\.,? 2013",
      "shortCiteRegEx" : "Williams et al\\.",
      "year" : 2013
    }, {
      "title" : "Transformers: State-of-the-art natural language processing",
      "author" : [ "Lhoest", "Alexander Rush." ],
      "venue" : "Proceedings of EMNLP 2020: System Demonstrations, pages 38–45.",
      "citeRegEx" : "Lhoest and Rush.,? 2020",
      "shortCiteRegEx" : "Lhoest and Rush.",
      "year" : 2020
    }, {
      "title" : "TOD-BERT: Pre-trained natural language understanding for task-oriented dialogue",
      "author" : [ "Chien-Sheng Wu", "Steven C.H. Hoi", "Richard Socher", "Caiming Xiong." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Wu et al\\.,? 2020a",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Probing task-oriented dialogue representation from language models",
      "author" : [ "Chien-Sheng Wu", "Caiming Xiong." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5036–5051, Online. Association for",
      "citeRegEx" : "Wu and Xiong.,? 2020",
      "shortCiteRegEx" : "Wu and Xiong.",
      "year" : 2020
    }, {
      "title" : "SlotRefine: A fast non-autoregressive model for joint intent detection and slot filling",
      "author" : [ "Di Wu", "Liang Ding", "Fan Lu", "Jian Xie." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1932–1937,",
      "citeRegEx" : "Wu et al\\.,? 2020b",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "End-to-end slot alignment and recognition for crosslingual NLU",
      "author" : [ "Weijia Xu", "Batool Haider", "Saab Mansour." ],
      "venue" : "Proceedings of EMNLP 2020, pages 5052–5063.",
      "citeRegEx" : "Xu et al\\.,? 2020",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2020
    }, {
      "title" : "Improving multilingual sentence embedding using bidirectional dual encoder with additive margin",
      "author" : [ "Yinfei Yang", "Gustavo Hernandez Abrego", "Steve Yuan", "Mandy Guo", "Qinlan Shen", "Daniel Cer", "Yun-hsuan Sung", "Brian Strope", "Ray Kurzweil" ],
      "venue" : null,
      "citeRegEx" : "Yang et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "Cognitive user interfaces",
      "author" : [ "Steve Young." ],
      "venue" : "IEEE Signal Processing Magazine.",
      "citeRegEx" : "Young.,? 2010",
      "shortCiteRegEx" : "Young.",
      "year" : 2010
    }, {
      "title" : "The HTK book",
      "author" : [ "Steve Young", "Gunnar Evermann", "Mark Gales", "Thomas Hain", "Dan Kershaw", "Xunying Liu", "Gareth Moore", "Julian Odell", "Dave Ollason", "Dan Povey", "Valtcho Valtchev", "Phil Woodland." ],
      "venue" : "Cambridge University Engineering Department.",
      "citeRegEx" : "Young et al\\.,? 2002",
      "shortCiteRegEx" : "Young et al\\.",
      "year" : 2002
    }, {
      "title" : "Multiwoz 2.2: A dialogue dataset with additional annotation corrections and state tracking baselines. arXiv preprint arXiv:2007.12720",
      "author" : [ "Xiaoxue Zang", "Abhinav Rastogi", "Srinivas Sunkara", "Raghav Gupta", "Jianguo Zhang", "Jindong Chen" ],
      "venue" : null,
      "citeRegEx" : "Zang et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Zang et al\\.",
      "year" : 2020
    }, {
      "title" : "Effectiveness of pre-training for few-shot intent classification",
      "author" : [ "Haode Zhang", "Yuwei Zhang", "Li-Ming Zhan", "Jiaxin Chen", "Guangyuan Shi", "Xiao-Ming Wu", "Albert Y.S. Lam." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP",
      "citeRegEx" : "Zhang et al\\.,? 2021a",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2021
    }, {
      "title" : "2021b. Few-shot intent",
      "author" : [ "Jianguo Zhang", "Trung Bui", "Seunghyun Yoon", "Xiang Chen", "Zhiwei Liu", "Congying Xia", "Quan Hung Tran", "Walter Chang", "Philip Yu" ],
      "venue" : null,
      "citeRegEx" : "Zhang et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2021
    }, {
      "title" : "Multi-point semantic representation for intent classification",
      "author" : [ "Jinghan Zhang", "Yuxiao Ye", "Yue Zhang", "Likun Qiu", "Bin Fu", "Yang Li", "Zhenglu Yang", "Jian Sun." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, 34:9531–9538.",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 36,
      "context" : "Research on task-oriented dialogue (ToD) systems (Levin and Pieraccini, 1995; Young et al., 2002) has become a key aspect in industry: e.",
      "startOffset" : 49,
      "endOffset" : 97
    }, {
      "referenceID" : 66,
      "context" : "Research on task-oriented dialogue (ToD) systems (Levin and Pieraccini, 1995; Young et al., 2002) has become a key aspect in industry: e.",
      "startOffset" : 49,
      "endOffset" : 97
    }, {
      "referenceID" : 51,
      "context" : ", ToD is used to automate telephone customer service tasks ranging from hospitality over healthcare to banking (Raux et al., 2003; Young, 2010; El Asri et al., 2017).",
      "startOffset" : 111,
      "endOffset" : 165
    }, {
      "referenceID" : 65,
      "context" : ", ToD is used to automate telephone customer service tasks ranging from hospitality over healthcare to banking (Raux et al., 2003; Young, 2010; El Asri et al., 2017).",
      "startOffset" : 111,
      "endOffset" : 165
    }, {
      "referenceID" : 50,
      "context" : "Typical ToD systems still rely on a modular design: (i) the Natural Language Understanding (NLU) module maps user utterances into a domainspecific set of intent labels and values (Rastogi et al., 2019; Heck et al., 2020; Dai et al., 2021), followed by (ii) the policy module, which makes decisions based on the information extracted by the NLU (Lubis et al.",
      "startOffset" : 179,
      "endOffset" : 238
    }, {
      "referenceID" : 19,
      "context" : "Typical ToD systems still rely on a modular design: (i) the Natural Language Understanding (NLU) module maps user utterances into a domainspecific set of intent labels and values (Rastogi et al., 2019; Heck et al., 2020; Dai et al., 2021), followed by (ii) the policy module, which makes decisions based on the information extracted by the NLU (Lubis et al.",
      "startOffset" : 179,
      "endOffset" : 238
    }, {
      "referenceID" : 8,
      "context" : "Typical ToD systems still rely on a modular design: (i) the Natural Language Understanding (NLU) module maps user utterances into a domainspecific set of intent labels and values (Rastogi et al., 2019; Heck et al., 2020; Dai et al., 2021), followed by (ii) the policy module, which makes decisions based on the information extracted by the NLU (Lubis et al.",
      "startOffset" : 179,
      "endOffset" : 238
    }, {
      "referenceID" : 43,
      "context" : ", 2021), followed by (ii) the policy module, which makes decisions based on the information extracted by the NLU (Lubis et al., 2020; Wang et al., 2020a) Yes, I need this card to arrive before 3pm on Jan 14 Intents: affirm, card, arrival, less_lower_before",
      "startOffset" : 113,
      "endOffset" : 153
    }, {
      "referenceID" : 54,
      "context" : ", 2021), followed by (ii) the policy module, which makes decisions based on the information extracted by the NLU (Lubis et al., 2020; Wang et al., 2020a) Yes, I need this card to arrive before 3pm on Jan 14 Intents: affirm, card, arrival, less_lower_before",
      "startOffset" : 113,
      "endOffset" : 153
    }, {
      "referenceID" : 18,
      "context" : ", the user’s intents) and corresponds to the standard NLU task of intent detection (ID); the latter extracts specific slot values and corresponds to the NLU task of slot labeling (SL) (Gupta et al., 2019).",
      "startOffset" : 184,
      "endOffset" : 204
    }, {
      "referenceID" : 3,
      "context" : "Consequently, this makes domain-relevant NLU data extremely expensive to collect and annotate, and prevents its reusability (Budzianowski et al., 2018).",
      "startOffset" : 124,
      "endOffset" : 151
    }, {
      "referenceID" : 20,
      "context" : "For instance, for some standard and commonly used NLU datasets such as ATIS (Hemphill et al., 1990; Xu et al., 2020) and SNIPS (Coucke et al.",
      "startOffset" : 76,
      "endOffset" : 116
    }, {
      "referenceID" : 63,
      "context" : "For instance, for some standard and commonly used NLU datasets such as ATIS (Hemphill et al., 1990; Xu et al., 2020) and SNIPS (Coucke et al.",
      "startOffset" : 76,
      "endOffset" : 116
    }, {
      "referenceID" : 7,
      "context" : ", 2020) and SNIPS (Coucke et al., 2018), the results of SotA models are all in the region of 97-98 F1, with new models getting statistically insignificant gains which might be due to overfitting to the test set or even some remaining annotation errors.",
      "startOffset" : 18,
      "endOffset" : 39
    }, {
      "referenceID" : 20,
      "context" : "the early 1990s, when the Airline Travel Information System (ATIS) project was started (Hemphill et al., 1990), consisting of spoken queries on flightrelated information.",
      "startOffset" : 87,
      "endOffset" : 110
    }, {
      "referenceID" : 3,
      "context" : "To adapt to the increasing data requirements of deep learning models, increasingly larger dialogue datasets have been released in recent years (Budzianowski et al., 2018; Wei et al., 2018; Rastogi et al., 2019; Peskov et al., 2019).",
      "startOffset" : 143,
      "endOffset" : 231
    }, {
      "referenceID" : 57,
      "context" : "To adapt to the increasing data requirements of deep learning models, increasingly larger dialogue datasets have been released in recent years (Budzianowski et al., 2018; Wei et al., 2018; Rastogi et al., 2019; Peskov et al., 2019).",
      "startOffset" : 143,
      "endOffset" : 231
    }, {
      "referenceID" : 50,
      "context" : "To adapt to the increasing data requirements of deep learning models, increasingly larger dialogue datasets have been released in recent years (Budzianowski et al., 2018; Wei et al., 2018; Rastogi et al., 2019; Peskov et al., 2019).",
      "startOffset" : 143,
      "endOffset" : 231
    }, {
      "referenceID" : 46,
      "context" : "To adapt to the increasing data requirements of deep learning models, increasingly larger dialogue datasets have been released in recent years (Budzianowski et al., 2018; Wei et al., 2018; Rastogi et al., 2019; Peskov et al., 2019).",
      "startOffset" : 143,
      "endOffset" : 231
    }, {
      "referenceID" : 27,
      "context" : "(4)We note that some Question Classification (Hovy et al., 2001), Paraphrasing (Dolan and Brockett, 2005) and Semantic Text Similarity(Agirre et al.",
      "startOffset" : 45,
      "endOffset" : 64
    }, {
      "referenceID" : 10,
      "context" : ", 2001), Paraphrasing (Dolan and Brockett, 2005) and Semantic Text Similarity(Agirre et al.",
      "startOffset" : 22,
      "endOffset" : 48
    }, {
      "referenceID" : 0,
      "context" : ", 2001), Paraphrasing (Dolan and Brockett, 2005) and Semantic Text Similarity(Agirre et al., 2012) datasets could be seen as the seed of modern ID datasets, but were not initially built for that purpose.",
      "startOffset" : 77,
      "endOffset" : 98
    }, {
      "referenceID" : 7,
      "context" : "handful of simple intents and slots (Coucke et al., 2018) to complex ontologies with much larger intent sets (Larson et al.",
      "startOffset" : 36,
      "endOffset" : 57
    }, {
      "referenceID" : 9,
      "context" : "Inspired by these NLU datasets and empowered by transfer learning with PLMs and sentence encoders (Devlin et al., 2019; Liu et al., 2019a; Henderson et al., 2020), there have been great improve-",
      "startOffset" : 98,
      "endOffset" : 162
    }, {
      "referenceID" : 39,
      "context" : "Inspired by these NLU datasets and empowered by transfer learning with PLMs and sentence encoders (Devlin et al., 2019; Liu et al., 2019a; Henderson et al., 2020), there have been great improve-",
      "startOffset" : 98,
      "endOffset" : 162
    }, {
      "referenceID" : 22,
      "context" : "Inspired by these NLU datasets and empowered by transfer learning with PLMs and sentence encoders (Devlin et al., 2019; Liu et al., 2019a; Henderson et al., 2020), there have been great improve-",
      "startOffset" : 98,
      "endOffset" : 162
    }, {
      "referenceID" : 34,
      "context" : "1) They use crowdworkers for data collection and annotation, often through simple rephrasings; they thus suffer from low lexical diversity and annotation errors (Larson et al., 2019a).",
      "startOffset" : 161,
      "endOffset" : 183
    }, {
      "referenceID" : 56,
      "context" : "While DST is theoretically more accurate, it requires amounts of data that grow exponentially with the number of turns; moreover, rule-based trackers have proven to be on par with the learned/statistical ones and require no data (Wang and Lemon, 2013).",
      "startOffset" : 229,
      "endOffset" : 251
    }, {
      "referenceID" : 5,
      "context" : "large set of fine-grained intents (again, with multiintent examples) and a large set of fine-grained slots, which prevents proper and more insightful evaluations of joint NLU models (Chen et al., 2019; Gangadharaiah and Narayanaswamy, 2019).",
      "startOffset" : 182,
      "endOffset" : 240
    }, {
      "referenceID" : 15,
      "context" : "large set of fine-grained intents (again, with multiintent examples) and a large set of fine-grained slots, which prevents proper and more insightful evaluations of joint NLU models (Chen et al., 2019; Gangadharaiah and Narayanaswamy, 2019).",
      "startOffset" : 182,
      "endOffset" : 240
    }, {
      "referenceID" : 47,
      "context" : "Further, synthetic multi-intent datasets have been created by concatenating single-intent sentences, but such datasets also do not capture the complexity of true and natural multi-intent sentences (Qin et al., 2020).",
      "startOffset" : 197,
      "endOffset" : 215
    }, {
      "referenceID" : 70,
      "context" : "(Zhang et al., 2020) proposed a similar way of annotating intents categorising them in four predefined factors.",
      "startOffset" : 0,
      "endOffset" : 20
    }, {
      "referenceID" : 2,
      "context" : "Note that in single-label ID setups, all possible intent combinations must be covered (Bi and Kwok, 2013; Hou et al., 2020), which leads to unnecessarily large intent sets and larger data requirements.",
      "startOffset" : 86,
      "endOffset" : 123
    }, {
      "referenceID" : 26,
      "context" : "Note that in single-label ID setups, all possible intent combinations must be covered (Bi and Kwok, 2013; Hou et al., 2020), which leads to unnecessarily large intent sets and larger data requirements.",
      "startOffset" : 86,
      "endOffset" : 123
    }, {
      "referenceID" : 20,
      "context" : "Following the design of previous standard SL datasets (Hemphill et al., 1990; Coucke et al., 2018; Coope et al., 2020), we provide span annotations",
      "startOffset" : 54,
      "endOffset" : 118
    }, {
      "referenceID" : 7,
      "context" : "Following the design of previous standard SL datasets (Hemphill et al., 1990; Coucke et al., 2018; Coope et al., 2020), we provide span annotations",
      "startOffset" : 54,
      "endOffset" : 118
    }, {
      "referenceID" : 6,
      "context" : "Following the design of previous standard SL datasets (Hemphill et al., 1990; Coucke et al., 2018; Coope et al., 2020), we provide span annotations",
      "startOffset" : 54,
      "endOffset" : 118
    }, {
      "referenceID" : 13,
      "context" : "However, even with much simpler ontologies, workers are prone to make annotation mistakes, leading to very noisy datasets (Eric et al., 2019).",
      "startOffset" : 122,
      "endOffset" : 141
    }, {
      "referenceID" : 29,
      "context" : "In addition, when workers are asked to rephrase a sentence, they often change its semantic meaning or tend to provide rephrasings with extremely low lexical variability (Kang et al., 2018).",
      "startOffset" : 169,
      "endOffset" : 188
    }, {
      "referenceID" : 20,
      "context" : "Table 4: Comparison of NLU++ with other popular NLU datasets; ATIS (Hemphill et al., 1990), SNIPS (Coucke et al.",
      "startOffset" : 67,
      "endOffset" : 90
    }, {
      "referenceID" : 7,
      "context" : ", 1990), SNIPS (Coucke et al., 2018), OOS (Larson et al.",
      "startOffset" : 15,
      "endOffset" : 36
    }, {
      "referenceID" : 28,
      "context" : "In order to asses the quality and diversity of the NLU data, we include two additional metrics: 1) Type-Token Ratio (TTR) (Jurafsky and Martin, 2000) which measures lexical diversity) and semantic diversity.",
      "startOffset" : 122,
      "endOffset" : 149
    }, {
      "referenceID" : 22,
      "context" : "The semantic diversity per intent is computed as follows: (i) sentence encodings, obtained by the ConveRT sentence encoder (Henderson et al., 2020),11 are computed for the set of sentences sharing the same intent; (ii) the centroid of these encodings is then computed; (iii) finally, the average cosine distance from each encoding to the centroid is computed.",
      "startOffset" : 123,
      "endOffset" : 147
    }, {
      "referenceID" : 9,
      "context" : "(2021) have recently shown that, for the ID task, full and expensive fine-tuning of large pretrained models such as BERT (Devlin et al., 2019) or RoBERTa (Liu et al.",
      "startOffset" : 121,
      "endOffset" : 142
    }, {
      "referenceID" : 39,
      "context" : ", 2019) or RoBERTa (Liu et al., 2019a) is not needed to reach strong ID performance.",
      "startOffset" : 19,
      "endOffset" : 38
    }, {
      "referenceID" : 22,
      "context" : "15 In a nutshell, the idea is to use fixed/frozen “offthe-shelf” universal sentence encoders such as ConveRT (Henderson et al., 2020) or Sentence-BERT (Reimers and Gurevych, 2019) models to encode",
      "startOffset" : 109,
      "endOffset" : 133
    }, {
      "referenceID" : 52,
      "context" : ", 2020) or Sentence-BERT (Reimers and Gurevych, 2019) models to encode",
      "startOffset" : 25,
      "endOffset" : 53
    }, {
      "referenceID" : 22,
      "context" : "The evalauted sentence encoders are: 1) CONVERT (Henderson et al., 2020),",
      "startOffset" : 48,
      "endOffset" : 72
    }, {
      "referenceID" : 14,
      "context" : "which produces 1,024-dimensional sentence encodings; 2) LABSE (Feng et al., 2020) (768-dim); 3) ROBL-1B (1,024-dim) and 4) LM12-1B (384dim) (Reimers and Gurevych, 2019; Thakur et al.",
      "startOffset" : 62,
      "endOffset" : 81
    }, {
      "referenceID" : 52,
      "context" : ", 2020) (768-dim); 3) ROBL-1B (1,024-dim) and 4) LM12-1B (384dim) (Reimers and Gurevych, 2019; Thakur et al., 2021).",
      "startOffset" : 66,
      "endOffset" : 115
    }, {
      "referenceID" : 53,
      "context" : ", 2020) (768-dim); 3) ROBL-1B (1,024-dim) and 4) LM12-1B (384dim) (Reimers and Gurevych, 2019; Thakur et al., 2021).",
      "startOffset" : 66,
      "endOffset" : 115
    }, {
      "referenceID" : 45,
      "context" : "tractive) question-answering (QA) problem (Namazifar et al., 2021).",
      "startOffset" : 42,
      "endOffset" : 66
    }, {
      "referenceID" : 49,
      "context" : "BERT/RoBERTa on readily available large generalpurpose QA data such as SQuAD (Rajpurkar et al., 2016), and then (ii) further fine-tune this general QA model with in-domain ID data.",
      "startOffset" : 77,
      "endOffset" : 101
    }, {
      "referenceID" : 45,
      "context" : "This strategy has recently shown very strong performance on single-label ATIS data (Namazifar et al., 2021).",
      "startOffset" : 83,
      "endOffset" : 107
    }, {
      "referenceID" : 38,
      "context" : "Here, [SENTENCE] is the placeholder for the actual input sentence, and [INTENT] is the placeholder for a short manually defined text (akin to language modeling prompts (Liu et al., 2021), see again Appendix A) which",
      "startOffset" : 168,
      "endOffset" : 186
    }, {
      "referenceID" : 48,
      "context" : "0 dataset (Rajpurkar et al., 2018) before additional QAtuning on NLU++ examples converted to the aforementioned QA format: ROBB-QA uses RoBERTaBase as the underlying LM, while ALB-QA relies",
      "startOffset" : 10,
      "endOffset" : 34
    }, {
      "referenceID" : 42,
      "context" : "We use the standard AdamW optimizer (Loshchilov and Hutter, 2018) with the learning rate of 0.",
      "startOffset" : 36,
      "endOffset" : 65
    }, {
      "referenceID" : 24,
      "context" : "For slot labeling, we benchmark two current SotA models: (i) ConvEx (Henderson and Vulić, 2021), as a SotA span-extraction SL model and (ii) the QA-based SL model (Namazifar et al.",
      "startOffset" : 68,
      "endOffset" : 95
    }, {
      "referenceID" : 45,
      "context" : "For slot labeling, we benchmark two current SotA models: (i) ConvEx (Henderson and Vulić, 2021), as a SotA span-extraction SL model and (ii) the QA-based SL model (Namazifar et al., 2021) based on ROBB-QA, which operates similarly to QAbased ID baselines discussed in §4.",
      "startOffset" : 163,
      "endOffset" : 187
    }, {
      "referenceID" : 4,
      "context" : ", the variations in F1 scores between all sentence encoders are typically below 4-6 F1 points in all setups), and 2) that CONVERT is the best-performing sentence encoder on average, which corroborates findings from prior work on other ID datasets (Casanueva et al., 2020; Wu and Xiong, 2020).",
      "startOffset" : 247,
      "endOffset" : 291
    }, {
      "referenceID" : 61,
      "context" : ", the variations in F1 scores between all sentence encoders are typically below 4-6 F1 points in all setups), and 2) that CONVERT is the best-performing sentence encoder on average, which corroborates findings from prior work on other ID datasets (Casanueva et al., 2020; Wu and Xiong, 2020).",
      "startOffset" : 247,
      "endOffset" : 291
    }, {
      "referenceID" : 38,
      "context" : "In the SL task, the QA-based model also demonstrates its superiority, again with huge gains in low-data 20-Fold and 10-Fold setups, confirming that such QA-based or prompt-based methods (Liu et al., 2021; Gao et al., 2021) are especially well suited for low-data setups.",
      "startOffset" : 186,
      "endOffset" : 222
    }, {
      "referenceID" : 16,
      "context" : "In the SL task, the QA-based model also demonstrates its superiority, again with huge gains in low-data 20-Fold and 10-Fold setups, confirming that such QA-based or prompt-based methods (Liu et al., 2021; Gao et al., 2021) are especially well suited for low-data setups.",
      "startOffset" : 186,
      "endOffset" : 222
    }, {
      "referenceID" : 24,
      "context" : "Table 6: F1 scores (×100%) on the NLU++ SL task for CONVEX (Henderson and Vulić, 2021) and a QABased approach (Namazifar et al.",
      "startOffset" : 59,
      "endOffset" : 86
    }, {
      "referenceID" : 45,
      "context" : "Table 6: F1 scores (×100%) on the NLU++ SL task for CONVEX (Henderson and Vulić, 2021) and a QABased approach (Namazifar et al., 2021) across different domains and data setups.",
      "startOffset" : 110,
      "endOffset" : 134
    } ],
    "year" : 0,
    "abstractText" : "We present NLU++, a novel dataset for natural language understanding (NLU) in taskoriented dialogue (ToD) systems, with the aim to provide a much more challenging evaluation environment for dialogue NLU models, up to date with the current application and industry requirements. NLU++ is divided into two domains (BANKING and HOTELS) and brings several crucial improvements over current commonly used NLU datasets. 1) NLU++ provides fine-grained domain ontologies with a large set of challenging multi-intent sentences combined with finer-grained and thus more challenging slot sets. 2) The ontology is divided into domain-specific and generic (i.e., domainuniversal) intents that overlap across domains, promoting cross-domain reusability of annotated examples. 3) The dataset design has been inspired by the problems observed in industrial ToD systems, and 4) it has been collected, filtered and carefully annotated by dialogue NLU experts, yielding high-quality annotated data. Finally, we benchmark a series of current state-of-the-art NLU models on NLU++; the results demonstrate the challenging nature of the dataset, especially in low-data regimes, and call for further research on ToD NLU.",
    "creator" : null
  }
}