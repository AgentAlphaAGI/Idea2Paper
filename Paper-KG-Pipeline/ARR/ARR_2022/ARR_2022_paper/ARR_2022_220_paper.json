{
  "name" : "ARR_2022_220_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Data Augmentation with Dual Training for Offensive Span Detection",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "It’s no secret that social networks are growing in popularity. However, growth in popularity also brings some challenges, including the toxicity associated with the content posted by users. It may take different forms in social media, including insults, mockery, threats, discrimination, or swearing. The presence of offensive text in social networks can have a detrimental effect on their users, making it desirable to identify and remove them from the text.\nSince this is an important requirement, the task of offensive language detection has been extensively studied in NLP community (Schmidt and Wiegand, 2017; Wulczyn et al., 2017; Feng et al., 2018; Borkan et al., 2019; Pavlopoulos et al., 2019; Sivanaiah et al., 2020; Yasaswini et al., 2021) Most existing works, however, only classify a text snippet as offensive or not, failing to provide further information on which specific words and phrases in the text contribute the most to its offensive tone. If the text snippet is lengthy, the moderators will need this information to decide how to proceed with the offenses flagged. As such, in this work, we fill this gap by proposing a novel model for the task of offensive span detection (OSD). As an example, in the given text “This live streamer clearly has no brain; he is such a tool!\", the phrase “has no brain\" and the slang word “tool\" are two offensive spans responsible for the toxicity of the text. One of the barriers to this task is the lack of labeled data. Inspired by the recent advances in the application of pre-trained language models to augment training data for low-resources tasks (Zhang et al., 2020; Yang et al., 2020; Peng et al., 2020; Kumar et al., 2020; Anaby-Tavor et al., 2020), we propose to employ the GPT-2 model to overcome the data scarcity of OSD. To address this limitation, we propose a novel model in which the OSD training data are augmented with the synthetic samples generated by a transformer-based language model. In particular, the original labeled samples of OSD, with special markers before and after each offensive span, are employed to fine-tune the parameters of the GPT-2 model to generate sentences containing offensive spans. Moreover, in order to increase the quality of the generated samples, we propose to explicitly encourage the GPT-2 model to generate diverse sentences while keeping them similar to the original training samples. Also, the model is encouraged to generate sentences that will result in improvement of the performance of the OSD task. To fulfill these objectives, in a dual training setting, the REINFORCE algorithm (Williams, 1992) is exploited to train the GPT-2 model. We evaluate the proposed model on a recently released dataset for offensive span detection. Our extensive experiments show the effectiveness of the proposed model by outperforming the strong baselines."
    }, {
      "heading" : "2 Model",
      "text" : "Formal Task Description: The input to the model is the document D = [w1, w2, . . . , wn] consisting of n words. The label provided for the document is also the sequence Y = [y1, y2, . . . , yn] in which yi is the label for the word wi in BIO format. This problem is modeled as a sequence labeling task in which the model predicts the label of every word wi in the document D. In this work, we propose a method to augment the original training samples O, with synthetic labeled text G generated by a fine-tuned GPT-2 model. The rest of this section describes the base model and the data augmentation process."
    }, {
      "heading" : "2.1 Base Model",
      "text" : "In our approach, we employ the pre-trained BERTbase transformer as the base sequence labeling model which is trained on D = O ⋃ G. Specifically, the document D ∈ D is fed into the BERT model in the form of [CLS]w1w2 . . . wn[SEP ] to obtain the word representations X = [x1, x2, . . . , xn]. Note that for the words consisting of multiple word pieces we take the average of their corresponding word-piece representations. Next, the representations xi are sent to a feed-forward network to predict the label distribution P (·|D, θ), where θ is the parameters of the BERT model. To train the model, we employ the negative log-likelihood:\nLbase = − |D|∑ i=1 n∑ j=1 P (yj |Di, θ) (1)\nwhere yj is the gold label for j-th word of the document Di."
    }, {
      "heading" : "2.2 Data Augmentation",
      "text" : "One of the limitations for OSD is the lack of enough labeled data. To address this limitation, inspired by the success of the generative language models to augment data for other tasks, we propose to employ GPT-2 to generate labeled synthetic data. We first discuss the generation process, then we provide details on how the generative model is encouraged to generate high-quality data. Generation: Following prior works (Zhang et al., 2020), to generate synthetic data we employ GPT2 (Radford et al., 2019) model. GPT-2 is a transformer-based language model pre-trained on\n40 GB of textual data. In order to fine-tune GPT2 for generating labeled data for OSD, we propose to employ the original labeled data G. Specifically, the document D ∈ G is first augmented with special tokens at the beginning and the end of the document and also around the offensive spans: D′ = [BOS]w1, w2, . . . [OFFENSIV ES ]wi, wi+1, . . . , wi+t[OFFENSIV EE ]wi+t+1, . . . , wn[EOS], where t is the length of the offensive span in D. Note that there might be multiple offensive span in a document. Next, the GPT-2 model is trained in an auto-regressive manner on the labeled augmented documents D′. Specifically, the following loss is employed for the fine-tuning process:\nLf = − |O|∑ i=1 |D′i|∑ j=1 PG(w ′ j |D′<j , α) (2)\nwhere w′j is the j-th word in the label augmented document D′i, D ′ <j is the left context of the word w′j in the document D ′ i, and α is the parameters of the GPT-2 model. Finally, the fine-tuned GPT-2 model is employed to generate |O| synthetic data. Specifically, the model is prompted with [BOS] token and the generation is stopped by generating the [EOS] token. In order to ensure that the generated data are labeled, we keep only the generated samples with at least one pair of [OFFENSIV ES ] and [OFFENSIV EE ] tokens. The generated samples, i.e., G, are combined with the original samples O, to obtain the final D dataset to train the base model. Improving Quality of Generated Samples: While the fine-tuning process of GPT-2 is supposed to be effective to generate high-quality data, it has been shown that the generated data might be noisy or have repeated sentences (Veyseh et al., 2021), providing harmful or less supervision signals to the base model training. As such, we propose to explicitly encourage GPT-2 model to generate documents that results in better performance on OSD task and satisfy the diversity requirements of the generated data. In particular, we propose to employ dual training with REINFORCE to ensure the following requirements are observed: (1) Usefulness: The generated documents should be helpful to improve the performance on the final task. As such, the F1 score of the base model, trained using D, on the original dataO is employed as a measure of usefulness of the generated data: Ru(G) = F1(O); (2) Diversity: If the generated samples are identical or\nsimilar to the original data, they will not provide enough new training signals to the base model. As such, it is necessary to ensure that the generated data can increase the diversity of the data. To this end, using the representation of the [CLS] token of each input document D obtained from the base model, we cluster the documents in the combined dataset D1. The number of detected clusters are used as the diversity reward: Rd(G) = |CD|\nThe overall reward for the generated documents G is computed asR = βRu(G)+γRd(G), where β and γ are trade-off parameters. The REINFORCE algorithm is employed to update the parameters of the GPT-2 model. Concretely, the parameters of the generative model are updated by the estimated gradient: ∇LG = −(R(G))∇ logP (G|α,O), where P (G|α,O) is the probability of the generated data G computed as the product of the probabilities P (D′|α,O) = ∑|D′| t=1 PG(w ′ j |D′<j , α). Training Procedure: In order to simultaneously update the parameters of the base model and also the GPT-2 model, we propose a dual training procedure. Specifically, at the first epoch, the parameters of the GPT-2 model are updated using the loss lf . Next, GPT-2 model is employed to generate the labeled synthetic data to obtain the combined dataset D. After one epoch of training the base model using the loss Lbase, the parameters of the GPT-2 model are updated using the REINFORCE algorithm. The updated GPT-2 model is employed to generate a new set of synthetic data to be replaced with the previously generated data in D. The new combined data will be next employed to update the base model. This process is repeated until the convergence of training."
    }, {
      "heading" : "3 Experiments",
      "text" : "In order to evaluate the effectiveness of the proposed model, called GAOSD (Generation-based Augmentation for Offensive Span Detection), in our experiments, we use the dataset of SemEval 2021 Task 5 (John Pavlopoulos and Laugier, 2021). This dataset contains annotations for 10,000 posts (comments) obtained from the archive of Civil Comment platform (a platform for community to share comments about various civility issues). We use the official splits with 7939/690/2000 documents in train/development/test sets. For each document, the word indices of offensive spans are provided. In our experiments, we create the BIO labels\n1We use K-means for clustering\nusing the provided word indices of the offensive spans. For reproducibility details, see appendices.\nwe compare the performance of GAOSD with the following baselines: (1) BiLSTM+CRF: The GloVe embedded document is encoded by BiLSTM and the labels are predicted by a CRF layer; (2) BERT+CRF: BERTbase parameters are finetuned on OSD task and the task-specific head, i.e., CRF, is employed for label prediction; (3) HITSZHLT (Zhu et al., 2021): This baseline is the existing SOTA model on SemEval 2021 Task 5 dataset; (4) SANER (Nie et al., 2020): This baseline is the SOTA model for sequence labeling on usergenerated text; (5) DUAL-MRC (Mao et al., 2021): This is the SOTA model for opinion and aspect term extraction. Note that since there are not target annotations in SemEval dataset, we skip the aspect term extraction task to train this baseline. To evaluate the performance we use the official metric, i.e. char-level F1-score, as the evaluation metric. Following prior work (Zhu et al., 2021), we also report the average of char-level precision and recall (Note that due to averaging, F1 6= 2(P ∗R)/(P +R)). Results: Table 1 shows the performance of the models on the test set. There are several observations from this table. First, the BiLSTM-CRF model significantly underperforms the other baselines that employ BERT embedding. It clearly shows that the background knowledge encoded in the BERT model is necessary for the task of offensive span detection. Second, both DUALMRC and SANER baseline outperform the BERTCRF model. This higher performance could be attributed to their capability to enhance the representation of the words obtained from the BERT model. Third, among all baselines, our proposed model achieves the highest performance. Our hypothesis for the achieved improvement is that in the proposed method we employ more diverse sets of patterns for expressing toxic. The increased diversity is realized by generating more diverse\nsentences. Also, this improvement proves that the generated sentences are in-domain and task specific, as such resulting in an improvement. The better performance of our model is impressive, especially considering that we use relatively simple base model compared to other baselines (in particular HITSZ-HLT which is an ensemble model). Analysis: To study the contribution of the proposed techniques, we conduct an ablation study on the development set of the SemEval 2021 Task 5 dataset. Specifically, we ablate the quality improvement component which ensures the usefulness and diversity of the generated samples. In particular, we study the performance of the model when the Usefulness Reward (UR−), the Diversity Reward (DR−), or both of them (UDR−) are ablated. Also, we study the performance of the model when no dual training is employed (DT−). Specifically, we first pre-train the base model on the available original data. Next, we fix the parameters of the base model and we use it to compute the usefulness reward. The results are shown in Table 2. This table shows that all components are necessary, as removing each will hurt the performance. Specifically, the dual training has the largest effect on the final performance, indicating the importance of the proposed method. Also, among the two proposed rewards to improve the quality of the generated data, we observe that usefulness reward is more critical, indicating the importance of task-specific generation for data augmentation.\nFinally, in order to provide more insight into the quality of the generated data, we provide some randomly selected text generated by the fine-tuned GPT-2 model. The results are shown in table 3. This table shows that the generated samples are natural and also they contain the offensive spans. The generative model is able to correctly locate the offensive spans in the generated text, thereby provided high-quality training samples for the base model. It is worth noting that the offensive spans generated by the fine-tuned GPT-2 model can be either short spans, as in samples 1 and 3 in table 3, or longer phrases, as in sample 2."
    }, {
      "heading" : "4 Related Work",
      "text" : "Prior works related to this task can be categorized into two groups: (i) Toxicity Detection: These works aim to classify a piece of text as toxic or nontoxic (Wulczyn et al., 2017; Borkan et al., 2019; Schmidt and Wiegand, 2017; Pavlopoulos et al., 2017a,b, 2019; Zampieri et al., 2019). The main limitation of these works is that they cannot recognize the spans in the text that are responsible for the toxicity of the text. (ii) Opinion Word Extraction: In this group of prior works, models perform a sequence labeling task to identify the spans in the text that convey the sentiment (Liu et al., 2015; Xu et al., 2018; Yin et al., 2016; Wang et al., 2016, 2017; Li and Lam, 2017; Mao et al., 2021). The major limitation of all these models is that they require the existence of the target opinion (i.e., the word or phrase that the text has a sentiment polarity toward it)."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this work, we propose a novel method for augmenting data for offensive span detection tasks. Specifically, we employ the pre-trained language model GPT-2 to be fine-tuned on the available training samples for OSD. The fine-tuned model is able to generate in-domain texts with special tokens indicating the offensive spans in them. Moreover, to improve the quality of the generated documents, we propose a novel dual training setting in which the feedback from the OSD model is employed to guide the GPT-2 model to generate more impact synthetic data. Together with a reward for encouraging the diversity of the generated data, the proposed method is effective to augment the training data for OSD, resulting in the state-of-the-art performance on the recent benchmark datasets."
    }, {
      "heading" : "A Reproducibility Checklist",
      "text" : "• Description of computing infrastructure used: We use a single GeForce RTX 2080 GPU with 11GB memory in this work. PyTorch 1.1 is used to implement the models.\n• Average runtime for each approach: Each epoch of our full model on average takes 14 minutes. We train the model for 20 epochs. The best epoch is chosen based on the F1 score over the development set.\n• Explanation of evaluation metrics used, with links to code: We use the official evaluation metrics for the SemEval 2021 Task 5 (John Pavlopoulos and Laugier, 2021).\n• Bounds for each hyperparameter: To train the proposed model, we choose the learning rate from [0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5] for the Adam optimizer, the mini-batch size from [16, 32, 64, 128], the dimensionality for hidden vectors in layers of all the feed-forward networks and BiLSTM modules in the baseline from [100, 150, 200, 250, 300, 350, 400, 450, 500], the numbers of layers for the feedforward networks from [1, 2, 3, 4, 5], all trade-off parameters from [0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.2, 0.3, 0.4, 0.5].\n• Hyperparameter configurations for bestperforming models: In our model we use the BERTbase to encode data; 250 dimensions for the hidden states of BiLSTM and 2 layers for feed-forward neural networks with 250 hidden dimensions. The trade-off parameters β and γ are set to 0.1, 0.1, and 0.05, respectively. The learning rate is set to 0.3 for the Adam optimizer and the batch size of 64 is employed during training.\n• The method of choosing hyperparameter values and the criterion used to select among them: We tune the hyperparameters for the proposed model using a random search. All the hyperparameters are selected based on the F1 scores on the development set."
    } ],
    "references" : [ {
      "title" : "Do not have enough data? deep learning to the rescue",
      "author" : [ "Ateret Anaby-Tavor", "Boaz Carmeli", "Esther Goldbraich", "Amir Kantor", "George Kour", "Segev Shlomov", "Naama Tepper", "Naama Zwerdling" ],
      "venue" : "In The Thirty-Fourth AAAI Conference on Artificial Intelli-",
      "citeRegEx" : "Anaby.Tavor et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Anaby.Tavor et al\\.",
      "year" : 2020
    }, {
      "title" : "Nuanced metrics for measuring unintended bias with real data for text classification",
      "author" : [ "Daniel Borkan", "Lucas Dixon", "Jeffrey Sorensen", "Nithum Thain", "Lucy Vasserman." ],
      "venue" : "Companion proceedings of the 2019 world wide web conference, pages 491–500.",
      "citeRegEx" : "Borkan et al\\.,? 2019",
      "shortCiteRegEx" : "Borkan et al\\.",
      "year" : 2019
    }, {
      "title" : "Pathologies of neural models make interpretations difficult",
      "author" : [ "Shi Feng", "Eric Wallace", "Alvin Grissom II", "Mohit Iyyer", "Pedro Rodriguez", "Jordan Boyd-Graber." ],
      "venue" : "arXiv preprint arXiv:1804.07781.",
      "citeRegEx" : "Feng et al\\.,? 2018",
      "shortCiteRegEx" : "Feng et al\\.",
      "year" : 2018
    }, {
      "title" : "Toxic span detection at semeval 2021",
      "author" : [ "Jeffrey Sorensen John Pavlopoulos", "Ion Androutsopoulos", "Léo Laugier." ],
      "venue" : "SemEval 2021 (To Appear).",
      "citeRegEx" : "Pavlopoulos et al\\.,? 2021",
      "shortCiteRegEx" : "Pavlopoulos et al\\.",
      "year" : 2021
    }, {
      "title" : "Data augmentation using pre-trained transformer models",
      "author" : [ "Varun Kumar", "Ashutosh Choudhary", "Eunah Cho." ],
      "venue" : "aarXiv.",
      "citeRegEx" : "Kumar et al\\.,? 2020",
      "shortCiteRegEx" : "Kumar et al\\.",
      "year" : 2020
    }, {
      "title" : "Deep multi-task learning for aspect term extraction with memory interaction",
      "author" : [ "Xin Li", "Wai Lam." ],
      "venue" : "Proceedings of the 2017 conference on empirical methods in natural language processing, pages 2886–2892.",
      "citeRegEx" : "Li and Lam.,? 2017",
      "shortCiteRegEx" : "Li and Lam.",
      "year" : 2017
    }, {
      "title" : "Finegrained opinion mining with recurrent neural networks and word embeddings",
      "author" : [ "Pengfei Liu", "Shafiq Joty", "Helen Meng." ],
      "venue" : "Proceedings of the 2015 conference on empirical methods in natural language processing, pages 1433–1443.",
      "citeRegEx" : "Liu et al\\.,? 2015",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2015
    }, {
      "title" : "A joint training dual-mrc framework for aspect based sentiment analysis",
      "author" : [ "Yue Mao", "Yi Shen", "Chao Yu", "Longjun Cai." ],
      "venue" : "arXiv preprint arXiv:2101.00816.",
      "citeRegEx" : "Mao et al\\.,? 2021",
      "shortCiteRegEx" : "Mao et al\\.",
      "year" : 2021
    }, {
      "title" : "Named entity recognition for social media texts with semantic augmentation",
      "author" : [ "Yuyang Nie", "Yuanhe Tian", "Xiang Wan", "Yan Song", "Bo Dai." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Nie et al\\.,? 2020",
      "shortCiteRegEx" : "Nie et al\\.",
      "year" : 2020
    }, {
      "title" : "Deep learning for user comment moderation",
      "author" : [ "John Pavlopoulos", "Prodromos Malakasiotis", "Ion Androutsopoulos." ],
      "venue" : "arXiv preprint arXiv:1705.09993.",
      "citeRegEx" : "Pavlopoulos et al\\.,? 2017a",
      "shortCiteRegEx" : "Pavlopoulos et al\\.",
      "year" : 2017
    }, {
      "title" : "Deeper attention to abusive user content moderation",
      "author" : [ "John Pavlopoulos", "Prodromos Malakasiotis", "Ion Androutsopoulos." ],
      "venue" : "Proceedings of the 2017 conference on empirical methods in natural language processing, pages 1125–1135.",
      "citeRegEx" : "Pavlopoulos et al\\.,? 2017b",
      "shortCiteRegEx" : "Pavlopoulos et al\\.",
      "year" : 2017
    }, {
      "title" : "Convai at semeval2019 task 6: Offensive language identification and categorization with perspective and bert",
      "author" : [ "John Pavlopoulos", "Nithum Thain", "Lucas Dixon", "Ion Androutsopoulos." ],
      "venue" : "Proceedings of the 13th international Workshop on Semantic",
      "citeRegEx" : "Pavlopoulos et al\\.,? 2019",
      "shortCiteRegEx" : "Pavlopoulos et al\\.",
      "year" : 2019
    }, {
      "title" : "Data augmentation for spoken language understanding via pretrained models",
      "author" : [ "Baolin Peng", "Chenguang Zhu", "Michael Zeng", "Jianfeng Gao" ],
      "venue" : null,
      "citeRegEx" : "Peng et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Peng et al\\.",
      "year" : 2020
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever" ],
      "venue" : "OpenAI blog,",
      "citeRegEx" : "Radford et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "A survey on hate speech detection using natural language processing",
      "author" : [ "Anna Schmidt", "Michael Wiegand." ],
      "venue" : "Proceedings of the fifth international workshop on natural language processing for social media, pages 1–10.",
      "citeRegEx" : "Schmidt and Wiegand.,? 2017",
      "shortCiteRegEx" : "Schmidt and Wiegand.",
      "year" : 2017
    }, {
      "title" : "Techssn at semeval-2020 task 12: Offensive language detection using bert embeddings",
      "author" : [ "Rajalakshmi Sivanaiah", "Angel Suseelan", "S Milton Rajendram", "Mirnalinee Tt." ],
      "venue" : "Proceedings of the Fourteenth Workshop on Semantic Evaluation, pages",
      "citeRegEx" : "Sivanaiah et al\\.,? 2020",
      "shortCiteRegEx" : "Sivanaiah et al\\.",
      "year" : 2020
    }, {
      "title" : "Unleash GPT2 power for event detection",
      "author" : [ "Amir Pouran Ben Veyseh", "Viet Lai", "Franck Dernoncourt", "Thien Huu Nguyen." ],
      "venue" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint",
      "citeRegEx" : "Veyseh et al\\.,? 2021",
      "shortCiteRegEx" : "Veyseh et al\\.",
      "year" : 2021
    }, {
      "title" : "Recursive neural conditional random fields for aspect-based sentiment analysis",
      "author" : [ "Wenya Wang", "Sinno Jialin Pan", "Daniel Dahlmeier", "Xiaokui Xiao." ],
      "venue" : "arXiv preprint arXiv:1603.06679.",
      "citeRegEx" : "Wang et al\\.,? 2016",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2016
    }, {
      "title" : "Coupled multi-layer tensor network for co-extraction of aspect and opinion terms",
      "author" : [ "Wenya Wang", "Sinno Jialin Pan", "Daniel Dahlmeier", "Xiaokui Xiao." ],
      "venue" : "Proceedings of AAAI, pages 3316–3322.",
      "citeRegEx" : "Wang et al\\.,? 2017",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2017
    }, {
      "title" : "Simple statistical gradientfollowing algorithms for connectionist reinforcement learning",
      "author" : [ "Ronald J. Williams." ],
      "venue" : "Kluwer Academic.",
      "citeRegEx" : "Williams.,? 1992",
      "shortCiteRegEx" : "Williams.",
      "year" : 1992
    }, {
      "title" : "Ex machina: Personal attacks seen at scale",
      "author" : [ "Ellery Wulczyn", "Nithum Thain", "Lucas Dixon." ],
      "venue" : "Proceedings of the 26th international conference on world wide web, pages 1391–1399.",
      "citeRegEx" : "Wulczyn et al\\.,? 2017",
      "shortCiteRegEx" : "Wulczyn et al\\.",
      "year" : 2017
    }, {
      "title" : "Double embeddings and cnn-based sequence labeling for aspect extraction",
      "author" : [ "Hu Xu", "Bing Liu", "Lei Shu", "Philip S Yu." ],
      "venue" : "arXiv preprint arXiv:1805.04601.",
      "citeRegEx" : "Xu et al\\.,? 2018",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2018
    }, {
      "title" : "G-daug: Generative data augmentation for commonsense reasoning",
      "author" : [ "Yiben Yang", "Chaitanya Malaviya", "Jared Fernandez", "Swabha Swayamdipta", "Ronan Le Bras", "Ji-Ping Wang", "Chandra Bhagavatula", "Yejin Choi", "Doug Downey." ],
      "venue" : "Findings",
      "citeRegEx" : "Yang et al\\.,? 2020",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2020
    }, {
      "title" : "Iiitt@ dravidianlangtech-eacl2021: Transfer learning for offensive language detection in dravidian languages",
      "author" : [ "Konthala Yasaswini", "Karthik Puranik", "Adeep Hande", "Ruba Priyadharshini", "Sajeetha Thavareesan", "Bharathi Raja Chakravarthi" ],
      "venue" : null,
      "citeRegEx" : "Yasaswini et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Yasaswini et al\\.",
      "year" : 2021
    }, {
      "title" : "Unsupervised word and dependency path embeddings for aspect term extraction",
      "author" : [ "Yichun Yin", "Furu Wei", "Li Dong", "Kaimeng Xu", "Ming Zhang", "Ming Zhou." ],
      "venue" : "arXiv preprint arXiv:1605.07843.",
      "citeRegEx" : "Yin et al\\.,? 2016",
      "shortCiteRegEx" : "Yin et al\\.",
      "year" : 2016
    }, {
      "title" : "Semeval-2019 task 6: Identifying and categorizing offensive language in social media (offenseval)",
      "author" : [ "Marcos Zampieri", "Shervin Malmasi", "Preslav Nakov", "Sara Rosenthal", "Noura Farra", "Ritesh Kumar." ],
      "venue" : "arXiv preprint arXiv:1903.08983.",
      "citeRegEx" : "Zampieri et al\\.,? 2019",
      "shortCiteRegEx" : "Zampieri et al\\.",
      "year" : 2019
    }, {
      "title" : "On data augmentation for extreme multi-label classification",
      "author" : [ "Danqing Zhang", "Tao Li", "Haiyang Zhang", "Bing Yin." ],
      "venue" : "arXiv.",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "HITSZ-HLT at SemEval-2021 task 5: Ensemble sequence labeling and span boundary detection for toxic span detection",
      "author" : [ "Qinglin Zhu", "Zijie Lin", "Yice Zhang", "Jingyi Sun", "Xiang Li", "Qihui Lin", "Yixue Dang", "Ruifeng Xu." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Zhu et al\\.,? 2021",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2021
    } ],
    "referenceMentions" : [ {
      "referenceID" : 14,
      "context" : "Since this is an important requirement, the task of offensive language detection has been extensively studied in NLP community (Schmidt and Wiegand, 2017; Wulczyn et al., 2017; Feng et al., 2018; Borkan et al., 2019; Pavlopoulos et al., 2019; Sivanaiah et al., 2020; Yasaswini et al., 2021) Most existing works, however, only classify a text snippet as offensive or not, failing to provide further information on which specific words and phrases in the text contribute the most to its offensive tone.",
      "startOffset" : 127,
      "endOffset" : 290
    }, {
      "referenceID" : 20,
      "context" : "Since this is an important requirement, the task of offensive language detection has been extensively studied in NLP community (Schmidt and Wiegand, 2017; Wulczyn et al., 2017; Feng et al., 2018; Borkan et al., 2019; Pavlopoulos et al., 2019; Sivanaiah et al., 2020; Yasaswini et al., 2021) Most existing works, however, only classify a text snippet as offensive or not, failing to provide further information on which specific words and phrases in the text contribute the most to its offensive tone.",
      "startOffset" : 127,
      "endOffset" : 290
    }, {
      "referenceID" : 2,
      "context" : "Since this is an important requirement, the task of offensive language detection has been extensively studied in NLP community (Schmidt and Wiegand, 2017; Wulczyn et al., 2017; Feng et al., 2018; Borkan et al., 2019; Pavlopoulos et al., 2019; Sivanaiah et al., 2020; Yasaswini et al., 2021) Most existing works, however, only classify a text snippet as offensive or not, failing to provide further information on which specific words and phrases in the text contribute the most to its offensive tone.",
      "startOffset" : 127,
      "endOffset" : 290
    }, {
      "referenceID" : 1,
      "context" : "Since this is an important requirement, the task of offensive language detection has been extensively studied in NLP community (Schmidt and Wiegand, 2017; Wulczyn et al., 2017; Feng et al., 2018; Borkan et al., 2019; Pavlopoulos et al., 2019; Sivanaiah et al., 2020; Yasaswini et al., 2021) Most existing works, however, only classify a text snippet as offensive or not, failing to provide further information on which specific words and phrases in the text contribute the most to its offensive tone.",
      "startOffset" : 127,
      "endOffset" : 290
    }, {
      "referenceID" : 11,
      "context" : "Since this is an important requirement, the task of offensive language detection has been extensively studied in NLP community (Schmidt and Wiegand, 2017; Wulczyn et al., 2017; Feng et al., 2018; Borkan et al., 2019; Pavlopoulos et al., 2019; Sivanaiah et al., 2020; Yasaswini et al., 2021) Most existing works, however, only classify a text snippet as offensive or not, failing to provide further information on which specific words and phrases in the text contribute the most to its offensive tone.",
      "startOffset" : 127,
      "endOffset" : 290
    }, {
      "referenceID" : 15,
      "context" : "Since this is an important requirement, the task of offensive language detection has been extensively studied in NLP community (Schmidt and Wiegand, 2017; Wulczyn et al., 2017; Feng et al., 2018; Borkan et al., 2019; Pavlopoulos et al., 2019; Sivanaiah et al., 2020; Yasaswini et al., 2021) Most existing works, however, only classify a text snippet as offensive or not, failing to provide further information on which specific words and phrases in the text contribute the most to its offensive tone.",
      "startOffset" : 127,
      "endOffset" : 290
    }, {
      "referenceID" : 23,
      "context" : "Since this is an important requirement, the task of offensive language detection has been extensively studied in NLP community (Schmidt and Wiegand, 2017; Wulczyn et al., 2017; Feng et al., 2018; Borkan et al., 2019; Pavlopoulos et al., 2019; Sivanaiah et al., 2020; Yasaswini et al., 2021) Most existing works, however, only classify a text snippet as offensive or not, failing to provide further information on which specific words and phrases in the text contribute the most to its offensive tone.",
      "startOffset" : 127,
      "endOffset" : 290
    }, {
      "referenceID" : 19,
      "context" : "To fulfill these objectives, in a dual training setting, the REINFORCE algorithm (Williams, 1992) is exploited to train the GPT-2 model.",
      "startOffset" : 81,
      "endOffset" : 97
    }, {
      "referenceID" : 26,
      "context" : "Generation: Following prior works (Zhang et al., 2020), to generate synthetic data we employ GPT2 (Radford et al.",
      "startOffset" : 34,
      "endOffset" : 54
    }, {
      "referenceID" : 13,
      "context" : ", 2020), to generate synthetic data we employ GPT2 (Radford et al., 2019) model.",
      "startOffset" : 51,
      "endOffset" : 73
    }, {
      "referenceID" : 16,
      "context" : "Improving Quality of Generated Samples: While the fine-tuning process of GPT-2 is supposed to be effective to generate high-quality data, it has been shown that the generated data might be noisy or have repeated sentences (Veyseh et al., 2021), providing harmful or less supervision signals to the base model training.",
      "startOffset" : 222,
      "endOffset" : 243
    }, {
      "referenceID" : 27,
      "context" : ", CRF, is employed for label prediction; (3) HITSZHLT (Zhu et al., 2021): This baseline is the existing SOTA model on SemEval 2021 Task 5 dataset; (4) SANER (Nie et al.",
      "startOffset" : 54,
      "endOffset" : 72
    }, {
      "referenceID" : 8,
      "context" : ", 2021): This baseline is the existing SOTA model on SemEval 2021 Task 5 dataset; (4) SANER (Nie et al., 2020): This baseline is the SOTA model for sequence labeling on usergenerated text; (5) DUAL-MRC (Mao et al.",
      "startOffset" : 92,
      "endOffset" : 110
    }, {
      "referenceID" : 7,
      "context" : ", 2020): This baseline is the SOTA model for sequence labeling on usergenerated text; (5) DUAL-MRC (Mao et al., 2021):",
      "startOffset" : 99,
      "endOffset" : 117
    }, {
      "referenceID" : 27,
      "context" : "Following prior work (Zhu et al., 2021), we also report the average of char-level precision and recall (Note that due to averaging, F1 6= 2(P ∗R)/(P +R)).",
      "startOffset" : 21,
      "endOffset" : 39
    }, {
      "referenceID" : 6,
      "context" : "a sequence labeling task to identify the spans in the text that convey the sentiment (Liu et al., 2015; Xu et al., 2018; Yin et al., 2016; Wang et al., 2016, 2017; Li and Lam, 2017; Mao et al., 2021).",
      "startOffset" : 85,
      "endOffset" : 199
    }, {
      "referenceID" : 21,
      "context" : "a sequence labeling task to identify the spans in the text that convey the sentiment (Liu et al., 2015; Xu et al., 2018; Yin et al., 2016; Wang et al., 2016, 2017; Li and Lam, 2017; Mao et al., 2021).",
      "startOffset" : 85,
      "endOffset" : 199
    }, {
      "referenceID" : 24,
      "context" : "a sequence labeling task to identify the spans in the text that convey the sentiment (Liu et al., 2015; Xu et al., 2018; Yin et al., 2016; Wang et al., 2016, 2017; Li and Lam, 2017; Mao et al., 2021).",
      "startOffset" : 85,
      "endOffset" : 199
    }, {
      "referenceID" : 5,
      "context" : "a sequence labeling task to identify the spans in the text that convey the sentiment (Liu et al., 2015; Xu et al., 2018; Yin et al., 2016; Wang et al., 2016, 2017; Li and Lam, 2017; Mao et al., 2021).",
      "startOffset" : 85,
      "endOffset" : 199
    }, {
      "referenceID" : 7,
      "context" : "a sequence labeling task to identify the spans in the text that convey the sentiment (Liu et al., 2015; Xu et al., 2018; Yin et al., 2016; Wang et al., 2016, 2017; Li and Lam, 2017; Mao et al., 2021).",
      "startOffset" : 85,
      "endOffset" : 199
    } ],
    "year" : 0,
    "abstractText" : "Recognizing offensive text is an important requirement for every content management system, especially for social networks. While the majority of the prior work formulate this problem as text classification, i.e., if a text excerpt is offensive or not, in this work we propose a novel model for offensive span detection (OSD), whose goal is to identify the spans responsible for the offensive tone of the text. One of the challenges to train a model for this novel setting is the lack of enough tanning data. To address this limitation, in this work we propose a novel method in which the large-scale pre-trained language model GPT2 is employed to generate synthetic training data for OSD. In particular, we propose to train the GPT-2 model in a dual-training setting using the REINFORCE algorithm to generate in-domain, natural and diverse training samples. Extensive experiments on the benchmark dataset for OSD reveal the effectiveness of the proposed method.",
    "creator" : null
  }
}