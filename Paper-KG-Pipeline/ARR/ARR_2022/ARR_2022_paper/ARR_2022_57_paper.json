{
  "name" : "ARR_2022_57_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "ElitePLM: An Empirical Study on General Language Ability Evaluation of Pretrained Language Models",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Recent years have featured a trend towards Transformer (Vaswani et al., 2017) based pretrained language models (PLMs) in natural language processing (NLP) systems. By first pretrained on massive unlabeled text, PLMs can be directly fine-tuned on downstream tasks, entirely removing the needs to task-specific architectures (Radford et al., 2018). This paradigm has led to significant progress on many challenging NLP tasks such as BERT (Devlin et al., 2019) on reading comprehension and GPT-3 (Brown et al., 2020) on text generation.\nGiving new state-of-the-art results that approach or surpass human performance on several tasks, it is an interesting question about how to systematically evaluate the language abilities of PLMs from\na wide range of perspectives. Given the increasing number of publicly released PLMs, it is particularly useful to derive principles or guidelines of selecting suitable PLMs for specific downstream tasks. However, existing works either target at some single ability (Talmor et al., 2020; Zhou et al., 2020), or consider a simple mixture of multiple (smallscale) tasks that lack a comprehensive design and test (Wang et al., 2019b; Liang Xu, 2020). There has been no detailed and systematic analysis characterizing the abilities of PLMs in large-scale NLP tasks. To fill the gap of PLMs evaluation, we introduce the genEral language ability evaluation (ElitePLM) for empirically and systematically assessing the general language abilities of PLMs.\nThe motivation behind PLMs is to create a machine learner equivalent to human being which can understand the language and then be asked to perform any specific task related to language. In cognitive science, the Wechsler Adult Intelligence Scale (WAIS) (Kaufman and Lichtenberger, 2005) is the most commonly used intelligence quotient (IQ) test for measuring the intelligence and cognitive ability of human being. This test would assess the level of individuals on verbal comprehension, perceptual reasoning, working memory, and processing speed. Thus, by imitating the intelligence test on human, we design four evaluation dimensions in ElitePLM for measuring the abilities of PLMs, including memory, comprehension, reasoning, and composition. Following previous works (Zhou et al., 2020; Wang et al., 2019b), for each ability in ElitePLM, we elaborate and choose multiple representative tasks (e.g., question answering for the comprehension ability) and commonly-used benchmarks (e.g., GLUE and SQuAD) to quantitatively evaluate the performance of PLMs. These results can serve as numerical explanations of PLMs at a certain ability.\nIn human intelligence tests, the background of participants (e.g., gender, race, and occupation)\nshould be as much as diverse. Thus, in ElitePLM, we also select a diversity of PLMs to conduct generalized and meaningful comparisons. According to training objectives, pretrained language models can be divided into three categories: unidirectional language models (e.g., GPT (Radford et al., 2019)) for natural language generation (NLG), bidirectional language models (e.g., BERT (Devlin et al., 2019)) for natural language understanding (NLU), and hybrid language models (e.g., UniLM (Dong et al., 2019)) for combining the first two paradigms. Besides, knowledge-enhanced language models (e.g., ERNIE (Zhang et al., 2019)) and text-to-text language models (e.g., T5 (Raffel et al., 2020)) also emerge as important branches of PLMs. Considering the variety, we finally choose ten widely-used PLMs within the above five categories and evaluate their abilities on the four dimensions. The comparisons of these PLMs in configuration and pretraining setting have been shown in Appendix A.\nFrom the experimental results we have three salient findings. First, the pretraining objectives and strategies have significant impacts on PLMs performance in downstream tasks. We observe that the bidirectional training objective like BERT and pretraining strategies like larger training batches in RoBERTa are helpful for memorizing large-scale pretraining corpus; pretraining objectives like permutation language modeling in XLNet are highly useful for modeling the bidirectional context in text; left-to-right prediction in GPT-2 for generating long text. Second, when fine-tuning PLMs in downstream tasks, their performances are usually sensitive to the data size and distribution, which can be addressed by designing task-specific objectives like inter-sentence coherence loss in ALBERT for sentence-level reasoning tasks. Third, PLMs have excellent transferability between similar tasks. This finding can be utilized to fine-tune PLMs in the zero-shot and few-shot tasks. For example, we can first fine-tune PLMs on a data-rich source task with massive data, and then transfer the fine-tuned PLMs to a similar data-scarce target task. We illustrate the effect extent of each factor for PLMs abilities in Appendix A.\nWe hope that this paper will help establish good principles on choosing, applying, interpreting and designing PLMs for NLP tasks in practical settings. We will also release the code for all experiments and tested results, providing the community with off-the-shelf tools to evaluate their PLMs."
    }, {
      "heading" : "2 ElitePLM",
      "text" : "In ElitePLM, we empirically study four kinds of language abilities of PLMs, namely memory, comprehension, reasoning, and composition. Next, we will describe each ability in detail.\nMemory Ability. For humanity, memory is the most fundamental ability, which is involved in how much information has been remembered in our life experience (Miyake and Shah, 1999). By analogy, it is similar to measure how much text PLMs have remembered in pretraining, as assessed by tests of recall of words conditioned on some contexts.\nOn the other hand, efficiency is also an important aspect of memory ability for PLMs learning from new data distribution in the fine-tuning stage. Thus, besides recalling words, we also compare the memory efficiency of PLMs with different model architectures and training objectives in terms of memorizing the given new information in fine-tuning. Based on the memorized information, PLMs can generalize such knowledge and language patterns into downstream tasks for understanding the similar context in text.\nComprehension Ability. Comprehension ability is complex and multifaceted. It is usually comprised of understanding a text’s vocabulary, background knowledge of a particular topic, and comprehension of its language structures like grammar (Cain and Oakhill, 2008). In particular, background knowledge is used to comprehend a special situation, lesson, or text (also called prior knowledge). For instance, when reading a text about dog training, readers are going to use their background knowledge of dog behavior, vocabulary related to dogs, aspects of training a dog, to comprehend the given text.\nOur ElitePLM contains several well-focused tasks to evaluate the comprehension ability of PLMs from three views, i.e., vocabulary, background knowledge, and language structures. First, the word sense disambiguation task requires PLMs to understand the meaning of vocabulary words and determine whether the words are used with the same sense in sentences (Wang et al., 2019a). Furthermore, the reading comprehension task may need some particular background knowledge about the passages to answer questions under a special topic (Lai et al., 2017). Besides, the language structure is concerned with the relationships between words such as knowledge of grammar, which can\nbe quantified by some syntactic tasks like coreference resolution (Wang et al., 2019b).\nReasoning Ability. Based on the comprehension of a text, reasoning ability refers to the power and effectiveness of the processes and strategies used in drawing inferences, reaching conclusions, arriving at solutions, and making decisions (Kyllonen and Christal, 1990). There are several distinct forms of reasoning, implicating different reasoning abilities. In ElitePLM, we mainly focus on three kinds of reasoning ability, i.e., commonsense reasoning, deductive reasoning, and abductive reasoning.\nSpecifically, commonsense reasoning requires PLMs to make mundane inferences using commonsense knowledge about the world, like the fact that “matches” plus “logs” usually equals “fire” (Sap et al., 2020). Note that, subtle differences exist between commonsense knowledge and background knowledge in comprehension ability. Commonsense knowledge is broadly defined as the total accumulation of facts and information that a person has gained from previous experiences. Besides, deductive reasoning involves PLMs drawing conclusions from a set of given premises in the form of categorical syllogisms (e.g., all x are y) or symbolic logic (e.g., if p then q) (Johnson-Laird, 1999), and abductive reasoning involves arriving at the most likely explanation for a set of facts, such as a scientific theory to explain a set of empirical findings (Walton, 2014).\nComposition Ability. Unlike previous abilities to memorize, comprehend, and reason on the given content, the composition ability is a highly intelligent and synthetic ability that requires PLMs to create new content from scratch. In the literary sense, composition is the way that a writer assembles words and sentences to create a coherent and meaningful work (e.g., poem, music, and narration), which is closely resemble to the text generation task in NLP research (Berninger, 1999).\nTherefore, in ElitePLM, we introduce several text generation tasks for evaluating the composition ability of PLMs including story generation, text summarization, and question generation. Note that, story generation is a representative composition task which needs PLMs to not only comprehend the given story background, but also reason about and create reasonable and coherent story endings (Fan et al., 2018). During the composition process, PLMs should include a good vocabulary,\ngrammar, spelling, and punctuation knowledge, and need to deliberate the structure of text."
    }, {
      "heading" : "3 Experiments",
      "text" : "In this section, we first set up baselines, and then report the results and analysis on four ability tests."
    }, {
      "heading" : "3.1 Models",
      "text" : "As mentioned before, we compare the performance of ten publicly released PLMs from five categories:\n• Bidirectional Language Model: BERT (Devlin et al., 2019), RoBERTa (Liu et al., 2019b), and ALBERT (Lan et al., 2020);\n• Unidirectional Language Model: GPT-2 (Radford et al., 2019);\n• Hybrid Language Model: XLNet (Yang et al., 2019) and UniLM (Dong et al., 2019);\n• Knowledge-enhanced Language Model: ERNIE (Zhang et al., 2019);\n• Text-to-Text Language Model: BART (Lewis et al., 2020), T5 (Raffel et al., 2020), and ProphetNet (Qi et al., 2020).\nWe implement all the models and tests mostly on huggingface (Wolf et al., 2020), fairseq (Ott et al., 2019), and jiant (Phang et al., 2020). For fair comparison, all PLMs are conducted with the same training setting such as batch size and learning rate."
    }, {
      "heading" : "3.2 Memory Tests",
      "text" : "Datasets. The goal of memory tests is to answer two questions: (1) how much information PLMs have remembered in pretraining, and (2) how efficiently PLMs remember new information. For this purpose, we adopt two datasets for evaluation, i.e., LAMA (F. Petroni and Riedel, 2019) and English Wikipedia (2,500M words).\nSpecifically, LAMA is a knowledge probe corpus containing a set of knowledge facts, where facts are either subject-relation-object triples or question-answer pairs. Each fact is converted into a cloze statement where the subject or object entity is masked. Wikipedia is one of the widely-used pretraining corpus for our selected PLMs (except GPT-2 and T5). Thus, to conduct fair comparison, we also pretrain GPT-2 and T5 on Wikipedia according to their pretraining objectives. Similar to LAMA, we randomly sample 100,000 text from Wikipedia and then mask a proportion of 15% tokens following BERT. By querying PLMs with the missing tokens on Wikipedia and LAMA, we can test the language pattern and factual knowledge in\nPLMs’ memory. Since the missing tokens might appear in the middle of a sentence, for auto-regressive PLM such as GPT-2, we only evaluate PLMs on those at the end. For efficiency, we measure it as the performance w.r.t. the number of training epochs: the more efficient a model is, the fewer epochs to achieve a reference performance.\nResults and Analysis. We first directly test PLMs using Wikipedia and LAMA without fine-tuning, which is similar to the zero-shot learning. The results on mean precision at one (P@1) metric are summarized in Table 1. Compared with bidirectional and hybrid language models (e.g., BERT and XLNet), GPT-2 uses constrained self-attention where every token can only attend to context to its left. This unidirectional training objective naturally limits the performance of GPT-2 in terms of memory ability. It has been previously reported that PLMs can remember more information by scaling up the model size (Brown et al., 2020). However, in our tests, BART-large (400M) achieves worse results than RoBERTa-base (125M) with the same training corpus and similar vocabulary sizes\n(50295 vs 50265). During pretraining, RoBERTa incorporates a series of training strategies, using more pretraining data, larger batches, longer sequence, and dynamic masking, etc. Compared with model size, training objectives and strategies reflect the way of PLMs memorizing information, which seems to have more significant impacts on the memory ability of PLMs. Besides, we can clearly observe that all PLMs achieve their best results in T-REx, a subset of Wikipedia triples, and show relatively good performance on Wikipedia. This indicates that the training corpus determine the knowledge scale of PLMs’ memory, which influences the performance of PLMs in downstream tasks, especially for zero-shot learning. This is the reason why previous studies choose to train PLMs on a very large corpus.\nTo test the memory efficiency, we fine-tune five models, BERT, ALBERT, GPT-2, BART, and XLNet, for several epochs with the same training settings (e.g., learning rate). As shown in Figure 1, to achieve a reference performance, the bidirectional training objective like BERT needs fewer epochs than other kinds of objectives. This further implies that besides memory capacity, the bidirectional training objective is also useful to facilitate the memory efficiency of PLMs, because bidirectional language modeling can effectively capture the bidirectional context."
    }, {
      "heading" : "3.3 Comprehension Tests",
      "text" : "Datasets. As discussed in Section 2, comprehension ability mainly refers to the understanding of a text’s vocabulary, background knowledge, and language structure. Considering these aspects, we\n1https://gluebenchmark.com/\nemploy five datasets for comprehension tests, i.e., GLUE (Wang et al., 2019b), SuperGLUE (Wang et al., 2019a), SQuAD v1.1 (Rajpurkar et al., 2016), SQuAD v2.0 (Rajpurkar et al., 2018), and RACE (Lai et al., 2017).\nAmong these datasets, GLUE and SuperGLUE are two widely-used reading comprehension benchmarks. Several tasks, such as semantic text similarity, and coreference resolution, can be adopted to test the understanding of PLMs about semantic meaning and syntactic structure of text. By contrast, SQuAD v1.1&v2.0, and RACE are three popular question answering datasets. To answer the natural language questions, PLMs should be aware of the background knowledge about some particular topic. For example, to answer the question “what can be used as rewards for dog training?”, the background knowledge “dogs like bones” will be helpful for PLMs to answer “bones”.\nResults and Analysis. Table 2 presents the results of comprehension test in GLUE dataset (results in other four datasets can be found in Appendix D). The last column in this table indicates the average overall performance across all tasks.\nInterestingly, the models behaving well in memory tests (e.g., RoBERTa and XLNet) also present good results in many comprehension tasks. These results indicate that the improvement on memory ability is likely to be helpful for the performance of comprehension ability, which is in line with our intuition. Compared with the bidirectional language modeling like BERT (relying on corrupted input with masks), the permutation language modeling used in XLNet enables PLMs to learn more kinds of context for enhancing PLMs’ understanding of the text, which seems to be effective for good comprehension ability.\nAmong these tasks, we observe a significant performance drop in the linguistic acceptability task (CoLA), which is because the PLMs saw different data distributions during pretraining (Wang et al., 2021). This kind of sensitiveness to unfamiliar tasks is also reflected in Figure 2, where the model performance on CoLA show a more volatile fluctuation (ranging from 10 to 35) than QNLI (ranging from 15 to 20). It indicates that the performance of PLMs is closely related to the similarity of data distributions in pretraining and finetuning. To solve this challenge, it will be better to adopt intermediate fine-tuning, which involves first fine-tuning PLMs on an intermediate similar dataset and then transfering to the final dataset."
    }, {
      "heading" : "3.4 Reasoning Tests",
      "text" : "Datasets. In reasoning tests, we mainly take into account three forms of reasoning ability, i.e., commonsense reasoning, deductive reasoning, and abductive reasoning, which focus on commonsense utilization, conclusion induction, and reason derivation, respectively. For evaluation, we select six reasoning datasets, namely CommonsenseQA (Talmor et al., 2019), ROCStories (Mostafazadeh et al., 2016), SWAG (Zellers et al., 2018), HellaSwag (Zellers et al., 2019), Sense Making (Wang et al., 2019c), and ARCT (Habernal et al., 2018).\nDifferent from the background knowledge, commonsense knowledge in CommonsenseQA spans a large portion of human experience of everyday life (Liu and Singh, 2004). ROCStories, SWAG, HellaSwag, and Sense Making Task A are concerned with deriving the conclusions of stories and events, while Sense Making Task B and ARCT focus on identifying the reason behind a statement.\nResults and Analysis. Table 3 shows the model performances in reasoning ability. We can clearly observe that, besides performing well in comprehension tasks, ALBERT and RoBERTa demonstrate stronger performance in almost all reasoning\ntasks. In pretraining, ALBERT introduces an intersentence coherence objective to capture the correlation among sentences, which can be more helpful for the sentence-level reasoning ability of PLMs. It has been found that the next sentence prediction (NSP) loss in BERT might hurt the performance of PLMs in sentence-level tasks of downstream datasets, thus RoBERTa removes this objective in pretraining (Liu et al., 2019b).\nInterestingly, though performing the best in comprehension tests, XLNet does not perform as well as we expected in reasoning tests. We speculate that the permutation operation in XLNet disturbs the semantic correlation between sentences and thus leads to poor reasoning ability. To improve the reasoning ability, it would be useful to design sentence-level reasoning objectives like inter-sentence coherence loss in ALBERT and then pretrain PLMs with these objectives. Moreover, despite incorporating knowledge into language models, ERNIE still shows mediocre performance in knowledge-oriented datasets such as CommonsenseQA. A possible reason might be ERNIE only utilizes the trained KB embeddings to enhance the semantic representations, while the the reasoning structure on KBs are ignored.\nTo test the transfer learning between different reasoning abilities, we conduct a two-stage experiment across three kinds of tasks, ROCStories, SMA, and ARCT, shown in Figure 3. We first train PLMs on source task with full data, and then finetune PLMs with ten instances on target task. It can be observed that PLMs have better reasoning transferability between similar tasks such as deductive reasoning tasks (ROCStories and Sense Making Task A). This shows that the model performance on data-scarce tasks can be improved by incorporating additional training on data-rich similar tasks (Wang et al., 2021)."
    }, {
      "heading" : "3.5 Composition Tests",
      "text" : "Datasets. Composition is closely related to the text generation task, which is also aimed at generating new content from scratch. Therefore, we utilize four text generation benchmarks for composition tests, i.e., WritingPrompts (Fan et al., 2018) on story generation, CNN/Daily Mail (Hermann et al., 2015) and GigaWord (Rush et al., 2015) on text summarization, and SQuAD v1.1 (Rajpurkar et al., 2016) on question generation. Specifically, according to the length of generated text, text summarization and question generation belong to short text generation, while story generation belongs to long text generation.\nFor performance comparison, we adopt three automatic metrics, i.e., BLEU (Papineni et al., 2002), ROUGE (Lin, 2004), and METEOR (Banerjee and\nLavie, 2005). BLEU and ROUGE compute the ratios of overlapping n-grams between generated and real text, while METEOR measures word-toword matches based on WordNet between generated and real text. Besides, we conduct human evaluation from these aspects following (Zou et al., 2021): Fluency evaluates whether the text is wellformed and logical to read; Informativeness measures whether the text contains useful information; Accuracy tests whether the text describes the given content accurately; Relevance measures whether the text is relevant to the given context; Overall evaluates the overall quality of the text. The overall quality is rated from 1 to 10, while the others are rated from 1 to 5.\nInspired by (Turing, 2009), we design a Turing test to further evaluate the generated text quality. In turing test, a human interrogator is requested to distinguish whether the given text is generated by human. For each model and gold text, we randomly select 500 text and each text is scored by judges.\nResults and Analysis. Table 4 and Table 5 present the automatic evaluation and human evaluation results on composition ability, respectively. We can observe that, ProphetNet and BART achieve great performance on short text generation, while GPT-2 and T5 show better results on long text generation. Specifically, BART employs denoising objectives for reconstructing the corrupted original text and ProphetNet adopts future n-gram prediction, which are flexible for modeling the semantic relations between tokens and phrases in short texts. However, in long texts, a small ratio of masked tokens (i.e., 15%) might be not effective to capture the complex long-range dependency. By comparison, the leftto-right prediction objective in GPT-2 can be more suitable to model the long-range semantic continuity in long text, and T5 has the largest model size to achieve a strong composition ability. For composition ability, we conclude that the denoising\nobjective is helpful for short text composition, while the left-to-right objective is more powerful for long text composition. Besides, the model size is also an important factor for the improvement of PLMs’ composition ability."
    }, {
      "heading" : "4 Discussion",
      "text" : "Based on the above four ability tests, we provide a guideline for helping researchers choose, apply, interpret and design PLMs for NLP tasks.\nIn section 3.3, we know that the improvement on memory ability is likely to be helpful for the performance of comprehension ability. Hence, designing PLMs with special training objectives such as permutation language modeling in XLNet for larger memory capacity will further benefit PLMs in the downstream comprehension tasks such as question answering. Besides, when applying PLMs to downstream comprehension tasks, it must be paid attention to the similarity of data distribution in pretraining and fine-tuning. Possible solutions such as intermediate fine-tuning can alleviate this problem to some extent.\nCompared with comprehension, reasoning in section 3.4 is more complex and usually involves multiple sentences. Therefore, PLMs such as ALBERT trained with sentence-level objectives can be more suitable to conduct reasoning tasks. Intuitively, incorporating sentence-level objectives during pretraining will encourage PLMs to learn the correlation among different sentences. Note that, PLMs have better reasoning transferability between similar tasks, thus data-scarce tasks can be improved by first training on data-rich tasks.\nFor composition tasks, PLMs with denoising training objective performs well enough on short text composition, while PLMs with left-to-right objective or larger model size are more suitable for long text composition. The reason behind might be that PLMs with different training objectives can finally capture different ranges of semantic dependency between tokens and phrases."
    }, {
      "heading" : "5 Related Work",
      "text" : "Pretrained Language Models. Owing to the great achievements Transformer (Vaswani et al., 2017) has made, the paradigm of pretrained language models (PLMs) is thriving (Radford et al., 2019; Devlin et al., 2019; Liu et al., 2019b; Lewis et al., 2020; Raffel et al., 2020). It is widely recognized\nthat PLMs can learn massive knowledge from corpus, leading to significant progress in various language tasks. Giving such results in extensive NLP tasks, now it has come to the point to systematically evaluate the abilities of PLMs, which can further deepen our understanding of PLMs and facilitate their application to more fields.\nLanguage Model Evaluation. Many efforts have studied the evaluation on language model performance. Liu et al. (2019a) evaluate BERT (Devlin et al., 2019), GPT (Radford et al., 2018), and ELMo (Peters et al., 2018) on a variety of linguistics tasks. Their results suggest that the features generated by PLMs are sufficient for high performance on a board set of tasks but fail on tasks requiring fine-grained linguistics knowledge. Tenney et al. (2019) evaluate similar models on a variety of sub-sentence linguistic analysis tasks, showing that PLMs encode both syntax and semantics into parameters. Zhou et al. (2020) is in line in the sense that PLMs can learn rich knowledge but focus on evaluating the commonsense. However, these work just focus on one dimension of PLMs ability evaluation. Other work such GLUE (Wang et al., 2019b) and CLUE (Liang Xu, 2020) just consider a simple mixture of multiple tasks lacking comprehensive evaluation. To the best of our knowledge, this is the first work to systematically evaluate PLMs by defining various kinds of ability and performing extensive comparison."
    }, {
      "heading" : "6 Conclusion",
      "text" : "This paper investigates the general language ability evaluation of pretrained language models. We first design four evaluation dimensions, including memory, comprehension, reasoning, and composition, and further measure ten widely-used PLMs within five categories. Our experimental results demonstrate that the pretraining objectives and strategies have significant impacts on PLMs performance in downstream tasks. Besides, when fine-tuning PLMs in downstream tasks, their performances are usually sensitive to the data size and distribution, which can be addressed by designing some taskspecific objectives. Furthermore, PLMs have great transferability between similar tasks. This characteristic can be utilized to solve the zero-shot and few-shot tasks. As a result, it is believed that this study will benefit future work about choosing or designing suitable PLMs for the target NLP tasks based on their properties."
    }, {
      "heading" : "A Configurations of Pretrained Language Models",
      "text" : "The selected ten PLMs within five categories and the comparisons of these PLMs in configuration and pretraining setting have been shown in Table 6. The effect extent of each factor for PLMs abilities in Table 7."
    }, {
      "heading" : "B Data Statistics",
      "text" : "Memory Tests. The data statistics of LAMA and Wikipedia of each model are presented in Table 8. Due to the differences of each PLM, we drop the data that are not in the vocabulary.\nComprehension Tests. The data statistics of GLUE, SuperGLUE, SQuAD and RACE are presented in Table 9.\nReasoning Tests. The data statistics for commonsense reasoning, deductive reasoning and abductive reasoning are presented in Table 10.\nComposition Tests. The data statistics for text summarization, question generation and story generation are presented in Table 11. For the first three datasets, we truncate the source text considering the input length of PLMs during training. And for WritingPrompts, we reconstruct the original dataset and discard examples where text contains more than 512 tokens."
    }, {
      "heading" : "C Memory Tests",
      "text" : "Full results on LAMA and Wikipedia datasets are presented in Table 12."
    }, {
      "heading" : "D Comprehension Tests",
      "text" : "Full results on SuperGLUE, SQuAD and RACE are presented in Table 13 and Table 14."
    }, {
      "heading" : "E Reasoning Tests",
      "text" : "Full results on CommonsenseQA, ROCStories, SWAG, HellaSwag, Sense Making, and ARCT are presented in Table 15."
    }, {
      "heading" : "F Composition Tests",
      "text" : "Full results on CNN/Daily-Mail, GigaWord, SQuAD, and WritingPrompts are presented in Table 16. Turing test results are presented in Table 5. We also show some summaries and stories generated by different PLMs in Table 18, Table 19, and Table 20."
    } ],
    "references" : [ {
      "title" : "METEOR: an automatic metric for MT evaluation with improved correlation with human judgments",
      "author" : [ "Satanjeev Banerjee", "Alon Lavie." ],
      "venue" : "Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Transla-",
      "citeRegEx" : "Banerjee and Lavie.,? 2005",
      "shortCiteRegEx" : "Banerjee and Lavie.",
      "year" : 2005
    }, {
      "title" : "Coordinating transcription and text generation in working memory during composing: Automatic and constructive processes",
      "author" : [ "Virginia W Berninger." ],
      "venue" : "Learning Disability Quarterly, 22(2):99–112.",
      "citeRegEx" : "Berninger.,? 1999",
      "shortCiteRegEx" : "Berninger.",
      "year" : 1999
    }, {
      "title" : "Language models are few-shot learners. arXiv preprint arXiv:2005.14165",
      "author" : [ "Tom B Brown", "Benjamin Mann", "Nick Ryder", "Melanie Subbiah", "Jared Kaplan", "Prafulla Dhariwal", "Arvind Neelakantan", "Pranav Shyam", "Girish Sastry", "Amanda Askell" ],
      "venue" : null,
      "citeRegEx" : "Brown et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Brown et al\\.",
      "year" : 2020
    }, {
      "title" : "Children’s comprehension problems in oral and written language: A cognitive perspective",
      "author" : [ "Kate Cain", "Jane Oakhill." ],
      "venue" : "Guilford Press.",
      "citeRegEx" : "Cain and Oakhill.,? 2008",
      "shortCiteRegEx" : "Cain and Oakhill.",
      "year" : 2008
    }, {
      "title" : "BERT: pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Unified language model pre-training for natural language understanding and generation",
      "author" : [ "Li Dong", "Nan Yang", "Wenhui Wang", "Furu Wei", "Xiaodong Liu", "Yu Wang", "Jianfeng Gao", "Ming Zhou", "Hsiao-Wuen Hon." ],
      "venue" : "Advances in Neural Infor-",
      "citeRegEx" : "Dong et al\\.,? 2019",
      "shortCiteRegEx" : "Dong et al\\.",
      "year" : 2019
    }, {
      "title" : "Language models as knowledge bases",
      "author" : [ "T. Rocktäschel", "S. Riedel" ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Petroni et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Petroni et al\\.",
      "year" : 2019
    }, {
      "title" : "Hierarchical neural story generation",
      "author" : [ "Angela Fan", "Mike Lewis", "Yann N. Dauphin." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long",
      "citeRegEx" : "Fan et al\\.,? 2018",
      "shortCiteRegEx" : "Fan et al\\.",
      "year" : 2018
    }, {
      "title" : "The argument reasoning comprehension task: Identification and reconstruction of implicit warrants",
      "author" : [ "Ivan Habernal", "Henning Wachsmuth", "Iryna Gurevych", "Benno Stein." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the",
      "citeRegEx" : "Habernal et al\\.,? 2018",
      "shortCiteRegEx" : "Habernal et al\\.",
      "year" : 2018
    }, {
      "title" : "Teaching machines to read and comprehend",
      "author" : [ "Karl Moritz Hermann", "Tomás Kociský", "Edward Grefenstette", "Lasse Espeholt", "Will Kay", "Mustafa Suleyman", "Phil Blunsom." ],
      "venue" : "Advances in Neural Information Processing Systems 28: Annual Conference",
      "citeRegEx" : "Hermann et al\\.,? 2015",
      "shortCiteRegEx" : "Hermann et al\\.",
      "year" : 2015
    }, {
      "title" : "Deductive reasoning",
      "author" : [ "Philip N Johnson-Laird." ],
      "venue" : "Annual review of psychology, 50(1):109–135.",
      "citeRegEx" : "Johnson.Laird.,? 1999",
      "shortCiteRegEx" : "Johnson.Laird.",
      "year" : 1999
    }, {
      "title" : "Assessing adolescent and adult intelligence",
      "author" : [ "Alan S Kaufman", "Elizabeth O Lichtenberger." ],
      "venue" : "John Wiley & Sons.",
      "citeRegEx" : "Kaufman and Lichtenberger.,? 2005",
      "shortCiteRegEx" : "Kaufman and Lichtenberger.",
      "year" : 2005
    }, {
      "title" : "Reasoning ability is (little more than) workingmemory capacity?! Intelligence, 14(4):389–433",
      "author" : [ "Patrick C Kyllonen", "Raymond E Christal" ],
      "venue" : null,
      "citeRegEx" : "Kyllonen and Christal.,? \\Q1990\\E",
      "shortCiteRegEx" : "Kyllonen and Christal.",
      "year" : 1990
    }, {
      "title" : "RACE: large-scale reading comprehension dataset from examinations",
      "author" : [ "Guokun Lai", "Qizhe Xie", "Hanxiao Liu", "Yiming Yang", "Eduard H. Hovy." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Lai et al\\.,? 2017",
      "shortCiteRegEx" : "Lai et al\\.",
      "year" : 2017
    }, {
      "title" : "ALBERT: A lite BERT for self-supervised learning of language representations",
      "author" : [ "Zhenzhong Lan", "Mingda Chen", "Sebastian Goodman", "Kevin Gimpel", "Piyush Sharma", "Radu Soricut." ],
      "venue" : "8th International Conference on Learning Representations,",
      "citeRegEx" : "Lan et al\\.,? 2020",
      "shortCiteRegEx" : "Lan et al\\.",
      "year" : 2020
    }, {
      "title" : "BART: denoising sequence-to-sequence pretraining for natural language",
      "author" : [ "Mike Lewis", "Yinhan Liu", "Naman Goyal", "Marjan Ghazvininejad", "Abdelrahman Mohamed", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer" ],
      "venue" : null,
      "citeRegEx" : "Lewis et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Lewis et al\\.",
      "year" : 2020
    }, {
      "title" : "Clue: A chinese language understanding evaluation",
      "author" : [ "Xuanwei Zhang" ],
      "venue" : null,
      "citeRegEx" : "Xu and Zhang.,? \\Q2020\\E",
      "shortCiteRegEx" : "Xu and Zhang.",
      "year" : 2020
    }, {
      "title" : "Rouge: A package for automatic evaluation of summaries",
      "author" : [ "Chin-Yew Lin." ],
      "venue" : "Text summarization branches out, pages 74–81.",
      "citeRegEx" : "Lin.,? 2004",
      "shortCiteRegEx" : "Lin.",
      "year" : 2004
    }, {
      "title" : "Conceptnet—a practical commonsense reasoning tool-kit",
      "author" : [ "Hugo Liu", "Push Singh." ],
      "venue" : "BT technology journal, 22(4):211–226.",
      "citeRegEx" : "Liu and Singh.,? 2004",
      "shortCiteRegEx" : "Liu and Singh.",
      "year" : 2004
    }, {
      "title" : "Linguistic knowledge and transferability of contextual representations",
      "author" : [ "Nelson F. Liu", "Matt Gardner", "Yonatan Belinkov", "Matthew E. Peters", "Noah A. Smith." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Associ-",
      "citeRegEx" : "Liu et al\\.,? 2019a",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Roberta: A robustly optimized bert pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "arXiv preprint arXiv:1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019b",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Models of working memory: Mechanisms of active maintenance and executive control",
      "author" : [ "Akira Miyake", "Priti Shah." ],
      "venue" : "Cambridge University Press.",
      "citeRegEx" : "Miyake and Shah.,? 1999",
      "shortCiteRegEx" : "Miyake and Shah.",
      "year" : 1999
    }, {
      "title" : "A corpus and evaluation framework for deeper understanding of commonsense stories",
      "author" : [ "Nasrin Mostafazadeh", "Nathanael Chambers", "Xiaodong He", "Devi Parikh", "Dhruv Batra", "Lucy Vanderwende", "Pushmeet Kohli", "James Allen." ],
      "venue" : "arXiv preprint",
      "citeRegEx" : "Mostafazadeh et al\\.,? 2016",
      "shortCiteRegEx" : "Mostafazadeh et al\\.",
      "year" : 2016
    }, {
      "title" : "fairseq: A fast, extensible toolkit for sequence modeling",
      "author" : [ "Myle Ott", "Sergey Edunov", "Alexei Baevski", "Angela Fan", "Sam Gross", "Nathan Ng", "David Grangier", "Michael Auli." ],
      "venue" : "Proceedings of NAACL-HLT 2019: Demonstrations.",
      "citeRegEx" : "Ott et al\\.,? 2019",
      "shortCiteRegEx" : "Ott et al\\.",
      "year" : 2019
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311–318.",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "Deep contextualized word representations",
      "author" : [ "Matthew E. Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Associ-",
      "citeRegEx" : "Peters et al\\.,? 2018",
      "shortCiteRegEx" : "Peters et al\\.",
      "year" : 2018
    }, {
      "title" : "jiant 2.0: A software toolkit for research on general-purpose text understanding models",
      "author" : [ "Jason Phang", "Phil Yeres", "Jesse Swanson", "Haokun Liu", "Ian F. Tenney", "Phu Mon Htut", "Clara Vania", "Alex Wang", "Samuel R. Bowman" ],
      "venue" : null,
      "citeRegEx" : "Phang et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Phang et al\\.",
      "year" : 2020
    }, {
      "title" : "Prophetnet: Predicting future n-gram for sequence-to-sequence pre-training",
      "author" : [ "Weizhen Qi", "Yu Yan", "Yeyun Gong", "Dayiheng Liu", "Nan Duan", "Jiusheng Chen", "Ruofei Zhang", "Ming Zhou." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods",
      "citeRegEx" : "Qi et al\\.,? 2020",
      "shortCiteRegEx" : "Qi et al\\.",
      "year" : 2020
    }, {
      "title" : "Improving language understanding by generative pre-training",
      "author" : [ "Alec Radford", "Karthik Narasimhan", "Tim Salimans", "Ilya Sutskever" ],
      "venue" : null,
      "citeRegEx" : "Radford et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2018
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever." ],
      "venue" : "OpenAI blog, 1(8):9.",
      "citeRegEx" : "Radford et al\\.,? 2019",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "author" : [ "Colin Raffel", "Noam Shazeer", "Adam Roberts", "Katherine Lee", "Sharan Narang", "Michael Matena", "Yanqi Zhou", "Wei Li", "Peter J. Liu." ],
      "venue" : "J. Mach. Learn. Res., 21:140:1–140:67.",
      "citeRegEx" : "Raffel et al\\.,? 2020",
      "shortCiteRegEx" : "Raffel et al\\.",
      "year" : 2020
    }, {
      "title" : "Know what you don’t know: Unanswerable questions for squad",
      "author" : [ "Pranav Rajpurkar", "Robin Jia", "Percy Liang." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-",
      "citeRegEx" : "Rajpurkar et al\\.,? 2018",
      "shortCiteRegEx" : "Rajpurkar et al\\.",
      "year" : 2018
    }, {
      "title" : "Squad: 100, 000+ questions for machine comprehension of text",
      "author" : [ "Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang." ],
      "venue" : "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin,",
      "citeRegEx" : "Rajpurkar et al\\.,? 2016",
      "shortCiteRegEx" : "Rajpurkar et al\\.",
      "year" : 2016
    }, {
      "title" : "A neural attention model for abstractive sentence summarization",
      "author" : [ "Alexander M. Rush", "Sumit Chopra", "Jason Weston." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal,",
      "citeRegEx" : "Rush et al\\.,? 2015",
      "shortCiteRegEx" : "Rush et al\\.",
      "year" : 2015
    }, {
      "title" : "Commonsense reasoning for natural language processing",
      "author" : [ "Maarten Sap", "Vered Shwartz", "Antoine Bosselut", "Yejin Choi", "Dan Roth." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts, ACL",
      "citeRegEx" : "Sap et al\\.,? 2020",
      "shortCiteRegEx" : "Sap et al\\.",
      "year" : 2020
    }, {
      "title" : "olmpics - on what language model pre-training captures",
      "author" : [ "Alon Talmor", "Yanai Elazar", "Yoav Goldberg", "Jonathan Berant." ],
      "venue" : "Trans. Assoc. Comput. Linguistics, 8:743–758.",
      "citeRegEx" : "Talmor et al\\.,? 2020",
      "shortCiteRegEx" : "Talmor et al\\.",
      "year" : 2020
    }, {
      "title" : "Commonsenseqa: A question answering challenge targeting",
      "author" : [ "Alon Talmor", "Jonathan Herzig", "Nicholas Lourie", "Jonathan Berant" ],
      "venue" : null,
      "citeRegEx" : "Talmor et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Talmor et al\\.",
      "year" : 2019
    }, {
      "title" : "What do you learn from context? probing for sentence structure",
      "author" : [ "Ian Tenney", "Patrick Xia", "Berlin Chen", "Alex Wang", "Adam Poliak", "R Thomas McCoy", "Najoung Kim", "Benjamin Van Durme", "Samuel R Bowman", "Dipanjan Das" ],
      "venue" : null,
      "citeRegEx" : "Tenney et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Tenney et al\\.",
      "year" : 2019
    }, {
      "title" : "Computing machinery and intelligence",
      "author" : [ "Alan M Turing." ],
      "venue" : "Parsing the turing test, pages 23–65. Springer.",
      "citeRegEx" : "Turing.,? 2009",
      "shortCiteRegEx" : "Turing.",
      "year" : 2009
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in Neural Information Processing Systems 30: Annual Conference on Neural",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Abductive reasoning",
      "author" : [ "Douglas Walton." ],
      "venue" : "University of Alabama Press.",
      "citeRegEx" : "Walton.,? 2014",
      "shortCiteRegEx" : "Walton.",
      "year" : 2014
    }, {
      "title" : "Superglue: A stickier benchmark for general-purpose language understanding systems",
      "author" : [ "Alex Wang", "Yada Pruksachatkun", "Nikita Nangia", "Amanpreet Singh", "Julian Michael", "Felix Hill", "Omer Levy", "Samuel R. Bowman." ],
      "venue" : "Advances in Neural Infor-",
      "citeRegEx" : "Wang et al\\.,? 2019a",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
      "author" : [ "Alex Wang", "Amanpreet Singh", "Julian Michael", "Felix Hill", "Omer Levy", "Samuel R. Bowman." ],
      "venue" : "7th International Conference on Learning Representa-",
      "citeRegEx" : "Wang et al\\.,? 2019b",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "Does it make sense? and why? A pilot study for sense making and explanation",
      "author" : [ "Cunxiang Wang", "Shuailong Liang", "Yue Zhang", "Xiaonan Li", "Tian Gao." ],
      "venue" : "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL",
      "citeRegEx" : "Wang et al\\.,? 2019c",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "Entailment as few-shot learner",
      "author" : [ "Sinong Wang", "Han Fang", "Madian Khabsa", "Hanzi Mao", "Hao Ma." ],
      "venue" : "arXiv preprint arXiv:2104.14690.",
      "citeRegEx" : "Wang et al\\.,? 2021",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2021
    }, {
      "title" : "Transformers: State-of-the-art natural language processing",
      "author" : [ "Clara Ma", "Yacine Jernite", "Julien Plu", "Canwen Xu", "Teven Le Scao", "Sylvain Gugger", "Mariama Drame", "Quentin Lhoest", "Alexander M. Rush." ],
      "venue" : "Proceedings of the 2020 Conference on",
      "citeRegEx" : "Ma et al\\.,? 2020",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2020
    }, {
      "title" : "Xlnet: Generalized autoregressive pretraining for language understanding",
      "author" : [ "Zhilin Yang", "Zihang Dai", "Yiming Yang", "Jaime G. Carbonell", "Ruslan Salakhutdinov", "Quoc V. Le." ],
      "venue" : "Advances in Neural Information Processing Systems 32: Annual Con-",
      "citeRegEx" : "Yang et al\\.,? 2019",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "SWAG: A large-scale adversarial dataset for grounded commonsense inference",
      "author" : [ "Rowan Zellers", "Yonatan Bisk", "Roy Schwartz", "Yejin Choi." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels,",
      "citeRegEx" : "Zellers et al\\.,? 2018",
      "shortCiteRegEx" : "Zellers et al\\.",
      "year" : 2018
    }, {
      "title" : "Hellaswag: Can a machine really finish your sentence",
      "author" : [ "Rowan Zellers", "Ari Holtzman", "Yonatan Bisk", "Ali Farhadi", "Yejin Choi" ],
      "venue" : "In Proceedings of the 57th Conference of the Association for Computational Linguistics,",
      "citeRegEx" : "Zellers et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Zellers et al\\.",
      "year" : 2019
    }, {
      "title" : "ERNIE: enhanced language representation with informative entities",
      "author" : [ "Zhengyan Zhang", "Xu Han", "Zhiyuan Liu", "Xin Jiang", "Maosong Sun", "Qun Liu." ],
      "venue" : "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL",
      "citeRegEx" : "Zhang et al\\.,? 2019",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    }, {
      "title" : "Evaluating commonsense in pretrained language models",
      "author" : [ "Xuhui Zhou", "Yue Zhang", "Leyang Cui", "Dandan Huang." ],
      "venue" : "The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of",
      "citeRegEx" : "Zhou et al\\.,? 2020",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2020
    }, {
      "title" : "Controllable generation from pre-trained language models via inverse prompting",
      "author" : [ "Xu Zou", "Da Yin", "Qingyang Zhong", "Hongxia Yang", "Zhilin Yang", "Jie Tang." ],
      "venue" : "arXiv preprint arXiv:2103.10685. 11",
      "citeRegEx" : "Zou et al\\.,? 2021",
      "shortCiteRegEx" : "Zou et al\\.",
      "year" : 2021
    } ],
    "referenceMentions" : [ {
      "referenceID" : 39,
      "context" : "Recent years have featured a trend towards Transformer (Vaswani et al., 2017) based pretrained language models (PLMs) in natural language processing (NLP) systems.",
      "startOffset" : 55,
      "endOffset" : 77
    }, {
      "referenceID" : 28,
      "context" : "By first pretrained on massive unlabeled text, PLMs can be directly fine-tuned on downstream tasks, entirely removing the needs to task-specific architectures (Radford et al., 2018).",
      "startOffset" : 159,
      "endOffset" : 181
    }, {
      "referenceID" : 4,
      "context" : "This paradigm has led to significant progress on many challenging NLP tasks such as BERT (Devlin et al., 2019) on reading comprehension and GPT-3 (Brown et al.",
      "startOffset" : 89,
      "endOffset" : 110
    }, {
      "referenceID" : 2,
      "context" : ", 2019) on reading comprehension and GPT-3 (Brown et al., 2020) on text generation.",
      "startOffset" : 43,
      "endOffset" : 63
    }, {
      "referenceID" : 35,
      "context" : "gle ability (Talmor et al., 2020; Zhou et al., 2020), or consider a simple mixture of multiple (smallscale) tasks that lack a comprehensive design and test (Wang et al.",
      "startOffset" : 12,
      "endOffset" : 52
    }, {
      "referenceID" : 50,
      "context" : "gle ability (Talmor et al., 2020; Zhou et al., 2020), or consider a simple mixture of multiple (smallscale) tasks that lack a comprehensive design and test (Wang et al.",
      "startOffset" : 12,
      "endOffset" : 52
    }, {
      "referenceID" : 42,
      "context" : ", 2020), or consider a simple mixture of multiple (smallscale) tasks that lack a comprehensive design and test (Wang et al., 2019b; Liang Xu, 2020).",
      "startOffset" : 111,
      "endOffset" : 147
    }, {
      "referenceID" : 11,
      "context" : "tive science, the Wechsler Adult Intelligence Scale (WAIS) (Kaufman and Lichtenberger, 2005) is the most commonly used intelligence quotient (IQ) test for measuring the intelligence and cognitive ability of human being.",
      "startOffset" : 59,
      "endOffset" : 92
    }, {
      "referenceID" : 50,
      "context" : "Following previous works (Zhou et al., 2020; Wang et al., 2019b), for each ability in ElitePLM, we elaborate and choose multiple representative tasks (e.",
      "startOffset" : 25,
      "endOffset" : 64
    }, {
      "referenceID" : 42,
      "context" : "Following previous works (Zhou et al., 2020; Wang et al., 2019b), for each ability in ElitePLM, we elaborate and choose multiple representative tasks (e.",
      "startOffset" : 25,
      "endOffset" : 64
    }, {
      "referenceID" : 29,
      "context" : ", GPT (Radford et al., 2019)) for natural language generation (NLG), bidirectional",
      "startOffset" : 6,
      "endOffset" : 28
    }, {
      "referenceID" : 4,
      "context" : ", BERT (Devlin et al., 2019)) for natural language understanding (NLU), and hybrid language models (e.",
      "startOffset" : 7,
      "endOffset" : 28
    }, {
      "referenceID" : 5,
      "context" : ", UniLM (Dong et al., 2019)) for combining the first two paradigms.",
      "startOffset" : 8,
      "endOffset" : 27
    }, {
      "referenceID" : 49,
      "context" : ", ERNIE (Zhang et al., 2019)) and text-to-text language models (e.",
      "startOffset" : 8,
      "endOffset" : 28
    }, {
      "referenceID" : 30,
      "context" : ", T5 (Raffel et al., 2020)) also emerge as important branches of PLMs.",
      "startOffset" : 5,
      "endOffset" : 26
    }, {
      "referenceID" : 21,
      "context" : "For humanity, memory is the most fundamental ability, which is involved in how much information has been remembered in our life experience (Miyake and Shah, 1999).",
      "startOffset" : 139,
      "endOffset" : 162
    }, {
      "referenceID" : 3,
      "context" : "prised of understanding a text’s vocabulary, background knowledge of a particular topic, and comprehension of its language structures like grammar (Cain and Oakhill, 2008).",
      "startOffset" : 147,
      "endOffset" : 171
    }, {
      "referenceID" : 41,
      "context" : "First, the word sense disambiguation task requires PLMs to understand the meaning of vocabulary words and determine whether the words are used with the same sense in sentences (Wang et al., 2019a).",
      "startOffset" : 176,
      "endOffset" : 196
    }, {
      "referenceID" : 13,
      "context" : "Furthermore, the reading comprehension task may need some particular background knowledge about the passages to answer questions under a special topic (Lai et al., 2017).",
      "startOffset" : 151,
      "endOffset" : 169
    }, {
      "referenceID" : 42,
      "context" : "be quantified by some syntactic tasks like coreference resolution (Wang et al., 2019b).",
      "startOffset" : 66,
      "endOffset" : 86
    }, {
      "referenceID" : 12,
      "context" : "Based on the comprehension of a text, reasoning ability refers to the power and effectiveness of the processes and strategies used in drawing inferences, reaching conclusions, arriving at solutions, and making decisions (Kyllonen and Christal, 1990).",
      "startOffset" : 220,
      "endOffset" : 249
    }, {
      "referenceID" : 34,
      "context" : "Specifically, commonsense reasoning requires PLMs to make mundane inferences using commonsense knowledge about the world, like the fact that “matches” plus “logs” usually equals “fire” (Sap et al., 2020).",
      "startOffset" : 185,
      "endOffset" : 203
    }, {
      "referenceID" : 10,
      "context" : ", if p then q) (Johnson-Laird, 1999), and abductive reasoning involves arriving at the",
      "startOffset" : 15,
      "endOffset" : 36
    }, {
      "referenceID" : 40,
      "context" : "most likely explanation for a set of facts, such as a scientific theory to explain a set of empirical findings (Walton, 2014).",
      "startOffset" : 111,
      "endOffset" : 125
    }, {
      "referenceID" : 1,
      "context" : ", poem, music, and narration), which is closely resemble to the text generation task in NLP research (Berninger, 1999).",
      "startOffset" : 101,
      "endOffset" : 118
    }, {
      "referenceID" : 7,
      "context" : "Note that, story generation is a representative composition task which needs PLMs to not only comprehend the given story background, but also reason about and create reasonable and coherent story endings (Fan et al., 2018).",
      "startOffset" : 204,
      "endOffset" : 222
    }, {
      "referenceID" : 4,
      "context" : "• Bidirectional Language Model: BERT (Devlin et al., 2019), RoBERTa (Liu et al.",
      "startOffset" : 37,
      "endOffset" : 58
    }, {
      "referenceID" : 20,
      "context" : ", 2019), RoBERTa (Liu et al., 2019b), and ALBERT (Lan et al.",
      "startOffset" : 17,
      "endOffset" : 36
    }, {
      "referenceID" : 29,
      "context" : "• Unidirectional Language Model: GPT-2 (Radford et al., 2019);",
      "startOffset" : 39,
      "endOffset" : 61
    }, {
      "referenceID" : 46,
      "context" : "• Hybrid Language Model: XLNet (Yang et al., 2019) and UniLM (Dong et al.",
      "startOffset" : 31,
      "endOffset" : 50
    }, {
      "referenceID" : 49,
      "context" : "• Knowledge-enhanced Language Model: ERNIE (Zhang et al., 2019);",
      "startOffset" : 43,
      "endOffset" : 63
    }, {
      "referenceID" : 15,
      "context" : "• Text-to-Text Language Model: BART (Lewis et al., 2020), T5 (Raffel et al.",
      "startOffset" : 36,
      "endOffset" : 56
    }, {
      "referenceID" : 2,
      "context" : "It has been previously reported that PLMs can remember more information by scaling up the model size (Brown et al., 2020).",
      "startOffset" : 101,
      "endOffset" : 121
    }, {
      "referenceID" : 44,
      "context" : "Among these tasks, we observe a significant performance drop in the linguistic acceptability task (CoLA), which is because the PLMs saw different data distributions during pretraining (Wang et al., 2021).",
      "startOffset" : 184,
      "endOffset" : 203
    }, {
      "referenceID" : 36,
      "context" : "For evaluation, we select six reasoning datasets, namely CommonsenseQA (Talmor et al., 2019), ROCStories (Mostafazadeh et al.",
      "startOffset" : 71,
      "endOffset" : 92
    }, {
      "referenceID" : 22,
      "context" : ", 2019), ROCStories (Mostafazadeh et al., 2016), SWAG (Zellers et al.",
      "startOffset" : 20,
      "endOffset" : 47
    }, {
      "referenceID" : 47,
      "context" : ", 2016), SWAG (Zellers et al., 2018), HellaSwag (Zellers et al.",
      "startOffset" : 14,
      "endOffset" : 36
    }, {
      "referenceID" : 48,
      "context" : ", 2018), HellaSwag (Zellers et al., 2019), Sense Making (Wang et al.",
      "startOffset" : 19,
      "endOffset" : 41
    }, {
      "referenceID" : 43,
      "context" : ", 2019), Sense Making (Wang et al., 2019c), and ARCT (Habernal et al.",
      "startOffset" : 22,
      "endOffset" : 42
    }, {
      "referenceID" : 18,
      "context" : "Different from the background knowledge, commonsense knowledge in CommonsenseQA spans a large portion of human experience of everyday life (Liu and Singh, 2004).",
      "startOffset" : 139,
      "endOffset" : 160
    }, {
      "referenceID" : 20,
      "context" : "of PLMs in sentence-level tasks of downstream datasets, thus RoBERTa removes this objective in pretraining (Liu et al., 2019b).",
      "startOffset" : 107,
      "endOffset" : 126
    }, {
      "referenceID" : 44,
      "context" : "This shows that the model performance on data-scarce tasks can be improved by incorporating additional training on data-rich similar tasks (Wang et al., 2021).",
      "startOffset" : 139,
      "endOffset" : 158
    }, {
      "referenceID" : 7,
      "context" : ", WritingPrompts (Fan et al., 2018) on story generation, CNN/Daily Mail (Hermann et al.",
      "startOffset" : 17,
      "endOffset" : 35
    }, {
      "referenceID" : 9,
      "context" : ", 2018) on story generation, CNN/Daily Mail (Hermann et al., 2015) and GigaWord (Rush et al.",
      "startOffset" : 44,
      "endOffset" : 66
    }, {
      "referenceID" : 33,
      "context" : ", 2015) and GigaWord (Rush et al., 2015) on text summarization, and SQuAD v1.",
      "startOffset" : 21,
      "endOffset" : 40
    }, {
      "referenceID" : 24,
      "context" : ", BLEU (Papineni et al., 2002), ROUGE (Lin, 2004), and METEOR (Banerjee and Lavie, 2005).",
      "startOffset" : 7,
      "endOffset" : 30
    }, {
      "referenceID" : 17,
      "context" : ", 2002), ROUGE (Lin, 2004), and METEOR (Banerjee and Lavie, 2005).",
      "startOffset" : 15,
      "endOffset" : 26
    }, {
      "referenceID" : 0,
      "context" : ", 2002), ROUGE (Lin, 2004), and METEOR (Banerjee and Lavie, 2005).",
      "startOffset" : 39,
      "endOffset" : 65
    }, {
      "referenceID" : 39,
      "context" : "Owing to the great achievements Transformer (Vaswani et al., 2017) has made, the paradigm of pretrained language models (PLMs) is thriving (Radford et al.",
      "startOffset" : 44,
      "endOffset" : 66
    }, {
      "referenceID" : 29,
      "context" : ", 2017) has made, the paradigm of pretrained language models (PLMs) is thriving (Radford et al., 2019; Devlin et al., 2019; Liu et al., 2019b; Lewis et al., 2020; Raffel et al., 2020).",
      "startOffset" : 80,
      "endOffset" : 183
    }, {
      "referenceID" : 4,
      "context" : ", 2017) has made, the paradigm of pretrained language models (PLMs) is thriving (Radford et al., 2019; Devlin et al., 2019; Liu et al., 2019b; Lewis et al., 2020; Raffel et al., 2020).",
      "startOffset" : 80,
      "endOffset" : 183
    }, {
      "referenceID" : 20,
      "context" : ", 2017) has made, the paradigm of pretrained language models (PLMs) is thriving (Radford et al., 2019; Devlin et al., 2019; Liu et al., 2019b; Lewis et al., 2020; Raffel et al., 2020).",
      "startOffset" : 80,
      "endOffset" : 183
    }, {
      "referenceID" : 15,
      "context" : ", 2017) has made, the paradigm of pretrained language models (PLMs) is thriving (Radford et al., 2019; Devlin et al., 2019; Liu et al., 2019b; Lewis et al., 2020; Raffel et al., 2020).",
      "startOffset" : 80,
      "endOffset" : 183
    }, {
      "referenceID" : 30,
      "context" : ", 2017) has made, the paradigm of pretrained language models (PLMs) is thriving (Radford et al., 2019; Devlin et al., 2019; Liu et al., 2019b; Lewis et al., 2020; Raffel et al., 2020).",
      "startOffset" : 80,
      "endOffset" : 183
    }, {
      "referenceID" : 4,
      "context" : "(2019a) evaluate BERT (Devlin et al., 2019), GPT (Radford et al.",
      "startOffset" : 22,
      "endOffset" : 43
    }, {
      "referenceID" : 28,
      "context" : ", 2019), GPT (Radford et al., 2018), and ELMo (Peters et al.",
      "startOffset" : 13,
      "endOffset" : 35
    }, {
      "referenceID" : 25,
      "context" : ", 2018), and ELMo (Peters et al., 2018) on a variety of linguistics tasks.",
      "startOffset" : 18,
      "endOffset" : 39
    }, {
      "referenceID" : 42,
      "context" : "Other work such GLUE (Wang et al., 2019b) and CLUE (Liang Xu, 2020) just consider a simple mixture of multiple tasks lacking comprehensive",
      "startOffset" : 21,
      "endOffset" : 41
    } ],
    "year" : 0,
    "abstractText" : "Pretrained language models (PLMs), such as BERT and GPT-3, have dominated the majority of NLP tasks. However, relatively little work has been conducted on systematically evaluating the language abilities of PLMs. In this paper, we present a largescale empirical study on genEral language ability evaluation of PLMs (ElitePLM). We first design four evaluation dimensions in ElitePLM, including memory, comprehension, reasoning, and composition, and further measure ten widely-used PLMs within five categories. Our empirical results demonstrate that: (1) the pretraining objectives and strategies have significant impacts on PLMs performance in downstream tasks; (2) fine-tuning PLMs in downstream tasks is usually sensitive to the data size and distribution; (3) PLMs have excellent transferability between similar tasks. Our experimental results summarize several important findings, which can guide the future work to choose, apply, and design PLMs for specific tasks. We have made all the details of experiments publicly available at https://anonymous.4open.science/ r/Paper-for-ACL-4FD1.",
    "creator" : null
  }
}