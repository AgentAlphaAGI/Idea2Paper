{
  "name" : "ARR_2022_157_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Commonsense and Named Entity Aware Knowledge Grounded Dialogue Generation",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Neural language models usually focus on fewer language components such as sentences, phrases, or words for text analysis. However, language acts on a much broader scale - there is frequently a central theme to a conversation, and the speakers share common information in order to comprehend one another. Information is frequently reused, however to avoid overuse, same things and persons are referred in the dialogue multiple times by using relevant expressions. A dialogue becomes coherent and speakers can understand each other when all of this information is delivered in a structured, logical, and consistent manner.\nSemantic understanding of dialogues can be aided by commonsense knowledge or world facts. Additionally, as a key human language phenomena, co-reference simplifies human languages while being a significant barrier for machines to understand, particularly for pronouns, which are difficult to parse due to their weak semantic meanings (Ehrlich, 1981). Grounded response generation approaches (Ghazvininejad et al., 2018; Dinan et al., 2018) can provide replication of facts in open-domain settings, whereas commonsense knowledge is critical for creating successful interactions since socially constructed commonsense knowledge is the collection of contextual details that humans are expected to understand and use during a conversation.\nDespite demonstrating efficacy in empirical evaluation, past work has a few significant drawbacks. There is no explicit representation of entities, semantic relations, or conversation structures, in particular. To solve such restrictions, asking a conversation model to identify relevant structures in dialogue histories can be used to directly test the level of dialogue understanding. We focus on named entity level knowledge in this paper, and analyze references to entities in a dialogue history context.\nTo ensure the generalizability of our model, we directly incorporate entities in the form of triplets, which is the most common format of modern knowledge graphs, instead of encoding it with features or rules as in conventional approaches. Take, for example, Fig. 1, where the dialogue consists of eight utterances. In the third utterance, to know if there exists any relation between the director “Micheal Mann\" and the movie “The Last of the Mohicans\", we need to resolve the co-reference relationship between the pronoun [It] and the entity [The Last of the Mohicans]. Using co-reference resolution we get an important triple for the movie “The Last of the Mohicans\" viz. (The Last of the Mohicans, RelatedTo, Micheal Mann). Similarly, from\nthe second last utterance, we obtain another triple as (The Last of the Mohicans, RelatedTo, Morgan Creek Pictures). Thus, for instance, to generate the fourth utterance \"I tried to read the book but gave up. I can’t remember what other movies Michael Mann has directed.\", it is important for the model to know that there is a relation between the concept word “movie\" and the named entities “Micheal Mann\", “The Last of the Mohicans\", to get a correct understanding of the dialogue context.\nWe create a conversational model called CNTF, a Commonsense, Named Entity and Topical Knowledge Fused neural network to provide successful response generation by leveraging both topic-specific document information and using structured entity and commonsense knowledge. We first construct triples based on named entity after resolving coreferences in the dialogues to enhance the already existing commonsense triples obtained from the ConceptNet (Speer and Havasi, 2012). We use multi-hop attention to iterate over the multi-source information. We obtain the weighted query vector from the interactive dialogue-knowledge module, which is used to query over the dialogue, topical knowledge and the corresponding triples. In each round, CNTF generates and reasons on the dialogue history and knowledge sentences, using which we filter out relevant information from dialogue and topical knowledge. Similarly to reason over the triples, we again iterate in multiple rounds, mask-\ning out irrelevant triples. Our work makes the following contributions: 1. We propose CNTF, a novel knowledge\ngrounded dialogue generation model that utilizes dialogue context, unstructured information, and structural knowledge to facilitate explicit reasoning. 2. We enhance the commonsense triples extracted from the ConceptNet with named entity-aware structures using co-reference resolution. 3. We define an effective sliding window mechanism in order to remove irrelevant information from longer dialogue contexts and ensure efficient memory utilization. We use an interactive module to form a weighted query vector to capture the interactions between the conversation and the topical knowledge. 4. Through extensive qualitative and quantitative validation on publicly available datasets, we show that our model outperforms the strong baselines."
    }, {
      "heading" : "2 Related Work",
      "text" : "Sequence-to-sequence models (Vinyals and Le, 2015; Sutskever et al., 2014) have long been used for natural language generation (NLG) tasks. Stemming off the vanilla encoder-decoder architecture - introduced initially for neural machine translation (Shang et al., 2015), a variety of models have\nbeen developed for enhancing the quality of the responses generated (Li et al., 2016a; Zhao et al., 2017; Tao et al., 2018) to effectively select the conversational context in multi-turn dialogues (Serban et al., 2016, 2017; Xing et al., 2017; Zhang et al., 2019); and to model persona while conversing (Li et al., 2016b; Zhang et al., 2018). Recent advances aim at enhancing dialogue generation by making it more humanized by means of incorporating knowledge based on the dialogue context or from external sources, such as the unstructured documents or the structured knowledge graphs.\nPre-trained language models (Devlin et al., 2019; Radford et al., 2019) have been utilized for dialogue generation (Edunov et al., 2019; Zhang et al., 2020). They have been extended to leverage the knowledge from the unstructured documents and other auxiliary sources via knowledge selection and various attention fusion techniques (Zhao et al., 2020c; Cao et al., 2020). The task was explored in low-resource setting (Zhao et al., 2020b) using a disentangled response decoder, and the usability of language models itself as a knowledge base has also been investigated (Zhao et al., 2020d). An issue with language models is the extra noise which they introduce. To limit the noise by generative models, knowledge selection (Zheng et al., 2021) by estimation of the weights for every term in the knowledge and using the most important terms in the response were studied. (Zhao et al., 2020a) proposed a pre-training based multiple knowledge syncretic transformer that uses a single framework to integrate knowledge from multiple sources. Knowledge based end-to-end memory networks have been developed for task-oriented dialogue generation (Raghu et al., 2019; Reddy et al., 2019; Chen et al., 2019; Wang et al., 2020) using multi-level, working, and dynamic types of memory. In DDMN (Wang et al., 2020), the flow of history information during conversations is dynamically tracked to retain the important parts from both dialogue and KB, using a memory manager for each.\nPrior studies (Young et al., 2018; Zhou et al., 2018a; Wu et al., 2020b) have demonstrated the feasibility of including commonsense knowledge into the dialogue systems. Further, in ConKADI (Wu et al., 2020a), felicitous facts highly relevant to the context were selected and effectively integrated in the generated response by means of fusion mechanisms. Recently, co-reference resolution has been utilized for obtaining coref-informed pre-\ntrained models (Ye et al., 2020), task-oriented dialogue generation (Jun Quan and Hu, 2019), and dialogue understanding (Zhang et al., 2021). Further, (Huang et al., 2021) demonstrated the improvement upon explicitly incorporating co-reference information to enhance the attention mechanism for the reading comprehension task.\nIn this paper, we show how structured and unstructured knowledge can be used to improve the task of document-grounded dialogue generation. We propose an effective knowledge-grounded dialogue model named CNTF, which is built with multi-source heterogeneous knowledge. Experiments on knowledge-based dialogue generation benchmark datasets, viz. Wizard of Wikipedia and CMU_DoG, show the efficacy of our proposed approach. Our method employs a large-scale named entity enhanced commonsense knowledge network as well as a domain-specific factual knowledge base to aid in the comprehension of an utterance as well as the generation of a response using a novel mutli-hop attention based model."
    }, {
      "heading" : "3 Methodology",
      "text" : ""
    }, {
      "heading" : "3.1 Problem Formulation",
      "text" : "Formally, let D = {di}Ki=1 denote a conversation composed of K dialogue turns, where di = (a1i , a 2 i ) is an exchange of dialogues between the two agents. Associated with each utterance a1i and a2i are the relevant documents S 1 i and S 2 i with topicspecific knowledge. We utilize common sense and named entity oriented knowledge by creating the set of triples τ = {τ1, τ2, ..., τ|τ |}, where τi is of the form (head, relation, tail), from the following sources: (a) extracting relations from ConceptNet for ev-\nery word in the utterances (if the word is a concept-word from ConceptNet), and (b) forming named entity based triples by using co-reference resolution method\nFor any arbitrary turn k, given the dialogue history {dj}k−1j=1 , the associated documents as well as the target document {S1j , S2j }kj=1, and the associated knowledge triples τ , the objective is to generate an appropriate response Y = {y1, y2, ..., y|Y |}. The architecture of CNTF is shown in Fig. 2."
    }, {
      "heading" : "3.2 Encoder",
      "text" : ""
    }, {
      "heading" : "3.2.1 Dialogue Encoder",
      "text" : "The Dialogue Encoder, that keeps track of the dialogue context in multi-turn conversations, encodes\nthe utterances turn by turn. The input at each turn is a sequence of tokens x = (x1, x2, ..., xn), where n is the number of tokens. For the first turn, a11 is fed as input, while for the subsequent turns (j > 1), the input is the concatenation of the previous turn’s second agent’s response and current turn’s first agent’s utterance, [a2j−1; a 1 j ]. The encoder then exploits BERT (Devlin et al., 2019) to obtain the representations HD = {hi}ni=1.\nUsing the dialogue representations, we maintain two different states for the dialogue, DS and DH , which are both initialized with the encoder hidden states HD, of the first turn. We then follow a sliding window mechanism to update both DS and DH for the succeeding turns. A window of size “l\" means we concatenate hidden states of only the previous “l-1\" turns. This helped in removing noise for longer dialogue contexts and saving memory. DH remains fixed and stores the hidden states for the dialogue context, while DS gets updated at each turn, with the goal of capturing proper history information for accurate response generation."
    }, {
      "heading" : "3.2.2 Knowledge Encoder",
      "text" : "Similarly, the Knowledge Encoder takes as input the document(s) associated with the utterances [S2j−1;S 1 j ] for turn j > 1, else S 1 1 for the first turn, truncated to a max token count of 400. We then again employ a BERT model and obtain the encoded features HKb = {hi}mi=1 where m is number of tokens in the document(s). To incorporate the external topic-specific knowledge effectively, we have knowledge states KbS and KbH . Similar to the dialogue states DS and DH , these are initialized with the hidden states HKb of the relevant documents associated with each utterance. Unlike\nthe sliding window mechanism used for the dialogue states for the upcoming turns, KbS and KbH store only the current turn’s hidden states obtained from the BERT based knowledge encoder."
    }, {
      "heading" : "3.3 Multi-hop Attention",
      "text" : "We adopt the dual and dynamic graph attention mechanism (Wang et al., 2020) to mimic human’s step-by-step exploring and reasoning behavior. In each step, we assume that the dialogue and knowledge states have some information to disseminate. At each hop r, we compute an attention vector α(r)t using the query embedding qt at the k-th turn using D(r−1)S at time step t. DH,k,t and the attention scores are used to obtain the context representation c (r) t .\nα (r) k,t = softmax(ek,t) (1)\nek,t = (v1(r)) ′ tanh(W(r)1 qk,t + W (r) 2 D (r−1) S,k,t ) (2)\nc (r) k,t = K∑ j=1 a (r) k,tDH,k (3)\nwhere v1(r) , W1(r) and W2(r) are the learnable parameters.\nDS is updated using the forget and add operations. To find more details on updating DS refer to Appendix Section A."
    }, {
      "heading" : "3.4 Constructing Named Entity based Triples using Co-reference Resolution",
      "text" : "To add more useful links to the already existing commonsense triples, we use the co-reference chains and named entities extracted from the dialogues. Firstly, we use AllenNLP1 co-reference\n1https://github.com/allenai/allennlp-models\nresolution module to identify co-reference chains in the dialogue. For example, in the dialogue shown in Fig. 1, using the first co-reference chain: [The Last of the Mohicans: it, that movie, It] we rewrite the dialogue with resolved mentions in the utterances as: “[The Last of the Mohicans] is a 1992 American epic historical drama [The Last of the Mohicans] is also one of my favorite movies. Me too. I love [The Last of the Mohicans] and the soundtrack in particular. [The Last of the Mohicans] was directed by Michael Mann, based on [James Fenimore Cooper’s eponymous 1826] novel and so on\". We then use the Spacy toolkit2 to recognize named entities from the augmented dialogue. Simultaneously, we also identify all the concept words using ConceptNet in the newly formed dialogue. The new set of triples are obtained using the named entities and concepts as nodes, and the corresponding edges are built as follows: (a) between every pair of named entities that ap-\npear in the same dialogue, and (b) between a named entity node and other con-\ncepts within the same dialogue. We may note that resolving the co-references first and then extracting named entities ensures that entities across multiple utterances are connected in a certain way."
    }, {
      "heading" : "3.5 Commonsense and Named Entity Enhanced Attention Module",
      "text" : "For each dialogue, the final set of triples is composed of both commonsense and named entity based triples. We obtain triples’ head and tail entity embedding from the trainable embedding layers i.e. E = emb_layer(τ). Formally, a query is used to loop over the triple embedding and compute the attention weights at each hop p.\nα (p) k,t = softmax(q (p−1) t E (p−1)) (4)\nFinally, the weighted context for knowledge triples, (cT )(p), is obtained by weighting the current set of triple embedding, E(p) using the attention scores, a(p). A query update mechanism is used, where the query embeddings are updated using the weighted triple embeddings of the current step.\n(cTk,t) p = n∑ j=1 apk,tE p (5) qpt = q p−1 t + (c T k,t) p (6)\n2https://github.com/huggingface/neuralcoref"
    }, {
      "heading" : "3.6 Decoder",
      "text" : ""
    }, {
      "heading" : "3.6.1 Interactive Dialogue-Knowledge Module",
      "text" : "As each utterance is linked to topic-specific unstructured knowledge, we employ an interactive mechanism to attend to both the dialogue and the knowledge sentences. We can improve information extraction from dialogue as well as knowledge hidden states by using the encoded weighted dialogue context as a query. To obtain the weighted dialogue context WHD, we apply the multi-hop attention as described in Section 3.3 between HD and HK which are the hidden states received from the dialogue and knowledge encoder, respectively. We use a GRU based decoder to generate responses word by word, and initialize the initial hidden states of the decoder with WHD. Then at time step t, the decoder state st can be updated as\nst = GRU(e(yt−1), st−1) (7)\nwhere e(yt−1) is the embedding of the previous word yt−1. Here, st is regarded as a “query” vector qt, which is used to attend to the dialogue, topicspecific knowledge and the structured knowledge triples, and obtain the weighted context, knowledge and triple representation as cDt , c K t and c T t , respectively."
    }, {
      "heading" : "3.6.2 Fusion Block",
      "text" : "The probability distribution over the vocabulary Pg(yt) words is obtained by fusing cDt , c K t , c T t and the decoder state, st, and then passing them through a softmax layer.\nPg(yt) = softmax(W5[st; cDt ; c K t ; c T t ]) (8)\nwhere W5 is a trainable parameter."
    }, {
      "heading" : "3.6.3 Copy Block",
      "text" : "In particular, a word at time step t is either generated from the vocabulary or copied from either the dialogue history, knowledge history, or using entities from the triples. Following the copy mechanism (Gulcehre et al., 2016), the attention scores are viewed as the probability to form the copy distribution. We use the attention score αDk,t of the dialogue and αKbk,t of the unstructured knowledge at the last round viz. PD(yt = w) = ∑ tj:wtj=w\nαDk,t; PKb(yt = w) = ∑ tj:wtj=w\nαKbk,t . The copy distribution over the triples is given by P T (yt = w) =∑\ntj:wtj=w αTk,t. We use the soft gates g1, g2 and g3\nto control whether a word is generated from the vocabulary or it is being copied by combining Pg(yt), PD(yt), PKb(yt), and PT (yt):\ng1 = Sigmoid(W8[st; cDt ] + b2) (9) Pkn(yt) = g1Pg(yt) + (1− g1)PD(yt) (10)\ng2 = Sigmoid(W9[st; cKt ] + b3) (11) Ptp(yt) = g2PKb(yt) + (1− g2)Pkn(yt) (12)\ng3 = Sigmoid(W10[st; cTt ] + b4) (13) P (yt) = g3PT (yt) + (1− g3)Ptp(yt) (14)\nwhere, W8, W9, W10 are parameters to be learned. Therefore, the decoder loss is the cross-entropy between the output distribution P (yt) and the reference distribution, pt, denoted as Loss = − ∑ ptlog(P (yt))."
    }, {
      "heading" : "4 Datasets and Experimental Setup",
      "text" : "In this section, we present the details of the datasets and the other experimental setups."
    }, {
      "heading" : "4.1 Dataset Description",
      "text" : ""
    }, {
      "heading" : "4.1.1 Knowledge Grounded Dialogue Dataset",
      "text" : "We test our proposed technique on two knowledgegrounded dialogue generation benchmark datasets, viz. Wizard of Wikipedia (Dinan et al., 2018) and CMU Document Grounded Conversations (Zhou et al., 2018b). The Woz and CMU DoG datasets consist of approximately ≈ 22K and ≈ 4K dialogs, respectively, covering more than 1,365 and 90 topics. The datasets are summarized in Section B of the Appendix. The statistics of the datasets are shown in Table 4 of the Appendix."
    }, {
      "heading" : "4.1.2 Commonsense Knowledge Base",
      "text" : "We use ConceptNet3, an open-domain repository of commonsense knowledge. It includes the relationships between concepts that are commonly used in everyday situations, such as \"Mango is a fruit.\" This function is desirable in our experiments because it is critical to be able to identify the informal relationships between common concepts in an open-domain conversation setting. We remove triples containing multi-word entities when filtering words based on dataset vocabulary, and 147, 676 triples were retained with 27, 468 entities and 44 relations for Wizard of Wikipedia dataset. For CMU_DoG dataset, we have a total of 14, 689 entities, 74, 485 triples and 42 relations.\n3https://conceptnet.io"
    }, {
      "heading" : "4.2 Baselines",
      "text" : "We use the following models as the baselines: 1. Transformer Memory Network (TMN)4 (Dinan et al., 2018): To encode dialogue, a shared transformer-based encoder is used. After knowledge selection, memory networks are used to reencode the dialogue information. Finally, a transformer decoder is used to decode the responses.\n2. DialogGPTfinetune(Zhao et al., 2020d): It utilises a DialoGPT (345M) model fine-tuned on training examples from the Topical Chat dataset to determine whether the pre-trained models can serve as knowledge bases for open-domain dialogue generation.\n3. Incremental Transformer with Deliberation Decoder (ITDD) (Li et al., 2019): It uses an incremental transformer-based model to encode utterances and documents and a deliberation decoder to decode responses.\n4. Disentanged Response Decoder (DRD) (Zhao et al., 2019): It is made up of three modules: a language model, a context processor, and a knowledge processor for decoding responses. The response decoder is broken down into independent components in this case to investigate knowledgebased dialogue generation.\n5. ConKADI (Wu et al., 2020a): It includes a Felicitous Fact mechanism to help the model focus on knowledge facts that are highly significant; additionally, two techniques, Context-Knowledge Fusion and Flexible Mode Fusion, are proposed to assist ConKADI in integrating the knowledge information.\n6. KnowledGPT (Zhao et al., 2020c): This model implements response generation by combining a pre-trained language model with a knowledge selection module, and it intends to jointly optimize knowledge selection and response generation with unlabeled dialogues using an unsupervised approach.\nImplementation details can be found in Section C of the Appendix. Details on ablation study can be found in Appendix, Section E.2."
    }, {
      "heading" : "4.3 Evaluation Metrics",
      "text" : "To evaluate the predicted responses, we choose BLEU (Papineni et al., 2002), PPL, F1 and Embedding-based metrics (Liu et al., 2016). For human evaluation, we use fluency, adequacy, knowl-\n4https://github.com/facebookresearch/ParlAI/ blob/master/projects/wizard_of_wikipedia\nedge existence, knowledge correctness and knowledge relevance. Section D of the Appendix provides more information on these metrics."
    }, {
      "heading" : "5 Results and Analysis",
      "text" : ""
    }, {
      "heading" : "5.1 Results of Automatic Evaluation",
      "text" : "Table 1 shows the results on automatic evaluation metrics on Wizard of Wikipedia and CMU_DoG datasets. On Wizard, CNTF gives a significant rise of 48% on Test Seen and 53% on Unseen in F1 score and around 2x on both Seen and Unseen, in terms of BLEU-4, compared to the strongest baseline, KnowledGPT. On CMU_DoG too, where the average turn length is roughly 2.5 times that of Wizard, CNTF surpasses the previous best on F1 and BLEU-4 by 8% and 20% respectively. So CNTF achieves new state-of-the-art on both datasets.\nExisting models struggle to generate engaging responses for dialogues based on new topics that were not encountered during the training phase, which most likely explains the observed low performance on Test Unseen. On the contrary, CNTF is capable of capturing the dialogue context and effectively utilizing external commonsense knowledge and parse the implicit mentions made to various\nentities through the conversation to produce accurate responses, as evidenced by the magnitude of improvement achieved. On embedding-based metrics, all three measures have significantly improved, demonstrating the efficacy of our methodology. Comparision to more baseline models can be found in Section E.1 of Appendix."
    }, {
      "heading" : "5.2 Human Evaluation Results",
      "text" : "Human evaluation results are shown in Table 2. We only compare our proposed model against KnowledGPT, ITDD and TMN on Wizard, as manual evaluation is expensive. It is clear that CNTF outperforms the baselines on both adequacy and knowledge-related criteria, demonstrating consistency with the results of automatic evaluation, and has comparable fluency performance. It is important to note that, despite providing contextually appropriate responses, KnowledgGPT failed to capture the accurate knowledge associated with the input sequences, resulting in low scores. All of the kappa values are greater than 0.75, indicating that the annotators agree.\nIn Table 3, we present a few example conversations as predicted by the proposed (CNTF) and\nthe strongest baseline (KnowledGPT) on Test Seen from Wizard of Wikipedia. In utterance 3, CNTF is able to decipher that the context of the discussion is dr. pepper using the triple (drink, RelatedTo, pepper) obtained using the mechanism explained in Section 3.5 unlike KnowledGPT which starts talking about 7up. Additionally, CNTF efficiently utilizes the commonsense knowledge triples by correctly copying the entities in the triples associated with the word flavor. As seen in the fourth utterance, the model correctly decodes the response using more detailed knowledge from the topicspecific knowledge base as opposed to KnowledGPT. Triples such as (1904, RelatedTo, pepper), (sold, RelatedTo, Europe) which were created using Section 3.4 have aided it in understanding the context better."
    }, {
      "heading" : "5.3 Error Analysis",
      "text" : "Using the generated responses, we perform a thorough examination of our proposed model and categorize the errors it encounters as follows:\n1. Repetition: There are some instances where certain words are repeated in the generated responses. For example, Predicted response: “i’ m not sure, but it is similar to violet, violet and violet.\"\n2. Incomplete response: As shown in the response for the last example in Table 3, incomplete responses result in lower fluency scores. The reason for this is that input sequences are truncated because the maximum sequence size for pre-trained models is limited to a fixed length. Few more error cases with examples are shown in Appendix Section E.3."
    }, {
      "heading" : "6 Conclusion",
      "text" : "We present a Commonsense, Named Entity, and Topical Knowledge Fused neural network (CNTF) to address reasoning over multiple knowledge bases in this paper. We propose, in particular, multihop attention over both structured and unstructured knowledge. Unlike previous approaches in Dialog, CNTF can find relevant supporting named entities in dialogs at each step of multihop attention in addition to already present commonsense knowledge. We test CNTF on Woz and CMU_DoG and achieve excellent results. Furthermore, our analysis shows that CNTF can generate consistent results.\nIn the future, we hope to expand our work to build models which include emotions for knowledge grounded dialogues. Also, to tackle repetition and incomplete response, we aim to introduce rewards functions for these factors."
    }, {
      "heading" : "7 Ethical Declaration",
      "text" : "Our work relies solely on publicly available data. We followed the policies for using the data and did not violate any copyright issues."
    }, {
      "heading" : "A Methodology",
      "text" : "To update DS , we use another GRU network to emulate the decoder at round r, obtaining the “intermediate” hidden states, s̃(r)t .\ns̃ (r) t = GRU(c (r) t , qt) (15)\nũ (r) t = u (r−1) t (1− ã (r) t F (r) t ) (16) F (r) t = Sigmoid(W (r) 3 , s̃ (r) t ) (17)\nD (r) S,t = ũ (r) t + ã (r) t A (r) t (18)\nA (r) t = Sigmoid(W (r) 4 , s̃ (r) t ) (19)\nW(r)3 and W (r) 4 are the learnable parameters. ã (r) t is computed similar to the manner defined in Eq 1."
    }, {
      "heading" : "B Datasets",
      "text" : "Experiments are carried out on two benchmark datasets, viz. Wizard of Wikipedia (Dinan et al., 2018) and CMU_DoG (Zhou et al., 2018b).\nWizard of Wikipedia is one of the most comprehensive knowledge-based conversation datasets, covering 1,365 open-domain topics. Each conversation takes place between a wizard who can retrieve knowledge about a specific topic and form a response based on it and an apprentice who is simply eager to speak with the wizard but lacks access to external knowledge. The test set is further divided into two parts: Test Seen and Test Unseen. The former contains conversations about topics that have previously been seen in the training set, whereas the latter contains conversations about topics that have never been seen in either the training or validation sets. CMU_DoG focuses on the movie domain, and the conversations take place between two users who both have access to the relevant documents. Every document includes information such as the title of the film, the cast, an introduction, ratings, and a few scenes. We consider subsequent utterances by the same person as a single one.\nC Implementation Details\nFor our proposed CNTF model, we set the word embedding dimension as 300, and use GloVe word\nembeddings. The hidden size of GRU is sampled from {128, 256}. Both the number of rounds R, the number of hops K are sampled from {2, 3}, and the sliding window size is sampled from {1, 2}. We use the ADAM optimizer (Kingma and Ba, 2014) whose learning rate is fixed to 0.0005 and set the beam size to 4, while decoding the responses. We truncate utterances to a max token count of 200 and knowledge base to 400. To handle the long-text knowledge base of CMU_DoG, for every utterance and knowledge sentence we compute a TF-IDF vector. We then compute the cosine similarity between an utterance and every sentence in the knowledge base and retain the top-2 knowledge sentences, similar to the procedure adopted in Enriched Topical Chat dataset (Gopalakrishnan et al., 2019). The conversation and knowledge base vocabulary is shared and comprises of 30,004 words, while common sense vocabulary is maintained separately. We choose batch size as 2 and 8 for CMU_DoG and Wizard of Wikipedia respectively, for training the models. There are roughly 83M parameters for our model when trained on Wizard of Wikipedia, and 38M on CMU_DoG, the difference in size is due to the vocabulary variation. These are much lesser than large pre-trained models which have much greater parameters (KnowledGPT which uses GPT2). It is trained for 10-15 epochs. We choose the best model when the loss on the validation set does not decrease. The variances of the results are at most 1e-3 after three runs with random initialization for each method, and they have no effect on the trend. We have adapted the code framework from DDMN (Wang et al., 2020). We have used GeForce GTX 1080 Ti as the computing infrastructure. The codes and models used to replicate our research results will be made publicly available."
    }, {
      "heading" : "D Evaluation Metrics",
      "text" : "D.1 Automatic Evaluation:\nWe choose BLEU (Papineni et al., 2002), PPL, F15 and Embedding-based metrics6 (Liu et al., 2016) such as Greedy Matching, Vector Extrema and Embedding Average for evaluation. Perplexity (PPL) is a metric used to assess how well a probability model predicts a sentence. BLEU (BLEU-4) and the unigram F1-score are used to calculate the word overlap between the ground truth and pro-\n5https://github.com/facebookresearch/ParlAI/blob/master/ parlai/core/metrics.py\n6https://github.com/Maluuba/nlg-eval\njected response. Word-matching-based metrics are an alternative to embedding-based metrics. These metrics assign a vector to each word in order to truly understand the intended meaning of the predicted sentence, as described by word embedding. Using the above standard metrics, we evaluate our models on both the seen and unseen test sets of the Wizard of Wikipedia dataset, as well as the test set of the CMU DoG dataset.\nD.2 Human Evaluation:\nAside from the automatic data evaluation, we chose 100 samples at random from the Wizard of Wikipedia’s Test Seen and Test Unseen datasets. We hire two experts, each with a post-graduate degree and experience , to serve as human judgment annotators.The annotators are regular employees (paid monthly in accordance with university policy) earning Rs 35,000 per month. The annotators are members of our research team and have been working on similar projects for the past three years. For each example, we provide our annotators with model responses and human ground-truth. We use the following metrics for evaluation:\n(i) Fluency: It is a metric that measures whether or not a sentence is comprehensible. (ii) Adequacy: This metric evaluates the coherence of the produced response in relation to the context. (iii) Knowledge Existence (KE): This metric determines whether or not the response contains knowledge. (iv) Knowledge Correctness (KC): This item metric is used to determine whether the knowledge in the generated responses is correct. (v) Knowledge Relevance (KR): This metric is used to assess whether or not the knowledge is correct and applicable to the topic of the conversation.\nEach response is given a score of 0 to 2 (representing \"incorrect,\" \"moderately correct,\" and \"perfect\") by the annotators. The annotators’ agreement is calculated using Fleiss’ kappa (Fleiss, 1971)."
    }, {
      "heading" : "E Results",
      "text" : "E.1 Automatic Evaluation\nWe also compare our proposed CNTF model to (Zhao et al., 2020a) and (Zheng et al., 2021). MKST (Zhao et al., 2020a) obtains a F1-score of 22.2 / 21.3 and BLEU-4 score of 0.077 / 0.072 on test seen / unseen of wizard dataset. KTWM (Zhao et al., 2020a) obtains a BLEU-4 score of 0.033 / 0.022 with an embedding average, extrema and greedy score of 0.682 / 0.668, 0.394 / 0.379,\n0.374 / 0.342 respectively. Our model clearly outperforms these baselines by obtaining a BLEU-4 score of 0.102 / 0.084, F1-score of 31.5 / 29.4 with an embedding average, extrema and greedy score of 0.917 / 0.901, 0.593 / 0.575, 0.770 / 0.758 respectively. In addition, our model clearly outperforms the BART based models for knowledge grounded generation (De Bruyn et al., 2020) on F1-score (Test Seen - 12.2 / 20.1; Test Unseen 14.9 /19.3) by a huge margin on both the test set of WoZ dataset.\nE.2 Ablation Study\nTo analyze the impact of the constituent modules in our model on performance, we compare CNTF with the following variants:\n(i) CNTF-D: This configuration only employs the dialogue encoder with multi-hop attention to demonstrate the significance of employing a knowledge encoder. This results in a 53% decrease in F1 score on Test Seen, demonstrating the effectiveness of our knowledge module with multi-hop attention. The score reduction in CMU DoG is less severe because workers do not rely as heavily on external knowledge as the Wizard does, where it is highly correlated with available knowledge. (ii) CNTFDK: Interactive attention is essential for generating insightful responses while decoding the answer. We remove the Interactive Dialogue-Knowledge module, as explained in Section 3.6.1, to demonstrate its utility. This results in a significant decrease in both BLEU and F1 scores. (iii) CNTFDKI: We conduct experiments with only the dialogue and knowledge modules, as well as the interactive module, to demonstrate the benefit of using structured knowledge in the form of triples for gauging the implicit references made throughout the conversation. We see a significant drop in scores here as well. (iv) CNTF-DKIC: This model is used to show the effectiveness of co-reference based named entity triples. We see a drop in BLEU4 scores for the seen testset, but we see an improvement on the unseen testset by using only commonsense knowledge. This could be attributed to the fact that for unseen data, the same entities are usually not present because they are have conversations on topics that are rarely seen in the training set.\nWe may note that CNTF beats the SOTA models on every metric however due to the addition of new triples (more than 60% increment in triples on an average for both the dataset) which may have added to noise in the model our proposed with\nthe enhanced triples obtains lower scores on some metrics than CNTF-DKIC.\nE.3 Error Analysis For a dialogue with no topic specific knowledge sentences usually our model fails to keep the conversation going by generating inadeqaute responses and also misses several entities. For example, Input utterance: that’s not uncommon! there are rescue groups that specialize in finding homes for retired sled dogs. I bet they retire them at a certain age then they need a home huh; Predicted Response (CNTF): that’s cute! i’m sure they’re cute!; Gold Response: yes. huskies got their name from the word referring to eskimos. As it can be clearly seen the model fails to capture the entity huskies and instead generates a generic response."
    } ],
    "references" : [ {
      "title" : "Pretrained language models for dialogue generation with multiple input sources",
      "author" : [ "Yu Cao", "Wei Bi", "Meng Fang", "Dacheng Tao." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 909–917, Online. Association for Com-",
      "citeRegEx" : "Cao et al\\.,? 2020",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2020
    }, {
      "title" : "A working memory model for task-oriented dialog response generation",
      "author" : [ "Xiuyi Chen", "Jiaming Xu", "Bo Xu." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2687–2693, Florence, Italy. Association for",
      "citeRegEx" : "Chen et al\\.,? 2019",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2019
    }, {
      "title" : "Bart for knowledge grounded conversations",
      "author" : [ "Maxime De Bruyn", "Ehsan Lotfi", "Jeska Buhmann", "Walter Daelemans." ],
      "venue" : "Converse@ KDD.",
      "citeRegEx" : "Bruyn et al\\.,? 2020",
      "shortCiteRegEx" : "Bruyn et al\\.",
      "year" : 2020
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Wizard of wikipedia: Knowledge-powered conversational agents",
      "author" : [ "Emily Dinan", "Stephen Roller", "Kurt Shuster", "Angela Fan", "Michael Auli", "Jason Weston." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Dinan et al\\.,? 2018",
      "shortCiteRegEx" : "Dinan et al\\.",
      "year" : 2018
    }, {
      "title" : "Pre-trained language model representations for language generation",
      "author" : [ "Sergey Edunov", "Alexei Baevski", "Michael Auli." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
      "citeRegEx" : "Edunov et al\\.,? 2019",
      "shortCiteRegEx" : "Edunov et al\\.",
      "year" : 2019
    }, {
      "title" : "Search and inference strategies in pronoun resolution: An experimental study",
      "author" : [ "Kate Ehrlich." ],
      "venue" : "19th Annual Meeting of the Association for Computational Linguistics, pages 89–93.",
      "citeRegEx" : "Ehrlich.,? 1981",
      "shortCiteRegEx" : "Ehrlich.",
      "year" : 1981
    }, {
      "title" : "Measuring nominal scale agreement among many raters",
      "author" : [ "Joseph L Fleiss." ],
      "venue" : "Psychological bulletin, 76(5):378.",
      "citeRegEx" : "Fleiss.,? 1971",
      "shortCiteRegEx" : "Fleiss.",
      "year" : 1971
    }, {
      "title" : "A knowledge-grounded neural conversation model",
      "author" : [ "Marjan Ghazvininejad", "Chris Brockett", "Ming-Wei Chang", "Bill Dolan", "Jianfeng Gao", "Wen-tau Yih", "Michel Galley." ],
      "venue" : "Thirty-Second AAAI Conference on Artificial Intelligence.",
      "citeRegEx" : "Ghazvininejad et al\\.,? 2018",
      "shortCiteRegEx" : "Ghazvininejad et al\\.",
      "year" : 2018
    }, {
      "title" : "Pointing the unknown words",
      "author" : [ "Caglar Gulcehre", "Sungjin Ahn", "Ramesh Nallapati", "Bowen Zhou", "Yoshua Bengio." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 140–149.",
      "citeRegEx" : "Gulcehre et al\\.,? 2016",
      "shortCiteRegEx" : "Gulcehre et al\\.",
      "year" : 2016
    }, {
      "title" : "Tracing origins: Coref-aware machine reading comprehension",
      "author" : [ "Baorong Huang", "Zhuosheng Zhang", "Hai Zhao" ],
      "venue" : null,
      "citeRegEx" : "Huang et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2021
    }, {
      "title" : "Gecor: An end-to-end generative ellipsis and co-reference resolution model for task-oriented dialogue",
      "author" : [ "Bonnie Webber Jun Quan", "Deyi Xiong", "Changjian Hu." ],
      "venue" : "Conference on Empirical Methods in Natural Language Processing and 9th International",
      "citeRegEx" : "Quan et al\\.,? 2019",
      "shortCiteRegEx" : "Quan et al\\.",
      "year" : 2019
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P Kingma", "Jimmy Ba." ],
      "venue" : "arXiv preprint arXiv:1412.6980.",
      "citeRegEx" : "Kingma and Ba.,? 2014",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2014
    }, {
      "title" : "A diversity-promoting objective function for neural conversation models",
      "author" : [ "Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "William B Dolan." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Li et al\\.,? 2016a",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "A persona-based neural conversation model",
      "author" : [ "Jiwei Li", "Michel Galley", "Chris Brockett", "Georgios Spithourakis", "Jianfeng Gao", "William B Dolan." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume",
      "citeRegEx" : "Li et al\\.,? 2016b",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Incremental transformer with deliberation decoder for document grounded conversations",
      "author" : [ "Zekang Li", "Cheng Niu", "Fandong Meng", "Yang Feng", "Qian Li", "Jie Zhou." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Lin-",
      "citeRegEx" : "Li et al\\.,? 2019",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "How NOT to evaluate your dialogue system: An empirical study of unsupervised evaluation metrics for dialogue response generation",
      "author" : [ "Chia-Wei Liu", "Ryan Lowe", "Iulian Serban", "Mike Noseworthy", "Laurent Charlin", "Joelle Pineau." ],
      "venue" : "Proceedings of",
      "citeRegEx" : "Liu et al\\.,? 2016",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2016
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Proceedings of the 40th annual meeting on association for computational linguistics, pages 311–318. Association for",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever" ],
      "venue" : "OpenAI blog,",
      "citeRegEx" : "Radford et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "Disentangling Language and Knowledge in TaskOriented Dialogs",
      "author" : [ "Dinesh Raghu", "Nikhil Gupta", "Mausam." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
      "citeRegEx" : "Raghu et al\\.,? 2019",
      "shortCiteRegEx" : "Raghu et al\\.",
      "year" : 2019
    }, {
      "title" : "Multi-level memory for task oriented dialogs",
      "author" : [ "Revanth Gangi Reddy", "Danish Contractor", "Dinesh Raghu", "Sachindra Joshi." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-",
      "citeRegEx" : "Reddy et al\\.,? 2019",
      "shortCiteRegEx" : "Reddy et al\\.",
      "year" : 2019
    }, {
      "title" : "Building end-to-end dialogue systems using generative hierarchical neural network models",
      "author" : [ "Iulian V Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron Courville", "Joelle Pineau." ],
      "venue" : "Thirtieth AAAI Conference on Artificial Intelligence.",
      "citeRegEx" : "Serban et al\\.,? 2016",
      "shortCiteRegEx" : "Serban et al\\.",
      "year" : 2016
    }, {
      "title" : "A hierarchical latent variable encoder-decoder model for generating dialogues",
      "author" : [ "Iulian Vlad Serban", "Alessandro Sordoni", "Ryan Lowe", "Laurent Charlin", "Joelle Pineau", "Aaron Courville", "Yoshua Bengio." ],
      "venue" : "Thirty-First AAAI Conference on Artificial Intelli-",
      "citeRegEx" : "Serban et al\\.,? 2017",
      "shortCiteRegEx" : "Serban et al\\.",
      "year" : 2017
    }, {
      "title" : "Neural responding machine for short-text conversation",
      "author" : [ "Lifeng Shang", "Zhengdong Lu", "Hang Li." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Lan-",
      "citeRegEx" : "Shang et al\\.,? 2015",
      "shortCiteRegEx" : "Shang et al\\.",
      "year" : 2015
    }, {
      "title" : "Representing general relational knowledge in conceptnet 5",
      "author" : [ "Robert Speer", "Catherine Havasi." ],
      "venue" : "LREC, pages 3679–3686.",
      "citeRegEx" : "Speer and Havasi.,? 2012",
      "shortCiteRegEx" : "Speer and Havasi.",
      "year" : 2012
    }, {
      "title" : "Sequence to sequence learning with neural networks",
      "author" : [ "Ilya Sutskever", "Oriol Vinyals", "Quoc V Le." ],
      "venue" : "Advances in neural information processing systems, pages 3104–3112.",
      "citeRegEx" : "Sutskever et al\\.,? 2014",
      "shortCiteRegEx" : "Sutskever et al\\.",
      "year" : 2014
    }, {
      "title" : "Get the point of my utterance! learning towards effective responses with multi-head attention mechanism",
      "author" : [ "Chongyang Tao", "Shen Gao", "Mingyue Shang", "Wei Wu", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "Proceedings of the 27th International Joint Conference on",
      "citeRegEx" : "Tao et al\\.,? 2018",
      "shortCiteRegEx" : "Tao et al\\.",
      "year" : 2018
    }, {
      "title" : "A neural conversational model",
      "author" : [ "Oriol Vinyals", "Quoc Le." ],
      "venue" : "arXiv preprint arXiv:1506.05869.",
      "citeRegEx" : "Vinyals and Le.,? 2015",
      "shortCiteRegEx" : "Vinyals and Le.",
      "year" : 2015
    }, {
      "title" : "Dual dynamic memory network for end-to-end multi-turn task-oriented dialog systems",
      "author" : [ "Jian Wang", "Junhao Liu", "Wei Bi", "Xiaojiang Liu", "Kejing He", "Ruifeng Xu", "Min Yang." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Wang et al\\.,? 2020",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "Diverse and informative dialogue generation with context-specific commonsense knowledge awareness",
      "author" : [ "Sixing Wu", "Ying Li", "Dawei Zhang", "Yang Zhou", "Zhonghai Wu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Wu et al\\.,? 2020a",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Topicka: Generating commonsense knowledge-aware dialogue responses towards the recommended topic fact",
      "author" : [ "Sixing Wu", "Ying Li", "Dawei Zhang", "Yang Zhou", "Zhonghai Wu." ],
      "venue" : "Proceedings of the Twenty-Ninth International Joint Conference on Arti-",
      "citeRegEx" : "Wu et al\\.,? 2020b",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Topic aware neural response generation",
      "author" : [ "Chen Xing", "Wei Wu", "Yu Wu", "Jie Liu", "Yalou Huang", "Ming Zhou", "Wei-Ying Ma." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 31.",
      "citeRegEx" : "Xing et al\\.,? 2017",
      "shortCiteRegEx" : "Xing et al\\.",
      "year" : 2017
    }, {
      "title" : "Coreferential Reasoning Learning for Language Representation",
      "author" : [ "Deming Ye", "Yankai Lin", "Jiaju Du", "Zhenghao Liu", "Peng Li", "Maosong Sun", "Zhiyuan Liu." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Ye et al\\.,? 2020",
      "shortCiteRegEx" : "Ye et al\\.",
      "year" : 2020
    }, {
      "title" : "Augmenting end-to-end dialogue systems with commonsense knowledge",
      "author" : [ "Tom Young", "Erik Cambria", "Iti Chaturvedi", "Hao Zhou", "Subham Biswas", "Minlie Huang." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 32.",
      "citeRegEx" : "Young et al\\.,? 2018",
      "shortCiteRegEx" : "Young et al\\.",
      "year" : 2018
    }, {
      "title" : "Recosa: Detecting the relevant contexts with self-attention for multi-turn dialogue generation",
      "author" : [ "Hainan Zhang", "Yanyan Lan", "Liang Pang", "Jiafeng Guo", "Xueqi Cheng." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Lin-",
      "citeRegEx" : "Zhang et al\\.,? 2019",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    }, {
      "title" : "Personalizing dialogue agents: I have a dog, do you have pets too",
      "author" : [ "Saizheng Zhang", "Emily Dinan", "Jack Urbanek", "Arthur Szlam", "Douwe Kiela", "Jason Weston" ],
      "venue" : "In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics",
      "citeRegEx" : "Zhang et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "What did you refer to? Evaluating co-references in dialogue",
      "author" : [ "Wei-Nan Zhang", "Yue Zhang", "Hanlin Tang", "Zhengyu Zhao", "Caihai Zhu", "Ting Liu." ],
      "venue" : "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 5075–5084,",
      "citeRegEx" : "Zhang et al\\.,? 2021",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2021
    }, {
      "title" : "Dialogpt: Largescale generative pre-training for conversational response generation",
      "author" : [ "Liu", "William B Dolan." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 270–278.",
      "citeRegEx" : "Liu and Dolan.,? 2020",
      "shortCiteRegEx" : "Liu and Dolan.",
      "year" : 2020
    }, {
      "title" : "Learning discourse-level diversity for neural dialog models using conditional variational autoencoders",
      "author" : [ "Tiancheng Zhao", "Ran Zhao", "Maxine Eskenazi." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume",
      "citeRegEx" : "Zhao et al\\.,? 2017",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2017
    }, {
      "title" : "Multiple knowledge syncretic transformer for natural dialogue generation",
      "author" : [ "Xiangyu Zhao", "Longbiao Wang", "Ruifang He", "Ting Yang", "Jinxin Chang", "Ruifang Wang." ],
      "venue" : "Proceedings of The Web Conference 2020, pages 752–762.",
      "citeRegEx" : "Zhao et al\\.,? 2020a",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2020
    }, {
      "title" : "Low-resource knowledge-grounded dialogue generation",
      "author" : [ "Xueliang Zhao", "Wei Wu", "Chongyang Tao", "Can Xu", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Zhao et al\\.,? 2019",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2019
    }, {
      "title" : "Low-resource knowledge-grounded dialogue generation",
      "author" : [ "Xueliang Zhao", "Wei Wu", "Chongyang Tao", "Can Xu", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "arXiv preprint arXiv:2002.10348.",
      "citeRegEx" : "Zhao et al\\.,? 2020b",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2020
    }, {
      "title" : "Knowledgegrounded dialogue generation with pre-trained language models",
      "author" : [ "Xueliang Zhao", "Wei Wu", "Can Xu", "Chongyang Tao", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Zhao et al\\.,? 2020c",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2020
    }, {
      "title" : "Are pre-trained language models knowledgeable to ground open domain dialogues? arXiv preprint arXiv:2011.09708",
      "author" : [ "Yufan Zhao", "Wei Wu", "Can Xu" ],
      "venue" : null,
      "citeRegEx" : "Zhao et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2020
    }, {
      "title" : "Knowledge-grounded dialogue generation with termlevel de-noising",
      "author" : [ "Wen Zheng", "Natasa Milic-Frayling", "Ke Zhou." ],
      "venue" : "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 2972–2983, Online. Association for Computa-",
      "citeRegEx" : "Zheng et al\\.,? 2021",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2021
    }, {
      "title" : "Commonsense knowledge aware conversation generation with graph attention",
      "author" : [ "Hao Zhou", "Tom Young", "Minlie Huang", "Haizhou Zhao", "Jingfang Xu", "Xiaoyan Zhu." ],
      "venue" : "Proceedings of the 27th International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "Zhou et al\\.,? 2018a",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2018
    }, {
      "title" : "A dataset for document grounded conversations",
      "author" : [ "Kangyan Zhou", "Shrimai Prabhumoye", "Alan W Black." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 708–713, Brussels, Belgium. Association",
      "citeRegEx" : "Zhou et al\\.,? 2018b",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "Additionally, as a key human language phenomena, co-reference simplifies human languages while being a significant barrier for machines to understand, particularly for pronouns, which are difficult to parse due to their weak semantic meanings (Ehrlich, 1981).",
      "startOffset" : 243,
      "endOffset" : 258
    }, {
      "referenceID" : 8,
      "context" : "Grounded response generation approaches (Ghazvininejad et al., 2018; Dinan et al., 2018) can provide replication of facts",
      "startOffset" : 40,
      "endOffset" : 88
    }, {
      "referenceID" : 4,
      "context" : "Grounded response generation approaches (Ghazvininejad et al., 2018; Dinan et al., 2018) can provide replication of facts",
      "startOffset" : 40,
      "endOffset" : 88
    }, {
      "referenceID" : 24,
      "context" : "We first construct triples based on named entity after resolving coreferences in the dialogues to enhance the already existing commonsense triples obtained from the ConceptNet (Speer and Havasi, 2012).",
      "startOffset" : 176,
      "endOffset" : 200
    }, {
      "referenceID" : 27,
      "context" : "Sequence-to-sequence models (Vinyals and Le, 2015; Sutskever et al., 2014) have long been used for natural language generation (NLG) tasks.",
      "startOffset" : 28,
      "endOffset" : 74
    }, {
      "referenceID" : 25,
      "context" : "Sequence-to-sequence models (Vinyals and Le, 2015; Sutskever et al., 2014) have long been used for natural language generation (NLG) tasks.",
      "startOffset" : 28,
      "endOffset" : 74
    }, {
      "referenceID" : 23,
      "context" : "Stemming off the vanilla encoder-decoder architecture - introduced initially for neural machine translation (Shang et al., 2015), a variety of models have",
      "startOffset" : 108,
      "endOffset" : 128
    }, {
      "referenceID" : 13,
      "context" : "been developed for enhancing the quality of the responses generated (Li et al., 2016a; Zhao et al., 2017; Tao et al., 2018) to effectively select the conversational context in multi-turn dialogues (Serban et al.",
      "startOffset" : 68,
      "endOffset" : 123
    }, {
      "referenceID" : 38,
      "context" : "been developed for enhancing the quality of the responses generated (Li et al., 2016a; Zhao et al., 2017; Tao et al., 2018) to effectively select the conversational context in multi-turn dialogues (Serban et al.",
      "startOffset" : 68,
      "endOffset" : 123
    }, {
      "referenceID" : 26,
      "context" : "been developed for enhancing the quality of the responses generated (Li et al., 2016a; Zhao et al., 2017; Tao et al., 2018) to effectively select the conversational context in multi-turn dialogues (Serban et al.",
      "startOffset" : 68,
      "endOffset" : 123
    }, {
      "referenceID" : 31,
      "context" : ", 2018) to effectively select the conversational context in multi-turn dialogues (Serban et al., 2016, 2017; Xing et al., 2017; Zhang et al., 2019); and to model persona while conversing (Li et al.",
      "startOffset" : 81,
      "endOffset" : 147
    }, {
      "referenceID" : 34,
      "context" : ", 2018) to effectively select the conversational context in multi-turn dialogues (Serban et al., 2016, 2017; Xing et al., 2017; Zhang et al., 2019); and to model persona while conversing (Li et al.",
      "startOffset" : 81,
      "endOffset" : 147
    }, {
      "referenceID" : 14,
      "context" : ", 2019); and to model persona while conversing (Li et al., 2016b; Zhang et al., 2018).",
      "startOffset" : 47,
      "endOffset" : 85
    }, {
      "referenceID" : 35,
      "context" : ", 2019); and to model persona while conversing (Li et al., 2016b; Zhang et al., 2018).",
      "startOffset" : 47,
      "endOffset" : 85
    }, {
      "referenceID" : 3,
      "context" : "Pre-trained language models (Devlin et al., 2019; Radford et al., 2019) have been utilized for dialogue generation (Edunov et al.",
      "startOffset" : 28,
      "endOffset" : 71
    }, {
      "referenceID" : 18,
      "context" : "Pre-trained language models (Devlin et al., 2019; Radford et al., 2019) have been utilized for dialogue generation (Edunov et al.",
      "startOffset" : 28,
      "endOffset" : 71
    }, {
      "referenceID" : 42,
      "context" : "They have been extended to leverage the knowledge from the unstructured documents and other auxiliary sources via knowledge selection and various attention fusion techniques (Zhao et al., 2020c; Cao et al., 2020).",
      "startOffset" : 174,
      "endOffset" : 212
    }, {
      "referenceID" : 0,
      "context" : "They have been extended to leverage the knowledge from the unstructured documents and other auxiliary sources via knowledge selection and various attention fusion techniques (Zhao et al., 2020c; Cao et al., 2020).",
      "startOffset" : 174,
      "endOffset" : 212
    }, {
      "referenceID" : 41,
      "context" : "The task was explored in low-resource setting (Zhao et al., 2020b) using a disentangled response decoder, and the usability of language models itself as a knowledge base has also been investigated (Zhao et al.",
      "startOffset" : 46,
      "endOffset" : 66
    }, {
      "referenceID" : 44,
      "context" : "To limit the noise by generative models, knowledge selection (Zheng et al., 2021) by estimation of the weights for every term in the knowledge and using the most important terms in the response were studied.",
      "startOffset" : 61,
      "endOffset" : 81
    }, {
      "referenceID" : 19,
      "context" : "Knowledge based end-to-end memory networks have been developed for task-oriented dialogue generation (Raghu et al., 2019; Reddy et al., 2019; Chen et al., 2019; Wang et al., 2020) using multi-level, working, and dynamic types of memory.",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 20,
      "context" : "Knowledge based end-to-end memory networks have been developed for task-oriented dialogue generation (Raghu et al., 2019; Reddy et al., 2019; Chen et al., 2019; Wang et al., 2020) using multi-level, working, and dynamic types of memory.",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 1,
      "context" : "Knowledge based end-to-end memory networks have been developed for task-oriented dialogue generation (Raghu et al., 2019; Reddy et al., 2019; Chen et al., 2019; Wang et al., 2020) using multi-level, working, and dynamic types of memory.",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 28,
      "context" : "Knowledge based end-to-end memory networks have been developed for task-oriented dialogue generation (Raghu et al., 2019; Reddy et al., 2019; Chen et al., 2019; Wang et al., 2020) using multi-level, working, and dynamic types of memory.",
      "startOffset" : 101,
      "endOffset" : 179
    }, {
      "referenceID" : 28,
      "context" : "In DDMN (Wang et al., 2020), the flow of history information during conversations is dynamically tracked to retain the important parts from both dialogue and KB, using a memory manager for each.",
      "startOffset" : 8,
      "endOffset" : 27
    }, {
      "referenceID" : 33,
      "context" : "Prior studies (Young et al., 2018; Zhou et al., 2018a; Wu et al., 2020b) have demonstrated the feasibility of including commonsense knowledge into the dialogue systems.",
      "startOffset" : 14,
      "endOffset" : 72
    }, {
      "referenceID" : 45,
      "context" : "Prior studies (Young et al., 2018; Zhou et al., 2018a; Wu et al., 2020b) have demonstrated the feasibility of including commonsense knowledge into the dialogue systems.",
      "startOffset" : 14,
      "endOffset" : 72
    }, {
      "referenceID" : 30,
      "context" : "Prior studies (Young et al., 2018; Zhou et al., 2018a; Wu et al., 2020b) have demonstrated the feasibility of including commonsense knowledge into the dialogue systems.",
      "startOffset" : 14,
      "endOffset" : 72
    }, {
      "referenceID" : 29,
      "context" : "Further, in ConKADI (Wu et al., 2020a), felicitous facts highly relevant to the context were selected and effectively integrated in the generated response by means of fusion mechanisms.",
      "startOffset" : 20,
      "endOffset" : 38
    }, {
      "referenceID" : 32,
      "context" : "Recently, co-reference resolution has been utilized for obtaining coref-informed pretrained models (Ye et al., 2020), task-oriented dialogue generation (Jun Quan and Hu, 2019), and dialogue understanding (Zhang et al.",
      "startOffset" : 99,
      "endOffset" : 116
    }, {
      "referenceID" : 36,
      "context" : ", 2020), task-oriented dialogue generation (Jun Quan and Hu, 2019), and dialogue understanding (Zhang et al., 2021).",
      "startOffset" : 95,
      "endOffset" : 115
    }, {
      "referenceID" : 10,
      "context" : "Further, (Huang et al., 2021) demonstrated the improvement upon explicitly incorporating co-reference information to enhance the attention mechanism for the reading comprehension task.",
      "startOffset" : 9,
      "endOffset" : 29
    }, {
      "referenceID" : 3,
      "context" : "The encoder then exploits BERT (Devlin et al., 2019) to obtain the representations HD = {hi}i=1.",
      "startOffset" : 31,
      "endOffset" : 52
    }, {
      "referenceID" : 28,
      "context" : "We adopt the dual and dynamic graph attention mechanism (Wang et al., 2020) to mimic human’s",
      "startOffset" : 56,
      "endOffset" : 75
    }, {
      "referenceID" : 9,
      "context" : "Following the copy mechanism (Gulcehre et al., 2016), the attention scores are viewed as the probability to form the copy distribution.",
      "startOffset" : 29,
      "endOffset" : 52
    }, {
      "referenceID" : 4,
      "context" : "Wizard of Wikipedia (Dinan et al., 2018) and CMU Document Grounded Conversations (Zhou et al.",
      "startOffset" : 20,
      "endOffset" : 40
    }, {
      "referenceID" : 46,
      "context" : ", 2018) and CMU Document Grounded Conversations (Zhou et al., 2018b).",
      "startOffset" : 48,
      "endOffset" : 68
    }, {
      "referenceID" : 4,
      "context" : "Transformer Memory Network (TMN)4 (Dinan et al., 2018): To encode dialogue, a shared transformer-based encoder is used.",
      "startOffset" : 34,
      "endOffset" : 54
    }, {
      "referenceID" : 15,
      "context" : "Incremental Transformer with Deliberation Decoder (ITDD) (Li et al., 2019): It uses an incremental transformer-based model to encode utterances and documents and a deliberation decoder to decode responses.",
      "startOffset" : 57,
      "endOffset" : 74
    }, {
      "referenceID" : 40,
      "context" : "Disentanged Response Decoder (DRD) (Zhao et al., 2019): It is made up of three modules: a language model, a context processor, and a knowledge processor for decoding responses.",
      "startOffset" : 35,
      "endOffset" : 54
    }, {
      "referenceID" : 29,
      "context" : "ConKADI (Wu et al., 2020a): It includes a Felicitous Fact mechanism to help the model focus on knowledge facts that are highly significant;",
      "startOffset" : 8,
      "endOffset" : 26
    }, {
      "referenceID" : 42,
      "context" : "KnowledGPT (Zhao et al., 2020c): This model implements response generation by combining a pre-trained language model with a knowledge selection module, and it intends to jointly optimize knowledge selection and response generation with unlabeled dialogues using an unsupervised approach.",
      "startOffset" : 11,
      "endOffset" : 31
    }, {
      "referenceID" : 17,
      "context" : "To evaluate the predicted responses, we choose BLEU (Papineni et al., 2002), PPL, F1 and Embedding-based metrics (Liu et al.",
      "startOffset" : 52,
      "endOffset" : 75
    }, {
      "referenceID" : 16,
      "context" : ", 2002), PPL, F1 and Embedding-based metrics (Liu et al., 2016).",
      "startOffset" : 45,
      "endOffset" : 63
    }, {
      "referenceID" : 42,
      "context" : "The values for baseline models are derived from (Zhao et al., 2020c) and (Zhao et al.",
      "startOffset" : 48,
      "endOffset" : 68
    } ],
    "year" : 0,
    "abstractText" : "Grounding dialogue on external knowledge and interpreting linguistic patterns in dialogue history context, such as ellipsis, anaphora, and co-reference is critical for dialogue comprehension and generation. In this paper, we present a novel open-domain dialogue generation model which effectively utilizes the largescale commonsense and named entity based knowledge in addition to the unstructured topicspecific knowledge associated with each utterance. We enhance the commonsense knowledge with named entity-aware structures using co-references. Our proposed model utilises a multi-hop attention layer to preserve the most accurate and critical parts of the dialogue history and the associated knowledge. In addition, we employ a Commonsense and Named Entity Enhanced Attention Module, which starts with the extracted triples from various sources and gradually finds the relevant supporting set of triples using multi-hop attention with the query vector obtained from the interactive dialogueknowledge module. Empirical results on two benchmark datasets demonstrate that our model significantly outperforms the state-of-the-art methods in terms of both automatic evaluation metrics and human judgment.",
    "creator" : null
  }
}