{
  "name" : "ARR_2022_40_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "SalesBot: Transitioning from Chit-Chat to Task-Oriented Dialogues",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Until now, researchers have often separated opendomain and task-oriented dialogues as two distinct types of tasks in the dialogue field. The publicly available datasets focuses on either open-domain\n1Our dataset, trained simulators, and annotations will be publicly available once accepted.\nor task-oriented dialogues. For example, a lot of prior work focused on building open-domain dialogue systems (Li et al., 2017; Zhang et al., 2018; Adiwardana et al., 2020a), which chat with users via suitable, engaging, safe conversations. With the capability of pre-trained models, a large set of human conversations is adopted to train their capability of free chatting (Zhang et al., 2020; Adiwardana et al., 2020b; Roller et al., 2021). Although these models show the outstanding capability of communicating with human, they are not able to complete tasks as human assistants. On the other hand, MultiWoz (Budzianowski et al., 2018; Hosseini-Asl et al., 2020) and Schema-Guided Dialogue (SGD) (Rastogi et al., 2020) are two popular large-scale datasets of task-oriented dialogues, which include plenty of multi-domain dialogues with state information to track users’ behaviors. In task-oriented scenarios, the users have their goals\nbefore starting the conversations, so the way we evaluate the system’s performance is whether the system can successfully complete the users’ goals. However, both skills of social chatting and taskoriented dialogues are important and may be used in a single conversation.\nConsidering that both skills are essential for a human-like dialogue system, the recent work (Sun et al., 2021) merged those two capabilities by inserting chit-chat sentences into the existing taskoriented dialogue data. The idea is to allow the agent gains more social, personalized communication skills when focusing on task-oriented dialogue generation. Even the released data contains both social and task-oriented dialogues, each dialogue still focuses on a task-oriented scenario where the user has the goal before starting the conversation. In our target scenarios as illustrated in Figure 1, the conversation starts without any specific goal in the user’s mind, and the agent explores the potential task-oriented intents and smoothly transitions to a task-oriented conversation. The focus of this paper is more similar to a salesperson’s capability, where he/she needs to chat with the user and discovers the implicit task-oriented intents that fit the business purposes and navigates the user to complete a task, such as purchasing a product, reserving a restaurant, or booking a hotel room. Hence, a new pipeline for constructing such data is proposed. Each dialogue in the released dataset starts with discovering a potential task-oriented intent of a user in the social conversation and ends in completing a specific task. Even though high-quality chit-chats and task-oriented dialogues can be separately generated shown in prior work (Hosseini-Asl et al., 2020; Adiwardana et al., 2020b; Roller et al., 2021), how to generate our desired dialogues has not been fully studied and remained unresolved.\nYu et al. (2017) built a dialogue framework for users not having a clear intention, where mixing social responses into the conversation guides the flow to a specific movie they want to promote. Our paper has a similar idea about exploring the potential topics in the social conversations and then promoting the targeted tasks. Although the prior work proposed the proper framework for the target scenarios, it required manual rules for dialogue strategies, making it difficult to scale. Also, it only covers a single domain (movie) and there is no any publicly available data for following research\nwork. This paper covers more common topics by taking advantage of the existing natural language generation models trained on substantial dialogue datasets, and releases the first large-scale dialogue dataset with conversations naturally transitioning from chit-chats to task-oriented forms. Our contributions can be summarized as 4-fold:\n• We present a framework with a simulated user and a simulated salesperson to automatically generate dialogues that smoothly transitions from social chit-chats to task-oriented dialogues, where the components inside the framework can be easily replaced by any desired models for better flexibility. • Human evaluation on the generated dialogues demonstrates that the proposed method produces dialogues with reasonable quality and natural conversation flows. • We release the first large-scale dataset of dialogues transitioning from chit-chat to taskoriented scenarios, which contains the automatically generated dialogues and the detailed human annotations for enabling the future research work. • The released framework with both user and sales simulators allows researchers to generate unlimited dialogues for semi-supervised and unsupervised usage."
    }, {
      "heading" : "2 Proposed Approach",
      "text" : "Figure 2 illustrates our proposed framework for constructing the dataset. It can be divided into three main parts: (1) open-domain dialogue generation, (2) chit-chat to task-oriented transition, and (3) taskoriented dialogue (TOD) generation."
    }, {
      "heading" : "2.1 Open-Domain Dialogue Generation",
      "text" : "As shown in Figure 1, the conversations start with social chatting between users and salespersons. To generate high-quality open-domain dialogues, the pre-trained dialogue generation models can be adopted. Here we choose BlenderBot (Roller et al., 2021) as our pre-trained generation model due to its outstanding capability trained on the largestever open-domain data. It shows the ability to be engaging, knowledgeable, and empathetic at a certain level by multi-tasking on the Blended Skill Talk (BST) dataset (Smith et al., 2020) with several different datasets blending.\nBecause users may explore any topics they want\nto discuss in a real-world setting, we manipulate the user and the sales to have different personas in order to cover wide-range topics in our generated dialogues. This can be easily implemented by the package ParlAI2 (Miller et al., 2017), which allows us to build two BlenderBots to self-chat with each other in order to construct various dialogues involving different personas in the BST."
    }, {
      "heading" : "2.2 Chit-Chat to Task-Oriented Transition",
      "text" : "From a salesperson’s perspective, how to capture the suitable timing and how to promote the target products/tasks are two main challenges. This paper proposes two components to address the above issues; specifically, a task-oriented intent detector and a transition turn generator focus on capturing the suitable timing and deciding how to smoothly transition to the target task respectively."
    }, {
      "heading" : "2.2.1 Task-Oriented Intent Detection",
      "text" : "To find out the good timing during social chatting, we focus on detecting whether the user currently has an implicit intent related to the target tasks. In our case, an intent indicates what a user desires to do or what he/she is very likely to do if someone encourages him/her to do so. If our intent detector is able to capture any task-oriented intent in the social content with diverse topics, it tells us the suitable timing for guiding the dialogue to a specific topic and then transition to a corresponding task-oriented conversation. Table 1 shows the intents we focus on in this paper, and other desired intents can be easily extended by our approach.\nAlthough detecting intents in task-oriented dialogues has been studied for long time, the intent detection models trained on task-oriented datasets cannot be directly utilized. The reason is that the in-\n2https://parl.ai\ntents in our scenarios are different from the intents in classical task-oriented data, where former ones are more implicit and the latter ones are more explicit. For example, a user utterance with the intent FindAttraction in our case may be “I never visit France, but I heard that it is a good place.” instead of “Find me the landmarks in Paris.” in classical task-oriented dialogue datasets. Therefore, this paper proposes to leverage the powerful capability of question answering (QA) systems to identify the potential task-oriented intents in a zero-shot fashion (Namazifar et al., 2020). Specifically, we use the pre-trained QA model and ask whether the user has a certain intent given the current dialogue. The questions need to be designed for describing the target task-oriented intents, and we use the following ways to create the questions focusing on task-oriented intents.\n1. Questions based on descriptions: we create questions associated with all intents based on their natural language descriptions, e.g. “Is the intent asking about playing songs?” for the intent PlaySong. 2. Paraphrased questions: to enhance the detection recall for open-domain dialogues, for each intent, we paraphrase the descriptionbased questions via a high-quality paraphrasing T5 model pre-trained on Quora Question Pairs data for its paraphrasing capability (Wang et al., 2017).\nThe proposed intent detector is illustrated in Figure 3, where the inputs are the open-domain conversation along with intent-related questions, and the outputs are Yes/No answers to these questions. Note that any type of QA models can be adopted in our framework. Here we start with a QA model pre-trained on large open-domain QA data, e.g., SQuAD (Rajpurkar et al., 2018) or CommonsenseQA (Talmor et al., 2019), which is supposed to be equipped with certain common knowledge and the reasoning ability useful for our intent detector. Furthermore, the general QA model may not be capable of correctly answering intent-related questions since the contexts and questions differ a lot from ones in the general QA data. To reduce the mismatch, we fine-tune the QA model on a publicly available task-oriented dataset (e.g., SGD). Specifically, the annotated intents in task-oriented dialogues are utilized to create the associated QA data, where there is a ground truth answer (Yes/No) to each intent-related question at all dialogue turns. Then the built training data (TOD-QA shown in Figure 3) allows the general QA model to better identify task-oriented intents. Although fine-tuned on the task-oriented dataset, we find that the model benefits from pre-training and thus it can be well applied to open-domain dialogues."
    }, {
      "heading" : "2.2.2 Transition Turn Generation",
      "text" : "This section describes how we generate the transition turn that bridges open-domain and taskoriented dialogues. Our transition turn generation procedure is composed of two parts: 1) using a template transition sentence to trigger the corresponding task-oriented user reaction and 2) re-generating the transition turn for better fluency and diversity.\nTemplate-based For each task-oriented intent, we adapt its intent description in the ontology to create a corresponding template question (e.g., Do you want to [Intent Description]?) as the transition sentence shown in the upper block of Figure 4. Although using template-based transition is simple\nand effective, it however makes the salesperson too aggressive and invariant to be professional. Generative-based To improve the fluency of transition and increase the diversity of word usage, we propose a generative-based approach to re-generate more smooth and nature transitions. With a similar idea as (Ennen et al., 2021; Sevegnani et al., 2021), our goal is to predict a transition utterance that can naturally bridge the past and the future utterances as below.\np(at | ut, ut+1) = ∏ k=0 p(at,k | ut, ut+1, at,1:k−1),\nwhere at is the current utterance, ut is the past utterance, ut+1 is the future utterance, and k the k-th token in at.\nSpecifically, we feed the last user’s open-domain utterance and the first user’s task-oriented utterance in our generated data as inputs, and learn to predict the template transition turn. To learn the capability of connecting different topics smoothly, the newly published data OTTers (Sevegnani et al., 2021) is leveraged for training our generative model. This data focuses on bridging two different topics via the transition in an entity path of a commonsense knowledge graph. The assumption of using this dataset is that open-domain utterances can be viewed as the previous topic and task-oriented utterances as the new one, so learning the transition turn is the same as learning how to smoothly transition from open-domain to task-oriented dialogues."
    }, {
      "heading" : "2.3 Task-Oriented Dialogue Generation",
      "text" : "After detecting the potential task-oriented intent and generating the transition turn, it is natural to\ncontinue the dialogue in a task-oriented scenario illustrated in the right part of Figure 2. Here we propose two ways of generating task-oriented dialogues following the transition turn.\nMerge SGD It is naive to simply merge an appropriate task-oriented dialogue taken from TOD data with a chit-chat dialogue to create such dialogue. In more details, all task-oriented dialogues in the SGD dataset are grouped by intents, and one TOD dialogue is sampled based on the detected task-oriented intent to append to the transition turn and form a new dialogue containing both chit-chat and TOD. Note that the delexicalized version of SGD (Sun et al., 2021) is used to avoid severe inconsistency between open-domain and task-oriented parts.\nTask-Oriented Simulation Different from opendomain social chatting, the roles in task-oriented dialogues are important. Therefore, two task-oriented simulators are trained, one for users and another for salespersons. Considering that training on task-oriented dialogues from scratch may limit the diversity of the generated dialogues, to generate the context-aware, fluent, and consistent conversations, we use the same type of open-domain dialogue generation models, BlenderBot (Roller et al., 2021), and additionally train on either user turns or agent turns in task-oriented dialogues for TOD User BlenderBot and TOD Sales BlenderBot. By allowing two simulators to talk with each other, they can generate endless conversations until one of the termination conditions is satisfied. There are three commonly used termination strategies we use when building our dataset: (1) Any pre-defined keyword appears in the utterance, e.g., bye. (2) The sales simulator generates a special token representing the ending of a dialogue. (3) When the dialogue starts to repeat itself, i.e., repeatedly producing the same utterances, because it usually means no more useful information.\nThe proposed framework enables us to construct a large-scale dataset with dialogues transitioning from open-domain to task-oriented scenarios, which align well with the salesperson’s business potential."
    }, {
      "heading" : "3 Data Quality Evaluation",
      "text" : "We use a widely-used crowdsourcing platform, Amazon Mechanical Turk (AMT)3, to collect hu-\n3https://www.mturk.com/\nman feedback for our generated dialogues."
    }, {
      "heading" : "3.1 Model Settings",
      "text" : "Intent Detector Our QA model is DistillBert (Sanh et al., 2020) pre-trained on the general QA data, SQuAD 2.0 (Rajpurkar et al., 2018), and then fine-tuned on TOD data, SGD. The value of learning rate and batch size are 3e-5 and 64 respectively with AdamW optimizer (Loshchilov and Hutter, 2019) for 20 epochs.\nTransition The T5 (T5-small) model is trained to generate transitions with a learning rate of 5e5 with Adafactor optimizer (Shazeer and Stern, 2018) and batch size of 16. We train our models for 5 epochs and select the model with lowest loss in the dev set. During decoding, we mix top-K sampling of 80 and top-p (nucleus) sampling of 0.95 (Holtzman et al., 2020).\nDialogue Generation To generate task-oriented utterances, we train our two simulators on the model BlenderBot-400M4 with the same training setting with generative transition. During generation, we use top-K sampling (Fan et al., 2018) of 120 for more diversity in our dialogues."
    }, {
      "heading" : "3.2 Crowdsourcing Tasks",
      "text" : "We randomly pick about 4,000 dialogues for two human evaluation tasks submit to AMT. The first task is designed for collecting feedback about the\n4https://parl.ai/projects/blenderbot2/\nentire dialogue, while the second one focuses on the transition part due to the main goal of this paper. Table 2 shows the dialogue example presented to crowdworkers for evaluation. Because our target dialogues can be viewed as salespersons’ capability, we describe the context to the recruited crowdworkers that the given dialogues are between a beginner salesperson and his/her customer and ask workers to provide feedback from different aspects in terms of the sales’ strategies. Note that the annotators are not aware that the dialogues are machine-generated, so the collected feedback is for human sales communication skills. Each task is briefly described below, and the full annotation guideline can be found in the Appendix A.\nTask 1: Salesperson-Customer Conversation The workers were presented with one entire dialogue and asked to rate (from 1 to 5) the entire conversation from three aspects: Relevance (Q1— How relevant is the recommended product or service to the conversation context?), Aggressiveness (Q2—How aggressive is the salesperson’s communication strategy?), and Overall (Q3—Do you think the sales conversation is overall a good example of making a sales recommendations?).\nTask 2: Chit-Chat to Task-Oriented Transition In addition to the entire dialogue, we also explicitly highlight the transition turn in the dialogue when presenting to crowdworkers. Similarly to the first task but only focusing on the transition part, we asked workers to rate from 1 to 5 from the following aspects: Right Time (Q1—Is it a good timing to make the transition?), Relevance (Q2—Is the transition relevant to the conversation context?), Aggressiveness (Q3—Is the transition aggressive?), and Overall (Q4—Do you think it is overall a good transition?). In each question, the detailed descriptions of all ratings are given to crowdworkers to ensure they have consistent understanding for all ratings. In addition, to enrich the transition turns and ensure their quality, we generate 4 additional transitions and ask workers to choose the best one. All transitions and ratings are included in our released data."
    }, {
      "heading" : "4 Results and Analysis",
      "text" : "Table 3 presents the statistics of the randomly sampled dialogues submitted to AMT. For brevity, we use T to denote Task in the following. Each dialogue is evaluated by three crowdworkers so that we can check the annotation variance for reliable\nresults. The evaluation results of all dialogues are visualized in the top charts of Figure 5, and the bottom charts show the results for existing TOD data (Merge) and simulator-generated TOD (Simulator).\nIt can be observed that our framework is able to produce context-relevant task-oriented conversations to match the topic of open-domain dialogues (Q1 in T1; Q2 in T2). This indicates that we can ensure the dialogue flow from open-domain to taskoriented dialogues is natural. The median relevance scores are slightly higher than the Neutral line, suggesting that our sales simulator can perform his sales strategy without annoying customers. The observation further demonstrates the feasibility and effectiveness of our proposed method. In terms of the salesperson’s aggressiveness, crowdworkers think that the transition is neutral and somewhat aggressive, showing that smoothly transitioning is still an important research problem to explore. Furthermore, the transition timing scores (Q1 in T2) also demonstrate that our proposed task-oriented intent detection can capture a suitable moment in a zero-shot setting, so that the sales may not miss any business opportunity of product promotion.\nWe can observe that most of overall scores (Q3 in T1; Q4 in T2) are above Neutral (Score 3)5, indicating that the generated dialogues and transitions are overall good for a salesperson’s business perspective. The human judgement demonstrates that our proposed approach is capable of simulating a large-scale reasonable dialogues aligned with our purpose, implying that both research community and industries can greatly benefit from our released data and the built simulators that can continuously generate more data for training. Our framework and the constructed dataset reduce the cost for largescale data requirement for better practice.\nTo further investigate whether the proposed TOD\n5The full description of each score is presented in Appendix A.\nsimulators described in Section 2.3 can generate reasonable dialogues compared to Merge SGD, we visualize their individual scores as shown at the bottom of Figure 5. There is no significant difference between two groups, and we further investigate their score distribution of each question shown in Figure 6. Both results tell that given the context of open-domain utterances, our TOD simulators are able to generate the suitable task-oriented dialogues with comparable quality to those from the publicly available benchmark TOD data–SGD. Consequently, our framework can be utilized to generate large-scale data cost-effectively and the generation quality is comparable with the current benchmark dialogue data.\nIn addition to the proposed framework and the released dataset, our collected human judgement also has the potential of providing valuable contributions to dialogue community or industrial products. For example, each question along with its corresponding scores from crowdworkers can be treated as a research problem which may interest re-\nsearchers, e.g. how human judges a dialogue is too aggressive. The release data along with the scores has a great potential for future research directions."
    }, {
      "heading" : "5 Related Work",
      "text" : "Our work is related to dataset construction for building persuasive dialogue systems that try to persuade\nthe participant to take a specific action. Hiraoka et al. (2014) annotated 34 dialogues, in which an experienced salesperson tries to convince a customer to buy a camera. Yoshino et al. (2018) requested crowdsourcing workers to generate 200 persuasive dialogues. In each dialogue, one participant persuaded another one to adopt his suggestion such as cleaning a room. Wang et al. (2019) collected 1017 dialogues, in which one of the participants was convinced to donate to a specific charity. We can see that the covered conversation scenarios in these datasets were strictly limited to specific tasks, while our scenarios are more general and can be easily extended to different cases. Also, our constructed dataset is about three times larger than the prior work, indicating the usefulness of the recent pre-trained paradigm.\nThe topic of conversational recommendation systems is also related to our work. A number of attempts have been made to collect training data for conversational recommendation systems. These studies (Wu et al., 2019; Zhou et al., 2020; Xu et al., 2020) first extracted a path consisting of an entity or attribute nodes from a knowledge base. Then they asked annotators to write conversational recommendation dialogues. The flow of mentioned topics in a dialogue should follow the extracted path. Similarly, Liu et al. (2020) also built a dataset by asking human workers to create dialogues based on a topic path. It should be noted that, in these datasets, the goal of such systems is to only make entity recommendations instead of tasks, while our work goes beyond them in naturally transferring from chit-chat to task-oriented dialogues and completing a task the user may want.\nAnother related work is generating a transition between two given open-domain utterances. Tang et al. (2019) proposed to generate the transition conditional on a specific word, because they want the generated transition can drive the conversation topic to the specified word. Sevegnani et al. (2021) collected a new dataset of human-created one-turn topic transitions. Each dialogue contains 2 utterances with different topics and 1 transition in the middle of them.\nThere are some recent studies trying to merge chit-chat and task-oriented dialogues, but the purposes of merged dialogues differ from ours. Sun et al. (2021) enhanced the utterances in taskoriented dialogues by appending chit-chat sen-\ntences. They hope that the agent gains more social, personalized, and engaging communication skills. Ennen et al. (2021) proposed a dialogue system that can transfer the style of generated response from chit-chat to task-oriented styles. However, the system is a prototype model, there is still a large gap to properly bridge chitchat and task-oriented dialogues. The motivation of our work is closely similar to that of the study by Yu et al. (2017). They manually created several task-oriented response generation strategies specifically designed for the movie promotion scenario. In addition, the expert knowledge was utilized to design reinforcement learning rewards that help their dialogue system to decide which action to take (i.e., continuing chitchat or selecting a task-oriented strategy to reply).\nHowever, we can observe that the prior work in these studies heavily relied on human efforts (data collection, expert-created strategies, etc.). Therefore, it can be expensive and hard to extend their data or method the practical cases due to the requirement of larger-scale training data. Our proposed framework benefits from the pre-trained models and shows its outstanding conversational capability. The flexibility of extending to diverse cases is also validated, considering that all components inside the framework can be easily substituted by the updated models, and the generated data can be used by semi-supervised or unsupervised methods for cold-start scenarios."
    }, {
      "heading" : "6 Conclusion",
      "text" : "This paper proposes a novel framework to generate dialogues that naturally transition from opendomain to task-oriented scenarios at a large scale without heavy human efforts. Our proposed chitchat to task-oriented transition approach can capture the suitable timing when the user shows the implicit intents and generate the diverse and natural transition turn to trigger the task-oriented utterances. Our human evaluation shows that the automatically generated dialogues have a reasonable quality with natural conversation flows from a business point of view. The released dataset and framework empowers research community to easily obtain large-scale target dialogues and the human annotated scores can be utilized for related work. This paper has a great potential of guiding future research directions and benefiting the community of both research and industry."
    }, {
      "heading" : "A Crowdsourcing Guideline",
      "text" : "A.1 Task1: Conversation between A Salesperson and A Customer\nIn order to improve the skills to sell more products, a beginner salesperson is learning dialogue strategies by reading prior conversations between customers and other salespeople. This beginner salesperson needs your help to determine if a salesperson used a good dialogue strategy to conduct an effective and strategic sales conversion.\nIn more detail, you will be presented with one conversation history between a salesperson and a customer. The salesperson may recommend a movie, a song, attractions and so on for the customer. Instead of recommending a product or service to the customer directly, the salesperson wants to make the recommendation more gradually and naturally by starting the conversation with chitchat.\nIn this task, you need to rate the conversation from the following 3 aspects:\n• How relevant is the recommended product or service to the conversation context? • How aggressive is the salesperson’s communication strategy? • Do you think the sales conversation is overall a good example of making sales recommendations?\nQuestions\n• How relevant is the recommended product or service to the conversation context?\n– 1: Not at all (it is impossible for me to find the relevance between the recommended item and the context) – 2: Less than neutral (it is a bit hard for me to find the relevance between the recommended item and the context) – 3: Neutral (With some effort, I can find a reasonable relevance between the recommended item and the context) – 4: Relevant (I can easily find that the recommend item has obvious relevance with the context, even though the recommended item is not perfectly matching the context) – 5: Very Relevant (the recommended item is perfectly matching the context)\n• How aggressive is the salesperson’s communication?\n– 1: Not aggressive at all (the conversation flows very naturally and smoothly from chit-chat to making recommendations; If I was the customer, I feel very comfortable when the salesperson is making recommendations) – 2: Less than neutral (The flow of the conversation is generally natural and smooth, although there are few imperfections) – 3: Neutral (The salesperson starts to recommend an item; It is ok to me) – 4: Aggressive (The salesperson suddenly starts to recommend an item; this makes me a bit uncomfortable) – 5: Very aggressive (The salesperson suddenly starts to recommend an item; this makes me very uncomfortable)\n• Is the sales conversation overall a good example to the beginner salesperson?\n– 1: Not at all (This example is really very bad; the beginner salesperson should not spend time on learning this example) – 2: Less than neutral (This example is not good; it would not be a pity if the beginner salesperson skips it) – 3: Neutral (This is not a bad example; the beginner salesperson may learn some useful dialogue skills from it, but not very much) – 4: Good (This is a good example of making recommendations; the imperfections\ncan be ignored; the beginner salesperson should keep this example in his mind) – 5: Very good (This is a perfect example of making recommendations; the beginner salesperson should keep it deeply in his mind)\nA.2 Task2: Transition between Chitchat and Task-Oriented\nIn order to improve the skills to sell more products, a beginner salesperson is learning dialogue strategies by reading prior conversations between customers and other salespeople. This beginner salesperson needs your help to determine if a salesperson used a good dialogue strategy to conduct an effective and strategic sales conversion.\nYou will be presented with a conversation between a salesperson and a customer. The salesperson may recommend a movie, a song, attractions and so on for the customer. Instead of recommending a product or service to the customer directly, the salesperson wants to make the recommendation more gradually and naturally by starting the conversation with chit-chat. Once the salesperson thinks it is the right time, he will say something (named transition in this task) to change the conversation from chit-chat to recommendation-making.\nIn this task, you will need to rate the transition from the following 4 aspects:\n• Is it the right time to make the transition?\n• Is the transition relevant to the conversation context?\n• Is the transition aggressive?\n• Is the transition overall good?\nQuestions\n• Is it the right time to make the transition?\n– 1: Very bad time (This is definitely not the right time to do it. It is highly likely that the customer will find you very annoying)\n– 2: Bad time (This is not a good time to make the transition. It may cause negative customer feelings)\n– 3: Neutral (I don’t think making the transition at the time is good, but it is ok to me to continue the conversation if I was the customer)\n– 4: Good time (it is a good time to make the transition, but maybe it will be perfect if the transition is made earlier or later)\n– 5: Very good time (it is a perfect time to make the transition)\n• Is the transition relevant to the conversation context?\n– 1: Not at all (it is impossible for me to find the relevance between the transition and the context)\n– 2: Less than neutral (it is a bit hard for me to find the relevance between the transition and the context)\n– 3: Neutral (With some effort, I can find a reasonable relevance between the transition and the context)\n– 4: Relevant (I can easily find that the transition has obvious relevance with the context, even though the transition is not perfectly matching the context)\n– 5: Very Relevant (the transition is perfectly matching the context; it is hard for me to find a better transition)\n• Is the transition aggressive?\n– 1: Not aggressive at all (the conversation flows very naturally and smoothly from chit-chat to making the transition; If I was the customer, I feel very comfortable when the salesperson is doing it)\n– 2: Less than neutral (The flow of the conversation is generally natural and smooth, although there are few imperfections)\n– 3: Neutral (The salesperson starts to make the transition; It is ok to me)\n– 4: Aggressive (The salesperson suddenly starts to make the transition; this makes me a bit uncomfortable)\n– 5: Very aggressive (The salesperson suddenly starts to make the transition; this makes me very uncomfortable)\n• Is the transition overall good?\n– 1: Not at all (This transition is really very bad; the beginner should not spend time on leaning this transition)\n– 2: Less than neutral (This transition is not good; It would not be a pity if the beginner salesperson skips this example)\n– 3: Neutral (This is not a bad transition; the beginner salesperson may learn some useful dialogue skills from it, but not very much)\n– 4: Good (This is a good example of making a transition; the imperfections can be ignored; the beginner salesperson should keep this example in his mind)\n– 5: Very good (This is a perfect example of making a transition; the beginner salesperson should keep it deeply in his mind)\n• Which transition of the following do you think is the best?\n– transition 1 – transition 2 – transition 3 – transition 4"
    }, {
      "heading" : "B Generated Dialogue Samples",
      "text" : "Task-oriented Simulators\nSales: Oh, I’m sorry to hear that. Do you have any other family members that you are close to? User: Yes, I have two brothers and two sisters. We are all very close. How about you? Sales: I don’t have any siblings, but I have a lot of cousins that I’m very close to. User: That’s great. I’m glad you have a good relationship with your cousins. What do you like to do for fun? Sales: I like to play video games and watch movies. What about you, what do you enjoy doing? User: I like playing video games as well. I also like to go to the movies. I love going to the theater. - FindMovies Sales: Sure, what kind of movies do you like to watch? Can you see [movie_name]? - [Transition] User: I would love to see Captain Marvel. I’d like to watch it at Century at Tanforan. Sales: I found [count] movie you might like. How about [movie_name]? User: Yeah, Hotel Mumbai sounds good. Sales: You want to play [title] without subtitles, is that right? User: Yes, that’s right. Sales: Okay, so you want me to play the movie you requested. I’ll start the movie now. User: Yes, please do. Sales: Can you please confirm that you want to play [title] without subtitles?\nMerge SGD\nUser: I like to drive around in my black car and listen to music. What do you like to do? Sales: I love going to the beach and swimming. What kind of music do you listen to? User: I listen to a lot of rap and hip hop. Do you have a favorite rapper? - LookupMusic Sales: I’m a top notch rapper and I’m a rock musician. Are you in the mood for the music. - [Transition] User: I’m in the mood for some music. Can you find songs from the album Camila. Sales: What about the song [song_name] from the album [album] by [artist]? User: I’m not in the mood for that one, do you have a different song? Sales: What about the song [song_name] from the album [album] by [artist]? User: What is the genre of the song? Sales: Real Friends is a [genre] song. User: Sounds good. Sales: Do you want to hear the song now? User: Yes, I would love to. Sales: You want to play [song_name] on your [playback_device]? User: No, I would prefer to play it on my kitchen speaker. Sales: You want to play [song_name] on your [playback_device]? User: Yes, that’s right. Sales: The song is now playing. User: Thank you very much. Sales: Is there anything else I can help you with? User: No, that is all. Thank you for your time. Sales: Enjoy your music. Have a wonderful day."
    } ],
    "references" : [ {
      "title" : "Towards a human-like opendomain chatbot",
      "author" : [ "Daniel Adiwardana", "Minh-Thang Luong", "David R. So", "Jamie Hall", "Noah Fiedel", "Romal Thoppilan", "Zi Yang", "Apoorv Kulshreshtha", "Gaurav Nemade", "Yifeng Lu", "Quoc V. Le" ],
      "venue" : null,
      "citeRegEx" : "Adiwardana et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Adiwardana et al\\.",
      "year" : 2020
    }, {
      "title" : "Towards a human-like open-domain chatbot",
      "author" : [ "Daniel Adiwardana", "Minh-Thang Luong", "David R So", "Jamie Hall", "Noah Fiedel", "Romal Thoppilan", "Zi Yang", "Apoorv Kulshreshtha", "Gaurav Nemade", "Yifeng Lu" ],
      "venue" : "arXiv preprint arXiv:2001.09977",
      "citeRegEx" : "Adiwardana et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Adiwardana et al\\.",
      "year" : 2020
    }, {
      "title" : "MultiWOZ - a large-scale multi-domain Wizard-of-Oz dataset for task-oriented dialogue modelling",
      "author" : [ "Paweł Budzianowski", "Tsung-Hsien Wen", "Bo-Hsiang Tseng", "Iñigo Casanueva", "Stefan Ultes", "Osman Ramadan", "Milica Gašić." ],
      "venue" : "Proceedings of",
      "citeRegEx" : "Budzianowski et al\\.,? 2018",
      "shortCiteRegEx" : "Budzianowski et al\\.",
      "year" : 2018
    }, {
      "title" : "Towards a universal nlg for dialogue systems and simulators with future bridging",
      "author" : [ "Philipp Ennen", "Yen-Ting Lin", "Ali Girayhan Ozbay", "Ferdinando Insalata", "Maolin Li", "Ye Tian", "Sepehr Jalali", "Da shan Shiu" ],
      "venue" : null,
      "citeRegEx" : "Ennen et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Ennen et al\\.",
      "year" : 2021
    }, {
      "title" : "Hierarchical neural story generation",
      "author" : [ "Angela Fan", "Mike Lewis", "Yann Dauphin." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 889–898, Melbourne, Australia. Association",
      "citeRegEx" : "Fan et al\\.,? 2018",
      "shortCiteRegEx" : "Fan et al\\.",
      "year" : 2018
    }, {
      "title" : "Reinforcement learning of cooperative persuasive dialogue policies using framing",
      "author" : [ "Takuya Hiraoka", "Graham Neubig", "Sakriani Sakti", "Tomoki Toda", "Satoshi Nakamura." ],
      "venue" : "Proceedings of COLING 2014, the 25th International Conference",
      "citeRegEx" : "Hiraoka et al\\.,? 2014",
      "shortCiteRegEx" : "Hiraoka et al\\.",
      "year" : 2014
    }, {
      "title" : "The curious case of neural text degeneration",
      "author" : [ "Ari Holtzman", "Jan Buys", "Li Du", "Maxwell Forbes", "Yejin Choi" ],
      "venue" : null,
      "citeRegEx" : "Holtzman et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Holtzman et al\\.",
      "year" : 2020
    }, {
      "title" : "A simple language model for task-oriented dialogue",
      "author" : [ "Ehsan Hosseini-Asl", "Bryan McCann", "Chien-Sheng Wu", "Semih Yavuz", "Richard Socher." ],
      "venue" : "Advances in Neural Information Processing Systems, volume 33, pages 20179–20191. Curran Associates,",
      "citeRegEx" : "Hosseini.Asl et al\\.,? 2020",
      "shortCiteRegEx" : "Hosseini.Asl et al\\.",
      "year" : 2020
    }, {
      "title" : "DailyDialog: A manually labelled multi-turn dialogue dataset",
      "author" : [ "Yanran Li", "Hui Su", "Xiaoyu Shen", "Wenjie Li", "Ziqiang Cao", "Shuzi Niu." ],
      "venue" : "Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Pa-",
      "citeRegEx" : "Li et al\\.,? 2017",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2017
    }, {
      "title" : "Towards conversational recommendation over multi-type dialogs",
      "author" : [ "Wanxiang Che", "Ting Liu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1036–1049, Online. Association for Computational",
      "citeRegEx" : "Che and Liu.,? 2020",
      "shortCiteRegEx" : "Che and Liu.",
      "year" : 2020
    }, {
      "title" : "Decoupled weight decay regularization",
      "author" : [ "Ilya Loshchilov", "Frank Hutter." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Loshchilov and Hutter.,? 2019",
      "shortCiteRegEx" : "Loshchilov and Hutter.",
      "year" : 2019
    }, {
      "title" : "Parlai: A dialog research software platform",
      "author" : [ "A.H. Miller", "W. Feng", "A. Fisch", "J. Lu", "D. Batra", "A. Bordes", "D. Parikh", "J. Weston." ],
      "venue" : "arXiv preprint arXiv:1705.06476.",
      "citeRegEx" : "Miller et al\\.,? 2017",
      "shortCiteRegEx" : "Miller et al\\.",
      "year" : 2017
    }, {
      "title" : "Language model is all you need: Natural language understanding as question answering",
      "author" : [ "Mahdi Namazifar", "Alexandros Papangelis", "Gokhan Tur", "Dilek Hakkani-Tür" ],
      "venue" : null,
      "citeRegEx" : "Namazifar et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Namazifar et al\\.",
      "year" : 2020
    }, {
      "title" : "Know what you don’t know: Unanswerable questions for SQuAD",
      "author" : [ "Pranav Rajpurkar", "Robin Jia", "Percy Liang." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 784–",
      "citeRegEx" : "Rajpurkar et al\\.,? 2018",
      "shortCiteRegEx" : "Rajpurkar et al\\.",
      "year" : 2018
    }, {
      "title" : "Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset",
      "author" : [ "Abhinav Rastogi", "Xiaoxue Zang", "Srinivas Sunkara", "Raghav Gupta", "Pranav Khaitan" ],
      "venue" : null,
      "citeRegEx" : "Rastogi et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Rastogi et al\\.",
      "year" : 2020
    }, {
      "title" : "Recipes for building an open-domain chatbot",
      "author" : [ "Stephen Roller", "Emily Dinan", "Naman Goyal", "Da Ju", "Mary Williamson", "Yinhan Liu", "Jing Xu", "Myle Ott", "Eric Michael Smith", "Y-Lan Boureau" ],
      "venue" : "In Proceedings of the 16th Conference of the European",
      "citeRegEx" : "Roller et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Roller et al\\.",
      "year" : 2021
    }, {
      "title" : "Distilbert, a distilled version of bert: smaller, faster, cheaper and lighter",
      "author" : [ "Victor Sanh", "Lysandre Debut", "Julien Chaumond", "Thomas Wolf" ],
      "venue" : null,
      "citeRegEx" : "Sanh et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Sanh et al\\.",
      "year" : 2020
    }, {
      "title" : "OTTers: One-turn topic transitions for open-domain dialogue",
      "author" : [ "Karin Sevegnani", "David M. Howcroft", "Ioannis Konstas", "Verena Rieser." ],
      "venue" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th Interna-",
      "citeRegEx" : "Sevegnani et al\\.,? 2021",
      "shortCiteRegEx" : "Sevegnani et al\\.",
      "year" : 2021
    }, {
      "title" : "Adafactor: Adaptive learning rates with sublinear memory cost",
      "author" : [ "Noam Shazeer", "Mitchell Stern." ],
      "venue" : "CoRR, abs/1804.04235.",
      "citeRegEx" : "Shazeer and Stern.,? 2018",
      "shortCiteRegEx" : "Shazeer and Stern.",
      "year" : 2018
    }, {
      "title" : "Can you put it all together: Evaluating conversational agents’ ability to blend skills",
      "author" : [ "Eric Michael Smith", "Mary Williamson", "Kurt Shuster", "Jason Weston", "Y-Lan Boureau." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Smith et al\\.,? 2020",
      "shortCiteRegEx" : "Smith et al\\.",
      "year" : 2020
    }, {
      "title" : "Adding chit-chat to enhance task-oriented dialogues",
      "author" : [ "Kai Sun", "Seungwhan Moon", "Paul Crook", "Stephen Roller", "Becka Silvert", "Bing Liu", "Zhiguang Wang", "Honglei Liu", "Eunjoon Cho", "Claire Cardie." ],
      "venue" : "Proceedings of the 2021 Conference of the North",
      "citeRegEx" : "Sun et al\\.,? 2021",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2021
    }, {
      "title" : "Commonsenseqa: A question answering challenge targeting commonsense knowledge",
      "author" : [ "Alon Talmor", "Jonathan Herzig", "Nicholas Lourie", "Jonathan Berant." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Talmor et al\\.,? 2019",
      "shortCiteRegEx" : "Talmor et al\\.",
      "year" : 2019
    }, {
      "title" : "Targetguided open-domain conversation",
      "author" : [ "Jianheng Tang", "Tiancheng Zhao", "Chenyan Xiong", "Xiaodan Liang", "Eric Xing", "Zhiting Hu." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5624–5634, Flo-",
      "citeRegEx" : "Tang et al\\.,? 2019",
      "shortCiteRegEx" : "Tang et al\\.",
      "year" : 2019
    }, {
      "title" : "Persuasion for good: Towards a personalized persuasive dialogue system for social good",
      "author" : [ "Xuewei Wang", "Weiyan Shi", "Richard Kim", "Yoojung Oh", "Sijia Yang", "Jingwen Zhang", "Zhou Yu." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Com-",
      "citeRegEx" : "Wang et al\\.,? 2019",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "Bilateral multi-perspective matching for natural language sentences",
      "author" : [ "Zhiguo Wang", "Wael Hamza", "Radu Florian" ],
      "venue" : null,
      "citeRegEx" : "Wang et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2017
    }, {
      "title" : "Proactive human-machine conversation with explicit conversation goal",
      "author" : [ "Wenquan Wu", "Zhen Guo", "Xiangyang Zhou", "Hua Wu", "Xiyuan Zhang", "Rongzhong Lian", "Haifeng Wang." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Com-",
      "citeRegEx" : "Wu et al\\.,? 2019",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2019
    }, {
      "title" : "Knowledge graph grounded goal planning for open-domain conversation generation",
      "author" : [ "Jun Xu", "Haifeng Wang", "Zhengyu Niu", "Hua Wu", "Wanxiang Che." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 9338–9345.",
      "citeRegEx" : "Xu et al\\.,? 2020",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2020
    }, {
      "title" : "Dialogue scenario collection of persuasive dialogue with emotional expressions via crowdsourcing",
      "author" : [ "Koichiro Yoshino", "Yoko Ishikawa", "Masahiro Mizukami", "Yu Suzuki", "Sakriani Sakti", "Satoshi Nakamura." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Yoshino et al\\.,? 2018",
      "shortCiteRegEx" : "Yoshino et al\\.",
      "year" : 2018
    }, {
      "title" : "Learning conversational systems that interleave task and non-task content",
      "author" : [ "Zhou Yu", "Alan W Black", "Alexander I. Rudnicky" ],
      "venue" : null,
      "citeRegEx" : "Yu et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2017
    }, {
      "title" : "Personalizing dialogue agents: I have a dog, do you have pets too",
      "author" : [ "Saizheng Zhang", "Emily Dinan", "Jack Urbanek", "Arthur Szlam", "Douwe Kiela", "Jason Weston" ],
      "venue" : null,
      "citeRegEx" : "Zhang et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "Dialogpt: Largescale generative pre-training for conversational response generation",
      "author" : [ "Yizhe Zhang", "Siqi Sun", "Michel Galley", "Yen-Chun Chen", "Chris Brockett", "Xiang Gao", "Jianfeng Gao", "Jingjing Liu", "William B Dolan." ],
      "venue" : "Proceedings of the 58th An-",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Towards topicguided conversational recommender system",
      "author" : [ "Kun Zhou", "Yuanhang Zhou", "Wayne Xin Zhao", "Xiaoke Wang", "Ji-Rong Wen." ],
      "venue" : "Proceedings of the 28th International Conference on Computational Linguistics, pages 4128–4139.",
      "citeRegEx" : "Zhou et al\\.,? 2020",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 8,
      "context" : "For example, a lot of prior work focused on building open-domain dialogue systems (Li et al., 2017; Zhang et al., 2018; Adiwardana et al., 2020a), which chat with users via suitable, engaging, safe conversations.",
      "startOffset" : 82,
      "endOffset" : 145
    }, {
      "referenceID" : 29,
      "context" : "For example, a lot of prior work focused on building open-domain dialogue systems (Li et al., 2017; Zhang et al., 2018; Adiwardana et al., 2020a), which chat with users via suitable, engaging, safe conversations.",
      "startOffset" : 82,
      "endOffset" : 145
    }, {
      "referenceID" : 30,
      "context" : "With the capability of pre-trained models, a large set of human conversations is adopted to train their capability of free chatting (Zhang et al., 2020; Adiwardana et al., 2020b; Roller et al., 2021).",
      "startOffset" : 132,
      "endOffset" : 199
    }, {
      "referenceID" : 15,
      "context" : "With the capability of pre-trained models, a large set of human conversations is adopted to train their capability of free chatting (Zhang et al., 2020; Adiwardana et al., 2020b; Roller et al., 2021).",
      "startOffset" : 132,
      "endOffset" : 199
    }, {
      "referenceID" : 2,
      "context" : "On the other hand, MultiWoz (Budzianowski et al., 2018; Hosseini-Asl et al., 2020) and Schema-Guided Dialogue (SGD) (Rastogi et al.",
      "startOffset" : 28,
      "endOffset" : 82
    }, {
      "referenceID" : 7,
      "context" : "On the other hand, MultiWoz (Budzianowski et al., 2018; Hosseini-Asl et al., 2020) and Schema-Guided Dialogue (SGD) (Rastogi et al.",
      "startOffset" : 28,
      "endOffset" : 82
    }, {
      "referenceID" : 14,
      "context" : ", 2020) and Schema-Guided Dialogue (SGD) (Rastogi et al., 2020) are two popular large-scale datasets of task-oriented dialogues, which include plenty of multi-domain dialogues with state information to track users’ behaviors.",
      "startOffset" : 41,
      "endOffset" : 63
    }, {
      "referenceID" : 20,
      "context" : "Considering that both skills are essential for a human-like dialogue system, the recent work (Sun et al., 2021) merged those two capabilities by inserting chit-chat sentences into the existing taskoriented dialogue data.",
      "startOffset" : 93,
      "endOffset" : 111
    }, {
      "referenceID" : 7,
      "context" : "Even though high-quality chit-chats and task-oriented dialogues can be separately generated shown in prior work (Hosseini-Asl et al., 2020; Adiwardana et al., 2020b; Roller et al., 2021), how to generate our desired dialogues has not been fully studied and remained unresolved.",
      "startOffset" : 112,
      "endOffset" : 186
    }, {
      "referenceID" : 15,
      "context" : "Even though high-quality chit-chats and task-oriented dialogues can be separately generated shown in prior work (Hosseini-Asl et al., 2020; Adiwardana et al., 2020b; Roller et al., 2021), how to generate our desired dialogues has not been fully studied and remained unresolved.",
      "startOffset" : 112,
      "endOffset" : 186
    }, {
      "referenceID" : 15,
      "context" : "Here we choose BlenderBot (Roller et al., 2021) as our pre-trained generation model due to its outstanding capability trained on the largestever open-domain data.",
      "startOffset" : 26,
      "endOffset" : 47
    }, {
      "referenceID" : 19,
      "context" : "It shows the ability to be engaging, knowledgeable, and empathetic at a certain level by multi-tasking on the Blended Skill Talk (BST) dataset (Smith et al., 2020) with several different datasets blending.",
      "startOffset" : 143,
      "endOffset" : 163
    }, {
      "referenceID" : 11,
      "context" : "This can be easily implemented by the package ParlAI2 (Miller et al., 2017), which allows us to build two BlenderBots to self-chat with each other in order to construct various dialogues involving different personas in the BST.",
      "startOffset" : 54,
      "endOffset" : 75
    }, {
      "referenceID" : 12,
      "context" : "Therefore, this paper proposes to leverage the powerful capability of question answering (QA) systems to identify the potential task-oriented intents in a zero-shot fashion (Namazifar et al., 2020).",
      "startOffset" : 173,
      "endOffset" : 197
    }, {
      "referenceID" : 24,
      "context" : "Paraphrased questions: to enhance the detection recall for open-domain dialogues, for each intent, we paraphrase the descriptionbased questions via a high-quality paraphrasing T5 model pre-trained on Quora Question Pairs data for its paraphrasing capability (Wang et al., 2017).",
      "startOffset" : 258,
      "endOffset" : 277
    }, {
      "referenceID" : 13,
      "context" : ", SQuAD (Rajpurkar et al., 2018) or CommonsenseQA (Talmor et al.",
      "startOffset" : 8,
      "endOffset" : 32
    }, {
      "referenceID" : 21,
      "context" : ", 2018) or CommonsenseQA (Talmor et al., 2019), which is supposed to be equipped with certain common knowledge and the reasoning ability useful for our intent detector.",
      "startOffset" : 25,
      "endOffset" : 46
    }, {
      "referenceID" : 3,
      "context" : "With a similar idea as (Ennen et al., 2021; Sevegnani et al., 2021), our goal is to predict a transition utterance that can naturally bridge the past and the future utterances as below.",
      "startOffset" : 23,
      "endOffset" : 67
    }, {
      "referenceID" : 17,
      "context" : "With a similar idea as (Ennen et al., 2021; Sevegnani et al., 2021), our goal is to predict a transition utterance that can naturally bridge the past and the future utterances as below.",
      "startOffset" : 23,
      "endOffset" : 67
    }, {
      "referenceID" : 17,
      "context" : "To learn the capability of connecting different topics smoothly, the newly published data OTTers (Sevegnani et al., 2021) is leveraged for training our generative model.",
      "startOffset" : 97,
      "endOffset" : 121
    }, {
      "referenceID" : 20,
      "context" : "Note that the delexicalized version of SGD (Sun et al., 2021) is used to avoid severe inconsistency between open-domain and task-oriented parts.",
      "startOffset" : 43,
      "endOffset" : 61
    }, {
      "referenceID" : 15,
      "context" : "Considering that training on task-oriented dialogues from scratch may limit the diversity of the generated dialogues, to generate the context-aware, fluent, and consistent conversations, we use the same type of open-domain dialogue generation models, BlenderBot (Roller et al., 2021), and additionally train on either user turns or agent turns in task-oriented dialogues for TOD User BlenderBot and TOD Sales BlenderBot.",
      "startOffset" : 262,
      "endOffset" : 283
    }, {
      "referenceID" : 16,
      "context" : "Intent Detector Our QA model is DistillBert (Sanh et al., 2020) pre-trained on the general QA data, SQuAD 2.",
      "startOffset" : 44,
      "endOffset" : 63
    }, {
      "referenceID" : 13,
      "context" : "0 (Rajpurkar et al., 2018), and then fine-tuned on TOD data, SGD.",
      "startOffset" : 2,
      "endOffset" : 26
    }, {
      "referenceID" : 10,
      "context" : "The value of learning rate and batch size are 3e-5 and 64 respectively with AdamW optimizer (Loshchilov and Hutter, 2019) for 20 epochs.",
      "startOffset" : 92,
      "endOffset" : 121
    }, {
      "referenceID" : 18,
      "context" : "Transition The T5 (T5-small) model is trained to generate transitions with a learning rate of 5e5 with Adafactor optimizer (Shazeer and Stern, 2018) and batch size of 16.",
      "startOffset" : 123,
      "endOffset" : 148
    }, {
      "referenceID" : 4,
      "context" : "During generation, we use top-K sampling (Fan et al., 2018) of 120 for more diversity in our dialogues.",
      "startOffset" : 41,
      "endOffset" : 59
    }, {
      "referenceID" : 25,
      "context" : "These studies (Wu et al., 2019; Zhou et al., 2020; Xu et al., 2020) first extracted a path consisting of an entity or attribute nodes from a knowledge base.",
      "startOffset" : 14,
      "endOffset" : 67
    }, {
      "referenceID" : 31,
      "context" : "These studies (Wu et al., 2019; Zhou et al., 2020; Xu et al., 2020) first extracted a path consisting of an entity or attribute nodes from a knowledge base.",
      "startOffset" : 14,
      "endOffset" : 67
    }, {
      "referenceID" : 26,
      "context" : "These studies (Wu et al., 2019; Zhou et al., 2020; Xu et al., 2020) first extracted a path consisting of an entity or attribute nodes from a knowledge base.",
      "startOffset" : 14,
      "endOffset" : 67
    } ],
    "year" : 0,
    "abstractText" : "Dialogue systems are usually categorized into two types, open-domain and task-oriented. The first one focuses on chatting with users and making them engage in the conversations, where selecting a proper topic to fit the dialogue context is essential for a successful dialogue. The other one focuses on a specific task instead of casual talks, e.g., finding a movie on Friday night, playing a song. These two directions have been studied separately due to their different purposes. However, how to smoothly transition from social chatting to task-oriented dialogues is important for triggering the business opportunities, and there is no any public data focusing on such scenarios. Hence, this paper focuses on investigating the conversations starting from open-domain social chatting and then gradually transitioning to taskoriented purposes, and releases a large-scale dataset with detailed annotations for encouraging this research direction. To achieve this goal, this paper proposes a framework to automatically generate many dialogues without human involvement, in which any powerful opendomain dialogue generation model can be easily leveraged. The human evaluation shows that our generated dialogue data has a natural flow at a reasonable quality, showing that our released data has a great potential of guiding future research directions and commercial activities. Furthermore, the released models allow researchers to automatically generate unlimited dialogues in the target scenarios, which can greatly benefit semi-supervised and unsupervised approaches.1",
    "creator" : null
  }
}