{
  "name" : "ARR_2022_6_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Square One Bias in NLP: Towards a Multi-Dimensional Exploration of the Research Manifold",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Our categorization of objects, say screwdrivers or NLP experiments, is heavily biased by early prototypes (Sherman, 1985; Das-Smaal, 1990). If the first 10 screwdrivers we see, are red and for hexagon socket screws, this will bias what features we learn to associate with screwdrivers. Likewise, if the first 10 NLP experiments we see or conduct are in sentiment analysis, this will likely also bias how we think of NLP experiments in the future.\nIn this position paper, we postulate that we can meaningfully talk about the prototypical NLP experiment, and that the existence of such an experimental prototype steers and biases the research\ndynamics in our community. We will refer to this prototype as NLP’s SQUARE ONE—and to the bias that follows from it, as the SQUARE ONE BIAS. We argue this bias manifests in a particular way: Since research is a creative endeavor, and researchers aim to push the research horizon, most research papers in NLP go beyond this prototype, but only along a single dimension at a time. Such dimensions include multilinguality, efficiency, fairness, and interpretability, among others. The effect of the SQUARE ONE BIAS is to baseline novel research contributions, rewarding work that differs from the prototype in a concise, one-dimensional way.\nWe present several examples of this effect in practice. For instance, analyzing the contributions of ACL 2021 papers along 4 dimensions, we observe that most work is either clustered around the SQUARE ONE or makes a contribution along a single dimension (see Figure 1). Multilingual work typically disregards efficiency, fairness, and interpretability. Work on efficient NLP typically only performs evaluations on English datasets, and\ndisregards fairness and interpretability. Fairness and interpretability work is also mostly limited to English, and tends to disregard efficiency concerns.\nWe argue that the SQUARE ONE BIAS has several negative effects, most of which amount to the study of one of the above dimensions being biased by ignoring the others. Specifically, by focusing only on exploring the edges of the manifold, we are not able to identify the non-linear interactions between different research dimensions. We highlight several examples of such interactions in Section 3. Overall, we encourage a focus on combining multiple dimensions on the research manifold in future NLP research, and delve deeper into studying their (linear and non-linear) interactions.\nContributions. We first establish that we can meaningfully talk about the prototypical NLP experiment, through a series of surveys and annotation experiments. This prototype amounts to applying a standard architecture to an English dataset and optimizing for accuracy or F1. We discuss the impact of this prototype on our research community, and the bias it introduces. We then discuss the negative effects of this bias. We also list work that has taken steps to overcome the bias. Finally, we highlight blind spots and unexplored research directions and make practical recommendations, aiming to inspire the community towards conducting more ‘multi-dimensional’ research (see Figure 1)."
    }, {
      "heading" : "2 Finding the Square One",
      "text" : "In order to determine the existence and nature of a SQUARE ONE, we seek to identify commonalities between students’ first exposure to NLP. In most cases, we expect such exposure to occur during an introductory NLP course.\nQuestionnaire for NLP Teachers. We therefore created a short questionnaire, which we sent to a geographically diverse set of teachers, including first authors from the last Teaching NLP workshop (Jurgens et al., 2021), asking about the first experiment that they presented in their NLP 101 course. We received 71 responses in total. Our first question was: The last time you taught an introductory NLP course, what was the first task you introduced the students to, or that they had to implement a model for? The relative majority of respondents (31.9%) said sentiment analysis, while 10.1% indicated topic classification.1 More importantly, we\n1The remaining responses included NER, language model-\nalso asked them about the language of the data used in the experiment, and what metric they optimized for. More than three quarters of respondents reported that they used English language training and evaluation data and more than three quarters of the respondents asked the students to optimize for accuracy or F1. The choice of using English language datasets is particularly interesting in contrast to the native languages of the teachers and their students: In around two thirds of the classes, most students shared an L1 language that was not English; and less than a quarter of the teachers were L1 English speakers themselves. In summary, the prototypical NLP 101 experiment, according to our survey, is on an English classification task with accuracy or F1 as performance metric. None of the respondents reported to have optimized for fairness, interpretability or efficiency metrics.\nClassification of NLP Textbooks. What, then, are the prototypical NLP experiments in undergraduate and graduate textbooks? We list five exemplary NLP textbooks, spanning 20 years, in Table 1. We observe that they, like the teachers in our survey, take the same point of departure: an Englishlanguage experiment in which we use supervised learning techniques to optimize for a standard performance metric, e.g., perplexity or error. We note an important difference, however: While the first four books largely ignore issues relating to fairness, interpretability, and efficiency, the most recent NLP textbook in Table 1 (Eisenstein, 2019) discusses efficiency (briefly) and fairness (more thoroughly).\nACL 2021 Oral Papers. We now seek to quantify whether the same bias exists in contemporary research. To this end, we annotate the 461 papers that were presented orally at ACL 2021, a representative cross-section of the 779 papers accepted to the main conference. We focus on 4 dimensions along which papers may differ from a prototypical\ning, language identification, hate speech detection, etc.\nNLP experiment: multilinguality, fairness and bias, efficiency, and interpretability.2 Compared to prior work that annotates the values of ML research papers (Birhane et al., 2021), we are not concerned with a paper’s motivation but whether its practical contributions constitute a meaningful departure from SQUARE ONE. For each paper, we annotate whether it makes a contribution along each dimension3 as well as the languages and metrics it employs for evaluation.\nThe general statistics from our classification of ACL 2021 papers are presented in Table 2. In addition, we highlight the statistics for the conference areas (tracks) corresponding to 3 of the 4 dimensions,4 as well as for the top 5 areas with the most papers. We show statistics for the remaining areas in Appendix A.1. We additionally visualize their distribution in Figure 1. Overall, almost 70% of papers evaluate only on English, clearly highlighting a lack of language diversity in NLP (Bender, 2011; Joshi et al., 2020). Almost 40% of papers only evaluate using accuracy and/or F1, foregoing metrics that may shed light on other aspects of model behavior. Regarding work that moves from the SQUARE ONE, most papers make a contribution in terms of efficiency, followed by multilinguality. However, most papers that evaluate on multiple\n2Other dimensions that could be considered in future work are robustness, multimodality, and privacy, among others.\n3For multilinguality, we consider papers that evaluate on 3 languages, or 4 languages if they focus on MT (as the standard MT experiment includes two languages). For fairness and bias, we consider papers that improve fairness in a specific setting or analyze the bias of a method, e.g. regarding gender. For efficiency, we consider papers that analyze memory, speed, or computational complexity. For interpretability, we consider papers that interpret or explain a model’s predictions.\n4Unlike EACL 2021, NAACL-HLT 2021 and EMNLP 2021, ACL 2021 had no area associated with efficiency. To compensate for this, we annotated the 20 oral papers of the “Efficient Models in NLP” track at EMNLP 2021 (see Appendix A.2).\nlanguages are part of the corresponding MT and Multilinguality track. Despite being an area receiving increasing attention (Blodgett et al., 2020), only 6.3% of papers evaluate the bias or fairness of a method. Overall, only 6.1% of papers make a contribution along two or more of these dimensions. Among these, joint contributions on both multilinguality and efficiency are the most common (see Figure 1). In fact, 22 of the 26 two-or-moredimensional papers focus on efficiency, and 17 of these on the combination of multilinguality and efficiency. This means less than 1% of the ACL 2021 papers consider combinations of (two or more of) multilinguality, fairness and interpretability. We find this surprising, given these topics are considered among the most popular topics in the field.\nSome areas have particularly concerning statistics. A large majority of research work in dialog (90.5%), summarization (91.7%), sentiment analysis (100%), and language grounding (100%) is done only on English; however, ways of expressing sentiment (Volkova et al., 2013; Yang and Eisenstein, 2017; Vilares et al., 2018) and visually grounded reasoning (Liu et al., 2021; Yin et al., 2021) do vary across languages and cultures. Systems in the top tracks tend to evaluate on efficiency, but in general do not consider fairness or interpretability of the proposed methods. Even the creation of new resources and evaluation sets (cf., Resource and Evaluation in Table 2) seems to be directed towards rewarding and enabling SQUARE ONE experiments; favoring English (77.1%), and with modest efforts on other dimensions. Notably, we only identified a single paper that considers three dimensions (Renduchintala et al., 2021). This paper considers gender bias (Fairness) in relation to speed-quality (Efficiency) trade-offs in multilingual machine translation (Multilinguality). Finally, we observe that best-paper award winning papers\nare not more likely to consider more than one of the four dimensions. Only 1 in 8 papers did; the best paper (Xu et al., 2021), like most two-dimensional ACL 2021 papers, considered multilinguality and efficiency.\nTest-of-Time Award Recipients. Current papers provide us with a snapshot of actual current research practices, but the one-dimensionality of the best paper award winning papers at ACL 2021 suggest the SQUARE ONE BIAS also biases what we value in research, i.e., our perception of ideal research practices. This can also be seen in the papers that have received the ACL Test-of-Time Award in the last two years (Table 3). Seven in eight papers included empirical evaluations performed exclusively on English data. Six papers were exclusively concerned with optimizing for accuracy or F1.\nBlackbox NLP Papers. Finally, we check if more multi-dimensional papers were presented at a workshop devoted to one of the above dimensions. The rationale would be that if everyone at a workshop already explores one of these dimensions, maybe including another is a way to have an edge over other submissions. Unfortunately, this does not seem to be the case. We manually annotated the first 10 papers in the Blackbox NLP 2021 program5 that were available as pre-prints at the time of submission.6 Of the 10 papers, only one included more than one dimension (Abdullah et al., 2021). This number aligns well with the overall statistics of ACL 2021 (6.1%). All the other Blackbox NLP papers only considered interpretability for English."
    }, {
      "heading" : "3 Square One Bias: Examples",
      "text" : "In the following, we highlight both historical and recent examples touching on different aspects of research in NLP that illustrate how the gravitational\n5https://blackboxnlp.github.io/ 6These annotations are made publicly available along with\nthe rest of the data collected for this paper at url.\nattraction of the SQUARE ONE has led researchers to draw false conclusions, unconsciously steer standard research practices, or make unwise choices.\nArchitectural Biases. One pervasive bias in our models regards morphology. Many of our models were not designed with morphology in mind, arguably because of the poor morphology of English. Traditional n-gram language models, for example, have been shown to perform much worse on languages with elaborate morphology due to data sparsity problems (Khudanpur, 2006; Bender, 2011; Gerz et al., 2018). Such models were nevertheless more commonly used than more linguistically informed alternatives such as factored language models (Bilmes and Kirchhoff, 2003) that represent words as sets of features. Word embeddings have been widely used, in part because pre-trained embeddings covered a large part of the English vocabulary. However, word embeddings are not useful for tasks that require access to morphemes, e.g., semantic tasks in morphologically rich languages (Avraham and Goldberg, 2017).\nWhile studies have demonstrated the ability of word embeddings to capture linguistic information in English, it remains unclear whether they capture the information needed for processing morphologically rich languages (Tsarfaty et al., 2020). A bias towards morphologically rich languages is also apparent in our tokenization algorithms. Subword tokenization performs poorly on languages with reduplication (Vania and Lopez, 2017), while byte pair encoding does not align well with morphology (Bostrom and Durrett, 2020). Consequently, languages with productive morphological systems also are disadvantaged when shared ‘languageuniversal’ tokenizers are used in current large-scale multilingual language models (Ács, 2019; Rust et al., 2021) without any further vocabulary adaptation (Wang et al., 2020; Pfeiffer et al., 2021).\nAnother bias in our models relates to word order. In order for n-gram models to capture interword dependencies, words need to appear in the n-gram window. This will occur more frequently in languages with relatively fixed word order compared to languages with relatively free word order (Bender, 2011). Word embedding approaches such as skip-gram (Mikolov et al., 2013) adhere to the same window-based approach and thus have similar weaknesses for languages with relatively free word order. LSTMs are also sensitive to word order and perform worse on agreement prediction in\nBasque, which is both morphologically richer and has a relatively free word order (Ravfogel et al., 2018) compared to English (Linzen et al., 2016). They have also been shown to transfer worse to distant languages for dependency parsing compared to self-attention models (Ahmad et al., 2019). Such biases concerning word order are not only inherent in our models but also in our algorithms. A recent unsupervised parsing algorithm (Shen et al., 2018) has been shown to be biased towards rightbranching structures and consequently performs better in right-branching languages like English (Dyer et al., 2019). While the recent generation of self-attention based architectures can be seen as inherently order-agnostic, recent methods focusing on making attention more efficient (Tay et al., 2020) introduce new biases into the models. Specifically, models that reduce the global attention to a local sliding window around the token (Liu et al., 2018; Child et al., 2019; Zaheer et al., 2020) may incur similar limitations as their n-gram and word embedding-based predecessors, performing worse on languages with relatively free word order.7\nThe singular focus on maximizing a performance metric such as accuracy introduces a bias towards models that are expressive enough to fit a given distribution well. Such models are typically blackbox and learn highly non-linear relations that are generally not interpretable. Interpretability is generally studied in papers focusing exclusively on this topic; a recent example is BERTology (Rogers et al., 2020). Studies proposing more interpretable methods typically build on state-of-the-art methods (Weiss et al., 2018) and much work focuses on leveraging components such as attention for interpretability, which have not been designed with that goal in mind (Serrano and Smith, 2019; Wiegreffe and Pinter, 2019). As a result, researchers eschew directions focusing on models that are intrinsically more interpretable such as generalized additive models (Hastie and Tibshirani, 2017) and their extensions (Chang et al., 2021; Agarwal et al., 2021) but which have so far not been shown to match the performance of state-of-the-art methods.\nAs most datasets on which models are evaluated focus on sentences or short documents, state-ofthe-art methods restrict their input size to around 512 tokens (Devlin et al., 2019) and leverage meth-\n7An older work of Khudanpur (2006) argues that free word order is less of a problem as local order within phrases is relatively stable. However, it remains to be seen to what degree this affects current models.\nods that are inefficient when scaling to longer documents. This has led to the emergence of a wide range of more efficient models (Tay et al., 2020), which, however, are rarely used as baseline methods in NLP. Similarly, the standard pretrainfine-tune paradigm (Ruder et al., 2019) requires separate model copies to be stored for each task, and thus restricts work on multi-domain, multitask, multi-lingual, multi-subpopulation methods that is enabled by more efficient and less resourceintensive (Schwartz et al., 2020) fine-tuning methods (Houlsby et al., 2019; Pfeiffer et al., 2020)\nIn sum, (what we typically consider as) standard baselines and state-of-the-art architectures favor languages with some characteristics over others and are optimized only for performance, which in turn propagates the SQUARE ONE BIAS: If researchers study aspects such as multilinguality, efficiency, fairness or interpretability, they are likely to do so with and for commonly used architectures (i.e., often termed ‘standard architectures’), in order to reduce (too) many degrees of freedom in their empirical research. This is in many ways a sensible choice in order to maximize perceived relevance— and thereby, impact. However, as a result, multilinguality, efficiency, fairness, interpretability, and other research areas inherit the same biases, which typically slip under the radar.\nAnnotation Biases. Many NLP tasks can be cast differently and formulated in multiple ways, and differences may result in different annotation styles. Sentiment, for example, can be annotated at the document, sentence or word level (Socher et al., 2013). In machine comprehension, answers are sometimes assumed to be continuous, but Zhu et al. (2020) annotate discontinuous spans. In dependency parsing, different annotation guidelines can lead to very different downstream performance (Elming et al., 2013). How we annotate for a task may interact in complex ways with dimensions such as multilinguality, efficiency, fairness, and interpretability. The Universal Dependencies project (Nivre et al., 2020) is motivated by the observation that not all dependency formalisms are easily applicable to all languages. Aligning guidelines across languages has enabled researchers to ask interesting questions, but such attempts may limit the analysis of outlier languages (Croft et al., 2017).\nOther examples of annotation guidelines interacting with the above dimensions exist: Slight nuances in how annotation guidelines are formulated can\nlead to severe model biases (Hansen and Søgaard, 2021a) and hurt model fairness. In interpretability, we can use feature attribution methods and wordlevel annotations to evaluate interpretability methods applied to sequence classifiers (Rei and Søgaard, 2018), but we cannot directly use feature attribution methods to obtain rationales for sequence labelers. Annotation biases can also stem from the characteristics of the annotators, including their domain experience (McAuley and Leskovec, 2013), demographics (Jørgensen and Søgaard, 2021), or educational level (Al Kuwatly et al., 2020).\nAnnotation biases form an integral part of the SQUARE ONE BIAS: In NLP experiments, we commonly rely on the same pools of annotators, e.g., computer science students, professional linguists, or MTurk contributors. Sometimes these biases percolate through reuse of resources, e.g., through human or machine translation into new languages. Examples of such recycled resources include Conneau et al. (2018) and Kassner et al. (2021), among others. Even when such translationbased resources resonate with syntax and semantics of the target language, and are fluent and natural, they still suffer from translation artefacts: they are often target-language surface realizations of source-language-based conceptual thinking. As a consequence, evaluations of cross-lingual transfer models on such data typically overestimate their performance as properties such as word order and even the choice of lexical units are inherently biased by the source language (Vanmassenhove et al., 2021). Put simply, the choice of the data creation protocol, e.g., translation-based versus data collection directly in the target language (Clark et al., 2020) can yield profound differences in model performance for some groups, or may have serious impact on the interpretability or computational efficiency (e.g., sample efficiency) of our models.\nSelection Biases. For many years, the English Penn Treebank (Marcus et al., 1994) was an integral part of the SQUARE ONE of NLP. This corpus consists entirely of newswire, i.e., articles and editorials from the Wall Street Journal, and arguably amplified the (existing) bias toward news articles. Since news articles tend to reflect a particular set of linguistic conventions, have a certain length, and are written by certain demographics, the bias toward news articles had an impact on the linguistic phenomena studied in NLP (Judge et al., 2006), led to under-representation of challenges with handling\nlonger documents (Beltagy et al., 2021), and had impact on early papers in fairness (Hovy and Søgaard, 2015). Note how such a bias may interact in non-linear ways with efficiency, i.e., efficient methods for shorter documents need not be efficient for longer ones, or fairness, i.e., what mitigates gender biases in news articles need not mitigate gender biases in product reviews.\nProtocol Biases. In the prototypical NLP experiment, the dataset is in the English language. As a consequence, it is also standard protocol in multilingual NLP to use English as a source language in zero-shot cross-lingual transfer (Hu et al., 2020). In practice, there are generally better source languages than English (Lin et al., 2019; Turc et al., 2021), and results are heavily biased by the common choice of English. For instance, effectiveness and efficiency of few-shot learning can be impacted by the choice of the source language (Pfeiffer et al., 2021; Zhao et al., 2021). English also dominates language pairs in machine translation, leading to lower performance for non-English translation directions (Fan et al., 2020), which are particularly important in multilingual societies. Again, such biases may interact in non-trivial ways with dimensions explored in NLP research: It is not inconceivable that there is an algorithm A that is more fair, interpretable or efficient than algorithm B on, say, English-to-Czech transfer or translation, but not on German-to-Czech or French-to-Czech.\nOrganizational Biases. The above architectural, annotation, selection and protocol biases follow from the SQUARE ONE BIAS, but they also conserve the SQUARE ONE. If our go-to architectures, resources, and experimental setups are tailored to some languages over others, some objectives over others, and some research paradigms over others, it is considerably more work to explore new sets of languages, new objectives, or new protocols. The organizational biases we discuss below may also reinforce the SQUARE ONE BIAS.\nThe organization of our conferences and reviewing processes perpetuates certain biases. In particular, both during reviewing and for later presentation at conferences, papers are organized in areas. Upon submission, a paper is assigned to a single area. Reviewers are recruited for their expertise in a specific area, which they are associated with. Such a reviewing system incentivizes papers that make contributions to the chosen area, in order to appeal to the reviewers of this area and\nimplicitly penalizes papers that make contributions along multiple dimensions, as reviewers unfamiliar with the related areas may not appreciate their inter-disciplinary or inter-areal magnitude or value. Even new initiatives that seek to improve reviewing such as ARR8 adhere to this area structure9 and thus further the SQUARE ONE BIAS. A reviewing system that allows papers to be associated with multiple dimensions of research and that assigns reviewers with complementary expertise—similar to TACL10—would ameliorate this situation. Once a paper is accepted, presentations at conferences are organized by areas, limiting audiences in most cases to members of said area and thereby reducing the cross-pollination of ideas.11\nUnexplored Areas of the Research Manifold. The discussed biases, which seem to originate from a SQUARE ONE BIAS, leave areas of the research manifold unexplored. Character-based language models are often reported to perform well for morphologically rich languages or on non-canonical text (Ma et al., 2020), but little is known about their fairness properties, and attribution-based interpretability methods have not been developed for such models. Annotation biases that stem from annotator demographics have been studied for English POS tagging (Hovy and Søgaard, 2015) or English summarization (Jørgensen and Søgaard, 2021), for example, but there has been very little research on such biases for other languages. While linguistic differences among genders is shared among some languages, genders differ in very different ways between other languages, e.g., Spanish and Swedish (Johannsen et al., 2015). We discuss important unexplored areas of the research manifold in §5, but first we briefly survey existing, multi-dimensional work, i.e., the counter-examples to our claim that NLP research is biased to onedimensional extensions of the square one.\n8aclrollingreview.org/ 9www.2022.aclweb.org/callpapers\n10transacl.org/index.php/tacl 11Another previously pervasive organizational bias, which is now fortunately being institutionally mitigated within the *ACL community through dedicated mentoring programs and improved reviewing guidelines, concerned penalizing research papers for their non-native writing style, where it was frequently suggested to the authors whose native language is not English to ‘have their paper proofread by a native speaker’. As one hidden consequence, this attitude might have set a higher bar for the native speakers of minor and endangered languages working on such languages to put their research problems in the spotlight, that way also implicitly hindering more work of the entire community on these languages."
    }, {
      "heading" : "4 Counter-Examples",
      "text" : "Most of the exceptions to our thesis about the ‘onedimensionality’ of NLP research, in our classification of ACL 2021 Oral Papers, came from studies of efficiency in a multilingual context. Another example of this is Ahia et al. (2021), who show that for low-resource languages, weight pruning hurts performance on tail phenomena, but improves robustness to out-of-distribution shifts—this is not observed in the SQUARE ONE (high-resource) regime. There are also studies of fairness in a multilingual context. Huang et al. (2020), for example, show significant differences in social bias for multilingual hate speech systems across different languages. Zhao et al. (2020) study gender bias in multilingual word embeddings and cross-lingual transfer. González et al. (2020) also study gender bias, but by relying on reflexive pronominal constructions that do not exist in the English language; this is a good example of research that would not have been possible taking SQUARE ONE as our point of departure. Dayanik and Padó (2021) study adversarial debiasing in the context of a multilingual corpus and show some mitigation methods are more effective for some languages rather than others. Nozza (2021) studies multilingual toxicity classification and finds that models misinterpret non-hateful language-specific taboo interjections as hate speech in some languages. There has been much less work on other combinations of these dimensions, e.g., fairness and efficiency, but Hansen and Søgaard (2021b) show that weight pruning has disparate effects on performance across demographics; the min-max difference in group disparities is negatively correlated with model size. Renduchintala et al. (2021) also observe that techniques to make inference more efficient, e.g., greedy search, quantization, or shallow decoder models, have a small impact on performance, but dramatically amplify gender bias. In a rare study of fairness and interpretability, Vig et al. (2020) propose a methodology to interpret which parts of a model are causally implicated in its behavior. They apply this methodology to analyze gender bias in pre-trained Transformers, finding that gender bias effects are sparse and concentrated in small parts of the network."
    }, {
      "heading" : "5 Blind Spots",
      "text" : "We identified several under-explored areas on the research manifold. The common theme is a lack\nof studies of how dimensions such as multilinguality, fairness, efficiency, and interpretability interact. We now summarize some open problems that we believe are particularly important to address: (i) While recent work has begun to study the trade-off between efficiency and fairness, this interaction remains largely unexplored, especially outside of the empirical risk minimization regime; (ii) fairness and interpretability interact in potentially many ways, i.e., interpretability techniques may affect the fairness of the underlying models (Agarwal, 2021), but rationales may also, for example, be biased toward certain demographics in how they are presented (Feng and Boyd-Graber, 2018; González et al., 2021); (iii) finally, multilinguality and interpretability seem heavily underexplored. While there exists resources for English for evaluating interpretability methods against gold-standard human annotations, there are, to the best of our knowledge, no such resources for other languages.12"
    }, {
      "heading" : "6 Discussion",
      "text" : "Is SQUARE ONE BIAS not the Flipside of Scientific Protocol? One potential argument for a community-wide SQUARE ONE BIAS is that when studying the impact of some technique t, say a novel regularization term, we want to compare some system with and without t, i.e., control for all other factors. To maximize impact and ease workload, it makes sense at first sight to stick to a system and experimental protocol that is familiar or wellstudied. Always returning to the SQUARE ONE is a way to control for all other factors and relating new findings to known territory. The reason why this is only seemingly a good idea, however, is that the factors we study in NLP research, may be nonlinearly related. The fact that t makes for a positive net contribution under one set of circumstances, does not imply that it would do so under different circumstances. This is illustrated most clearly by the research surveyed in §3. Ideally, we thus want to study the impact of t under as many circumstances as possible, but in the absence of resources to do so, it is a better (collective) search strategy to apply t to a random set of circumstances (within the space of relevant circumstances, of course).\nShould Each Paper Aim to Cover All Dimensions? We believe that a researcher should aspire\n12We again note that there are other possible dimensions, not studied in this work, that can expose more blind spots: e.g., fairness and multi-modality, multilinguality and privacy.\nto cover as many dimensions as possible with their research. While this may not be possible in every instance due to various factors (lack of data, time, standardization, tooling, etc), considering the dimensions encourages us to think more holistically about our research and its final impact. It may also accelerate progress as follow-up work will already be able to build on the insights of multidimensional analyses of new methods. It will also promote the cross-pollination of ideas, which will no longer be confined to their own sub-areas. At the same time, multi-dimensional research requires researchers to become experts in multiple areas.\nPractical Recommendations. What can we do to incentivize and facilitate multi-dimensional research? i) Currently, most NLP models are evaluated by one or two performance metrics, but we believe dimensions such as fairness, efficiency, and interpretability need to become integral criteria for model evaluation, in line with recent proposals of more user-centric leaderboards (Ethayarajh and Jurafsky, 2020; Ma et al., 2021). This requires new tools, e.g., to evaluate environmental impact (Henderson et al., 2020), as well as new benchmarks, e.g., to evaluate fairness (Koh et al., 2021). ii) We believe separate conference tracks (areas) lead to unfortunate silo effects and inhibit multidimensional research. Rather, we imagine conference submissions could provide a checklist with dimensions along which they make contributions, similar to reproducibility checklist. Reviewers can be assigned based on their expertise corresponding to different dimensions. iii) Finally, we recommend awareness of research prototypes and encourage reviewers and chairs to prioritize research that departs from prototypes in multiple dimensions, in order to explore new areas of the research manifold."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We identified the prototypical NLP experiment through surveys and annotation experiments. We highlighted the associated SQUARE ONE BIAS, which encourages research to go beyond the prototype in a single dimension. We discussed the problems resulting from this bias, by studying the area statistics of a recent NLP conference as well as by discussing historic and recent examples. We finally pointed to under-explored research directions and made practical recommendations to inspire more multi-dimensional research in NLP."
    }, {
      "heading" : "A Appendix",
      "text" : "A.1 Analysis of remaining areas at ACL 2021 We provide statistics for the remaining areas at ACL 2021 in Table 4.\nA.2 Analysis of Efficiency area at EMNLP 2021\nWe annotated the 20 papers presented orally at EMNLP 2021 in the “Efficient Models in NLP” area. Among the presented papers, 19/20 are monolingual and 17 focus only on English. Among the other two, one focuses on Indonesian and one on Chinese. The last paper focuses on MT with multiple languages. Papers mainly evaluate using accuracy and/or F1 and many papers evaluate on GLUE. There is a single two-dimensional paper according to our criteria (the paper focusing on MT, which makes contributions on multilinguality and efficiency) while two other papers can be considered two-dimensional but cover dimensions that we do not annotate, i.e. privacy and robustness respectively. This analysis corroborates our findings that research papers depart from SQUARE ONE in such dedicated conference areas/tracks, but largely only across a single dimension."
    } ],
    "references" : [ {
      "title" : "How familiar does that sound? Cross-lingual representational similarity analysis of acoustic word embeddings",
      "author" : [ "Badr Abdullah", "Iuliia Zaitova", "Tania Avgustinova", "Bernd Möbius", "Dietrich Klakow." ],
      "venue" : "Proceedings of the Fourth BlackboxNLP",
      "citeRegEx" : "Abdullah et al\\.,? 2021",
      "shortCiteRegEx" : "Abdullah et al\\.",
      "year" : 2021
    }, {
      "title" : "Exploring BERT’s Vocabulary",
      "author" : [ "Judit Ács." ],
      "venue" : "Blog Post.",
      "citeRegEx" : "Ács.,? 2019",
      "shortCiteRegEx" : "Ács.",
      "year" : 2019
    }, {
      "title" : "Neural additive models: Interpretable machine learning with neural nets",
      "author" : [ "Rishabh Agarwal", "Levi Melnick", "Nicholas Frosst", "Xuezhou Zhang", "Ben Lengerich", "Rich Caruana", "Geoffrey Hinton." ],
      "venue" : "Proceedings of NeurIPS 2021.",
      "citeRegEx" : "Agarwal et al\\.,? 2021",
      "shortCiteRegEx" : "Agarwal et al\\.",
      "year" : 2021
    }, {
      "title" : "Trade-offs between fairness and interpretability in machine learning",
      "author" : [ "Sushant Agarwal." ],
      "venue" : "Proceedings of the IJCAI 2021 Workshop on AI for Social Good.",
      "citeRegEx" : "Agarwal.,? 2021",
      "shortCiteRegEx" : "Agarwal.",
      "year" : 2021
    }, {
      "title" : "The low-resource double bind: An empirical study of pruning for low-resource machine translation",
      "author" : [ "Orevaoghene Ahia", "Julia Kreutzer", "Sara Hooker." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2021, pages 3316–3333.",
      "citeRegEx" : "Ahia et al\\.,? 2021",
      "shortCiteRegEx" : "Ahia et al\\.",
      "year" : 2021
    }, {
      "title" : "On difficulties of cross-lingual transfer with order differences: A case study on dependency parsing",
      "author" : [ "Wasi Ahmad", "Zhisong Zhang", "Xuezhe Ma", "Eduard Hovy", "Kai-Wei Chang", "Nanyun Peng." ],
      "venue" : "Proceedings of NAACL-HLT 2019, pages 2440–2452.",
      "citeRegEx" : "Ahmad et al\\.,? 2019",
      "shortCiteRegEx" : "Ahmad et al\\.",
      "year" : 2019
    }, {
      "title" : "Identifying and measuring annotator bias based on annotators’ demographic characteristics",
      "author" : [ "Hala Al Kuwatly", "Maximilian Wich", "Georg Groh." ],
      "venue" : "Proceedings of the Fourth Workshop on Online Abuse and Harms, pages 184–190.",
      "citeRegEx" : "Kuwatly et al\\.,? 2020",
      "shortCiteRegEx" : "Kuwatly et al\\.",
      "year" : 2020
    }, {
      "title" : "The interplay of semantics and morphology in word embeddings",
      "author" : [ "Oded Avraham", "Yoav Goldberg." ],
      "venue" : "Proceedings of EACL 2017, pages 422– 426.",
      "citeRegEx" : "Avraham and Goldberg.,? 2017",
      "shortCiteRegEx" : "Avraham and Goldberg.",
      "year" : 2017
    }, {
      "title" : "Distributional memory: A general framework for corpus-based semantics",
      "author" : [ "Marco Baroni", "Alessandro Lenci." ],
      "venue" : "Computational Linguistics, 36(4):673–721.",
      "citeRegEx" : "Baroni and Lenci.,? 2010",
      "shortCiteRegEx" : "Baroni and Lenci.",
      "year" : 2010
    }, {
      "title" : "Beyond paragraphs: NLP for long sequences",
      "author" : [ "Iz Beltagy", "Arman Cohan", "Hannaneh Hajishirzi", "Sewon Min", "Matthew E. Peters." ],
      "venue" : "Proceedings of NAACL-HLT 2021: Tutorials, pages 20–24.",
      "citeRegEx" : "Beltagy et al\\.,? 2021",
      "shortCiteRegEx" : "Beltagy et al\\.",
      "year" : 2021
    }, {
      "title" : "On achieving and evaluating language-independence in NLP",
      "author" : [ "Emily M. Bender." ],
      "venue" : "Linguistic Issues in Language Technology, 6(3):1–26.",
      "citeRegEx" : "Bender.,? 2011",
      "shortCiteRegEx" : "Bender.",
      "year" : 2011
    }, {
      "title" : "A maximum entropy approach to natural language processing",
      "author" : [ "Adam L. Berger", "Stephen A. Della Pietra", "Vincent J. Della Pietra." ],
      "venue" : "Computational Linguistics, 22(1):39–71.",
      "citeRegEx" : "Berger et al\\.,? 1996",
      "shortCiteRegEx" : "Berger et al\\.",
      "year" : 1996
    }, {
      "title" : "Factored language models and generalized parallel backoff",
      "author" : [ "Jeff Bilmes", "Katrin Kirchhoff." ],
      "venue" : "Companion Volume of the Proceedings of HLTNAACL 2003-Short Papers, pages 4–6.",
      "citeRegEx" : "Bilmes and Kirchhoff.,? 2003",
      "shortCiteRegEx" : "Bilmes and Kirchhoff.",
      "year" : 2003
    }, {
      "title" : "Natural Language Processing with Python: Analyzing Text with the Natural Language Toolkit",
      "author" : [ "Steven Bird", "Ewan Klein", "Edward Loper." ],
      "venue" : "O’Reilly, Beijing.",
      "citeRegEx" : "Bird et al\\.,? 2009",
      "shortCiteRegEx" : "Bird et al\\.",
      "year" : 2009
    }, {
      "title" : "The values encoded in machine learning research",
      "author" : [ "Abeba Birhane", "Pratyusha Kalluri", "Dallas Card", "William Agnew", "Ravit Dotan", "Michelle Bao." ],
      "venue" : "CoRR, abs/2106.15590.",
      "citeRegEx" : "Birhane et al\\.,? 2021",
      "shortCiteRegEx" : "Birhane et al\\.",
      "year" : 2021
    }, {
      "title" : "Language (technology) is power: A critical survey of \"bias\" in NLP",
      "author" : [ "Su Lin Blodgett", "Solon Barocas", "Hal Daumé III", "Hanna M. Wallach." ],
      "venue" : "CoRR, abs/2005.14050.",
      "citeRegEx" : "Blodgett et al\\.,? 2020",
      "shortCiteRegEx" : "Blodgett et al\\.",
      "year" : 2020
    }, {
      "title" : "Byte pair encoding is suboptimal for language model pretraining",
      "author" : [ "Kaj Bostrom", "Greg Durrett." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 4617–4624.",
      "citeRegEx" : "Bostrom and Durrett.,? 2020",
      "shortCiteRegEx" : "Bostrom and Durrett.",
      "year" : 2020
    }, {
      "title" : "Assessing agreement on classification tasks: The kappa statistic",
      "author" : [ "Jean Carletta." ],
      "venue" : "Computational Linguistics, 22(2):249–254.",
      "citeRegEx" : "Carletta.,? 1996",
      "shortCiteRegEx" : "Carletta.",
      "year" : 1996
    }, {
      "title" : "How interpretable and trustworthy are GAMs",
      "author" : [ "Chun-Hao Chang", "Sarah Tan", "Ben Lengerich", "Anna Goldenberg", "Rich Caruana" ],
      "venue" : "In Proceedings of KDD",
      "citeRegEx" : "Chang et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Chang et al\\.",
      "year" : 2021
    }, {
      "title" : "Generating long sequences with sparse Transformers",
      "author" : [ "Rewon Child", "Scott Gray", "Alec Radford", "Ilya Sutskever." ],
      "venue" : "CoRR, abs/1904.10509.",
      "citeRegEx" : "Child et al\\.,? 2019",
      "shortCiteRegEx" : "Child et al\\.",
      "year" : 2019
    }, {
      "title" : "TyDi QA: A benchmark for information-seeking question answering in typologically diverse languages",
      "author" : [ "Jonathan H. Clark", "Eunsol Choi", "Michael Collins", "Dan Garrette", "Tom Kwiatkowski", "Vitaly Nikolaev", "Jennimaria Palomaki." ],
      "venue" : "Transactions of the",
      "citeRegEx" : "Clark et al\\.,? 2020",
      "shortCiteRegEx" : "Clark et al\\.",
      "year" : 2020
    }, {
      "title" : "XNLI: Evaluating cross-lingual sentence representations",
      "author" : [ "Alexis Conneau", "Ruty Rinott", "Guillaume Lample", "Adina Williams", "Samuel Bowman", "Holger Schwenk", "Veselin Stoyanov." ],
      "venue" : "Proceedings of EMNLP 2018, pages 2475–2485.",
      "citeRegEx" : "Conneau et al\\.,? 2018",
      "shortCiteRegEx" : "Conneau et al\\.",
      "year" : 2018
    }, {
      "title" : "Linguistic typology meets universal dependencies",
      "author" : [ "William Croft", "Dawn Nordquist", "Katherine Looney", "Michael Regan." ],
      "venue" : "Proceedings of the 15th International Workshop on Treebanks and Linguistic Theories (TLT15), pages 63–75.",
      "citeRegEx" : "Croft et al\\.,? 2017",
      "shortCiteRegEx" : "Croft et al\\.",
      "year" : 2017
    }, {
      "title" : "Biases in categorization",
      "author" : [ "Edith A. Das-Smaal." ],
      "venue" : "volume 68 of Advances in Psychology, pages 349– 386. North-Holland.",
      "citeRegEx" : "Das.Smaal.,? 1990",
      "shortCiteRegEx" : "Das.Smaal.",
      "year" : 1990
    }, {
      "title" : "Disentangling document topic and author gender in multiple languages: Lessons for adversarial debiasing",
      "author" : [ "Erenay Dayanik", "Sebastian Padó." ],
      "venue" : "In",
      "citeRegEx" : "Dayanik and Padó.,? 2021",
      "shortCiteRegEx" : "Dayanik and Padó.",
      "year" : 2021
    }, {
      "title" : "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of NAACL-HLT 2019.",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "A critical analysis of biased parsers in unsupervised parsing",
      "author" : [ "Chris Dyer", "Gábor Melis", "Phil Blunsom." ],
      "venue" : "CoRR, abs/1909.09428.",
      "citeRegEx" : "Dyer et al\\.,? 2019",
      "shortCiteRegEx" : "Dyer et al\\.",
      "year" : 2019
    }, {
      "title" : "Introduction to Natural Language Processing",
      "author" : [ "Jacob Eisenstein." ],
      "venue" : "Adaptive Computation and Machine Learning series. MIT Press.",
      "citeRegEx" : "Eisenstein.,? 2019",
      "shortCiteRegEx" : "Eisenstein.",
      "year" : 2019
    }, {
      "title" : "Down-stream effects of tree-to-dependency conversions",
      "author" : [ "Jakob Elming", "Anders Johannsen", "Sigrid Klerke", "Emanuele Lapponi", "Hector Martinez Alonso", "Anders Søgaard." ],
      "venue" : "Proceedings of NAACL-HLT 2013, pages 617–626.",
      "citeRegEx" : "Elming et al\\.,? 2013",
      "shortCiteRegEx" : "Elming et al\\.",
      "year" : 2013
    }, {
      "title" : "Utility is in the eye of the user: A critique of NLP leaderboards",
      "author" : [ "Kawin Ethayarajh", "Dan Jurafsky." ],
      "venue" : "Proceedings of EMNLP 2020, pages 4846–4853.",
      "citeRegEx" : "Ethayarajh and Jurafsky.,? 2020",
      "shortCiteRegEx" : "Ethayarajh and Jurafsky.",
      "year" : 2020
    }, {
      "title" : "Beyond English-Centric Multilingual Machine Translation",
      "author" : [ "Michael Auli", "Armand Joulin." ],
      "venue" : "arXiv preprint arXiv:2010.11125.",
      "citeRegEx" : "Auli and Joulin.,? 2020",
      "shortCiteRegEx" : "Auli and Joulin.",
      "year" : 2020
    }, {
      "title" : "What can AI do for me: Evaluating machine learning interpretations in cooperative play",
      "author" : [ "Shi Feng", "Jordan L. Boyd-Graber." ],
      "venue" : "CoRR, abs/1810.09648.",
      "citeRegEx" : "Feng and Boyd.Graber.,? 2018",
      "shortCiteRegEx" : "Feng and Boyd.Graber.",
      "year" : 2018
    }, {
      "title" : "On the relation between linguistic typology and (limitations of) multilingual language modeling",
      "author" : [ "Daniela Gerz", "Ivan Vulić", "Edoardo Maria Ponti", "Roi Reichart", "Anna Korhonen." ],
      "venue" : "Proceedings of EMNLP 2018, pages 316–327.",
      "citeRegEx" : "Gerz et al\\.,? 2018",
      "shortCiteRegEx" : "Gerz et al\\.",
      "year" : 2018
    }, {
      "title" : "Type B reflexivization as an unambiguous testbed for multilingual multi-task gender bias",
      "author" : [ "Ana Valeria González", "Maria Barrett", "Rasmus Hvingelby", "Kellie Webster", "Anders Søgaard." ],
      "venue" : "Proceedings of EMNLP 2020, pages 2637–2648.",
      "citeRegEx" : "González et al\\.,? 2020",
      "shortCiteRegEx" : "González et al\\.",
      "year" : 2020
    }, {
      "title" : "On the interaction of belief bias and explanations",
      "author" : [ "Ana Valeria González", "Anna Rogers", "Anders Søgaard." ],
      "venue" : "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 2930–2942.",
      "citeRegEx" : "González et al\\.,? 2021",
      "shortCiteRegEx" : "González et al\\.",
      "year" : 2021
    }, {
      "title" : "Centering: A framework for modeling the local coherence of discourse",
      "author" : [ "Barbara J. Grosz", "Aravind K. Joshi", "Scott Weinstein." ],
      "venue" : "Computational Linguistics, 21(2):203–225.",
      "citeRegEx" : "Grosz et al\\.,? 1995",
      "shortCiteRegEx" : "Grosz et al\\.",
      "year" : 1995
    }, {
      "title" : "Guideline bias in Wizard-of-Oz dialogues",
      "author" : [ "Victor Petrén Bach Hansen", "Anders Søgaard." ],
      "venue" : "Proceedings of the 1st Workshop on Benchmarking: Past, Present and Future, pages 8–14.",
      "citeRegEx" : "Hansen and Søgaard.,? 2021a",
      "shortCiteRegEx" : "Hansen and Søgaard.",
      "year" : 2021
    }, {
      "title" : "Is the lottery fair? evaluating winning tickets across demographics",
      "author" : [ "Victor Petrén Bach Hansen", "Anders Søgaard." ],
      "venue" : "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3214–3224.",
      "citeRegEx" : "Hansen and Søgaard.,? 2021b",
      "shortCiteRegEx" : "Hansen and Søgaard.",
      "year" : 2021
    }, {
      "title" : "Generalized additive models",
      "author" : [ "Trevor J. Hastie", "Robert J. Tibshirani." ],
      "venue" : "Routledge.",
      "citeRegEx" : "Hastie and Tibshirani.,? 2017",
      "shortCiteRegEx" : "Hastie and Tibshirani.",
      "year" : 2017
    }, {
      "title" : "Towards the systematic reporting of the energy and carbon footprints of machine learning",
      "author" : [ "Peter Henderson", "Jieru Hu", "Joshua Romoff", "Emma Brunskill", "Dan Jurafsky", "Joelle Pineau." ],
      "venue" : "Journal of Machine Learning Research, 21(248):1–43.",
      "citeRegEx" : "Henderson et al\\.,? 2020",
      "shortCiteRegEx" : "Henderson et al\\.",
      "year" : 2020
    }, {
      "title" : "Parameter-efficient transfer learning for NLP",
      "author" : [ "Neil Houlsby", "Andrei Giurgiu", "Stanislaw Jastrzebski", "Bruna Morrone", "Quentin De Laroussilhe", "Andrea Gesmundo", "Mona Attariyan", "Sylvain Gelly." ],
      "venue" : "Proceedings of ICML 2019, pages 2790–2799.",
      "citeRegEx" : "Houlsby et al\\.,? 2019",
      "shortCiteRegEx" : "Houlsby et al\\.",
      "year" : 2019
    }, {
      "title" : "Tagging performance correlates with author age",
      "author" : [ "Dirk Hovy", "Anders Søgaard." ],
      "venue" : "Proceedings of ACL-IJCNLP 2015, pages 483–488.",
      "citeRegEx" : "Hovy and Søgaard.,? 2015",
      "shortCiteRegEx" : "Hovy and Søgaard.",
      "year" : 2015
    }, {
      "title" : "XTREME: A Massively Multilingual Multitask Benchmark for Evaluating Cross-lingual Generalization",
      "author" : [ "Junjie Hu", "Sebastian Ruder", "Aditya Siddhant", "Graham Neubig", "Orhan Firat", "Melvin Johnson." ],
      "venue" : "Proceedings of ICML 2020.",
      "citeRegEx" : "Hu et al\\.,? 2020",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2020
    }, {
      "title" : "Multilingual Twitter corpus and baselines for evaluating demographic bias in hate speech recognition",
      "author" : [ "Xiaolei Huang", "Linzi Xing", "Franck Dernoncourt", "Michael J. Paul." ],
      "venue" : "Proceedings of LREC 2020, pages 1440–1448.",
      "citeRegEx" : "Huang et al\\.,? 2020",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2020
    }, {
      "title" : "Cross-lingual syntactic variation over age and gender",
      "author" : [ "Anders Johannsen", "Dirk Hovy", "Anders Søgaard." ],
      "venue" : "Proceedings of CoNLL 2015, pages 103– 112.",
      "citeRegEx" : "Johannsen et al\\.,? 2015",
      "shortCiteRegEx" : "Johannsen et al\\.",
      "year" : 2015
    }, {
      "title" : "Evaluation of summarization systems across gender, age, and race",
      "author" : [ "Anna Jørgensen", "Anders Søgaard." ],
      "venue" : "Proceedings of the Third Workshop on New Frontiers in Summarization, pages 51–56.",
      "citeRegEx" : "Jørgensen and Søgaard.,? 2021",
      "shortCiteRegEx" : "Jørgensen and Søgaard.",
      "year" : 2021
    }, {
      "title" : "The State and Fate of Linguistic Diversity and Inclusion in the NLP World",
      "author" : [ "Pratik Joshi", "Sebastin Santy", "Amar Budhiraja", "Kalika Bali", "Monojit Choudhury." ],
      "venue" : "Proceedings of ACL 2020.",
      "citeRegEx" : "Joshi et al\\.,? 2020",
      "shortCiteRegEx" : "Joshi et al\\.",
      "year" : 2020
    }, {
      "title" : "QuestionBank: Creating a corpus of parse-annotated questions",
      "author" : [ "John Judge", "Aoife Cahill", "Josef van Genabith." ],
      "venue" : "Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computa-",
      "citeRegEx" : "Judge et al\\.,? 2006",
      "shortCiteRegEx" : "Judge et al\\.",
      "year" : 2006
    }, {
      "title" : "Speech and language processing : an introduction to natural language processing, computational linguistics, and speech recognition",
      "author" : [ "Dan Jurafsky", "James H. Martin." ],
      "venue" : "Pearson Prentice Hall, Upper Saddle River, N.J.",
      "citeRegEx" : "Jurafsky and Martin.,? 2009",
      "shortCiteRegEx" : "Jurafsky and Martin.",
      "year" : 2009
    }, {
      "title" : "Multilingual LAMA: Investigating knowledge in multilingual pretrained language models",
      "author" : [ "Nora Kassner", "Philipp Dufter", "Hinrich Schütze." ],
      "venue" : "Proceedings of EACL 2021, pages 3250–3258.",
      "citeRegEx" : "Kassner et al\\.,? 2021",
      "shortCiteRegEx" : "Kassner et al\\.",
      "year" : 2021
    }, {
      "title" : "Multilingual language modeling",
      "author" : [ "Sanjeev P Khudanpur." ],
      "venue" : "Multilingual Speech Processing, page 169.",
      "citeRegEx" : "Khudanpur.,? 2006",
      "shortCiteRegEx" : "Khudanpur.",
      "year" : 2006
    }, {
      "title" : "WILDS: A benchmark of in-the-wild distribution shifts",
      "author" : [ "shaw", "Imran S. Haque", "Sara Beery", "Jure Leskovec", "Anshul Kundaje", "Emma Pierson", "Sergey Levine", "Chelsea Finn", "Percy Liang" ],
      "venue" : "In Proceedings of ICML 2021",
      "citeRegEx" : "shaw et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "shaw et al\\.",
      "year" : 2021
    }, {
      "title" : "Assessing the ability of LSTMs to learn syntax-sensitive dependencies",
      "author" : [ "Tal Linzen", "Emmanuel Dupoux", "Yoav Goldberg." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 4:521– 535.",
      "citeRegEx" : "Linzen et al\\.,? 2016",
      "shortCiteRegEx" : "Linzen et al\\.",
      "year" : 2016
    }, {
      "title" : "Visually Grounded Reasoning across Languages and Cultures",
      "author" : [ "Fangyu Liu", "Emanuele Bugliarello", "Edoardo Maria Ponti", "Siva Reddy", "Nigel Collier", "Desmond Elliott." ],
      "venue" : "Proceedings of EMNLP 2021.",
      "citeRegEx" : "Liu et al\\.,? 2021",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2021
    }, {
      "title" : "Generating Wikipedia by Summarizing Long Sequences",
      "author" : [ "Peter J. Liu", "Mohammad Saleh", "Etienne Pot", "Ben Goodrich", "Ryan Sepassi", "Łukasz Kaiser", "Noam Shazeer." ],
      "venue" : "Proceedings of ICLR 2018.",
      "citeRegEx" : "Liu et al\\.,? 2018",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2018
    }, {
      "title" : "CharBERT: Character-aware pre-trained language model",
      "author" : [ "Wentao Ma", "Yiming Cui", "Chenglei Si", "Ting Liu", "Shijin Wang", "Guoping Hu." ],
      "venue" : "Proceedings of the 28th International Conference on Computational Linguistics, pages 39–50, Barcelona,",
      "citeRegEx" : "Ma et al\\.,? 2020",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2020
    }, {
      "title" : "Dynaboard: An evaluation-as-a-service platform for holistic nextgeneration benchmarking",
      "author" : [ "Zhiyi Ma", "Kawin Ethayarajh", "Tristan Thrush", "Somya Jain", "Ledell Wu", "Robin Jia", "Christopher Potts", "Adina Williams", "Douwe Kiela." ],
      "venue" : "CoRR, abs/2106.06052.",
      "citeRegEx" : "Ma et al\\.,? 2021",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2021
    }, {
      "title" : "Foundations of Statistical Natural Language Processing",
      "author" : [ "Christopher D. Manning", "Hinrich Schütze." ],
      "venue" : "The MIT Press, Cambridge, Massachusetts.",
      "citeRegEx" : "Manning and Schütze.,? 1999",
      "shortCiteRegEx" : "Manning and Schütze.",
      "year" : 1999
    }, {
      "title" : "The Penn Treebank: Annotating predicate argument structure",
      "author" : [ "Mitchell Marcus", "Grace Kim", "Mary Ann Marcinkiewicz", "Robert MacIntyre", "Ann Bies", "Mark Ferguson", "Karen Katz", "Britta Schasberger." ],
      "venue" : "Human Language Technology:",
      "citeRegEx" : "Marcus et al\\.,? 1994",
      "shortCiteRegEx" : "Marcus et al\\.",
      "year" : 1994
    }, {
      "title" : "From amateurs to connoisseurs: Modeling the evolution of user expertise through online reviews",
      "author" : [ "Julian John McAuley", "Jure Leskovec." ],
      "venue" : "Proceedings of WWW 2013, page 897–908.",
      "citeRegEx" : "McAuley and Leskovec.,? 2013",
      "shortCiteRegEx" : "McAuley and Leskovec.",
      "year" : 2013
    }, {
      "title" : "Distributed Representations of Words and Phrases and their Compositionality",
      "author" : [ "Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean." ],
      "venue" : "Proceedings of NeurIPS 2013.",
      "citeRegEx" : "Mikolov et al\\.,? 2013",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Universal Dependencies v2: An evergrowing multilingual treebank collection",
      "author" : [ "Joakim Nivre", "Marie-Catherine de Marneffe", "Filip Ginter", "Jan Hajič", "Christopher D. Manning", "Sampo Pyysalo", "Sebastian Schuster", "Francis Tyers", "Daniel Zeman." ],
      "venue" : "In",
      "citeRegEx" : "Nivre et al\\.,? 2020",
      "shortCiteRegEx" : "Nivre et al\\.",
      "year" : 2020
    }, {
      "title" : "Exposing the Limits of Zero-shot Cross-lingual Hate Speech Detection",
      "author" : [ "Debora Nozza." ],
      "venue" : "Proceedings of ACL 2021, pages 907–914.",
      "citeRegEx" : "Nozza.,? 2021",
      "shortCiteRegEx" : "Nozza.",
      "year" : 2021
    }, {
      "title" : "Finding deceptive opinion spam by any stretch of the imagination",
      "author" : [ "Myle Ott", "Yejin Choi", "Claire Cardie", "Jeffrey T. Hancock." ],
      "venue" : "Proceedings of ACL 2011, pages 309–319.",
      "citeRegEx" : "Ott et al\\.,? 2011",
      "shortCiteRegEx" : "Ott et al\\.",
      "year" : 2011
    }, {
      "title" : "MAD-X: An Adapter-Based Framework for Multi-Task Cross-Lingual Transfer",
      "author" : [ "Jonas Pfeiffer", "Ivan Vulić", "Iryna Gurevych", "Sebastian Ruder." ],
      "venue" : "Proceedings of EMNLP 2020, pages 7654–7673.",
      "citeRegEx" : "Pfeiffer et al\\.,? 2020",
      "shortCiteRegEx" : "Pfeiffer et al\\.",
      "year" : 2020
    }, {
      "title" : "UNKs everywhere: Adapting multilingual language models to new scripts",
      "author" : [ "Jonas Pfeiffer", "Ivan Vulić", "Iryna Gurevych", "Sebastian Ruder." ],
      "venue" : "Proceedings of EMNLP 2021.",
      "citeRegEx" : "Pfeiffer et al\\.,? 2021",
      "shortCiteRegEx" : "Pfeiffer et al\\.",
      "year" : 2021
    }, {
      "title" : "Can LSTM learn to capture agreement? the case of Basque",
      "author" : [ "Shauli Ravfogel", "Yoav Goldberg", "Francis Tyers." ],
      "venue" : "Proceedings of the 2018 EMNLP Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 98–107.",
      "citeRegEx" : "Ravfogel et al\\.,? 2018",
      "shortCiteRegEx" : "Ravfogel et al\\.",
      "year" : 2018
    }, {
      "title" : "Zero-shot sequence labeling: Transferring knowledge from sentences to tokens",
      "author" : [ "Marek Rei", "Anders Søgaard." ],
      "venue" : "Proceedings of NAACL-HLT 2018, pages 293–302.",
      "citeRegEx" : "Rei and Søgaard.,? 2018",
      "shortCiteRegEx" : "Rei and Søgaard.",
      "year" : 2018
    }, {
      "title" : "Gender bias amplification during speed-quality optimization in neural machine translation",
      "author" : [ "Adithya Renduchintala", "Denise Diaz", "Kenneth Heafield", "Xian Li", "Mona Diab." ],
      "venue" : "Proceedings of ACL-IJCNLP 2021, pages 99–109.",
      "citeRegEx" : "Renduchintala et al\\.,? 2021",
      "shortCiteRegEx" : "Renduchintala et al\\.",
      "year" : 2021
    }, {
      "title" : "A primer in BERTology: What we know about how BERT works",
      "author" : [ "Anna Rogers", "Olga Kovaleva", "Anna Rumshisky." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 8:842–866.",
      "citeRegEx" : "Rogers et al\\.,? 2020",
      "shortCiteRegEx" : "Rogers et al\\.",
      "year" : 2020
    }, {
      "title" : "Transfer learning in natural language processing",
      "author" : [ "Sebastian Ruder", "Matthew E Peters", "Swabha Swayamdipta", "Thomas Wolf." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Ruder et al\\.,? 2019",
      "shortCiteRegEx" : "Ruder et al\\.",
      "year" : 2019
    }, {
      "title" : "How Good is Your Tokenizer? On the Monolingual Performance of Multilingual Language Models",
      "author" : [ "Phillip Rust", "Jonas Pfeiffer", "Ivan Vulić", "Sebastian Ruder", "Iryna Gurevych." ],
      "venue" : "Proceedings of ACL-IJCNLP 2021, pages 3118–3135.",
      "citeRegEx" : "Rust et al\\.,? 2021",
      "shortCiteRegEx" : "Rust et al\\.",
      "year" : 2021
    }, {
      "title" : "Green AI",
      "author" : [ "Roy Schwartz", "Jesse Dodge", "Noah A. Smith", "Oren Etzioni." ],
      "venue" : "Communications of the ACM, 63(12):54–63.",
      "citeRegEx" : "Schwartz et al\\.,? 2020",
      "shortCiteRegEx" : "Schwartz et al\\.",
      "year" : 2020
    }, {
      "title" : "Is attention interpretable",
      "author" : [ "Sofia Serrano", "Noah A. Smith" ],
      "venue" : "In Proceedings of ACL",
      "citeRegEx" : "Serrano and Smith.,? \\Q2019\\E",
      "shortCiteRegEx" : "Serrano and Smith.",
      "year" : 2019
    }, {
      "title" : "Neural Language Modeling by Jointly Learning Syntax and Lexicon",
      "author" : [ "Yikang Shen", "Zhouhan Lin", "Chin-wei Huang", "Aaron Courville." ],
      "venue" : "Proceedings of ICLR 2018.",
      "citeRegEx" : "Shen et al\\.,? 2018",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2018
    }, {
      "title" : "Categorization skills in infants",
      "author" : [ "Tracy Sherman." ],
      "venue" : "Child Development, 56(6):1561–73.",
      "citeRegEx" : "Sherman.,? 1985",
      "shortCiteRegEx" : "Sherman.",
      "year" : 1985
    }, {
      "title" : "Recursive deep models for semantic compositionality over a sentiment treebank",
      "author" : [ "Richard Socher", "Alex Perelygin", "Jean Wu", "Jason Chuang", "Christopher D. Manning", "Andrew Ng", "Christopher Potts." ],
      "venue" : "Proceedings of EMNLP 2013, pages 1631–",
      "citeRegEx" : "Socher et al\\.,? 2013",
      "shortCiteRegEx" : "Socher et al\\.",
      "year" : 2013
    }, {
      "title" : "Semi-supervised learning and domain adaptation for NLP",
      "author" : [ "Anders Søgaard." ],
      "venue" : "Synthesis Lectures on Human Language Technologies. Morgan & Claypool Publishers, United States.",
      "citeRegEx" : "Søgaard.,? 2013",
      "shortCiteRegEx" : "Søgaard.",
      "year" : 2013
    }, {
      "title" : "Lexicon-based methods for sentiment analysis",
      "author" : [ "Maite Taboada", "Julian Brooke", "Milan Tofiloski", "Kimberly Voll", "Manfred Stede." ],
      "venue" : "Computational Linguistics, 37(2):267–307.",
      "citeRegEx" : "Taboada et al\\.,? 2011",
      "shortCiteRegEx" : "Taboada et al\\.",
      "year" : 2011
    }, {
      "title" : "Efficient transformers: A survey",
      "author" : [ "Yi Tay", "Mostafa Dehghani", "Dara Bahri", "Donald Metzler." ],
      "venue" : "CoRR, abs/2009.06732.",
      "citeRegEx" : "Tay et al\\.,? 2020",
      "shortCiteRegEx" : "Tay et al\\.",
      "year" : 2020
    }, {
      "title" : "From SPMRL to NMRL: What did we learn (and unlearn) in a decade of parsing morphologically-rich languages (MRLs)",
      "author" : [ "Reut Tsarfaty", "Dan Bareket", "Stav Klein", "Amit Seker" ],
      "venue" : "In Proceedings of ACL",
      "citeRegEx" : "Tsarfaty et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Tsarfaty et al\\.",
      "year" : 2020
    }, {
      "title" : "Revisiting the Primacy of English in Zero-shot Cross-lingual Transfer",
      "author" : [ "Iulia Turc", "Kenton Lee", "Jacob Eisenstein", "Ming-Wei Chang", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:2106.16171.",
      "citeRegEx" : "Turc et al\\.,? 2021",
      "shortCiteRegEx" : "Turc et al\\.",
      "year" : 2021
    }, {
      "title" : "Word representations: A simple and general method for semi-supervised learning",
      "author" : [ "Joseph Turian", "Lev-Arie Ratinov", "Yoshua Bengio." ],
      "venue" : "Proceedings of ACL 2010, pages 384–394.",
      "citeRegEx" : "Turian et al\\.,? 2010",
      "shortCiteRegEx" : "Turian et al\\.",
      "year" : 2010
    }, {
      "title" : "From characters to words to in between: Do we capture morphology",
      "author" : [ "Clara Vania", "Adam Lopez" ],
      "venue" : "In Proceedings of ACL",
      "citeRegEx" : "Vania and Lopez.,? \\Q2017\\E",
      "shortCiteRegEx" : "Vania and Lopez.",
      "year" : 2017
    }, {
      "title" : "Machine translationese: Effects of algorithmic bias on linguistic complexity in machine translation",
      "author" : [ "Eva Vanmassenhove", "Dimitar Shterionov", "Matthew Gwilliam." ],
      "venue" : "Proceedings of the EACL 2021, pages 2203–2213.",
      "citeRegEx" : "Vanmassenhove et al\\.,? 2021",
      "shortCiteRegEx" : "Vanmassenhove et al\\.",
      "year" : 2021
    }, {
      "title" : "Investigating gender bias in language models using causal mediation analysis",
      "author" : [ "Jesse Vig", "Sebastian Gehrmann", "Yonatan Belinkov", "Sharon Qian", "Daniel Nevo", "Yaron Singer", "Stuart M Shieber." ],
      "venue" : "Proceedings of NeurIPS 2020.",
      "citeRegEx" : "Vig et al\\.,? 2020",
      "shortCiteRegEx" : "Vig et al\\.",
      "year" : 2020
    }, {
      "title" : "BabelSenticNet: A commonsense reasoning framework for multilingual sentiment analysis",
      "author" : [ "David Vilares", "Haiyun Peng", "Ranjan Satapathy", "Erik Cambria." ],
      "venue" : "2018 IEEE Symposium Series on Computational Intelligence (SSCI), pages 1292–",
      "citeRegEx" : "Vilares et al\\.,? 2018",
      "shortCiteRegEx" : "Vilares et al\\.",
      "year" : 2018
    }, {
      "title" : "Exploring demographic language variations to improve multilingual sentiment analysis in social media",
      "author" : [ "Svitlana Volkova", "Theresa Wilson", "David Yarowsky." ],
      "venue" : "Proceedings of EMNLP 2013, pages 1815–1827.",
      "citeRegEx" : "Volkova et al\\.,? 2013",
      "shortCiteRegEx" : "Volkova et al\\.",
      "year" : 2013
    }, {
      "title" : "Extending multilingual BERT to low-resource languages",
      "author" : [ "Zihan Wang", "Karthikeyan K", "Stephen Mayhew", "Dan Roth." ],
      "venue" : "Findings of EMNLP 2020, pages 2649–2656.",
      "citeRegEx" : "Wang et al\\.,? 2020",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "Extracting Automata from Recurrent Neural Networks Using Queries and Counterexamples",
      "author" : [ "Gail Weiss", "Yoav Goldberg", "Eran Yahav." ],
      "venue" : "Proceedings of ICML 2018.",
      "citeRegEx" : "Weiss et al\\.,? 2018",
      "shortCiteRegEx" : "Weiss et al\\.",
      "year" : 2018
    }, {
      "title" : "Attention is not not explanation",
      "author" : [ "Sarah Wiegreffe", "Yuval Pinter." ],
      "venue" : "Proceedings of EMNLPIJCNLP 2019, pages 11–20.",
      "citeRegEx" : "Wiegreffe and Pinter.,? 2019",
      "shortCiteRegEx" : "Wiegreffe and Pinter.",
      "year" : 2019
    }, {
      "title" : "Vocabulary learning via optimal transport for neural machine translation",
      "author" : [ "Jingjing Xu", "Hao Zhou", "Chun Gan", "Zaixiang Zheng", "Lei Li." ],
      "venue" : "Proceedings of ACL-IJCNLP 2021, pages 7361–7373.",
      "citeRegEx" : "Xu et al\\.,? 2021",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2021
    }, {
      "title" : "Overcoming language variation in sentiment analysis with social attention",
      "author" : [ "Yi Yang", "Jacob Eisenstein." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 5:295–307.",
      "citeRegEx" : "Yang and Eisenstein.,? 2017",
      "shortCiteRegEx" : "Yang and Eisenstein.",
      "year" : 2017
    }, {
      "title" : "Unsupervised word sense disambiguation rivaling supervised methods",
      "author" : [ "David Yarowsky." ],
      "venue" : "Proceedings of ACL 1995, pages 189–196.",
      "citeRegEx" : "Yarowsky.,? 1995",
      "shortCiteRegEx" : "Yarowsky.",
      "year" : 1995
    }, {
      "title" : "Broaden the vision: Geodiverse visual commonsense reasoning",
      "author" : [ "Da Yin", "Liunian Harold Li", "Ziniu Hu", "Nanyun Peng", "Kai-Wei Chang." ],
      "venue" : "Proceedings of EMNLP 2021, pages 2115–2129.",
      "citeRegEx" : "Yin et al\\.,? 2021",
      "shortCiteRegEx" : "Yin et al\\.",
      "year" : 2021
    }, {
      "title" : "Big bird: Transformers for longer sequences",
      "author" : [ "Manzil Zaheer", "Guru Guruganesh", "Kumar Avinava Dubey", "Joshua Ainslie", "Chris Alberti", "Santiago Ontanon", "Philip Pham", "Anirudh Ravula", "Qifan Wang", "Li Yang" ],
      "venue" : "NeurIPS",
      "citeRegEx" : "Zaheer et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Zaheer et al\\.",
      "year" : 2020
    }, {
      "title" : "Gender bias in multilingual embeddings and cross-lingual transfer",
      "author" : [ "Jieyu Zhao", "Subhabrata Mukherjee", "Saghar Hosseini", "Kai-Wei Chang", "Ahmed Hassan Awadallah." ],
      "venue" : "Proceedings of ACL 2020, pages 2896–2907.",
      "citeRegEx" : "Zhao et al\\.,? 2020",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2020
    }, {
      "title" : "A closer look at few-shot crosslingual transfer: The choice of shots matters",
      "author" : [ "Mengjie Zhao", "Yi Zhu", "Ehsan Shareghi", "Ivan Vulić", "Roi Reichart", "Anna Korhonen", "Hinrich Schütze." ],
      "venue" : "Proceedings of ACL-IJNCLP 2021, pages 5751–5767.",
      "citeRegEx" : "Zhao et al\\.,? 2021",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2021
    }, {
      "title" : "Question answering with long multiple-span answers",
      "author" : [ "Ming Zhu", "Aman Ahuja", "Da-Cheng Juan", "Wei Wei", "Chandan K. Reddy." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 3840–3849, Online. Associa-",
      "citeRegEx" : "Zhu et al\\.,? 2020",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 75,
      "context" : "Our categorization of objects, say screwdrivers or NLP experiments, is heavily biased by early prototypes (Sherman, 1985; Das-Smaal, 1990).",
      "startOffset" : 106,
      "endOffset" : 138
    }, {
      "referenceID" : 23,
      "context" : "Our categorization of objects, say screwdrivers or NLP experiments, is heavily biased by early prototypes (Sherman, 1985; Das-Smaal, 1990).",
      "startOffset" : 106,
      "endOffset" : 138
    }, {
      "referenceID" : 27,
      "context" : "We note an important difference, however: While the first four books largely ignore issues relating to fairness, interpretability, and efficiency, the most recent NLP textbook in Table 1 (Eisenstein, 2019) discusses efficiency (briefly) and fairness (more thoroughly).",
      "startOffset" : 187,
      "endOffset" : 205
    }, {
      "referenceID" : 14,
      "context" : "work that annotates the values of ML research papers (Birhane et al., 2021), we are not concerned with a paper’s motivation but whether its practical contributions constitute a meaningful departure from SQUARE ONE.",
      "startOffset" : 53,
      "endOffset" : 75
    }, {
      "referenceID" : 10,
      "context" : "Overall, almost 70% of papers evaluate only on English, clearly highlighting a lack of language diversity in NLP (Bender, 2011; Joshi et al., 2020).",
      "startOffset" : 113,
      "endOffset" : 147
    }, {
      "referenceID" : 46,
      "context" : "Overall, almost 70% of papers evaluate only on English, clearly highlighting a lack of language diversity in NLP (Bender, 2011; Joshi et al., 2020).",
      "startOffset" : 113,
      "endOffset" : 147
    }, {
      "referenceID" : 15,
      "context" : "ceiving increasing attention (Blodgett et al., 2020), only 6.",
      "startOffset" : 29,
      "endOffset" : 52
    }, {
      "referenceID" : 87,
      "context" : "7%), sentiment analysis (100%), and language grounding (100%) is done only on English; however, ways of expressing sentiment (Volkova et al., 2013; Yang and Eisenstein, 2017; Vilares et al., 2018) and visually grounded reasoning (Liu et al.",
      "startOffset" : 125,
      "endOffset" : 196
    }, {
      "referenceID" : 92,
      "context" : "7%), sentiment analysis (100%), and language grounding (100%) is done only on English; however, ways of expressing sentiment (Volkova et al., 2013; Yang and Eisenstein, 2017; Vilares et al., 2018) and visually grounded reasoning (Liu et al.",
      "startOffset" : 125,
      "endOffset" : 196
    }, {
      "referenceID" : 86,
      "context" : "7%), sentiment analysis (100%), and language grounding (100%) is done only on English; however, ways of expressing sentiment (Volkova et al., 2013; Yang and Eisenstein, 2017; Vilares et al., 2018) and visually grounded reasoning (Liu et al.",
      "startOffset" : 125,
      "endOffset" : 196
    }, {
      "referenceID" : 53,
      "context" : ", 2018) and visually grounded reasoning (Liu et al., 2021; Yin et al., 2021) do vary across languages and cultures.",
      "startOffset" : 40,
      "endOffset" : 76
    }, {
      "referenceID" : 94,
      "context" : ", 2018) and visually grounded reasoning (Liu et al., 2021; Yin et al., 2021) do vary across languages and cultures.",
      "startOffset" : 40,
      "endOffset" : 76
    }, {
      "referenceID" : 68,
      "context" : "Notably, we only identified a single paper that considers three dimensions (Renduchintala et al., 2021).",
      "startOffset" : 75,
      "endOffset" : 103
    }, {
      "referenceID" : 91,
      "context" : "Only 1 in 8 papers did; the best paper (Xu et al., 2021), like most two-dimensional",
      "startOffset" : 39,
      "endOffset" : 56
    }, {
      "referenceID" : 0,
      "context" : "6 Of the 10 papers, only one included more than one dimension (Abdullah et al., 2021).",
      "startOffset" : 62,
      "endOffset" : 85
    }, {
      "referenceID" : 50,
      "context" : "guages with elaborate morphology due to data sparsity problems (Khudanpur, 2006; Bender, 2011; Gerz et al., 2018).",
      "startOffset" : 63,
      "endOffset" : 113
    }, {
      "referenceID" : 10,
      "context" : "guages with elaborate morphology due to data sparsity problems (Khudanpur, 2006; Bender, 2011; Gerz et al., 2018).",
      "startOffset" : 63,
      "endOffset" : 113
    }, {
      "referenceID" : 32,
      "context" : "guages with elaborate morphology due to data sparsity problems (Khudanpur, 2006; Bender, 2011; Gerz et al., 2018).",
      "startOffset" : 63,
      "endOffset" : 113
    }, {
      "referenceID" : 12,
      "context" : "models (Bilmes and Kirchhoff, 2003) that represent words as sets of features.",
      "startOffset" : 7,
      "endOffset" : 35
    }, {
      "referenceID" : 7,
      "context" : ", semantic tasks in morphologically rich languages (Avraham and Goldberg, 2017).",
      "startOffset" : 51,
      "endOffset" : 79
    }, {
      "referenceID" : 83,
      "context" : "Subword tokenization performs poorly on languages with reduplication (Vania and Lopez, 2017), while byte",
      "startOffset" : 69,
      "endOffset" : 92
    }, {
      "referenceID" : 16,
      "context" : "pair encoding does not align well with morphology (Bostrom and Durrett, 2020).",
      "startOffset" : 50,
      "endOffset" : 77
    }, {
      "referenceID" : 1,
      "context" : "Consequently, languages with productive morphological systems also are disadvantaged when shared ‘languageuniversal’ tokenizers are used in current large-scale multilingual language models (Ács, 2019; Rust et al., 2021) without any further vocabulary adaptation (Wang et al.",
      "startOffset" : 189,
      "endOffset" : 219
    }, {
      "referenceID" : 71,
      "context" : "Consequently, languages with productive morphological systems also are disadvantaged when shared ‘languageuniversal’ tokenizers are used in current large-scale multilingual language models (Ács, 2019; Rust et al., 2021) without any further vocabulary adaptation (Wang et al.",
      "startOffset" : 189,
      "endOffset" : 219
    }, {
      "referenceID" : 88,
      "context" : ", 2021) without any further vocabulary adaptation (Wang et al., 2020; Pfeiffer et al., 2021).",
      "startOffset" : 50,
      "endOffset" : 92
    }, {
      "referenceID" : 65,
      "context" : ", 2021) without any further vocabulary adaptation (Wang et al., 2020; Pfeiffer et al., 2021).",
      "startOffset" : 50,
      "endOffset" : 92
    }, {
      "referenceID" : 10,
      "context" : "This will occur more frequently in languages with relatively fixed word order compared to languages with relatively free word order (Bender, 2011).",
      "startOffset" : 132,
      "endOffset" : 146
    }, {
      "referenceID" : 60,
      "context" : "Word embedding approaches such as skip-gram (Mikolov et al., 2013) adhere to the same window-based approach and thus have similar weaknesses for languages with relatively free word order.",
      "startOffset" : 44,
      "endOffset" : 66
    }, {
      "referenceID" : 5,
      "context" : "They have also been shown to transfer worse to distant languages for dependency parsing compared to self-attention models (Ahmad et al., 2019).",
      "startOffset" : 122,
      "endOffset" : 142
    }, {
      "referenceID" : 74,
      "context" : "A recent unsupervised parsing algorithm (Shen et al., 2018) has been shown to be biased towards rightbranching structures and consequently performs better in right-branching languages like English",
      "startOffset" : 40,
      "endOffset" : 59
    }, {
      "referenceID" : 79,
      "context" : "While the recent generation of self-attention based architectures can be seen as inherently order-agnostic, recent methods focusing on making attention more efficient (Tay et al., 2020) introduce new biases into the models.",
      "startOffset" : 167,
      "endOffset" : 185
    }, {
      "referenceID" : 54,
      "context" : "ically, models that reduce the global attention to a local sliding window around the token (Liu et al., 2018; Child et al., 2019; Zaheer et al., 2020) may incur similar limitations as their n-gram and word embedding-based predecessors, performing worse on languages with relatively free word order.",
      "startOffset" : 91,
      "endOffset" : 150
    }, {
      "referenceID" : 19,
      "context" : "ically, models that reduce the global attention to a local sliding window around the token (Liu et al., 2018; Child et al., 2019; Zaheer et al., 2020) may incur similar limitations as their n-gram and word embedding-based predecessors, performing worse on languages with relatively free word order.",
      "startOffset" : 91,
      "endOffset" : 150
    }, {
      "referenceID" : 95,
      "context" : "ically, models that reduce the global attention to a local sliding window around the token (Liu et al., 2018; Child et al., 2019; Zaheer et al., 2020) may incur similar limitations as their n-gram and word embedding-based predecessors, performing worse on languages with relatively free word order.",
      "startOffset" : 91,
      "endOffset" : 150
    }, {
      "referenceID" : 69,
      "context" : "this topic; a recent example is BERTology (Rogers et al., 2020).",
      "startOffset" : 42,
      "endOffset" : 63
    }, {
      "referenceID" : 89,
      "context" : "Studies proposing more interpretable methods typically build on state-of-the-art methods (Weiss et al., 2018) and much work focuses on leveraging components such as attention for interpretability, which have not been designed with",
      "startOffset" : 89,
      "endOffset" : 109
    }, {
      "referenceID" : 38,
      "context" : "As a result, researchers eschew directions focusing on models that are intrinsically more interpretable such as generalized additive models (Hastie and Tibshirani, 2017) and their extensions (Chang et al.",
      "startOffset" : 140,
      "endOffset" : 169
    }, {
      "referenceID" : 18,
      "context" : "As a result, researchers eschew directions focusing on models that are intrinsically more interpretable such as generalized additive models (Hastie and Tibshirani, 2017) and their extensions (Chang et al., 2021; Agarwal et al., 2021) but which have so far not been shown to match the performance of state-of-the-art methods.",
      "startOffset" : 191,
      "endOffset" : 233
    }, {
      "referenceID" : 2,
      "context" : "As a result, researchers eschew directions focusing on models that are intrinsically more interpretable such as generalized additive models (Hastie and Tibshirani, 2017) and their extensions (Chang et al., 2021; Agarwal et al., 2021) but which have so far not been shown to match the performance of state-of-the-art methods.",
      "startOffset" : 191,
      "endOffset" : 233
    }, {
      "referenceID" : 25,
      "context" : "As most datasets on which models are evaluated focus on sentences or short documents, state-ofthe-art methods restrict their input size to around 512 tokens (Devlin et al., 2019) and leverage meth-",
      "startOffset" : 157,
      "endOffset" : 178
    }, {
      "referenceID" : 79,
      "context" : "wide range of more efficient models (Tay et al., 2020), which, however, are rarely used as baseline methods in NLP.",
      "startOffset" : 36,
      "endOffset" : 54
    }, {
      "referenceID" : 70,
      "context" : "Similarly, the standard pretrainfine-tune paradigm (Ruder et al., 2019) requires separate model copies to be stored for each task,",
      "startOffset" : 51,
      "endOffset" : 71
    }, {
      "referenceID" : 72,
      "context" : "and thus restricts work on multi-domain, multitask, multi-lingual, multi-subpopulation methods that is enabled by more efficient and less resourceintensive (Schwartz et al., 2020) fine-tuning methods (Houlsby et al.",
      "startOffset" : 156,
      "endOffset" : 179
    }, {
      "referenceID" : 76,
      "context" : "Sentiment, for example, can be annotated at the document, sentence or word level (Socher et al., 2013).",
      "startOffset" : 81,
      "endOffset" : 102
    }, {
      "referenceID" : 28,
      "context" : "In dependency parsing, different annotation guidelines can lead to very different downstream performance (Elming et al., 2013).",
      "startOffset" : 105,
      "endOffset" : 126
    }, {
      "referenceID" : 61,
      "context" : "The Universal Dependencies project (Nivre et al., 2020) is motivated by the observation that not all dependency formalisms are easily applicable to all languages.",
      "startOffset" : 35,
      "endOffset" : 55
    }, {
      "referenceID" : 22,
      "context" : "Aligning guidelines across languages has enabled researchers to ask interesting questions, but such attempts may limit the analysis of outlier languages (Croft et al., 2017).",
      "startOffset" : 153,
      "endOffset" : 173
    }, {
      "referenceID" : 36,
      "context" : "lead to severe model biases (Hansen and Søgaard, 2021a) and hurt model fairness.",
      "startOffset" : 28,
      "endOffset" : 55
    }, {
      "referenceID" : 67,
      "context" : "we can use feature attribution methods and wordlevel annotations to evaluate interpretability methods applied to sequence classifiers (Rei and Søgaard, 2018), but we cannot directly use feature attribution methods to obtain rationales for sequence",
      "startOffset" : 134,
      "endOffset" : 157
    }, {
      "referenceID" : 59,
      "context" : "Annotation biases can also stem from the characteristics of the annotators, including their domain experience (McAuley and Leskovec, 2013), demographics (Jørgensen and Søgaard, 2021), or educational level (Al Kuwatly et al.",
      "startOffset" : 110,
      "endOffset" : 138
    }, {
      "referenceID" : 45,
      "context" : "Annotation biases can also stem from the characteristics of the annotators, including their domain experience (McAuley and Leskovec, 2013), demographics (Jørgensen and Søgaard, 2021), or educational level (Al Kuwatly et al.",
      "startOffset" : 153,
      "endOffset" : 182
    }, {
      "referenceID" : 84,
      "context" : "models on such data typically overestimate their performance as properties such as word order and even the choice of lexical units are inherently biased by the source language (Vanmassenhove et al., 2021).",
      "startOffset" : 176,
      "endOffset" : 204
    }, {
      "referenceID" : 20,
      "context" : ", translation-based versus data collection directly in the target language (Clark et al., 2020) can yield profound differences in model performance for some groups, or may have serious impact on the interpretability or computational effi-",
      "startOffset" : 75,
      "endOffset" : 95
    }, {
      "referenceID" : 58,
      "context" : "For many years, the English Penn Treebank (Marcus et al., 1994) was an integral part of the SQUARE ONE of NLP.",
      "startOffset" : 42,
      "endOffset" : 63
    }, {
      "referenceID" : 47,
      "context" : "Since news articles tend to reflect a particular set of linguistic conventions, have a certain length, and are written by certain demographics, the bias toward news articles had an impact on the linguistic phenomena studied in NLP (Judge et al., 2006), led to under-representation of challenges with handling longer documents (Beltagy et al.",
      "startOffset" : 231,
      "endOffset" : 251
    }, {
      "referenceID" : 9,
      "context" : ", 2006), led to under-representation of challenges with handling longer documents (Beltagy et al., 2021), and had impact on early papers in fairness (Hovy and Sø-",
      "startOffset" : 82,
      "endOffset" : 104
    }, {
      "referenceID" : 42,
      "context" : "consequence, it is also standard protocol in multilingual NLP to use English as a source language in zero-shot cross-lingual transfer (Hu et al., 2020).",
      "startOffset" : 134,
      "endOffset" : 151
    }, {
      "referenceID" : 81,
      "context" : "In practice, there are generally better source languages than English (Lin et al., 2019; Turc et al., 2021), and results are heavily biased by the com-",
      "startOffset" : 70,
      "endOffset" : 107
    }, {
      "referenceID" : 65,
      "context" : "For instance, effectiveness and efficiency of few-shot learning can be impacted by the choice of the source language (Pfeiffer et al., 2021; Zhao et al., 2021).",
      "startOffset" : 117,
      "endOffset" : 159
    }, {
      "referenceID" : 97,
      "context" : "For instance, effectiveness and efficiency of few-shot learning can be impacted by the choice of the source language (Pfeiffer et al., 2021; Zhao et al., 2021).",
      "startOffset" : 117,
      "endOffset" : 159
    }, {
      "referenceID" : 55,
      "context" : "Character-based language models are often reported to perform well for morphologically rich languages or on non-canonical text (Ma et al., 2020), but little is known about their fairness properties, and attribution-based in-",
      "startOffset" : 127,
      "endOffset" : 144
    }, {
      "referenceID" : 41,
      "context" : "Annotation biases that stem from annotator demographics have been studied for English POS tagging (Hovy and Søgaard, 2015) or English summarization (Jørgensen and Søgaard,",
      "startOffset" : 98,
      "endOffset" : 122
    }, {
      "referenceID" : 3,
      "context" : ", interpretability techniques may affect the fairness of the underlying models (Agarwal, 2021), but rationales may also, for example, be bi-",
      "startOffset" : 79,
      "endOffset" : 94
    }, {
      "referenceID" : 31,
      "context" : "ased toward certain demographics in how they are presented (Feng and Boyd-Graber, 2018; González et al., 2021); (iii) finally, multilinguality and interpretability seem heavily underexplored.",
      "startOffset" : 59,
      "endOffset" : 110
    }, {
      "referenceID" : 34,
      "context" : "ased toward certain demographics in how they are presented (Feng and Boyd-Graber, 2018; González et al., 2021); (iii) finally, multilinguality and interpretability seem heavily underexplored.",
      "startOffset" : 59,
      "endOffset" : 110
    }, {
      "referenceID" : 29,
      "context" : "model evaluation, in line with recent proposals of more user-centric leaderboards (Ethayarajh and Jurafsky, 2020; Ma et al., 2021).",
      "startOffset" : 82,
      "endOffset" : 130
    }, {
      "referenceID" : 56,
      "context" : "model evaluation, in line with recent proposals of more user-centric leaderboards (Ethayarajh and Jurafsky, 2020; Ma et al., 2021).",
      "startOffset" : 82,
      "endOffset" : 130
    }, {
      "referenceID" : 39,
      "context" : ", to evaluate environmental impact (Henderson et al., 2020), as well as new benchmarks, e.",
      "startOffset" : 35,
      "endOffset" : 59
    } ],
    "year" : 0,
    "abstractText" : "The first NLP experiment many researchers performed in their careers likely involved training a standard architecture on labeled English data and optimizing for accuracy, without accounting for other dimensions such as fairness, interpretability, or computational efficiency. We show through surveys that this is indeed the case and refer to it as the square one experimental setup. NLP research often goes beyond the square one setup, e.g, focusing not only on accuracy, but also on fairness or interpretability, but typically only along a single dimension. Most work focused on multilinguality, for example, considers only accuracy; most work on fairness or interpretability considers only English; and so on. We show this through manual classification of recent NLP research papers and ACL Test-of-Time award recipients. Such one-dimensionality of most research means we are only exploring a fraction of the NLP research search space. We provide historical and recent examples of how the square one bias has led researchers to draw false conclusions or make unwise choices, point to promising yet unexplored directions on the research manifold, and make practical recommendations to enable more multi-dimensional research.",
    "creator" : null
  }
}