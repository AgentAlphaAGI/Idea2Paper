{
  "name" : "ARR_2022_78_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Learning Confidence for Transformer-based Neural Machine Translation",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Confidence estimation has become increasingly critical with the widespread deployment of deep neural networks in practice (Amodei et al., 2016). It aims to measure the model’s confidence in the prediction, showing when it probably fails. A calibrated confidence estimate can accurately identify failure, further measuring the potential risk induced by noisy samples and out-of-distribution data preva-\nSrc：\nRef：\n爱丽莎 的 扮演者 张艳 是 国家 一 级 演员\nelisa is played by zhang yan, a class-1 actress on the state level\nOurs：zhang yan , a figure who loves to play , is a national class actor\nlent in real scenarios (Nguyen and O’Connor, 2015; Snoek et al., 2019).\nUnfortunately, neural machine translation (NMT) is reported to yield poor-calibrated confidence estimate (Kumar and Sarawagi, 2019; Wang et al., 2020), which is common in the application of modern neural networks (Guo et al., 2017). It implies that the probability a model assigns to a prediction is not reflective of its correctness. Even worse, the model often fails silently by providing high-probability predictions while being woefully mistaken (Hendrycks and Gimpel, 2017). We take Figure 1 as an example. The mistranslations are produced with high probabilities (dark green blocks in the dashed box), making it problematic to assess the quality based on prediction probability when having no access to references.\nThe confidence estimation on classification tasks is well-studied in the literature (Platt, 1999; Guo et al., 2017). Yet, researches on structured generation tasks like NMT is scarce. Existing researches only study the phenomenon that the generated probability in NMT cannot reflect the accuracy (Müller et al., 2019; Wang et al., 2020), while little is known about how to establish a well-calibrated confidence estimate to describe the predictive uncertainty of the NMT model accurately.\nTo deal with this issue, we aim to learn the con-\nfidence estimate jointly with the training process in an unsupervised manner. Inspired by Ask For Hints (DeVries and Taylor, 2018), we explain confidence as how many hints the NMT model needs to make a correct prediction. Specifically, we design a scenario where ground truth is available for the NMT model as hints to deal with tricky translations. But each hint is given at the price of some penalty. Under this setting, the NMT model is encouraged to translate independently in most cases to avoid penalties but ask for hints to ensure a loss reduction when uncertain about the decision. More hints mean low confidence and vice versa. In practice, we design a confidence network, taking multi-layer hidden states of the decoder as inputs to predict the confidence estimate. Based on this, we further propose a novel confidence-based label smoothing approach, in which the translation more challenging to predict has more smoothing to its labels.\nRecall the example in Figure 1. The first phrase “a figure who loves to play” is incorrect, resulting in a low confidence level under our estimation. We notice that the NMT model is also uncertain about the second expression “a national class actor”, which is semantically related but has inaccurate wording. The translation accuracy largely agrees with our learned confidence rather than model probabilities.\nWe verify our confidence estimate as a wellcalibrated metrics on extensive sentence/word-level quality estimation tasks, which is proven to be more representative in predicting translation accuracy than existing unsupervised metrics (Fomicheva et al., 2020). Further analyses confirm that our confidence estimate can precisely detect potential risk caused by the distributional shift in two real-world settings: separating noisy samples and identifying out-of-domain data. The model needs more hints to predict fake or tricky translations in these cases, thus assigning them low confidence. Additionally, experimental results show the superiority of our confidence-based label smoothing over the standard label smoothing technique on different-scale translation tasks (WMT14 En⇒De, NIST Zh⇒En, WMT16 Ro⇒En, and IWSLT14 De⇒En).\nThe contributions of this paper are three-fold:\n• We propose the learned confidence estimate to predict the confidence of the NMT output, which is simple to implement without any degradation on the translation performance.\n• We prove our learned confidence estimate as a better indicator of translation accuracy on\nsentence/word-level quality estimation tasks. Furthermore, it enables precise assessment of risk when given noisy data with varying noise degrees and diverse out-of-domain datasets.\n• We design a novel confidence-based label smoothing method to adaptively tune the mass of smoothing based on the learned confidence level, which is experimentally proven to surpass the standard label smoothing technique."
    }, {
      "heading" : "2 Background",
      "text" : "In this section, we first briefly introduce a mainstream NMT framework, Transformer (Vaswani et al., 2017), with a focus on how to generate prediction probabilities. Then we present an analysis of the confidence miscalibration observed in NMT, which motivates our ideas discussed afterward."
    }, {
      "heading" : "2.1 Transformer-based NMT",
      "text" : "The Transformer has a stacked encoder-decoder structure. When given a pair of parallel sentences x = {x1, x2, ...xS} and y = {y1, y2, ...yT }, the encoder first transforms input to a sequence of continuous representations h = { h01, h 0 2, ...h 0 T } , which are then passed to the decoder. The decoder is composed of a stack of N identical blocks, each of which includes self-attention, cross-lingual attention, and a fully connected feedforward network. The outputs of l-th block hlt are fed to the successive block. At the t-th position, the model produces the translation probabilities pt, a vocabulary-sized vector, based on outputs of the N -th layer:\npt = softmax(Wh N t + b) (1)\nDuring training, the model is optimized by minimizing the cross entropy loss:\nLNMT = T∑ t=1 −ytlog(pt) (2)\nwhere {W , b} are trainable parameters and yt is denoted as a one-hot vector. During inference, we implement beam search by selecting high-probability tokens from generated probability for each step."
    }, {
      "heading" : "2.2 Confidence Miscalibration in NMT",
      "text" : "Modern neural networks have been found to yield a miscalibrated confidence estimate (Guo et al., 2017; Hendrycks and Gimpel, 2017). It means that\n0.0 0.5 1.0 0.06 0.08 0.10 0.12 0.14 De ns ity p=0.358 BAD 0.0 0.5 1.0 0.00 0.05 0.10 0.15 0.20 0.25 p=0.249\nPrediction Probability\nOK\nFigure 2: The density function of word probabilities predicted by the NMT model on OK and BAD translations. We outline the miscalibration with slash mark: over-confident (producing high probabilities for errors) and under-confident (generating low probabilities for right translations).\nthe prediction probability, as used at each inference step, is not reflective of its accuracy. The problem is more complex for structured outputs in NMT. We cannot judge a translation as an error, even if it differs from the ground truth, as several semantically equivalent translations exist for the same source sentence. Thus we manually annotate each target word as OK or BAD on 200 Zh⇒En translations. Only definite mistakes are labeled as BAD, while other uncertain translations are overlooked.\nFigure 2 reports the density function of prediction probabilities on OK and BAD translations. We observe severe miscalibration in NMT: overconfident problems account for 35.8% when the model outputs BAD translations, and 24.9% OK translations are produced with low probabilities. These issues make it challenging to identify model failure. It further drives us to establish an estimate to describe model confidence better."
    }, {
      "heading" : "3 Learning to Estimate Confidence",
      "text" : "A well-calibrated confidence estimate should be able to tell when the NMT model probably fails. Ideally, we would like to learn a measure of confidence for each target-side translation, but this remains a thorny problem in the absence of ground truth for confidence estimate. Inspired by Ask For Hints (DeVries and Taylor, 2018) on the image classification task, we define confidence as how many hints the NMT model needs to produce the correct translation. More hints mean low confidence, and that is a high possibility of failure.\nMotivation. We assume that the NMT model can ask for hints (look at ground-truth labels) during training, but each clue comes at the cost of a slight penalty. Intuitively, a good strategy is to independently make the predictions that the model is confi-\ndent about and then ask for clues when the model is uncertain about the decision. Under this assumption, we approximate the confidence level of each translation by counting the number of hints used.\nTo enable the NMT model to ask for hints, we add a confidence estimation network (ConNet) in parallel with the original prediction branch, as shown in Figure 3. The ConNet takes hidden states of the decoder at t-th step (ht) as inputs and predicts a single scalar between 0 and 1.\nct = σ(W ′ ht + b ′ ) (3)\nwhere θc = {W ′ , b ′} are trainable parameters. σ(·) is the sigmoid function. If the model is confident that it can translate correctly, it should output ct close to 1. Conversely, the model should output ct close to 0 for more hints.\nTo offer the model “hints” during training, we adjust softmax prediction probabilities by interpolating the ground truth probability distribution yt (denoted as a one-hot vector) into the original prediction. The degree of interpolation is decided by the generated confidence ct:\np ′ t = ct · pt + (1− ct) · yt (4)\nThe translation loss is calculated using modified prediction probabilities.\nLNMT = T∑ t=1 −ytlog(p ′ t) (5)\nTo prevent the model from minimizing the loss by always setting ct = 0 (receiving all the ground truth), we add a log penalty to the loss function.\nLConf = −log(ct) (6)\nThe final loss is the sum of the translation loss and the confidence loss, which is weighted by the hyper-parameter λ:\nL = LNMT + λLConf (7)\nUnder this setting, when c → 1 (the model is quite confident), we can see that p\n′ → p and LConf → 0, which is equal to a standard training procedure. In the case where c → 0 (the model is quite unconfident), we see that p\n′ → y (the model obtains correct labels). In this scenario, LNMT would approach 0, but LConf becomes very large. Thus, the model can reduce the overall loss only when it successfully predicts which outputs are likely to be correct.\nImplementation Details. Due to the complexity of Transformer architecture, it requires several optimizations to prevent the confidence branch from degrading the performance of the translation branch.\nDo not provide hints at the initial stage. The early model is fragile, which lays the groundwork for the following optimization. We find that affording hints at an early period leads to a significant performance drop. To this end, we propose to dynamically control the value of λ (as in Equation 7) by the training step (s) as:\nλ(s) = λ0 ∗ e−s/β0 (8)\nwhere λ0 and β0 control the initial value and the declining speed of λ. We expect the weight of confidence loss to be large at the beginning (c → 1) and give hints during middle and later stages.\nDo not use high-layer hidden states to predict confidence. We find that it would add much burden to the highest layer hidden state if used to predict translation and confidence simultaneously. So we suggest using low-layer hidden states for the confidence branch and leaving the translation branch unchanged (here, the decoder has 6 layers):\nht = AVE(h 1 t + h 2 t + h 3 t ) (9)\nwhere hlt is the l-th layer hidden state in the decoder. Besides, other combinations of low-layer hidden states are alternative, i.e., ht = AVE(h1t + h 3 t ).\nDo not let the model lazily learn complex examples. We encounter the situation where the model frequently requests hints rather than learning from difficulty. We follow DeVries and Taylor (2018) to give hints with 50% probability. In practice, we apply Equation 4 to only half of the batch.\nConfidence-based Label Smoothing. Smoothing labels is a typical way to prevent the network from miscalibration (Müller et al., 2019). It has been used in many state-of-the-art models, which\nassigns a certain probability mass (ϵ0) to other nonground-truth labels (Szegedy et al., 2016). Here we attempt to employ our confidence estimate to improve smoothing. We propose a novel instancespecific confidence-based label smoothing technique, where predictions with greater confidence receive less label smoothing and vice versa. The amount of label smoothing applied to a prediction (ϵt) is proportional to its confidence level.\nϵt = ϵ0 ∗ e1− ct ĉ\nwhere ϵ0 is the fixed value for vanilla label smoothing, ĉ is the batch-level average confidence level."
    }, {
      "heading" : "4 Experiments",
      "text" : "This section first exhibits empirical studies on the Quality Estimation (QE) task, a primary application of confidence estimation. Then, we present experimental results of our confidence-based label smoothing, an extension of our confidence estimate to better smoothing in NMT."
    }, {
      "heading" : "4.1 Confidence-based Quality Estimation",
      "text" : "To evaluate the ability of our confidence estimate on mistake prediction, we experiment on extensive sentence/word-level QE tasks. Supervised QE task requires large amounts of parallel data annotated with the human evaluation, which is labor-intensive and impractical for low-resource languages. Here, we propose to address QE in an unsupervised way along with the training of the NMT model."
    }, {
      "heading" : "4.1.1 Sentence-level Quality Estimation",
      "text" : "We experiment on WMT2020 QE shared tasks1, including high-resource language pairs (EnglishGerman and English-Chinese) and mid-resource language pairs (Estonian-English and RomanianEnglish). This task provides source language sentences, corresponding machine translations, and\n1http://www.statmt.org/wmt20/quality-estimationtask.html\nNMT models used to generate translation. Each translation is annotated with direct assessment (DA) by professional translators, ranging from 0- 100, according to the perceived translation quality. We can evaluate the performance of QE in terms of Pearson’s correlation with DA scores.\nWe compare our confidence estimate with four unsupervised QE metrics (Fomicheva et al., 2020):\n• TP: the sentence-level translation probability normalized by length T .\n• Softmax-Ent: the average entropy of softmax output distribution at each decoding step.\n• Sent-Std: the standard deviation of word-level log-probability p(y1), ..., p(yT ).\n• D-TP: the expectation for the set of TP scores by running K stochastic forward passes through the NMT model with model parameters θ̂k perturbed by Monte Carlo (MC) dropout (Gal and Ghahramani, 2016).\nWe also report two supervised QE models:\n• Predictor-Estimator (Kim et al., 2017): a weak neural approach, which is usually set as the baseline system for supervised QE tasks.\n• BERT-BiRNN (Kepler et al., 2019b): a strong QE model using a large-scale dataset for pretraining and quality labels for fine-tuning.\nWe propose four confidence-based metrics: (1) Conf : the sentence-level confidence estimate averaged by length, (2) Sent-Std-Conf : the standard deviation of word-level log-confidence c1, ..., cT , (3) D-Conf : similar to D-TP, we compute the expectation of Conf by running K forward passes through the NMT model, and (4) D-Comb: the combination of D-TP and D-Conf:\nD-Comb = 1\nK K∑ k=1 (Conf θ̂k +TPθ̂k) (10)\nNote that our confidence estimate is produced together with translations. It is hard to let our model generate exact translations as provided by WMT, even with a similar configuration. Thus, we train our model on parallel sentences as used to train provided NMT models. Then, we employ force decoding on given translations to obtain existing unsupervised metrics and our estimations. We do not use any human judgment labels for supervision.\nTable 1 shows the Pearson’s correlation with DA scores for the above QE indicators. We find that:\nOur confidence-based metrics substantially surpass probability-based metrics (the first three lines in Table 1). Compared with dropout-based methods (D-TP), our metrics obtain comparable results on mid-resource datasets while yielding better performance on high-resource translation tasks. We note that the benefits brought from the MC dropout strategy are limited for our metrics, which is significant in probability-based methods. It also proves the stability of our confidence estimate. In addition, the predictive power of MC dropout comes at the cost of computation, as performing forward passes through the NMT model is time-consuming and impractical for the large-scale dataset.\nOur approach outperforms PredEst, a weak supervised method, on three tasks and further narrows the gap on Ro-En. Though existing unsupervised QE methods still fall behind with the strong QE model (BERT-BiRNN), the exploration of unsupervised metrics is also meaningful for real-world deployment with the limited annotated dataset."
    }, {
      "heading" : "4.1.2 Word-level Quality Estimation",
      "text" : "We also validate the effectiveness of our confidence estimate on QE tasks from a more finegrained view. We randomly select 250 sentences from Zh⇒En NIST03 and obtain NMT translations. Two graduate students are asked to annotate each target word as either OK or BAD. We assess the performance of failure prediction with standard metrics, which are introduced in Appendix A.\nExperimental results are given in Table 3. We implement competitive failure prediction approaches, including Maximum Softmax Probability (MSP) (Hendrycks and Gimpel, 2017) and Monte Carlo Dropout (MCDropout) (Gal and Ghahramani, 2016). We find that our learned confidence estimate yields a better separation of OK and BAD translation than MSP. Compared with MCDropout, our metrics achieve competing performance with significant advantages on computational expenses.\nOverall, the learned confidence estimate is a competitive indicator of translation precision compared with other unsupervised QE metrics. Moreover, the confidence branch added to the NMT system is a light component. It allows each translation to come with quality measurement without degradation of the translation accuracy. The performance with the confidence branch is in Appendix B."
    }, {
      "heading" : "4.2 Confidence-based Label Smoothing",
      "text" : "We extend our confidence estimate to improve smoothing and experiment on different-scale translation tasks: WMT14 English-to-German (En⇒De), LDC Chinese-to-English (Zh⇒En)2, WMT16 Romanian-to-English (Ro⇒En), and IWSLT14 German-to-English (De⇒En). We use the 4-gram BLEU (Papineni et al., 2002) to score the performance. More details about data processing and experimental settings are in Appendix C.\n2The corpora includes LDC2000T50, LDC2002T01, LDC2002E18, LDC2003E07, LDC2003E14, LDC2003T17, and LDC2004T07.\nTable 2 presents the translation performance. Our confidence-based label smoothing outperforms standard label smoothing by adaptively tuning the amount of each label smoothing. For Zh⇒En task, our method improves the performance over Transformer w/o LS by 0.95 BLEU, which also exceeds standard label smoothing by 0.62 BLEU. We find that improvements over standard label smoothing differ in other language pairs (0.35 BLEU in En⇒De, 0.5 BLEU in De⇒En, and 0.79 BLEU in Ro⇒En). It can be attributed to that the seriousness of miscalibration varies in different language pairs and datasets (Wang et al., 2020)."
    }, {
      "heading" : "5 Analysis",
      "text" : "Confidence estimation is particularly critical in realworld deployment, where noisy samples and out-ofdistribution data are prevalent (Snoek et al., 2019). Given those abnormal inputs, neural network models are prone to be highly confident in misclassification (Nguyen et al., 2015). Thus, we need an accurate confidence estimate to detect potential failures caused by odd inputs by assigning them low confidence. This section explores whether our confidence estimate can accurately measure risk under those two conditions."
    }, {
      "heading" : "5.1 Noisy Label Identification",
      "text" : "We expect that the model requires more hints to fit noisy labels by predicting low confidence. To test this point, we experiment on the IWSLT14 De⇒En dataset containing 160k parallel sentences. We build several datasets with progressively increasing noisy samples by randomly replacing target-side words with others in the vocabulary. We train on each dataset with the same configuration and picture the learned confidence estimate in Figure 4.\nThe learned confidence estimate appears to make reasonable assessments. (1) It predicts low confidence on noisy samples but high confidence on clean ones. Specifically, the confidence estimate is\nmuch lower as a higher pollution degree in one example (darker in color). (2) With increasing noises in the dataset, the NMT model becomes more uncertain about its decision accordingly. Large numbers of noises also raise a challenge for separating clean and noisy samples.\nWe also compare ours with the model probability by giving the accuracy of separating clean and noisy examples under varying pollution rates. We set clean data as the positive example and use evaluation metrics listed in Appendix A.\nAs shown in Table 4, our confidence estimate obtains better results in all cases, especially in a high noise rate. Our metric improves the area under\nthe precision-recall curve (AUPR) from 64.15% to 76.76% and reduces the detection error (DET) from 13.41% to 8.13% at an 80% noise rate. It proves that our confidence estimate is more reliable for detecting potential risks induced by noisy data."
    }, {
      "heading" : "5.2 Out-of-Domain Data Detection",
      "text" : "For our in-domain examples, we train an NMT model on the 2.1M LDC Zh⇒En news dataset and then sample 1k sentences from NIST2004 as the in-domain testbed. We select five out-of-domain datasets and extract 1k samples from each. Most of them are available for download on OPUS, specified in Appendix D. Regarding the unknown words (UNK) rate, the average length of input sentences, and domain diversity, the descending order based on distance with the in-domain dataset is WMTnews > Tanzil > Tico-19 > TED2013 > NewsCommentary. Test sets closer to the in-domain dataset are intuitively harder to tell apart.\nWe use sentence-level posterior probability and confidence estimate of the translation to separate in- and out-of-domain data. Evaluation metrics are in Appendix A. Results are given in Table 5.\nWe find that our approach performs comparably with the probability-based method on datasets with distinct domains (WMT-news and Tanzil). But when cross-domain knowledge is harder to detect (the last three lines in Table 5), our metric yields a better separation of in- and out-of-domain ones.\nTo better understand the behaviour of our confidence estimates on out-of-domain data, we visualize word clouds of the most confident/uncertain words ranked by model probability and our measurements on a medicine dataset (Tico-19) in Figure 5. The colors of words indicate their frequencies in the in-domain dataset.\nOur metrics correctly separate in- and out-ofdomain data from two aspects: (1) word frequency: the NMT model is certain about frequent words yet hesitates on rare words as seen in Figure 5(b). But colors in Figure 5(a) are relatively mixing. (2) domain relation: the most uncertain words ranked by our confidence estimate are domain-related, like “patho” and “syndrome”, while the most confident words are domain-unrelated (e.g., punctuations and prepositions). This phenomenon cannot be seen in Figure 5(a), showing that probabilities from softmax fall short in representing model uncertainty for domain-shift data."
    }, {
      "heading" : "6 Related Work",
      "text" : "The task of confidence estimation is crucial in realworld conditions, which helps failure prediction (Corbière et al., 2019) and out-of-distribution detection (Hendrycks and Gimpel, 2017; Snoek et al., 2019; Lee et al., 2018). This section reviews recent researches on confidence estimation and related applications on quality estimation for NMT."
    }, {
      "heading" : "6.1 Confidence Estimation for NMT",
      "text" : "Only a few studies have investigated calibration in NMT. Müller et al. (2019) find that the NMT model is well-calibrated in training, which is proven severely miscalibrated in inference (Wang et al., 2020), especially when predicting the end of a sentence (Kumar and Sarawagi, 2019). Regarding the complex structures of NMT, the exploration for fixing miscalibration in NMT is scarce. Wang et al. (2019); Xiao et al. (2020) use Monte Carlo dropout to capture uncertainty in NMT, which is time-consuming and computationally expensive. Unlike them, we are the first to introduce learned confidence estimate into NMT. Our method is welldesigned to adapt to Transformer architecture and NMT tasks, which is also simple but effective."
    }, {
      "heading" : "6.2 Quality Estimation for NMT",
      "text" : "QE is to predict the quality of the translation provided by an MT system at test time without standard references. Recent supervised QE models are resource-heavy and require a large mass of annotated quality labels for training (Wang et al., 2018; Kepler et al., 2019a), which is labor-consuming and unavailable for low-resource languages.\nExploring internal information from the NMT system to indicate translation quality is another alternative. Fomicheva et al. (2020) find that uncertainty quantification is competitive in predicting the translation quality, which is also complementary to supervised QE model (Wang et al., 2021). However, they rely on repeated Monte Carlo dropout (Gal and Ghahramani, 2016) to assess uncertainty at the high cost of computation. Our confidence estimate outperforms existing unsupervised QE metrics, which is also intuitive and easy to implement."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this paper, we propose to learn confidence estimates for NMT jointly with the training process. We demonstrate that learned confidence can better indicate translation accuracy on extensive sentence/word-level QE tasks and precisely measures potential risk induced by noisy samples or out-of-domain data. We further extend the learned confidence estimate to improve smoothing, outperforming the standard label smoothing technique. As our confidence estimate outlines how much the model knows, we plan to apply our work to design a more suitable curriculum during training and post-edit low-confidence translations in the future."
    }, {
      "heading" : "A Evaluation Metrics",
      "text" : "We let TP, FP, TN, and FN represent true positives, false positives, true negatives, and false negatives. We use the following metrics for evaluating the accuracy of word-level QE, noisy label identification, and out-of-domain detection:\n• AUROC: the Area Under the Receiver Operating Characteristic (ROC) curve, which plots the relation between TPR and FPR.\n• AUPR: the Area Under the Precision-Recall (PR) curve. The PR curve is made by plotting precision = TP/(TP+FP) and recall = TP/(TP+FN).\n• DET: the Detection Error, which is the minimum possible misclassification probability over all possible threshold when separating positive and negative examples.\n• EER: the Equal error rate. It is the error rate when the confidence threshold is located where FPR is the same with the false negative rate (FNR) = FN / (TP+FN).\nWe set OK translations in the word-level QE task, clean samples in the noisy data identification task, and in-domain samples in the out-of-domain data detection task as the positive example."
    }, {
      "heading" : "B Translation Results with the Confidence Branch",
      "text" : "The confidence branch added to the NMT system is a light component. It allows each translation to come with quality measurement without degradation of the translation accuracy. Translation results with the confidence branch are given in Table 6.\nWe see that the added confidence branch does not affect the translation performance. Implementation details in section 3 are necessary for achieving this. For instance, if we use the highest hidden state to predict confidence and translation together, BLEU scores would dramatically decline with a larger beam size, the drop of which is more significant than that of the baseline model. For the En⇒De task, the change is from 27.31 (beam size 4) to 25.6 (beam size 100), while the baseline model even improves 0.5 BLEU further with a larger beam size 100."
    }, {
      "heading" : "C Experimental Settings for Confidence-based Label Smoothing",
      "text" : "We experiment on different-scale translation tasks: WMT14 En⇒De, LDC Zh⇒En, WMT16 Ro⇒En, and IWSLT14 De⇒En.\nDatasets. We tokenize the corpora by Moses (Koehn et al., 2007). Byte pair encoding (BPE) (Sennrich et al., 2016) is applied to all language pairs to construct a join 32k vocabulary except for Zh⇒En where the source and target languages are separately encoded.\nFor En⇒De, we train on 4.5M training samples. Newstest2013 and newstest2014 are set as validation and test sets. For Zh⇒En, we remove sentences of more than 50 words and collect 2.1M training samples. We use NIST 2002 as the validation set, NIST 2003-2006 (MT03-06), and 2008 (MT08) as the testbed. For Ro⇒En, we train on 0.61M training data and use newsdev2016 and newstest2016 as validation and test sets. For De⇒En, we train on its training set with 160k training samples and evaluate on its test set.\nSettings. We implement the described model with fairseq5 toolkit for training and evaluating. We follow Vaswani et al. (2017) to set the configurations of models with the base Transformer. The dropout rate of the residual connection is 0.1 except for Zh⇒En (0.3). The experiments last for 150k steps for Zh⇒En and En⇒De, 30k for smallscale De⇒En and Ro⇒En. We average the last ten checkpoints for evaluation and adopt beam search (beam size 4, length penalty 0.6). We set ϵls = 0.1 for the vanilla label smoothing.\nThe hyper-parameters λ0 and β0 (as seen Equation 8) control the initial value and declining speed of λ (as in Equation 7), which decides the number of hints the NMT model can receive. To ensure that no hints are available at the early stage of training, we set λ0 = 30, β0 = 4.5 ∗ 104 for Zh⇒En and En⇒De, β0 = 1.2 ∗ 104 for De⇒En and Ro⇒En. We set ϵ0 = 0.1 (as seen in Equation 10) for all language pairs."
    }, {
      "heading" : "D Out-of-domain Data Detection",
      "text" : "We select five out-of-domain datasets for our tests (we extract 1k samples each), which are available for download on OPUS3. The datasets are:\n5https://github.com/pytorch/fairseq 3https://opus.nlpl.eu/\nMethods Zh⇒En En⇒De De⇒En MT03 MT04 MT05 MT06 MT08 ALL\nTransformer 49.14 48.48 50.53 47.44 36.23 45.83 27.40 34.52 + ConNet 49.51 48.47 50.51 47.29 36.44 45.90 27.55 34.73"
    } ],
    "references" : [ {
      "title" : "Concrete problems in AI safety",
      "author" : [ "Dario Amodei", "Chris Olah", "Jacob Steinhardt", "Paul F. Christiano", "John Schulman", "Dan Mané." ],
      "venue" : "CoRR, abs/1606.06565.",
      "citeRegEx" : "Amodei et al\\.,? 2016",
      "shortCiteRegEx" : "Amodei et al\\.",
      "year" : 2016
    }, {
      "title" : "Addressing failure prediction by learning model confidence",
      "author" : [ "Charles Corbière", "Nicolas Thome", "Avner Bar-Hen", "Matthieu Cord", "Patrick Pérez." ],
      "venue" : "Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information",
      "citeRegEx" : "Corbière et al\\.,? 2019",
      "shortCiteRegEx" : "Corbière et al\\.",
      "year" : 2019
    }, {
      "title" : "Learning confidence for out-of-distribution detection in neural networks",
      "author" : [ "Terrance DeVries", "Graham W. Taylor." ],
      "venue" : "CoRR, abs/1802.04865.",
      "citeRegEx" : "DeVries and Taylor.,? 2018",
      "shortCiteRegEx" : "DeVries and Taylor.",
      "year" : 2018
    }, {
      "title" : "Unsupervised quality estimation for neural machine translation",
      "author" : [ "Marina Fomicheva", "Shuo Sun", "Lisa Yankovskaya", "Frédéric Blain", "Francisco Guzmán", "Mark Fishel", "Nikolaos Aletras", "Vishrav Chaudhary", "Lucia Specia." ],
      "venue" : "Transactions of the Association",
      "citeRegEx" : "Fomicheva et al\\.,? 2020",
      "shortCiteRegEx" : "Fomicheva et al\\.",
      "year" : 2020
    }, {
      "title" : "Dropout as a bayesian approximation: Representing model uncertainty in deep learning",
      "author" : [ "Yarin Gal", "Zoubin Ghahramani." ],
      "venue" : "Proceedings of the 33nd International Conference on Machine Learning, ICML 2016, volume 48, pages 1050–1059. JMLR.org.",
      "citeRegEx" : "Gal and Ghahramani.,? 2016",
      "shortCiteRegEx" : "Gal and Ghahramani.",
      "year" : 2016
    }, {
      "title" : "On calibration of modern neural networks",
      "author" : [ "Chuan Guo", "Geoff Pleiss", "Yu Sun", "Kilian Q. Weinberger." ],
      "venue" : "Proceedings of the 34th International Conference on Machine Learning, ICML 2017, volume 70 of Proceedings of Machine Learning Re-",
      "citeRegEx" : "Guo et al\\.,? 2017",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2017
    }, {
      "title" : "A baseline for detecting misclassified and out-of-distribution examples in neural networks",
      "author" : [ "Dan Hendrycks", "Kevin Gimpel." ],
      "venue" : "5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track",
      "citeRegEx" : "Hendrycks and Gimpel.,? 2017",
      "shortCiteRegEx" : "Hendrycks and Gimpel.",
      "year" : 2017
    }, {
      "title" : "Unbabel’s participation in the WMT19 translation quality estimation shared task",
      "author" : [ "Fabio Kepler", "Jonay Trénous", "Marcos Treviso", "Miguel Vera", "António Góis", "M. Amin Farajian", "António V. Lopes", "André F.T. Martins." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Kepler et al\\.,? 2019a",
      "shortCiteRegEx" : "Kepler et al\\.",
      "year" : 2019
    }, {
      "title" : "Unbabel’s participation in the WMT19 translation quality estimation shared task",
      "author" : [ "Fabio Kepler", "Jonay Trénous", "Marcos V. Treviso", "Miguel Vera", "António Góis", "M. Amin Farajian", "António V. Lopes", "André F.T. Martins." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Kepler et al\\.,? 2019b",
      "shortCiteRegEx" : "Kepler et al\\.",
      "year" : 2019
    }, {
      "title" : "Predictor-estimator using multilevel task learning",
      "author" : [ "Hyun Kim", "Jong-Hyeok Lee", "Seung-Hoon Na" ],
      "venue" : null,
      "citeRegEx" : "Kim et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2017
    }, {
      "title" : "Calibration of encoder decoder models for neural machine translation",
      "author" : [ "Aviral Kumar", "Sunita Sarawagi." ],
      "venue" : "CoRR, abs/1903.00802.",
      "citeRegEx" : "Kumar and Sarawagi.,? 2019",
      "shortCiteRegEx" : "Kumar and Sarawagi.",
      "year" : 2019
    }, {
      "title" : "A simple unified framework for detecting outof-distribution samples and adversarial attacks",
      "author" : [ "Kimin Lee", "Kibok Lee", "Honglak Lee", "Jinwoo Shin." ],
      "venue" : "Advances in Neural Information Processing Systems, volume 31, pages 7167–7177. Curran Associates Inc.",
      "citeRegEx" : "Lee et al\\.,? 2018",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2018
    }, {
      "title" : "When does label smoothing help",
      "author" : [ "Rafael Müller", "Simon Kornblith", "Geoffrey E. Hinton" ],
      "venue" : "In Advances in Neural Information Processing Systems 32: Annual Conference on Neural Information Processing Systems",
      "citeRegEx" : "Müller et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Müller et al\\.",
      "year" : 2019
    }, {
      "title" : "Deep neural networks are easily fooled: High confidence predictions for unrecognizable images",
      "author" : [ "Anh Mai Nguyen", "Jason Yosinski", "Jeff Clune." ],
      "venue" : "IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, pages 427–436.",
      "citeRegEx" : "Nguyen et al\\.,? 2015",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2015
    }, {
      "title" : "Posterior calibration and exploratory analysis for natural language processing models",
      "author" : [ "Khanh Nguyen", "Brendan O’Connor" ],
      "venue" : "In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Nguyen and O.Connor.,? \\Q2015\\E",
      "shortCiteRegEx" : "Nguyen and O.Connor.",
      "year" : 2015
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318. Association for",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods",
      "author" : [ "John C. Platt." ],
      "venue" : "Advances in Large Margin Classifiers.",
      "citeRegEx" : "Platt.,? 1999",
      "shortCiteRegEx" : "Platt.",
      "year" : 1999
    }, {
      "title" : "Neural machine translation of rare words with subword units",
      "author" : [ "Rico Sennrich", "Barry Haddow", "Alexandra Birch." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715–1725.",
      "citeRegEx" : "Sennrich et al\\.,? 2016",
      "shortCiteRegEx" : "Sennrich et al\\.",
      "year" : 2016
    }, {
      "title" : "Can you trust your model’s uncertainty? evaluating predictive uncertainty under dataset shift",
      "author" : [ "Jasper Snoek", "Yaniv Ovadia", "Emily Fertig", "Balaji Lakshminarayanan", "Sebastian Nowozin", "D. Sculley", "Joshua V. Dillon", "Jie Ren", "Zachary Nado." ],
      "venue" : "Ad-",
      "citeRegEx" : "Snoek et al\\.,? 2019",
      "shortCiteRegEx" : "Snoek et al\\.",
      "year" : 2019
    }, {
      "title" : "Rethinking the inception architecture for computer vision",
      "author" : [ "Christian Szegedy", "Vincent Vanhoucke", "Sergey Ioffe", "Jonathon Shlens", "Zbigniew Wojna." ],
      "venue" : "2016 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2016, pages 2818–",
      "citeRegEx" : "Szegedy et al\\.,? 2016",
      "shortCiteRegEx" : "Szegedy et al\\.",
      "year" : 2016
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "undefinedukasz Kaiser", "Illia Polosukhin" ],
      "venue" : "In Proceedings of the 31st International Conference on Neural Information Processing",
      "citeRegEx" : "Vaswani et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Alibaba submission for WMT18 quality estimation task",
      "author" : [ "Jiayi Wang", "Kai Fan", "Bo Li", "Fengming Zhou", "Boxing Chen", "Yangbin Shi", "Luo Si." ],
      "venue" : "Proceedings of the Third Conference on Machine Translation: Shared Task Papers, pages 809–815. Associa-",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "Beyond glassbox features: Uncertainty quantification enhanced quality estimation for neural machine translation",
      "author" : [ "Ke Wang", "Yangbin Shi", "Jiayi Wang", "Yuqi Zhang", "Yu Zhao", "Xiaolin Zheng." ],
      "venue" : "Findings of the Association for Computational Lin-",
      "citeRegEx" : "Wang et al\\.,? 2021",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2021
    }, {
      "title" : "Improving back-translation with uncertainty-based confidence estimation",
      "author" : [ "Shuo Wang", "Yang Liu", "Chao Wang", "Huanbo Luan", "Maosong Sun." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th",
      "citeRegEx" : "Wang et al\\.,? 2019",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "On the inference calibration of neural machine translation",
      "author" : [ "Shuo Wang", "Zhaopeng Tu", "Shuming Shi", "Yang Liu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020, pages 3070–3079.",
      "citeRegEx" : "Wang et al\\.,? 2020",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "Wat zei je? detecting out-of-distribution translations with variational transformers",
      "author" : [ "Tim Z. Xiao", "Aidan N. Gomez", "Yarin Gal." ],
      "venue" : "CoRR, abs/2006.08344. 10",
      "citeRegEx" : "Xiao et al\\.,? 2020",
      "shortCiteRegEx" : "Xiao et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Confidence estimation has become increasingly critical with the widespread deployment of deep neural networks in practice (Amodei et al., 2016).",
      "startOffset" : 122,
      "endOffset" : 143
    }, {
      "referenceID" : 10,
      "context" : "Unfortunately, neural machine translation (NMT) is reported to yield poor-calibrated confidence estimate (Kumar and Sarawagi, 2019; Wang et al., 2020), which is common in the application of modern neural networks (Guo et al.",
      "startOffset" : 105,
      "endOffset" : 150
    }, {
      "referenceID" : 24,
      "context" : "Unfortunately, neural machine translation (NMT) is reported to yield poor-calibrated confidence estimate (Kumar and Sarawagi, 2019; Wang et al., 2020), which is common in the application of modern neural networks (Guo et al.",
      "startOffset" : 105,
      "endOffset" : 150
    }, {
      "referenceID" : 5,
      "context" : ", 2020), which is common in the application of modern neural networks (Guo et al., 2017).",
      "startOffset" : 70,
      "endOffset" : 88
    }, {
      "referenceID" : 6,
      "context" : "Even worse, the model often fails silently by providing high-probability predictions while being woefully mistaken (Hendrycks and Gimpel, 2017).",
      "startOffset" : 115,
      "endOffset" : 143
    }, {
      "referenceID" : 16,
      "context" : "The confidence estimation on classification tasks is well-studied in the literature (Platt, 1999; Guo et al., 2017).",
      "startOffset" : 84,
      "endOffset" : 115
    }, {
      "referenceID" : 5,
      "context" : "The confidence estimation on classification tasks is well-studied in the literature (Platt, 1999; Guo et al., 2017).",
      "startOffset" : 84,
      "endOffset" : 115
    }, {
      "referenceID" : 12,
      "context" : "Existing researches only study the phenomenon that the generated probability in NMT cannot reflect the accuracy (Müller et al., 2019; Wang et al., 2020), while little is known about how to establish a well-calibrated confidence estimate to describe the predictive uncertainty of the NMT model accurately.",
      "startOffset" : 112,
      "endOffset" : 152
    }, {
      "referenceID" : 24,
      "context" : "Existing researches only study the phenomenon that the generated probability in NMT cannot reflect the accuracy (Müller et al., 2019; Wang et al., 2020), while little is known about how to establish a well-calibrated confidence estimate to describe the predictive uncertainty of the NMT model accurately.",
      "startOffset" : 112,
      "endOffset" : 152
    }, {
      "referenceID" : 2,
      "context" : "Inspired by Ask For Hints (DeVries and Taylor, 2018), we explain confidence as how many hints the NMT model needs to make a correct prediction.",
      "startOffset" : 26,
      "endOffset" : 52
    }, {
      "referenceID" : 20,
      "context" : "In this section, we first briefly introduce a mainstream NMT framework, Transformer (Vaswani et al., 2017), with a focus on how to generate prediction probabilities.",
      "startOffset" : 84,
      "endOffset" : 106
    }, {
      "referenceID" : 5,
      "context" : "Modern neural networks have been found to yield a miscalibrated confidence estimate (Guo et al., 2017; Hendrycks and Gimpel, 2017).",
      "startOffset" : 84,
      "endOffset" : 130
    }, {
      "referenceID" : 6,
      "context" : "Modern neural networks have been found to yield a miscalibrated confidence estimate (Guo et al., 2017; Hendrycks and Gimpel, 2017).",
      "startOffset" : 84,
      "endOffset" : 130
    }, {
      "referenceID" : 2,
      "context" : "Inspired by Ask For Hints (DeVries and Taylor, 2018) on the image classification task, we define confidence as how many hints the NMT model needs to produce the correct translation.",
      "startOffset" : 26,
      "endOffset" : 52
    }, {
      "referenceID" : 12,
      "context" : "Smoothing labels is a typical way to prevent the network from miscalibration (Müller et al., 2019).",
      "startOffset" : 77,
      "endOffset" : 98
    }, {
      "referenceID" : 19,
      "context" : "It has been used in many state-of-the-art models, which assigns a certain probability mass (ε0) to other nonground-truth labels (Szegedy et al., 2016).",
      "startOffset" : 128,
      "endOffset" : 150
    }, {
      "referenceID" : 4,
      "context" : "• D-TP: the expectation for the set of TP scores by running K stochastic forward passes through the NMT model with model parameters θ̂k perturbed by Monte Carlo (MC) dropout (Gal and Ghahramani, 2016).",
      "startOffset" : 174,
      "endOffset" : 200
    }, {
      "referenceID" : 9,
      "context" : "• Predictor-Estimator (Kim et al., 2017): a weak neural approach, which is usually set as the baseline system for supervised QE tasks.",
      "startOffset" : 22,
      "endOffset" : 40
    }, {
      "referenceID" : 8,
      "context" : "• BERT-BiRNN (Kepler et al., 2019b): a strong QE model using a large-scale dataset for pretraining and quality labels for fine-tuning.",
      "startOffset" : 13,
      "endOffset" : 35
    }, {
      "referenceID" : 6,
      "context" : "We implement competitive failure prediction approaches, including Maximum Softmax Probability (MSP) (Hendrycks and Gimpel, 2017) and Monte Carlo Dropout (MCDropout) (Gal and Ghahramani, 2016).",
      "startOffset" : 100,
      "endOffset" : 128
    }, {
      "referenceID" : 4,
      "context" : "We implement competitive failure prediction approaches, including Maximum Softmax Probability (MSP) (Hendrycks and Gimpel, 2017) and Monte Carlo Dropout (MCDropout) (Gal and Ghahramani, 2016).",
      "startOffset" : 165,
      "endOffset" : 191
    }, {
      "referenceID" : 15,
      "context" : "We use the 4-gram BLEU (Papineni et al., 2002) to score the performance.",
      "startOffset" : 23,
      "endOffset" : 46
    }, {
      "referenceID" : 24,
      "context" : "It can be attributed to that the seriousness of miscalibration varies in different language pairs and datasets (Wang et al., 2020).",
      "startOffset" : 111,
      "endOffset" : 130
    }, {
      "referenceID" : 18,
      "context" : "Confidence estimation is particularly critical in realworld deployment, where noisy samples and out-ofdistribution data are prevalent (Snoek et al., 2019).",
      "startOffset" : 134,
      "endOffset" : 154
    }, {
      "referenceID" : 13,
      "context" : "Given those abnormal inputs, neural network models are prone to be highly confident in misclassification (Nguyen et al., 2015).",
      "startOffset" : 105,
      "endOffset" : 126
    }, {
      "referenceID" : 1,
      "context" : "The task of confidence estimation is crucial in realworld conditions, which helps failure prediction (Corbière et al., 2019) and out-of-distribution detection (Hendrycks and Gimpel, 2017; Snoek et al.",
      "startOffset" : 101,
      "endOffset" : 124
    }, {
      "referenceID" : 6,
      "context" : ", 2019) and out-of-distribution detection (Hendrycks and Gimpel, 2017; Snoek et al., 2019; Lee et al., 2018).",
      "startOffset" : 42,
      "endOffset" : 108
    }, {
      "referenceID" : 18,
      "context" : ", 2019) and out-of-distribution detection (Hendrycks and Gimpel, 2017; Snoek et al., 2019; Lee et al., 2018).",
      "startOffset" : 42,
      "endOffset" : 108
    }, {
      "referenceID" : 11,
      "context" : ", 2019) and out-of-distribution detection (Hendrycks and Gimpel, 2017; Snoek et al., 2019; Lee et al., 2018).",
      "startOffset" : 42,
      "endOffset" : 108
    }, {
      "referenceID" : 24,
      "context" : "(2019) find that the NMT model is well-calibrated in training, which is proven severely miscalibrated in inference (Wang et al., 2020), especially when predicting the end of a sentence (Kumar and Sarawagi, 2019).",
      "startOffset" : 115,
      "endOffset" : 134
    }, {
      "referenceID" : 10,
      "context" : ", 2020), especially when predicting the end of a sentence (Kumar and Sarawagi, 2019).",
      "startOffset" : 58,
      "endOffset" : 84
    }, {
      "referenceID" : 21,
      "context" : "Recent supervised QE models are resource-heavy and require a large mass of annotated quality labels for training (Wang et al., 2018; Kepler et al., 2019a), which is labor-consuming and unavailable for low-resource languages.",
      "startOffset" : 113,
      "endOffset" : 154
    }, {
      "referenceID" : 7,
      "context" : "Recent supervised QE models are resource-heavy and require a large mass of annotated quality labels for training (Wang et al., 2018; Kepler et al., 2019a), which is labor-consuming and unavailable for low-resource languages.",
      "startOffset" : 113,
      "endOffset" : 154
    }, {
      "referenceID" : 22,
      "context" : "translation quality, which is also complementary to supervised QE model (Wang et al., 2021).",
      "startOffset" : 72,
      "endOffset" : 91
    }, {
      "referenceID" : 4,
      "context" : "However, they rely on repeated Monte Carlo dropout (Gal and Ghahramani, 2016) to assess uncertainty at the high cost of computation.",
      "startOffset" : 51,
      "endOffset" : 77
    } ],
    "year" : 0,
    "abstractText" : "Confidence estimation is to quantify the confidence of the model prediction, providing an expectation of success. A well-calibrated confidence estimate enables accurate failure prediction and proper risk measurement when given noisy samples and out-of-distribution data in real-world settings. However, this task remains a severe challenge for neural machine translation (NMT), where probabilities from softmax distribution fail to describe when the model is probably mistaken. To address this problem, we propose an unsupervised confidence estimate learning jointly with the training of the NMT model. We explain confidence as how many hints the NMT model needs to make a correct prediction, and more hints indicate low confidence. Specifically, the NMT model is given the option to ask for hints to improve translation accuracy at the cost of some slight penalty. Then, we approximate their level of confidence by counting the number of hints the model uses. We demonstrate that our learned confidence estimate achieves high accuracy on extensive sentence/word-level quality estimation tasks. Analytical results verify that our confidence estimate can correctly assess underlying risk in two real-world scenarios: (1) discovering noisy samples and (2) detecting out-of-domain data. We further propose a novel confidence-based instance-specific label smoothing approach based on our learned confidence estimate, which outperforms standard label smoothing.",
    "creator" : null
  }
}