{
  "name" : "ARR_2022_268_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Other Roles Matter! Enhancing Role-Oriented Dialogue Summarization via Role Interactions",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Dialogue summarization aims at compressing the main content of a long conversation into a short text. With the development of online conversation tools, the amount and length of conversation are growing up rapidly. Since a dialogue often contains complicated structure and ellipsis, it is time-consuming to read the whole dialogue. Dialogue summarization thus becomes valuable since it could extract the key point of a conversation and greatly reduce the time cost. This technique is widely used in customer service (Liu et al., 2019), meeting (McCowan et al., 2005), online chatting (Gliwa et al., 2019), etc.\nIn a dialogue, each role has its own opinion and goal, and different roles exchange information or\nreach a consensus through interactions. Therefore, in addition to summarizing the whole dialogue, we could summarize the main content for each role. Lin et al. (2021) first define the role-oriented dialogue summarization task and provide a related dataset CSDS. They define role-oriented dialogue summarization as grasping the main viewpoint of a given role from dialogue and mention the usage of role-oriented summaries in the customer service domain, e.g., reflecting the user’s requirements and evaluating agent service quality. Besides, role-oriented summarization is beneficial to other dialogue domains such as medical inquiry (Song et al., 2020) and court debate (Duan et al., 2019).\nFor role-oriented summarization, existing methods simply generate summaries for each role separately (Lin et al., 2021) or generate in a sequence labeling process (Song et al., 2020). They ignore the strong relativeness among summaries for dif-\nferent roles and thus fail to utilize the information from other roles to enhance the summaries. However, information from other roles is also crucial for this task. We summarize two cases where other roles’ information helps:\n(1) Other roles’ dialogue utterances could help enhance the informativeness of summaries. In Figure 1, utterance 7 (Yes, it is OK normally.) is the key utterance of the agent’s content, expressing a confirmation to the user’s question. While only extracting it makes the agent summary ambiguous since it lacks the confirming object (JD can pay via wechat in blue). In this case, the agent summary needs to integrate the content from the user’s utterance (utterance 6 in yellow) to enhance its informativeness.\n(2) Other roles’ summaries could help judge the key content in the dialogue. In a dialogue, different roles often discuss the same topic. Therefore, considering the key content of the other role could help grasp the key content of a given role. As shown in Figure 1, the user summary contains a question about the payment (in red), and the agent summary contains the response to the payment question (in blue). If the summary of one role struggles in judging whether the discussion about payment should be contained in the summary, by referring to the summary of the other role, the summarization model could be more confident to include this information into the summary.\nAlthough we notice the importance of other roles’ information, it is difficult to extract the key information from other roles through a simple multi-task framework. The main issue is that it could not judge which information from other roles is useful without modeling the interaction between different roles. Thus, in this work, we propose two interaction methods to obtain the key information from other roles for enhancing role-oriented summarization. First, we apply a cross attention interaction to let each role decoder select the most useful dialogue utterances from other roles. Specifically, we calculate the Cross Attention for different roles’ utterances separately and add a new Attention Divergence Loss to interactively share the cross attention distributions between different roles. Second, we apply a decoder self-attention interaction to let each role decoder obtain other roles’ summary information. We develop an interactive mechanism between decoders to consider other role summary information embedded in the\ndecoder states. A new Role Attention module is added to each role decoder, where the attention object is the hidden states of other role decoders. At last, we use the role attention result and multiple context attention results to predict the word probability distribution of the summary.\nTo examine the effectiveness of our method, we conduct experiments on two dialogue summarization datasets (Lin et al., 2021; Song et al., 2020) with role-oriented summaries in different domains (customer service, medical inquiry). We apply our method on two widely-used summarization frameworks (RNN-based and Transformer-based). The results have shown that, compared with baseline systems and naive multi-task approaches, applying role interactions could significantly improve the quality of role-oriented summaries. Further analyses verify that our proposed method can help the model correctly attend to other roles’ key information and generate summaries with more complete semantic and correct topic structures.\nThe main contributions of this paper include: (1) We are the first to enhance role-oriented dialogue summarization by focusing on other roles’ key information. (2) We innovatively design two role interaction methods to obtain other roles’ key information useful for generating summaries. (3) Experimental results on two datasets have shown that our method could lead to considerable improvements. Besides, our method has good generalizability since it works on multiple baseline frameworks."
    }, {
      "heading" : "2 Related Work",
      "text" : ""
    }, {
      "heading" : "2.1 Dialogue Summarization",
      "text" : "Dialogue summarization has been studied in various domains, e.g., meeting (McCowan et al., 2005; Janin et al., 2003), daily chatting (Gliwa et al., 2019; Chen et al., 2021), customer service (Liu et al., 2019; Zou et al., 2021), and medical inquiry (Song et al., 2020; Krishna et al., 2021). Considering the particularity of dialogue, many studies try to improve the dialogue summarization performance by focusing on dialogue-specific features (Feng et al., 2021), such as topic information (Chen and Yang, 2020), discourse structure (Chen and Yang, 2021), coreference information (Liu et al., 2021) and speaker information (Lei et al., 2021).\nHowever, all the above studies focus on summarizing the whole dialogue. Only a few studies pay attention to role-oriented summarization, which aims to summarize the main content of a single\nrole in the dialogue. A relative task is focused meeting summarization (Wang and Cardie, 2013; Mehdad et al., 2014; Zhong et al., 2021). It aims to summarize a specific part of the meeting dialogue, while role-oriented summarization focuses on a single role, and the relationship between different roles is much closer. Tamura et al. (2011) focus on contact center dialogue summarization, but they only extract salient sentences from the dialogue and do not summarize for different roles.\nDue to the lack of labeled data, Zhang et al. (2021) propose an unsupervised method to generate summaries for the customer and the agent under a variational auto-encoder framework. As for supervised methods, there are only two datasets available for training. Lin et al. (2021) propose a customer service domain dataset named CSDS, where each dialogue has an overall summary and two role-oriented summaries for user and agent. They train two separate models for generating user summary and agent summary. Song et al. (2020) provide a medical inquiry dialogue summarization dataset where each dialogue has two extractive summaries for the patient and the doctor. They train a sequence labeling model to extract summaries for these two roles. Compared with these approaches, to the best of our knowledge, we are the first to enhance role-oriented summarization by explicitly considering other roles’ critical information."
    }, {
      "heading" : "2.2 Interactive Decoding",
      "text" : "Interactive decoding is a mechanism to share information between different decoders in the decoding process. Zhou et al. (2019) propose this mechanism and use it on machine translation to simultaneously decode from both left-to-right and rightto-left. Wang et al. (2019) and Liu et al. (2020) further utilize it on more complex machine translation tasks, including multilingual translation and speech translation. In this work, we first use the interactive decoding mechanism on the summarization task to decode summaries for different roles, aiming at utilizing other roles’ summary information for summarization. Besides, we also propose an interaction method on cross attention to utilize other roles’ critical dialogue utterance information."
    }, {
      "heading" : "3 Our Approach",
      "text" : ""
    }, {
      "heading" : "3.1 Task Definition",
      "text" : "Given a dialogue D containing m utterances {u1, ..., um} and p speakers S = {s1, ..., sp}, the\nrole-oriented summarization task aims to generate a summary yk for each speaker sk. Each utterance uk consists of a speaker role rk ∈ S and related content. By concatenating all the utterances and related speaker roles, we achieve the final input {x1, ..., xn}. Note that since both datasets used in this work have two speakers, one asking questions and one giving answers, we thus use yuser and yagent to represent two role-oriented summaries in the following illustration1."
    }, {
      "heading" : "3.2 Role Interactions",
      "text" : "In a traditional encoder-decoder framework for dialogue summarization, the encoder hidden states represent the semantic information of input dialogue utterances, and the decoder hidden states contain the information used to generate summaries. To fully exploit the information from other roles, we apply two role interactions on the attention module of both hidden states. We present the structure of our method in Figure 2 and introduce the detail of interactions in the following paragraphs."
    }, {
      "heading" : "3.2.1 Cross Attention Interaction",
      "text" : "Our method is constructed based on a multi-task framework where an encoder is used to encode dialogue utterances and two role decoders (user decoder and agent decoder) are used to decode user summary and agent summary. First, the input {x1, ..., xn} is sent to an encoder (omitted in the figure for simplicity) and the encoder outputs the context hidden representation {h1, ..., hn}. In the decoding phase, to calculate the cross attention results for different roles separately, we use User Mask and Agent Mask to split the context information into user context Hencu and agent context Henca . H enc u contains the hidden representation of all user utterances, and Henca contains the hidden representation of all agent utterances.\nThe cross attention module extracts the most useful information from the context according to the temporary decoder state. Here we modify the module to attend to different role contexts separately. Taking user decoder as example, at step k, we use the hidden state of user decoder huserk to attend to user context Hencu and agent context H enc a , obtaining two attention distributions attuu,k, att u a,k and context attention results cuu,k, c u a,k. Both context results involve generating summaries. The process\n1Here we need to point out that our method could also apply for more than two speakers.\nis the same with agent decoder, where two attention distributions are noted as attau,k, att a a,k.\nSince existing models are poor at extracting important information from other roles, it reflects in incorrect cross-role attentions attau,k (agent decoder to user context) and attua,k (user decoder to agent context). Meanwhile, the same-role attentions attuu,k (user decoder to user context) and attaa,k (agent decoder to agent context) are learned better since most information of role-oriented summaries comes from the given role’s utterances. Thus we want to use the same-role attention to guide the cross-role attention. As different roles often discuss the same topic in one dialogue, the accumulated cross attention distribution for user decoder and agent decoder on the same role’s utterances should be similar. A new Attention Divergence Loss is added to constrain this attention similarity as:\nLatt−user = KL(Avg(attau)||Avg(attuu))\nLatt−agent = KL(Avg(attua)||Avg(attaa))\nBy minimizing these two losses, the agent decoder attends to user utterances as the user decoder does and the user decoder attends to agent utterances as the agent decoder does. Two role decoders interactively learn to focus on the key information of the other role in dialogue utterances."
    }, {
      "heading" : "3.2.2 Decoder Self-Attention Interaction",
      "text" : "Since the decoder calculates the hidden states that could help predict summaries, the hidden states must contain much important information of summaries. We thus try to exploit the information embedded in other role decoders. Specifically, for user\ndecoder, at time step t, we achieve the decoder hidden states husert and use a Role Attention module to weigh the last t hidden states of agent decoder {hagent1 , ..., h agent t }. The role context information rusert is obtained by adding all the agent hidden states with their weights, and it helps generate the probability of next word ŷusert for user summary. The calculation formulas are given as:\nrusert = Attn(h user t , h agent 1:t )\np(ŷusert ) = F(husert , rusert , cuu,k, cua,k)\nThe function F includes an MLP layer to fuse different information and a softmax layer to predict the vocabulary probability distribution. The process is the same with the agent decoder, and two decoders decode interactively."
    }, {
      "heading" : "3.2.3 Training and Inference",
      "text" : "In the training phase, we use the teacher-forcing method to jointly train two role decoders and use the Negative Log-Likelihood loss to optimize. The NLL loss for a single sample is formulized as:\nLnll = α· |yuser|∑ i=1 logP (yuseri |yuser<i , y agent <i , D)+\n(1− α)· |yagent|∑ i=1 logP (yagenti |y agent <i , y user <i , D)\nα is a hyper-parameter for balancing the weights of different summarization tasks. Besides, we add the attention divergence loss to constrain the attention distribution, and the total loss is calculated as:\nL = Lnll + β(Latt−user + Latt−agent)\nβ is a hyper-parameter for balancing the weights of different loss functions.\nIn the inference phase, we also make some adjustments on beam search for our proposed method. We maintain two beams, one for user summary and one for agent summary. At each step of decoding, the kth sequence of the user summary beam should consider the states in the kth sequence of the agent summary beam for role attention. Once one beam has finished decoding, we keep the beam fixed and search for the other one. The beam search will finish if both two beams have finished searching."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Datasets",
      "text" : "There are two dialogue summarization datasets with role-oriented summarization tasks. Thus we evaluate the effectiveness of our proposed method on both datasets. First, we experiment on a Chinese fine-grained customer service summarization dataset CSDS2 (Lin et al., 2021). It provides separate summaries for the user and the agent, and both may contain multiple topics. The other one is a Chinese medical inquiry summarization dataset MC3 (Song et al., 2020). Each dialogue has a summary of the patient’s description and a summary of the doctor’s suggestion. We note them as user summary and agent summary as well. Most of the summaries in MC are extractive, and only some are different from dialogue scripts. Moreover, most dialogues in MC have only one topic. Comparing two datasets, MC is easier to summarize while CSDS is more specific for role-oriented summarization and more challenging. The detailed statistics of the two datasets are given in Table 1.\n2https://github.com/xiaolinAndy/CSDS. 3https://github.com/cuhksz-nlp/HET-MC. We use the official crawling script to acquire the dataset and divide some data from the training set as the validation set. Due to the update of the website, the data may have a slight difference compared with the version in the original paper."
    }, {
      "heading" : "4.2 Baselines and Experiment Settings",
      "text" : "We apply the role interaction methods on two widely-used seq2seq models in the summarization community, including PGN (See et al., 2017) and BERTAbs (Liu and Lapata, 2019). Therefore, we will introduce these two backbone models and how we apply Role Interactions to them."
    }, {
      "heading" : "4.2.1 PGN-based Methods",
      "text" : "PGN is an LSTM-based seq2seq model with a copy mechanism to copy words from the input and a coverage mechanism for constraining context attention. We set two PGN-based baselines for comparison. PGN-single is to separately train two PGN models for generating user summary and agent summary, while PGN-multi tries to jointly train two PGN models by sharing the same encoder.\nTo apply role interactions, we choose the output of the LSTM cell in the decoder as the query to calculate cross attention and role attention. The attention object in role attention is the output of the LSTM cell from the other decoder. Since we calculate the cross attention for different roles separately, we use a learnable gate prole to control the weight of different cross attentions and add them together according to their weights to achieve the overall context attention distribution. It is used for the copy and coverage mechanism. We set PGNcross as adding cross attention interaction, PGNself as adding decoder self-attention interaction, and PGN-both as adding both interactions."
    }, {
      "heading" : "4.2.2 BERTAbs-based Methods",
      "text" : "Transformer has been widely used in language understanding and generation models due to its strong representation ability and concurrency, especially in pretrained models (Devlin et al., 2019; Lewis et al., 2020). Here we choose BERTAbs (Liu and Lapata, 2019) as the backbone structure since it performs well on many summarization datasets and is available for non-English languages such as Chinese. It adopts a pretrained BERT model as encoder and a transformer decoder structure to decode summaries. Both the encoder and the decoder contain six layers, and each layer contains three sub-layers (self-attention, encoder-decoder attention, feedforward). Similar with PGN-based methods, we set BERT-single and BERT-multi as two baselines.\nWe apply both interactions to each layer in BERTAbs. For cross attention interaction, we change the encoder-decoder attention sub-layer into two separate cross attention modules; for de-\ncoder self-attention interaction, we add the role attention module parallel with the encoder-decoder attention module. The query, key, and value of the role attention module are all the output from the self-attention sub-layer. BERT-cross, BERT-self, and BERT-both are kept the same with the settings in PGN-based methods."
    }, {
      "heading" : "4.2.3 Other Experiment Settings",
      "text" : "We add the role information to the front of the utterance in each turn and concatenate all the utterances in the dialogue sequentially as the input of the model. Both PGN4 and BERTAbs5 baseline methods are adopted from publicly available codes. For PGN-based methods, we use pretrained Chinese word vectors provided by Tencent6, and the vocabulary size is 10000. While for BERTAbs-based methods, we use Chinese-BERT-wwm7 pretrained embeddings. The best checkpoint is chosen based on validation set loss, and we use beam search to decode summaries on the best checkpoint with beam size 5. For choosing hyper-parameters, α is set to be 0.5 for PGN and 0.25 for BERTAbs. Since the agent summary is more complex than the user summary in MC, we set β to be 0.2 to give the agent summary more weight. It is set to be 0.5 for CSDS. The hyper-parameter settings are chosen by experimenting on the validation set. More details are given in Appendix A, and we will also release our source code after publication."
    }, {
      "heading" : "4.3 Evaluation Metrics",
      "text" : "We adopt six common automatic evaluation metrics to evaluate the summary quality. The metrics include traditional n-gram overlapping metrics, such as ROUGE (Lin and Hovy, 2002), BLEU (Papineni et al., 2002), and distributed representation matching metrics, including BERTScore (Zhang et al., 2020) and MoverScore (Zhao et al., 2019). We use files2rouge toolkit to calculate the F1 score of ROUGE-1, ROUGE-2, ROUGE-L. More details of evaluation scripts are given in Appendix A.\nIn addition to automatic metrics, we also compare the summary quality at a fine-grained level through human evaluation. Following the human evaluation process in Lin et al. (2021), we recruit several volunteers and let them evaluate the summaries in the following aspects: (1) Informative-\n4https://github.com/atulkum/pointer_summarizer 5https://github.com/nlpyang/PreSumm 6https://ai.tencent.com/ailab/nlp/en/embedding.html 7https://github.com/ymcui/Chinese-BERT-wwm\nness: Does the generated summary correctly cover the information in the ground truth summary? (2) Non-redundancy: Does the generated summary not contain repeated, meaningless or unnecessary information? (3) Fluency: Is the generated summary well-formed, semantically complete, and easy to understand? All three aspects are evaluated at the sub-summary level8 on a three-point scale, 0 for the worst, 1 for the medium, and 2 for the best."
    }, {
      "heading" : "5 Results and Analysis",
      "text" : ""
    }, {
      "heading" : "5.1 Automatic Evaluation Results",
      "text" : "First, we present the results of automatic metrics with Student’s t-test as significance test in Table 2 and 3. The results are similar on the two datasets. First, the multi-task mechanism could bring some improvement than separately training on most of the metrics. However, the improvement is limited, especially for the PGN model on CSDS. After adding the enhancement of other roles’ information, the performance is significantly boosted.\nOn CSDS, PGN-single and BERT-single are two strong baselines provided in Lin et al. (2021)9. The best method PGN-both achieves 2.84 and 1.53 higher points on ROUGE-L for user summary and agent summary than PGN-single. For BERTAbsbased methods, the improvements are even greater, which are 4.73 and 2.69. Only applying one interaction (-cross or -self ) also shows promising improvement than single and multi baselines on nearly all the metrics, while applying both performs the best on most metrics.\nThe circumstance is similar on MC. User summarization is relatively simple on MC, and the baseline methods could achieve high performance (5.35 points of ROUGE-2 higher than the best performance in the original paper (Song et al., 2020)). Despite this, both cross attention interaction and decoder self-attention interaction could still increase the performance of user summary a bit. Additionally, the improvement on agent summary is more significant. PGN-both method achieves 0.90 points of ROUGE-2 and 1.29 points of MoverScore improvement, while BERT-both achieves 0.76 points of ROUGE-2 and 0.66 points of MoverScore im-\n8We split summaries into different topic segments, and each segment is a sub-summary, same as Lin et al. (2021).\n9Note that we do not mention the baseline Fast-RL (Chen and Bansal, 2018) in Lin et al. (2021). It first extracts salient utterances and generates summary sentences from each utterance separately, which is not available to add our proposed interaction methods.\nprovement. PGN-both also beats the best result in the original paper on most of the metrics, which uses additional information such as hospital department and disease name. In conclusion, our proposed interaction methods could bring remarkable improvement on different backbone structures and different datasets."
    }, {
      "heading" : "5.2 Human Evaluation Results",
      "text" : "To evaluate the summary quality at a more finegrained level, we compare the summaries from different models according to the pre-defined three aspects: informativeness, non-redundancy, fluency. Since the multi-task framework works better than the single baseline, we directly compare it with applying both interactions. As CSDS is more challenging for this task, we randomly select 100 samples from the test set and obtain the outputs of two baseline methods (PGN-multi and BERT-multi) and two interaction methods (PGN-both and BERT-\nboth). We recruit three volunteers and train them on the evaluation rules10. Then we let them evaluate the generated summaries according to the ground truth and the original dialogue in the three aspects. We run the inter-annotator agreement study on three volunteers’ scores, and obtain a reasonable kappa score 0.48 on average. We also calculate an “Overall” metric by averaging the results of all three aspects to represent the summary quality in general. We normalize the result into 0 to 1 and present it in Table 4.\nThe result shows different trends on two backbone structures. For the PGN model, applying interactions could largely reduce the redundancy of both user and agent summary, with a comparable performance of informativeness. Besides, it also improves the fluency of the two summaries. While for the BERTAbs model, the interaction method significantly improves the informativeness while the redundancy also increases a bit. The difference exists because BERTAbs prefers to generate short summaries. Thus, considering information from other roles could help generate more useful information but also induce some redundant texts. In contrast, PGN tends to generate lengthy summaries. When considering information from other roles, it first tries to discard the redundant texts and\n10More details are in Appendix C with ethical concerns.\nonly retains more important ones. The fluency improvement on both methods proves that other roles’ information helps generate more semantically complete summaries. Considering the overall metric, we conclude that our proposed interaction method is also effective through human evaluation."
    }, {
      "heading" : "5.3 Further Analysis",
      "text" : "Agent Summary Completeness Analysis The agent summary often suffers semantic incompleteness due to missing key information from other roles (Lin et al., 2021). Since our proposed role interactions aim at extracting other roles’ key information, we wonder whether it works on these incomplete cases. Following the settings in Lin et al. (2021), we compare the summary quality of samples that need to integrate other roles’ information and those that do not need separately11. The result in Table 5 shows that the interaction method could actually help improve the performance on samples that need to integrate. Besides, samples that do not need also get improved. We believe that it is because considering other roles’ information could also help extract critical content from the role’s own utterances as well.\nTopic Structural Summary Analysis Since we assume that role interactions could help generate better summaries by sharing the same discussion topic, we wonder whether the summaries generated by our methods could include the correct topic structure. More specifically, we want to find out the performance of our methods on summarizing each topic. Following the evaluation method in (Lin et al., 2021), we treat each sentence in the summary as a sub-summary for a single topic and calculate the number of matching sub-summaries with the reference by a ROUGE-L-based matching algorithm. We calculate the precision, recall, and F1 scores of correctly matched sub-summary ratios\n11Which sample needs other roles’ information is labeled in CSDS.\nand present them in Table 6. The result shows that two role interaction methods achieve higher recall and F1 scores on sub-summary matching. It proves that role interactions could help the model grasp the discussion topic in the dialogue and generate a more accurate summary for each topic.\nCase Study We also present an example in Appendix B to prove the effectiveness of our proposed role interaction method. In both cases, adding role interactions could help generate the necessary information omitted by baseline methods. The attention distribution heatmap also proves that the cross attention interaction helps attend to the necessary utterances from other roles."
    }, {
      "heading" : "6 Conclusion and Future Work",
      "text" : "In this paper, we focus on the role-oriented dialogue summarization task. To fully exploit the information from other roles, we propose two role interaction methods on cross attention and decoder self-attention. The cross attention interaction calculates the context information for different roles separately and uses same-role attention to guide cross-role attention. The decoder self-attention interaction adds a role attention module to attend to other role decoder states interactively. Experiments on two dialogue summarization datasets prove that both interactions perform much better than baselines. Adding role interactions also helps generate summaries with complete semantics and correct topic structure. In the future, we will try to apply this method to other dialogue-related tasks."
    }, {
      "heading" : "A Experiment Details",
      "text" : "Here, we will introduce some detailed settings for our experiments on two datasets.\n• PGN-based methods: We construct the vocabulary by choosing the top 10,000 most frequent words in the training data. The settings of PGN are the same as the original setting, with hidden size 256 and Adagrad optimizer.\nFor CSDS dataset, we use the given word split result to construct the vocabulary. The maximum input length is set as 500. The maximum output length is 100, and the minimum is 15. We train 40 epochs without coverage mechanism or KL divergence loss (if needed) and 10 epochs with coverage mechanism and KL divergence loss. Then we choose the best checkpoint by comparing the loss on the validation set and use it to decode summaries.\nFor MC dataset, we use jieba12 tool to split sentences into words for constructing the vocabulary. The maximum input and output length are the same with CSDS, while the minimum output length is 10 since the user summary in MC is relatively shorter. We train 30 epochs without coverage mechanism and do not finetune with coverage mechanism since we found that it makes the performance worse. The KL divergence loss is added to training loss for PGN-cross and PGN-both in all the training process.\n• BERTAbs-based methods: Since the BERT model is already finetuned, there is no need to reconstruct the vocabulary. The Chinese BERT model works on character-level. Thus we set the length limit larger. The dimension and optimizer settings of BERTAbs are also the same as the original settings.\nFor CSDS dataset, the maximum input and output length are 1,000 and 200, respectively. The minimum output length is 15. We train the model for 4000 steps and save the checkpoint for every 400 steps. We use Adam optimizer with a warmup of 1000 steps. The KL divergence loss is added by finetuning 1000 more steps.\n12https://pypi.org/project/jieba/\nFor MC dataset, the maximum input and output length are kept the same, and the minimum output length is 10. We train the model for 8000 steps and add the KL divergence loss in all the training process.\nAll the PGN-based models are run on an NVIDIA TITAN Xp, and all the BERTAbs-based models are run on an NVIDIA RTX3090. The whole running time is less than a week.\nWe also provide the running scripts of auto evaluation metrics for better reproduction. For ROUGE metrics, we use the files2rouge13 toolkit with the default parameters. All the Chinese characters are transferred into number ids for calculation, and the period is used to split each summary into several sentences for ROUGE-L calculation. For BERTScore, we use the official code14. For MoverScore, we use moverscore-v215 and the bert-basechinese pretrained model for obtaining representations."
    }, {
      "heading" : "B Case Study",
      "text" : "Here we use the same example illustrated in the main paper to prove the effectiveness of our proposed method. The outputs of different methods are given in Figure 3. Comparing the outputs of user summary, only PGN-both correctly summarizes the key issue “The user asked whether wechat payment is available.”, while other baselines omit it. This could be contributed to decoder self-attention interaction by attending to the information in the decoded agent summary. As for the agent summary, PGN omits the keyword “JD” and PGN-multi generates a redundant clause “The customer service replied that it can be paid by wechat”. Compared with them, PGN-both generates the agent summary with both informativeness and preciseness.\nAs given in Figure 4, we also present the average attention distribution for cross attention module in the PGN-both method. Although the attention distributions for user summary and agent summary are different, they also show some similarities, such as both focusing on the second line from the bottom, which is the key utterance for both summaries. This could be benefited by the cross attention interaction since we close the gap between the attention distributions of different role decoders on the same role’s utterances.\n13https://github.com/pltrdy/files2rouge 14https://pypi.org/project/bert-score/0.2.1/ 15https://github.com/AIPHES/emnlp19-moverscore"
    }, {
      "heading" : "C Ethical Concerns",
      "text" : "We only use the data provided by two datasets for training. The private information in CSDS has already been anonymized, such as replacing all numbers with special token <NUM> and all order IDs with <ORDER-ID>. There is no personal information available in CSDS. The circumstance is the same for MC, where all the dialogues do not contain detailed personal information. Thus the methods provided in our experiment do not have any issues with privacy disclosure. As for human evaluation, all the participants are Chinese graduate students who volunteer to make the evaluation, and they are all proficient in Chinese. We first let them read the evaluating instructions and let them evaluate on ten samples. Then we will give feedback on their evaluation to ensure that they have the same judgement standard."
    } ],
    "references" : [ {
      "title" : "Multi-view sequenceto-sequence models with conversational structure for abstractive dialogue summarization",
      "author" : [ "Jiaao Chen", "Diyi Yang." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages",
      "citeRegEx" : "Chen and Yang.,? 2020",
      "shortCiteRegEx" : "Chen and Yang.",
      "year" : 2020
    }, {
      "title" : "Structure-aware abstractive conversation summarization via discourse and action graphs",
      "author" : [ "Jiaao Chen", "Diyi Yang." ],
      "venue" : "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
      "citeRegEx" : "Chen and Yang.,? 2021",
      "shortCiteRegEx" : "Chen and Yang.",
      "year" : 2021
    }, {
      "title" : "Fast abstractive summarization with reinforce-selected sentence rewriting",
      "author" : [ "Yen-Chun Chen", "Mohit Bansal." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 675–686, Mel-",
      "citeRegEx" : "Chen and Bansal.,? 2018",
      "shortCiteRegEx" : "Chen and Bansal.",
      "year" : 2018
    }, {
      "title" : "DialogSum: A real-life scenario dialogue summarization dataset",
      "author" : [ "Yulong Chen", "Yang Liu", "Liang Chen", "Yue Zhang." ],
      "venue" : "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 5062–5074, Online. Association for",
      "citeRegEx" : "Chen et al\\.,? 2021",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2021
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Legal summarization for multi-role debate dialogue via controversy focus mining and multi-task",
      "author" : [ "Xinyu Duan", "Yating Zhang", "Lin Yuan", "Xin Zhou", "Xiaozhong Liu", "Tianyi Wang", "Ruocheng Wang", "Qiong Zhang", "Changlong Sun", "Fei Wu" ],
      "venue" : null,
      "citeRegEx" : "Duan et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Duan et al\\.",
      "year" : 2019
    }, {
      "title" : "A survey on dialogue summarization: Recent advances and new frontiers",
      "author" : [ "Xiachong Feng", "Xiaocheng Feng", "Bing Qin." ],
      "venue" : "arXiv preprint arXiv:2107.03175.",
      "citeRegEx" : "Feng et al\\.,? 2021",
      "shortCiteRegEx" : "Feng et al\\.",
      "year" : 2021
    }, {
      "title" : "SAMSum corpus: A human-annotated dialogue dataset for abstractive summarization",
      "author" : [ "Bogdan Gliwa", "Iwona Mochol", "Maciej Biesek", "Aleksander Wawer." ],
      "venue" : "Proceedings of the 2nd Workshop on New Frontiers in Summarization, pages 70–79,",
      "citeRegEx" : "Gliwa et al\\.,? 2019",
      "shortCiteRegEx" : "Gliwa et al\\.",
      "year" : 2019
    }, {
      "title" : "The icsi meeting corpus",
      "author" : [ "Adam Janin", "Don Baron", "Jane Edwards", "Dan Ellis", "David Gelbart", "Nelson Morgan", "Barbara Peskin", "Thilo Pfau", "Elizabeth Shriberg", "Andreas Stolcke" ],
      "venue" : null,
      "citeRegEx" : "Janin et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Janin et al\\.",
      "year" : 2003
    }, {
      "title" : "Generating SOAP notes from doctor-patient conversations using modular summarization techniques",
      "author" : [ "Kundan Krishna", "Sopan Khosla", "Jeffrey Bigham", "Zachary C. Lipton." ],
      "venue" : "Proceedings of the 59th Annual Meeting of the Association for Compu-",
      "citeRegEx" : "Krishna et al\\.,? 2021",
      "shortCiteRegEx" : "Krishna et al\\.",
      "year" : 2021
    }, {
      "title" : "Hierarchical speaker-aware sequence-to-sequence model for dialogue summarization",
      "author" : [ "Yuejie Lei", "Yuanmeng Yan", "Zhiyuan Zeng", "Keqing He", "Ximing Zhang", "Weiran Xu." ],
      "venue" : "ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and",
      "citeRegEx" : "Lei et al\\.,? 2021",
      "shortCiteRegEx" : "Lei et al\\.",
      "year" : 2021
    }, {
      "title" : "BART: Denoising sequence-to-sequence pretraining for natural language",
      "author" : [ "Mike Lewis", "Yinhan Liu", "Naman Goyal", "Marjan Ghazvininejad", "Abdelrahman Mohamed", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer" ],
      "venue" : null,
      "citeRegEx" : "Lewis et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Lewis et al\\.",
      "year" : 2020
    }, {
      "title" : "Manual and automatic evaluation of summaries",
      "author" : [ "Chin-Yew Lin", "Eduard Hovy." ],
      "venue" : "Proceedings of the ACL-02 Workshop on Automatic Summarization, pages 45–51, Phildadelphia, Pennsylvania, USA. Association for Computational Linguistics.",
      "citeRegEx" : "Lin and Hovy.,? 2002",
      "shortCiteRegEx" : "Lin and Hovy.",
      "year" : 2002
    }, {
      "title" : "CSDS: A fine-grained Chinese dataset for customer service dialogue summarization",
      "author" : [ "Haitao Lin", "Liqun Ma", "Junnan Zhu", "Lu Xiang", "Yu Zhou", "Jiajun Zhang", "Chengqing Zong." ],
      "venue" : "Proceedings of the 2021 Conference on Empirical Methods in Natural Lan-",
      "citeRegEx" : "Lin et al\\.,? 2021",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2021
    }, {
      "title" : "Automatic dialogue summary generation for customer service",
      "author" : [ "Chunyi Liu", "Peng Wang", "Jiang Xu", "Zang Li", "Jieping Ye." ],
      "venue" : "Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 1957–",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Text summarization with pretrained encoders",
      "author" : [ "Yang Liu", "Mirella Lapata." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing",
      "citeRegEx" : "Liu and Lapata.,? 2019",
      "shortCiteRegEx" : "Liu and Lapata.",
      "year" : 2019
    }, {
      "title" : "Synchronous speech recognition and speech-to-text translation with interactive decoding",
      "author" : [ "Yuchen Liu", "Jiajun Zhang", "Hao Xiong", "Long Zhou", "Zhongjun He", "Hua Wu", "Haifeng Wang", "Chengqing Zong." ],
      "venue" : "Proceedings of the AAAI Conference on",
      "citeRegEx" : "Liu et al\\.,? 2020",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Coreference-aware dialogue summarization",
      "author" : [ "Zhengyuan Liu", "Ke Shi", "Nancy Chen." ],
      "venue" : "Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 509–519, Singapore and Online. Association for",
      "citeRegEx" : "Liu et al\\.,? 2021",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2021
    }, {
      "title" : "The ami meeting corpus",
      "author" : [ "I McCowan", "J Carletta", "W Kraaij", "S Ashby", "S Bourban", "M Flynn", "M Guillemot", "T Hain", "J Kadlec", "V Karaiskos" ],
      "venue" : "In Proceedings of Measuring Behavior",
      "citeRegEx" : "McCowan et al\\.,? \\Q2005\\E",
      "shortCiteRegEx" : "McCowan et al\\.",
      "year" : 2005
    }, {
      "title" : "Abstractive summarization of spoken and written conversations based on phrasal queries",
      "author" : [ "Yashar Mehdad", "Giuseppe Carenini", "Raymond T. Ng." ],
      "venue" : "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1:",
      "citeRegEx" : "Mehdad et al\\.,? 2014",
      "shortCiteRegEx" : "Mehdad et al\\.",
      "year" : 2014
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia,",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "Get to the point: Summarization with pointergenerator networks",
      "author" : [ "Abigail See", "Peter J. Liu", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1073–",
      "citeRegEx" : "See et al\\.,? 2017",
      "shortCiteRegEx" : "See et al\\.",
      "year" : 2017
    }, {
      "title" : "Summarizing medical conversations via identifying important utterances",
      "author" : [ "Yan Song", "Yuanhe Tian", "Nan Wang", "Fei Xia." ],
      "venue" : "Proceedings of the 28th International Conference on Computational Linguistics, pages 717–729, Barcelona, Spain (Online). In-",
      "citeRegEx" : "Song et al\\.,? 2020",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2020
    }, {
      "title" : "Extractive summarization method for contact center dialogues based on call logs",
      "author" : [ "Akihiro Tamura", "Kai Ishikawa", "Masahiro Saikou", "Masaaki Tsuchida." ],
      "venue" : "Proceedings of 5th International Joint Conference on Natural Language Processing, pages",
      "citeRegEx" : "Tamura et al\\.,? 2011",
      "shortCiteRegEx" : "Tamura et al\\.",
      "year" : 2011
    }, {
      "title" : "Domainindependent abstract generation for focused meeting summarization",
      "author" : [ "Lu Wang", "Claire Cardie." ],
      "venue" : "Proceedings of the 51st Annual",
      "citeRegEx" : "Wang and Cardie.,? 2013",
      "shortCiteRegEx" : "Wang and Cardie.",
      "year" : 2013
    }, {
      "title" : "Synchronously generating two languages with interactive decoding",
      "author" : [ "Yining Wang", "Jiajun Zhang", "Long Zhou", "Yuchen Liu", "Chengqing Zong." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the",
      "citeRegEx" : "Wang et al\\.,? 2019",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "Bertscore: Evaluating text generation with BERT",
      "author" : [ "Tianyi Zhang", "Varsha Kishore", "Felix Wu", "Kilian Q. Weinberger", "Yoav Artzi." ],
      "venue" : "8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30,",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Unsupervised abstractive dialogue summarization for tete-a-tetes",
      "author" : [ "Xinyuan Zhang", "Ruiyi Zhang", "Manzil Zaheer", "Amr Ahmed." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, 35(16):14489–14497.",
      "citeRegEx" : "Zhang et al\\.,? 2021",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2021
    }, {
      "title" : "MoverScore: Text generation evaluating with contextualized embeddings and earth mover distance",
      "author" : [ "Wei Zhao", "Maxime Peyrard", "Fei Liu", "Yang Gao", "Christian M. Meyer", "Steffen Eger." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in",
      "citeRegEx" : "Zhao et al\\.,? 2019",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2019
    }, {
      "title" : "QMSum: A new benchmark for querybased multi-domain meeting summarization",
      "author" : [ "Ming Zhong", "Da Yin", "Tao Yu", "Ahmad Zaidi", "Mutethia Mutuma", "Rahul Jha", "Ahmed Hassan Awadallah", "Asli Celikyilmaz", "Yang Liu", "Xipeng Qiu", "Dragomir Radev." ],
      "venue" : "Pro-",
      "citeRegEx" : "Zhong et al\\.,? 2021",
      "shortCiteRegEx" : "Zhong et al\\.",
      "year" : 2021
    }, {
      "title" : "Synchronous Bidirectional Neural Machine Translation",
      "author" : [ "Long Zhou", "Jiajun Zhang", "Chengqing Zong." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 7:91–105.",
      "citeRegEx" : "Zhou et al\\.,? 2019",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2019
    }, {
      "title" : "Topic-oriented spoken dialogue summarization for customer service with saliency-aware topic",
      "author" : [ "Yicheng Zou", "Lujun Zhao", "Yangyang Kang", "Jun Lin", "Minlong Peng", "Zhuoren Jiang", "Changlong Sun", "Qi Zhang", "Xuanjing Huang", "Xiaozhong Liu" ],
      "venue" : null,
      "citeRegEx" : "Zou et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Zou et al\\.",
      "year" : 2021
    } ],
    "referenceMentions" : [ {
      "referenceID" : 14,
      "context" : "This technique is widely used in customer service (Liu et al., 2019), meeting (McCowan et al.",
      "startOffset" : 50,
      "endOffset" : 68
    }, {
      "referenceID" : 18,
      "context" : ", 2019), meeting (McCowan et al., 2005), online chatting (Gliwa et al.",
      "startOffset" : 17,
      "endOffset" : 39
    }, {
      "referenceID" : 22,
      "context" : "Besides, role-oriented summarization is beneficial to other dialogue domains such as medical inquiry (Song et al., 2020) and court debate (Duan et al.",
      "startOffset" : 101,
      "endOffset" : 120
    }, {
      "referenceID" : 13,
      "context" : "For role-oriented summarization, existing methods simply generate summaries for each role separately (Lin et al., 2021) or generate in a sequence labeling process (Song et al.",
      "startOffset" : 101,
      "endOffset" : 119
    }, {
      "referenceID" : 22,
      "context" : ", 2021) or generate in a sequence labeling process (Song et al., 2020).",
      "startOffset" : 51,
      "endOffset" : 70
    }, {
      "referenceID" : 13,
      "context" : "To examine the effectiveness of our method, we conduct experiments on two dialogue summarization datasets (Lin et al., 2021; Song et al., 2020) with role-oriented summaries in different domains (customer service, medical inquiry).",
      "startOffset" : 106,
      "endOffset" : 143
    }, {
      "referenceID" : 22,
      "context" : "To examine the effectiveness of our method, we conduct experiments on two dialogue summarization datasets (Lin et al., 2021; Song et al., 2020) with role-oriented summaries in different domains (customer service, medical inquiry).",
      "startOffset" : 106,
      "endOffset" : 143
    }, {
      "referenceID" : 18,
      "context" : ", meeting (McCowan et al., 2005; Janin et al., 2003), daily chatting (Gliwa et al.",
      "startOffset" : 10,
      "endOffset" : 52
    }, {
      "referenceID" : 8,
      "context" : ", meeting (McCowan et al., 2005; Janin et al., 2003), daily chatting (Gliwa et al.",
      "startOffset" : 10,
      "endOffset" : 52
    }, {
      "referenceID" : 7,
      "context" : ", 2003), daily chatting (Gliwa et al., 2019; Chen et al., 2021), customer service (Liu et al.",
      "startOffset" : 24,
      "endOffset" : 63
    }, {
      "referenceID" : 3,
      "context" : ", 2003), daily chatting (Gliwa et al., 2019; Chen et al., 2021), customer service (Liu et al.",
      "startOffset" : 24,
      "endOffset" : 63
    }, {
      "referenceID" : 14,
      "context" : ", 2021), customer service (Liu et al., 2019; Zou et al., 2021), and medical inquiry (Song et al.",
      "startOffset" : 26,
      "endOffset" : 62
    }, {
      "referenceID" : 31,
      "context" : ", 2021), customer service (Liu et al., 2019; Zou et al., 2021), and medical inquiry (Song et al.",
      "startOffset" : 26,
      "endOffset" : 62
    }, {
      "referenceID" : 6,
      "context" : "Considering the particularity of dialogue, many studies try to improve the dialogue summarization performance by focusing on dialogue-specific features (Feng et al., 2021), such as topic information (Chen and Yang, 2020), discourse structure (Chen and Yang, 2021), coreference information (Liu et al.",
      "startOffset" : 152,
      "endOffset" : 171
    }, {
      "referenceID" : 0,
      "context" : ", 2021), such as topic information (Chen and Yang, 2020), discourse structure (Chen and Yang, 2021), coreference information (Liu et al.",
      "startOffset" : 35,
      "endOffset" : 56
    }, {
      "referenceID" : 1,
      "context" : ", 2021), such as topic information (Chen and Yang, 2020), discourse structure (Chen and Yang, 2021), coreference information (Liu et al.",
      "startOffset" : 78,
      "endOffset" : 99
    }, {
      "referenceID" : 17,
      "context" : ", 2021), such as topic information (Chen and Yang, 2020), discourse structure (Chen and Yang, 2021), coreference information (Liu et al., 2021) and speaker information (Lei et al.",
      "startOffset" : 125,
      "endOffset" : 143
    }, {
      "referenceID" : 24,
      "context" : "A relative task is focused meeting summarization (Wang and Cardie, 2013; Mehdad et al., 2014; Zhong et al., 2021).",
      "startOffset" : 49,
      "endOffset" : 113
    }, {
      "referenceID" : 19,
      "context" : "A relative task is focused meeting summarization (Wang and Cardie, 2013; Mehdad et al., 2014; Zhong et al., 2021).",
      "startOffset" : 49,
      "endOffset" : 113
    }, {
      "referenceID" : 29,
      "context" : "A relative task is focused meeting summarization (Wang and Cardie, 2013; Mehdad et al., 2014; Zhong et al., 2021).",
      "startOffset" : 49,
      "endOffset" : 113
    }, {
      "referenceID" : 13,
      "context" : "First, we experiment on a Chinese fine-grained customer service summarization dataset CSDS2 (Lin et al., 2021).",
      "startOffset" : 92,
      "endOffset" : 110
    }, {
      "referenceID" : 22,
      "context" : "The other one is a Chinese medical inquiry summarization dataset MC3 (Song et al., 2020).",
      "startOffset" : 69,
      "endOffset" : 88
    }, {
      "referenceID" : 21,
      "context" : "We apply the role interaction methods on two widely-used seq2seq models in the summarization community, including PGN (See et al., 2017) and BERTAbs (Liu and Lapata, 2019).",
      "startOffset" : 118,
      "endOffset" : 136
    }, {
      "referenceID" : 4,
      "context" : "Transformer has been widely used in language understanding and generation models due to its strong representation ability and concurrency, especially in pretrained models (Devlin et al., 2019; Lewis et al., 2020).",
      "startOffset" : 171,
      "endOffset" : 212
    }, {
      "referenceID" : 11,
      "context" : "Transformer has been widely used in language understanding and generation models due to its strong representation ability and concurrency, especially in pretrained models (Devlin et al., 2019; Lewis et al., 2020).",
      "startOffset" : 171,
      "endOffset" : 212
    }, {
      "referenceID" : 15,
      "context" : "Here we choose BERTAbs (Liu and Lapata, 2019) as the backbone structure since it performs well on many summarization datasets and is available for non-English languages such as Chinese.",
      "startOffset" : 23,
      "endOffset" : 45
    }, {
      "referenceID" : 12,
      "context" : "The metrics include traditional n-gram overlapping metrics, such as ROUGE (Lin and Hovy, 2002), BLEU (Papineni et al.",
      "startOffset" : 74,
      "endOffset" : 94
    }, {
      "referenceID" : 20,
      "context" : "The metrics include traditional n-gram overlapping metrics, such as ROUGE (Lin and Hovy, 2002), BLEU (Papineni et al., 2002), and distributed representation matching metrics, including BERTScore (Zhang et al.",
      "startOffset" : 101,
      "endOffset" : 124
    }, {
      "referenceID" : 26,
      "context" : ", 2002), and distributed representation matching metrics, including BERTScore (Zhang et al., 2020) and MoverScore (Zhao et al.",
      "startOffset" : 78,
      "endOffset" : 98
    }, {
      "referenceID" : 22,
      "context" : "35 points of ROUGE-2 higher than the best performance in the original paper (Song et al., 2020)).",
      "startOffset" : 76,
      "endOffset" : 95
    }, {
      "referenceID" : 2,
      "context" : "(9)Note that we do not mention the baseline Fast-RL (Chen and Bansal, 2018) in Lin et al.",
      "startOffset" : 52,
      "endOffset" : 75
    }, {
      "referenceID" : 22,
      "context" : "MC ROUGE-1 ROUGE-2 ROUGE-L BLEU BERTScore MoverScore user agent user agent user agent user agent user agent user agent (Song et al., 2020) 92.",
      "startOffset" : 119,
      "endOffset" : 138
    }, {
      "referenceID" : 13,
      "context" : "Agent Summary Completeness Analysis The agent summary often suffers semantic incompleteness due to missing key information from other roles (Lin et al., 2021).",
      "startOffset" : 140,
      "endOffset" : 158
    }, {
      "referenceID" : 13,
      "context" : "Following the evaluation method in (Lin et al., 2021), we treat each sentence in the summary as a sub-summary for a single topic and calculate the number of matching sub-summaries with the reference by a ROUGE-L-based matching algorithm.",
      "startOffset" : 35,
      "endOffset" : 53
    } ],
    "year" : 0,
    "abstractText" : "Role-oriented dialogue summarization is to generate summaries for different roles in the dialogue, e.g., merchants and consumers. Existing methods handle this task by summarizing each role’s content separately, thus are prone to ignore the information from other roles. However, we believe that other roles’ content could benefit the quality of summaries, such as the omitted information mentioned by other roles. Therefore, we propose a novel role interaction enhanced method for role-oriented dialogue summarization. It adopts cross attention and decoder self-attention interactions to interactively acquire other roles’ critical information. The cross attention interaction aims to select other roles’ critical dialogue utterances, while the decoder self-attention interaction aims to obtain key information from other roles’ summaries. Experimental results have shown that our proposed method significantly outperforms strong baselines on two public role-oriented dialogue summarization datasets. Extensive analyses have demonstrated that other roles’ content could help generate summaries with more complete semantics and correct topic structures.",
    "creator" : null
  }
}