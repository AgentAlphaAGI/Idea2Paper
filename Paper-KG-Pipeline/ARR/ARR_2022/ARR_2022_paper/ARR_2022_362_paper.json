{
  "name" : "ARR_2022_362_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Cross-Domain Classification of Moral Values",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "We provide the first extensive investigation on the effects of cross-domain classification of moral values from text. We compare a state-ofthe-art deep learning model (BERT) in seven domains and four cross-domain settings. We show that a value classifier can generalize and transfer knowledge to novel domains, albeit introducing catastrophic forgetting. We also highlight the typical classification errors in cross-domain value classification and compare the model predictions to the annotators agreement. Our results provide insights to computer and social scientists that seek to identify moral rhetoric in a domain of discourse."
    }, {
      "heading" : "1 Introduction",
      "text" : "Morality helps humans discern right from wrong. Pluralist moral philosophers argue that human morality can be represented, understood, and explained by a finite number of irreducible basic elements, referred to as moral values (Graham et al., 2013). The difference in our preferences over moral values explains how and why we think differently. For instance, both conservatives and liberals may agree that individual welfare is important. However, a conservative, who cherishes the values of freedom and independence, may believe that taxes should be decreased to attain more individual welfare. In contrast, a liberal, who cherishes the values of community and care, may believe that taxes should be increased to obtain welfare (Graham et al., 2009).\nIt is crucial to understand human morality to develop beneficial AI (Soares and Fallenstein, 2017; Russell, 2019). As artificial agents live and operate among humans (Akata et al., 2020), they must be able to comprehend and recognize the moral values that drive the differences in human behavior (Gabriel, 2020). The ability to understand moral rhetoric can be instrumental for, e.g., facilitating human-agent trust (Chhogyal et al., 2019; Mehrotra et al., 2021) and engineering value-aligned sociotechnical systems (Murukannaiah et al., 2020; Serramia et al., 2020; Montes and Sierra, 2021).\nThere are survey instruments to estimate individual value profiles (Schwartz, 2012; Graham et al., 2013). However, reasoning about moral values is challenging for humans (Le Dantec et al., 2009; Pommeranz et al., 2012). Further, in practical applications, e.g., to conduct meaningful conversations (Tigunova et al., 2019) or to identify online trends (Mooijman et al., 2018), artificial agents should be able to understand moral rhetoric on the fly.\nThe growing capabilities of natural language processing (NLP) enable the estimation of moral rhetoric from discourse (Lin et al., 2018; Mooijman et al., 2018; Rezapour et al., 2019; Hoover et al., 2020; Araque et al., 2020). Value classifiers can be used to identify the moral values underlying a piece of text on the fly. For instance, Mooijman et al. (2018) show that detecting moral values from tweets can predict violent protests.\nExisting value classifiers are evaluated on a specific dataset, without re-training or testing the classifier on a different dataset. This shows the ability of the classifier to predict values from text, but not the ability to transfer the learned knowledge across datasets. A critical aspect of moral values is that they are intrinsically linked to the domain under discussion (Pommeranz et al., 2012; Liscio et al., 2021). Moral value expressions may take different forms in different domains. For example, in the driving domain, the value of safety concerns speed\nlimits and seat belts, but in the COVID-19 domain, safety concerns social distancing and face masks. Thus, a word (broadly, language) may trigger different moral rhetoric in different domains. For example, in a libertarian blog, the word ‘taxes’ may be linked to the authority values, but in a socialist blog it may be linked to the community values. Then, it is crucial for a value classifier to recognize domain-specific connotations of moral rhetoric.\nCollecting and annotating a sufficient amount of training examples in each domain is expensive and time consuming. To reduce the need for new annotated examples, we can pretrain classifiers with similar available annotated data and transfer the acquired knowledge to a novel task—a practice known as transfer learning (Ruder, 2019). Despite the benefits, transfer learning poses wellknown challenges, including: (1) generalizability: how well does a classifier perform on novel data? (2) transferability: how well is knowledge transferred from one domain to another? and (3) catastrophic forgetting: to what extent is knowledge of a previous domain lost after training in a new domain? These challenges are crucial for value classification because of its domain-specific nature.\nWe perform the first comprehensive crossdomain evaluation of a value classifier. We employ the Moral Foundation Twitter Corpus (Hoover et al., 2020), consisting of seven datasets spanning different socio-political areas, annotated with the value taxonomy of the Moral Foundation Theory (Graham et al., 2013). Treating each dataset as a domain, we train a deep learning model (BERT Devlin et al. (2019)) in four training settings to evaluate the value classifier’s generalizability, transferability, and catastrophic forgetting.\nOur experiments show that (1) a value classifier can generalize to novel domains, especially when trained on a varied array of domains, (2) initializing a classifier with examples from different domains improves performance in novel domains even when little training data is available in the novel domains, (3) catastrophic forgetting occurs even when training on a small portion of data from the novel domain, and its impact must be considered when training on a novel domain, and (4) in the large majority of cases, in all considered training settings, there is at least one annotator that agrees with the model predictions. These results provide insights to researchers and practitioners on estimating moral values in different domains."
    }, {
      "heading" : "2 Background and Data",
      "text" : "We introduce the Moral Foundation Theory (MFT) (Graham et al., 2013) and the Moral Foundation Twitter Corpus (MFTC) (Hoover et al., 2020) used in our experiments.\nThe MFT is a well-established theory of moral values developed by social and cultural psychologists. It argues that human morality is composed of a finite set of innate moral foundations, similar to how the five taste receptors (for sweet, sour, salt, bitter, and umami) combine to yield the tastes we experience. The MFT includes five foundations, each composed of a vice–virtue duality, resulting in the 10 moral values shown in Table 1."
    }, {
      "heading" : "Foundation Definition",
      "text" : "Care/ Harm\nSupport for care for others/ Refrain from harming others\nFairness/ Cheating\nSupport for fairness and equality/ Refrain from cheating or exploiting others\nLoyalty/ Betrayal\nSupport for prioritizing one’s inner circle/ Refrain from betraying the inner circle\nAuthority/ Subversion Support for respecting authority and tradition/ Refrain from subverting authority or tradition\nPurity/ Degradation Support for the purity of sacred entities/ Refrain from corrupting such entities\nThe MFTC is composed of 35,108 tweets, divided into seven datasets, each corresponding to a topic: All Lives Matter (ALM), Baltimore protests (BLT), Black Lives Matter (BLM), hate speech and offensive language (DAV) (Davidson et al., 2017), 2016 presidential election (ELE), MeToo movement (MT), and hurricane Sandy (SND). These datasets from complex and diverse socio-political issues allow us to evaluate the transferability by treating each dataset as belonging to a domain.\nThe tweets were annotated by multiple annotators with the MFT taxonomy. Hoover et al. (2020) provide additional details on the annotation process. They recognize that the vice and the virtue constituting one moral foundation are expressed differently in natural language. For example, an utterance describing a care concern (e.g., taking care of one’s offspring) does not necessarily also contain harm expressions. For this reason, each tweet was annotated with all 10 individual moral values plus an additional nonmoral label, resulting in 11 possible labels per tweet. Due to the subjective nature of moral values, different annotators may\nlabel the same tweet differently. For this reason, Hoover et al. (2020) apply a majority vote to select the definitive label(s) of each tweet. Tweets with no majority label are labeled as nonmoral. Table 2 show three examples of annotated tweets.\nTable 3 shows the distribution of labels. The MeanIR is a measure of imbalance in a dataset (Charte et al., 2015). MeanIR is the mean of IRl for each label l, where IRl is the ratio of the number of instances having the majority (i.e., nonmoral) label and the number of instances having label l. The degree of imbalance varies largely across datasets, which is realistic since different domains are likely to have different distributions of moral content."
    }, {
      "heading" : "Foundation ALM BLT BLM DAV ELE MT SND",
      "text" : ""
    }, {
      "heading" : "3 Experimental Setup",
      "text" : "Predicting moral values is a multi-label classification problem. Given a set of textual documents, T , and a set of moral value labels, L = (l1, l2, . . . , ln), we wish to learn a mapping C : T 7→ P(L). Each element in P(L) is a binary vector, y = (y1, y2, . . . , yn), where yi = 1 if the corresponding text is labeled with li. The mapping C is learned via BERT (Devlin et al., 2019), a language representation model based on the Transformer architecture\n(Vaswani et al., 2017). We choose BERT as it represents the state-of-the-art for several NLP tasks. We provide additional details, including hyperparameters, in the Appendix."
    }, {
      "heading" : "3.1 Cross-Domain Evaluation",
      "text" : "To perform cross-domain evaluation, we partition the MFTC datasets into Tsource and Ttarget. We treat Tsource as available data and Ttarget as an incoming dataset from a novel domain. In our experiments, Ttarget is always composed of one MFTC dataset. We experiment with Tsource composed of one, three, and six datasets. We present the results for the setting with six datasets as Tsource in Section 4 and the other settings in the Appendix.\nFor each partition, we train a value classifier, C, in each of the four scenarios shown in Figure 1. These scenarios differ in how the classifier is trained. (1) In the source scenario, Tsource is the training set. (2) In the target scenario, Ttarget is the training set. (3) In the finetune scenario, the classifier is first trained on Tsource and then finetuned on Ttarget. (4) In the all scenario, the training set includes both Tsource and Ttarget.\nIn each scenario, the classifier is evaluated on both Tsource and Ttarget, resulting in eight settings (combinations of training scenario and evaluation set) as shown in Figure 1. For example, C(source, target) indicates that C is trained in the source scenario (i.e., on Tsource) and evaluated on Ttarget.\nAs we have seven partitions and four scenarios, we train 28 unique models. We evaluate the models on both Tsource and Ttarget, covering 56 settings."
    }, {
      "heading" : "3.2 Comparisons",
      "text" : "Our experimental setting (partitioning, training scenarios, and evaluation settings) enables a compre-\nhensive cross-domain evaluation of the value classifiers as described below. Baseline C(source, source) and C(target, target) show the performances of a value classifier on the training domain, when no cross-domain training is performed. Topline C(all, source) and C(all, target) represent the ideal scenario, where all data is simultaneously available for training. Generalizability C(source, target) and C(target, source) reflect the ability of a value classifier to generalize to a new domain. Transferability Comparing C(finetune, target) and C(target, target) shows whether the knowledge learned by pretraining on Tsource (finetune scenario) has an advantage over the absence of pretraining (target scenario). Catastrophic Forgetting Comparing C(finetune, source) and C(source, source) shows the extent to which the knowledge learned by training on Tsource is lost when finetuned on Ttarget."
    }, {
      "heading" : "3.3 Metrics",
      "text" : "Since the imbalance in our datasets varies greatly, we report both the micro F1-score and the macro F1-score in each setting. The micro F1-score, m, is the weighted (by class size) mean of the perlabel F1-scores. The macro F1-score, M , is the unweighted mean of the per-label F1-scores.\nWhen training and testing on the same set, we use 10-fold cross-validation with fixed splits into training and test data, and report the average F1scores over the 10 runs. For consistency, when testing on a set different from the training set, we test on 10 splits of the set (i.e., ultimately on the whole set) and report average F1-scores."
    }, {
      "heading" : "4 Results and Discussion",
      "text" : "We evaluate the performance of the model in four training scenarios (source, target, finetune, all). Table 4 reports the micro and macro F1-scores of the eight evaluation settings. The columns indicate the dataset used as Ttarget (e.g., in the BLT column, BLT is Ttarget and the remaining six datasets compose Tsource). The final column reports the average F1-scores over the seven datasets. We also report the results of the majority classifier which labels all tweets as nonmoral (the majority class in all datasets), for both Tsource and Ttarget.\nWe perform Wilcoxon’s ranksum test (Hollander\nand Wolfe, 1999) to evaluate whether two results significantly differ or not. In each column (and in the top-half or the bottom-half), we choose the setting with the highest F1-score and perform a pair-wise comparison with each of the other settings in that (half) column. We highlight, in bold, the best result and the results that are not significantly different (p > 0.05) from the best."
    }, {
      "heading" : "4.1 General Trends",
      "text" : "Before cross-domain analysis, we observe some general trends. First, the topline training scenario (all) leads to the best results when evaluating on both Tsource and Ttarget (Table 4). However, all is the ideal scenario. In the top half of the table, C(source, source) has comparable results to C(all, source), which is to be expected, since the two models are trained on similar data (six out of seven datasets in the source scenario, all seven in the all scenario). Analogously, in the bottom half of the table, the C(finetune, target) setting leads to results comparable to C(all, target). We analyze this result further in Section 4.3.\nSecond, the results are rather consistent across datasets when evaluating on Tsource (top half of Table 4), but have large differences when evaluating on Ttarget (bottom half of Table 4). These differences can be attributed to BLT and DAV, two highly-imbalanced datasets (Table 3). The class imbalance also justifies the large difference between micro and macro F1-scores for these two datasets."
    }, {
      "heading" : "4.2 Generalizability",
      "text" : "To evaluate generalizability, we analyze the results for the C(source, target) and C(target, source) settings. In C(source, target), Tsource includes six datasets and Ttarget includes one dataset. In contrast, in C(target, source), Tsource includes one dataset and Ttarget includes six datasets. Thus, C(target, source) is a more challenging setting for generalization than C(source, target).\nFirst, we observe that the model achieves better average F1-scores in the C(source, target) setting than the majority (target) baseline. This indicates that the moral rhetoric learned on a varied array of domains is generalizable to a novel domain to some extent, in spite of the domain-specific nature of moral values. However, the performances in C(source, target) are not on par with the best results on Ttarget, as we discuss in Section 4.3.\nSecond, we observe that the model achieves better average F1-scores in the C(target, source) set-"
    }, {
      "heading" : "Classifier Setting m M m M m M m M m M m M m M m M",
      "text" : "C(source, source) 73.9 65.6 73.9 68.3 71.2 61.8 71.1 66.4 73.3 66.4 75.7 68.0 74.5 66.5 73.4 66.1 C(target, source) 61.6 37.7 43.8 13.1 62.6 43.0 38.8 5.1 59.3 40.4 52.4 39.1 54.4 36.6 53.3 30.7 C(finetune, source) 70.3 57.2 61.2 47.8 69.2 54.9 56.6 41.9 70.5 61.5 67.7 60.5 68.0 60.8 66.2 54.9 C(all, source) 73.7 65.6 73.7 68.0 71.3 62.1 71.0 66.4 73.6 66.7 75.6 67.7 74.3 66.6 73.3 66.2\nMajority (source) 47.0 6.1 42.3 5.6 49.0 6.2 38.8 5.3 46.1 6.0 49.0 6.2 48.9 6.2 45.9 5.9\nC(source, target) 63.7 57.9 63.2 29.2 76.1 75.3 83.9 8.7 63.4 54.8 54.3 51.3 49.2 38.6 64.8 45.1 C(target, target) 68.0 56.8 71.4 23.5 84.4 84.6 92.2 9.0 70.9 52.6 59.4 55.9 65.3 44.6 73.1 46.7 C(finetune, target) 69.4 67.0 72.1 37.4 84.6 85.5 92.2 9.2 72.9 65.2 61.4 59.3 66.7 55.6 74.2 54.2 C(all, target) 69.9 67.0 71.2 34.7 83.9 85.2 90.4 9.3 71.1 62.3 61.4 59.3 66.3 55.6 73.5 53.3\nMajority (target) 37.9 5.1 64.8 7.4 28.3 4.2 92.2 8.7 44.5 5.7 27.9 4.4 26.4 4.0 46.0 5.6\nting than the majority (source) baseline, despite the more challenging setting. However, the results are just marginally better than the majority (source) baseline, showing the difficulty in generalizing from one to multiple domains.\nFinally, in both cases, when we look at the results for individual datasets, the generalizability result does not hold for BLT and DAV, which highlights the challenge of generalizing to domains with a skewed distribution of moral values."
    }, {
      "heading" : "4.3 Transferability",
      "text" : "Recall that, in the target scenario, a model is only trained on Ttarget, but in the finetune scenario, the model is first trained on Tsource and then finetuned on Ttarget. Thus, to evaluate transferability, we compare the C(finetune, target) and C(target, target) settings.\nFrom the average F1-scores in Table 4, we observe that C(finetune, target) performs better than or on par with C(target, target)—precisely, similar m and 8% increase of M . Thus, the benefits of finetuning are larger for the macro than the micro F1-scores. This suggests that pretraining on Tsource, which contains a more varied distribution of labels than Ttarget, improves the prediction of the minority labels in Ttarget.\nTo transfer knowledge from Tsource to Ttarget, typically, we need some labeled data in Ttarget. For the results in Table 4, we used 90% of Ttarget for training, and the leftover 10% for evaluating at each fold. However, in practice, such a large amount of training data may not be available in the target domain. Thus, we perform an additional experiment to compare C(target, target) and C(finetune, target), when trained or finetuned, respectively, on\na smaller portion of Ttarget (10%, 25%, and 50%) and tested on a fixed, randomly selected, 10% of Ttarget. Figure 2 shows this comparison. We report the average results of 10-fold cross-validations performed on each of the seven datasets.\nWe make an important observation from Figure 2. The finetuning paradigm does not require a large portion of Ttarget to perform well in the target domain. In contrast, the performance of C(target, target) increases (but does not surpass C(finetune, target)) as training data from Ttarget increases. Indeed, C(finetune, target) with 10% of Ttarget performs on par with C(target, target) trained on 90% of Ttarget. This result shows that transferring the knowledge of values from source domains to a target domain is valuable especially when the target domain has little training data."
    }, {
      "heading" : "4.4 Catastrophic Forgetting",
      "text" : "Recall that, in the source scenario, a model is only trained on Tsource, but in the finetune scenario, the model is first trained on Tsource and then finetuned on Ttarget. Thus, comparing C(finetune, source) and C(source, source) provides insight\non the extent to which a model forgot about Tsource because of finetuning on Ttarget.\nWe observe that the model suffers from catastrophic forgetting since finetuning on Ttarget reduces the performance on Tsource. The forgetting is most evident when finetuning on unbalanced datasets such as DAV than balanced datasets such as BLM. In fact, C(finetune, source) leads to only slightly worse results than C(source, source) in BLM (decrease of 2% in m and 7% in M ), with the difference being largest in DAV (decrease of 15% in m and 25% in M ).\nFigure 2 shows that the finetuning paradigm ensures good performances on Ttarget even when the model is trained on a small portion of Ttarget. Next, we evaluate catastrophic forgetting in the same setting, comparing C(source, source) and C(finetune, source) when the model is trained with increasing portions of Ttarget (10%, 25%, and 50%) as shown in Figure 3.\nFigure 3 indicates that catastrophic forgetting worsens as the model is trained with a larger portion of Ttarget. C(finetune, source) trained with 10% of Ttarget leads to a decrease of 4% in m and 7% in M compared to C(source, source) (evident by comparing the source flat blue line to the first red finetune square in Figure 3). Further, C(finetune, target) trained with 10% of Ttarget leads to an increase of 7% in m and 6% in M compared to C(source, target) (evident by comparing the average C(source, target) in Table 4 to the first red finetune square in Figure 2). These results show the tradeoff between the advantage of transfer learning and the impact of forgetting, even when finetuning with a small portion of Ttarget."
    }, {
      "heading" : "4.5 Misclassification Errors",
      "text" : "We reported F1-scores to provide an overview of the model performance in different training settings.\nNext, we investigate four types of misclassification errors (which add up to 100%) the models make: Error I A tweet labeled with one (or more) values is classified (by the model) as nonmoral. Error II A tweet labeled as nonmoral is classified with one (or more) values. Error III A tweet labeled with a value is classified with values from other foundations. Error IV A tweet labeled as a vice/virtue is classified as the opposite virtue/vice of the foundation.\nTable 5 shows the distribution of errors, averaged over the seven datasets.\nGeneralizability In C(target, source), Error I occurs largely more often than the other errors, indicating that, when generalizing from one to several domains, labeling value-laden tweets as nonmoral is the most common mistake. In contrast, in C(source, target), when generalizing from several to one domain, Error I is less prominent, indicating that the model attempts to classify moral rhetoric in the novel domain.\nTransferability Error III is more prevalent in C(target, target) than C(finetune, target). Thus, the confusion among moral values reduces when a model is pretrained on the source domain.\nCatastrophic Forgetting Error I occurs largely more often in C(finetune, source) than C(source, source), indicating that the major type of catastrophic forgetting is missing moral rhetoric in the source dataset.\nFinally, Error IV occurs seldom, suggesting that the models generally learn to not confuse between virtues and vices of the same moral foundation."
    }, {
      "heading" : "4.6 Annotators Agreement",
      "text" : "We analyze the correspondence between the model predictions and the annotators agreement. Each tweet in the MFTC was annotated by at least three and at most eight different annotators (Hoover et al.,\n2020, Table 1). More than 99% of the tweets were annotated by three to five annotators and 84% by three or four annotators. As described in Section 2, the majority agreement was selected for training and evaluation—that is, only values annotated by at least 50% of the annotators were retained as correct labels. However, given the subjectivity in value annotation, values labeled by a minority of annotators ought to be considered too.\nTables 6 and 7 show the percentage of annotators that agree with the model predictions considered as errors and accurate, respectively, averaged over the seven datasets. The columns indicate the percentage of annotators agreeing with the model prediction. For instance, if one out of the four workers who annotated a tweet agrees with the model prediction, we record a 25% agreement.\nFirst, we analyze the classification errors in Table 6. We observe that the sum of the last three columns is always larger than 50%. This indicates that, in all settings, more than half of the model classification errors are not severe in that at least one human annotator agrees with the model prediction. Then, we notice that the settings with the highest incidence of ‘bad’ classification errors (i.e., where no annotators agree with the model prediction) are those employed to evaluate\ngeneralizability (C(target, source) and C(source, target)) and catastrophic forgetting (C(finetune, source)). These results are explained by the harder challenge represented in these settings (refer to Sections 4.2 and 4.4 for a more in-depth discussion). Finally, we observe that there is a small percentage of errors with agreement between 34% and 50%. For the agreement to be in this range, a tweet must have been annotated by at least 5 annotators. However, 84% of the tweets in the MFTC have been annotated by four annotators or less, thus resulting in a smaller agreement in the last column.\nSecond, we analyze the correct predictions in Table 7. We notice, in all settings, a high correspondence between 100% agreement among annotators and correct model predictions—that is, tweets annotated with consistent agreement reliably lead to correct predictions. Further, we observe that the distributions of agreement and correct predictions are consistent across different settings."
    }, {
      "heading" : "5 Related Work",
      "text" : "We review closely related works on value estimation from text, and on cross-domain classification in NLP subfields relevant to value classification."
    }, {
      "heading" : "5.1 Value Estimation from Text",
      "text" : "Value estimation has been addressed from both unsupervised and supervised approaches. Unsupervised methods exploit value lexicons to identify values in text. Value lexicons are generated manually (Graham et al., 2009), via semi-automated methods (Wilson et al., 2018; Rezapour et al., 2019; Araque et al., 2020; Hopp et al., 2020), or expanded from an initial seed via NLP techniques (Ponizovskiy et al., 2020; Araque et al., 2021). Value lexicons are used to identify values in text through word count software (Pennebaker et al., 2001) or similarity in embedding space (Garten et al., 2018; Shen et al., 2019; Bahgat et al., 2020). However, adapting a lexicon to a novel domain is a significant additional effort as it requires identifying words that are relevant and removing words that are not relevant in the novel domain.\nSupervised methods employ the classification paradigm (Maheshwari et al., 2017; Lin et al., 2018; Mooijman et al., 2018; Hoover et al., 2020). A textual dataset is annotated with values belonging to a value taxonomy, and the labels are used to train a supervised model. This approach is akin to the one we use in this paper. However, in the reviewed\nliterature, no emphasis is put on the effect of crossdomain training. Further, the works mentioned above use binary classification to independently predict the presence of a value in text. That is, given N values, N classifiers are employed (one per value). This approach is limited in that it does not exploit the relationship among values. In contrast, we train a multi-label value classifier. However, our objective is not to compare binary and multi-label value classification but to evaluate the cross-domain capabilities (generalizability, transferability, and catastrophic forgetting) of a value classifier."
    }, {
      "heading" : "5.2 Cross-Domain NLP Classification",
      "text" : "Cross-domain classification is gaining attention (Aji et al., 2020; Nguyen et al., 2021; Rongali et al., 2021; Bornea et al., 2021; Markov and Daelemans, 2021). Ruder (2019) provides an overview of the basic terminology, including generalizability, transferability, and catastrophic forgetting.\nCross-domain classification has been investigated in NLP tasks such as sentiment analysis (AlMoslmi et al., 2017; Qu et al., 2019; Du et al., 2020), fake news detection (Fung et al., 2021; Silva et al., 2021; Yuan et al., 2021), and argument mining (Al-Khatib et al., 2016; Daxenberger et al., 2017; Thorn Jakobsen et al., 2021). These tasks are similar to value classification in that they aim to classify high-level constructs (such as sentiments and arguments). However, value classification stands out for its multi-label and domainspecific nature. Also, cross-domain classification is particularly important for values because reasoning about values (Pommeranz et al., 2012) and generating value-annotated datasets is very difficult."
    }, {
      "heading" : "6 Conclusions and Directions",
      "text" : "We perform a comprehensive cross-domain evaluation of a multi-label value classifier, by comparing a deep learning model (BERT) in seven domains with four cross-domain training scenarios. Our aim is to support practical applications of moral rhetoric classification. Our findings inform both computer scientists, e.g., (Mooijman et al., 2018), and social scientists, e.g., (Mouter et al., 2021), on training value classifiers. However, we do not provide a fixed recipe since the right model and approach depend on the time, resources, and data available.\nOur experiments show that a supervised value classifier generally exhibits the ability to classify\nmoral values across domains. However, the results are highly dependent on the distribution of moral rhetoric in the domains under analysis.\nOur experiments support the following key findings. First, a value classifier can generalize to novel domains, especially when trained on multiple domains. However, its performance on the novel domain improve even when trained with a small portion of data from the novel domain. Second, pretraining a value classifier with data from different domains has two benefits when finetuning the classifier. It yields (1) better performances on the novel domain than other settings, and (2) good performances even when little training data is available in the novel domain. Third, finetuning on a novel domain causes catastrophic forgetting of the domain it was pretrained with, even when finetuning on a small portion of data from the novel domain. Thus, the tradeoff between benefits of transferability and adverse effects of forgetting must be considered in choosing the extent of finetuning. Finally, despite the challenging nature of cross-domain value classification, we observe that the majority of classification errors are not severe in that, in all evaluation settings, at least one annotator agrees with the model prediction.\nOur investigation opens avenues for additional experiments with advanced methods to improve transfer learning (Howard and Ruder, 2018; Sun et al., 2019; Jiang et al., 2020; Nguyen et al., 2021) and mitigate catastrophic forgetting (Kirkpatrick et al., 2017; Li and Hoiem, 2018; Thompson et al., 2019). Further, based on the analysis of classification errors, we suggest incorporating the annotators (dis-)agreement into the training of the model, e.g., by treating the distributions of annotations as soft labels, as opposed to the current ‘one-hot’ majority approach (Basile et al., 2021)."
    }, {
      "heading" : "7 Ethical Considerations",
      "text" : "We discuss three ethical considerations relevant to our work. First, the MFTC is composed of monolingual tweets about US-centric topics. Whether or not our conclusions hold for results across different languages and cultures is yet to be evaluated. This limitation may cause the perpetuation of Western biases and values (Mehrabi et al., 2021). However, we believe that our experimental setup offers a systematic approach to studying such influence.\nSecond, the MFTC has low annotator agreement (Hoover et al., 2020, Table 6), potentially caused\nby the subjectivity and complexity of annotating values. Selecting the majority label as golden label may perpetuate the ‘tyranny’ of the majority, which is especially dangerous when dealing with values. We expose the impact of the annotator agreement in Section 4.6 and identify an avenue for addressing it as a future direction (Section 6).\nFinally, the importance of understanding moral values has been recognized by computer scientists (Russell, 2019) and designers (Friedman et al., 2008). However, we recognize that value classification can be misused, especially, when sensitive attributes such as gender and race are attached to the data. For instance, authorities could use it to automatically identify and suppress liberal minorities in non-liberal countries. Additional research is necessary for addressing such problems, e.g., by devising classifiers that mitigate bias and unfairness by design (Kleinberg et al., 2018; Dinan et al., 2020; Vargas and Cotterell, 2020)."
    }, {
      "heading" : "A Experimental Details",
      "text" : "As we train deep learning models, reproducibility is an issue due to the inherent randomness of the training procedure. Nevertheless, we seek to provide all possible tools for reproducing our experimental results. To do so, we attach our code and the complete set of results. Furthermore, the following sections describe our data preprocessing, the hyperparameters, the computing infrastructure, and the random seeds used in our experiments."
    }, {
      "heading" : "A.1 Data Preprocessing",
      "text" : "We choose to use the datasets as they are, despite their imbalanced label distribution (Table 3), since such imbalance is representative of realistic applications. We preprocess the tweets by removing URLs, emails, usernames and mentions. Next, we employ the Ekphrasis package1 to correct common spelling mistakes and unpack contractions. Finally, emojis are transformed into their respective words using the Python Emoji package2."
    }, {
      "heading" : "A.2 Hyperparameters",
      "text" : "To select the hyperparameters, we trained and evaluated the model on the entire MFTC corpus with 10-fold cross-validation. Table A1 shows the hyperparameters that were compared in this setting, highlighting in bold the best performing option that we then used in the experiments described in the paper. If a parameter is not present in the table, the default value supplied by the framework was used.\nTable A1: Hyperparameters tested and selected\nHyperparameters Options\nModel name bert-base-uncased Number of parameters 110M Max sequence length 64 Epochs 2, 3, 5 Batch size 16, 32, 64 Dropout 0.05, 0.1, 0.02 Optimizer AdamW Learning Rate 5*10-5 Loss function Binary Cross Entropy"
    }, {
      "heading" : "A.3 Computing Infrastructure",
      "text" : "The following are the main libraries and computing environment used in our experiments.\n• PyTorch: 1.8.1 1https://github.com/cbaziotis/\nekphrasis 2https://pypi.org/project/emoji/\n• TensorFlow: 2.5.0\n• FastText: 0.8.22\n• Hugginface’s Transformers: 4.6.0\n• NVIDIA GeForce RTX 2080 Ti GPU\n• CUDA: 11.2\n• cuDNN: 8.1.1.33\nRefer to the code base for a detailed list of the libraries we used, and their versions.\nThe following list details the amount of GPU hours spent for obtaining our results:\n• Tables 4, B1, and B2: 44 hours\n• Figures 2 and 3: 33 hours\n• Tables B3, B4, and B5: 24 hours\n• Table B6: 26 hours\nThe error analysis (Tables 5, 6, and 7) did not require additional GPU time."
    }, {
      "heading" : "A.4 Random Seeds",
      "text" : "In our experiments, we ensured that the same traintest splits are used across different runs of each experiment. Further, to control for randomness, we fixed the random seeds in the following libraries:\n• Python (random.seed);\n• NumPy (numpy.random.seed);\n• PyTorch (torch.manual_seed);\n• Tensorflow (tensorflow.random.set_seed)."
    }, {
      "heading" : "A.5 Artifacts Usage",
      "text" : "We have mainly used two artifacts in this research: the MFTC and BERT.\nThe MFTC was collected with the intent of facilitating NLP research on moral values (Hoover et al., 2020). It can be downloaded3 and used under the Creative Commons Attribution 4.0 license.\nBERT (Devlin et al., 2019) was created with the intent of performing, among others, text classification. Thus, we are using it as originally intended, under its Apache 2.0 distribution license4.\n3https://osf.io/k5n7y/ 4https://github.com/google-research/\nbert/blob/master/LICENSE"
    }, {
      "heading" : "B Extended Results",
      "text" : "In this Appendix we extend the results presented in the paper. The following results are not crucial for supporting our conclusions. Nevertheless, they provide additional details on our experiments."
    }, {
      "heading" : "B.1 Model Comparison",
      "text" : "We have presented the results of the transferability analysis with the BERT model. In order to evaluate whether our conclusions generalize to other model architectures, we repeat the experiment conducted in the paper (see Sections 3 and 4) with the following two additional models:\n• Long Short Term Memory (LSTM), a category of Recurrent Neural Networks (RNN). We choose LSTM as a baseline model since it is commonly used in moral value classification (Lin et al., 2018; Mooijman et al., 2018; Rezapour et al., 2019; Hoover et al., 2020).\n• fastText, a machine learning approach that learns character-level information, in contrast to the whole word representations LSTM employs. This flexibility makes fastText a good candidate for transfer learning. Further, we choose fastText as it attains performances on par with state-of-the-art deep learning methods, but is considerably faster.\nTables B1 and B2 present the results of the transferability analysis, performed and presented analogously to Table 4, for LSTM, fastText, and BERT. We observe that BERT outperforms fastText and LSTM in most settings. This is not surprising, since BERT is state-of-the-art for text classification. Both BERT and fastText outperform LSTM, the model extensively used for predicting moral values. Further, we notice that the general trends observed in Section 4.1 hold for all three models. Generalizability All three models achieve better average F1-scores in the C(source, target) setting than the majority (target) baseline. However, compared to the majority (source) baseline, C(target, source) performs worse with LSTM, comparably with fastText, and much better with BERT. This suggests that a contextualized representation, as in BERT, is necessary for value classification in novel domains, especially for the novel domains with a large moral vocabulary as is the case in C(target, source).\nTransferability From the average F1-scores in Table B2, we observe that C(finetune, target) performs better than or on par with C(target, target) across all three models. The benefits of finetuning are most evident for LSTM (7% increase in the average m and 17% increase in M ). The benefits can also be observed for fastText (similar m and 8% increase of M ) and BERT (similar m and 8% increase of M ), but to a lesser degree than LSTM.\nCatastrophic Forgetting We observe that all three models suffer from catastrophic forgetting since finetuning on Ttarget reduces the performance on Tsource. As mentioned in the paper, the degree of catastrophic forgetting is most evident when finetuning on unbalanced datasets such as DAV than balanced datasets such as BLM."
    }, {
      "heading" : "B.1.1 Training Time",
      "text" : "In some applications, e.g., estimating value trends on Twitter, value classifiers need to be re-trained frequently since the trends can shift fast. Similarly, to employ techniques such as active learning for value annotation requires training a classifier at every iteration to prompt for new labels. In such cases, training time is an important factor for selecting an approach and model. Figure B1 shows the average training time in logarithmic scale, for different models and scenarios (Appendix A.3 describes our computing infrastructure).\nLSTM fastText BERT\n1\n10\n100\n1,000\nSe co\nnd s\n(l og\nar ith\nm ic\nsc al\ne)\nsource target finetune all\nFigure B1: Average training time per model and scenario\nTwo considerations are evident. First, fastText trains significantly faster than the other two models. Second, for all three models, the training time is approximately proportional to the amount of data in the training set—the target and finetune scenarios employ a similar amount of data, which is roughly six times smaller than in the source and all scenarios.\nTable B1: Results of the four training scenarios and three models evaluated on Tsource. The columns indicate the dataset used as Ttarget. For each experiment we report micro F1-score (m, left-hand column) and macro F1-score (M , right-hand column).\nALM BLT BLM DAV ELE MT SND Average\nClassifier Setting m M m M m M m M m M m M m M m M\nL ST\nM C(source, source) 64.1 45.7 64.0 52.1 61.1 39.6 59.2 48.0 63.5 46.5 66.4 47.1 65.6 46.8 63.4 46.5 C(target, source) 47.8 19.3 41.0 6.1 53.5 25.6 38.8 5.1 51.1 20.2 39.1 11.9 35.1 16.1 43.8 14.9 C(finetune, source) 61.4 37.4 48.3 25.1 60.0 39.6 41.6 11.0 60.7 40.5 55.1 39.1 52.3 36.6 54.2 32.8 C(all, source) 64.5 46.7 63.2 49.2 62.3 41.4 59.3 47.7 64.2 48.6 66.4 48.7 65.8 48.1 63.7 47.2\nfa st\nTe xt C(source, source) 66.8 56.0 65.9 57.8 64.4 51.5 63.1 56.9 66.6 56.7 69.5 59.5 67.8 56.8 66.3 56.5 C(target, source) 54.5 30.9 42.7 8.5 56.4 33.1 38.7 5.1 52.2 30.0 48.9 22.0 41.3 20.3 47.8 21.4 C(finetune, source) 62.1 48.8 54.4 39.5 62.6 46.4 52.9 39.9 61.4 50.8 57.3 45.7 56.7 49.7 58.2 45.8 C(all, source) 66.9 56.3 66.0 57.5 64.8 52.1 63.1 56.7 66.9 57.0 68.7 58.2 67.5 56.4 66.3 56.3\nB E\nR T C(source, source) 73.9 65.6 73.9 68.3 71.2 61.8 71.1 66.4 73.3 66.4 75.7 68.0 74.5 66.5 73.4 66.1 C(target, source) 61.6 37.7 43.8 13.1 62.6 43.0 38.8 5.1 59.3 40.4 52.4 39.1 54.4 36.6 53.3 30.7 C(finetune, source) 70.3 57.2 61.2 47.8 69.2 54.9 56.6 41.9 70.5 61.5 67.7 60.5 68.0 60.8 66.2 54.9 C(all, source) 73.7 65.6 73.7 68.0 71.3 62.1 71.0 66.4 73.6 66.7 75.6 67.7 74.3 66.6 73.3 66.2\nMajority (source) 47.0 6.1 42.3 5.6 49.0 6.2 38.8 5.3 46.1 6.0 49.0 6.2 48.9 6.2 45.9 5.9\nTable B2: Results of the four training scenarios and three models evaluated on Ttarget. The columns indicate the dataset used as Ttarget. For each experiment we report micro F1-score (m, left-hand column) and macro F1-score (M , right-hand column).\nALM BLT BLM DAV ELE MT SND Average"
    }, {
      "heading" : "Classifier Setting m M m M m M m M m M m M m M m M",
      "text" : "L ST\nM C(source, target) 52.5 40.2 61.7 19.3 59.6 43.2 85.9 8.5 52.7 35.7 43.3 33.3 36.9 21.8 56.1 28.9 C(target, target) 47.2 25.7 64.1 8.2 71.6 55.8 92.2 9.0 56.4 24.5 37.2 18.3 50.1 26.4 59.8 24.0 C(finetune, target) 61.4 51.2 69.0 23.2 78.2 77.2 92.2 9.0 64.7 44.6 49.6 43.3 54.7 36.8 67.1 40.8 C(all, target) 57.6 48.7 65.2 20.3 71.1 64.4 90.3 9.1 60.3 42.3 47.8 41.2 51.1 35.3 63.3 37.3\nfa st\nTe xt C(source, target) 57.5 46.8 57.1 23.1 62.9 54.6 83.5 8.9 54.1 39.5 49.2 45.5 38.5 24.9 57.5 34.8 C(target, target) 62.4 50.4 69.2 18.3 77.6 74.2 92.1 9.0 63.8 39.5 49.4 40.8 57.4 34.0 67.4 38.0 C(finetune, target) 62.5 57.5 68.6 30.1 77.8 78.6 88.6 9.7 65.8 53.3 51.4 47.6 59.0 46.7 67.7 46.2 C(all, target) 61.8 55.3 66.8 30.4 75.2 75.3 88.1 9.8 63.1 51.6 52.5 49.2 57.1 45.1 66.4 45.2\nB E\nR T C(source, target) 63.7 57.9 63.2 29.2 76.1 75.3 83.9 8.7 63.4 54.8 54.3 51.3 49.2 38.6 64.8 45.1 C(target, target) 68.0 56.8 71.4 23.5 84.4 84.6 92.2 9.0 70.9 52.6 59.4 55.9 65.3 44.6 73.1 46.7 C(finetune, target) 69.4 67.0 72.1 37.4 84.6 85.5 92.2 9.2 72.9 65.2 61.4 59.3 66.7 55.6 74.2 54.2 C(all, target) 69.9 67.0 71.2 34.7 83.9 85.2 90.4 9.3 71.1 62.3 61.4 59.3 66.3 55.6 73.5 53.3\nMajority (target) 37.9 5.1 64.8 7.4 28.3 4.2 92.2 8.7 44.5 5.7 27.9 4.4 26.4 4.0 46.0 5.6\nB.2 Composition of Tsource In Section 3.1, we mention that in our experiments Ttarget is always composed of one dataset of the MFTC, while we test with Tsource being composed of one, three, or six datasets. In the main paper we present the results where Tsource is composed of six datasets. Here, we present the results where it is composed of one or three datasets, using BERT.\nB.2.1 One Dataset as Tsource Not all the settings described in Section 3.1 can be meaningfully replicated when Tsource is composed of just one dataset. For instance, C(source, source) and C(target, target) would coincide, as well as C(source, target) and C(target, source). Thus, in Tables B3, B4, and B5 we present the results along the lines of generalizability, transferability, and catastrophic forgetting, respectively. When possible, we compare the results to the results presented in the paper (where Tsource is composed of six datasets). As in the paper, we highlight in bold the best result and the results that are not significantly different from it. Generalizability To evaluate generalizability (Table B3), the model is trained on Tsource and evaluated on Ttarget, akin to the C(source, target) setting described in the paper. Thus, at the end of the table, we append the results of C(source, target) from Table 4 (where Tsource is composed of six datasets). First, we notice that the results are gener-\nTable B3: Generalizability: the model is trained on Tsource and evaluated on Ttarget.\nTtarget → ALM BLT BLM DAV ELE MT SND\nTsource ↓ m M m M m M m M m M m M m M\nALM - - 65.6 21.3 72.0 55.4 87.2 8.5 58.4 30.3 45.1 33.1 44.8 24.2 BLT 33.4 11.4 - - 36.0 17.6 90.9 8.6 44.9 8.4 26.9 9.2 30.3 7.3 BLM 64.1 53.6 64.2 21.6 - - 86.4 8.4 65.2 49.7 49.7 43.3 44.5 30.4 DAV 35.8 4.9 63.0 7.3 25.3 3.9 - - 46.6 6.0 27.8 4.5 25.2 3.9 ELE 53.7 35.2 63.5 22.7 60.8 49.8 85.8 9.6 - - 48.4 41.3 47.3 30.8 MT 47.9 43.8 58.8 20.5 54.9 48.3 49.9 6.0 54.7 41.9 - - 41.5 29.2 SND 47.7 33.5 54.8 22.6 50.6 37.2 79.1 8.6 48.9 33.6 42.8 35.1 - -\nSix 63.7 57.9 63.2 29.2 76.1 75.3 83.9 8.7 63.4 54.8 54.3 51.3 49.2 38.6\nTable B4: Transferability: the model is trained on Tsource, retrained on Ttarget, and evaluated on Ttarget.\nTtarget → ALM BLT BLM DAV ELE MT SND\nTsource ↓ m M m M m M m M m M m M m M\nALM - - 74.3 31.8 85.3 86.0 89.8 8.6 72.4 62.7 61.1 58.8 67.4 54.5 BLT 69.4 58.0 - - 82.9 83.6 91.7 8.7 72.1 62.7 58.4 55.4 65.2 47.2 BLM 66.9 60.8 72.6 33.4 - - 92.5 8.8 72.4 66.9 61.0 59.1 68.8 62.6 DAV 23.7 13.8 68.1 16.9 56.2 43.9 - - 46.9 33.1 29.6 16.2 46.6 25.5 ELE 68.6 61.1 72.1 36.2 82.9 83.5 92.5 8.8 - - 60.0 58.7 66.9 53.6 MT 66.7 60.2 72.9 36.4 83.8 84.1 90.1 8.6 73.4 61.1 - - 65.7 52.5 SND 69.6 66.7 73.9 34.7 83.6 85.1 91.9 8.7 68.7 58.8 60.7 56.4 - -\nSix 69.4 67.0 72.1 37.4 84.6 85.5 92.2 9.2 72.9 65.2 61.4 59.3 66.7 55.6\nTable B5: Catastrophic forgetting: the model is trained on Tsource, retrained on Ttarget, and evaluated on Tsource.\nTtarget → ALM BLT BLM DAV ELE MT SND No retrain\nTsource ↓ m M m M m M m M m M m M m M m M\nALM - - 48.4 34.6 67.0 64.3 49.2 24.3 60.6 55.2 57.2 52.5 60.1 57.7 68.0 56.8 BLT 66.0 24.0 - - 65.7 25.8 67.6 12.7 64.8 28.6 62.5 28.9 57.6 25.7 71.4 23.5 BLM 79.4 79.8 60.2 55.4 - - 52.2 40.5 77.7 78.1 74.9 74.5 74.5 76.6 84.4 84.6 DAV 45.1 4.3 91.5 8.7 70.3 6.9 - - 59.9 6.3 45.0 4.9 63.1 6.6 92.2 9.0 ELE 67.6 48.0 57.8 33.1 70.0 55.3 46.5 8.4 - - 63.8 56.7 59.8 52.8 70.9 52.6 MT 51.3 45.0 40.2 28.2 55.4 50.8 28.4 5.1 55.8 52.2 - - 54.3 51.0 59.4 55.9 SND 54.0 37.5 39.9 20.4 55.8 41.7 26.9 4.4 55.0 43.3 57.4 47.3 - - 65.3 44.6\nally better when Tsource is composed of six datasets. Further, there is no dataset that stands out as clearly better than the other six in generalizability.\nTransferability To evaluate transferability (Table B4), the model is trained on Tsource, retrained on Ttarget, and evaluated on Ttarget, akin to the C(finetune, target) setting described in the paper. Thus, at the end of the table, we append the results of C(finetune, target) from Table 4 (where Tsource is composed of six datasets). First, we notice that the results are generally better or on par to the results where Tsource is composed of six datasets. Further, there is no dataset that stands out as clearly better than the other six in transferability. These two aspects suggest that a combination of the six datasets as Tsource consistently leads to better transferability results. Catastrophic Forgetting To evaluate catastrophic forgetting (Table B5), the model is trained on Tsource, retrained on Ttarget, and evaluated on Tsource, akin to the C(finetune, source) setting described in the paper. However, we cannot compare the results with the C(finetune, source) setting, as the evaluation sets differ (one dataset in Table B5, six datasets in C(finetune, source) in Table 4). However, we compare to the case where the model is only trained on Tsource. Differently from the previous tables, the evaluation sets (i.e., Tsource) are consistent in every row, not in every column. Thus, we highlight the best results per row. It is evident that catastrophic forgetting happens even when Tsource is composed of one dataset. Further, there is no dataset that stands out as better than the other six in mitigating forgetting.\nTable B6: Results of the four training scenarios evaluated on Tsource and Ttarget, when Tsource is composed of three or six datasets. The columns indicate the dataset used as Ttarget. We report both micro F1-score (m, left column) and macro F1-score (M , right column).\nALM BLT BLM DAV ELE MT SND Average\nClassifier Setting m M m M m M m M m M m M m M m M\nth re\ne C(source, source) 70.9 68.8 66.1 62.5 67.2 63.4 76.1 70.3 71.2 69.1 75.0 71.8 72.4 69.6 71.3 67.9 C(target, source) 52.8 40.7 34.2 8.8 59.1 49.4 46.3 6.0 52.9 44.3 50.6 43.8 48.3 37.3 49.2 32.9 C(finetune, source) 64.1 59.4 50.9 38.5 65.0 58.8 58.7 34.6 66.9 63.7 68.2 65.7 65.0 62.7 62.7 54.8 C(all, source) 70.9 69.1 66.3 62.6 67.1 63.4 75.9 69.8 70.9 68.9 74.6 71.5 72.5 69.7 71.2 67.9\nsi x C(source, source) 73.9 65.6 73.9 68.3 71.2 61.8 71.1 66.4 73.3 66.4 75.7 68.0 74.5 66.5 73.4 66.1 C(target, source) 61.6 37.7 43.8 13.1 62.6 43.0 38.8 5.1 59.3 40.4 52.4 39.1 54.4 36.6 53.3 30.7 C(finetune, source) 70.3 57.2 61.2 47.8 69.2 54.9 56.6 41.9 70.5 61.5 67.7 60.5 68.0 60.8 66.2 54.9 C(all, source) 73.7 65.6 73.7 68.0 71.3 62.1 71.0 66.4 73.6 66.7 75.6 67.7 74.3 66.6 73.3 66.2\nth re\ne C(source, target) 64.8 58.9 61.4 26.6 77.1 74.5 85.3 8.8 60.0 54.7 54.9 51.7 51.3 41.1 65.0 45.2 C(target, target) 68.1 56.8 71.1 23.3 83.8 84.2 92.2 8.7 71.0 53.6 59.1 54.9 65.2 44.7 72.9 46.6 C(finetune, target) 70.1 67.4 72.6 37.4 84.9 85.4 92.2 8.7 72.9 64.7 61.2 59.6 68.0 58.3 74.5 54.5 C(all, target) 69.6 66.2 71.2 35.0 84.0 85.1 91.0 9.3 71.7 64.2 61.0 59.2 67.8 58.3 73.7 53.9\nsi x C(source, target) 63.7 57.9 63.2 29.2 76.1 75.3 83.9 8.7 63.4 54.8 54.3 51.3 49.2 38.6 64.8 45.1 C(target, target) 68.0 56.8 71.4 23.5 84.4 84.6 92.2 9.0 70.9 52.6 59.4 55.9 65.3 44.6 73.1 46.7 C(finetune, target) 69.4 67.0 72.1 37.4 84.6 85.5 92.2 9.2 72.9 65.2 61.4 59.3 66.7 55.6 74.2 54.2 C(all, target) 69.9 67.0 71.2 34.7 83.9 85.2 90.4 9.3 71.1 62.3 61.4 59.3 66.3 55.6 73.5 53.3\nMajority (target) 37.9 5.1 64.8 7.4 28.3 4.2 92.2 8.7 44.5 5.7 27.9 4.4 26.4 4.0 46.0 5.6\nB.2.2 Three Datasets as Tsource When employing three datasets as Tsource, the settings described in Section 3.1 can be meaningfully reproduced. However, the selection of the three datasets (out of the six available at each experiment) that compose Tsource is not trivial. Experimenting with all possible combinations would result in 6!3!(6−3)! = 20 experiments per setting. In order to simplify the experiments, we decide to test with only one combination of three datasets, selected as the best performing combination from the experiments in Section B.2.1. We average the results of Tables B3, B4, and B5, and for each dataset used as Ttarget, we select the three datasets that led to the best average performance. Due to the class imbalance of all datasets, one of the biggest challenges is to achieve good performances across all values. Thus, we decide to consider only the average macro F1-scores. We report the best resulting datasets in Table B7—for each dataset that we use as Ttarget in the following experiments, we use the indicated three datasets as Tsource.\nTable B6 reports the complete cross-domain evaluation results, analogously to Table 4. For further comparison, we add the results from Table 4 (where Tsource is composed of six datasets). The results in the bottom half of the table can be directly compared, as in each column the model is evaluated on the same test set. However, the results on the\nTable B7: The three datasets used as Tsource in Table B6\nTtarget Tsource ALM BLM, MT, SND BLT ELE, MT, SND BLM ALM, ELE, MT DAV BLT, BLM, ELE ELE BLM, MT, SND MT BLM, ELE, SND SND BLM, ELE, MT\ntop half cannot be directly compared, as the model is evaluated on different test sets (three and six datasets, respectively).\nIt is evident that the results are consistent with the results presented in the main paper. In the top half of the table, the best performing settings are C(source, source) and C(all, source), both when Tsource is composed of three and six datasets. In the bottom half, where the results can be directly compared, we notice that the best performing settings are consistent, and lead to comparable results.\nWe conclude that selecting the three best performing datasets as Tsource has neither advantage nor disadvantage over selecting all six datasets. However, selecting all six allows for a consistent evaluation, where all MFTC datasets are used in all evaluation settings, thus avoiding the arbitrary choice of datasets to be used as Tsource that we described at the beginning of this section."
    } ],
    "references" : [ {
      "title" : "In Neural Machine Translation, What Does Transfer Learning Transfer",
      "author" : [ "Alham Fikri Aji", "Nikolay Bogoychev", "Kenneth Heafield", "Rico Sennrich" ],
      "venue" : "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Aji et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Aji et al\\.",
      "year" : 2020
    }, {
      "title" : "A Research Agenda for Hybrid Intelligence",
      "author" : [ "Prakken", "Stefan Schlobach", "Linda van der Gaag", "Frank van Harmelen", "Herke van Hoof", "Birna van Riemsdijk", "Aimee van Wynsberghe", "Rineke Verbrugge", "Bart Verheij", "Piek Vossen", "Max Welling" ],
      "venue" : null,
      "citeRegEx" : "Prakken et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Prakken et al\\.",
      "year" : 2020
    }, {
      "title" : "Crossdomain mining of argumentative text through distant supervision",
      "author" : [ "Khalid Al-Khatib", "Henning Wachsmuth", "Matthias Hagen", "Jonas Köhler", "Benno Stein." ],
      "venue" : "2016 Conference of the North American Chapter of the Association for Computational",
      "citeRegEx" : "Al.Khatib et al\\.,? 2016",
      "shortCiteRegEx" : "Al.Khatib et al\\.",
      "year" : 2016
    }, {
      "title" : "Approaches to CrossDomain Sentiment Analysis: A Systematic Literature Review",
      "author" : [ "Tareq Al-Moslmi", "Nazlia Omar", "Salwani Abdullah", "Mohammed Albared." ],
      "venue" : "IEEE Access, 5:16173–16192.",
      "citeRegEx" : "Al.Moslmi et al\\.,? 2017",
      "shortCiteRegEx" : "Al.Moslmi et al\\.",
      "year" : 2017
    }, {
      "title" : "MoralStrength: Exploiting a moral lexicon and embedding similarity for moral foundations prediction",
      "author" : [ "Oscar Araque", "Lorenzo Gatti", "Kyriaki Kalimeri." ],
      "venue" : "Knowledge-Based Systems, 191:1–29.",
      "citeRegEx" : "Araque et al\\.,? 2020",
      "shortCiteRegEx" : "Araque et al\\.",
      "year" : 2020
    }, {
      "title" : "The Language of Liberty: A preliminary study",
      "author" : [ "Oscar Araque", "Lorenzo Gatti", "Kyriaki Kalimeri." ],
      "venue" : "Companion Proceedings of the Web Conference 2021 (WWW ’21 Companion), pages 1–4, Ljubljana, Slovenia. Association for Computing Machinery.",
      "citeRegEx" : "Araque et al\\.,? 2021",
      "shortCiteRegEx" : "Araque et al\\.",
      "year" : 2021
    }, {
      "title" : "Towards Using Word Embedding Vector Space for Better Cohort Analysis",
      "author" : [ "Mohamed Bahgat", "Steven R. Wilson", "Walid Magdy." ],
      "venue" : "Proceedings of the Fourteenth International AAAI Conference on Web and Social Media (ICWSM 2020), pages 919–923,",
      "citeRegEx" : "Bahgat et al\\.,? 2020",
      "shortCiteRegEx" : "Bahgat et al\\.",
      "year" : 2020
    }, {
      "title" : "We Need to Consider Disagreement in Evaluation",
      "author" : [ "Valerio Basile", "Michael Fell", "Tommaso Fornaciari", "Dirk Hovy", "Silviu Paun", "Barbara Plank", "Massimo Poesio", "Alexandra Uma." ],
      "venue" : "Proceedings of the 1st Workshop on Benchmarking: Past, Present and",
      "citeRegEx" : "Basile et al\\.,? 2021",
      "shortCiteRegEx" : "Basile et al\\.",
      "year" : 2021
    }, {
      "title" : "Multilingual Transfer Learning for QA Using Translation as Data Augmentation",
      "author" : [ "Mihaela Bornea", "Lin Pan", "Sara Rosenthal", "Radu Florian", "Avirup Sil." ],
      "venue" : "The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21) Multilingual, pages 12583–12591,",
      "citeRegEx" : "Bornea et al\\.,? 2021",
      "shortCiteRegEx" : "Bornea et al\\.",
      "year" : 2021
    }, {
      "title" : "Addressing imbalance in multilabel classification: Measures and random resampling algorithms",
      "author" : [ "Francisco Charte", "Antonio J. Rivera", "María J. del Jesus", "Francisco Herrera." ],
      "venue" : "Neurocomputing, 163:3–16.",
      "citeRegEx" : "Charte et al\\.,? 2015",
      "shortCiteRegEx" : "Charte et al\\.",
      "year" : 2015
    }, {
      "title" : "A value-based trust assessment model for multi-agent systems",
      "author" : [ "Kinzang Chhogyal", "Abhaya Nayak", "Aditya Ghose", "Hoa K. Dam." ],
      "venue" : "IJCAI International Joint Conference on Artificial Intelligence, pages 194–200.",
      "citeRegEx" : "Chhogyal et al\\.,? 2019",
      "shortCiteRegEx" : "Chhogyal et al\\.",
      "year" : 2019
    }, {
      "title" : "Automated hate speech detection and the problem of offensive language",
      "author" : [ "Thomas Davidson", "Dana Warmsley", "Michael Macy", "Ingmar Weber." ],
      "venue" : "Proceedings of the 11th International Conference on Web and Social Media, ICWSM 2017, pages 512–515.",
      "citeRegEx" : "Davidson et al\\.,? 2017",
      "shortCiteRegEx" : "Davidson et al\\.",
      "year" : 2017
    }, {
      "title" : "What is the essence of a claim? Cross-domain claim identification",
      "author" : [ "Johannes Daxenberger", "Steffen Eger", "Ivan Habernal", "Christian Stab", "Iryna Gurevych." ],
      "venue" : "EMNLP 2017 - Conference on Empirical Methods in Natural Language Processing, Proceed-",
      "citeRegEx" : "Daxenberger et al\\.,? 2017",
      "shortCiteRegEx" : "Daxenberger et al\\.",
      "year" : 2017
    }, {
      "title" : "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of NAACL, page 4171–4186.",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "MultiDimensional Gender Bias Classification",
      "author" : [ "Emily Dinan", "Angela Fan", "Ledell Wu", "Jason Weston", "Douwe Kiela", "Adina Williams." ],
      "venue" : "EMNLP 9",
      "citeRegEx" : "Dinan et al\\.,? 2020",
      "shortCiteRegEx" : "Dinan et al\\.",
      "year" : 2020
    }, {
      "title" : "Adversarial and Domain-Aware BERT for Cross-Domain Sentiment Analysis",
      "author" : [ "Chunning Du", "Haifeng Sun", "Jingyu Wang", "Qi Qi", "Jianxin Liao." ],
      "venue" : "Proceedings ofthe 58th Annual Meeting of the Association for Computational Linguistics, pages 4019–",
      "citeRegEx" : "Du et al\\.,? 2020",
      "shortCiteRegEx" : "Du et al\\.",
      "year" : 2020
    }, {
      "title" : "Value Sensitive Design and Information Systems",
      "author" : [ "Batya Friedman", "Peter H. Kahn", "Alan Borning." ],
      "venue" : "The Handbook of Information and Computer Ethics, pages 69–101. John Wiley & Sons, Inc., Hoboken, NJ, USA.",
      "citeRegEx" : "Friedman et al\\.,? 2008",
      "shortCiteRegEx" : "Friedman et al\\.",
      "year" : 2008
    }, {
      "title" : "InfoSurgeon: Cross-media fine-grained information consistency checking for fake news detection",
      "author" : [ "Yi Fung", "Christopher Thomas", "Revanth Gangi Reddy", "Sandeep Polisetty", "Heng Ji", "Shih-Fu Chang", "Kathleen McKeown", "Mohit Bansal", "Avi Sil." ],
      "venue" : "Proceed-",
      "citeRegEx" : "Fung et al\\.,? 2021",
      "shortCiteRegEx" : "Fung et al\\.",
      "year" : 2021
    }, {
      "title" : "Artificial Intelligence, Values, and Alignment",
      "author" : [ "Iason Gabriel." ],
      "venue" : "Minds and Machines, 30(3):411–437.",
      "citeRegEx" : "Gabriel.,? 2020",
      "shortCiteRegEx" : "Gabriel.",
      "year" : 2020
    }, {
      "title" : "Dictionaries and distributions: Combining expert knowledge and large scale textual data content analysis: Distributed dictionary representation",
      "author" : [ "Justin Garten", "Joe Hoover", "Kate M. Johnson", "Reihane Boghrati", "Carol Iskiwitch", "Morteza Dehghani" ],
      "venue" : null,
      "citeRegEx" : "Garten et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Garten et al\\.",
      "year" : 2018
    }, {
      "title" : "Moral Foundations Theory: The Pragmatic Validity of Moral Pluralism",
      "author" : [ "Jesse Graham", "Jonathan Haidt", "Sena Koleva", "Matt Motyl", "Ravi Iyer", "Sean P. Wojcik", "Peter H. Ditto." ],
      "venue" : "Advances in Experimental Social Psychology, volume 47, pages 55–130.",
      "citeRegEx" : "Graham et al\\.,? 2013",
      "shortCiteRegEx" : "Graham et al\\.",
      "year" : 2013
    }, {
      "title" : "Liberals and Conservatives Rely on Different Sets of Moral Foundations",
      "author" : [ "Jesse Graham", "Jonathan Haidt", "Brian A. Nosek." ],
      "venue" : "Journal of Personality and Social Psychology, 96(5):1029–1046.",
      "citeRegEx" : "Graham et al\\.,? 2009",
      "shortCiteRegEx" : "Graham et al\\.",
      "year" : 2009
    }, {
      "title" : "Nonparametric Statistical Methods",
      "author" : [ "Myles Hollander", "Douglas A. Wolfe." ],
      "venue" : "Wiley, New York, USA.",
      "citeRegEx" : "Hollander and Wolfe.,? 1999",
      "shortCiteRegEx" : "Hollander and Wolfe.",
      "year" : 1999
    }, {
      "title" : "Moral Foundations Twitter Corpus: A Collection of 35k Tweets Annotated for Moral Sentiment",
      "author" : [ "tian Leong", "Jun Yen Leung", "Arineh Mirinjian", "Morteza Dehghani" ],
      "venue" : "Social Psychological and Personality Science,",
      "citeRegEx" : "Leong et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Leong et al\\.",
      "year" : 2020
    }, {
      "title" : "The extended Moral Foundations Dictionary (eMFD): Development and applications of a crowd-sourced approach to extracting moral intuitions from text",
      "author" : [ "Frederic R. Hopp", "Jacob T. Fisher", "Devin Cornell", "Richard Huskey", "René Weber." ],
      "venue" : "Be-",
      "citeRegEx" : "Hopp et al\\.,? 2020",
      "shortCiteRegEx" : "Hopp et al\\.",
      "year" : 2020
    }, {
      "title" : "Universal language model fine-tuning for text classification",
      "author" : [ "Jeremy Howard", "Sebastian Ruder." ],
      "venue" : "ACL 2018 - 56th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (Long Papers), pages 328–339.",
      "citeRegEx" : "Howard and Ruder.,? 2018",
      "shortCiteRegEx" : "Howard and Ruder.",
      "year" : 2018
    }, {
      "title" : "SMART: Robust and Efficient Fine-Tuning for Pretrained Natural Language Models through Principled Regularized Optimization",
      "author" : [ "Haoming Jiang", "Pengcheng He", "Weizhu Chen", "Xiaodong Liu", "Jianfeng Gao", "Tuo Zhao." ],
      "venue" : "Proceedings ofthe 58th",
      "citeRegEx" : "Jiang et al\\.,? 2020",
      "shortCiteRegEx" : "Jiang et al\\.",
      "year" : 2020
    }, {
      "title" : "Algorithmic Fairness",
      "author" : [ "Jon Kleinberg", "Jens Ludwig", "Sendhil Mullainathan", "Ashesh Rambachan." ],
      "venue" : "AEA Papers and Proceedings, 108:22–27.",
      "citeRegEx" : "Kleinberg et al\\.,? 2018",
      "shortCiteRegEx" : "Kleinberg et al\\.",
      "year" : 2018
    }, {
      "title" : "Values as lived experience",
      "author" : [ "Christopher A. Le Dantec", "Erika Shehan Poole", "Susan P. Wyche." ],
      "venue" : "Proceedings of the 27th international conference on Human factors in computing systems - CHI 09, page 1141, New York, New York, USA. ACM Press.",
      "citeRegEx" : "Dantec et al\\.,? 2009",
      "shortCiteRegEx" : "Dantec et al\\.",
      "year" : 2009
    }, {
      "title" : "Learning without Forgetting",
      "author" : [ "Zhizhong Li", "Derek Hoiem." ],
      "venue" : "IEEE Transactions on Pattern Analysis and Machine Intelligence, 40(12):2935–2947.",
      "citeRegEx" : "Li and Hoiem.,? 2018",
      "shortCiteRegEx" : "Li and Hoiem.",
      "year" : 2018
    }, {
      "title" : "Acquiring Background Knowledge to Improve Moral Value Prediction",
      "author" : [ "Ying Lin", "Joe Hoover", "Gwenyth Portillo-Wightman", "Christina Park", "Morteza Dehghani", "Heng Ji." ],
      "venue" : "2018 IEEE/ACM International Conference on Advances in Social Networks Analysis",
      "citeRegEx" : "Lin et al\\.,? 2018",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2018
    }, {
      "title" : "A Collaborative Platform for Identifying Context-Specific Values",
      "author" : [ "Enrico Liscio", "Michiel van der Meer", "Catholijn M. Jonker", "Pradeep K. Murukannaiah." ],
      "venue" : "Proc. of the 20th International Conference on Autonomous Agents and Multiagent Systems (AA-",
      "citeRegEx" : "Liscio et al\\.,? 2021",
      "shortCiteRegEx" : "Liscio et al\\.",
      "year" : 2021
    }, {
      "title" : "A societal sentiment analysis: Predicting the values and ethics",
      "author" : [ "Tushar Maheshwari", "Aishwarya N. Reganti", "Samiksha Gupta", "Anupam Jamatia", "Upendra Kumar", "Björn Gambäck", "Amitava Das" ],
      "venue" : null,
      "citeRegEx" : "Maheshwari et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Maheshwari et al\\.",
      "year" : 2017
    }, {
      "title" : "Moralization in social",
      "author" : [ "Morteza Dehghani" ],
      "venue" : null,
      "citeRegEx" : "Dehghani.,? \\Q2018\\E",
      "shortCiteRegEx" : "Dehghani.",
      "year" : 2018
    }, {
      "title" : "Crosslingual transfer",
      "author" : [ "Thien Huu Nguyen" ],
      "venue" : null,
      "citeRegEx" : "Nguyen.,? \\Q2021\\E",
      "shortCiteRegEx" : "Nguyen.",
      "year" : 2021
    }, {
      "title" : "Elicitation of situated values: Need for tools to help stakeholders and designers to reflect and communicate",
      "author" : [ "Alina Pommeranz", "Christian Detweiler", "Pascal Wiggers", "Catholijn M. Jonker." ],
      "venue" : "Ethics and Information Technology, 14(4):285–303.",
      "citeRegEx" : "Pommeranz et al\\.,? 2012",
      "shortCiteRegEx" : "Pommeranz et al\\.",
      "year" : 2012
    }, {
      "title" : "Development and Validation of the Personal Values Dictionary: A Theory-Driven Tool for Investigating References to Basic Human Values in Text",
      "author" : [ "Vladimir Ponizovskiy", "Murat Ardag", "Lusine Grigoryan", "Ryan Boyd", "Henrik Dobewall", "Peter Holtz." ],
      "venue" : "Euro-",
      "citeRegEx" : "Ponizovskiy et al\\.,? 2020",
      "shortCiteRegEx" : "Ponizovskiy et al\\.",
      "year" : 2020
    }, {
      "title" : "Adversarial category alignment network for cross-domain sentiment classification",
      "author" : [ "Xiaoye Qu", "Zhikang Zou", "Yu Cheng", "Yang Yang", "Pan Zhou." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Qu et al\\.,? 2019",
      "shortCiteRegEx" : "Qu et al\\.",
      "year" : 2019
    }, {
      "title" : "Enhancing the Measurement of Social Effects by Capturing Morality",
      "author" : [ "Rezvaneh Rezapour", "Saumil H. Shah", "Jana Diesner." ],
      "venue" : "Proceedings ofthe 10th Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis, pages",
      "citeRegEx" : "Rezapour et al\\.,? 2019",
      "shortCiteRegEx" : "Rezapour et al\\.",
      "year" : 2019
    }, {
      "title" : "Exploring Transfer Learning For End-to-End Spoken Language Understanding",
      "author" : [ "Subendhu Rongali", "Beiye Liu", "Liwei Cai", "Konstantine Arkoudas", "Chengwei Su", "Wael Hamza." ],
      "venue" : "The Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-",
      "citeRegEx" : "Rongali et al\\.,? 2021",
      "shortCiteRegEx" : "Rongali et al\\.",
      "year" : 2021
    }, {
      "title" : "Neural Transfer Learning for Natural Language Processing",
      "author" : [ "Sebastian Ruder." ],
      "venue" : "Ph.D. thesis, NUI Galway.",
      "citeRegEx" : "Ruder.,? 2019",
      "shortCiteRegEx" : "Ruder.",
      "year" : 2019
    }, {
      "title" : "Human compatible: Artificial intelligence and the problem of control",
      "author" : [ "Stuart Russell." ],
      "venue" : "Penguin.",
      "citeRegEx" : "Russell.,? 2019",
      "shortCiteRegEx" : "Russell.",
      "year" : 2019
    }, {
      "title" : "An Overview of the Schwartz Theory of Basic Values",
      "author" : [ "Shalom H. Schwartz." ],
      "venue" : "Online readings in Psychology and Culture, 2(1):1–20.",
      "citeRegEx" : "Schwartz.,? 2012",
      "shortCiteRegEx" : "Schwartz.",
      "year" : 2012
    }, {
      "title" : "A Qualitative Approach to Composing Value-Aligned Norm Systems",
      "author" : [ "Marc Serramia", "Maite Lopez-Sanchez", "Juan A. Rodríguez-Aguilar." ],
      "venue" : "Proc. ofthe 19th International Conference on Autonomous Agents and Multiagent Systems (AAMAS 2020), pages",
      "citeRegEx" : "Serramia et al\\.,? 2020",
      "shortCiteRegEx" : "Serramia et al\\.",
      "year" : 2020
    }, {
      "title" : "Measuring Personal Values in Cross-Cultural User-Generated Content",
      "author" : [ "Yiting Shen", "Steven R. Wilson", "Rada Mihalcea." ],
      "venue" : "Proceedings of the 10th International Conference on Social Informatics (SocInfo ’19), pages 143–156. Springer.",
      "citeRegEx" : "Shen et al\\.,? 2019",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2019
    }, {
      "title" : "Embracing Domain Differences in Fake News: Cross-domain Fake News Detection using Multi-modal Data",
      "author" : [ "Amila Silva", "Ling Luo", "Shanika Karunasekera", "Christopher Leckie." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Silva et al\\.,? 2021",
      "shortCiteRegEx" : "Silva et al\\.",
      "year" : 2021
    }, {
      "title" : "Agent Foundations for Aligning Machine Intelligence with Human Interests: A Technical Research Agenda",
      "author" : [ "Nate Soares", "Benya Fallenstein." ],
      "venue" : "The Technological Singularity: Managing the Journey, pages 103–125. Springer, Berlin.",
      "citeRegEx" : "Soares and Fallenstein.,? 2017",
      "shortCiteRegEx" : "Soares and Fallenstein.",
      "year" : 2017
    }, {
      "title" : "How to Fine-Tune BERT for Text Classification?, volume 11856 LNAI",
      "author" : [ "Chi Sun", "Xipeng Qiu", "Yige Xu", "Xuanjing Huang." ],
      "venue" : "Springer International Publishing.",
      "citeRegEx" : "Sun et al\\.,? 2019",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2019
    }, {
      "title" : "Overcoming catastrophic forgetting during domain adaptation of neural machine translation",
      "author" : [ "Brian Thompson", "Jeremy Gwinnup", "Huda Khayrallah", "Kevin Duh", "Philipp Koehn." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of",
      "citeRegEx" : "Thompson et al\\.,? 2019",
      "shortCiteRegEx" : "Thompson et al\\.",
      "year" : 2019
    }, {
      "title" : "Spurious correlations in crosstopic argument mining",
      "author" : [ "Terne Sasha Thorn Jakobsen", "Maria Barrett", "Anders Søgaard." ],
      "venue" : "Proceedings of *SEM 2021: The Tenth Joint Conference on Lexical and Computational Semantics, pages 263–277, Online.",
      "citeRegEx" : "Jakobsen et al\\.,? 2021",
      "shortCiteRegEx" : "Jakobsen et al\\.",
      "year" : 2021
    }, {
      "title" : "Listening between the lines: Learning personal attributes from conversations",
      "author" : [ "Anna Tigunova", "Paramita Mirza", "Andrew Yates", "Gerhard Weikum." ],
      "venue" : "Proceedings of the World Wide Web Conference, WWW 2019, pages 1818–1828.",
      "citeRegEx" : "Tigunova et al\\.,? 2019",
      "shortCiteRegEx" : "Tigunova et al\\.",
      "year" : 2019
    }, {
      "title" : "Exploring the Linear Subspace Hypothesis in Gender Bias Mitigation",
      "author" : [ "Francisco Vargas", "Ryan Cotterell." ],
      "venue" : "EMNLP 2020 - 2020 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference, pages 2902–2913.",
      "citeRegEx" : "Vargas and Cotterell.,? 2020",
      "shortCiteRegEx" : "Vargas and Cotterell.",
      "year" : 2020
    }, {
      "title" : "Attention Is All You Need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "31st Conference on Neural Information Processing Systems, pages 5998–6008, Long Beach,",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Building and validating hierarchical lexicons with a case study on personal values",
      "author" : [ "Steven R. Wilson", "Yiting Shen", "Rada Mihalcea." ],
      "venue" : "Proceedings of the 10th International Conference on Social Informatics (SocInfo ’18), pages 455–470, St. Petersburg,",
      "citeRegEx" : "Wilson et al\\.,? 2018",
      "shortCiteRegEx" : "Wilson et al\\.",
      "year" : 2018
    }, {
      "title" : "Improving fake news detection with domain-adversarial and graph-attention neural network",
      "author" : [ "Hua Yuan", "Jie Zheng", "Qiongwei Ye", "Yu Qian", "Yan Zhang." ],
      "venue" : "Decision Support Systems, 53:113633. 12",
      "citeRegEx" : "Yuan et al\\.,? 2021",
      "shortCiteRegEx" : "Yuan et al\\.",
      "year" : 2021
    } ],
    "referenceMentions" : [ {
      "referenceID" : 20,
      "context" : "Pluralist moral philosophers argue that human morality can be represented, understood, and explained by a finite number of irreducible basic elements, referred to as moral values (Graham et al., 2013).",
      "startOffset" : 179,
      "endOffset" : 200
    }, {
      "referenceID" : 21,
      "context" : "In contrast, a liberal, who cherishes the values of community and care, may believe that taxes should be increased to obtain welfare (Graham et al., 2009).",
      "startOffset" : 133,
      "endOffset" : 154
    }, {
      "referenceID" : 46,
      "context" : "It is crucial to understand human morality to develop beneficial AI (Soares and Fallenstein, 2017; Russell, 2019).",
      "startOffset" : 68,
      "endOffset" : 113
    }, {
      "referenceID" : 41,
      "context" : "It is crucial to understand human morality to develop beneficial AI (Soares and Fallenstein, 2017; Russell, 2019).",
      "startOffset" : 68,
      "endOffset" : 113
    }, {
      "referenceID" : 18,
      "context" : ", 2020), they must be able to comprehend and recognize the moral values that drive the differences in human behavior (Gabriel, 2020).",
      "startOffset" : 117,
      "endOffset" : 132
    }, {
      "referenceID" : 10,
      "context" : ", facilitating human-agent trust (Chhogyal et al., 2019; Mehrotra et al., 2021) and engineering value-aligned socio-",
      "startOffset" : 33,
      "endOffset" : 79
    }, {
      "referenceID" : 42,
      "context" : "There are survey instruments to estimate individual value profiles (Schwartz, 2012; Graham et al., 2013).",
      "startOffset" : 67,
      "endOffset" : 104
    }, {
      "referenceID" : 20,
      "context" : "There are survey instruments to estimate individual value profiles (Schwartz, 2012; Graham et al., 2013).",
      "startOffset" : 67,
      "endOffset" : 104
    }, {
      "referenceID" : 35,
      "context" : "However, reasoning about moral values is challenging for humans (Le Dantec et al., 2009; Pommeranz et al., 2012).",
      "startOffset" : 64,
      "endOffset" : 112
    }, {
      "referenceID" : 50,
      "context" : ", to conduct meaningful conversations (Tigunova et al., 2019) or to identify online trends (Mooijman et al.",
      "startOffset" : 38,
      "endOffset" : 61
    }, {
      "referenceID" : 30,
      "context" : "The growing capabilities of natural language processing (NLP) enable the estimation of moral rhetoric from discourse (Lin et al., 2018; Mooijman et al., 2018; Rezapour et al., 2019; Hoover et al., 2020; Araque et al., 2020).",
      "startOffset" : 117,
      "endOffset" : 223
    }, {
      "referenceID" : 38,
      "context" : "The growing capabilities of natural language processing (NLP) enable the estimation of moral rhetoric from discourse (Lin et al., 2018; Mooijman et al., 2018; Rezapour et al., 2019; Hoover et al., 2020; Araque et al., 2020).",
      "startOffset" : 117,
      "endOffset" : 223
    }, {
      "referenceID" : 4,
      "context" : "The growing capabilities of natural language processing (NLP) enable the estimation of moral rhetoric from discourse (Lin et al., 2018; Mooijman et al., 2018; Rezapour et al., 2019; Hoover et al., 2020; Araque et al., 2020).",
      "startOffset" : 117,
      "endOffset" : 223
    }, {
      "referenceID" : 35,
      "context" : "A critical aspect of moral values is that they are intrinsically linked to the domain under discussion (Pommeranz et al., 2012; Liscio et al., 2021).",
      "startOffset" : 103,
      "endOffset" : 148
    }, {
      "referenceID" : 31,
      "context" : "A critical aspect of moral values is that they are intrinsically linked to the domain under discussion (Pommeranz et al., 2012; Liscio et al., 2021).",
      "startOffset" : 103,
      "endOffset" : 148
    }, {
      "referenceID" : 40,
      "context" : "notated examples, we can pretrain classifiers with similar available annotated data and transfer the acquired knowledge to a novel task—a practice known as transfer learning (Ruder, 2019).",
      "startOffset" : 174,
      "endOffset" : 187
    }, {
      "referenceID" : 20,
      "context" : ", 2020), consisting of seven datasets spanning different socio-political areas, annotated with the value taxonomy of the Moral Foundation Theory (Graham et al., 2013).",
      "startOffset" : 145,
      "endOffset" : 166
    }, {
      "referenceID" : 20,
      "context" : "We introduce the Moral Foundation Theory (MFT) (Graham et al., 2013) and the Moral Foundation Twitter Corpus (MFTC) (Hoover et al.",
      "startOffset" : 47,
      "endOffset" : 68
    }, {
      "referenceID" : 11,
      "context" : "The MFTC is composed of 35,108 tweets, divided into seven datasets, each corresponding to a topic: All Lives Matter (ALM), Baltimore protests (BLT), Black Lives Matter (BLM), hate speech and offensive language (DAV) (Davidson et al., 2017), 2016 presidential election (ELE), MeToo movement (MT), and hurricane Sandy (SND).",
      "startOffset" : 216,
      "endOffset" : 239
    }, {
      "referenceID" : 9,
      "context" : "The MeanIR is a measure of imbalance in a dataset (Charte et al., 2015).",
      "startOffset" : 50,
      "endOffset" : 71
    }, {
      "referenceID" : 13,
      "context" : "The mapping C is learned via BERT (Devlin et al., 2019), a language representation model based on the Transformer architecture (Vaswani et al.",
      "startOffset" : 34,
      "endOffset" : 55
    }, {
      "referenceID" : 52,
      "context" : ", 2019), a language representation model based on the Transformer architecture (Vaswani et al., 2017).",
      "startOffset" : 79,
      "endOffset" : 101
    }, {
      "referenceID" : 22,
      "context" : "We perform Wilcoxon’s ranksum test (Hollander and Wolfe, 1999) to evaluate whether two results significantly differ or not.",
      "startOffset" : 35,
      "endOffset" : 62
    }, {
      "referenceID" : 21,
      "context" : "Value lexicons are generated manually (Graham et al., 2009), via semi-automated methods (Wilson et al.",
      "startOffset" : 38,
      "endOffset" : 59
    }, {
      "referenceID" : 53,
      "context" : ", 2009), via semi-automated methods (Wilson et al., 2018; Rezapour et al., 2019; Araque et al., 2020; Hopp et al., 2020), or expanded from an initial seed via NLP techniques (Ponizovskiy et al.",
      "startOffset" : 36,
      "endOffset" : 120
    }, {
      "referenceID" : 38,
      "context" : ", 2009), via semi-automated methods (Wilson et al., 2018; Rezapour et al., 2019; Araque et al., 2020; Hopp et al., 2020), or expanded from an initial seed via NLP techniques (Ponizovskiy et al.",
      "startOffset" : 36,
      "endOffset" : 120
    }, {
      "referenceID" : 4,
      "context" : ", 2009), via semi-automated methods (Wilson et al., 2018; Rezapour et al., 2019; Araque et al., 2020; Hopp et al., 2020), or expanded from an initial seed via NLP techniques (Ponizovskiy et al.",
      "startOffset" : 36,
      "endOffset" : 120
    }, {
      "referenceID" : 24,
      "context" : ", 2009), via semi-automated methods (Wilson et al., 2018; Rezapour et al., 2019; Araque et al., 2020; Hopp et al., 2020), or expanded from an initial seed via NLP techniques (Ponizovskiy et al.",
      "startOffset" : 36,
      "endOffset" : 120
    }, {
      "referenceID" : 36,
      "context" : ", 2020), or expanded from an initial seed via NLP techniques (Ponizovskiy et al., 2020; Araque et al., 2021).",
      "startOffset" : 61,
      "endOffset" : 108
    }, {
      "referenceID" : 5,
      "context" : ", 2020), or expanded from an initial seed via NLP techniques (Ponizovskiy et al., 2020; Araque et al., 2021).",
      "startOffset" : 61,
      "endOffset" : 108
    }, {
      "referenceID" : 19,
      "context" : ", 2001) or similarity in embedding space (Garten et al., 2018; Shen et al., 2019; Bahgat et al., 2020).",
      "startOffset" : 41,
      "endOffset" : 102
    }, {
      "referenceID" : 44,
      "context" : ", 2001) or similarity in embedding space (Garten et al., 2018; Shen et al., 2019; Bahgat et al., 2020).",
      "startOffset" : 41,
      "endOffset" : 102
    }, {
      "referenceID" : 6,
      "context" : ", 2001) or similarity in embedding space (Garten et al., 2018; Shen et al., 2019; Bahgat et al., 2020).",
      "startOffset" : 41,
      "endOffset" : 102
    }, {
      "referenceID" : 32,
      "context" : "Supervised methods employ the classification paradigm (Maheshwari et al., 2017; Lin et al., 2018; Mooijman et al., 2018; Hoover et al., 2020).",
      "startOffset" : 54,
      "endOffset" : 141
    }, {
      "referenceID" : 30,
      "context" : "Supervised methods employ the classification paradigm (Maheshwari et al., 2017; Lin et al., 2018; Mooijman et al., 2018; Hoover et al., 2020).",
      "startOffset" : 54,
      "endOffset" : 141
    }, {
      "referenceID" : 0,
      "context" : "Cross-domain classification is gaining attention (Aji et al., 2020; Nguyen et al., 2021; Rongali et al., 2021; Bornea et al., 2021; Markov and Daelemans, 2021).",
      "startOffset" : 49,
      "endOffset" : 159
    }, {
      "referenceID" : 39,
      "context" : "Cross-domain classification is gaining attention (Aji et al., 2020; Nguyen et al., 2021; Rongali et al., 2021; Bornea et al., 2021; Markov and Daelemans, 2021).",
      "startOffset" : 49,
      "endOffset" : 159
    }, {
      "referenceID" : 8,
      "context" : "Cross-domain classification is gaining attention (Aji et al., 2020; Nguyen et al., 2021; Rongali et al., 2021; Bornea et al., 2021; Markov and Daelemans, 2021).",
      "startOffset" : 49,
      "endOffset" : 159
    }, {
      "referenceID" : 17,
      "context" : ", 2020), fake news detection (Fung et al., 2021; Silva et al., 2021; Yuan et al., 2021), and argument mining (Al-Khatib et al.",
      "startOffset" : 29,
      "endOffset" : 87
    }, {
      "referenceID" : 45,
      "context" : ", 2020), fake news detection (Fung et al., 2021; Silva et al., 2021; Yuan et al., 2021), and argument mining (Al-Khatib et al.",
      "startOffset" : 29,
      "endOffset" : 87
    }, {
      "referenceID" : 54,
      "context" : ", 2020), fake news detection (Fung et al., 2021; Silva et al., 2021; Yuan et al., 2021), and argument mining (Al-Khatib et al.",
      "startOffset" : 29,
      "endOffset" : 87
    }, {
      "referenceID" : 35,
      "context" : "Also, cross-domain classification is particularly important for values because reasoning about values (Pommeranz et al., 2012) and generating value-annotated datasets is very difficult.",
      "startOffset" : 102,
      "endOffset" : 126
    }, {
      "referenceID" : 25,
      "context" : "experiments with advanced methods to improve transfer learning (Howard and Ruder, 2018; Sun et al., 2019; Jiang et al., 2020; Nguyen et al., 2021) and mitigate catastrophic forgetting (Kirkpatrick et al.",
      "startOffset" : 63,
      "endOffset" : 146
    }, {
      "referenceID" : 47,
      "context" : "experiments with advanced methods to improve transfer learning (Howard and Ruder, 2018; Sun et al., 2019; Jiang et al., 2020; Nguyen et al., 2021) and mitigate catastrophic forgetting (Kirkpatrick et al.",
      "startOffset" : 63,
      "endOffset" : 146
    }, {
      "referenceID" : 26,
      "context" : "experiments with advanced methods to improve transfer learning (Howard and Ruder, 2018; Sun et al., 2019; Jiang et al., 2020; Nguyen et al., 2021) and mitigate catastrophic forgetting (Kirkpatrick et al.",
      "startOffset" : 63,
      "endOffset" : 146
    }, {
      "referenceID" : 29,
      "context" : ", 2021) and mitigate catastrophic forgetting (Kirkpatrick et al., 2017; Li and Hoiem, 2018; Thompson et al., 2019).",
      "startOffset" : 45,
      "endOffset" : 114
    }, {
      "referenceID" : 48,
      "context" : ", 2021) and mitigate catastrophic forgetting (Kirkpatrick et al., 2017; Li and Hoiem, 2018; Thompson et al., 2019).",
      "startOffset" : 45,
      "endOffset" : 114
    }, {
      "referenceID" : 7,
      "context" : ", by treating the distributions of annotations as soft labels, as opposed to the current ‘one-hot’ majority approach (Basile et al., 2021).",
      "startOffset" : 117,
      "endOffset" : 138
    }, {
      "referenceID" : 41,
      "context" : "Finally, the importance of understanding moral values has been recognized by computer scientists (Russell, 2019) and designers (Friedman et al.",
      "startOffset" : 97,
      "endOffset" : 112
    }, {
      "referenceID" : 16,
      "context" : "Finally, the importance of understanding moral values has been recognized by computer scientists (Russell, 2019) and designers (Friedman et al., 2008).",
      "startOffset" : 127,
      "endOffset" : 150
    }, {
      "referenceID" : 27,
      "context" : ", by devising classifiers that mitigate bias and unfairness by design (Kleinberg et al., 2018; Dinan et al., 2020; Vargas and Cotterell, 2020).",
      "startOffset" : 70,
      "endOffset" : 142
    }, {
      "referenceID" : 14,
      "context" : ", by devising classifiers that mitigate bias and unfairness by design (Kleinberg et al., 2018; Dinan et al., 2020; Vargas and Cotterell, 2020).",
      "startOffset" : 70,
      "endOffset" : 142
    }, {
      "referenceID" : 51,
      "context" : ", by devising classifiers that mitigate bias and unfairness by design (Kleinberg et al., 2018; Dinan et al., 2020; Vargas and Cotterell, 2020).",
      "startOffset" : 70,
      "endOffset" : 142
    } ],
    "year" : 0,
    "abstractText" : "Moral values influence how we interpret and act upon the information we receive. Identifying human moral values is essential for building artificial intelligence that can understand and live among humans. Recent progress in natural language processing allows the identification of moral values in textual discourse. However, the domain-specific nature of moral rhetoric introduces challenges in transferring knowledge from one domain to the other. We provide the first extensive investigation on the effects of cross-domain classification of moral values from text. We compare a state-ofthe-art deep learning model (BERT) in seven domains and four cross-domain settings. We show that a value classifier can generalize and transfer knowledge to novel domains, albeit introducing catastrophic forgetting. We also highlight the typical classification errors in cross-domain value classification and compare the model predictions to the annotators agreement. Our results provide insights to computer and social scientists that seek to identify moral rhetoric in a domain of discourse.",
    "creator" : null
  }
}