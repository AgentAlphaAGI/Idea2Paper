{
  "name" : "ARR_2022_166_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "What does it take to bake a cake? The RecipeRef corpus and anaphora resolution in procedural text",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Anaphora resolution is a core component in information extraction tasks (Poesio et al., 2016; Rösiger, 2019) and critical for various downstream natural language processing tasks, such as named entity recognition (Dai et al., 2019) and machine translation (Stanovsky et al., 2019). It consists of two primary anaphoric types, coreference (Ng, 2017; Clark and Manning, 2015) and bridging (Asher and Lascarides, 1998; Rösiger et al., 2018). Most anaphora corpora (Pradhan et al., 2012; Ghaddar and Langlais, 2016a; Poesio et al., 2008), however, only focus on either coreference or bridging. To fill the gap in anaphora resolution, it is becoming increasingly important to have both types annotated.\nCurrent research on anaphora resolution is mostly based on declarative text (Pradhan et al., 2012; Ghaddar and Langlais, 2016b; Rösiger, 2018a; Hou et al., 2018), such as news or dialogue. Procedural text, such as patents describing chemical synthesis or instruction manuals, has received more limited attention although it is critical\nfor human knowledge (Yamakata et al., 2020). In turn, correct resolution of entities is the cornerstone of procedural text comprehension—resolution of anaphora in these texts is required to determine what action applies to which entity.\nWe focus in this work on the procedural text type of recipes. As shown in Fig 1, recipes have rich and complex anaphora phenomena. Here, the expression the biscuits appears several times in text; while each occurrence relates to the same biscuits concept, their state and semantic meaning vary.\nWe aim to address anaphora resolution in procedural text, especially for recipes, identifying anaphoric references and determining the relationships among the entities. We generalize an existing anaphora annotation schema developed for chemical patents (Fang et al., 2021a,b) to the context of recipes and define four types of anaphora relationships, encompassing coreference and bridging. We then create a dataset based on this schema and achieve high inner annotator agreement with two annotators experienced with the domain. We further analyze the textual properties of procedural texts, i.e. chemical patents and recipes, and explore the feasibility of applying transfer learning from the chemical domain to solve recipe anaphora resolution problem. The dataset and related code are publicly available.1\nOur contributions in this paper include: (1) generalisation of the anaphora annotation framework from chemical patents for modelling anaphoric phenomena in recipes; (2) creation of a publicly accessible recipe anaphora resolution dataset based on the annotation framework; (3) investigation of the textual properties of chemical patents and recipes; and (4) demonstration of the benefit of utilizing procedural knowledge from the chemical domain to solve recipe anaphora resolution via transfer learning.\n1[link withhold for anonymous submission]"
    }, {
      "heading" : "2 Related Work",
      "text" : "Anaphora relation subsumes two referring types, coreference — expressions in the text that refer to the same entity (Clark and Manning, 2015; Ng, 2017), and bridging — expressions that are linked via semantic, lexical, or encyclopedic relations (Asher and Lascarides, 1998; Hou et al., 2018).\nExisting anaphora corpora mostly focus on declarative text across various domains (Poesio et al., 2008; Pradhan et al., 2012; Ghaddar and Langlais, 2016b; Cohen et al., 2017). A few procedural corpora are annotated for anaphora resolution but most only have coreference annotated (Mysore et al., 2019; Friedrich et al., 2020).\nPradhan et al. (2012) propose the CoNLL 2012 corpus for generic coreference resolution. It consists of three languages, English, Chinese and Arabic, in declarative texts including news and magazine articles. This corpus follows the OntoNotes 5.0 (Weischedel et al., 2013) annotation, modelling coreference in terms of two subtypes: Identity, where the anaphoric references and referents are identical, and Appositive, where a noun phrase is modified by an intermediately-adjacent noun phrase. It models coreference as a clustering task and the direction of relations is not preserved. Following the same annotation framework largely, the WikiCoref corpus (Ghaddar and Langlais, 2016b) annotates Wikipedia texts.\nBioNLP-ST 2011 (Nguyen et al., 2011) is a generelated coreference corpus based on abstracts from biomedical publications. It consists of four types of coreference: RELAT (relative pronouns or relative adjectives, e.g. that), PRON (pronouns, e.g. it),\nDNP (definite NPs or demonstrative NPs, e.g. NPs that begin with the) and APPOS (coreferences in apposition). As it only focuses on gene-related annotation, the coreference is limited. CRAFTST 2019 (Cohen et al., 2017) annotates 97 full biomedical articles for coreference resolution based on the OntoNotes 5.0 annotation framework with minor adaptations. Compared to the BioNLP 2011 corpus, it contains a wider range of annotations and is not limited to only abstracts. SCIERC (Luan et al., 2018) contains 500 abstracts from scientific articles. They annotate coreference of any two expressions that point to the same entity.\nDue to the complexities of defining bridging (Zeldes, 2017; Hou et al., 2018), different corpora have adopted different definitions of bridging. According to Rösiger et al. (2018), bridging can be divided into: referential, where the anaphoric references rely on the referent to be interpretable (e.g. a new town hall - the door, the old oak tree - leaves, etc.), and lexical, describing lexical-semantic relations, such as meronymy or hyponymy (e.g. Europe and Spain are in a whole-part relation). The ARRAU corpus (Poesio et al., 2008) consists of three types of declarative text: news, dialogue and narrative text. The bridging annotations are mostly lexical, with few referential. The ISNotes corpus (Hou et al., 2018) is based on 50 Wall Street Journal (WSJ) texts from the OntoNotes corpus, and contains both coreference and referential bridging. Similar to ISNotes, BASHI (Rösiger, 2018a) is based on another 50 WSJ texts from OntoNotes with referential bridging. With the same annotation scheme as BASHI, SciCorp (Rösiger, 2016)\nfocuses on scientific text and referential bridging.\nThere are a few domain-specific anaphora corpora for procedural text. The ChEMU-ref corpus (Fang et al., 2021a) contains 1,500 chemical patent excerpts describing chemical reactions. Based on generic and chemical knowledge, they model five types of anaphora relationships, i.e. Coreference, Transfers, Reaction-associated, Work-up and Contained. Friedrich et al. (2020) propose the SOFCExp corpus based on 45 material sciences articles for the information extraction task. As this corpus mainly focuses on named entity extraction and relation extraction, coreference is presented as a supplemented annotation based on the notion of coindexation between a common noun or a pronoun and a more specific mention appears earlier in the text. Mysore et al. (2019) work on 230 synthesis procedures and capture coreference within text in parenthesis, coreferent abbreviation, etc. The InScript corpus (Modi et al., 2016) consists of 1,000 stories from 10 different scenarios and annotates coreference for noun phrases.\nRecent work in recipe comprehension includes visual instructions (Huang et al., 2017; Nishimura et al., 2020) and linguistic texts (Agarwal and Miller, 2011; Kiddon et al., 2015; Jiang et al., 2020) across Japanese (Harashima and Hiramatsu, 2020; Harashima et al., 2016) and English (Batra et al., 2020; Marin et al., 2019). Most research models linguistic recipes as a workflow graph based on actions (Kiddon et al., 2015; Mori et al., 2014; Yamakata et al., 2020), where the vertices represent name entities (e.g. action, food, etc.) and edges represent processing information (e.g. action complement, food complement, etc.). Although interactions among ingredients can be derived via action nodes, this approach doesn’t sufficiently capture anaphoric phenomena, i.e. coreference and bridging. The RISeC corpus (Jiang et al., 2020) identifies candidate expressions for zero anaphora verbs in English recipes. However, they do not capture generic anaphoric phenomena.\nMost research handles coreference and bridging separately due to limited data availability. For coreference resolution, span ranking models (Lee et al., 2017, 2018) have become the benchmark method over mention ranking models (Clark and Manning, 2015, 2016a,b; Wiseman et al., 2015, 2016). Various span ranking variants have proposed (Zhang et al., 2018; Grobol, 2019; Kantor and Globerson, 2019) and achieved strong perfor-\nmance. With the increasing amount of coreference corpora, transfer learning (Brack et al., 2021; Xia and Van Durme, 2021) involving pretraining on a source domain and fine-tuning on a target domain has shown great potential to improve coreference resolution. Bridging methods can be categorised into: (1) rule-based methods (Hou et al., 2014; Rösiger et al., 2018; Rösiger, 2018b) and (2) machine learning methods (Hou, 2018a,b, 2020; Yu and Poesio, 2020). Hou (2020) modelled bridging resolution as a question answering task and finetuned the question answering model from generic question answering corpora. By utilizing transfer learning, they achieved a stronger performance on the bridging task. Yu and Poesio (2020) proposed a joint training framework for bridging and coreference resolution based on the end-to-end coreference model (Lee et al., 2017). Similar to coreference, they modelled bridging as a clustering task. They achieved great improvement over the bridging task. However, the impact on the coreference task is not clear. Fang et al. (2021a) adopted the same end-to-end framework for joint training anaphora resolution. They modelled bridging as a mention pair classification task and showed improvement on both subtasks."
    }, {
      "heading" : "3 Annotation Scheme",
      "text" : "In this section, we describe our adopted annotation scheme for recipe anaphora annotation. The complete annotation guideline is available at [Link withhold for anonymous submission]."
    }, {
      "heading" : "3.1 Corpus Selection",
      "text" : "We create our RecipeRef dataset by random sampling texts from RecipeDB (Batra et al., 2020), a large diverse recipe database containing 118,171 English recipes with 268 processes and more than 20,262 ingredients. It consists of ingredient lists and instruction sections. We select the instruction section of recipes for the corpus, detailing the steps for preparing the recipe."
    }, {
      "heading" : "3.2 Mention Types",
      "text" : "As our goal is to capture anaphoric phenomena in recipes, we focus on ingredient-related expressions. Verbs (e.g. bake, chop, etc.) are not annotated. In line with previous work (Pradhan et al., 2012; Cohen et al., 2017; Fang et al., 2021a; Ghaddar and Langlais, 2016b), we leave out singleton mentions, i.e. mentions that are not involved in anaphora rela-\ntions (as defined in Section 3.3) are not annotated. Mention types that are considered for anaphora relations are listed below.\nIngredient Terms In recipes, ingredient terms are essential as they indicate what ingredients are used, in the form of individual words or phrases, such as butter, endive heads, red peppers, garlic powder, etc.\nReferring Expressions We consider referring expressions to be pronouns (e.g. it, they, etc.) and generic phrases (e.g. soup, the pastry mixture, etc.) used to represent ingredients previously introduced.\nWe adopt several assumptions for mentions:\n• Premodifiers: One of the key challenges in procedural text is to track down the state change of entities. It is critical to include premodifiers as they play an important role in identifying an entity’s state. We consider ingredients with premodifiers as atomic mentions, e.g. chopped chicken, roasted red peppers and four sandwiches.\n• Numbers: In some cases, individual number expressions can be used to imply the ingredients and are considered as mentions. For example, 1 in “Beat eggs, 1 at a time”, three in “Combine together to make a sandwich. Repeat to make three”."
    }, {
      "heading" : "3.3 Relation Types",
      "text" : "One of the core components in procedural comprehension is understanding entities state (Dalvi et al., 2018; Tandon et al., 2018). Recipes contain rich information about the change of ingredients state. As shown in Fig 1, to obtain the biscuits in line 6, the biscuits in line 1 has gone through several processes, involving physical (e.g. flatten) and chemical change (e.g. bake). Capturing interaction relations among ingredients benefits in understanding ingredients (i.e. where is the ingredient from) and detailing the relation types with states gives a deeper understanding of recipes (i.e. how to get the ingredient).\nThere are two basic types of anaphora: coreference and bridging. In recipes, we define bridging as three subtypes of referring relations based on the state of entities. The overall schema of anaphora relations in recipes is shown in Fig 2.\nIn anaphora resolution, an antecedent is a linguistic expression that provides the interpretation\nfor a second expression, anaphor, which cannot be interpreted in isolation or only has little meaning on its own. Anaphors are linked to antecedents via anaphora relations. Consistent with previous work, we limit anaphors to link to antecedents appearing earlier in the text, and the direction of links is preserved."
    }, {
      "heading" : "3.3.1 Coreference",
      "text" : "Coreference focuses on expressions that refer to the same entity in the real-world (Clark and Manning, 2015; Ng, 2017). In procedural text, the state of an entity can be changed by the action applied to the entity. To distinguish this subtle information, we consider mentions are coreferent when they point to the same entity and there is no state change, such as a physical or chemical change.\nAlso, the entity can be repeated in text. To eliminate ambiguity in linking coreferent antecedents, the closet antecedent is linked for a given anaphor."
    }, {
      "heading" : "3.3.2 Bridging",
      "text" : "As discussed in Section 3.3.1, we aim to preserve the state change information of entities in procedural text. In the case of recipes, we define three types of bridging relation based on the entity state.\nTRANSFORMED A one-to-one anaphoric link for a set of ingredients that is meaning-wise the same but has undergone physical/chemical change (e.g. peeling, baking, boiling, etc.). For example, in Fig 1, the biscuits in line 4 and 5 are linked as TRANSFORMED because of the bake action that changes the state of the biscuits in line 4.\nINGREDIENT(WITHOUT-STATE-CHANGE)ASSOCIATED A one-to-many relationship between a processed food and its source ingredients, where the source ingredients have not undergone a state change (i.e. physical/chemical change). As shown in Fig 1, the cheese in line 5 refers to its source ingredients the mozzarella\nand Parmesan cheese in line 4 and there is no state change. Thus, they are annotated as INGREDIENT(WITHOUT-STATE-CHANGE)ASSOCIATED.\nINGREDIENT(WITH-STATE-CHANGE)ASSOCIATED A one-to-many relationship between a processed food and its source ingredients which have undergone a state change. As an example, the biscuits in Fig 1 line 6 is a combination of previous source ingredients (i.e. the sauce, a pinch of the oregano, pepperoni, the cheese and the biscuits) via baking. They are linked as INGREDIENT(WITH-STATE-CHANGE)ASSOCIATED as bake changes the state of the previous ingredients."
    }, {
      "heading" : "3.4 Comparison with Chemical Patents",
      "text" : "As shown in Table 1, chemical patents and recipes have commonalities. They use similar language to describe the application of processes (e.g. combination, removal, etc.) to source entities to obtain new entities, making it feasible to generalize the anaphora annotation scheme from chemical patents (Fang et al., 2021a,b) to recipes.\nHowever, there are some key differences in the annotation schemes.\n• Domain Differences: Some relation types defined for chemical patents are domain-specific, e.g. the WORK-UP relation is specific to chemistry. Such relation types cannot be directly applied to the general domain.\n• Determining State Change: In both chemical patents and recipes, anaphora resolution aims to capture anaphoric relation among mentions involving possible state changes. In the chemical domain, we are most concerned with chemical changes (e.g. oxidation, acidification, etc.). However, in the recipe domain, we are also interested in physical changes (e.g. chop, slice, etc.).\n• Rich Semantic Meaning in Recipes: Ingredient terms in recipes may represent a combination of ingredients. As shown in Fig 1, the biscuits in line 6 represent a combination of previous ingredients and not just the biscuit ingredient itself. However, in chemical patents, chemical names have specific meanings and cannot be semantically extended. This is a key challenge in resolving anaphora in recipes.\n• Variance in Instruction Descriptions: Although chemical patents and recipes have similar structures, instruction descriptions in recipes are more variable. In chemical patents, processed entities are mostly directly used in the immediately following process after a mention. However, processed entities in recipes can be mentioned far later in text.\n• Hierarchical Structure in Recipe Relation Types: Anaphora relation types in recipes are defined in a hierarchy (as shown in Fig 2). A simplified version of recipe anaphora resolution task, i.e. without considering state change, can be easily derived. In chemical patents, there is no clear way simplifying the scheme while presenting anaphoric relations."
    }, {
      "heading" : "4 Task definition",
      "text" : "Following the definition in Fang et al. (2021a), anaphora resolution is modelled as a two-step task, mention detection and anaphora relation detection.\nAs anaphora relation types in recipes are defined in a hierarchy, we can derive a simplified version of recipe anaphora resolution task by removing state changes. As such, COREFERENCE and TRANSFORMED can be merged without considering state changes and similarly for INGREDIENT(WITHOUT-STATECHANGE)-ASSOCIATED and INGREDIENT(WITHSTATE-CHANGE)-ASSOCIATED relationships. We evaluate recipe anaphora resolution both with and without state change.\nFor evaluation, we use precision, recall and F1. Although our recipe corpus models coreference as a one-to-one relation and it is transitive, we follow the coreference evaluation of the ChEMU-ref corpus and do not use traditional coreference evaluation metrics (Luo, 2005; Recasens and Hovy, 2011; Moosavi and Strube, 2016). Surface coreference, where a coreferent anaphor links to the closest antecedent, and atom coreference, where a coreferent anaphor links to a correct antecedent, are applied to evaluate coreference resolution (Kim et al., 2012).\nFor manual annotation, we use the Brat rapid annotation tool.2 To achieve high quality, we went through 8 rounds of annotation training and refinement of the anaphora annotation with two annotators experienced with the domain. In each round of training, they independently annotated 10 recipes (different for each round of annotation) and met afterwards to compare annotation results. Further refinement of annotation guidelines were made based on the discussion.\nAfter annotation training, we reached a high inner annotator agreement (IAA) between annotators. Krippendorff’s α score, F1 score at mention level and relation level are 0.85, 0.88 and 0.67, respectively. As a comparison, it was 0.45, 0.51 and\n2https://brat.nlplab.org/\n0.29 at the beginning, respectively. The individual annotation is in progress.\nWe use 80 harmonized recipes as our current corpus for experimentation. The statistics of this recipe corpus in comparison with the ChEMU-ref corpus (Fang et al., 2021a) are shown in Table 2."
    }, {
      "heading" : "5 Methodology",
      "text" : "To investigate the benefit of utilizing transfer learning from chemical domain, we follow the configuration of Fang et al. (2021a), modelling bridging as a classification task and adopting the benchmark end-to-end neural coreference model (Lee et al., 2017, 2018) for joint training of the two anaphora resolution types.\nFor each span xi, the model learns: (1) a mention score smi for mention detection:\nsm(i) = ws · FFNNs(si)\n(2) a distribution P (·) over possible antecedent spans Y (i) for coreference resolution:\nP (y) = exp(sc(i, y))∑\ny′∈Y exp(sc(i, y ′))\nwhere sc(i, y) is the output of a feed-forward neural network with span pair embedding si,y, and (3) a pair-wise score sb(i, y) of each possible antecedent span y for bridging resolution:\nsb(i, y) = softmax(wb · FFNNb(si,y))\nA span representation si is the concatenation of output token representations (x∗i ) from a bidirectional LSTM (BiLSTM) (Hochreiter and Schmidhuber, 1997), the syntactic head representation (hi) obtained from an attention mechanism (Bahdanau et al., 2015), and a feature vector of mention (ϕ(i)):\nsi = [x ∗ START(i), x ∗ END(i), hi, ϕ(i)]\nwhere START(i) and END(i) represent the starting and ending token index for span i, respectively.\nA span pair embedding si,y is obtained by the concatenation of each span embedding (s(i), s(y)) and the element-wise multiplication of the span embeddings (s(i)◦ s(y)) and a feature vector (ϕ(i, y)) for span pair i and y:\nsi,y = [s(i), s(y), s(i) ◦ s(y), ϕ(i, y)]\nFor mention loss, we unitize cross-entropy loss: Lm = − λT∑ i=1 mi ∗ log(sigmoid(sm(i)))\n+ (1−mi) ∗ log(1− sigmoid(sm(i)))\nwhere:\nmi = { 0 span i /∈ GOLDm 1 span i ∈ GOLDm\nGOLDm is the set of gold mentions that are involved in anaphora relations.\nFor coreference resolution, we compute the loss as follows, where GOLDc(i) is the gold coreferent antecedents that span i refers to:\nLc = log λT∏ i=1 ∑ ŷ∈Y (i) ⋂ GOLDc(i) P (ŷ)\nFor bridging resolution, the loss is obtained by multiclass cross-entropy:\nLb = − Kc∑ c=1 λT∑ i=1 ∑ y bi,j,c log(sb(i, y, c))\nwhere Kc represents the number of bridging categories, sb(i, j, c) denotes the prediction of sb(i, j) under category c, and:\nbi,j,c = { 0 span pair(i, j) /∈ GOLDb(c) 1 span pair(i, j) ∈ GOLDb(c)\nwhere GOLDb(c) is the gold bridging relation under category c.\nWe compute total loss as L = Lm+Lref , where\nLref =  Lc for coreference Lb for bridging Lc + Lb for joint training"
    }, {
      "heading" : "6 Experiments",
      "text" : "In this section, we present experimental results both with and without state change for recipe anaphora resolution. We use a similar configuration to Lee et al. (2018). Specifically, we use the concatenation of 300-dimensional GloVe embeddings (Pennington et al., 2014), 1024-dimensional ELMo word representations (Peters et al., 2018) and 8- dimensional character embeddings that are learned from a character CNN with windows of 3, 4, and 5 characters as the pretrianed token embeddings.\nEach feed-forward neural network consists of two hidden layers with 150 dimensions and rectified linear units (Nair and Hinton, 2010). The gold mentions are separated in coreference and bridging. For joint training, the gold mentions are combined.\nWe use 10-fold cross-validation to evaluate our model on recipe anaphora resolution. Since end-toend model performance varies due to random initialization (Lee et al., 2017), we randomly shuffle the dataset 5 times and run cross-validation 3 times for each shuffle. Averaged results are reported.\nTable 3 show our primary results without state change. For coreference resolution, we show experimental results on both surface and atom coreference metrics. For bridging resolution, we focus on overall bridging results. Since surface and atom coreference metrics show the same trends in performance, we use surface coreference and overall bridging to compute overall results.\nOverall, joint training achieves 26.2% F1 score for surface coreference and 26.9% F1 score for bridging, with +1.4% and +0.9% F1 score absolute improvement over the component-wise models. As such, joint training improves the performance of both tasks. Compared to precision, recall in anaphor and relation detection is lower, indicating the complexity in anaphoric forms in recipes.\nWe also experimented with joint coreference resolution and change-of-state classification, and observed similar trends in the results, at reduced performance levels due to the difficulty in predicting state changes (as shown in Appendix A).\nAs discussed in Section 3.4, chemical patents and recipes share similar text structures. We argue that the structure information can be beneficial for the anaphora resolution task. We hence experiment with utilizing transfer learning from chemical domain to recipes. Specifically, we pretrain the anaphora resolution model on the ChEMU-ref corpus (Fang et al., 2021a,b) with 10,000 epochs and fine-tune it with the recipe corpus.\nTable 4 shows results with transfer learning, demonstrating consistent improvement over coreference and bridging resolution. Overall, we achieve 27.9% F1 score for relation prediction under joint training and transfer learning, obtaining +0.8% F1 score absolute improvement. Incorporating procedural knowledge also improves component-wise models by +0.5% and 0.7% F1 score (absolute) for surface coreference and bridging, respectively.\nWe performance error analysis on 5 randomly se-\nlected batches from 10-fold cross-validation based on joint training models. Overall, models suffer from (1) semantic understanding of ingredient terms. As we discussed in section 3.4, ingredient terms can semantically represent a mixture, e.g. the biscuits in Fig 1 line 6 represents a mixture of previous ingredients. Models cannot tell the subtle differences and incorrectly link those ingredient terms as COREFERENCE. (2) detection of state change. Models fail to capture the state transition of entities, mostly falsely inferring TRANSFORMED as COREFERENCE and inferring INGREDIENT(WITHOUT-STATECHANGE)-ASSOCIATED as INGREDIENT(WITHSTATE-CHANGE)-ASSOCIATED.\nErrors in coreference resolution occur also due to (1) imbalance of coreference and bridging and (2) entities with different expressions. As shown in Table 2, coreference relations are not common in recipe anaphora, making it harder for models\nto capture coreference links. Models also fail to capture the coreference relationship of entities in the face of variations in expression.\nIn bridging resolution, models also tend to predict anaphoric links as INGREDIENT(WITHSTATE-CHANGE)-ASSOCIATED due to its domination in recipe anaphora relations. Furthermore, within the INGREDIENT(WITH-STATE-CHANGE)ASSOCIATED relationship, models over-predict the relations for a given anaphor. One of the possible reasons is the individual span-pair prediction, which makes it hard to capture the interactions within anaphors. Simultaneously evaluating candidate antecedents might address this issue.\nBy incorporating procedural knowledge via transfer learning, models achieve better performance. However, models suffer more severely from false negatives due to the difference in the annotation scheme, as discussed in Section 3.4.\nFuture directions include (1) Joint learning with COREFERENCE and TRANSFORMED relations. These only differ in whether or not state change is considered; considering them together may be effective. (2) Incorporation of external knowledge including world knowledge about ingredient entities; this may further improve transfer learning."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We investigate the textual properties in chemical patents and recipes and generalized the annotation guideline for chemical patents to recipes. We create a publicly available recipe anaphora resolution corpus based on the adopted annotation scheme. We further define two tasks for modelling anaphoric phenomena in recipes, with and without state change. Our experiment shows the benefit of utilizing joint training setting and transfer learning from chemical domain."
    }, {
      "heading" : "A Additional Experimental Results",
      "text" : "In the following tables, we provide detailed experiment results described in the main paper. Table 5 provides anaphora resolution results with state changes on 10 fold cross validation. Table 6 provides a full comparison of transfer learning per anaphora relation with state change on 10 fold cross validation. Table 7 provides a full comparison of transfer learning per anaphora relation without state change on 10 fold cross validation."
    } ],
    "references" : [ {
      "title" : "Information extraction from recipes",
      "author" : [ "Rahul Agarwal", "Kevin Miller." ],
      "venue" : "Department of Computer Science, Stanford University-2008.",
      "citeRegEx" : "Agarwal and Miller.,? 2011",
      "shortCiteRegEx" : "Agarwal and Miller.",
      "year" : 2011
    }, {
      "title" : "Bridging",
      "author" : [ "Nicholas Asher", "Alex Lascarides." ],
      "venue" : "Journal of Semantics, 15(1):83–113.",
      "citeRegEx" : "Asher and Lascarides.,? 1998",
      "shortCiteRegEx" : "Asher and Lascarides.",
      "year" : 1998
    }, {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio." ],
      "venue" : "3rd International Conference on Learning Representations (ICLR 2015), San Diego, USA.",
      "citeRegEx" : "Bahdanau et al\\.,? 2015",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2015
    }, {
      "title" : "Recipedb: A resource for exploring recipes",
      "author" : [ "Devansh Batra", "Nirav Diwan", "Utkarsh Upadhyay", "Jushaan Singh Kalra", "Tript Sharma", "Aman Kumar Sharma", "Dheeraj Khanna", "Jaspreet Singh Marwah", "Srilakshmi Kalathil", "Navjot Singh" ],
      "venue" : null,
      "citeRegEx" : "Batra et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Batra et al\\.",
      "year" : 2020
    }, {
      "title" : "Coreference resolution in research papers from multiple domains",
      "author" : [ "Arthur Brack", "Daniel Uwe Müller", "Anett Hoppe", "Ralph Ewerth." ],
      "venue" : "arXiv preprint arXiv:2101.00884.",
      "citeRegEx" : "Brack et al\\.,? 2021",
      "shortCiteRegEx" : "Brack et al\\.",
      "year" : 2021
    }, {
      "title" : "Entitycentric coreference resolution with model stacking",
      "author" : [ "Kevin Clark", "Christopher D Manning." ],
      "venue" : "Proc. of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language",
      "citeRegEx" : "Clark and Manning.,? 2015",
      "shortCiteRegEx" : "Clark and Manning.",
      "year" : 2015
    }, {
      "title" : "Deep reinforcement learning for mention-ranking coreference models",
      "author" : [ "Kevin Clark", "Christopher D. Manning." ],
      "venue" : "Proc. of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 2256–2262, Austin, USA.",
      "citeRegEx" : "Clark and Manning.,? 2016a",
      "shortCiteRegEx" : "Clark and Manning.",
      "year" : 2016
    }, {
      "title" : "Improving coreference resolution by learning entitylevel distributed representations",
      "author" : [ "Kevin Clark", "Christopher D. Manning." ],
      "venue" : "Proc. of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 643–653,",
      "citeRegEx" : "Clark and Manning.,? 2016b",
      "shortCiteRegEx" : "Clark and Manning.",
      "year" : 2016
    }, {
      "title" : "Coreference annotation and resolution in the Colorado Richly Annotated",
      "author" : [ "K Bretonnel Cohen", "Arrick Lanfranchi", "Miji Joo-young Choi", "Michael Bada", "William A Baumgartner", "Natalya Panteleyeva", "Karin Verspoor", "Martha Palmer", "Lawrence E Hunter" ],
      "venue" : null,
      "citeRegEx" : "Cohen et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Cohen et al\\.",
      "year" : 2017
    }, {
      "title" : "Coreference aware representation learning for neural named entity recognition",
      "author" : [ "Zeyu Dai", "Hongliang Fei", "Ping Li." ],
      "venue" : "IJCAI, pages 4946–4953.",
      "citeRegEx" : "Dai et al\\.,? 2019",
      "shortCiteRegEx" : "Dai et al\\.",
      "year" : 2019
    }, {
      "title" : "Tracking state changes in procedural text: A challenge dataset and models for process paragraph comprehension",
      "author" : [ "Bhavana Dalvi", "Lifu Huang", "Niket Tandon", "Wen tau Yih", "Peter Clark." ],
      "venue" : "NAACL.",
      "citeRegEx" : "Dalvi et al\\.,? 2018",
      "shortCiteRegEx" : "Dalvi et al\\.",
      "year" : 2018
    }, {
      "title" : "ChEMU-ref: A corpus for modeling anaphora resolution in the chemical domain",
      "author" : [ "Biaoyan Fang", "Christian Druckenbrodt", "Saber A Akhondi", "Jiayuan He", "Timothy Baldwin", "Karin Verspoor." ],
      "venue" : "Proceedings of the 16th Conference of the European",
      "citeRegEx" : "Fang et al\\.,? 2021a",
      "shortCiteRegEx" : "Fang et al\\.",
      "year" : 2021
    }, {
      "title" : "2021b. ChEMURef dataset for modeling anaphora resolution",
      "author" : [ "Biaoyan Fang", "Christian Druckenbrodt", "Colleen Yeow Hui Shiuan", "Sacha Novakovic", "Ralph Hössel", "Saber A. Akhondi", "Jiayuan He", "Meladel Mistica", "Timothy Baldwin", "Karin Verspoor" ],
      "venue" : null,
      "citeRegEx" : "Fang et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Fang et al\\.",
      "year" : 2021
    }, {
      "title" : "The SOFC-exp corpus and neural approaches to information extraction in the materials science domain",
      "author" : [ "Annemarie Friedrich", "Heike Adel", "Federico Tomazic", "Johannes Hingerl", "Renou Benteau", "Anika Marusczyk", "Lukas Lange." ],
      "venue" : "Proceedings of the 58th",
      "citeRegEx" : "Friedrich et al\\.,? 2020",
      "shortCiteRegEx" : "Friedrich et al\\.",
      "year" : 2020
    }, {
      "title" : "Wikicoref: An English coreference-annotated corpus of Wikipedia articles",
      "author" : [ "Abbas Ghaddar", "Philippe Langlais." ],
      "venue" : "Proc. of the Tenth International Conference on Language Resources and Evaluation (LREC 2016), pages 136–142, Portorož, Slovenia.",
      "citeRegEx" : "Ghaddar and Langlais.,? 2016a",
      "shortCiteRegEx" : "Ghaddar and Langlais.",
      "year" : 2016
    }, {
      "title" : "WikiCoref: An English coreference-annotated corpus of Wikipedia articles",
      "author" : [ "Abbas Ghaddar", "Phillippe Langlais." ],
      "venue" : "Proc. of the Tenth International Conference on Language Resources and Evaluation (LREC’16), pages 136–142, Portorož, Slovenia.",
      "citeRegEx" : "Ghaddar and Langlais.,? 2016b",
      "shortCiteRegEx" : "Ghaddar and Langlais.",
      "year" : 2016
    }, {
      "title" : "Neural coreference resolution with limited lexical context and explicit mention detection for oral French",
      "author" : [ "Loïc Grobol." ],
      "venue" : "Proc. of the Second Workshop on Computational Models of Reference, Anaphora and Coreference, pages 8–14, Minneapolis, USA.",
      "citeRegEx" : "Grobol.,? 2019",
      "shortCiteRegEx" : "Grobol.",
      "year" : 2019
    }, {
      "title" : "A large-scale recipe and meal data collection as infrastructure for food research",
      "author" : [ "Jun Harashima", "Michiaki Ariga", "Kenta Murata", "Masayuki Ioki." ],
      "venue" : "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16),",
      "citeRegEx" : "Harashima et al\\.,? 2016",
      "shortCiteRegEx" : "Harashima et al\\.",
      "year" : 2016
    }, {
      "title" : "Cookpad parsed corpus: Linguistic annotations of Japanese recipes",
      "author" : [ "Jun Harashima", "Makoto Hiramatsu." ],
      "venue" : "Proceedings of the 14th Linguistic Annotation Workshop, pages 87–92, Barcelona, Spain. Association for Computational Linguistics.",
      "citeRegEx" : "Harashima and Hiramatsu.,? 2020",
      "shortCiteRegEx" : "Harashima and Hiramatsu.",
      "year" : 2020
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber." ],
      "venue" : "Neural Computation, 9(8):1735– 1780.",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? 1997",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "A deterministic algorithm for bridging anaphora resolution",
      "author" : [ "Yufang Hou." ],
      "venue" : "Proc. of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1938–1948, Brussels, Belgium.",
      "citeRegEx" : "Hou.,? 2018a",
      "shortCiteRegEx" : "Hou.",
      "year" : 2018
    }, {
      "title" : "Enhanced word representations for bridging anaphora resolution",
      "author" : [ "Yufang Hou." ],
      "venue" : "Proc. of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers),",
      "citeRegEx" : "Hou.,? 2018b",
      "shortCiteRegEx" : "Hou.",
      "year" : 2018
    }, {
      "title" : "Bridging anaphora resolution as question answering",
      "author" : [ "Yufang Hou." ],
      "venue" : "Proc. of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1428–1438, Online.",
      "citeRegEx" : "Hou.,? 2020",
      "shortCiteRegEx" : "Hou.",
      "year" : 2020
    }, {
      "title" : "A rule-based system for unrestricted bridging resolution: Recognizing bridging anaphora and finding links to antecedents",
      "author" : [ "Yufang Hou", "Katja Markert", "Michael Strube." ],
      "venue" : "Proc. of the 2014 Conference on Empirical Methods in Natural Language Process-",
      "citeRegEx" : "Hou et al\\.,? 2014",
      "shortCiteRegEx" : "Hou et al\\.",
      "year" : 2014
    }, {
      "title" : "Unrestricted bridging resolution",
      "author" : [ "Yufang Hou", "Katja Markert", "Michael Strube." ],
      "venue" : "Computational Linguistics, 44(2):237–284.",
      "citeRegEx" : "Hou et al\\.,? 2018",
      "shortCiteRegEx" : "Hou et al\\.",
      "year" : 2018
    }, {
      "title" : "Unsupervised visual-linguistic reference resolution in instructional videos",
      "author" : [ "De-An Huang", "Joseph J Lim", "Li Fei-Fei", "Juan Carlos Niebles." ],
      "venue" : "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2183–2192.",
      "citeRegEx" : "Huang et al\\.,? 2017",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2017
    }, {
      "title" : "Recipe instruction semantics corpus (RISeC): Resolving semantic structure and zero anaphora in recipes",
      "author" : [ "Yiwei Jiang", "Klim Zaporojets", "Johannes Deleu", "Thomas Demeester", "Chris Develder." ],
      "venue" : "Proceedings of the 1st Conference of the Asia-Pacific Chap-",
      "citeRegEx" : "Jiang et al\\.,? 2020",
      "shortCiteRegEx" : "Jiang et al\\.",
      "year" : 2020
    }, {
      "title" : "Coreference resolution with entity equalization",
      "author" : [ "Ben Kantor", "Amir Globerson." ],
      "venue" : "Proc. of the 57th Annual Meeting of the Association for Computational Linguistics (ACL 2019), pages 673–677, Florence, Italy.",
      "citeRegEx" : "Kantor and Globerson.,? 2019",
      "shortCiteRegEx" : "Kantor and Globerson.",
      "year" : 2019
    }, {
      "title" : "Mise en place: Unsupervised interpretation of instructional recipes",
      "author" : [ "Chloé Kiddon", "Ganesa Thandavam Ponnuraj", "Luke Zettlemoyer", "Yejin Choi." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages",
      "citeRegEx" : "Kiddon et al\\.,? 2015",
      "shortCiteRegEx" : "Kiddon et al\\.",
      "year" : 2015
    }, {
      "title" : "The Genia event and protein coreference tasks of the BioNLP shared task",
      "author" : [ "Jin-Dong Kim", "Ngan Nguyen", "Yue Wang", "Jun’ichi Tsujii", "Toshihisa Takagi", "Akinori Yonezawa" ],
      "venue" : "BMC Bioinformatics,",
      "citeRegEx" : "Kim et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2012
    }, {
      "title" : "End-to-end neural coreference resolution",
      "author" : [ "Kenton Lee", "Luheng He", "Mike Lewis", "Luke Zettlemoyer." ],
      "venue" : "Proc. of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 188– 197, Copenhagen, Denmark.",
      "citeRegEx" : "Lee et al\\.,? 2017",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2017
    }, {
      "title" : "Higher-order coreference resolution with coarse-tofine inference",
      "author" : [ "Kenton Lee", "Luheng He", "Luke Zettlemoyer." ],
      "venue" : "Proc. of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-",
      "citeRegEx" : "Lee et al\\.,? 2018",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2018
    }, {
      "title" : "Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction",
      "author" : [ "Yi Luan", "Luheng He", "Mari Ostendorf", "Hannaneh Hajishirzi." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Luan et al\\.,? 2018",
      "shortCiteRegEx" : "Luan et al\\.",
      "year" : 2018
    }, {
      "title" : "On coreference resolution performance metrics",
      "author" : [ "Xiaoqiang Luo." ],
      "venue" : "Proc. of the Conference on Human Language Technology and Empirical Methods in Natural Language Processing (EMNLP 2005), pages 25–32, Vancouver, Canada.",
      "citeRegEx" : "Luo.,? 2005",
      "shortCiteRegEx" : "Luo.",
      "year" : 2005
    }, {
      "title" : "Recipe1m+: A dataset for learning cross-modal embeddings for cooking recipes and food images",
      "author" : [ "Javier Marin", "Aritro Biswas", "Ferda Ofli", "Nicholas Hynes", "Amaia Salvador", "Yusuf Aytar", "Ingmar Weber", "Antonio Torralba." ],
      "venue" : "IEEE transactions on pattern anal-",
      "citeRegEx" : "Marin et al\\.,? 2019",
      "shortCiteRegEx" : "Marin et al\\.",
      "year" : 2019
    }, {
      "title" : "InScript: Narrative texts annotated with script information",
      "author" : [ "Ashutosh Modi", "Tatjana Anikina", "Simon Ostermann", "Manfred Pinkal." ],
      "venue" : "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16), pages 3485–",
      "citeRegEx" : "Modi et al\\.,? 2016",
      "shortCiteRegEx" : "Modi et al\\.",
      "year" : 2016
    }, {
      "title" : "Which coreference evaluation metric do you trust? a proposal for a link-based entity aware metric",
      "author" : [ "Nafise Sadat Moosavi", "Michael Strube." ],
      "venue" : "Proc. of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
      "citeRegEx" : "Moosavi and Strube.,? 2016",
      "shortCiteRegEx" : "Moosavi and Strube.",
      "year" : 2016
    }, {
      "title" : "Flow graph corpus from recipe texts",
      "author" : [ "Shinsuke Mori", "Hirokuni Maeta", "Yoko Yamakata", "Tetsuro Sasada." ],
      "venue" : "Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), pages 2370–2377, Reykjavik, Iceland.",
      "citeRegEx" : "Mori et al\\.,? 2014",
      "shortCiteRegEx" : "Mori et al\\.",
      "year" : 2014
    }, {
      "title" : "The materials science procedural text corpus: Annotating materials synthesis procedures with shallow",
      "author" : [ "Sheshera Mysore", "Zachary Jensen", "Edward Kim", "Kevin Huang", "Haw-Shiuan Chang", "Emma Strubell", "Jeffrey Flanigan", "Andrew McCallum", "Elsa Olivetti" ],
      "venue" : null,
      "citeRegEx" : "Mysore et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Mysore et al\\.",
      "year" : 2019
    }, {
      "title" : "Rectified linear units improve restricted Boltzmann machines",
      "author" : [ "Vinod Nair", "Geoffrey E Hinton." ],
      "venue" : "Proc. of the 33rd International Conference on Machine Learning (ICML 2016), New York, USA. 10",
      "citeRegEx" : "Nair and Hinton.,? 2010",
      "shortCiteRegEx" : "Nair and Hinton.",
      "year" : 2010
    }, {
      "title" : "Machine learning for entity coreference resolution: A retrospective look at two decades of research",
      "author" : [ "Vincent Ng." ],
      "venue" : "Proc. of the Thirty-First AAAI Conference on Artificial Intelligence (AAAI’17), pages 4877–4884, San Francisco, USA.",
      "citeRegEx" : "Ng.,? 2017",
      "shortCiteRegEx" : "Ng.",
      "year" : 2017
    }, {
      "title" : "Overview of BioNLP 2011 protein coreference shared task",
      "author" : [ "Ngan Nguyen", "Jin-Dong Kim", "Jun’ichi Tsujii" ],
      "venue" : "In Proc. of BioNLP Shared Task 2011 Workshop,",
      "citeRegEx" : "Nguyen et al\\.,? \\Q2011\\E",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2011
    }, {
      "title" : "Visual grounding annotation of recipe flow graph",
      "author" : [ "Taichi Nishimura", "Suzushi Tomori", "Hayato Hashimoto", "Atsushi Hashimoto", "Yoko Yamakata", "Jun Harashima", "Yoshitaka Ushiku", "Shinsuke Mori." ],
      "venue" : "Proceedings of the 12th Language Resources and",
      "citeRegEx" : "Nishimura et al\\.,? 2020",
      "shortCiteRegEx" : "Nishimura et al\\.",
      "year" : 2020
    }, {
      "title" : "GloVe: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher Manning." ],
      "venue" : "Proc. of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543, Doha, Qatar.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Deep contextualized word representations",
      "author" : [ "Matthew Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer." ],
      "venue" : "Proc. of the 2018 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Peters et al\\.,? 2018",
      "shortCiteRegEx" : "Peters et al\\.",
      "year" : 2018
    }, {
      "title" : "Anaphoric annotation in the ARRAU corpus",
      "author" : [ "Massimo Poesio", "Ron Artstein" ],
      "venue" : "In Proc. of the Sixth International Conference on Language Resources and Evaluation (LREC",
      "citeRegEx" : "Poesio and Artstein,? \\Q2008\\E",
      "shortCiteRegEx" : "Poesio and Artstein",
      "year" : 2008
    }, {
      "title" : "Anaphora Resolution",
      "author" : [ "Massimo Poesio", "Roland Stuckardt", "Yannick Versley." ],
      "venue" : "Springer.",
      "citeRegEx" : "Poesio et al\\.,? 2016",
      "shortCiteRegEx" : "Poesio et al\\.",
      "year" : 2016
    }, {
      "title" : "CoNLL2012 shared task: Modeling multilingual unrestricted coreference in OntoNotes",
      "author" : [ "Sameer Pradhan", "Alessandro Moschitti", "Nianwen Xue", "Olga Uryupina", "Yuchen Zhang." ],
      "venue" : "Proc. of EMNLPCoNLL 2012: Conference on Empirical Methods",
      "citeRegEx" : "Pradhan et al\\.,? 2012",
      "shortCiteRegEx" : "Pradhan et al\\.",
      "year" : 2012
    }, {
      "title" : "BLANC: Implementing the Rand index for coreference evaluation",
      "author" : [ "Marta Recasens", "Eduard Hovy." ],
      "venue" : "Natural Language Engineering, 17(4):485–510.",
      "citeRegEx" : "Recasens and Hovy.,? 2011",
      "shortCiteRegEx" : "Recasens and Hovy.",
      "year" : 2011
    }, {
      "title" : "Scicorp: A corpus of English scientific articles annotated for information status analysis",
      "author" : [ "Ina Rösiger." ],
      "venue" : "Proc. of the Tenth International Conference on Language Resources and Evaluation (LREC 2016), pages 1743–1749, Portorož, Slovenia.",
      "citeRegEx" : "Rösiger.,? 2016",
      "shortCiteRegEx" : "Rösiger.",
      "year" : 2016
    }, {
      "title" : "BASHI: A corpus of Wall Street Journal articles annotated with bridging links",
      "author" : [ "Ina Rösiger." ],
      "venue" : "Proc. of the Eleventh International Conference on Language Resources and Evaluation (LREC-2018).",
      "citeRegEx" : "Rösiger.,? 2018a",
      "shortCiteRegEx" : "Rösiger.",
      "year" : 2018
    }, {
      "title" : "Rule- and learning-based methods for bridging resolution in the ARRAU corpus",
      "author" : [ "Ina Rösiger." ],
      "venue" : "Proc. of the First Workshop on Computational Models of Reference, Anaphora and Coreference, pages 23–33, New Orleans, USA.",
      "citeRegEx" : "Rösiger.,? 2018b",
      "shortCiteRegEx" : "Rösiger.",
      "year" : 2018
    }, {
      "title" : "Computational modelling of coreference and bridging resolution",
      "author" : [ "Ina Rösiger." ],
      "venue" : "Ph.D. thesis, Stuttgart University.",
      "citeRegEx" : "Rösiger.,? 2019",
      "shortCiteRegEx" : "Rösiger.",
      "year" : 2019
    }, {
      "title" : "Bridging resolution: Task definition, corpus resources and rule-based experiments",
      "author" : [ "Ina Rösiger", "Arndt Riester", "Jonas Kuhn." ],
      "venue" : "Proc. of the 27th International Conference on Computational Linguistics, pages 3516–3528, Santa Fe, USA.",
      "citeRegEx" : "Rösiger et al\\.,? 2018",
      "shortCiteRegEx" : "Rösiger et al\\.",
      "year" : 2018
    }, {
      "title" : "Evaluating gender bias in machine translation",
      "author" : [ "Gabriel Stanovsky", "Noah A. Smith", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1679–1684, Florence, Italy. Association for",
      "citeRegEx" : "Stanovsky et al\\.,? 2019",
      "shortCiteRegEx" : "Stanovsky et al\\.",
      "year" : 2019
    }, {
      "title" : "Reasoning about actions and state changes by injecting commonsense knowledge",
      "author" : [ "Niket Tandon", "Bhavana Dalvi Mishra", "Joel Grus", "Wen tau Yih", "Antoine Bosselut", "Peter Clark." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Tandon et al\\.,? 2018",
      "shortCiteRegEx" : "Tandon et al\\.",
      "year" : 2018
    }, {
      "title" : "OntoNotes release",
      "author" : [ "Ralph Weischedel", "Martha Palmer", "Mitchell Marcus", "Eduard Hovy", "Sameer Pradhan", "Lance Ramshaw", "Nianwen Xue", "Ann Taylor", "Jeff Kaufman", "Michelle Franchini", "Mohammed El-Bachouti", "Robert Belvin", "Ann Houston" ],
      "venue" : null,
      "citeRegEx" : "Weischedel et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Weischedel et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning anaphoricity and antecedent ranking features for coreference resolution",
      "author" : [ "Sam Wiseman", "Alexander M. Rush", "Stuart Shieber", "Jason Weston." ],
      "venue" : "Proc. of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th",
      "citeRegEx" : "Wiseman et al\\.,? 2015",
      "shortCiteRegEx" : "Wiseman et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning global features for coreference resolution",
      "author" : [ "Sam Wiseman", "Alexander M. Rush", "Stuart M. Shieber." ],
      "venue" : "Proc. of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
      "citeRegEx" : "Wiseman et al\\.,? 2016",
      "shortCiteRegEx" : "Wiseman et al\\.",
      "year" : 2016
    }, {
      "title" : "Moving on from ontonotes: Coreference resolution model transfer",
      "author" : [ "Patrick Xia", "Benjamin Van Durme." ],
      "venue" : "arXiv preprint arXiv:2104.08457.",
      "citeRegEx" : "Xia and Durme.,? 2021",
      "shortCiteRegEx" : "Xia and Durme.",
      "year" : 2021
    }, {
      "title" : "English recipe flow graph corpus",
      "author" : [ "Yoko Yamakata", "Shinsuke Mori", "John Carroll." ],
      "venue" : "Proceedings of the 12th Language Resources and Evaluation Conference, pages 5187–5194, Marseille, France. European Language Resources Association.",
      "citeRegEx" : "Yamakata et al\\.,? 2020",
      "shortCiteRegEx" : "Yamakata et al\\.",
      "year" : 2020
    }, {
      "title" : "Multi-task learning based neural bridging reference resolution",
      "author" : [ "Juntao Yu", "Massimo Poesio." ],
      "venue" : "arXiv preprint arXiv:2003.03666.",
      "citeRegEx" : "Yu and Poesio.,? 2020",
      "shortCiteRegEx" : "Yu and Poesio.",
      "year" : 2020
    }, {
      "title" : "The GUM corpus: Creating multilayer resources in the classroom",
      "author" : [ "Amir Zeldes." ],
      "venue" : "Language Resources and Evaluation, 51(3):581–612.",
      "citeRegEx" : "Zeldes.,? 2017",
      "shortCiteRegEx" : "Zeldes.",
      "year" : 2017
    }, {
      "title" : "Neural coreference resolution with deep biaffine attention by joint mention detection and mention clustering",
      "author" : [ "Rui Zhang", "Cícero Nogueira dos Santos", "Michihiro Yasunaga", "Bing Xiang", "Dragomir Radev." ],
      "venue" : "Proc. of the 56th Annual Meeting of the",
      "citeRegEx" : "Zhang et al\\.,? 2018",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 46,
      "context" : "Anaphora resolution is a core component in information extraction tasks (Poesio et al., 2016; Rösiger, 2019) and critical for various downstream natural language processing tasks, such as named entity recognition (Dai et al.",
      "startOffset" : 72,
      "endOffset" : 108
    }, {
      "referenceID" : 52,
      "context" : "Anaphora resolution is a core component in information extraction tasks (Poesio et al., 2016; Rösiger, 2019) and critical for various downstream natural language processing tasks, such as named entity recognition (Dai et al.",
      "startOffset" : 72,
      "endOffset" : 108
    }, {
      "referenceID" : 9,
      "context" : ", 2016; Rösiger, 2019) and critical for various downstream natural language processing tasks, such as named entity recognition (Dai et al., 2019) and machine translation (Stanovsky et al.",
      "startOffset" : 127,
      "endOffset" : 145
    }, {
      "referenceID" : 40,
      "context" : "It consists of two primary anaphoric types, coreference (Ng, 2017; Clark and Manning, 2015) and bridging (Asher and Lascarides, 1998; Rösiger et al.",
      "startOffset" : 56,
      "endOffset" : 91
    }, {
      "referenceID" : 5,
      "context" : "It consists of two primary anaphoric types, coreference (Ng, 2017; Clark and Manning, 2015) and bridging (Asher and Lascarides, 1998; Rösiger et al.",
      "startOffset" : 56,
      "endOffset" : 91
    }, {
      "referenceID" : 1,
      "context" : "It consists of two primary anaphoric types, coreference (Ng, 2017; Clark and Manning, 2015) and bridging (Asher and Lascarides, 1998; Rösiger et al., 2018).",
      "startOffset" : 105,
      "endOffset" : 155
    }, {
      "referenceID" : 53,
      "context" : "It consists of two primary anaphoric types, coreference (Ng, 2017; Clark and Manning, 2015) and bridging (Asher and Lascarides, 1998; Rösiger et al., 2018).",
      "startOffset" : 105,
      "endOffset" : 155
    }, {
      "referenceID" : 47,
      "context" : "Most anaphora corpora (Pradhan et al., 2012; Ghaddar and Langlais, 2016a; Poesio et al., 2008), however, only focus on either coreference or bridging.",
      "startOffset" : 22,
      "endOffset" : 94
    }, {
      "referenceID" : 14,
      "context" : "Most anaphora corpora (Pradhan et al., 2012; Ghaddar and Langlais, 2016a; Poesio et al., 2008), however, only focus on either coreference or bridging.",
      "startOffset" : 22,
      "endOffset" : 94
    }, {
      "referenceID" : 47,
      "context" : "Current research on anaphora resolution is mostly based on declarative text (Pradhan et al., 2012; Ghaddar and Langlais, 2016b; Rösiger, 2018a; Hou et al., 2018), such as news or dialogue.",
      "startOffset" : 76,
      "endOffset" : 161
    }, {
      "referenceID" : 15,
      "context" : "Current research on anaphora resolution is mostly based on declarative text (Pradhan et al., 2012; Ghaddar and Langlais, 2016b; Rösiger, 2018a; Hou et al., 2018), such as news or dialogue.",
      "startOffset" : 76,
      "endOffset" : 161
    }, {
      "referenceID" : 50,
      "context" : "Current research on anaphora resolution is mostly based on declarative text (Pradhan et al., 2012; Ghaddar and Langlais, 2016b; Rösiger, 2018a; Hou et al., 2018), such as news or dialogue.",
      "startOffset" : 76,
      "endOffset" : 161
    }, {
      "referenceID" : 24,
      "context" : "Current research on anaphora resolution is mostly based on declarative text (Pradhan et al., 2012; Ghaddar and Langlais, 2016b; Rösiger, 2018a; Hou et al., 2018), such as news or dialogue.",
      "startOffset" : 76,
      "endOffset" : 161
    }, {
      "referenceID" : 60,
      "context" : "Procedural text, such as patents describing chemical synthesis or instruction manuals, has received more limited attention although it is critical for human knowledge (Yamakata et al., 2020).",
      "startOffset" : 167,
      "endOffset" : 190
    }, {
      "referenceID" : 5,
      "context" : "Anaphora relation subsumes two referring types, coreference — expressions in the text that refer to the same entity (Clark and Manning, 2015; Ng, 2017), and bridging — expressions that are linked via semantic, lexical, or encyclopedic relations (Asher and Lascarides, 1998; Hou et al.",
      "startOffset" : 116,
      "endOffset" : 151
    }, {
      "referenceID" : 40,
      "context" : "Anaphora relation subsumes two referring types, coreference — expressions in the text that refer to the same entity (Clark and Manning, 2015; Ng, 2017), and bridging — expressions that are linked via semantic, lexical, or encyclopedic relations (Asher and Lascarides, 1998; Hou et al.",
      "startOffset" : 116,
      "endOffset" : 151
    }, {
      "referenceID" : 1,
      "context" : "Anaphora relation subsumes two referring types, coreference — expressions in the text that refer to the same entity (Clark and Manning, 2015; Ng, 2017), and bridging — expressions that are linked via semantic, lexical, or encyclopedic relations (Asher and Lascarides, 1998; Hou et al., 2018).",
      "startOffset" : 245,
      "endOffset" : 291
    }, {
      "referenceID" : 24,
      "context" : "Anaphora relation subsumes two referring types, coreference — expressions in the text that refer to the same entity (Clark and Manning, 2015; Ng, 2017), and bridging — expressions that are linked via semantic, lexical, or encyclopedic relations (Asher and Lascarides, 1998; Hou et al., 2018).",
      "startOffset" : 245,
      "endOffset" : 291
    }, {
      "referenceID" : 38,
      "context" : "A few procedural corpora are annotated for anaphora resolution but most only have coreference annotated (Mysore et al., 2019; Friedrich et al., 2020).",
      "startOffset" : 104,
      "endOffset" : 149
    }, {
      "referenceID" : 13,
      "context" : "A few procedural corpora are annotated for anaphora resolution but most only have coreference annotated (Mysore et al., 2019; Friedrich et al., 2020).",
      "startOffset" : 104,
      "endOffset" : 149
    }, {
      "referenceID" : 56,
      "context" : "0 (Weischedel et al., 2013) annotation, modelling coreference in terms of two subtypes: Identity, where the anaphoric references and referents are identical, and Appositive, where a noun phrase is modified by an intermediately-adjacent noun phrase.",
      "startOffset" : 2,
      "endOffset" : 27
    }, {
      "referenceID" : 15,
      "context" : "Following the same annotation framework largely, the WikiCoref corpus (Ghaddar and Langlais, 2016b) annotates Wikipedia texts.",
      "startOffset" : 70,
      "endOffset" : 99
    }, {
      "referenceID" : 41,
      "context" : "BioNLP-ST 2011 (Nguyen et al., 2011) is a generelated coreference corpus based on abstracts from biomedical publications.",
      "startOffset" : 15,
      "endOffset" : 36
    }, {
      "referenceID" : 8,
      "context" : "CRAFTST 2019 (Cohen et al., 2017) annotates 97 full biomedical articles for coreference resolution based on the OntoNotes 5.",
      "startOffset" : 13,
      "endOffset" : 33
    }, {
      "referenceID" : 32,
      "context" : "SCIERC (Luan et al., 2018) contains 500 abstracts from scientific articles.",
      "startOffset" : 7,
      "endOffset" : 26
    }, {
      "referenceID" : 62,
      "context" : "Due to the complexities of defining bridging (Zeldes, 2017; Hou et al., 2018), different corpora have adopted different definitions of bridging.",
      "startOffset" : 45,
      "endOffset" : 77
    }, {
      "referenceID" : 24,
      "context" : "Due to the complexities of defining bridging (Zeldes, 2017; Hou et al., 2018), different corpora have adopted different definitions of bridging.",
      "startOffset" : 45,
      "endOffset" : 77
    }, {
      "referenceID" : 24,
      "context" : "The ISNotes corpus (Hou et al., 2018) is based on 50 Wall Street Journal (WSJ) texts from the OntoNotes corpus, and contains both coreference and referential bridging.",
      "startOffset" : 19,
      "endOffset" : 37
    }, {
      "referenceID" : 50,
      "context" : "Similar to ISNotes, BASHI (Rösiger, 2018a) is based on another 50 WSJ texts from OntoNotes with referential bridging.",
      "startOffset" : 26,
      "endOffset" : 42
    }, {
      "referenceID" : 49,
      "context" : "With the same annotation scheme as BASHI, SciCorp (Rösiger, 2016)",
      "startOffset" : 50,
      "endOffset" : 65
    }, {
      "referenceID" : 11,
      "context" : "The ChEMU-ref corpus (Fang et al., 2021a) contains 1,500 chemical patent excerpts describing chemical reactions.",
      "startOffset" : 21,
      "endOffset" : 41
    }, {
      "referenceID" : 35,
      "context" : "The InScript corpus (Modi et al., 2016) consists of 1,000 stories from 10 different scenarios and annotates coreference for noun phrases.",
      "startOffset" : 20,
      "endOffset" : 39
    }, {
      "referenceID" : 25,
      "context" : "visual instructions (Huang et al., 2017; Nishimura et al., 2020) and linguistic texts (Agarwal and Miller, 2011; Kiddon et al.",
      "startOffset" : 20,
      "endOffset" : 64
    }, {
      "referenceID" : 42,
      "context" : "visual instructions (Huang et al., 2017; Nishimura et al., 2020) and linguistic texts (Agarwal and Miller, 2011; Kiddon et al.",
      "startOffset" : 20,
      "endOffset" : 64
    }, {
      "referenceID" : 0,
      "context" : ", 2020) and linguistic texts (Agarwal and Miller, 2011; Kiddon et al., 2015; Jiang et al., 2020) across Japanese (Harashima and Hiramatsu, 2020; Harashima et al.",
      "startOffset" : 29,
      "endOffset" : 96
    }, {
      "referenceID" : 28,
      "context" : ", 2020) and linguistic texts (Agarwal and Miller, 2011; Kiddon et al., 2015; Jiang et al., 2020) across Japanese (Harashima and Hiramatsu, 2020; Harashima et al.",
      "startOffset" : 29,
      "endOffset" : 96
    }, {
      "referenceID" : 26,
      "context" : ", 2020) and linguistic texts (Agarwal and Miller, 2011; Kiddon et al., 2015; Jiang et al., 2020) across Japanese (Harashima and Hiramatsu, 2020; Harashima et al.",
      "startOffset" : 29,
      "endOffset" : 96
    }, {
      "referenceID" : 18,
      "context" : ", 2020) across Japanese (Harashima and Hiramatsu, 2020; Harashima et al., 2016) and English (Batra et al.",
      "startOffset" : 24,
      "endOffset" : 79
    }, {
      "referenceID" : 17,
      "context" : ", 2020) across Japanese (Harashima and Hiramatsu, 2020; Harashima et al., 2016) and English (Batra et al.",
      "startOffset" : 24,
      "endOffset" : 79
    }, {
      "referenceID" : 28,
      "context" : "Most research models linguistic recipes as a workflow graph based on actions (Kiddon et al., 2015; Mori et al., 2014; Yamakata et al., 2020), where the vertices represent name entities (e.",
      "startOffset" : 77,
      "endOffset" : 140
    }, {
      "referenceID" : 37,
      "context" : "Most research models linguistic recipes as a workflow graph based on actions (Kiddon et al., 2015; Mori et al., 2014; Yamakata et al., 2020), where the vertices represent name entities (e.",
      "startOffset" : 77,
      "endOffset" : 140
    }, {
      "referenceID" : 60,
      "context" : "Most research models linguistic recipes as a workflow graph based on actions (Kiddon et al., 2015; Mori et al., 2014; Yamakata et al., 2020), where the vertices represent name entities (e.",
      "startOffset" : 77,
      "endOffset" : 140
    }, {
      "referenceID" : 26,
      "context" : "The RISeC corpus (Jiang et al., 2020) identifies candidate expressions for zero anaphora verbs in English recipes.",
      "startOffset" : 17,
      "endOffset" : 37
    }, {
      "referenceID" : 63,
      "context" : "Various span ranking variants have proposed (Zhang et al., 2018; Grobol, 2019; Kantor and Globerson, 2019) and achieved strong performance.",
      "startOffset" : 44,
      "endOffset" : 106
    }, {
      "referenceID" : 16,
      "context" : "Various span ranking variants have proposed (Zhang et al., 2018; Grobol, 2019; Kantor and Globerson, 2019) and achieved strong performance.",
      "startOffset" : 44,
      "endOffset" : 106
    }, {
      "referenceID" : 27,
      "context" : "Various span ranking variants have proposed (Zhang et al., 2018; Grobol, 2019; Kantor and Globerson, 2019) and achieved strong performance.",
      "startOffset" : 44,
      "endOffset" : 106
    }, {
      "referenceID" : 4,
      "context" : "With the increasing amount of coreference corpora, transfer learning (Brack et al., 2021; Xia and Van Durme, 2021) involving pretraining on a source domain and fine-tuning on a target domain has shown great potential to improve coreference resolution.",
      "startOffset" : 69,
      "endOffset" : 114
    }, {
      "referenceID" : 61,
      "context" : ", 2018; Rösiger, 2018b) and (2) machine learning methods (Hou, 2018a,b, 2020; Yu and Poesio, 2020).",
      "startOffset" : 57,
      "endOffset" : 98
    }, {
      "referenceID" : 30,
      "context" : "Yu and Poesio (2020) proposed a joint training framework for bridging and coreference resolution based on the end-to-end coreference model (Lee et al., 2017).",
      "startOffset" : 139,
      "endOffset" : 157
    }, {
      "referenceID" : 3,
      "context" : "We create our RecipeRef dataset by random sampling texts from RecipeDB (Batra et al., 2020), a large diverse recipe database containing 118,171 English recipes with 268 processes and more than 20,262 ingredients.",
      "startOffset" : 71,
      "endOffset" : 91
    }, {
      "referenceID" : 47,
      "context" : "In line with previous work (Pradhan et al., 2012; Cohen et al., 2017; Fang et al., 2021a; Ghaddar and Langlais, 2016b), we leave out singleton mentions, i.",
      "startOffset" : 27,
      "endOffset" : 118
    }, {
      "referenceID" : 8,
      "context" : "In line with previous work (Pradhan et al., 2012; Cohen et al., 2017; Fang et al., 2021a; Ghaddar and Langlais, 2016b), we leave out singleton mentions, i.",
      "startOffset" : 27,
      "endOffset" : 118
    }, {
      "referenceID" : 11,
      "context" : "In line with previous work (Pradhan et al., 2012; Cohen et al., 2017; Fang et al., 2021a; Ghaddar and Langlais, 2016b), we leave out singleton mentions, i.",
      "startOffset" : 27,
      "endOffset" : 118
    }, {
      "referenceID" : 15,
      "context" : "In line with previous work (Pradhan et al., 2012; Cohen et al., 2017; Fang et al., 2021a; Ghaddar and Langlais, 2016b), we leave out singleton mentions, i.",
      "startOffset" : 27,
      "endOffset" : 118
    }, {
      "referenceID" : 10,
      "context" : "One of the core components in procedural comprehension is understanding entities state (Dalvi et al., 2018; Tandon et al., 2018).",
      "startOffset" : 87,
      "endOffset" : 128
    }, {
      "referenceID" : 55,
      "context" : "One of the core components in procedural comprehension is understanding entities state (Dalvi et al., 2018; Tandon et al., 2018).",
      "startOffset" : 87,
      "endOffset" : 128
    }, {
      "referenceID" : 5,
      "context" : "Coreference focuses on expressions that refer to the same entity in the real-world (Clark and Manning, 2015; Ng, 2017).",
      "startOffset" : 83,
      "endOffset" : 118
    }, {
      "referenceID" : 40,
      "context" : "Coreference focuses on expressions that refer to the same entity in the real-world (Clark and Manning, 2015; Ng, 2017).",
      "startOffset" : 83,
      "endOffset" : 118
    }, {
      "referenceID" : 29,
      "context" : "Surface coreference, where a coreferent anaphor links to the closest antecedent, and atom coreference, where a coreferent anaphor links to a correct antecedent, are applied to evaluate coreference resolution (Kim et al., 2012).",
      "startOffset" : 208,
      "endOffset" : 226
    }, {
      "referenceID" : 11,
      "context" : "The statistics of this recipe corpus in comparison with the ChEMU-ref corpus (Fang et al., 2021a) are shown in Table 2.",
      "startOffset" : 77,
      "endOffset" : 97
    }, {
      "referenceID" : 19,
      "context" : "A span representation si is the concatenation of output token representations (xi ) from a bidirectional LSTM (BiLSTM) (Hochreiter and Schmidhuber, 1997), the syntactic head representation (hi) obtained from an attention mechanism (Bahdanau et al.",
      "startOffset" : 119,
      "endOffset" : 153
    }, {
      "referenceID" : 2,
      "context" : "A span representation si is the concatenation of output token representations (xi ) from a bidirectional LSTM (BiLSTM) (Hochreiter and Schmidhuber, 1997), the syntactic head representation (hi) obtained from an attention mechanism (Bahdanau et al., 2015), and a feature vector of mention (φ(i)):",
      "startOffset" : 231,
      "endOffset" : 254
    }, {
      "referenceID" : 43,
      "context" : "Specifically, we use the concatenation of 300-dimensional GloVe embeddings (Pennington et al., 2014), 1024-dimensional ELMo word representations (Peters et al.",
      "startOffset" : 75,
      "endOffset" : 100
    }, {
      "referenceID" : 44,
      "context" : ", 2014), 1024-dimensional ELMo word representations (Peters et al., 2018) and 8dimensional character embeddings that are learned from a character CNN with windows of 3, 4, and 5 characters as the pretrianed token embeddings.",
      "startOffset" : 52,
      "endOffset" : 73
    }, {
      "referenceID" : 39,
      "context" : "Each feed-forward neural network consists of two hidden layers with 150 dimensions and rectified linear units (Nair and Hinton, 2010).",
      "startOffset" : 110,
      "endOffset" : 133
    }, {
      "referenceID" : 30,
      "context" : "Since end-toend model performance varies due to random initialization (Lee et al., 2017), we randomly shuffle the dataset 5 times and run cross-validation 3 times for each shuffle.",
      "startOffset" : 70,
      "endOffset" : 88
    } ],
    "year" : 0,
    "abstractText" : "Procedural text contains rich anaphoric phenomena yet has not received much attention in NLP. To fill this gap, we investigate the textual properties of two types of procedural text, recipes and chemical patents, and generalize an anaphora annotation framework developed for the chemical domain for modelling anaphoric phenomena in recipes. We apply this framework to annotate the RecipeRef corpus with both bridging and coreference relations. Through comparison to chemical patents, we show the complexity of anaphora resolution in recipes. We demonstrate empirically that transfer learning from the chemical domain improves resolution of anaphora in recipes, suggesting transferability of general procedural knowledge. The corpus is made available at withheld_for_review.",
    "creator" : null
  }
}