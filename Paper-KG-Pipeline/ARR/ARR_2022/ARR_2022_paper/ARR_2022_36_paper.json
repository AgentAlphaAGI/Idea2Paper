{
  "name" : "ARR_2022_36_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "FiNER: Financial Numeric Entity Recognition for XBRL Tagging",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Natural language processing (nlp) for finance is an emerging research area (Hahn et al., 2019; Chen et al., 2020; El-Haj et al., 2020). Financial data are mostly reported in tables, but substantial information can also be found in textual form, e.g., in company filings, analyst reports, and economic news. Such information is useful in numerous financial intelligence tasks, like stock market prediction (Chen et al., 2019; Yang et al., 2019), financial sentiment analysis (Malo et al., 2014; Wang et al., 2013; Akhtar et al., 2017), economic event detection (Ein-Dor et al., 2019; Jacobs et al., 2018; Zhai and Zhang, 2019), and causality analysis (Tabari et al., 2018; Izumi and Sakaji, 2019). In this work,\nwe study how financial reports can be automatically enriched with word-level tags from the eXtensive Business Reporting Language (xbrl), a tedious and costly task not considered so far.1\nTo promote transparency among shareholders and potential investors, publicly traded companies are required to file periodic financial reports. These comprise multiple sections, including financial tables and text paragraphs, called text notes. In addition, legislation in the us, the uk, the eu and elsewhere requires the reports to be annotated with tags of xbrl, an xml-based language, to facilitate the processing of financial information.2 The annotation of tables can be easily achieved by using company-specific pre-tagged table templates, since the structure and contents of the tables in the reports of a particular company rarely change. On the other hand, the unstructured and dynamic nature of text notes (Figure 1) makes adding xbrl tags to them much more difficult. Hence, we focus on automatically tagging text notes. Tackling this task could facilitate the annotation of new and old reports (which may not include xbrl tags), e.g., by inspecting automatically suggested tags.\nTowards this direction, we release finer-139, a new dataset of 1.1M sentences with gold xbrl\n1See https://www.xbrl.org/the-standard/what/ an-introduction-to-xbrl/ for an introduction to xbrl.\n2Consult, e.g., https://www.xbrl.org/news/esefbecomes-european-law/ for legislation requirements.\ntags, from annual and quarterly reports of publicly traded companies obtained from the us Securities and Exchange Commission (sec). Unlike other entity extraction tasks, like named entity recognition (ner) or contract element extraction (Table 1), which typically require identifying entities of a small set of common types (e.g., persons, organizations), xbrl defines approx. 6k entity types. As a first step, we consider the 139 most frequent xbrl entity types, still a much larger label set than usual.\nAnother important difference from typical entity extraction is that most tagged tokens (∼91%) in the text notes we consider are numeric, with the correct tag per token depending mostly on context, not the token itself (Figure 1). The abundance of numeric tokens also leads to a very high ratio of outof-vocabulary (oov) tokens, approx. 10.4% when usingword2vec (Mikolov et al., 2013a). When using subwords, e.g., in models like bert (Devlin et al., 2019), there are no oov tokens, but numeric expressions get excessively fragmented, making it difficult for the model to gather information from the fragments and correctly tag them all. In our experiments, this is evident by the slightly better performance of stacked bilstms (Graves et al., 2013; Lample et al., 2016) operating on word embeddings compared to bert. The latter improves when using a crf (Lafferty et al., 2001) layer, which helps avoid assigning nonsensical sequences of labels to the fragments (subwords) of numeric expressions.\nTo further improve bert’s performance, we propose two simple and effective solutions that replace numeric expressions with pseudo-tokens reflecting the original token shapes and magnitudes. We also experiment with fin-bert, an existing bert model for the financial domain, and release our own bert (sec-bert), pre-trained on 200k financial filings, achieving the best overall performance.\nOur key contributions are: 1. We introduce xbrl tagging, a new financial\nnlp task for a real-world need, and we release finer-139, the first xbrl tagging dataset.\n2. We provide extensive experimental results with neural classifiers, including bilstms and bert with generic or in-domain pre-training, which establish strong baseline results for future work on finer-139.\n3. We show that replacing numeric tokens with pseudo-tokens reflecting token shapes and magnitudes significantly boosts the performance of bert-based models in this task.\n4. We release a new bert model (sec-bert) pre-trained on 200k financial filings that obtains the best results on finer-139.3"
    }, {
      "heading" : "2 Related Work",
      "text" : "Entity extraction: xbrl tagging differs from ner and other previous entity extraction tasks (Table 1), like contract element extraction (Chalkidis et al., 2019). Crucially, in xbrl tagging there is a much larger set of entity types (6k in full xbrl, 139 in finer-139), most tagged tokens are numeric (∼91%), and the correct tag highly depends on context. In most ner datasets, numeric expressions are classified in generic entity types like ‘amount’ or ‘date’ (Bikel et al., 1999; Nadeau and Sekine, 2007); this can often be achieved with regular expressions that look for common formats of numeric expressions, and the latter are often among the easiest entity types in ner datasets. By contrast, although it is easy to figure out that the first three highlighted expressions of Figure 1 are amounts, assigning them the correct xbrl tags requires carefully considering their context. Contract element extraction (Chalkidis et al., 2019) also requires considering the context of dates, amounts etc. to distinguish, for example, start dates from end dates, total amounts from other mentioned amounts, but the number of entity types in finer-139 is an order of magnitude larger (Table 1) and the full tag set of xbrl is even larger (6k).\nFinancial ner: Previous financial ner applications use at most 9 (generic) class labels. Salinas Alvarado et al. (2015) investigated ner in finance to recognize organizations, persons, locations, and miscellaneous entities on 8 manually annotated sec financial agreements using crfs. Francis et al. (2019) experimented with transfer learning by unfreezing different layers of a bilstm\n3Release urls are omitted to preserve anonymity.\nwith a crf layer, pre-trained on invoices, to extract 9 entity types with distinct morphological patterns (e.g., iban, company name, date, total amount). Also, Hampton et al. (2015, 2016) applied a Maximum Entropy classifier, crfs, and handcrafted rules to London Stock Exchange filings to detect 9 generic entity types (e.g., person, organization, location, money, date, percentages). Finally, Kumar et al. (2016) extended the work of Finkel et al. (2005) and built a financial entity recognizer of dates, numeric values, economic terms in sec and non-sec documents, using numerous handcrafted text features. By contrast, finer-139 uses a specialized set of 139 highly technical economic tags derived from the real-world need of xbrl tagging, and we employ no handcrafted features.\nNumerical reasoning: Neural numerical reasoning studies how to represent numbers to solve numeracy tasks, e.g., compare numbers, understand mathematical operations mentioned in a text etc. Zhang et al. (2020) released numbert, a Transformer-based model that handles numerical reasoning tasks by representing numbers by their scientific notation and applying subword tokenization. On the other hand, genbert (Geva et al., 2020) uses the decimal notation and digit-by-digit tokenization of numbers. Both models attempt to deal with the problem that word-level tokenization often turns numeric tokens to oovs (Thawani et al., 2021). This is important, because numerical reasoning requires modeling the exact value of each numeric token. In finer-139, the correct xbrl tags of numeric tokens depend much more on their contexts and token shapes than on their exact numeric values (Fig. 1). Hence, these methods are not directly relevant. genbert’s digit-by-digit tokenization would also lead to excessive fragmentation, which we experimentally find to harm performance."
    }, {
      "heading" : "3 Task and Dataset",
      "text" : "Traditionally, business filings were simply rendered in plain text. Thus, analysts and researchers needed to manually identify, copy, and paste each amount of interest (e.g., from filings to spreadsheets). With xbrl-tagged filings, identifying and extracting amounts of interest (e.g., to spreadsheets or databases) can be automated. More generally, xbrl facilitates the machine processing of financial documents.4 Hence, xbrl-tagged financial\n4xbrl is an accounting instance of xml. See also https: //www.investopedia.com/terms/x/xbrl.asp.\nreports are required in several countries, as already noted (Section 1). However, manually tagging reports with xbrl tags is tedious and resourceintensive. Therefore, we release finer-139 to foster research towards automating xbrl tagging. finer-139 was compiled from approx. 10k annual and quarterly English reports (filings) of publicly traded companies downloaded from sec’s edgar system.5 The downloaded reports span a 5-year period, from 2016 to 2020. They are annotated with xbrl tags by professional auditors and describe the performance and projections of the companies. We used regular expressions to extract the text notes from the Financial Statements Item of each filing, which is the primary source of xbrl tags in annual and quarterly reports. xbrl taxonomies have many different attributes, making xbrl tagging challenging even for humans (Baldwin et al., 2006; Hoitash and Hoitash, 2018). Furthermore, each jurisdiction has its own xbrl taxonomy. Since we work with us documents, our labels come from us-gaap.6 Since this is the first effort towards automatic xbrl tagging, we chose to work with the most essential and informative attribute, the tag names, which populate our label set. Also, since xbrl tags change periodically, we selected the 139 (out of 6,008) most frequent xbrl tags with at least 1,000 appearances in finer-139. The distribution of these tags seems to follow a power law (Figure 2), hence most of the 6k xbrl tags that we did not consider are very rare. We used the iob2 annotation scheme to distinguish tokens at the beginning, inside, or outside of tagged expressions, which leads to 279 possible token labels.\n5https://www.sec.gov/edgar/ 6www.xbrl.us/xbrl-taxonomy/2020-us-gaap/\nWe split the text notes into 1.8M sentences, the majority of which (∼90%) contained no tags.7 The sentences are also html-stripped, normalized, and lower-cased. To avoid conflating trivial and more difficult cases, we apply heuristic rules to discard sentences that can be easily flagged as almost certainly requiring no tagging; in a real-life setting, the heuristics, possibly further improved, would discard sentences that do not need to be processed by the tagger. The heuristic rules were created by inspecting the training subset and include regular expressions that look for amounts and other expressions that are typically annotated. Approx. 40% of the 1.8M sentences were removed, discarding only 1% of tagged ones. We split chronologically the remaining sentences into training, development, and test sets with an 80/10/10 ratio (Table 2)."
    }, {
      "heading" : "4 Baseline Models",
      "text" : "spaCy (Honnibal et al., 2020) is an open-source nlp library.8 It includes an industrial ner that uses word-level Bloom embeddings (Serrà and Karatzoglou, 2017) and residual Convolutional Neural Networks (cnns) (He et al., 2016). We trained spaCy’s ner from scratch on finer-139.\nbilstm: This baseline uses a stacked bidirectional Long-Short Term Memory (lstm) network (Graves et al., 2013; Lample et al., 2016) with residual connections. Each token ti of a sentence S = {t1, ..., tn} is mapped to an embedding and passed through the bilstm stack to extract the corresponding contextualized embedding. A shared multinomial logistic regression (lr) layer operates on top of each contextualized embedding to predict the correct label. We leverage our ownword2vec embeddings (Mikolov et al., 2013a,b), trained with the skip-gram algorithm on 200k unlabeled sec filings we downloaded, called sec-corpus.9\nbert: This is similar to bilstm, but now we finetune bert-base (Devlin et al., 2019) to extract contextualized embeddings of subwords. Again, a\n7We use nltk (Bird et al., 2009) for sentence splitting. 8We used spaCy v.2.3; see https://spacy.io/. 9We used gensim’s (Řehůřek and Sojka, 2010) skip-gram\nimplementation, with default settings.\nmultinomial lr layer operates on top of the contextualized embeddings to predict the correct label of the corresponding subword.\ncrfs: In this case, we replace the lr layer of the previous two models with a Conditional Random Field (crf) layer (Lafferty et al., 2001), which has been shown to be beneficial in several sequence labeling tasks (Huang et al., 2015; Lample et al., 2016; Chalkidis et al., 2020b).10"
    }, {
      "heading" : "5 Baseline Results",
      "text" : "We report micro-F1 (µ-F1) and macro-F1 (m-F1) at the entity level, i.e., if a gold tag annotates a multi-word span, a model gets credit only if it tags the exact same span. This allows comparing more easily methods that label words vs. subwords.\nTable 3 shows that spaCy performs poorly, possibly due to the differences from typical sequence labeling tasks, i.e., the large amount of entity types, the abundance of numeric tokens, and the fact that in finer-139 the tagging decisions depend mostly on context. Interestingly enough, bilstm (with word embeddings) performs slightly better than bert. However, when a crf layer is added, bert achieves the best results, while the performance of bilstm (with word embeddings) deteriorates significantly, contradicting previous studies.\nWe hypothesize that the inconsistent effect of crfs is due to tokenization differences. When using bert’s subword (wordpiece) tokenizer, there are more decisions that need to be all correct for a tagged span to be correct (one decision per subword) than when using word tokenization (one decision per word). Thus, it becomes more difficult for subword models to avoid nonsensical sequences of token labels, e.g., labeling two consecutive subwords as beginning and inside of different entity types, especially given the large set of 279 labels\n10We use a linear-chain crf layer with log-likelihood optimization and Viterbi decoding.\n(Table 1). The crf layer on top of subword models helps reduce the (more frequent than with word models) nonsensical sequences of labels.\nOn the other side, when using words as tokens, there are fewer opportunities for nonsensical label sequences, because there are fewer tokens.11 Hence, it is easier for the bilstm (on its own) to avoid predicting nonsensical sequences of labels. Thus, the crf layer on top of the bilstm (with word embeddings) has less room to contribute and mainly introduces noise (e.g., it often assigns low probabilities to acceptable, but less frequent label sequences). With the crf layer, the model tries to maximize both the confidence of the bilstm for the predicted label of each word and the probability that the predicted sequence of labels is frequent. When the bilstm on its own rarely predicts nonsensical sequences of labels, adding the crf layer rewards commonly seen sequences of labels, even if they are not the correct labels, without reducing the already rare nonsensical sequences of labels.\nTo further support our hypothesis, we repeated the bilstm experiments, but with subword instead of word embeddings.12 Without the crf, the subword bilstm performs much worse than the word bilstm (6% drop in µ-F1), because of the many more decisions and opportunities to predict nonsensical label sequences. The crf layer substantially improves the performance of the subword bilstm (4.1% increase in µ-F1), as expected, though the word bilstm (without crf) is still better, because of the fewer opportunities for nonsensical predictions. A drawback of crfs is that they significantly slow down the models both during training and inference, especially when using large label sets (Goldman and Goldberger, 2020), as in our case. Hence, although bert with crf was the best model in Table 3, we wished to improve bert’s performance further without employing crfs.\n6 Fragmentation in bert\nIn finer-139, the majority (91.2%) of the gold tagged spans are numeric expressions, which cannot all be included in bert’s finite vocabulary; e.g., the token ‘9,323.0’ is split into five subword units, [‘9’, ‘##,’, ‘##323’, ‘##.’, ‘##0’], while the token ‘12.78’ is split into [‘12’, ‘##.’, ‘##78’]. The excessive fragmentation of numeric expressions, when using\n11The average number of subwords and words per gold span is 2.53 and 1.04, respectively.\n12We trained our own subword word2vec embeddings, with the same subword vocabulary as with bert.\nsubword tokenization, harms the performance of the subword-based models (Table 3), because it increases the probability of producing nonsensical sequences of labels, as already discussed. We, therefore, propose two simple and effective solutions to avoid the over-fragmentation of numbers.\nbert + [num]: We detect numbers using regular expressions and replace each one with a single [num] pseudo-token, which cannot be split. The pseudo-token is added to the bert vocabulary, and its representation is learned during fine-tuning. This allows handling all numeric expressions in a uniform manner, disallowing their fragmentation.\nbert + [shape]: We replace numbers with pseudo-tokens that cannot be split and represent the number’s shape. For instance, ‘53.2’ becomes ‘XX.X’, and ‘40,200.5’ becomes ‘XX,XXX.X’. We use 214 special tokens that cover all the number shapes of the training set. Again, the representations of the pseudo-tokens are fine-tuned, and numeric expressions (of known shapes) are no longer fragmented. The shape pseudo-tokens also capture information about each number’s magnitude; the intuition is that numeric tokens of similar magnitudes may require similar xbrl tags. Figure 3 illustrates the use of [num] and [shape] pseudo-tokens."
    }, {
      "heading" : "7 In-domain Pre-training",
      "text" : "We also pre-train bert models on financial text, motivated by reported benefits of in-domain pretraining (Alsentzer et al., 2019; Beltagy et al., 2019; Yang et al., 2020; Chalkidis et al., 2020b).\nfin-bert: We fine-tune fin-bert (Yang et al.,\n2020), which is pre-trained on a financial corpus from sec documents, earnings call transcripts, and analyst reports.13 The 30k subwords vocabulary of fin-bert is built from scratch from its pre-training corpus. Again, we utilize fin-bert with and without our numeric pseudo-tokens, whose representations are learned during fine-tuning.\nsec-bert: We also release our own bert model. Following the original setup of Devlin et al. (2019), we pre-trained bert from scratch on the financial corpus we gathered from sec (sec-corpus, Section 4). The resulting model, called sec-bert, has a newly created vocabulary of 30k subwords. To further examine the impact of the proposed [num] and [shape] special tokens, we also pre-trained two additional bert variants, sec-bert-num and sec-bert-shape, on the same corpus, having replaced all numbers by [num] or [shape] pseudotokens, respectively. In this case, the representations of the pseudo-tokens are learned during pretraining and they are updated during fine-tuning.\n8 Improved bert Results\nTable 4 reports micro-averaged precision, recall, and F1 on development and test data. Focusing on the second zone, we observe that the [num] pseudotoken improves bert’s results, as expected, since it does not allow numeric expressions to be fragmented. The results of bert + [num] are now comparable to those of bert + crf. Performance improves further when utilizing the shape pseudotokens (bert + [shape]), yielding 79.4 µ-F1 and showing that information about each number’s magnitude is valuable when predicting xbrl tags.\n13We use the finbert-finvocab-uncased version from https://github.com/yya518/FinBERT.\nInterestingly, fin-bert (3rd zone) performs worse than bert despite its pre-training on financial data. Similarly to bert, this can be attributed to the fragmentation of numbers (2.5 subwords per gold tag span). Again, the proposed pseudo-tokens ([num], [shape]) alleviate this problem and allow fin-bert to leverage its in-domain pre-training in order to finally surpass the corresponding bert variants, achieving an 80.1 µ-F1 test score.\nOur new model, sec-bert (last zone), which is pre-trained on sec reports, performs better than the existing bert and fin-bert models, when no numeric pseudo-tokens are used. However, secbert is still worse than bertwith numeric pseudotokens (75.7 vs. 78.3 and 79.4 test µ-F1), suffering from number fragmentation (2.4 subwords per gold tag span). sec-bert (without pseudo-tokens) also performs worse than the bilstm with word embeddings (75.7 vs. 77.3 µ-F1, cf. Table 3). However, when the proposed pseudo-tokens are used, secbert-num and sec-bert-shape achieve the best overall performance, boosting the test µ-F1 to 80.4 and 82.1, respectively. This indicates that learning to handle numeric expressions during model pretraining is a better strategy than trying to acquire this knowledge only during fine-tuning."
    }, {
      "heading" : "9 Additional Experiments",
      "text" : ""
    }, {
      "heading" : "9.1 Subword pooling",
      "text" : "An alternative way to bypass word fragmentation is to use subword pooling for each word. Ács et al. (2021) found that for ner tasks, it is better to use the first subword only, i.e., predict the label of an entire word from the contextualized embedding of its first subword only; they compared to several other methods, such as using only the last subword\nof each word, or combining the contextualized embeddings of all subwords with a self-attention mechanism. Given this finding, we conducted an ablation study and compare (i) our best model (secbert) with first subword pooling (denoted secbert-first) to (ii) sec-bert with our special tokens (sec-bert-num, sec-bert-shape), which avoid segmenting numeric tokens.\nTable 5 shows that, in xbrl tagging, using the proposed special tokens is comparable (sec-bertnum) or better (sec-bert-shape) than performing first pooling (sec-bert-first). It might be worth trying other pooling strategies as well, like last-pooling or subword self-attention pooling. It’s worth noting, however, that the latter will increase the training and inference times.\n9.2 Subword bilstm with [num] and [shape]\nTo further investigate the effectiveness of our pseudo-tokens, we incorporated them in the bilstm operating on subword embeddings (3rd model of Table 3). Again, we replace each number by a single [num] pseudo-token or one of 214 [shape] pseudo-tokens, for the two approaches, respectively. These replacements also happen when pretrainingword2vec subword embeddings; hence, an embedding is obtained for each pseudo-token.\nTable 6 shows that bilstm-num outperforms the bilstm subword model.bilstm-shape further improves performance and is the best bilstm subword model overall, surpassing the subword bilstm with crf, which was the best subword bilstm model in Table 3. These results further support our hypothesis that the [num] and [shape] pseudo-tokens help subword models successfully generalize over numeric expressions, with [shape] being the best of the two approaches, while also avoiding the over-fragmentation of numbers."
    }, {
      "heading" : "9.3 A Business Use Case",
      "text" : "Since xbrl tagging is derived from a real-world need, it is crucial to analyze the model’s performance in a business use case. After consulting\nwith experts of the financial domain, we concluded that one practical use case would be to use an xbrl tagger as a recommendation engine that would propose the k most probable xbrl tags for a specific token selected by the user. The idea is that an expert (e.g., accountant, auditor) knows beforehand the token(s) that should be annotated and the tagger would assist by helping identify the appropriate tags more quickly. Instead of having to select from several hundreds of xbrl tags, the expert would only have to inspect a short list of k proposed tags.\nWe evaluate our best model, sec-bert-shape, in this use case using Hits@k. We use the model to return the k most probable xbrl tags for each token that needs to be annotated, now assuming that the tokens to be annotated are known. If the correct tag is among the top k, we increase the number of hits by one. Finally, we divide by the number of tokens to be annotated. Figure 4 shows the results for different values of k. The curve is steep for k = 1 to 5 and saturates as k approaches 10, where Hits@k is nearly perfect (99.4%). In practice, this means that a user would have to inspect 10 recommended xbrl tags instead of hundreds for each token to be annotated; and in most cases, the correct tag would be among the top 5 recommended ones."
    }, {
      "heading" : "9.4 Error Analysis",
      "text" : "We also performed an exploratory data and error analysis to unveil the peculiarities of finer-139, extract new insights about it, and discover the limitations of our best model. Specifically, we manually inspected the errors of sec-bert-shape in under-performing classes (where F1 < 50%) and identified three main sources of errors.\nSpecialized terminology: In this type of errors, the model is able to understand the general financial semantics, but does not fully comprehend highly technical details. For example, Operating Lease Expense amounts are sometimes missclassified as Lease And Rental Expense, i.e., the model manages to predict that these amounts are about expenses in general, but fails to identify the specific details that distinguish operating lease expenses from lease and rental expenses. Similarly, Payments to Acquire Businesses (Net of Cash Acquired) amounts are mostly misclassified as Payments to Acquire Businesses (Gross). In this case, the model understands the notion of business acquisition, but fails to differentiate between net and gross payments.\nFinancial dates: Another interesting error type is the misclassification of financial dates. For example, tokens of the class Debt Instrument Maturity Date are mostly missclassified as not belonging to any entity at all (‘O’ tag). Given the previous type of errors, one would expect the model to missclassify these tokens as a different type of financial date, but this is not the case here. We suspect that errors of this type may be due to annotation inconsistencies by the financial experts.\nAnnotation inconsistencies: Even though the gold xbrl tags of finer-139 come from professional auditors, as required by the Securities & Exchange Commission (sec) legislation, there are still some discrepancies. We provide an illustrative example in Figure 5. We believe that such inconsistencies are inevitable to occur and they are a part of the real-world nature of the problem.\nWe hope that this analysis inspires future work on xbrl tagging. For example, the specialized terminology and financial date errors may be alleviated by adopting hierarchical classifiers (Chalkidis et al., 2020a; Manginas et al., 2020), which would first detect entities in coarse classes (e.g., expenses, dates) and would then try to classify the identified entities into coarser classes (e.g., lease vs. rent expenses, instrument maturity dates vs. other types\nof dates). It would also be interesting to train classifiers towards detecting wrong (or missing) gold annotations, in order to help in quality assurance checks of xbrl-tagged documents."
    }, {
      "heading" : "10 Conclusions and Future Work",
      "text" : "We introduced a new real-word nlp task from the financial domain, xbrl tagging, required by regulatory commissions worldwide. We released finer139, a dataset of 1.1M sentences with xbrl tags. Unlike typical entity extraction tasks, finer-139 uses a much larger label set (139 tags), most tokens to be tagged are numeric, and the correct tag depends mostly on context rather than the tagged token. We experimented with several neural classifiers, showing that a bilstm outperforms bert due to the excessive numeric token fragmentation of the latter. We proposed two simple and effective solutions that use special tokens to generalize over the shapes and magnitudes of numeric expressions. We also experimented with fin-bert, an existing bert model for the financial domain, which also benefits from our special tokens. Finally, we pretrained and released our own domain-specific bert model, sec-bert, both with and without the special tokens, which achieves the best overall results with the special tokens, without costly crf layers.\nIn future work, we intend to hire experts to reannotate a subset of the dataset to measure human performance against the gold tags. We also plan to include less frequent xbrl tags (few- and zero-shot learning) and exploit the hierarchical dependencies of xbrl tags, possibly with hierarchical classifiers, building upon our error analysis insights."
    }, {
      "heading" : "A Experimental Setup",
      "text" : "For spaCy, we followed the recommended practices.14 All other methods were implemented in tensorflow.15 Concerning bert models, we used the implementation of huggingface (Wolf et al., 2020). We also use Adam (Kingma and Ba, 2015), Glorot initialization (Glorot and Bengio, 2010), and the categorical cross-entropy loss.\nHyper-parameters were tuned on development data with Bayesian Optimization monitoring the development loss for 15 trials.16 For the bilstm encoders, we searched for {1, 2, 3} hidden layers, {128, 200, 256} hidden units, {1e-3, 2e-3, 3e-3, 4e3, 5e-3} learning rate, and {0.1, 0.2, 0.3} dropout. We trained for 30 epochs using early stopping with patience 4. For bert, we used grid-search to select the optimal learning rate from {1e-5, 2e-5, 3e-5, 4e5, 5e-5}, fine-tuning for 10 epochs, using early stopping with patience 2. All final hyper-parameters are shown in Table 7. Training was performed mainly on a dgx station with 4 nvidia v100 gpus and an Intel Xeon cpu e5-2698 v4 @ 2.20ghz."
    }, {
      "heading" : "B Additional Results",
      "text" : "Table 8 shows micro-averaged Precision, Recall, and F1 for the development and test data, using all baseline methods. The macro-averaged scores are similar and we omit them for brevity. Using a logistic regression (lr) classification layer, bilstm (words) surpasses bert both in Precision and F1 score. However, when using a crf layer on top, bert outperforms bilstm (words) in all measures.\nTable 9 shows the micro-averaged Precision, Recall, and F1 for the development and test data using the bilstmmodels operating on subwords with the proposed tokenizations. [num] and [shape] tokens help the model to bypass the word fragmentation problem, increasing its scores in all metrics.\n14https://spacy.io/usage/v2-3. 15https://www.tensorflow.org/ 16We used keras tuner (https://keras-team.\ngithub.io/keras-tuner/documentation/tuners/)"
    } ],
    "references" : [ {
      "title" : "Subword pooling makes a difference",
      "author" : [ "Judit Ács", "Ákos Kádár", "Andras Kornai." ],
      "venue" : "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 2284–2295, Online.",
      "citeRegEx" : "Ács et al\\.,? 2021",
      "shortCiteRegEx" : "Ács et al\\.",
      "year" : 2021
    }, {
      "title" : "A multilayer perceptron based ensemble technique for fine-grained financial sentiment analysis",
      "author" : [ "Md Shad Akhtar", "Abhishek Kumar", "Deepanway Ghosal", "Asif Ekbal", "Pushpak Bhattacharyya." ],
      "venue" : "Proceedings of the 2017 Conference on Empiri-",
      "citeRegEx" : "Akhtar et al\\.,? 2017",
      "shortCiteRegEx" : "Akhtar et al\\.",
      "year" : 2017
    }, {
      "title" : "Publicly available clinical BERT embeddings",
      "author" : [ "Emily Alsentzer", "John Murphy", "William Boag", "WeiHung Weng", "Di Jin", "Tristan Naumann", "Matthew McDermott." ],
      "venue" : "Proceedings of the 2nd Clinical Natural Language Processing Workshop, pages 72–78,",
      "citeRegEx" : "Alsentzer et al\\.,? 2019",
      "shortCiteRegEx" : "Alsentzer et al\\.",
      "year" : 2019
    }, {
      "title" : "Xbrl: An impacts framework and research challenge",
      "author" : [ "Amelia Annette Baldwin", "Carol E. Brown", "Brad S. Trinkle." ],
      "venue" : "Journal of Emerging Technologies in Accounting, 3:97–116.",
      "citeRegEx" : "Baldwin et al\\.,? 2006",
      "shortCiteRegEx" : "Baldwin et al\\.",
      "year" : 2006
    }, {
      "title" : "SciBERT: A pretrained language model for scientific text",
      "author" : [ "Iz Beltagy", "Kyle Lo", "Arman Cohan." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Lan-",
      "citeRegEx" : "Beltagy et al\\.,? 2019",
      "shortCiteRegEx" : "Beltagy et al\\.",
      "year" : 2019
    }, {
      "title" : "An algorithm that learns what’s in a name",
      "author" : [ "Daniel M. Bikel", "Richard Schwartz", "Ralph M. Weischedel." ],
      "venue" : "Machine Learning, 34(1-3):211–231.",
      "citeRegEx" : "Bikel et al\\.,? 1999",
      "shortCiteRegEx" : "Bikel et al\\.",
      "year" : 1999
    }, {
      "title" : "Natural Language Processing with Python, 1st edition",
      "author" : [ "Steven Bird", "Ewan Klein", "Edward Loper." ],
      "venue" : "O’Reilly Media, Inc.",
      "citeRegEx" : "Bird et al\\.,? 2009",
      "shortCiteRegEx" : "Bird et al\\.",
      "year" : 2009
    }, {
      "title" : "An empirical study on large-scale multi-label text classification including few and zero-shot labels",
      "author" : [ "Ilias Chalkidis", "Manos Fergadiotis", "Sotiris Kotitsas", "Prodromos Malakasiotis", "Nikolaos Aletras", "Ion Androutsopoulos." ],
      "venue" : "Proceedings of the 2020",
      "citeRegEx" : "Chalkidis et al\\.,? 2020a",
      "shortCiteRegEx" : "Chalkidis et al\\.",
      "year" : 2020
    }, {
      "title" : "LEGAL-BERT: The muppets straight out of law school",
      "author" : [ "Ilias Chalkidis", "Manos Fergadiotis", "Prodromos Malakasiotis", "Nikolaos Aletras", "Ion Androutsopoulos." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 2898–",
      "citeRegEx" : "Chalkidis et al\\.,? 2020b",
      "shortCiteRegEx" : "Chalkidis et al\\.",
      "year" : 2020
    }, {
      "title" : "Neural contract element extraction revisited",
      "author" : [ "Ilias Chalkidis", "Manos Fergadiotis", "Prodromos Malakasiotis", "Ion Androutsopoulos." ],
      "venue" : "Workshop on Document Intelligence at NeurIPS 2019.",
      "citeRegEx" : "Chalkidis et al\\.,? 2019",
      "shortCiteRegEx" : "Chalkidis et al\\.",
      "year" : 2019
    }, {
      "title" : "Group, extract and aggregate: Summarizing a large amount of finance news for forex movement prediction",
      "author" : [ "Deli Chen", "Shuming Ma", "Keiko Harimoto", "Ruihan Bao", "Qi Su", "Xu Sun." ],
      "venue" : "Proceedings of the Second Workshop on Economics and Natural",
      "citeRegEx" : "Chen et al\\.,? 2019",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2019
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "The automatic content extraction (ACE) program – tasks, data, and evaluation",
      "author" : [ "George Doddington", "Alexis Mitchell", "Mark Przybocki", "Lance Ramshaw", "Stephanie Strassel", "Ralph Weischedel." ],
      "venue" : "Proceedings of the Fourth International Conference",
      "citeRegEx" : "Doddington et al\\.,? 2004",
      "shortCiteRegEx" : "Doddington et al\\.",
      "year" : 2004
    }, {
      "title" : "Financial event extraction using Wikipedia-based weak supervision",
      "author" : [ "Liat Ein-Dor", "Ariel Gera", "Orith Toledo-Ronen", "Alon Halfon", "Benjamin Sznajder", "Lena Dankin", "Yonatan Bilu", "Yoav Katz", "Noam Slonim." ],
      "venue" : "Proceedings of the Second Work-",
      "citeRegEx" : "Ein.Dor et al\\.,? 2019",
      "shortCiteRegEx" : "Ein.Dor et al\\.",
      "year" : 2019
    }, {
      "title" : "Incorporating non-local information into information extraction systems by Gibbs sampling",
      "author" : [ "Jenny Rose Finkel", "Trond Grenager", "Christopher Manning." ],
      "venue" : "Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics",
      "citeRegEx" : "Finkel et al\\.,? 2005",
      "shortCiteRegEx" : "Finkel et al\\.",
      "year" : 2005
    }, {
      "title" : "Transfer learning for named entity recognition in financial and biomedical documents",
      "author" : [ "Sumam Francis", "Jordy Van Landeghem", "MarieFrancine Moens." ],
      "venue" : "Information, 10(8):248.",
      "citeRegEx" : "Francis et al\\.,? 2019",
      "shortCiteRegEx" : "Francis et al\\.",
      "year" : 2019
    }, {
      "title" : "Injecting numerical reasoning skills into language models",
      "author" : [ "Mor Geva", "Ankit Gupta", "Jonathan Berant." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020, pages 946–958.",
      "citeRegEx" : "Geva et al\\.,? 2020",
      "shortCiteRegEx" : "Geva et al\\.",
      "year" : 2020
    }, {
      "title" : "Understanding the difficulty of training deep feedforward neural networks",
      "author" : [ "Xavier Glorot", "Yoshua Bengio." ],
      "venue" : "Proceedings of the Thirteenth 9",
      "citeRegEx" : "Glorot and Bengio.,? 2010",
      "shortCiteRegEx" : "Glorot and Bengio.",
      "year" : 2010
    }, {
      "title" : "Crf with deep class embedding for large scale classification",
      "author" : [ "Eran Goldman", "Jacob Goldberger." ],
      "venue" : "Computer Vision and Image Understanding, 191:102865.",
      "citeRegEx" : "Goldman and Goldberger.,? 2020",
      "shortCiteRegEx" : "Goldman and Goldberger.",
      "year" : 2020
    }, {
      "title" : "Speech recognition with deep recurrent neural networks",
      "author" : [ "Alex Graves", "Abdel rahman Mohamed", "Geoffrey E. Hinton." ],
      "venue" : "2013 IEEE International Conference on Acoustics, Speech and Signal Processing, pages 6645–6649.",
      "citeRegEx" : "Graves et al\\.,? 2013",
      "shortCiteRegEx" : "Graves et al\\.",
      "year" : 2013
    }, {
      "title" : "Automated sequence tagging: Applications in financial hybrid systems",
      "author" : [ "Peter Hampton", "Hui Wang", "William Blackburn", "Zhiwei Lin." ],
      "venue" : "Research and Development in Intelligent Systems XXXIII, pages 295–306.",
      "citeRegEx" : "Hampton et al\\.,? 2016",
      "shortCiteRegEx" : "Hampton et al\\.",
      "year" : 2016
    }, {
      "title" : "A hybrid ensemble for classifying and repurposing financial entities",
      "author" : [ "Peter John Hampton", "Hui Wang", "William Blackburn." ],
      "venue" : "Research and Development in Intelligent Systems XXXII, pages 197– 202.",
      "citeRegEx" : "Hampton et al\\.,? 2015",
      "shortCiteRegEx" : "Hampton et al\\.",
      "year" : 2015
    }, {
      "title" : "Deep residual learning for image recognition",
      "author" : [ "Kaiming He", "X. Zhang", "Shaoqing Ren", "Jian Sun." ],
      "venue" : "2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770–778.",
      "citeRegEx" : "He et al\\.,? 2016",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2016
    }, {
      "title" : "Measuring accounting reporting complexity with xbrl",
      "author" : [ "Rani Hoitash", "Udi Hoitash." ],
      "venue" : "The Accounting Review, 93:259–287.",
      "citeRegEx" : "Hoitash and Hoitash.,? 2018",
      "shortCiteRegEx" : "Hoitash and Hoitash.",
      "year" : 2018
    }, {
      "title" : "spaCy: Industrial-strength Natural Language Processing in Python",
      "author" : [ "Matthew Honnibal", "Ines Montani", "Sofie Van Landeghem", "Adriane Boyd" ],
      "venue" : null,
      "citeRegEx" : "Honnibal et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Honnibal et al\\.",
      "year" : 2020
    }, {
      "title" : "Bidirectional LSTM-CRF models for sequence tagging",
      "author" : [ "Zhiheng Huang", "Wei Xu", "Kai Yu." ],
      "venue" : "CoRR, abs/1508.01991.",
      "citeRegEx" : "Huang et al\\.,? 2015",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2015
    }, {
      "title" : "Economic causal-chain search using text mining technology",
      "author" : [ "Kiyoshi Izumi", "Hiroki Sakaji." ],
      "venue" : "Proceedings of the First Workshop on Financial Technology and Natural Language Processing, pages 61–65, Macao, China.",
      "citeRegEx" : "Izumi and Sakaji.,? 2019",
      "shortCiteRegEx" : "Izumi and Sakaji.",
      "year" : 2019
    }, {
      "title" : "Economic event detection in company-specific news text",
      "author" : [ "Gilles Jacobs", "Els Lefever", "Véronique Hoste." ],
      "venue" : "Proceedings of the First Workshop on Economics and Natural Language Processing, pages 1– 10, Melbourne, Australia.",
      "citeRegEx" : "Jacobs et al\\.,? 2018",
      "shortCiteRegEx" : "Jacobs et al\\.",
      "year" : 2018
    }, {
      "title" : "Genia corpus–a semantically annotated corpus for bio-textmining",
      "author" : [ "J-D Kim", "Tomoko Ohta", "Yuka Tateisi", "Jun’ichi Tsujii" ],
      "venue" : "Bioinformatics, 19:i180–",
      "citeRegEx" : "Kim et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2003
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P. Kingma", "Jimmy Ba." ],
      "venue" : "3rd International Conference on Learning Representations, ICLR 2015, San Diego, USA, May 7-9, 2015, Conference Track Proceedings.",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "Experiments in candidate phrase selection for financial named entity extraction - a demo",
      "author" : [ "Aman Kumar", "Hassan Alam", "Tina Werner", "Manan Vyas." ],
      "venue" : "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics:",
      "citeRegEx" : "Kumar et al\\.,? 2016",
      "shortCiteRegEx" : "Kumar et al\\.",
      "year" : 2016
    }, {
      "title" : "Conditional random fields: Probabilistic models for segmenting and labeling sequence data",
      "author" : [ "John D. Lafferty", "Andrew McCallum", "Fernando C.N. Pereira." ],
      "venue" : "Proceedings of the Eighteenth International Conference on Machine Learning, ICML",
      "citeRegEx" : "Lafferty et al\\.,? 2001",
      "shortCiteRegEx" : "Lafferty et al\\.",
      "year" : 2001
    }, {
      "title" : "Neural architectures for named entity recognition",
      "author" : [ "Guillaume Lample", "Miguel Ballesteros", "Sandeep Subramanian", "Kazuya Kawakami", "Chris Dyer." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Lample et al\\.,? 2016",
      "shortCiteRegEx" : "Lample et al\\.",
      "year" : 2016
    }, {
      "title" : "Good debt or bad debt: Detecting semantic orientations in economic texts",
      "author" : [ "Pekka Malo", "Ankur Sinha", "Pekka J. Korhonen", "Jyrki Wallenius", "Pyry Takala." ],
      "venue" : "J. Assoc. Inf. Sci. Technol., 65(4):782–796.",
      "citeRegEx" : "Malo et al\\.,? 2014",
      "shortCiteRegEx" : "Malo et al\\.",
      "year" : 2014
    }, {
      "title" : "Layer-wise guided training for bert: Learning incrementally refined document representations",
      "author" : [ "Nikolaos Manginas", "Ilias Chalkidis", "Prodromos Malakasiotis." ],
      "venue" : "SPNLP.",
      "citeRegEx" : "Manginas et al\\.,? 2020",
      "shortCiteRegEx" : "Manginas et al\\.",
      "year" : 2020
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "Tomás Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean." ],
      "venue" : "1st International Conference on Learning Representations, ICLR 2013, Scottsdale, USA.",
      "citeRegEx" : "Mikolov et al\\.,? 2013a",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "Tomás Mikolov", "Ilya Sutskever", "Kai Chen", "Gregory S. Corrado", "Jeffrey Dean." ],
      "venue" : "Advances in Neural Information Processing Systems 26: 27th Annual Conference on",
      "citeRegEx" : "Mikolov et al\\.,? 2013b",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "A survey of named entity recognition and classification",
      "author" : [ "David Nadeau", "S. Sekine." ],
      "venue" : "Lingvisticae Investigationes, 30:3–26.",
      "citeRegEx" : "Nadeau and Sekine.,? 2007",
      "shortCiteRegEx" : "Nadeau and Sekine.",
      "year" : 2007
    }, {
      "title" : "CoNLL2012 shared task: Modeling multilingual unrestricted coreference in OntoNotes",
      "author" : [ "Sameer Pradhan", "Alessandro Moschitti", "Nianwen Xue", "Olga Uryupina", "Yuchen Zhang." ],
      "venue" : "Joint Conference on EMNLP and CoNLL - Shared Task, pages",
      "citeRegEx" : "Pradhan et al\\.,? 2012",
      "shortCiteRegEx" : "Pradhan et al\\.",
      "year" : 2012
    }, {
      "title" : "Software Framework for Topic Modelling with Large Corpora",
      "author" : [ "Radim Řehůřek", "Petr Sojka." ],
      "venue" : "10",
      "citeRegEx" : "Řehůřek and Sojka.,? 2010",
      "shortCiteRegEx" : "Řehůřek and Sojka.",
      "year" : 2010
    }, {
      "title" : "Domain adaption of named entity recognition to support credit risk assessment",
      "author" : [ "Julio Cesar Salinas Alvarado", "Karin Verspoor", "Timothy Baldwin." ],
      "venue" : "Proceedings of the Australasian Language Technology Association Workshop 2015, pages 84–90, Par-",
      "citeRegEx" : "Alvarado et al\\.,? 2015",
      "shortCiteRegEx" : "Alvarado et al\\.",
      "year" : 2015
    }, {
      "title" : "Getting deep recommenders fit: Bloom embeddings for sparse binary input/output networks",
      "author" : [ "Joan Serrà", "Alexandros Karatzoglou." ],
      "venue" : "Proceedings of the Eleventh ACM Conference on Recommender Systems, page 279–287, New York, USA.",
      "citeRegEx" : "Serrà and Karatzoglou.,? 2017",
      "shortCiteRegEx" : "Serrà and Karatzoglou.",
      "year" : 2017
    }, {
      "title" : "Causality analysis of Twitter sentiments and stock market returns",
      "author" : [ "Narges Tabari", "Piyusha Biswas", "Bhanu Praneeth", "Armin Seyeditabari", "Mirsad Hadzikadic", "Wlodek Zadrozny." ],
      "venue" : "Proceedings of the First Workshop on Economics and Natu-",
      "citeRegEx" : "Tabari et al\\.,? 2018",
      "shortCiteRegEx" : "Tabari et al\\.",
      "year" : 2018
    }, {
      "title" : "Representing numbers in NLP: a survey and a vision",
      "author" : [ "Avijit Thawani", "Jay Pujara", "Filip Ilievski", "Pedro Szekely." ],
      "venue" : "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan-",
      "citeRegEx" : "Thawani et al\\.,? 2021",
      "shortCiteRegEx" : "Thawani et al\\.",
      "year" : 2021
    }, {
      "title" : "Introduction to the conll-2003 shared task: Language-independent named entity recognition",
      "author" : [ "Erik F. Tjong Kim Sang", "Fien De Meulder." ],
      "venue" : "Proceedings of CoNLL-2003, pages 142–147. Edmonton, Canada.",
      "citeRegEx" : "Sang and Meulder.,? 2003",
      "shortCiteRegEx" : "Sang and Meulder.",
      "year" : 2003
    }, {
      "title" : "Financial sentiment analysis for risk prediction",
      "author" : [ "Chuan-Ju Wang", "Ming-Feng Tsai", "Tse Liu", "ChinTing Chang." ],
      "venue" : "Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 802–808, Nagoya, Japan.",
      "citeRegEx" : "Wang et al\\.,? 2013",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2013
    }, {
      "title" : "Transformers: State-of-the-art natural language processing",
      "author" : [ "Teven Le Scao", "Sylvain Gugger", "Mariama Drame", "Quentin Lhoest", "Alexander M. Rush." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing:",
      "citeRegEx" : "Scao et al\\.,? 2020",
      "shortCiteRegEx" : "Scao et al\\.",
      "year" : 2020
    }, {
      "title" : "Leveraging BERT to improve the FEARS index for stock forecasting",
      "author" : [ "Linyi Yang", "Ruihai Dong", "Tin Lok James Ng", "Yang Xu." ],
      "venue" : "Proceedings of the First Workshop on Financial Technology and Natural Language Processing, pages 54–60, Macao,",
      "citeRegEx" : "Yang et al\\.,? 2019",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "Finbert: A pretrained language model for financial communications",
      "author" : [ "Yi Yang", "Mark Christopher Siy UY", "Allen Huang." ],
      "venue" : "arXiv, abs/2006.08097.",
      "citeRegEx" : "Yang et al\\.,? 2020",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2020
    }, {
      "title" : "Forecasting firm material events from 8-k reports",
      "author" : [ "Shuang (Sophie) Zhai", "Zhu (Drew) Zhang" ],
      "venue" : "In Proceedings of the Second Workshop on Economics and Natural Language Processing,",
      "citeRegEx" : "Zhai and Zhang.,? \\Q2019\\E",
      "shortCiteRegEx" : "Zhai and Zhang.",
      "year" : 2019
    }, {
      "title" : "Do language embeddings capture scales? In Findings of the Association for Computational Linguistics: EMNLP",
      "author" : [ "Xikun Zhang", "Deepak Ramachandran", "Ian Tenney", "Yanai Elazar", "Dan Roth" ],
      "venue" : null,
      "citeRegEx" : "Zhang et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 10,
      "context" : "Such information is useful in numerous financial intelligence tasks, like stock market prediction (Chen et al., 2019; Yang et al., 2019), financial sentiment analysis (Malo et al.",
      "startOffset" : 98,
      "endOffset" : 136
    }, {
      "referenceID" : 47,
      "context" : "Such information is useful in numerous financial intelligence tasks, like stock market prediction (Chen et al., 2019; Yang et al., 2019), financial sentiment analysis (Malo et al.",
      "startOffset" : 98,
      "endOffset" : 136
    }, {
      "referenceID" : 33,
      "context" : ", 2019), financial sentiment analysis (Malo et al., 2014; Wang et al., 2013; Akhtar et al., 2017), economic event detection (Ein-Dor et al.",
      "startOffset" : 38,
      "endOffset" : 97
    }, {
      "referenceID" : 45,
      "context" : ", 2019), financial sentiment analysis (Malo et al., 2014; Wang et al., 2013; Akhtar et al., 2017), economic event detection (Ein-Dor et al.",
      "startOffset" : 38,
      "endOffset" : 97
    }, {
      "referenceID" : 1,
      "context" : ", 2019), financial sentiment analysis (Malo et al., 2014; Wang et al., 2013; Akhtar et al., 2017), economic event detection (Ein-Dor et al.",
      "startOffset" : 38,
      "endOffset" : 97
    }, {
      "referenceID" : 13,
      "context" : ", 2017), economic event detection (Ein-Dor et al., 2019; Jacobs et al., 2018; Zhai and Zhang, 2019), and causality analysis (Tabari et al.",
      "startOffset" : 34,
      "endOffset" : 99
    }, {
      "referenceID" : 27,
      "context" : ", 2017), economic event detection (Ein-Dor et al., 2019; Jacobs et al., 2018; Zhai and Zhang, 2019), and causality analysis (Tabari et al.",
      "startOffset" : 34,
      "endOffset" : 99
    }, {
      "referenceID" : 49,
      "context" : ", 2017), economic event detection (Ein-Dor et al., 2019; Jacobs et al., 2018; Zhai and Zhang, 2019), and causality analysis (Tabari et al.",
      "startOffset" : 34,
      "endOffset" : 99
    }, {
      "referenceID" : 42,
      "context" : ", 2018; Zhai and Zhang, 2019), and causality analysis (Tabari et al., 2018; Izumi and Sakaji, 2019).",
      "startOffset" : 54,
      "endOffset" : 99
    }, {
      "referenceID" : 26,
      "context" : ", 2018; Zhai and Zhang, 2019), and causality analysis (Tabari et al., 2018; Izumi and Sakaji, 2019).",
      "startOffset" : 54,
      "endOffset" : 99
    }, {
      "referenceID" : 11,
      "context" : ", in models like bert (Devlin et al., 2019), there are no oov tokens, but numeric",
      "startOffset" : 22,
      "endOffset" : 43
    }, {
      "referenceID" : 19,
      "context" : "In our experiments, this is evident by the slightly better performance of stacked bilstms (Graves et al., 2013; Lample et al., 2016) operating on word embeddings compared to bert.",
      "startOffset" : 90,
      "endOffset" : 132
    }, {
      "referenceID" : 32,
      "context" : "In our experiments, this is evident by the slightly better performance of stacked bilstms (Graves et al., 2013; Lample et al., 2016) operating on word embeddings compared to bert.",
      "startOffset" : 90,
      "endOffset" : 132
    }, {
      "referenceID" : 31,
      "context" : "The latter improves when using a crf (Lafferty et al., 2001) layer, which helps avoid assigning nonsensical sequences of labels to the fragments (subwords) of numeric expressions.",
      "startOffset" : 37,
      "endOffset" : 60
    }, {
      "referenceID" : 9,
      "context" : "Entity extraction: xbrl tagging differs from ner and other previous entity extraction tasks (Table 1), like contract element extraction (Chalkidis et al., 2019).",
      "startOffset" : 136,
      "endOffset" : 160
    }, {
      "referenceID" : 9,
      "context" : "Contract element extraction (Chalkidis et al., 2019) also requires considering the context of dates, amounts etc.",
      "startOffset" : 28,
      "endOffset" : 52
    }, {
      "referenceID" : 16,
      "context" : "On the other hand, genbert (Geva et al., 2020) uses the decimal notation and digit-by-digit tok-",
      "startOffset" : 27,
      "endOffset" : 46
    }, {
      "referenceID" : 43,
      "context" : "Both models attempt to deal with the problem that word-level tokenization often turns numeric tokens to oovs (Thawani et al., 2021).",
      "startOffset" : 109,
      "endOffset" : 131
    }, {
      "referenceID" : 3,
      "context" : "xbrl taxonomies have many different attributes, making xbrl tagging challenging even for humans (Baldwin et al., 2006; Hoitash and Hoitash, 2018).",
      "startOffset" : 96,
      "endOffset" : 145
    }, {
      "referenceID" : 23,
      "context" : "xbrl taxonomies have many different attributes, making xbrl tagging challenging even for humans (Baldwin et al., 2006; Hoitash and Hoitash, 2018).",
      "startOffset" : 96,
      "endOffset" : 145
    }, {
      "referenceID" : 41,
      "context" : "8 It includes an industrial ner that uses word-level Bloom embeddings (Serrà and Karatzoglou, 2017) and residual Convolutional Neural Networks (cnns) (He et al.",
      "startOffset" : 70,
      "endOffset" : 99
    }, {
      "referenceID" : 22,
      "context" : "8 It includes an industrial ner that uses word-level Bloom embeddings (Serrà and Karatzoglou, 2017) and residual Convolutional Neural Networks (cnns) (He et al., 2016).",
      "startOffset" : 150,
      "endOffset" : 167
    }, {
      "referenceID" : 19,
      "context" : "bilstm: This baseline uses a stacked bidirectional Long-Short Term Memory (lstm) network (Graves et al., 2013; Lample et al., 2016) with residual connections.",
      "startOffset" : 89,
      "endOffset" : 131
    }, {
      "referenceID" : 32,
      "context" : "bilstm: This baseline uses a stacked bidirectional Long-Short Term Memory (lstm) network (Graves et al., 2013; Lample et al., 2016) with residual connections.",
      "startOffset" : 89,
      "endOffset" : 131
    }, {
      "referenceID" : 11,
      "context" : "bert: This is similar to bilstm, but now we finetune bert-base (Devlin et al., 2019) to extract contextualized embeddings of subwords.",
      "startOffset" : 63,
      "endOffset" : 84
    }, {
      "referenceID" : 6,
      "context" : "7We use nltk (Bird et al., 2009) for sentence splitting.",
      "startOffset" : 13,
      "endOffset" : 32
    }, {
      "referenceID" : 39,
      "context" : "9We used gensim’s (Řehůřek and Sojka, 2010) skip-gram implementation, with default settings.",
      "startOffset" : 18,
      "endOffset" : 43
    }, {
      "referenceID" : 31,
      "context" : "crfs: In this case, we replace the lr layer of the previous two models with a Conditional Random Field (crf) layer (Lafferty et al., 2001), which has been shown to be beneficial in several sequence labeling tasks (Huang et al.",
      "startOffset" : 115,
      "endOffset" : 138
    }, {
      "referenceID" : 25,
      "context" : ", 2001), which has been shown to be beneficial in several sequence labeling tasks (Huang et al., 2015; Lample et al., 2016; Chalkidis et al., 2020b).",
      "startOffset" : 82,
      "endOffset" : 148
    }, {
      "referenceID" : 32,
      "context" : ", 2001), which has been shown to be beneficial in several sequence labeling tasks (Huang et al., 2015; Lample et al., 2016; Chalkidis et al., 2020b).",
      "startOffset" : 82,
      "endOffset" : 148
    }, {
      "referenceID" : 8,
      "context" : ", 2001), which has been shown to be beneficial in several sequence labeling tasks (Huang et al., 2015; Lample et al., 2016; Chalkidis et al., 2020b).",
      "startOffset" : 82,
      "endOffset" : 148
    }, {
      "referenceID" : 18,
      "context" : "A drawback of crfs is that they significantly slow down the models both during training and inference, especially when using large label sets (Goldman and Goldberger, 2020), as in our case.",
      "startOffset" : 142,
      "endOffset" : 172
    }, {
      "referenceID" : 7,
      "context" : "For example, the specialized terminology and financial date errors may be alleviated by adopting hierarchical classifiers (Chalkidis et al., 2020a; Manginas et al., 2020), which would first detect entities in coarse classes (e.",
      "startOffset" : 122,
      "endOffset" : 170
    }, {
      "referenceID" : 34,
      "context" : "For example, the specialized terminology and financial date errors may be alleviated by adopting hierarchical classifiers (Chalkidis et al., 2020a; Manginas et al., 2020), which would first detect entities in coarse classes (e.",
      "startOffset" : 122,
      "endOffset" : 170
    } ],
    "year" : 0,
    "abstractText" : "Publicly traded companies are required to submit periodic reports with eXtensive Business Reporting Language (xbrl) word-level tags. Manually tagging the reports is tedious and costly. We, therefore, introduce xbrl tagging as a new sequence labeling task for the financial domain and release finer-139, a dataset of 1.1M sentences with gold xbrl tags. Unlike typical entity extraction datasets, finer139 uses a much larger label set of 139 entity types. Most annotated tokens are numeric, with the correct tag per token depending mostly on context, rather than the token itself. We show that subword fragmentation of numeric expressions harms bert’s performance, allowing word-level bilstms to perform better. To improve bert’s performance, we propose two simple and effective solutions that replace numeric expressions with pseudotokens reflecting original token shapes and numeric magnitudes. We also experiment with fin-bert, an existing bert model for the financial domain, and release our own bert (sec-bert), pre-trained on financial filings, which performs best. Through data and error analysis, we finally identify possible limitations to inspire future work on xbrl tagging.",
    "creator" : null
  }
}