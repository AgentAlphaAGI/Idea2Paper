{
  "name" : "ARR_2022_222_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Learning Discriminative Representations for Open Relation Extraction with Instance Ranking and Label Calibration",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Open relation extraction (OpenRE) has been proposed to extract new relational facts where the types of target relations are not pre-defined. Previous methods can be classified into two types: open information extraction (OpenIE) and unsupervised relation discovery. For OpenIE (Yates et al., 2007; Etzioni et al., 2008; Fader et al., 2011), the relations are directly represented by relation phrases extracted in the sentence. However, the generalization capabilities of these methods are limited since they severely rely on surface-form relations and a relation can be expressed by many surface forms.\n1We will release our code after blind review.\nRecently, much attention has been focused on unsupervised relation discovery, which is commonly formulated as a clustering task to learn effective relation representations and cluster them (Yao et al., 2011; Marcheggiani and Titov, 2016; Simon et al., 2019). Hu et al. (2020) leverage BERT to extract relational feature and propose a self-supervised framework to learn relation representations from pseudo labels. Because current methods are unstable and easily collapsed (Simon et al., 2019), Liu et al. (2021) solve above-mentioned problems from a causal view and propose element intervention to alleviate the spurious correlations in OpenRE models. However, there are still some hard or semi-hard samples wrongly predicted in the representation space due to the spurious correlations from entities and context to the relation type.\nAs shown in Figure 1(a), there are two types of negative instances for the relation type BORN_IN_PLACE: Hard negative and Semihard negative. For Semi-hard negative instances like S4, OpenRE models will assign S1 and S4 into the same relation type BORN_IN_PLACE since S1 and S4 share similar context information. This problem can be even more severe if the representation space exists some hard negative instances like\nS3, because S3 possesses a similar context \"was born in \"and similar entity \"Jon\" to S1. An intuitive way to solve this problem is to refine the relational feature space, as shown in Figure 1(b). Besides, all instances should follow the same relative relationship in the label semantic space which means the original and positive instance have a more similar cluster probability distribution than the hard and semi-hard negative instances. Therefore, it is important to model the constraint relationship between these instances in the label semantic space.\nIn this paper, we propose a novel method based on Instance Ranking and Label Calibration strategies (IRLC) to better identify the hard and semihard negative instances by learning discriminative representations in relational feature and label semantic space simultaneously. However, due to lacking of the instance label, we cannot directly obtain the positive, hard negative and semi-hard negative instances of the original instance. To solve this, we use three data augmentation strategies to generate the positive, hard negative and semi-hard negative instances for the original instance. To refine the relational feature space, we introduce instance ranking to make the original instance close to its positive instance and away from its hard and semi-hard negative instances. To correct the cluster assignment probabilities of hard and semi-hard instances, and keep the probability distributions of the original and positive instance aligned, in the label semantic space, Label Calibration strategy is designed to model two constraint relationships between the original and hard negative instance, and between the hard and semi-hard negative instance.\nTo summarize, the major contributions of our work are as follows: (1) We propose a novel method based on instance ranking and label calibration to learn discriminative representations in relational feature and label semantic space simultaneously. (2) We introduce three surrogate strategies to generate the positive, hard negative and semi-hard negative instances under unsupervised manner. (3) Experimental results show that our proposed method significantly outperforms the previous state-of-the-art models with the improvements of average performance of 11.1% and 11.8%, on two datasets respectively."
    }, {
      "heading" : "2 Method",
      "text" : "In this work, we propose a novel method to learn relation representations in feature and semantic space simultaneously. As shown in Figure 2, our method\nmainly consists of three components: data augmentation, instance ranking, and label calibration modules. We will introduce these module details in the following subsections."
    }, {
      "heading" : "2.1 Data Augmentation",
      "text" : "Since there is no pre-defined relation types, it is difficult to directly obtain the positive, hard negative, and semi-hard negative instances of the original instance. To solve this problem, we introduce three surrogate data augmentation strategies to generate above-mentioned instances for the original instance. Specifically, for an original relation instance Xi, we use the following strategies: Back Translation for Positive: To keep the relation type consistent with the original instance and introduce minimal semantic impact, we use back translation to generate the high-quality positive instance by first translating the original instance to another language and then back to English. Entity Replacing for Hard Negative: We choose T5 (Raffel et al., 2019) to generate the most similar word to head or tail entity, and then replace the head or tail entity with its augmented word to obtain the hard negative instance, which possesses the similar entity and context to original instance. Entity Swap For Semi-Hard Negative: To construct a semi-hard negative instance for the original instance, we follow the setting of Entity Swap (Cao and Wang, 2021), which swaps the target entities with other randomly selected entities of the same entity type in the original instance."
    }, {
      "heading" : "2.2 Instance Ranking",
      "text" : "After instance construction, we obtain a group of augmented instances of the original instance. Instance Ranking aims to refine the relational feature space. Specifically, given a group of instances (Xi, Xpi , X hn i , X sn i ), where X p i , X hn i , X sn i are positive, hard, and semi-hard instance respectively. We first encode them to obtain their relation representations (ri, r p i , r hn i , r sn i ), and then map these representations into the relational feature space with an instance-level head h to obtain a group of relational feature (ti, t p i , t hn i , t sn i ). Then we can obtain the instance-level ranking loss:\nLIR(θ; ri) = max(0, D(ti, tpi )−D(ti, t hn i ) +mH)\n+ max(0, D(ti, t hn i )−D(ti, tsni )\n+mS) (1)\nwhere D(x, y) is the euclidean distance between x and y, mH and mS are two margins for instancelevel ranking loss, and θ is the model parameters. Optimized by the objective LIRi , model can make the original relation instance closer to its positive instance and away from its correspondingly hard and semi-hard negative instances with different margins."
    }, {
      "heading" : "2.3 Label Calibration",
      "text" : "In addition to refining the feature space, we introduce Label Calibration to model the constraint relationship between instances to correct the cluster assignment probabilities of hard and semi-hard instances and keep the probability distributions of the original and positive instance aligned in the label semantic space. With a group of relation representations (ri, r p i , r hn i , r sn i ) encoded from their corresponding instances, we first generate the group of cluster representations (zi, z p i , z hn i , z sn i ) by mapping them into the label semantic space with a cluster-level head g, and then obtain the clusterlevel ranking loss:\nLLCi (θ; zi) = max(0, D(zi, z p i )−D(zi, z hn i ))\n+ max(0, D(zi, z hn i )−D(zi, zsni )\n+mL) (2)\nwhere D(x, y) is the KL distance between x and y to measure the difference between the cluster assignment probabilities of the instances, mL is the margin for cluster-level ranking loss, and θ is the model parameters. The first term is to model\nthe constraint relationship between the original and hard negative instance, and the second term is to the constraint relationship between the hard and semihard negative instance. The final loss function is L = − 1n ∑n i=1(LIRi + LLCi )."
    }, {
      "heading" : "3 Experiments",
      "text" : ""
    }, {
      "heading" : "3.1 Setup",
      "text" : "Datasets. To assess the performance of our method, we conduct experiments on T-REx SPO and TREx DS, which both come from T-REx (Elsahar et al., 2018) but differ in whether having surfaceform relations or not. Following the setup of Liu et al. (2021), we use 80% of instances for model training and 20% for validation on both two datasets."
    }, {
      "heading" : "3.2 Main Results",
      "text" : "We summarize the performances of the baselines and our method in Table 1. From the experimental results, we can see that our method IRLC significantly outperforms baselines by a large margin and achieves new state-of-the-art results on both two datasets. For T-REx SPO, compared with the previous SOTA model, IRLC improves the average performance by 11.1%, B3 F1-score by 12.4%, Vmeasure F1-score by 15.1%, and ARI by 5.7%. The results confirm IRLC can learn discriminative representations to help model extract novel relations. For T-REx DS, our method IRLC outperforms the SOTA model with an average performance gain of 11.8%, proving the effectiveness of IRLC for OpenRE."
    }, {
      "heading" : "3.3 Ablation Study",
      "text" : "To study the effect of instance ranking and label calibration in the proposed method, we conduct ablation experiments on two datasets and report the results in Table 1. We find that the performance of IRLC will severely degrade without instance ranking or label calibration. It proves both two strategies proposed in our method are important and effective, and combining these two strategies can achieve a noticeable performance gain. More specifically, we can observe that instance ranking or label calibration is effective enough to outperform previous SOTA models with an average performance gain of at least 3.7% in T-REx SPO dataset, showing the effectiveness of these two strategies."
    }, {
      "heading" : "3.4 Qualitative Analysis",
      "text" : "In this section, we analyse the representation distribution of novel relations on two datasets from two perspectives, intra-class and inter-class, to study how our method refines the representation space. IRLC leads to smaller intra-class distance. Table 2 shows the intra-class variance statistics. Specifically, we use intra-class variance to indicate the intra-class distance of relation type. Each cluster intra-class variance is obtained by calculating the average variances of all normalized relation representations corresponding to the same relation type, and we report the min/max/mean/median variance values on all relation types. From the results, we can see that the intra-class variance are much\nsmaller than compared method in four aspects. It confirms IRLC can make the relation representations from same relation type closer. IRLC leads to larger inter-class distance. Figure 3 shows the inter-class distance statistics. The X-axis is the number of the nearest class centers. We obtain the euclidean distances between each class center and its nearest class centers with different number, and then average these distances of all relation types as the inter-class distance. From the results, we can observe that IRLC significant increases the inter-class distance with different number of the nearest class centers, especially in T-REx SPO. In summary, IRLC can obtain a better relation representation space with smaller intra-class distance and larger inter-class distance for OpenRE. We also provide a visualization in the Appendix."
    }, {
      "heading" : "4 Conclusion",
      "text" : "In this paper, we propose a novel method based on instance ranking and label calibration (IRLC) to learn discriminative representations for better identifying the hard and semi-hard negative intances, in the relational feature and label semantic space simultaneously. Due to lacking the label of each instance, we introduce three surrogate strategies to generate the augmented views for the original instance. And then instance ranking is used to refine the relational feature space, and label calibration is designed to model the constraint relationship between instances. Experiments and analysis confirm the effectiveness of IRLC for OpenRE."
    }, {
      "heading" : "B Baselines Details",
      "text" : "For comparison, we consider the following baselines:\n• rel-LDA A generative method proposed by Yao et al. (2011), which treats unsupervised relation discovery as a topic model. In our experiment, we choose the full rel-LDA to compare.\n• March A method (Marcheggiani and Titov, 2016) based on self-supervised signal from entity link predictor to learn a VAE-based model.\n• UIE A method proposed by Simon et al. (2019) to solve instability and use two regularization to train a discriminative model for OpenRE. In our experiments, we compare our method with two versions of UIE, which only differ in the relation encoding model, i.e., PCNN and BERT.\n• SelfORE A self-supervised framework propose by Hu et al. (2020), which learn contextual relation representations from pseudo labels.\n• Element Intervention A method proposed by Liu et al. (2021), which formulates OpenRE by using a structural causal model."
    }, {
      "heading" : "C Evaluation Metrics.",
      "text" : "As the previous work (Simon et al., 2019; Hu et al., 2020; Liu et al., 2021), we adopt B3 (Bagga\nand Baldwin, 1998), V-measure (Rosenberg and Hirschberg, 2007), and Adjusted Rand Index (ARI) (Hubert and Arabie, 1985) to evaluate different methods. Considering that any of the three metrics can measure the clustering performance from different angles, we take the average for comprehensive evaluation.\nD Visualization of Relation Representations\nTo intuitively show how our method helps to refine the relation representation space, we visual the representations of novel relations by using tSNE (Van der Maaten and Hinton, 2008) to reduce the dimension to 2. We randomly choose 5 relations and sample 200 instances in each relation. As shown in Figure 4(a), the relation representation space of compared model is chaotic and somewhat dense. However, the relation representations from different types are mostly separated in our proposed method, as shown in Figure 4(b)."
    } ],
    "references" : [ {
      "title" : "Entity-based cross-document coreferencing using the vector space model",
      "author" : [ "Amit Bagga", "Breck Baldwin." ],
      "venue" : "36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1,",
      "citeRegEx" : "Bagga and Baldwin.,? 1998",
      "shortCiteRegEx" : "Bagga and Baldwin.",
      "year" : 1998
    }, {
      "title" : "Cliff: Contrastive learning for improving faithfulness and factuality in abstractive summarization",
      "author" : [ "Shuyang Cao", "Lu Wang." ],
      "venue" : "arXiv preprint arXiv:2109.09209.",
      "citeRegEx" : "Cao and Wang.,? 2021",
      "shortCiteRegEx" : "Cao and Wang.",
      "year" : 2021
    }, {
      "title" : "T-REx: A large scale alignment of natural language with knowledge base triples",
      "author" : [ "Hady Elsahar", "Pavlos Vougiouklis", "Arslen Remaci", "Christophe Gravier", "Jonathon Hare", "Frederique Laforest", "Elena Simperl." ],
      "venue" : "Proceedings of the Eleventh International",
      "citeRegEx" : "Elsahar et al\\.,? 2018",
      "shortCiteRegEx" : "Elsahar et al\\.",
      "year" : 2018
    }, {
      "title" : "Open information extraction from the web",
      "author" : [ "Oren Etzioni", "Michele Banko", "Stephen Soderland", "Daniel S Weld." ],
      "venue" : "Communications of the ACM, 51(12):68–74.",
      "citeRegEx" : "Etzioni et al\\.,? 2008",
      "shortCiteRegEx" : "Etzioni et al\\.",
      "year" : 2008
    }, {
      "title" : "Identifying relations for open information extraction",
      "author" : [ "Anthony Fader", "Stephen Soderland", "Oren Etzioni." ],
      "venue" : "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1535–1545, Edinburgh, Scotland, UK. Associ-",
      "citeRegEx" : "Fader et al\\.,? 2011",
      "shortCiteRegEx" : "Fader et al\\.",
      "year" : 2011
    }, {
      "title" : "SelfORE: Self-supervised relational feature learning for open relation extraction",
      "author" : [ "Xuming Hu", "Lijie Wen", "Yusong Xu", "Chenwei Zhang", "Philip Yu." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Hu et al\\.,? 2020",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2020
    }, {
      "title" : "Comparing partitions",
      "author" : [ "Lawrence Hubert", "Phipps Arabie." ],
      "venue" : "Journal of classification, 2(1):193–218.",
      "citeRegEx" : "Hubert and Arabie.,? 1985",
      "shortCiteRegEx" : "Hubert and Arabie.",
      "year" : 1985
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P Kingma", "Jimmy Ba." ],
      "venue" : "arXiv preprint arXiv:1412.6980.",
      "citeRegEx" : "Kingma and Ba.,? 2014",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2014
    }, {
      "title" : "Element intervention for open relation extraction",
      "author" : [ "Fangchao Liu", "Lingyong Yan", "Hongyu Lin", "Xianpei Han", "Le Sun." ],
      "venue" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Confer-",
      "citeRegEx" : "Liu et al\\.,? 2021",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2021
    }, {
      "title" : "Discretestate variational autoencoders for joint discovery and factorization of relations",
      "author" : [ "Diego Marcheggiani", "Ivan Titov." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 4:231–244.",
      "citeRegEx" : "Marcheggiani and Titov.,? 2016",
      "shortCiteRegEx" : "Marcheggiani and Titov.",
      "year" : 2016
    }, {
      "title" : "Automatic differentiation in pytorch",
      "author" : [ "Adam Paszke", "Sam Gross", "Soumith Chintala", "Gregory Chanan", "Edward Yang", "Zachary DeVito", "Zeming Lin", "Alban Desmaison", "Luca Antiga", "Adam Lerer." ],
      "venue" : "NIPSW.",
      "citeRegEx" : "Paszke et al\\.,? 2017",
      "shortCiteRegEx" : "Paszke et al\\.",
      "year" : 2017
    }, {
      "title" : "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "author" : [ "Colin Raffel", "Noam Shazeer", "Adam Roberts", "Katherine Lee", "Sharan Narang", "Michael Matena", "Yanqi Zhou", "Wei Li", "Peter J Liu." ],
      "venue" : "arXiv preprint arXiv:1910.10683.",
      "citeRegEx" : "Raffel et al\\.,? 2019",
      "shortCiteRegEx" : "Raffel et al\\.",
      "year" : 2019
    }, {
      "title" : "Vmeasure: A conditional entropy-based external cluster evaluation measure",
      "author" : [ "Andrew Rosenberg", "Julia Hirschberg." ],
      "venue" : "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural",
      "citeRegEx" : "Rosenberg and Hirschberg.,? 2007",
      "shortCiteRegEx" : "Rosenberg and Hirschberg.",
      "year" : 2007
    }, {
      "title" : "Unsupervised information extraction: Regularizing discriminative approaches with relation distribution losses",
      "author" : [ "Étienne Simon", "Vincent Guigue", "Benjamin Piwowarski." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computa-",
      "citeRegEx" : "Simon et al\\.,? 2019",
      "shortCiteRegEx" : "Simon et al\\.",
      "year" : 2019
    }, {
      "title" : "Visualizing data using t-sne",
      "author" : [ "Laurens Van der Maaten", "Geoffrey Hinton." ],
      "venue" : "Journal of machine learning research, 9(11).",
      "citeRegEx" : "Maaten and Hinton.,? 2008",
      "shortCiteRegEx" : "Maaten and Hinton.",
      "year" : 2008
    }, {
      "title" : "Transformers: State-of-the-art natural language processing",
      "author" : [ "Teven Le Scao", "Sylvain Gugger", "Mariama Drame", "Quentin Lhoest", "Alexander Rush." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System",
      "citeRegEx" : "Scao et al\\.,? 2020",
      "shortCiteRegEx" : "Scao et al\\.",
      "year" : 2020
    }, {
      "title" : "Structured relation discovery using generative models",
      "author" : [ "Limin Yao", "Aria Haghighi", "Sebastian Riedel", "Andrew McCallum." ],
      "venue" : "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1456–1466, Edinburgh,",
      "citeRegEx" : "Yao et al\\.,? 2011",
      "shortCiteRegEx" : "Yao et al\\.",
      "year" : 2011
    }, {
      "title" : "TextRunner: Open information extraction on the web",
      "author" : [ "Alexander Yates", "Michele Banko", "Matthew Broadhead", "Michael Cafarella", "Oren Etzioni", "Stephen Soderland." ],
      "venue" : "Proceedings of Human Language Technologies: The Annual Conference of the",
      "citeRegEx" : "Yates et al\\.,? 2007",
      "shortCiteRegEx" : "Yates et al\\.",
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "For OpenIE (Yates et al., 2007; Etzioni et al., 2008; Fader et al., 2011), the relations are directly represented by relation phrases extracted in the sentence.",
      "startOffset" : 11,
      "endOffset" : 73
    }, {
      "referenceID" : 3,
      "context" : "For OpenIE (Yates et al., 2007; Etzioni et al., 2008; Fader et al., 2011), the relations are directly represented by relation phrases extracted in the sentence.",
      "startOffset" : 11,
      "endOffset" : 73
    }, {
      "referenceID" : 4,
      "context" : "For OpenIE (Yates et al., 2007; Etzioni et al., 2008; Fader et al., 2011), the relations are directly represented by relation phrases extracted in the sentence.",
      "startOffset" : 11,
      "endOffset" : 73
    }, {
      "referenceID" : 16,
      "context" : "Recently, much attention has been focused on unsupervised relation discovery, which is commonly formulated as a clustering task to learn effective relation representations and cluster them (Yao et al., 2011; Marcheggiani and Titov, 2016; Simon et al., 2019).",
      "startOffset" : 189,
      "endOffset" : 257
    }, {
      "referenceID" : 9,
      "context" : "Recently, much attention has been focused on unsupervised relation discovery, which is commonly formulated as a clustering task to learn effective relation representations and cluster them (Yao et al., 2011; Marcheggiani and Titov, 2016; Simon et al., 2019).",
      "startOffset" : 189,
      "endOffset" : 257
    }, {
      "referenceID" : 13,
      "context" : "Recently, much attention has been focused on unsupervised relation discovery, which is commonly formulated as a clustering task to learn effective relation representations and cluster them (Yao et al., 2011; Marcheggiani and Titov, 2016; Simon et al., 2019).",
      "startOffset" : 189,
      "endOffset" : 257
    }, {
      "referenceID" : 13,
      "context" : "Because current methods are unstable and easily collapsed (Simon et al., 2019), Liu et al.",
      "startOffset" : 58,
      "endOffset" : 78
    }, {
      "referenceID" : 11,
      "context" : "Entity Replacing for Hard Negative: We choose T5 (Raffel et al., 2019) to generate the most similar word to head or tail entity, and then replace the head or tail entity with its augmented word to obtain the hard negative instance, which possesses the similar entity and context to original instance.",
      "startOffset" : 49,
      "endOffset" : 70
    }, {
      "referenceID" : 1,
      "context" : "Entity Swap For Semi-Hard Negative: To construct a semi-hard negative instance for the original instance, we follow the setting of Entity Swap (Cao and Wang, 2021), which swaps the target entities with other randomly selected entities of the same entity type in the original instance.",
      "startOffset" : 143,
      "endOffset" : 163
    }, {
      "referenceID" : 2,
      "context" : "To assess the performance of our method, we conduct experiments on T-REx SPO and TREx DS, which both come from T-REx (Elsahar et al., 2018) but differ in whether having surfaceform relations or not.",
      "startOffset" : 117,
      "endOffset" : 139
    } ],
    "year" : 0,
    "abstractText" : "Open relation extraction is the task to extract relational facts without pre-defined relation types from open-domain corpora. However, since there are some hard or semi-hard instances sharing similar context and entity information but belonging to different underlying relation, current OpenRE methods always cluster them into the same relation type. In this paper, we propose a novel method based on Instance Ranking and Label Calibration strategies (IRLC) to learn discriminative representations for open relation extraction. Due to lacking the original instance label, we provide three surrogate strategies to generate the positive, hard negative, and semi-hard negative instances for the original instance. Instance ranking aims to refine the relational feature space by pushing the hard and semi-hard negative instances apart from the original instance with different margins and pulling the original instance and its positive instance together. To refine the cluster probability distributions of these instances, we introduce a label calibration strategy to model the constraint relationship between instances. Experimental results on two public datasets demonstrate that our proposed method can significantly outperform the previous state-of-the-art methods1.",
    "creator" : null
  }
}