{
  "name" : "ARR_2022_335_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Learning to Express in Knowledge-Grounded Conversation",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Building an open domain dialogue system has attracted increasing attention from the community of AI and NLP. Despite the impressive progress, existing models are notorious for replying with generic and bland responses. To bridge the gap, researchers resort to ground dialogue generation by extra knowledge such as unstructured documents (Zhou et al., 2018c; Dinan et al., 2019). By this means, the documents serve as content sources and make a dialogue system knowledgeable regarding various concepts in a discussion.\nHowever, existing studies focus on how to synthesize a response with proper knowledge (Dinan et al., 2019; Kim et al., 2020; Zhao et al., 2020b), but pay little attention to the fact that the same knowledge could be expressed differently even under the same context. These models usually employ a regular decoder to generate the response\ninto knowledge-related and knowledge-irrelevant segments.\nin an auto-regressive manner given the contextual representations of knowledge and dialogue context, which makes the generation process less explainable and controllable.\nIn general, the expression style of response is composed of two aspects: the structure of the response and the style of the content in each part. As the example shown in Table 1, knowledge-related phrases and clauses tend to be long, like “And I’d give credit to three different voice actors for anna.”, or short, like “74 in Metacritics”. Besides, they may appear at the beginning of the sentence, or at the end. For the sake of description, we decompose a response into a sequence of non-overlapping segments, each is either related to certain background knowledge and diverse in content style, or almost irrelevant to the knowledge but simply playing the role of stitching the context and carrying on the conversation. We therefore define the structure style as the distribution and number of two kinds of segments. The structure style itself is far from dominant in the sentence expression, since different speakers could convey converse attitude even if the context and the knowledge are exactly the same. So\nit is necessary to introduce the content style as the expression fashion within each knowledge-related segment. We further introduce two latent variables to facilitate end-to-end training, one for predicting the start and end positions of a segment, the other for deciding the category of each segment. Since the human annotations for sentence segmentation are absent and enumerating over all possibilities to maximize the likelihood of the response is timeconsuming, we propose a variational framework for segmentation-based generation and induce an evidence lower bound of the likelihood.\nFormally, our model follows an encoder-decoder architecture. The encoder is to obtain the contextual representation of conversational context and knowledge in a regular way. The decoder consists of three types of modules: (1) context module, for response only based on context without knowledge; (2) plain-knowledge module, for response referring knowledges but without particular style; and (3) stylized-knowledge module, for response referring knowledges and with a specific style. The context module is the only module not relying on knowledge, but simply paying attention to contextual information. Compared with plain-knowledge module, stylized-knowledge module has unique adapters, which is their primary discrepancy. When decoding, the decoder first predicts the segmentation of the response and then makes a choice in three kinds of modules to generate a single segment. Both the segmentation and the module selection are instructed under sequential latent variables.\nWe train our model on the Reddit Corpus published by (Li et al., 2020) and evaluate our model on two benchmarks of knowledge-grounded conversation: Wizard of Wikipedia(Wizard) (Dinan et al., 2019) and CMU Document Grounded Conversation(CMU_DoG) (Zhou et al., 2018c). Evaluation results indicate that our model can significantly outperform state-of-the-art methods in the zero-resource setting (i.e., only trained on the Reddit Corpus). In addition, the performance of our model improves significantly on Wizard and CMU_DoG with the presence of only 10% training data and the segment distributions after fine-tuning are consistent with our prior knowledge about the two datasets, indicating that our model can learn the structure style with little cost. Finally, our model outperforms previous state-of-the-art models on the accuracy of performing sentiment classification using generated responses. It is worth noting\nthat our model achieves 10%+ accuracy improvement on Wizard Seen, 12%+ accuracy improvement on Wizard Unseen, and 12%+ accuracy improvement on CMU_DoG than the present stateof-the-art models, which indicates that the model can be controlled to express knowledge with the desired content style.\nContributions in this work are three-fold: (1) exploration of the knowledge expression in knowledge-grounded conversation; (2) proposal of a variational segmentation-based generation model to discover the underlying expression style in a response; (3) empirical verification of the effectiveness of the proposed model on two benchmarks of knowledge-grounded conversation."
    }, {
      "heading" : "2 Related Work",
      "text" : "On the vanilla encoder-decoder architecture (Shang et al., 2015; Vinyals and Le, 2015), various extensions have been made to model the structure of dialogue contexts (Serban et al., 2016, 2017; Zhang et al., 2019a); to improve diversity of responses (Li et al., 2015; Xing et al., 2017; Zhao et al., 2017; Tao et al., 2018); to control attributes of responses (Xu et al., 2019; Zhou et al., 2017; Wang et al., 2018; See et al., 2019); and to bias responses to some specific personas (Li et al., 2016; Zhang et al., 2018). Recently, grounding dialogue generation by extra knowledge has seemed promising to bridge the gap between conversation with existing systems and conversation with humans, and the knowledge could be obtained from knowledge graphs (Zhou et al., 2018b; Moon et al., 2019; Tuan et al., 2019), retrieved from unstructured documents (Dinan et al., 2019; Lian et al., 2019; Zhao et al., 2020a; Kim et al., 2020; Li et al., 2020) or visual background (Mostafazadeh et al., 2017; Shuster et al., 2018; Huber et al., 2018). In this work, we study document-grounded dialogue generation. Rather than selecting knowledge relevant to dialogue context and directly exploiting pre-trained language models to generate the response, we focus on expressing knowledge in this task.\nThe idea of sequence modeling via segmentation (Wang et al., 2017) has attracted widespread attention in several natural language processing tasks. In text segmentation task, Wang et al. (2017) propose a probabilistic model for sequence modeling via their segmentation and a “Sleep-WAke Network”(SWAN) method. In machine translation, Huang et al. (2017) propose a neural phrase-based\nmachine translation system that models phrase structures in the target language using SWAN. In data-to-text generation, Wiseman et al. (2018) develop a neural template-like generation model with an HSMM decoder, which is learned tractably by backpropagating through a dynamic program; to tackle the problem of weak Markov assumption for the segment transition probability, Shen et al. (2020) propose to explicitly segment target text into fragments and align them with their data correspondences, and jointly learn the segmentation and correspondence via dynamic programming."
    }, {
      "heading" : "3 Approach",
      "text" : "We start by providing the problem formalization and overview of the proposed model in Sec.3.1. Then in Sec.3.2 we describe the design for each components. Lastly, we elaborate how to optimize the components with variational inference and weak supervision in Sec.3.3."
    }, {
      "heading" : "3.1 Overview",
      "text" : "Suppose that we have a dataset D = {(Ui,Ki, Ri)}Ni=1, where ∀i ∈ {1, . . . , N}, Ki serves as background knowledge of the dialogue (Ui, Ri) with Ki,j being the j-th sentence, Ui is the context of the dialogue with Ui,j the j-th utterance, and Ri is the response. To bias the expression to a specific structure style, we further assume that there are a few examples Dsty = {(Ui,Ki, Ri)}Mi=1 provided by users depicting the required style for knowledge expression. Note that we have N ≫M , since corpus in a specific expression style is rare and difficult to acquire. The goal is to learn a generation model pθ(R|U,K) (θ denotes the parameters of the model) from D, to generate a responseR following pθ(R|U,K) given a new dialogue context U and the associated knowledge K. Different from previous KGC generation model, we allow users to either (1) bias the structure style of Pθ(R|U,K) to Dsty with little cost; or (2) switch the content style of knowledge expression in R.\nFigure 1 gives an overview of the proposed model, which is based on the encoder-decoder architecture. The encoder generates the contextual representations of the dialogue and knowledge, while the decoder generates the segments one after another. hNt encodes the dialogue context up to timestep t − 1 with N denoting the number of decoder layers. Given R = (r1, · · · , rt, · · · , rlr)\nwith rt referring the t-th token of R whose length is supposed to be lr, the variable Z = {zt}lrt=1 is utilized to control the choice of module of each segment (Module Indicator), and its historical information is encoded by {ct}lrt=0. M = {mt} lr t=1 is a sequence of binary variables and used to determine the boundary of each segment (Boundary Indicator). Specifically, mt = 1 indicating that the current segment is already completed and a new segment should be created at the next timestep. Otherwise, mt = 0 and the current segment remains unfinished. The generative process is disassembled into two steps: (1) determine the type of a new segment based on previously generated text and previous segment types; (2) generate within the current segment until the binary variable mt = 1."
    }, {
      "heading" : "3.2 Model Architecture",
      "text" : "Context and Knowledge Encoding. We exploit the pre-trained BART (Lewis et al., 2020) as the backbone of our architecture, which is pretrained using a variety of denoising objectives and achieves state-of-the-art results on a range of text generation tasks. Given the dialogue context U = (U1, · · · , Un), we simply concatenate them as (u1, · · · , ulu). Similarly, we concatenate the associated knowledge K = (K1, · · · ,Km) as (k1, · · · , klk). lu and lk are the length of dialogue context and background knowledge respectively. The input of the encoder is then defined as:\nI = [BOS]k1 . . . klk [EOS]u1 . . . ulu [EOS]. (1)\nThe input I is truncated or padded to the maximum capacity and then passes through the stacked self-attention layers and results in a knowledgeaware context representation C, and a contextaware knowledge representation K. Specifically, the context-aware knowledge representation is defined as K = [henc1 , · · · ,henclk+1] where h enc t is the last layer of BART encoder at time t. Similarly, the knowledge-aware context representation is defined as C = [henclk+2, · · · ,h enc lk+lu+2 ].\nPrior of Module Indicator. We use the sequential discrete latent variable Z = {zt}lrt=1 to decide which module to invoke at each timestep. The transition of zt occurs only when a segment is completed, which is decided by the binary boundary variable M . The prior quantifies the distribution of zt before we observe the segment, and it is reasonable to assume that the prior of zt depends on\nprevious module choices z<t and previously generated text. Then the transition of Z is defined as:\npθz(zt|r<t, z<t,mt−1) = mt−1 · p̃(zt|ct) +(1−mt−1) · δ(zt = zt−1), (2)\nwhere δ is a Kronecker delta function. ct encodes all previous latent states z<t and generated text r<t as follows:\nct = mt−1 ·fz−rnn(z̃t−1, ct−1)+(1−mt−1)·ct−1. (3) z̃t−1 = [et−1;h N,dec t−1 ] with et−1 the embedding of zt−1 and h N,dec t−1 the representation of last generated token. Specifically, mt−1 = 0 means that the next timestep t is still in the same segment as the previous timestep t − 1 and thus the latent variable zt should not be updated. Otherwise, it means that current segment is completed and zt is updated with the transition function p̃(zt|ct). Because we only have Nsty + 2 options when choosing a module, where Nsty is the number of different user-defined styles in addition to 2 default styles, so in this model, the latent variable zt ranges in natural integer to denote corresponding style type. Specifically, zt = 0 denotes choosing the context expression module to generate a knowledge-irrelevant segment; zt = 1 tells the model to choose the knowledge expression module without specially customized style; we leave the zt ≥ 2 to be user-defined so as to select the\nknowledge expression module combined with customized style. The transition function p̃(zt|ct) is then implemented as a multinomial distribution parameterized by Softmax(fz−mlp(ct))1.\nPrior of Boundary Indicator. The boundary indicator M = {mt}lrt=1 depicts the segmental structure of the response, with mt = 1 indicates that a new segment should start at time t + 1. Presumably, the prior of mt could be inferred from r≤t and zt. We model the distribution pθm(mt|r≤t, zt) by a Bernoulli distribution parameterized by σ(fm−mlp([et;h N,dec t ])), where σ denotes the sigmoid function.\nStylized Generation. As mentioned above, the generation process involves scheduling different modules according to zt. Here we give a systematic description of the generation process. The decoder accepts the token generated last timestep rt−1 as input, performs transformation inN decoder layers, finally obtains a dense representation.\nWe use hlt to denote the hidden state after the l-th layer at timestep t, which is a shorthand for hl,dect for brevity. Specially, h 0 t is the output of the embedding layer. When zt = 0, it implies that knowledge encoding is unnecessary for current segment so hlt is defined as:\nhlt = DecoderLayer(h l−1 t ,H l−1 t−1,C), (4)\n1We use f∗−mlp to denote a multi-layer perceptron network in this paper.\nwhere Hlt−1 = [h l 1, · · · ,hlt−1] is a sequence of decoder hidden states in previous timesteps, and C is the context representation mentioned above. DecoderLayer(·, ·, ·) is implemented as pre-trained BART decoder layer where hl−1t first plays selfattention on Hl−1t−1 then performs cross-attention on C. The probability p(rt|r<t, zt = 0) is defined as a multinomial distribution parameterized by Softmax(fr−mlp(hNt )), where hNt encodes the generated tokens up to timestep t−1. When zt = 1, the implementation of decoder layer is analogous to the zt = 0 case except that we replace C with K, since knowledge is needed:\nhlt = DecoderLayer(h l−1 t ,H l−1 t−1,K). (5)\nTo generate a segment with a particular customized style when zt ≥ 2, we introduce some adapters to bias the generation efficiently following Houlsby et al. (2019). Specifically, the hidden state hlt is defined as:\nhlt = DecoderLayeradp(h l−1 t ,H l−1 t−1,K), (6)\nwhere DecoderLayeradp(·, ·, ·) denotes the transformer decoder layer with adapters inserted. To make the style fine-grained and adjustable, each style has a unique set of adapters. Different styles have no adapter in common. In addition, our model has the ability to learn to express in any style, as long as a discriminator for the desired style is provided.2"
    }, {
      "heading" : "3.3 Learning Details",
      "text" : "We introduce auxiliary distributions qϕm(M |R) =∏lr\nt=1 qϕm(mt|R) and qϕz(Z|M,R) =∏lr t=1 qϕz(zt|M,R), which serve as an approximation to the intractable posterior of the boundary indicator M and the module indicator Z. We then apply variational approximation which gives the following evidence lower bound objective 3(ELBO) (Hoffman et al., 2013):\nlog pθ(R|U,K)\n≥ Eqϕm (M|R) ( Eqϕz (Z|M,R) lr∑ t=1 log pθ(rt|r<t, zt) − lr∑ t=1 mt−1 ·DKL ( qϕz (zt|M,R)∥pθz (zt) )) − lr∑ t=1 DKL ( qϕm(mt|R)∥pθm(mt) ) , (7)\n2The proposed method is also able to control the content style of knowledge-irrelevant segmentation by introducing extra adapters. But we focus on knowledge expression in this work.\n3We always have m0 = 1\nwhere pθz(zt) and pθm(mt) stand for pθz(zt|r<t, z<t,mt−1) and pθm(mt|r≤t, zt) respectively, and DKL(·∥·)) refers to Kullback–Leibler divergence. Detailed derivations are presented in the appendix.\nBased on the intuition that the response provides hints about the segmentation, we construct the posterior distribution qϕm(mt|R) as a Bernoulli distribution parameterized by σ(f ′m−mlp(ψt)). ψt is a feature extracted from a bi-directional LSTM ψ(R). Since the module indicator is kept unchanged within a segment, the posterior distribution qϕz(zt|M,R) is conditioned on the boundary indicator mt−1 and defined as:\nqϕz(zt|M,R) =mt−1 · q̃(zt|ψt) + (1−mt−1) · δ(zt = zt−1),\n(8) where δ(·) denotes Dirac delta function and the transition function q̃(zt|ψt) is implemented as a multinomial distribution parameterized by Softmax(f ′z−mlp(ψt)). Once we have the posterior distribution, we apply Gumbel-Softmax (Jang et al., 2016) to take samples of mt and zt.\nWeak Supervision on M and Z. We first use StanfordNLP toolkit (Manning et al., 2014) to parse every response in the training set as a sequence of segments, and use M̃ = {m̃t}lrt=1 to denote the results of segmentation labeling. The pseudo label of module choice Z̃ = {zt}lrt=1 is tagged in a similar way to multiclass classification, determined by (1) the similarity between each segment and knowledge and (2) the classification confidence of the style discriminator. More details about the construction of Z̃ and M̃ are provided in the appendix.\nWith Z̃ and M̃ , the loss function of weak supervision is defined as:\nLm = − lr∑ t=1 log pθm(m̃t|r≤t, z̃t),\nLz = − lr∑ t=1 m̃t−1 · log pθz(z̃t|r<t, z̃<t, m̃t−1).\n(9) The learning algorithm is summarized and provided in the appendix."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Datasets",
      "text" : "We test our model on benchmarks of knowledgegrounded dialogue generation, including Wizard of\nWikipedia (Wizard) (Dinan et al., 2019) and CMU Document Grounded Conversations (CMU_DoG) (Zhou et al., 2018c). We choose the Reddit Corpus published by (Li et al., 2020) as D for pre-training. Since it is abundant in expression style as a corpus from online forum, the two latent variables could be well initialized. We use part of the training data of Wizard and CMU_DoG as Dsty respectively, for these two datasets are distinctive in expression style and differ from each other. The dialogues in CMU_DoG tend to be causal and short, with most utterances irrelevant to knowledge while the responses in Wizard are usually long and knowledgeable, as some phrases are directly extracted from wiki articles.\nMore details about the datasets are described in the appendix."
    }, {
      "heading" : "4.2 Experimental Setup",
      "text" : "In this paper, we mainly consider two experimental setups, corresponding to the two aspects of knowledge expression. To explore how our model can be used to control the distribution of different kinds of segments (knowledge-related and knowledgeirrelevant), we first train the model on the Reddit Corpus and then fine-tune it on a small amount of examples in Wizard and CMU_DoG, respectively.4 To verify whether our model can generate the knowledge-related segments in the desired style, we still train the model on the Reddit Corpus, and use a style tag to control the generation process. In this experimental setup, we are primarily concerned with generating with two kinds of styles, positive and negative, where zt = 2 · min(1, zt) tells the model to generate a response in positive sentiment and zt = 3 ·min(1, zt) is for response in negative sentiment.\nEvaluation Metrics. Following Dinan et al. (2019), we choose PPL and unigram F1 as the\n4We provide the evaluation results of training on the whole Wizard and CMU_DoG in the appendix.\nmetrics to evaluate the appropriateness. We further use Distinct-1/2 (D-1/2), which are calculated as ratios of distinct unigrams and bigrams in responses respectively, to evaluate the distinctness. We also employ classification accuracy as the evaluation metrics for style control experiments.5 Due to space limitation, we provide automatic evaluation results on more metrics (i.e., BLEU-1/2/3/4, METEOR, and ROUGE-L) in the appendix.\nTo further verify whether our model could learn structure style and content style, we randomly sample 300 examples from Test Seen of Wizard, and the test set of CMU_DoG respectively, and recruit 6 well-educated native speakers to do qualitative analysis on the responses generated by our model and all baselines. The annotators need to judge the quality of the responses from four aspects (i.e., fluency, context coherence, knowledge relevance and style consistency), and assigns a score from {0, 1, 2} (representing “bad”, “fair” and “good” respectively) to each response for each aspect. The agreement among all annotators is measured via Fleiss’ kappa (Fleiss, 1971). More details about the setup of human evaluation as well as the results on learning content style are provided in the appendix."
    }, {
      "heading" : "4.3 Baselines",
      "text" : "Due to the space limitation, we provide the details about baselines in the appendix."
    }, {
      "heading" : "4.4 Results on Learning Structure Style",
      "text" : "In this section, we demonstrate the effectiveness of our segmentation-based generation framework in both low-resource setting and zero-resource setting and empirically verify that our model can learn structure style with a few annotated examples.\nIn zero-resource setting, we trained our model on the Reddit Corpus published by (Li et al., 2020) and tested on Wizard and CMU_DoG respectively. Automatic evaluation results are shown in Table 2. It\n5We exploit Roberta trained on the SST-2 training set (Socher et al., 2013) as the evaluator.\ncould be observed that: (1) our model significantly outperforms ZRKGC and BART on most metrics and achieves the new state-of-the-art performance on Wizard. It is impressive that our model exceeds BART in CMU_DoG especially since the proposed model degrades into BART without two sequential latent variables Z and M. The result serves as strong evidence for the effect of two latent variables, which enable the model to learn complex expression style in Reddit Corpus to handle flexible expression in CMU_DoG. By contrast, BART is far from satisfying with only a regular decoder. (2) our model exceeds ZRKGC significantly in terms of Distinct metrics, for ZRKGC mainly focuses on leveraging external knowledge sources for response generation, but falls short on expression diversity. In the low-resource setting, after training our model on the Reddit Corpus, we then fine-tune it with only 10% training size of Wizard and CMU_DoG respectively (i.e., Dsty in Sec ??) to adjust p(zt) and p(mt) to a new structure style. When provided with only 10% training data, our model gets obvious improvement (∼ 1% increase in F1) in contrast with BART (∼ 0.5% increase in F1) and ZRKGC (∼ 0.2% increase in F1), proving that the proposed model can learn more sophisticated structure style through quick adjustment on a specific dataset with little cost.6\nHuman Evaluation. Table 3 shows human evaluation results on learning structure style. It could\n6After trained with 10% Wizard data, the diversity of our model decreases for it fits the specific expression style of Wizard.\nbe observed that: (1)our model is significantly superior to others on style consistency, indicating that the model can learn a consistent expression style with very little data. (2) our model has better performance on context coherence and knowledge relevance, tallying with its impressive performance in the low-resource scenario.\nFine-tuning with limited annotated data. We first train the model on the Reddit Corpus and then fine-tune it with the amount of annotated data (e.g., Wizard and CMU_DoG) gradually increasing from 2% to 10%. To have a more intuitive understanding of the effects of latent variables Z and M, we compare the proposed model with BART, which generates the response with a single decoder. The evaluation results are shown in Figure 2. It can be concluded from the result that: (1) our model can learn the expression style of a particular dataset more efficiently. As the training data increases, our model has a more significant improvement in terms of the F1 metric; (2) our model performs better in meager resources since there is a considerable gap between our model and BART when the training data is close to 0%; (3) the expression style of CMU_DoG can be learned with less data because the model has a significant change in performance after using 2% CMU_DoG training data."
    }, {
      "heading" : "Refashioning of knowledge-related segments.",
      "text" : "To know how our model adjusts to different datasets, we compare the knowledge-related segments before and after trained with annotated data from two aspects: (1) the average proportion of\nknowledge-related segments (pklg) in a sentence; (2) the average proportion of words belonging to knowledge-related segments (lklg). The motivation behind is that the frequency and length of these two kinds of segments generally indicates how well the latent variable is learned to capture the knowledge expression structure. We identify these two kinds of segmentation by comparing their lexical similarities with the knowledge. Figure 3 reports the results. The results indicate that our model could learn the underlying structure style of both datasets, with the great difference of pklg and lklg before and after fine-tuning as evidence. After fine-tuning with Wizard data, pklg drops to 0.26 while the lklg grows up a bit, indicating that the knowledge-related segments generated by our model are fewer and longer, which tallies with the fact that the responses in Wizard are probably directly copied from background knowledge. However, after CMU_DoG data is fed to the model, both pklg and lklg shrinks drastically, which agrees with the fact that crowd-sourcing workers converse more liberally online and the responses are less relevant to the background knowledge."
    }, {
      "heading" : "4.5 Results on Learning Content Style",
      "text" : "We further investigate whether the proposed model could express knowledge with the desired sentiment. Specifically, we introduce two sets of style adapters to endow knowledge expression in two different sentiments, namely positive and negative. So in this scenario, it is required that responses\nare not only coherent with context but also limited in positive or negative sentiment. To apply ECM on knowledge-grounded conversation, we label the sentiment category for each response with a classifier pre-trained on the SST (Socher et al., 2013) training set. For DialoGPT, we similarly annotate each response with a sentiment category and append the sentiment token before the context tokens. The evaluation results is shown in Table 4. We can conclude that: (1) The proposed model outperforms all baseline models in terms of all metrics, which indicates that our model can control the sentiment of knowledge expression and guarantee high quality of the generated responses; (2) Simply adding a sentiment indicating token at the beginning of the sequence can not effectively control the style of knowledge expression, as the performance of DialoGPT on sentiment control is poor; (3) Although ECM is designed for sentiment control, it still fails to perform well in this task, proving that sentiment control in the knowledge-grounded conversation is rather difficult. Besides, ECM can only control the sentiment of the whole response but is helpless to manage every knowledge-related segment at a fine-grained level."
    }, {
      "heading" : "5 Conclusions",
      "text" : "We explore knowledge expression in knowledgegrounded conversation and break down the expression style of a response into the structure of the response (structure style) and the style of the content in each part (content style). We propose a variational segmentation-based generation model to discover the underlying expression style in response. Specifically, we introduce two latent variables to model these two aspects of expression style respectively and induce an evidence lower bound of the likelihood. Evaluation results on two benchmarks of the task indicate that our model can learn the structure style with little cost and generate responses in desired content style without any human-annotated data."
    }, {
      "heading" : "A Appendix",
      "text" : "A.1 Derivation of ELBO log p(R|U,K)\n= log ∑\n(M,Z)\np(R,M,Z)\n= log ∑\n(M,Z)\nq(M,Z|R)p(R,M,Z) q(M,Z|R)\n= logE(M,Z)∼q(M,Z|R) p(R,M,Z)\nq(M,Z|R)\n≥ E(M,Z)∼q(M,Z|R) log p(R,M,Z) q(M,Z|R) = E(M,Z)∼q(M,Z|R) log p(R|M,Z) − E(M,Z)∼q(M,Z|R) ( log q(M,Z|R)\n− log p(M,Z) ) .\n(10)\nAccording to the mean-filed approximation, q(M,Z) ≈ q(M)q(Z). Therefore, E(M,Z)∼q(M,Z|R) log p(R|M,Z) and E(M,Z)∼q(M,Z|R) ( log q(M,Z|R)− log p(M,Z)\n) can be re-written as:\nE(M,Z)∼q(M,Z|R) log p(R|M,Z)\n= EM∼q(M|R) ( EZ∼q(Z|M,R) lr∑ t=1 log p(rt|r<t, zt)) ) (11)\nE(M,Z)∼q(M,Z|R) ( log q(M,Z|R)− log p(M,Z) ) = EM∼q(M|R) ( EZ∼q(Z|M,R) ( log q(M |R)− log p(M)\n) + EZ∼q(Z|M,R) ( log q(Z|M,R)− log p(Z)\n)) = EM∼q(M|R) ( log q(M |R)− log p(M)\n) + EM∼q(M|R) ( EZ∼q(Z|M,R) ( log q(Z|M,R)− log p(Z)\n)) =\nlr∑ t=1 ( EM∼q(M|R) ( log q(mt)− log p(mt) ))\n+ EM∼q(M|R) ( lr∑\nt=1\nmt−1 · EZ∼q(Z|M,R) ( log q(zt)− log p(zt)\n))\n= lr∑ t=1 DKL(q(mt)∥p(mt))\n+ EM∼q(M|R) ( lr∑\nt=1\nmt−1 ·DKL(q(zt)∥p(zt)) ) .\n(12)"
    }, {
      "heading" : "A.2 Baselines",
      "text" : "For the exploration of structure style, we select the following models as baselines: (1) BART (Lewis et al., 2020): a model that achieves state-of-theart performance on various text generation tasks. Note that our model degrades into BART once we\nremove the module indicator Z and the boundary indicator M; (2) Zero-resource Knowledge-grounded Conversation (ZRKGC) (Li et al., 2020)7: a model that is based on UniLM (Dong et al., 2019) and optimized with Generalized EM method.\nFor the content style, we consider the following models as baselines: (1)Emotional Chatting Machine (ECM) (Zhou et al., 2018a)8: a model which can generate appropriate responses not only content-relevant but also emotional consistent; (2)variant of DialoGPT (Zhang et al., 2019b): We add a sentiment indicating token at the first of the sequence and explore whether such simple heuristics works for controlling knowledge expression; (3) CTRL (Keskar et al., 2019) 9 : a large-scale model trained on conditional codes to govern the style and content of generation.\nOur model and all baselines are trained on the identical Reddit Corpus to maintain fairness."
    }, {
      "heading" : "A.3 Human Evaluation",
      "text" : "We randomly sample 300 examples from Test Seen of Wizard, and the test set of CMU_DoG respectively, and recruit 6 well-educated native speakers to do qualitative analysis on the responses generated by our model and all baselines. For evaluation of structure style, we defined two kinds of structure styles based on two datasets, namely the Wizardlike style Swizard and the CMU_DoG-like style Scmudog. While for evaluation of content style, we roughly divide content styles in two categories, Spos and Sneg for convenience. The responses provided by different models are randomly shuffled to hide their sources. The annotators need to judge the quality of the responses from four aspects: (1) fluency: whether the response is fluent without any grammatical errors; (2) context coherence: whether the response is coherent with the context; (3) knowledge relevance: whether the response is relevant with the knowledge; and (4) style consistency: whether the response exhibits the desired style. Each annotator assigns a score from {0, 1, 2} (representing “bad”, “fair” and “good” respectively) to each response for each aspect. Each response obtains four scores for aforementioned four aspects, and the agreement among all annotators is measured via Fleiss’ kappa (Fleiss, 1971).\n7 https://github.com/nlpxucan/ZRKGC 8 https://github.com/thu-coai/ecm 9 https://github.com/salesforce/ctrl\nResults on Learning content style. Table 5 reports the human evaluation results on learning content style. The three models are trained on the Reddit Corpus. We can conclude that: (1) by introducing two latent variables and a number of adapters for different styles, our model can generate responses in desired content style (i.e., Spos and Sneg) more accurately and achieve significant improvement on style consistency, which is consistent with the results in Table 4; (2) our model also outperforms ECM and DialoGPT on fluency,context coherency and knowledge relevance thanks to the capacity of large-scale pre-trained language models and the introduction of external knowledge respectively."
    }, {
      "heading" : "A.4 More Results about Automatic Evaluation",
      "text" : "Table 8 reports the more results about the automatic evaluation, from which we can see that our model still outperforms the baselines."
    }, {
      "heading" : "A.5 Details about the Construction of M̃ and",
      "text" : "Z̃\nIn this section, we provide more details about of construction of M̃ and Z̃. For every response in the training set, we parse it as a syntax tree using StanfordNLP toolkit (Manning et al., 2014). The syntax tree we obtain is in a hierarchical and nested structure. The root node of the tree represents the whole response sentence and the root node of every subtree represents a corresponding phrase, a small part of a sentence. For example, if a phrase could be divided into three parts, then the node representing the phrase has three child nodes and each represents\na part of the phrase. After we acquire the parsing tree, segmentation is then carried out recursively. To be concrete, we traverse the parsing tree by deepfirst search order. Every time we arrive at a node, compute the similarity10 between the knowledge and the phrase represented by the node. If the similarity is above the threshold µseg, we mark the phrase as a segment and search in this branch terminates. Else we continue to search the child nodes of the current node to segment at a more refined level. We use M̃ = {m̃t}lrt=1 to denote the results of segmentation labeling.\nThe pseudo label of module choice Z̃ = {zt}lrt=1 is tagged in a similar way to multiclass classification. Specifically, for a segment (rs, · · · , re) where s and e are the start and end position of a segment respectively. If the similarity between this segment and the knowledge falls below a threshold µknl, its pseudo label (zs, · · · , ze) will be set to 0. Otherwise we send the segment to a series of style discriminators one after another until the classification confidence given by a discriminator is above µstyi and pseudo module choice label will be set to i+1. If all discriminators fail to classify the segment at a confidence greater than µstyi , (zs, · · · , ze) are all 1, indicating knowledge should be expressed without particular style."
    }, {
      "heading" : "A.6 More Implementation Details",
      "text" : "We employ a knowledge selection(KS) module to select the top 7 related sentences in knowledge. The KS module is implemented based on Robertabase(125M) and trained on the Reddit Corpus.\n10We use unigram Precision to calculate the similarity.\nSpecifically, we treat the sentence which has the highest F1 score with the response as the positive sample, and the negative sample is randomly sampled from all the other knowledge sentences. We train the KS module via maximum likelihood estimation (MLE) with a batch size of 64 and an initial learning rate of 1e − 5. The threshold µseg, µknl, µpos and µneg11 in weak supervision are set as 0.9, 0.5, 0.8 and 0.8, respectively. The encoder-decoder architecture is implemented on the basis of Bartbase(139M) and trained on the Reddit Corpus with a batch size of 64 and an initial learning rate of 5e− 6. The parameters for prior and posterior distributions of Z and M (i.e., θz , θm, ϕz and ϕm) are initialized randomly, and optimized with a learning rate of 1e − 4. The parameters for adapters are initialized randomly and optimized with a learning rate of 2e − 3. We only train the adapters for the first 1000 steps. We utilize gated recurrent units (GRUs) as the basic units in fz−rnn. We set the hidden size and the number of layers of RNN in our model(i.e., fz−rnn and ψ(·)) as 128 and 1 respectively. The embedding size for Z is set as 128 and the adapter size is set as 64. When finetuning the model on the Wizard and CMU_DoG\n11We consider positive and negative sentiment style in our experiments.\ndatasets, the learning rate and the batch size are set as 5e − 5 and 32 respectively. We employ greedy search in response decoding. All models are learned with Adam (Kingma and Ba, 2015) optimizer with β1 = 0.9 and β2 = 0.999. We increase the learning rate linearly for the first 200 steps and decrease it thereafter proportionally to the inverse square root of the step number. Early stopping on validation is adopted as a regularization strategy. All models are trained on a 8×RTX 2080 Ti machine."
    }, {
      "heading" : "A.7 Details of Datasets",
      "text" : "Training Data. We choose the Reddit Corpus published by (Li et al., 2020) as D for pre-training. The data contains 842, 521 context-knowledgeresponse triples for training and 2, 737 contextknowledge-response triples for validation. On average, each dialogue contains 3.1 utterances in both sets, and the average length of the utterance is 16.0 in training and is 16.1 in validation.\nEvaluation Data. We test our model on benchmarks of knowledge-grounded dialogue generation, including Wizard of Wikipedia (Wizard) (Dinan et al., 2019) and CMU Document Grounded Conversations (CMU_DoG) (Zhou et al., 2018c). Both datasets are split into training sets, validation sets,\nand test sets by the data owners. We follow (Dinan et al., 2019) and conduct the pre-processing with the code published on ParlAI12. Topics in Wizard cover a wide range (1, 365 in total), and each conversation happens between a wizard who has access to the knowledge about a specific topic and an apprentice who is just eager to learn from the wizard about the topic. The test set is split into two subsets. Test Seen only contains dialogues with topics that have already appeared in the training set, while topics in Test Unseen never appear in the training set and the validation set. Different from Wizard, CMU_DoG focuses on movie domain, and besides wizard-apprentice conversations, the data also contain conversations between two workers who know the document and try to discuss the content in depth. In both datasets, only the turns where knowledge is accessible are considered in response generation. Table 6 reports the statistics of the Wizard data and the CMU_DoG data"
    }, {
      "heading" : "A.8 Comparison with More Baselines",
      "text" : "We compare with models trained on full training data, and Table 7 shows the evaluation results. First, it is noted that our model outperforms KnowledGPT in terms of F1 by using only 10% training data13 on CMU_DoG, which provides a strong support for the effectiveness of the proposed model. Second, by adjusting the structure style on a small amount of data, the gap between our model and KnowledGPT is further narrowed, while the improvement on ZRKGC and BART is trivial."
    }, {
      "heading" : "A.9 Ablation over Weak Supervision",
      "text" : "To have more insights into the impact of weak supervision on the performance of our model, we compare the proposed model with the following variants: (1)-weak supervision on Z: the weak supervision on module indicator Z is removed; (2)- weak supervision on Z and M: the weak supervision on module indicator and boundary indicator is removed. Table 9 reports the evaluation results. We can conclude that (1) the weak supervision objectives significantly improve model performance; (2) the weak supervision objectives play a more crucial role on CMU_DoG, as removing them causes a dramatic drop in performance. The reason is\n12 https://github.com/facebookresearch/ParlAI/blob/ master/projects/wizard_of_wikipedia 13The 10% training data is randomly sampled. The result is an average value of three repetitive experiments on every dataset\nthat this dataset has more sophisticated expression styles and it is difficult to learn these styles without auxiliary supervision signals."
    }, {
      "heading" : "A.10 Learning Algorithm",
      "text" : "The learning algorithm is summarized in Algorithm 1."
    }, {
      "heading" : "A.11 Case Study",
      "text" : "This section mainly studies how different models vary in knowledge expression for the same context and background knowledge. Table 10 shows an example from the test set of CMU_DoG. This example contains the background knowledge which gives a plot from the movie, and the dialogue context which is generated by discussing the content in the knowledge. We choose the following four models to generate the response in corresponding style given the dialogue context and knowledge, and all models are pre-trained with the Reddit Corpus: (1) Wizard Model for Swizard: the model fine-tuned with 10% training data in Wizard; (2) CMU_DoG Model for Scmudog: the model fine-tuned with 10% training data in CMU_DoG; (3) Positive Model for Spos: the model forced to express knowledge with positive sentiment; (4) Negative Model for Sneg: the model forced to express knowledge with negative sentiment. We can see that the knowlege expression style of the Wizard Model and CMU_DoG Model are quite different. The central part of the Wizard Model response is copied from the background knowledge, which is consistent with the style of Wizard data. The response generated by CMU_DoG Model is more casual in knowledge expression, and the content is mainly related to the conversation context. Besides, responses generated by the Positive Model exhibit evident positive sentiment, while responses generated by the Negative Model show relatively negative sentiment.\nAlgorithm 1 Learning Algorithm 1: Input: Training data D, thresholds for weak supervision µseg , µknl and µsty , discriminator{Disi} Nsty i=1 , maximum step M ,\nadapter training step M ′ .\n2: for m← 1 to M do 3: Sample a mini-batch {(Ui,Ki, Ri)} from D. 4: Conduct segmentation on Ri to get M̃ . 5: for i← 1 to Nseg do 6: for j ← 1 to Nsty do 7: Use Disj to classify response segment (rsi , · · · , rei). 8: if Confidence of Disj ≥ µsty and (zsi , · · · , zei) are not assigned then 9: (zsi , · · · , zei)← j + 1\n10: end if 11: end for 12: end for 13: if m ≤M ′ then 14: Update the adapters based on the first term in ELBO. 15: else 16: Update the parameters θ (i.e., θm, θz and the parameters in p(rt)) and ϕ (i.e., ϕm and ϕz) based on ELBO and Weak\nSupervision. 17: end if 18: end for 19: return Generation Model pθ(R|U,K) with prior distribution pθm and pθz"
    } ],
    "references" : [ {
      "title" : "Wizard of wikipedia: Knowledge-powered conversational agents",
      "author" : [ "Emily Dinan", "Stephen Roller", "Kurt Shuster", "Angela Fan", "Michael Auli", "Jason Weston." ],
      "venue" : "ICLR.",
      "citeRegEx" : "Dinan et al\\.,? 2019",
      "shortCiteRegEx" : "Dinan et al\\.",
      "year" : 2019
    }, {
      "title" : "Unified language model pre-training for natural language understanding and generation",
      "author" : [ "Li Dong", "Nan Yang", "Wenhui Wang", "Furu Wei", "Xiaodong Liu", "Yu Wang", "Jianfeng Gao", "Ming Zhou", "Hsiao-Wuen Hon." ],
      "venue" : "Advances in Neural Information Pro-",
      "citeRegEx" : "Dong et al\\.,? 2019",
      "shortCiteRegEx" : "Dong et al\\.",
      "year" : 2019
    }, {
      "title" : "Measuring nominal scale agreement among many raters",
      "author" : [ "Joseph L Fleiss." ],
      "venue" : "Psychological bulletin, 76(5):378.",
      "citeRegEx" : "Fleiss.,? 1971",
      "shortCiteRegEx" : "Fleiss.",
      "year" : 1971
    }, {
      "title" : "Stochastic variational inference",
      "author" : [ "Matthew D Hoffman", "David M Blei", "Chong Wang", "John Paisley." ],
      "venue" : "Journal of Machine Learning Research, 14(5).",
      "citeRegEx" : "Hoffman et al\\.,? 2013",
      "shortCiteRegEx" : "Hoffman et al\\.",
      "year" : 2013
    }, {
      "title" : "Parameter-efficient transfer learning for nlp",
      "author" : [ "Neil Houlsby", "Andrei Giurgiu", "Stanislaw Jastrzebski", "Bruna Morrone", "Quentin De Laroussilhe", "Andrea Gesmundo", "Mona Attariyan", "Sylvain Gelly." ],
      "venue" : "International Conference on Machine Learning, pages",
      "citeRegEx" : "Houlsby et al\\.,? 2019",
      "shortCiteRegEx" : "Houlsby et al\\.",
      "year" : 2019
    }, {
      "title" : "Towards neural phrase-based machine translation",
      "author" : [ "Po-Sen Huang", "Chong Wang", "Sitao Huang", "Dengyong Zhou", "Li Deng." ],
      "venue" : "arXiv preprint arXiv:1706.05565.",
      "citeRegEx" : "Huang et al\\.,? 2017",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2017
    }, {
      "title" : "Emotional dialogue generation using image-grounded language models",
      "author" : [ "Bernd Huber", "Daniel McDuff", "Chris Brockett", "Michel Galley", "Bill Dolan." ],
      "venue" : "CHI, page 277. ACM.",
      "citeRegEx" : "Huber et al\\.,? 2018",
      "shortCiteRegEx" : "Huber et al\\.",
      "year" : 2018
    }, {
      "title" : "Categorical reparameterization with gumbel-softmax",
      "author" : [ "Eric Jang", "Shixiang Gu", "Ben Poole." ],
      "venue" : "arXiv preprint arXiv:1611.01144.",
      "citeRegEx" : "Jang et al\\.,? 2016",
      "shortCiteRegEx" : "Jang et al\\.",
      "year" : 2016
    }, {
      "title" : "Ctrl: A conditional transformer language model for controllable generation",
      "author" : [ "Nitish Shirish Keskar", "Bryan McCann", "Lav R Varshney", "Caiming Xiong", "Richard Socher." ],
      "venue" : "arXiv preprint arXiv:1909.05858.",
      "citeRegEx" : "Keskar et al\\.,? 2019",
      "shortCiteRegEx" : "Keskar et al\\.",
      "year" : 2019
    }, {
      "title" : "Sequential latent knowledge selection for knowledge-grounded dialogue",
      "author" : [ "Byeongchang Kim", "Jaewoo Ahn", "Gunhee Kim." ],
      "venue" : "arXiv preprint arXiv:2002.07510.",
      "citeRegEx" : "Kim et al\\.,? 2020",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2020
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P Kingma", "Jimmy Ba." ],
      "venue" : "ICLR.",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "Bart: Denoising sequence-to-sequence pre-training for natural language",
      "author" : [ "Mike Lewis", "Yinhan Liu", "Naman Goyal", "Marjan Ghazvininejad", "Abdelrahman Mohamed", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer" ],
      "venue" : null,
      "citeRegEx" : "Lewis et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Lewis et al\\.",
      "year" : 2020
    }, {
      "title" : "A diversity-promoting objective function for neural conversation models",
      "author" : [ "Jiwei Li", "Michel Galley", "Chris Brockett", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "NAACL, pages 110–119.",
      "citeRegEx" : "Li et al\\.,? 2015",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2015
    }, {
      "title" : "A persona-based neural conversation model",
      "author" : [ "Jiwei Li", "Michel Galley", "Chris Brockett", "Georgios Spithourakis", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "ACL, pages 994–1003.",
      "citeRegEx" : "Li et al\\.,? 2016",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Zero-resource knowledge-grounded dialogue generation",
      "author" : [ "Linxiao Li", "Can Xu", "Wei Wu", "Yufan Zhao", "Xueliang Zhao", "Chongyang Tao." ],
      "venue" : "arXiv preprint arXiv:2008.12918.",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Learning to select knowledge for response generation in dialog systems",
      "author" : [ "Rongzhong Lian", "Min Xie", "Fan Wang", "Jinhua Peng", "Hua Wu." ],
      "venue" : "arXiv preprint arXiv:1902.04911.",
      "citeRegEx" : "Lian et al\\.,? 2019",
      "shortCiteRegEx" : "Lian et al\\.",
      "year" : 2019
    }, {
      "title" : "The stanford corenlp natural language processing toolkit",
      "author" : [ "Christopher D Manning", "Mihai Surdeanu", "John Bauer", "Jenny Rose Finkel", "Steven Bethard", "David McClosky." ],
      "venue" : "Proceedings of 52nd annual meeting of the association for computational linguis-",
      "citeRegEx" : "Manning et al\\.,? 2014",
      "shortCiteRegEx" : "Manning et al\\.",
      "year" : 2014
    }, {
      "title" : "Opendialkg: Explainable conversational reasoning with attention-based walks over knowledge graphs",
      "author" : [ "Seungwhan Moon", "Pararth Shah", "Anuj Kumar", "Rajen Subba." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Moon et al\\.,? 2019",
      "shortCiteRegEx" : "Moon et al\\.",
      "year" : 2019
    }, {
      "title" : "Image-grounded conversations: Multimodal context for natural question and response generation",
      "author" : [ "Nasrin Mostafazadeh", "Chris Brockett", "Bill Dolan", "Michel Galley", "Jianfeng Gao", "Georgios Spithourakis", "Lucy Vanderwende." ],
      "venue" : "Proceedings of",
      "citeRegEx" : "Mostafazadeh et al\\.,? 2017",
      "shortCiteRegEx" : "Mostafazadeh et al\\.",
      "year" : 2017
    }, {
      "title" : "What makes a good conversation? how controllable attributes affect human judgments",
      "author" : [ "Abigail See", "Stephen Roller", "Douwe Kiela", "Jason Weston." ],
      "venue" : "arXiv preprint arXiv:1902.08654.",
      "citeRegEx" : "See et al\\.,? 2019",
      "shortCiteRegEx" : "See et al\\.",
      "year" : 2019
    }, {
      "title" : "Building end-to-end dialogue systems using generative hierarchical neural network models",
      "author" : [ "Iulian Vlad Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron C Courville", "Joelle Pineau." ],
      "venue" : "AAAI, volume 16, pages 3776–3784.",
      "citeRegEx" : "Serban et al\\.,? 2016",
      "shortCiteRegEx" : "Serban et al\\.",
      "year" : 2016
    }, {
      "title" : "A hierarchical latent variable encoder-decoder model for generating dialogues",
      "author" : [ "Iulian Vlad Serban", "Alessandro Sordoni", "Ryan Lowe", "Laurent Charlin", "Joelle Pineau", "Aaron C Courville", "Yoshua Bengio." ],
      "venue" : "AAAI, pages 3295–3301.",
      "citeRegEx" : "Serban et al\\.,? 2017",
      "shortCiteRegEx" : "Serban et al\\.",
      "year" : 2017
    }, {
      "title" : "Neural responding machine for short-text conversation",
      "author" : [ "Lifeng Shang", "Zhengdong Lu", "Hang Li." ],
      "venue" : "ACL, pages 1577–1586.",
      "citeRegEx" : "Shang et al\\.,? 2015",
      "shortCiteRegEx" : "Shang et al\\.",
      "year" : 2015
    }, {
      "title" : "Neural data-to-text generation via jointly learning the segmentation and correspondence",
      "author" : [ "Xiaoyu Shen", "Ernie Chang", "Hui Su", "Cheng Niu", "Dietrich Klakow." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages",
      "citeRegEx" : "Shen et al\\.,? 2020",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2020
    }, {
      "title" : "Engaging image chat: Modeling personality in grounded dialogue",
      "author" : [ "Kurt Shuster", "Samuel Humeau", "Antoine Bordes", "Jason Weston." ],
      "venue" : "arXiv preprint arXiv:1811.00945.",
      "citeRegEx" : "Shuster et al\\.,? 2018",
      "shortCiteRegEx" : "Shuster et al\\.",
      "year" : 2018
    }, {
      "title" : "Recursive deep models for semantic compositionality over a sentiment treebank",
      "author" : [ "Richard Socher", "Alex Perelygin", "Jean Wu", "Jason Chuang", "Christopher D Manning", "Andrew Y Ng", "Christopher Potts." ],
      "venue" : "Proceedings of the 2013 conference on empiri-",
      "citeRegEx" : "Socher et al\\.,? 2013",
      "shortCiteRegEx" : "Socher et al\\.",
      "year" : 2013
    }, {
      "title" : "Get the point of my utterance! learning towards effective responses with multi-head attention mechanism",
      "author" : [ "Chongyang Tao", "Shen Gao", "Mingyue Shang", "Wei Wu", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "IJCAI, pages 4418–4424.",
      "citeRegEx" : "Tao et al\\.,? 2018",
      "shortCiteRegEx" : "Tao et al\\.",
      "year" : 2018
    }, {
      "title" : "Dykgchat: Benchmarking dialogue generation grounding on dynamic knowledge graphs",
      "author" : [ "Yi-Lin Tuan", "Yun-Nung Chen", "Hung-yi Lee." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th",
      "citeRegEx" : "Tuan et al\\.,? 2019",
      "shortCiteRegEx" : "Tuan et al\\.",
      "year" : 2019
    }, {
      "title" : "A neural conversational model",
      "author" : [ "Oriol Vinyals", "Quoc Le." ],
      "venue" : "arXiv preprint arXiv:1506.05869.",
      "citeRegEx" : "Vinyals and Le.,? 2015",
      "shortCiteRegEx" : "Vinyals and Le.",
      "year" : 2015
    }, {
      "title" : "Sequence modeling via segmentations",
      "author" : [ "Chong Wang", "Yining Wang", "Po-Sen Huang", "Abdelrahman Mohamed", "Dengyong Zhou", "Li Deng." ],
      "venue" : "International Conference on Machine Learning, pages 3674– 3683. PMLR.",
      "citeRegEx" : "Wang et al\\.,? 2017",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2017
    }, {
      "title" : "Learning to ask questions in open-domain conversational systems with typed decoders",
      "author" : [ "Yansen Wang", "Chenyi Liu", "Minlie Huang", "Liqiang Nie." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "Learning neural templates for text generation",
      "author" : [ "Sam Wiseman", "Stuart M Shieber", "Alexander M Rush." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3174–3187.",
      "citeRegEx" : "Wiseman et al\\.,? 2018",
      "shortCiteRegEx" : "Wiseman et al\\.",
      "year" : 2018
    }, {
      "title" : "Topic aware neural response generation",
      "author" : [ "Chen Xing", "Wei Wu", "Jie Liu", "Yalou Huang", "Ming Zhou", "Wei-Ying Ma." ],
      "venue" : "AAAI, pages 3351–3357.",
      "citeRegEx" : "Xing et al\\.,? 2017",
      "shortCiteRegEx" : "Xing et al\\.",
      "year" : 2017
    }, {
      "title" : "Neural response generation with meta-words",
      "author" : [ "Can Xu", "Wei Wu", "Chongyang Tao", "Huang Hu", "Matt Schuerman", "Ying Wang." ],
      "venue" : "arXiv preprint arXiv:1906.06050.",
      "citeRegEx" : "Xu et al\\.,? 2019",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2019
    }, {
      "title" : "Recosa: Detecting the relevant contexts with self-attention for multi-turn dialogue generation",
      "author" : [ "Hainan Zhang", "Yanyan Lan", "Liang Pang", "Jiafeng Guo", "Xueqi Cheng." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Zhang et al\\.,? 2019a",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    }, {
      "title" : "Personalizing dialogue agents: I have a dog, do you have pets too? arXiv preprint arXiv:1801.07243",
      "author" : [ "Saizheng Zhang", "Emily Dinan", "Jack Urbanek", "Arthur Szlam", "Douwe Kiela", "Jason Weston" ],
      "venue" : null,
      "citeRegEx" : "Zhang et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "Dialogpt: Large-scale generative pre-training for conversational response generation",
      "author" : [ "Yizhe Zhang", "Siqi Sun", "Michel Galley", "Yen-Chun Chen", "Chris Brockett", "Xiang Gao", "Jianfeng Gao", "Jingjing Liu", "Bill Dolan." ],
      "venue" : "arXiv preprint arXiv:1911.00536.",
      "citeRegEx" : "Zhang et al\\.,? 2019b",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    }, {
      "title" : "Learning discourse-level diversity for neural dialog models using conditional variational autoencoders",
      "author" : [ "Tiancheng Zhao", "Ran Zhao", "Maxine Eskenazi." ],
      "venue" : "ACL, pages 654–664.",
      "citeRegEx" : "Zhao et al\\.,? 2017",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2017
    }, {
      "title" : "Low-resource knowledge-grounded dialogue generation",
      "author" : [ "Xueliang Zhao", "Wei Wu", "Chongyang Tao", "Can Xu", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "arXiv preprint arXiv:2002.10348.",
      "citeRegEx" : "Zhao et al\\.,? 2020a",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2020
    }, {
      "title" : "Knowledgegrounded dialogue generation with pre-trained language models",
      "author" : [ "Xueliang Zhao", "Wei Wu", "Can Xu", "Chongyang Tao", "Dongyan Zhao", "Rui Yan." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Zhao et al\\.,? 2020b",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2020
    }, {
      "title" : "Emotional chatting machine: Emotional conversation generation with internal and external memory",
      "author" : [ "Hao Zhou", "Minlie Huang", "Tianyang Zhang", "Xiaoyan Zhu", "Bing Liu." ],
      "venue" : "arXiv preprint arXiv:1704.01074.",
      "citeRegEx" : "Zhou et al\\.,? 2017",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2017
    }, {
      "title" : "Emotional chatting machine: Emotional conversation generation with internal and external memory",
      "author" : [ "Hao Zhou", "Minlie Huang", "Tianyang Zhang", "Xiaoyan Zhu", "Bing Liu." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 32.",
      "citeRegEx" : "Zhou et al\\.,? 2018a",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2018
    }, {
      "title" : "Commonsense knowledge aware conversation generation with graph attention",
      "author" : [ "Hao Zhou", "Tom Young", "Minlie Huang", "Haizhou Zhao", "Jingfang Xu", "Xiaoyan Zhu." ],
      "venue" : "IJCAI, pages 4623–4629.",
      "citeRegEx" : "Zhou et al\\.,? 2018b",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2018
    }, {
      "title" : "A dataset for document grounded conversations",
      "author" : [ "Kangyan Zhou", "Shrimai Prabhumoye", "Alan W Black." ],
      "venue" : "arXiv preprint arXiv:1809.07358.",
      "citeRegEx" : "Zhou et al\\.,? 2018c",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 43,
      "context" : "To bridge the gap, researchers resort to ground dialogue generation by extra knowledge such as unstructured documents (Zhou et al., 2018c; Dinan et al., 2019).",
      "startOffset" : 118,
      "endOffset" : 158
    }, {
      "referenceID" : 0,
      "context" : "To bridge the gap, researchers resort to ground dialogue generation by extra knowledge such as unstructured documents (Zhou et al., 2018c; Dinan et al., 2019).",
      "startOffset" : 118,
      "endOffset" : 158
    }, {
      "referenceID" : 0,
      "context" : "However, existing studies focus on how to synthesize a response with proper knowledge (Dinan et al., 2019; Kim et al., 2020; Zhao et al., 2020b), but pay little attention to the fact that the same knowledge could be expressed differently even under the same context.",
      "startOffset" : 86,
      "endOffset" : 144
    }, {
      "referenceID" : 9,
      "context" : "However, existing studies focus on how to synthesize a response with proper knowledge (Dinan et al., 2019; Kim et al., 2020; Zhao et al., 2020b), but pay little attention to the fact that the same knowledge could be expressed differently even under the same context.",
      "startOffset" : 86,
      "endOffset" : 144
    }, {
      "referenceID" : 39,
      "context" : "However, existing studies focus on how to synthesize a response with proper knowledge (Dinan et al., 2019; Kim et al., 2020; Zhao et al., 2020b), but pay little attention to the fact that the same knowledge could be expressed differently even under the same context.",
      "startOffset" : 86,
      "endOffset" : 144
    }, {
      "referenceID" : 14,
      "context" : "We train our model on the Reddit Corpus published by (Li et al., 2020) and evaluate our model on two benchmarks of knowledge-grounded conversation: Wizard of Wikipedia(Wizard) (Dinan et al.",
      "startOffset" : 53,
      "endOffset" : 70
    }, {
      "referenceID" : 0,
      "context" : ", 2020) and evaluate our model on two benchmarks of knowledge-grounded conversation: Wizard of Wikipedia(Wizard) (Dinan et al., 2019) and CMU Document Grounded Conversation(CMU_DoG) (Zhou et al.",
      "startOffset" : 113,
      "endOffset" : 133
    }, {
      "referenceID" : 43,
      "context" : ", 2019) and CMU Document Grounded Conversation(CMU_DoG) (Zhou et al., 2018c).",
      "startOffset" : 56,
      "endOffset" : 76
    }, {
      "referenceID" : 22,
      "context" : "On the vanilla encoder-decoder architecture (Shang et al., 2015; Vinyals and Le, 2015), various extensions have been made to model the structure of dialogue contexts (Serban et al.",
      "startOffset" : 44,
      "endOffset" : 86
    }, {
      "referenceID" : 28,
      "context" : "On the vanilla encoder-decoder architecture (Shang et al., 2015; Vinyals and Le, 2015), various extensions have been made to model the structure of dialogue contexts (Serban et al.",
      "startOffset" : 44,
      "endOffset" : 86
    }, {
      "referenceID" : 34,
      "context" : ", 2015; Vinyals and Le, 2015), various extensions have been made to model the structure of dialogue contexts (Serban et al., 2016, 2017; Zhang et al., 2019a); to improve diversity of responses (Li et al.",
      "startOffset" : 109,
      "endOffset" : 157
    }, {
      "referenceID" : 12,
      "context" : ", 2019a); to improve diversity of responses (Li et al., 2015; Xing et al., 2017; Zhao et al., 2017; Tao et al., 2018); to control attributes of responses (Xu et al.",
      "startOffset" : 44,
      "endOffset" : 117
    }, {
      "referenceID" : 32,
      "context" : ", 2019a); to improve diversity of responses (Li et al., 2015; Xing et al., 2017; Zhao et al., 2017; Tao et al., 2018); to control attributes of responses (Xu et al.",
      "startOffset" : 44,
      "endOffset" : 117
    }, {
      "referenceID" : 37,
      "context" : ", 2019a); to improve diversity of responses (Li et al., 2015; Xing et al., 2017; Zhao et al., 2017; Tao et al., 2018); to control attributes of responses (Xu et al.",
      "startOffset" : 44,
      "endOffset" : 117
    }, {
      "referenceID" : 26,
      "context" : ", 2019a); to improve diversity of responses (Li et al., 2015; Xing et al., 2017; Zhao et al., 2017; Tao et al., 2018); to control attributes of responses (Xu et al.",
      "startOffset" : 44,
      "endOffset" : 117
    }, {
      "referenceID" : 33,
      "context" : ", 2018); to control attributes of responses (Xu et al., 2019; Zhou et al., 2017; Wang et al., 2018; See et al., 2019); and to bias responses to some specific personas (Li et al.",
      "startOffset" : 44,
      "endOffset" : 117
    }, {
      "referenceID" : 40,
      "context" : ", 2018); to control attributes of responses (Xu et al., 2019; Zhou et al., 2017; Wang et al., 2018; See et al., 2019); and to bias responses to some specific personas (Li et al.",
      "startOffset" : 44,
      "endOffset" : 117
    }, {
      "referenceID" : 30,
      "context" : ", 2018); to control attributes of responses (Xu et al., 2019; Zhou et al., 2017; Wang et al., 2018; See et al., 2019); and to bias responses to some specific personas (Li et al.",
      "startOffset" : 44,
      "endOffset" : 117
    }, {
      "referenceID" : 19,
      "context" : ", 2018); to control attributes of responses (Xu et al., 2019; Zhou et al., 2017; Wang et al., 2018; See et al., 2019); and to bias responses to some specific personas (Li et al.",
      "startOffset" : 44,
      "endOffset" : 117
    }, {
      "referenceID" : 13,
      "context" : ", 2019); and to bias responses to some specific personas (Li et al., 2016; Zhang et al., 2018).",
      "startOffset" : 57,
      "endOffset" : 94
    }, {
      "referenceID" : 35,
      "context" : ", 2019); and to bias responses to some specific personas (Li et al., 2016; Zhang et al., 2018).",
      "startOffset" : 57,
      "endOffset" : 94
    }, {
      "referenceID" : 42,
      "context" : "Recently, grounding dialogue generation by extra knowledge has seemed promising to bridge the gap between conversation with existing systems and conversation with humans, and the knowledge could be obtained from knowledge graphs (Zhou et al., 2018b; Moon et al., 2019; Tuan et al., 2019), retrieved from unstructured documents (Dinan et al.",
      "startOffset" : 229,
      "endOffset" : 287
    }, {
      "referenceID" : 17,
      "context" : "Recently, grounding dialogue generation by extra knowledge has seemed promising to bridge the gap between conversation with existing systems and conversation with humans, and the knowledge could be obtained from knowledge graphs (Zhou et al., 2018b; Moon et al., 2019; Tuan et al., 2019), retrieved from unstructured documents (Dinan et al.",
      "startOffset" : 229,
      "endOffset" : 287
    }, {
      "referenceID" : 27,
      "context" : "Recently, grounding dialogue generation by extra knowledge has seemed promising to bridge the gap between conversation with existing systems and conversation with humans, and the knowledge could be obtained from knowledge graphs (Zhou et al., 2018b; Moon et al., 2019; Tuan et al., 2019), retrieved from unstructured documents (Dinan et al.",
      "startOffset" : 229,
      "endOffset" : 287
    }, {
      "referenceID" : 0,
      "context" : ", 2019), retrieved from unstructured documents (Dinan et al., 2019; Lian et al., 2019; Zhao et al., 2020a; Kim et al., 2020; Li et al., 2020) or visual background (Mostafazadeh et al.",
      "startOffset" : 47,
      "endOffset" : 141
    }, {
      "referenceID" : 15,
      "context" : ", 2019), retrieved from unstructured documents (Dinan et al., 2019; Lian et al., 2019; Zhao et al., 2020a; Kim et al., 2020; Li et al., 2020) or visual background (Mostafazadeh et al.",
      "startOffset" : 47,
      "endOffset" : 141
    }, {
      "referenceID" : 38,
      "context" : ", 2019), retrieved from unstructured documents (Dinan et al., 2019; Lian et al., 2019; Zhao et al., 2020a; Kim et al., 2020; Li et al., 2020) or visual background (Mostafazadeh et al.",
      "startOffset" : 47,
      "endOffset" : 141
    }, {
      "referenceID" : 9,
      "context" : ", 2019), retrieved from unstructured documents (Dinan et al., 2019; Lian et al., 2019; Zhao et al., 2020a; Kim et al., 2020; Li et al., 2020) or visual background (Mostafazadeh et al.",
      "startOffset" : 47,
      "endOffset" : 141
    }, {
      "referenceID" : 14,
      "context" : ", 2019), retrieved from unstructured documents (Dinan et al., 2019; Lian et al., 2019; Zhao et al., 2020a; Kim et al., 2020; Li et al., 2020) or visual background (Mostafazadeh et al.",
      "startOffset" : 47,
      "endOffset" : 141
    }, {
      "referenceID" : 29,
      "context" : "The idea of sequence modeling via segmentation (Wang et al., 2017) has attracted widespread attention in several natural language processing tasks.",
      "startOffset" : 47,
      "endOffset" : 66
    }, {
      "referenceID" : 11,
      "context" : "We exploit the pre-trained BART (Lewis et al., 2020) as the backbone of our architecture, which is pretrained using a variety of denoising objectives and achieves state-of-the-art results on a range of text generation tasks.",
      "startOffset" : 32,
      "endOffset" : 52
    }, {
      "referenceID" : 3,
      "context" : "We then apply variational approximation which gives the following evidence lower bound objective 3(ELBO) (Hoffman et al., 2013):",
      "startOffset" : 105,
      "endOffset" : 127
    }, {
      "referenceID" : 7,
      "context" : "Once we have the posterior distribution, we apply Gumbel-Softmax (Jang et al., 2016) to take samples of mt and zt.",
      "startOffset" : 65,
      "endOffset" : 84
    }, {
      "referenceID" : 16,
      "context" : "We first use StanfordNLP toolkit (Manning et al., 2014) to parse every response in the training set as a sequence of segments, and use M̃ = {m̃t} t=1 to denote the results of segmentation labeling.",
      "startOffset" : 33,
      "endOffset" : 55
    }, {
      "referenceID" : 0,
      "context" : "Wikipedia (Wizard) (Dinan et al., 2019) and CMU Document Grounded Conversations (CMU_DoG) (Zhou et al.",
      "startOffset" : 19,
      "endOffset" : 39
    }, {
      "referenceID" : 43,
      "context" : ", 2019) and CMU Document Grounded Conversations (CMU_DoG) (Zhou et al., 2018c).",
      "startOffset" : 58,
      "endOffset" : 78
    }, {
      "referenceID" : 14,
      "context" : "We choose the Reddit Corpus published by (Li et al., 2020) as D for pre-training.",
      "startOffset" : 41,
      "endOffset" : 58
    }, {
      "referenceID" : 2,
      "context" : "The agreement among all annotators is measured via Fleiss’ kappa (Fleiss, 1971).",
      "startOffset" : 65,
      "endOffset" : 79
    }, {
      "referenceID" : 14,
      "context" : "In zero-resource setting, we trained our model on the Reddit Corpus published by (Li et al., 2020) and tested on Wizard and CMU_DoG respectively.",
      "startOffset" : 81,
      "endOffset" : 98
    }, {
      "referenceID" : 25,
      "context" : "We exploit Roberta trained on the SST-2 training set (Socher et al., 2013) as the evaluator.",
      "startOffset" : 53,
      "endOffset" : 74
    }, {
      "referenceID" : 25,
      "context" : "To apply ECM on knowledge-grounded conversation, we label the sentiment category for each response with a classifier pre-trained on the SST (Socher et al., 2013) training set.",
      "startOffset" : 140,
      "endOffset" : 161
    } ],
    "year" : 0,
    "abstractText" : "Grounding dialogue generation by extra knowledge has shown great potentials towards building a system capable of replying with knowledgeable and engaging responses. Existing studies focus on how to synthesize a response with proper knowledge, yet neglect that the same knowledge could be expressed differently by speakers even under the same context. In this work, we mainly consider two aspects of knowledge expression, namely the structure of the response and style of the content in each part. We therefore introduce two sequential latent variables to represent the structure and the content style respectively. We propose a segmentation-based generation model and optimize the model by a variational approach to discover the underlying pattern of knowledge expression in a response. Evaluation results on two benchmarks indicate that our model can learn the structure style defined by a few examples and generate responses in desired content style.",
    "creator" : null
  }
}