{
  "name" : "ARR_2022_355_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Cross-document Misinformation Detection based on Event Graph Reasoning",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The dissemination of fake news has become an important social issue. For emergent complex events, human readers are usually exposed to multiple news documents, where some are real and others are fake. News documents from different sources naturally form a cluster of topically related documents. We notice that articles about the same topic may contain conflicting or complementary information, which can benefit the task of misinformation detection. An example is shown in Figure 1. As shown in the knowledge graph, the death of Rosanne Boyland in 2021 US Capitol attack is a shared event across all four documents. Each\n1We attach the codes in the submission and upload the datasets to google drive at LINK.\ndocument is internally consistent, which makes it difficult to identify misinformation when judging each news separately. However, the three real news documents complement each other’s statements regarding the death of Boyland, while the fake news document contradicts the other stories. Such crossdocument connections can be leveraged to help detect misinformation.\nMost existing work in fake news detection is limited to judging each document in isolation. In contrast, we propose a novel task of cross-document misinformation detection that aims to detect fake information from a cluster of topically related news documents. We conduct the task at both document level and event level. Each event describes a specific type of real-world event mentioned in the text (e.g., the death of Boyland in Figure 1), and usually involves certain participants to represent different aspects of the event (e.g., the death cause and the victim of the death event). Document-level detection aims to detect fake news documents. Eventlevel detection is a more fine-grained task that aims to detect fake events, thereby pinpointing specific fake information in news documents.\nExisting work on fine-grained misinformation detection detects fake knowledge triplets (Fung et al., 2021). However, we focus on identifying false events instead of relations or entities, because events are more important to storytelling, and easier to compare across multiple documents through cross-document coreference resolution.\nTo the best of our knowledge, there are no fake news detection datasets with clusters of topically related documents. Therefore, we construct 3 new benchmark datasets based on existing real news corpus with such clusters. Following Fung et al. (2021), we train a generator that generates a document from a knowledge graph (KG), and feed manipulated KGs into the generator to generate fake news documents. By tracking the manipulation operations, we also obtain supervision for\nevent-level detection. We further propose a detection system as shown in Figure 2. Given a cluster of documents, we first use an IE system (Lin et al., 2020) to construct a within-document KG for each document. Then, we connect the within-document KGs to form a crossdocument KG using cross-document event coreference resolution (Lai et al., 2021; Wen et al., 2021). Eventually, we use a heterogeneous graph neural network (GNN) to encode the cross-document KG and conduct detection at two levels.\nOur contributions are summarized as follows: 1. We propose the novel task of cross-document\nmisinformation detection, and conduct the task at two levels, document level and the more fine-grained event level. 2. We construct 3 new datasets for our proposed task based on existing document clusters categorized by topics. 3. We propose a detector that leverages crossdocument information and improve documentlevel detection by utilizing features produced by the event-level detector. Experiments on 3 datasets demonstrate that our method significantly outperforms existing methods."
    }, {
      "heading" : "2 Related Work",
      "text" : "Fake News Detection: Early work for fake news detection uses hand-crafted features to conduct document classification (Rubin et al., 2016; Wang, 2017; Rashkin et al., 2017; Pérez-Rosas et al., 2018; Sarkar et al., 2018; Atanasova et al., 2019). Recent work uses neural network such as RNN (Karimi\net al., 2018; Nasir et al., 2021) and Transformer (Zellers et al., 2019) to encode the news document. To model the internal structure of a news document, Karimi and Tang (2019) models the intersentence dependency tree, Vaibhav et al. (2019) and Hu et al. (2021) model the interactions between sentences, and Pan et al. (2018) and Fung et al. (2021) model the knowledge graph extracted by IE systems. Similar to our work, Hu et al. (2021) compares the news with external knowledge base (KB) to check for inconsistencies. However, the correlation between news and KB is not as close as the correlation between related news documents due to the incompleteness of these KBs. Other work utilizes additional information such as user engagements and behaviors on social media (Shu et al., 2019; Nguyen et al., 2020) and multi-modal features (Khattar et al., 2019; Tan et al., 2020; Fung et al., 2021). However, to the best of our knowledge, no published work has considered using cross-document inference for misinformation detection.\nIn addition to document-level detection, the task of fine-grained detection is also important but rarely explored. The most relevant work detects fake knowledge triplets extracted from each individual news article (Fung et al., 2021).\nAnother related task is fact verification which aims to verify a statement based on retrieved evidence. Fact verification has been explored in multiple domains such as general domain (Thorne et al., 2018), climate change (Diggelmann et al., 2020) and COVID-19 (Wadden et al., 2020; Saakyan\net al., 2021). However, fact verification focuses on short single-sentence statements, and cannot model the complicated internal structure of a news document.\nFake News Datasets: The main difficulty in constructing a fake news dataset is to obtain annotations. Rashkin et al. (2017) and Rubin et al. (2016) obtain labels from the source information, and consider news from reliable sources as real news, and unreliable sources as fake news. A potential issue is that the detector may only learn to distinguish the style of different news sources, rather than the authenticity of the content. Shu et al. (2020) collects annotations from fact-checking websites, and Pérez-Rosas et al. (2018) collects annotations via crowd-sourcing. These approaches produce datasets of higher quality, but require extensive manual efforts. With the development of powerful generative models capable of mimicking humanwritten news (Zellers et al., 2019), recent work has constructed datasets by using generative models to generate fake news (Tan et al., 2020; Fung et al., 2021). Fung et al. (2021) further generates fake news from manipulated KG, which we follow to construct our dataset."
    }, {
      "heading" : "3 Task Formulation",
      "text" : "Given a cluster of documents about the same story, the task of cross-document misinformation detection aims to detect the fake information included in\nthe cluster. Formally, let S = {d1, · · · ,dN} be the document cluster, and N = |S| be the size of the cluster. Some documents in S are real, while others are fake. From each document d ∈ S, we extract events E(d) = {e1, · · · , em}, where m = |E(d)| is the number of events in document d. In an extracted event set E(d), some events are real and others are fake.\nWe conduct the task of misinformation detection at two levels, document level and event level. Document-level detection aims to predict whether each document d ∈ S is real or fake. Event-level detection is a more fine-grained task which aims to predict whether each event e ∈ E(d),d ∈ S is real or fake. In the example in Figure 1, the die event in the fake news is fake, since it falsely describes Boyland being killed by the police but she actually died of drug overdose."
    }, {
      "heading" : "4 Approach",
      "text" : "An overview of our approach is shown in Figure 2. Given a cluster of documents, we first construct a within-document KG for each document using an IE system (Lin et al., 2020), and then connect the within-document KGs into a cross-document KG using cross-document event coreference resolution. Based on the cross-document KG, we use a hetereogeneous GNN (Schlichtkrull et al., 2018; Hu et al., 2019) to conduct detection. We further\nincorporate the results of event-level detection to help the document-level detector."
    }, {
      "heading" : "4.1 Knowledge Graph Construction",
      "text" : "Within-document KG: We first construct a within-document IE-based knowledge graph for each document. We leverage OneIE (Lin et al., 2020), a joint IE system, to extract the entities, relations and events contained in a given document. Then, we conduct entity linking and entity coreference resolution (Lee et al., 2017; Wen et al., 2021) to merge multiple mentions of the same entities together. Eventually, we obtain a withindocument KG where entities and events are nodes, relations are edges between entities, and arguments are edges between events and entities.\nCross-document KG: We leverage crossdocument event coreference resolution to connect the within-document KGs into a cross-document KG as illustrated in Figure 2. We employ a crossdocument event coreference resolution system (Lai et al., 2021; Wen et al., 2021) to identify clusters of events from multiple documents that refer to the same real-world events. The system utilizes both textual contexts of the event mentions and the symbolic features such as the event type information. An example of the detected event cluster is shown in Table 1, where the four events from four documents all refer to the same explosion attack on Venezuela President Nicolas Marduro. These four events contain complementary or contradictory details, which can be used for misinformation detection. For each event cluster, we add a node to represent the overall information of the real-world complex event corresponding to the cluster. Then, an edge is added between each event node and corresponding cluster node to allow reasoning among cross-document coreferential events.\nTo indicate which document each entity or event belongs to and capture the global information of each document, we further introduce a document node and connect it to the associated entity and event nodes for each document.\nThe resulting KG contains 4 types of nodes (i.e. entity nodes, event nodes, document nodes, and event cluster nodes) and 5 types of edges (i.e. relation edges, event argument edges, document-toentity edges, document-to-event edges, and edges connecting event nodes to event cluster nodes). Since all edges are directional, we add an inverse edge for each edge to propagate features along both\ndirections, and the final KG contains 10 edge types, accounting for the inverse of existing edge types.\nKG representation: To initialize the node and edge embeddings in the KG, we use BERT (Devlin et al., 2019) to encode the text descriptions of nodes or edges and take the embeddings of [CLS] tokens. For a document node, we use the entire document as the text description; for an entity node, we use its canonical mention; for an event node, we use the sentence where the event trigger occurs; and for an event cluster node, we average the embeddings of all events in the cluster as the embedding for the cluster node. For a relation edge or an event argument role edge, we use the linearized representation as the text description. For example, the Leadership relation between “Nicolas Maduro” and “Venezuelan” is described as “Nicolas Maduro, Leadership, Venezuelan” , and “guns” as the ExplosiveDevice argument of the DetonateExplode event is described as “DetonateExplode, ExplosiveDevice, guns”."
    }, {
      "heading" : "4.2 Knowledge Graph Encoder",
      "text" : "Heterogeneous GNN: Given the heterogeneous nature of the cross-document KG, we adopt a het-\nereogeneous GNN to encode the KG. Formally, let G denote the KG and V denote the nodes in G. We use R to denote the 10 types of edges as discussed in the previous section, and for each edge type r ∈ R, we use Gr to denote the subgraph of G that only contains edges of type r. At the l-th layer, the inputs are output features produced by the previous layer denoted as h(l−1)i , i ∈ V . For each edge type r ∈ R, we apply a separate GNN to encode Gr and produce a set of features denoted as h(l)i,r. Then, we aggregate the outputs for all edge types into the final output as follows:\nh (l) i = ∑ r∈R h (l) i,r/|R| (1)\nFor document-to-entity edges, document-toevent edges, and edges connecting event nodes to event cluster nodes, we use standard graph attention network (GAT). For relation edges and event argument edges, we apply edge-aware GAT to leverage the edge features. Here, the edge features refer to the BERT embeddings of text descriptions such as “Nicolas Maduro, Leadership, Venezuelan” or “DetonateExplode, ExplosiveDevice, guns” as described in Section 4.1. The remainder of Section 4.2 presents details of GAT and edge-aware GAT, i.e., how to produce h(l)i,r based on h (l−1) i .\nGraph attention network: For each given node, GAT aggregates the node features of its neighbors via attention mechanism (Velickovic et al., 2018). For a given edge type r ∈ R, let Ni,r denote the neighbors of node i in Gr. At the l-th layer, the attention weights αij are calculated as follows:\neij = LeakyReLU ( a> [ Wh (l−1) i ‖Wh (l−1) j ]) (2) αij = softmaxj(eij) = exp(eij)∑\nk∈Ni,r exp(eik) (3)\nwhere a and W are trainable parameters, and ‖ denotes the feature concatenation. The output features h(l)i,r for node i in Gr are calculated as follows:\nh (l) i,r = ∑ j∈Ni,r αijWh (l−1) j (4)\nEdge-aware graph attention network: Edgeaware GAT is an extension of GAT that considers edge features in addition to node features (Huang et al., 2020; Yasunaga et al., 2021). Let rij denote\nthe features of the edge between node i and j. For a given edge type r ∈ R, at the l-th layer, the attention weights αij are computed as follows:\nr′ij = W r [ h (l−1) i ‖h (l−1) j ‖rij ] (5)\nαij = softmaxj ( (WQh (l−1) i )(W Kr′ij) > ) (6)\nwhere Wr, WQ and WK are trainable parameters. The output features h(l)i,r for node i in Gr are computed as follows:\nh (l) i,r = ∑ j∈Ni,r αijW V r′ij (7)\nwhere WV is a learnable matrix."
    }, {
      "heading" : "4.3 Misinformation Detector",
      "text" : "Using the previously described graph encoder, we are able to obtain representations of the document and event nodes. We conduct document-level detection using the document node representations, and event-level detection using the event node representations. We separately train two detectors for these two levels of tasks.\nHowever, these two tasks are not mutually independent. Intuitively, document-level detection can benefit from the results of event-level detection, because the presence of a large number of false events indicates that the document is more likely to be fake. Therefore, we feed the results produced by a well-trained event-level detector into each layer of the document-level detector. Let ei denote the representations of node i produced by the event-level detector. At the l-th layer of the document-level detector, instead of using the output features of the previous layer h(l−1)i as input features, we use a linear projection of the concatenation of ei and h (l−1) i calculated as follows:\nW (l) proj [ ei‖h(l−1)i ] (8)\nwhere W(l)proj is a learnable matrix."
    }, {
      "heading" : "5 Dataset Construction",
      "text" : "Currently, there are no existing resources for crossdocument misinformation detection. We propose to construct datasets based on real news datasets with clustering information. For each cluster, we randomly sample 50% real news and replace them with manipulated fake news. Figure 3 shows an\noverview of fake news generation process, and more examples are presented in Appendix C.\nFollowing Fung et al. (2021), we train a KG-totext generator from the real news in our datasets, and generate fake news from manipulated KGs. The main differences between Fung et al. (2021)’s method and ours in terms of manipulating KG are: (1) we only conduct entity swapping, and do not adopt other types of manipulation including adding relations or events and subgraph replacement; (2) since we focus on events, we select entities to be replaced that are arguments of high-frequency events, instead of based on entity node degree; (3) we select entities from other documents in the same document cluster to replace the original entities, so that the entities before and after replacement are more similar.\nWe record the manipulation operations, and use a heuristic rule to obtain supervision for event-level detection as explained below. In a fake document, if an event involves manipulated entities as arguments, we consider this event as fake."
    }, {
      "heading" : "6 Experiments",
      "text" : ""
    }, {
      "heading" : "6.1 Data",
      "text" : "We construct 3 new benchmark datasets based on three datasets that naturally have clusters of topically related documents. IED dataset is a complex event corpus, where each complex event refers to a real-world story (e.g., Boston bombing) and is described by multiple documents (Li et al., 2021). Therefore, a complex event can be considered as a document cluster. TL17 and Crisis are two timeline summarization datasets containing multiple\n“timelines”. Each timeline contains multiple documents describing an evolving long-term event such as Influenza H1N1 and Egypt Revolution (Tran et al., 2013, 2015), and thus can be regarded as a document cluster. The detailed statistics of the original datasets are shown in Appendix A.\nHowever, the documents within the same cluster may not be closely related as the story described by a cluster can span up to three years. To obtain smaller and more closely related clusters, we split each timeline into smaller clusters of approximately size of 10 based on publication dates2. Then, we employ the methods described in Section 5 to generate fake documents. The statistics of the constructed datasets are in Table 2."
    }, {
      "heading" : "6.2 Experimental Settings",
      "text" : "For our proposed method, we use a 4-layer heterogeneous GAT and use bert-base-uncased to initialize the node and edge embeddings. For comparison, on the document-level detection task, we compare our method against two baselines: HDSF that models inter-sentence dependency tree (Karimi and Tang, 2019), and GROVER (Zellers et al., 2019), a Transformer-based detector. On the event-level detection task, since there are no existing methods, we compare our method against two heuristic baselines: random guessing and logistic regression. For logistic regression, we use handcrafted features to represent the event including the event type, the number of arguments, and the size of the event cluster. The detailed settings are presented in Appendix B.\nFor evaluation, we use F1 to evaluate documentlevel detection. Considering the label imbalance of event-level detection, we use F1 and AUC to evaluate event-level detection. For F1 metric, we\n2For IED, we randomly split the clusters due to the lack of publication dates.\nselect the optimal threshold on the validation set."
    }, {
      "heading" : "6.3 Document-level Detection Results",
      "text" : "Table 3 shows the results of document-level detection. Our method yields consistent improvements on all 3 datasets, and significantly outperforms the baselines that judge the authenticity for each document in isolation. To understand the effectiveness of each component, we conduct an ablation study and show the results in Table 4. We have the following findings:\n(1) We remove the edges between event nodes and event center nodes to analyze the impact of cross-document event coreference resolution, and find that such information significantly improves the performance on IED and TL17. We also train our detector with smaller clusters on TL17 and get worse performance (84.53% and 87.37% on clusters with size 1 and 2 respectively), which verifies that our model benefits from more cross-document information. The benefit of cross-document event coreference resolution is less significant on the large-scale Crisis dataset containing 1.7k documents. This may imply that cross-document misinformation detection is more useful for emerging new events where large-scale training data is not available.\n(2) Using the event-level detection results consistently improves the performance by 1-3 points\non all datasets. Since the projection modules introduce additional parameters, we further train a detector utilizing random features and find that using random features reduces the performance. This verifies that the improvement is brought by utilizing the knowledge learnt by the event-level detector rather than additional parameters."
    }, {
      "heading" : "6.4 Event-level Detection Results",
      "text" : "We track the manipulation operations during the dataset construction process, which allows us to obtain supervision for event-level detection. The results are shown in Table 5. Since there are no existing methods for this new task, we compare our method with two heuristic baselines, random guessing and logistic regression with hand-crafted event features. We find that random guessing performs the worst, logistic regression achieves satisfactory performance, and our method significantly outperforms these two baselines by a large margin. As in document-level detection, we conduct an ablation study on the use of cross-document event coreference resolution by removing edges between event nodes and event cluster nodes, and find that such information brings slight improvements over AUC metric."
    }, {
      "heading" : "6.5 Analysis and Discussion",
      "text" : "To demonstrate the benefits of using crossdocument event coreference resolution, we show an example in Figure 4, with 4 documents from the same cluster. As shown in Figure 4, by performing cross-document reasoning on events in the same event cluster, our model achieves better performance compared to Ours(ABLATION), i.e., our model without edges between event nodes and event cluster nodes.\nWe further analyze the remaining errors from our model. Figure 5 shows two representative cases\nwhere both document-level and event-level detectors fail to detect misinformation. In the first example, the manipulated entity is not captured by the IE system, and the error of IE system is propagated into the detector. A potential solution is to use an OpenIE system (Stanovsky et al., 2018) that is able to cover more event and entity types. The second example is a more challenging case where the event containing fake information is not mentioned by any other documents. This makes it difficult to either verify or disprove via cross-document reasoning, and may require the detector to actively search for external information related to the event.\nThere are some remaining challenges and limitations in our proposed methodology. First, some cross-document contradictions are difficult to capture by coreference resolution only. In the example in Figure 1, knowing that the police is unlikely to help and attack Boyland at the same time requires commonsense knowledge reasoning, which we leave as our future work. Second, an underlying assumption of our framework is that real news articles are consistent and complementary with each other, while fake news often contradicts each other. This assumption is true for our constructed datasets because we manipulate the KGs via random entity swapping. However, certain types of human-\nwritten fake news documents, such as conspiracy theories, tend to be closely related to each other and convey highly similar information because they share the same biases or aim to manipulate readers in the same way. This may limit the performance of our proposed system in real-world scenarios."
    }, {
      "heading" : "7 Conclusions and Future Work",
      "text" : "We are the first to study the new task of crossdocument misinformation detection. We conduct the task at two levels, document-level and the more fine-grained event-level, and construct 3 new datasets to handle the lack of training data. We further propose a graph-based cross-document detector that conducts reasoning over a cross-document knowledge graph and feed the event-level detection results into document-level detector. Experimental results show that our proposed method significantly outperforms existing methods.\nFor future work, we intend to extend our method to conduct cross-document reasoning over more types of information (e.g., entities and relations) in addition to events. We also plan to extend our method to multi-media news including texts, images, audios and videos, which requires the construction of cross-document multi-modal knowledge graphs. Finally, a challenging but important task is to construct a large-scale fake news detection corpus with human-written fake news containing document clusters and study our method in this scenario."
    }, {
      "heading" : "8 Ethical Considerations",
      "text" : "The goal of this work is to advance state-of-theart research in the field of misinformation detection, by analyzing multiple documents on the same topic. We build new benchmark datasets using a fake news generator, and propose a detector that achieves high performance in such scenarios. We have released the constructed datasets and detector codes in this submission as a useful reference for future research. We hope our work will encourage more efforts in this direction and benefit the community.\nHowever, as with any work that utilizes text generation, our work involves the risk of being applied to produce false information to mislead or manipulate readers. Therefore, we promise not to share codes or checkpoints of our generator to avoid potential negative consequences. To improve reproducibility, we describe the general idea and a few crucial details of the fake news generator."
    }, {
      "heading" : "A Statistics of Original Datasets",
      "text" : "Statistics of the original IED, TL17 and Crisis dataset are presented in Table 6."
    }, {
      "heading" : "B Experiment Details",
      "text" : "Detailed settings of our method: For our proposed method, we use a 4-layer heterogeneous GNN, where each GAT layer contains 8 heads. To initialize the node and edge embeddings, we use bert-base-uncased model with the feature\ndimension of 768. Our model contains 233M parameters.\nFor hyperparameters, we use a batch size of 16, and search the learning rate from {10−3, 10−4, 10−5} and the number of layers within {2, 4, 8}. Our best-found hyperparameters are a learning rate of 10−5 and a number of layer of 4. We train our model with Adam optimizer until convergence. To reduce computation cost, we freeze BERT’s parameters. The training process takes approximately 6 hours on a Tesla P100 GPU.\nDocument-level baselines: For document-level detection, we compare our method against two baselines: HDSF that models inter-sentence dependency tree (Karimi and Tang, 2019), and GROVER (Zellers et al., 2019), a Transformer-based detector. For HDSF, we use the implementation at https: //github.com/hamidkarimi/HDSF/. For GROVER, we use the implementation at https: //github.com/rowanz/grover and experiment with two settings, medium setting and mega setting. Since fine-tuning the GROVER model is computationally expensive, we use GROVER in the zero-shot setting.\nEvent-level baselines: For event-level detection, since there are no existing methods, we use two heuristic baselines, random guessing and logistic regression. In random guessing, for each event, we randomly draws a value from a uniform distribution between [0, 1] as the probability that the event is false. In logistic regression, we use the following features: event type (represented by onehot feature), number of arguments, and number of coreferential events. The features are normalized on the training set. We use the implementation of logistic regression and default parameters provided by sklearn."
    }, {
      "heading" : "C Examples of Fake News Generation",
      "text" : "We present two examples of generated fake news in Figure 6 and 7, including the original real news, manipulated KG, and generated fake news. The\ngenerated fake news conveys the manipulated misinformation and meanwhile is stylistically similar to real news."
    }, {
      "heading" : "D Scientific Artifacts",
      "text" : "In this work, we use three datasets including IED (Li et al., 2021), TL17 (Tran et al., 2013) and Crisis (Tran et al., 2015). There are no licenses or terms of use associated with all three datasets.\nWe use five software. Among them, HDSF (Karimi and Tang, 2019), OneIE (Lin et al., 2020) and RESIN (Wen et al., 2021) have no license or terms of use. GROVER (Zellers et al., 2019) and huggingface are licensed under the Apache License 2.0. Fairseq (Ott et al., 2019) is licenced under the MIT License.\nWe use two models, BERT (Devlin et al., 2019) and BART (Lewis et al., 2020), licenced under the Apache License 2.0 and the MIT License respectively.\nIn summary, all artifacts involved either have no associated licenses or terms of use, or are licensed under the Apache License 2.0 or the MIT License. Both the Apache License 2.0 or the MIT License permit commercial and private use. Therefore, our use is consistent with their intended use. We will release the dataset and software with licenses compatible with the original access conditions."
    } ],
    "references" : [ {
      "title" : "Automatic fact-checking using context and discourse information",
      "author" : [ "Pepa Atanasova", "Preslav Nakov", "Lluís Màrquez", "Alberto Barrón-Cedeño", "Georgi Karadzhov", "Tsvetomila Mihaylova", "Mitra Mohtarami", "James R. Glass." ],
      "venue" : "ACM J. Data Inf. Qual.,",
      "citeRegEx" : "Atanasova et al\\.,? 2019",
      "shortCiteRegEx" : "Atanasova et al\\.",
      "year" : 2019
    }, {
      "title" : "BERT: pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "CLIMATE-FEVER: A dataset for verification of real-world climate claims",
      "author" : [ "Thomas Diggelmann", "Jordan L. Boyd-Graber", "Jannis Bulian", "Massimiliano Ciaramita", "Markus Leippold." ],
      "venue" : "CoRR, abs/2012.00614.",
      "citeRegEx" : "Diggelmann et al\\.,? 2020",
      "shortCiteRegEx" : "Diggelmann et al\\.",
      "year" : 2020
    }, {
      "title" : "Infosurgeon: Cross-media fine-grained information consistency checking for fake news",
      "author" : [ "Yi Fung", "Christopher Thomas", "Revanth Gangi Reddy", "Sandeep Polisetty", "Heng Ji", "Shih-Fu Chang", "Kathleen R. McKeown", "Mohit Bansal", "Avi Sil" ],
      "venue" : null,
      "citeRegEx" : "Fung et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Fung et al\\.",
      "year" : 2021
    }, {
      "title" : "Heterogeneous graph attention networks for semi-supervised short text classification",
      "author" : [ "Linmei Hu", "Tianchi Yang", "Chuan Shi", "Houye Ji", "Xiaoli Li." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and",
      "citeRegEx" : "Hu et al\\.,? 2019",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2019
    }, {
      "title" : "Compare to the knowledge: Graph neural fake news detection with external knowledge",
      "author" : [ "Linmei Hu", "Tianchi Yang", "Luhao Zhang", "Wanjun Zhong", "Duyu Tang", "Chuan Shi", "Nan Duan", "Ming Zhou." ],
      "venue" : "Proceedings of the 59th Annual Meeting of",
      "citeRegEx" : "Hu et al\\.,? 2021",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2021
    }, {
      "title" : "Biomedical event extraction on graph edgeconditioned attention networks with hierarchical knowledge graphs",
      "author" : [ "Kung-Hsiang Huang", "Mu Yang", "Nanyun Peng." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020, On-",
      "citeRegEx" : "Huang et al\\.,? 2020",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2020
    }, {
      "title" : "Multi-source multi-class fake news detection",
      "author" : [ "Hamid Karimi", "Proteek Roy", "Sari Saba-Sadiya", "Jiliang Tang." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, COLING 2018, Santa Fe, New Mexico, USA, August 20-26,",
      "citeRegEx" : "Karimi et al\\.,? 2018",
      "shortCiteRegEx" : "Karimi et al\\.",
      "year" : 2018
    }, {
      "title" : "Learning hierarchical discourse-level structure for fake news detection",
      "author" : [ "Hamid Karimi", "Jiliang Tang." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
      "citeRegEx" : "Karimi and Tang.,? 2019",
      "shortCiteRegEx" : "Karimi and Tang.",
      "year" : 2019
    }, {
      "title" : "MVAE: multimodal variational autoencoder for fake news detection",
      "author" : [ "Dhruv Khattar", "Jaipal Singh Goud", "Manish Gupta", "Vasudeva Varma." ],
      "venue" : "The World Wide Web Conference, WWW 2019, San Francisco, CA, USA, May 13-17, 2019, pages 2915–2921.",
      "citeRegEx" : "Khattar et al\\.,? 2019",
      "shortCiteRegEx" : "Khattar et al\\.",
      "year" : 2019
    }, {
      "title" : "A context-dependent gated module for incorporating symbolic semantics into event coreference resolution",
      "author" : [ "Tuan Manh Lai", "Heng Ji", "Trung Bui", "Quan Hung Tran", "Franck Dernoncourt", "Walter Chang." ],
      "venue" : "Proceedings of the 2021 Conference of the",
      "citeRegEx" : "Lai et al\\.,? 2021",
      "shortCiteRegEx" : "Lai et al\\.",
      "year" : 2021
    }, {
      "title" : "End-to-end neural coreference resolution",
      "author" : [ "Kenton Lee", "Luheng He", "Mike Lewis", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-",
      "citeRegEx" : "Lee et al\\.,? 2017",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2017
    }, {
      "title" : "BART: denoising sequence-to-sequence pretraining for natural language",
      "author" : [ "Mike Lewis", "Yinhan Liu", "Naman Goyal", "Marjan Ghazvininejad", "Abdelrahman Mohamed", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer" ],
      "venue" : null,
      "citeRegEx" : "Lewis et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Lewis et al\\.",
      "year" : 2020
    }, {
      "title" : "Future is not one-dimensional: Graph modeling based complex event schema induction for event prediction",
      "author" : [ "Manling Li", "Sha Li", "Zhenhailong Wang", "Lifu Huang", "Kyunghyun Cho", "Heng Ji", "Jiawei Han", "Clare R. Voss." ],
      "venue" : "CoRR, abs/2104.06344.",
      "citeRegEx" : "Li et al\\.,? 2021",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2021
    }, {
      "title" : "A joint neural model for information extraction with global features",
      "author" : [ "Ying Lin", "Heng Ji", "Fei Huang", "Lingfei Wu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020, pages",
      "citeRegEx" : "Lin et al\\.,? 2020",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2020
    }, {
      "title" : "Fake news detection: A hybrid cnnrnn based deep learning approach",
      "author" : [ "Jamal Abdul Nasir", "Osama Subhani Khan", "Iraklis Varlamis." ],
      "venue" : "International Journal of Information Management Data Insights, 1(1):100007.",
      "citeRegEx" : "Nasir et al\\.,? 2021",
      "shortCiteRegEx" : "Nasir et al\\.",
      "year" : 2021
    }, {
      "title" : "FANG: leveraging social context for fake news detection using graph representation",
      "author" : [ "Van-Hoang Nguyen", "Kazunari Sugiyama", "Preslav Nakov", "Min-Yen Kan." ],
      "venue" : "CIKM ’20: The 29th ACM International Conference on Information and Knowledge",
      "citeRegEx" : "Nguyen et al\\.,? 2020",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2020
    }, {
      "title" : "fairseq: A fast, extensible toolkit for sequence modeling",
      "author" : [ "Myle Ott", "Sergey Edunov", "Alexei Baevski", "Angela Fan", "Sam Gross", "Nathan Ng", "David Grangier", "Michael Auli." ],
      "venue" : "Proceedings of NAACL-HLT 2019: Demonstrations.",
      "citeRegEx" : "Ott et al\\.,? 2019",
      "shortCiteRegEx" : "Ott et al\\.",
      "year" : 2019
    }, {
      "title" : "Content based fake news detection using knowledge graphs",
      "author" : [ "Jeff Z. Pan", "Siyana Pavlova", "Chenxi Li", "Ningxi Li", "Yangmei Li", "Jinshuo Liu." ],
      "venue" : "The Semantic Web - ISWC 2018 - 17th International Semantic Web Conference, Monterey, CA, USA, Octo-",
      "citeRegEx" : "Pan et al\\.,? 2018",
      "shortCiteRegEx" : "Pan et al\\.",
      "year" : 2018
    }, {
      "title" : "Automatic detection of fake news",
      "author" : [ "Verónica Pérez-Rosas", "Bennett Kleinberg", "Alexandra Lefevre", "Rada Mihalcea." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, COLING 2018, Santa Fe, New Mexico, USA,",
      "citeRegEx" : "Pérez.Rosas et al\\.,? 2018",
      "shortCiteRegEx" : "Pérez.Rosas et al\\.",
      "year" : 2018
    }, {
      "title" : "Truth of varying shades: Analyzing language in fake news and political fact-checking",
      "author" : [ "Hannah Rashkin", "Eunsol Choi", "Jin Yea Jang", "Svitlana Volkova", "Yejin Choi." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Rashkin et al\\.,? 2017",
      "shortCiteRegEx" : "Rashkin et al\\.",
      "year" : 2017
    }, {
      "title" : "Fake news or truth? using satirical cues to detect potentially misleading news",
      "author" : [ "Victoria L Rubin", "Niall Conroy", "Yimin Chen", "Sarah Cornwell." ],
      "venue" : "Proceedings of the second workshop on computational approaches to deception detection, pages 7–17.",
      "citeRegEx" : "Rubin et al\\.,? 2016",
      "shortCiteRegEx" : "Rubin et al\\.",
      "year" : 2016
    }, {
      "title" : "Covid-fact: Fact extraction and verification of real-world claims on COVID-19 pandemic",
      "author" : [ "Arkadiy Saakyan", "Tuhin Chakrabarty", "Smaranda Muresan." ],
      "venue" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguis-",
      "citeRegEx" : "Saakyan et al\\.,? 2021",
      "shortCiteRegEx" : "Saakyan et al\\.",
      "year" : 2021
    }, {
      "title" : "Attending sentences to detect satirical fake news",
      "author" : [ "Sohan De Sarkar", "Fan Yang", "Arjun Mukherjee." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, COLING 2018, Santa Fe, New Mexico, USA, August 20-26,",
      "citeRegEx" : "Sarkar et al\\.,? 2018",
      "shortCiteRegEx" : "Sarkar et al\\.",
      "year" : 2018
    }, {
      "title" : "Modeling relational data with graph convolutional networks",
      "author" : [ "Michael Sejr Schlichtkrull", "Thomas N. Kipf", "Peter Bloem", "Rianne van den Berg", "Ivan Titov", "Max Welling." ],
      "venue" : "The Semantic Web - 15th International Conference, ESWC 2018, Heraklion,",
      "citeRegEx" : "Schlichtkrull et al\\.,? 2018",
      "shortCiteRegEx" : "Schlichtkrull et al\\.",
      "year" : 2018
    }, {
      "title" : "Fakenewsnet: A data repository with news content, social context, and spatiotemporal information for studying fake news on social media",
      "author" : [ "Kai Shu", "Deepak Mahudeswaran", "Suhang Wang", "Dongwon Lee", "Huan Liu." ],
      "venue" : "Big Data, 8(3):171–188.",
      "citeRegEx" : "Shu et al\\.,? 2020",
      "shortCiteRegEx" : "Shu et al\\.",
      "year" : 2020
    }, {
      "title" : "Beyond news contents: The role of social context for fake news detection",
      "author" : [ "Kai Shu", "Suhang Wang", "Huan Liu." ],
      "venue" : "Proceedings of the Twelfth ACM International Conference on Web Search and Data Mining, WSDM 2019, Melbourne, VIC, Australia,",
      "citeRegEx" : "Shu et al\\.,? 2019",
      "shortCiteRegEx" : "Shu et al\\.",
      "year" : 2019
    }, {
      "title" : "Supervised open information extraction",
      "author" : [ "Gabriel Stanovsky", "Julian Michael", "Luke Zettlemoyer", "Ido Dagan." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human",
      "citeRegEx" : "Stanovsky et al\\.,? 2018",
      "shortCiteRegEx" : "Stanovsky et al\\.",
      "year" : 2018
    }, {
      "title" : "Detecting cross-modal inconsistency to defend against neural fake news",
      "author" : [ "Reuben Tan", "Bryan A. Plummer", "Kate Saenko." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online,",
      "citeRegEx" : "Tan et al\\.,? 2020",
      "shortCiteRegEx" : "Tan et al\\.",
      "year" : 2020
    }, {
      "title" : "FEVER: a large-scale dataset for fact extraction and verification",
      "author" : [ "James Thorne", "Andreas Vlachos", "Christos Christodoulopoulos", "Arpit Mittal." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the",
      "citeRegEx" : "Thorne et al\\.,? 2018",
      "shortCiteRegEx" : "Thorne et al\\.",
      "year" : 2018
    }, {
      "title" : "Timeline summarization from relevant headlines",
      "author" : [ "Giang Binh Tran", "Mohammad Alrifai", "Eelco Herder." ],
      "venue" : "Advances in Information Retrieval - 37th European Conference on IR Research, ECIR 2015, Vienna, Austria, March 29 - April 2,",
      "citeRegEx" : "Tran et al\\.,? 2015",
      "shortCiteRegEx" : "Tran et al\\.",
      "year" : 2015
    }, {
      "title" : "Predicting relevant news events for timeline summaries",
      "author" : [ "Giang Binh Tran", "Mohammad Alrifai", "Dat Quoc Nguyen." ],
      "venue" : "22nd International World Wide Web Conference, WWW ’13, Rio de Janeiro, Brazil, May 13-17, 2013, Companion Volume, pages",
      "citeRegEx" : "Tran et al\\.,? 2013",
      "shortCiteRegEx" : "Tran et al\\.",
      "year" : 2013
    }, {
      "title" : "Do sentence interactions matter? leveraging sentence level representations for fake news classification",
      "author" : [ "Vaibhav Vaibhav", "Raghuram Mandyam Annasamy", "Eduard H. Hovy." ],
      "venue" : "Proceedings of the Thirteenth Workshop on Graph-Based Methods for Nat-",
      "citeRegEx" : "Vaibhav et al\\.,? 2019",
      "shortCiteRegEx" : "Vaibhav et al\\.",
      "year" : 2019
    }, {
      "title" : "Graph attention networks",
      "author" : [ "Petar Velickovic", "Guillem Cucurull", "Arantxa Casanova", "Adriana Romero", "Pietro Liò", "Yoshua Bengio." ],
      "venue" : "6th International Conference on Learning Representations, ICLR 2018, Vancouver, BC, Canada, April 30 - May",
      "citeRegEx" : "Velickovic et al\\.,? 2018",
      "shortCiteRegEx" : "Velickovic et al\\.",
      "year" : 2018
    }, {
      "title" : "Fact or fiction: Verifying scientific claims",
      "author" : [ "Hannaneh Hajishirzi." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, pages 7534–7550. Association for",
      "citeRegEx" : "Hajishirzi.,? 2020",
      "shortCiteRegEx" : "Hajishirzi.",
      "year" : 2020
    }, {
      "title" : "liar, liar pants on fire\": A new benchmark dataset for fake news detection",
      "author" : [ "William Yang Wang." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 2:",
      "citeRegEx" : "Wang.,? 2017",
      "shortCiteRegEx" : "Wang.",
      "year" : 2017
    }, {
      "title" : "RESIN: A dockerized schemaguided cross-document cross-lingual cross-media information extraction and event tracking system",
      "author" : [ "Brown", "Martha Palmer", "Chris Callison-Burch", "Carl Vondrick", "Jiawei Han", "Dan Roth", "Shih-Fu Chang", "Heng Ji." ],
      "venue" : "In",
      "citeRegEx" : "Brown et al\\.,? 2021",
      "shortCiteRegEx" : "Brown et al\\.",
      "year" : 2021
    }, {
      "title" : "QAGNN: reasoning with language models and knowledge graphs for question answering",
      "author" : [ "Michihiro Yasunaga", "Hongyu Ren", "Antoine Bosselut", "Percy Liang", "Jure Leskovec." ],
      "venue" : "Proceedings of the 2021 Conference of the North American Chap-",
      "citeRegEx" : "Yasunaga et al\\.,? 2021",
      "shortCiteRegEx" : "Yasunaga et al\\.",
      "year" : 2021
    }, {
      "title" : "Defending against neural fake news",
      "author" : [ "Rowan Zellers", "Ari Holtzman", "Hannah Rashkin", "Yonatan Bisk", "Ali Farhadi", "Franziska Roesner", "Yejin Choi." ],
      "venue" : "Advances in Neural Information Processing Systems 32: Annual Conference on Neural Infor-",
      "citeRegEx" : "Zellers et al\\.,? 2019",
      "shortCiteRegEx" : "Zellers et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 3,
      "context" : "Existing work on fine-grained misinformation detection detects fake knowledge triplets (Fung et al., 2021).",
      "startOffset" : 87,
      "endOffset" : 106
    }, {
      "referenceID" : 14,
      "context" : "Given a cluster of documents, we first use an IE system (Lin et al., 2020) to construct a within-document KG for each document.",
      "startOffset" : 56,
      "endOffset" : 74
    }, {
      "referenceID" : 21,
      "context" : "Fake News Detection: Early work for fake news detection uses hand-crafted features to conduct document classification (Rubin et al., 2016; Wang, 2017; Rashkin et al., 2017; Pérez-Rosas et al., 2018; Sarkar et al., 2018; Atanasova et al., 2019).",
      "startOffset" : 118,
      "endOffset" : 243
    }, {
      "referenceID" : 35,
      "context" : "Fake News Detection: Early work for fake news detection uses hand-crafted features to conduct document classification (Rubin et al., 2016; Wang, 2017; Rashkin et al., 2017; Pérez-Rosas et al., 2018; Sarkar et al., 2018; Atanasova et al., 2019).",
      "startOffset" : 118,
      "endOffset" : 243
    }, {
      "referenceID" : 20,
      "context" : "Fake News Detection: Early work for fake news detection uses hand-crafted features to conduct document classification (Rubin et al., 2016; Wang, 2017; Rashkin et al., 2017; Pérez-Rosas et al., 2018; Sarkar et al., 2018; Atanasova et al., 2019).",
      "startOffset" : 118,
      "endOffset" : 243
    }, {
      "referenceID" : 19,
      "context" : "Fake News Detection: Early work for fake news detection uses hand-crafted features to conduct document classification (Rubin et al., 2016; Wang, 2017; Rashkin et al., 2017; Pérez-Rosas et al., 2018; Sarkar et al., 2018; Atanasova et al., 2019).",
      "startOffset" : 118,
      "endOffset" : 243
    }, {
      "referenceID" : 23,
      "context" : "Fake News Detection: Early work for fake news detection uses hand-crafted features to conduct document classification (Rubin et al., 2016; Wang, 2017; Rashkin et al., 2017; Pérez-Rosas et al., 2018; Sarkar et al., 2018; Atanasova et al., 2019).",
      "startOffset" : 118,
      "endOffset" : 243
    }, {
      "referenceID" : 0,
      "context" : "Fake News Detection: Early work for fake news detection uses hand-crafted features to conduct document classification (Rubin et al., 2016; Wang, 2017; Rashkin et al., 2017; Pérez-Rosas et al., 2018; Sarkar et al., 2018; Atanasova et al., 2019).",
      "startOffset" : 118,
      "endOffset" : 243
    }, {
      "referenceID" : 7,
      "context" : "Recent work uses neural network such as RNN (Karimi et al., 2018; Nasir et al., 2021) and Transformer (Zellers et al.",
      "startOffset" : 44,
      "endOffset" : 85
    }, {
      "referenceID" : 15,
      "context" : "Recent work uses neural network such as RNN (Karimi et al., 2018; Nasir et al., 2021) and Transformer (Zellers et al.",
      "startOffset" : 44,
      "endOffset" : 85
    }, {
      "referenceID" : 38,
      "context" : ", 2021) and Transformer (Zellers et al., 2019) to encode the news document.",
      "startOffset" : 24,
      "endOffset" : 46
    }, {
      "referenceID" : 26,
      "context" : "work utilizes additional information such as user engagements and behaviors on social media (Shu et al., 2019; Nguyen et al., 2020) and multi-modal features (Khattar et al.",
      "startOffset" : 92,
      "endOffset" : 131
    }, {
      "referenceID" : 16,
      "context" : "work utilizes additional information such as user engagements and behaviors on social media (Shu et al., 2019; Nguyen et al., 2020) and multi-modal features (Khattar et al.",
      "startOffset" : 92,
      "endOffset" : 131
    }, {
      "referenceID" : 3,
      "context" : "The most relevant work detects fake knowledge triplets extracted from each individual news article (Fung et al., 2021).",
      "startOffset" : 99,
      "endOffset" : 118
    }, {
      "referenceID" : 29,
      "context" : "Fact verification has been explored in multiple domains such as general domain (Thorne et al., 2018), climate change (Diggelmann et al.",
      "startOffset" : 79,
      "endOffset" : 100
    }, {
      "referenceID" : 2,
      "context" : ", 2018), climate change (Diggelmann et al., 2020) and COVID-19 (Wadden et al.",
      "startOffset" : 24,
      "endOffset" : 49
    }, {
      "referenceID" : 38,
      "context" : "With the development of powerful generative models capable of mimicking humanwritten news (Zellers et al., 2019), recent work has constructed datasets by using generative models to generate fake news (Tan et al.",
      "startOffset" : 90,
      "endOffset" : 112
    }, {
      "referenceID" : 28,
      "context" : ", 2019), recent work has constructed datasets by using generative models to generate fake news (Tan et al., 2020; Fung et al., 2021).",
      "startOffset" : 95,
      "endOffset" : 132
    }, {
      "referenceID" : 3,
      "context" : ", 2019), recent work has constructed datasets by using generative models to generate fake news (Tan et al., 2020; Fung et al., 2021).",
      "startOffset" : 95,
      "endOffset" : 132
    }, {
      "referenceID" : 14,
      "context" : "Given a cluster of documents, we first construct a within-document KG for each document using an IE system (Lin et al., 2020), and then connect the within-document KGs into a cross-document KG using cross-document event coreference resolution.",
      "startOffset" : 107,
      "endOffset" : 125
    }, {
      "referenceID" : 24,
      "context" : "Based on the cross-document KG, we use a hetereogeneous GNN (Schlichtkrull et al., 2018; Hu et al., 2019) to conduct detection.",
      "startOffset" : 60,
      "endOffset" : 105
    }, {
      "referenceID" : 4,
      "context" : "Based on the cross-document KG, we use a hetereogeneous GNN (Schlichtkrull et al., 2018; Hu et al., 2019) to conduct detection.",
      "startOffset" : 60,
      "endOffset" : 105
    }, {
      "referenceID" : 14,
      "context" : "We leverage OneIE (Lin et al., 2020), a joint IE system, to extract the entities, relations and events contained in a given document.",
      "startOffset" : 18,
      "endOffset" : 36
    }, {
      "referenceID" : 11,
      "context" : "tity coreference resolution (Lee et al., 2017; Wen et al., 2021) to merge multiple mentions of the same entities together.",
      "startOffset" : 28,
      "endOffset" : 64
    }, {
      "referenceID" : 10,
      "context" : "We employ a crossdocument event coreference resolution system (Lai et al., 2021; Wen et al., 2021) to identify clusters",
      "startOffset" : 62,
      "endOffset" : 98
    }, {
      "referenceID" : 33,
      "context" : "GAT aggregates the node features of its neighbors via attention mechanism (Velickovic et al., 2018).",
      "startOffset" : 74,
      "endOffset" : 99
    }, {
      "referenceID" : 6,
      "context" : "Edge-aware graph attention network: Edgeaware GAT is an extension of GAT that considers edge features in addition to node features (Huang et al., 2020; Yasunaga et al., 2021).",
      "startOffset" : 131,
      "endOffset" : 174
    }, {
      "referenceID" : 37,
      "context" : "Edge-aware graph attention network: Edgeaware GAT is an extension of GAT that considers edge features in addition to node features (Huang et al., 2020; Yasunaga et al., 2021).",
      "startOffset" : 131,
      "endOffset" : 174
    }, {
      "referenceID" : 13,
      "context" : ", Boston bombing) and is described by multiple documents (Li et al., 2021).",
      "startOffset" : 57,
      "endOffset" : 74
    }, {
      "referenceID" : 8,
      "context" : "For comparison, on the document-level detection task, we compare our method against two baselines: HDSF that models inter-sentence dependency tree (Karimi and Tang, 2019), and GROVER (Zellers et al.",
      "startOffset" : 147,
      "endOffset" : 170
    }, {
      "referenceID" : 38,
      "context" : "For comparison, on the document-level detection task, we compare our method against two baselines: HDSF that models inter-sentence dependency tree (Karimi and Tang, 2019), and GROVER (Zellers et al., 2019), a Transformer-based detector.",
      "startOffset" : 183,
      "endOffset" : 205
    }, {
      "referenceID" : 8,
      "context" : "We report the F1 scores of HDSF (Karimi and Tang, 2019), GROVER of two settings (Zellers et al.",
      "startOffset" : 32,
      "endOffset" : 55
    }, {
      "referenceID" : 38,
      "context" : "We report the F1 scores of HDSF (Karimi and Tang, 2019), GROVER of two settings (Zellers et al., 2019), and our proposed method.",
      "startOffset" : 80,
      "endOffset" : 102
    }, {
      "referenceID" : 27,
      "context" : "A potential solution is to use an OpenIE system (Stanovsky et al., 2018) that is able to cover more event and entity types.",
      "startOffset" : 48,
      "endOffset" : 72
    } ],
    "year" : 0,
    "abstractText" : "For emerging events, human readers are often exposed to both real news and fake news. Multiple news articles may contain complementary or contradictory information that readers can leverage to help detect fake news. Inspired by this process, we propose a novel task of cross-document misinformation detection. Given a cluster of topically related news documents, we aim to detect misinformation at both document level and a more finegrained level, event level. Due to the lack of data, we generate fake news by manipulating real news, and construct 3 new datasets with 422, 276, and 1, 413 clusters of topically related documents, respectively. We further propose a graph-based detector that constructs a cross-document knowledge graph using cross-document event coreference resolution and employs a heterogeneous graph neural network to conduct detection at two levels. We then feed the event-level detection results into the document-level detector. Experimental results show that our proposed method significantly outperforms existing methods by up to 7 F1 points on this new task.1",
    "creator" : null
  }
}