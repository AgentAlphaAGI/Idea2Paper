{
  "name" : "ARR_2022_301_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Time Waits for No One! Analysis and Challenges of Temporal Misalignment",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Changes in the ways a language is used over time are widely attested (Labov, 1994; Altmann et al., 2009; Eisenstein et al., 2014); how these changes will affect NLP systems built from text corpora, and in particular their long-term performance, is not as well understood.\nThis paper focuses on temporal misalignment, i.e., where training and evaluation datasets are drawn from different periods of time. In today’s pretraining-finetuning paradigm, this misalignment can affect a pretrained language model—a situation that has received recent attention (Jaidka et al., 2018; Lazaridou et al., 2021; Peters et al., 2018; Raffel et al., 2020; Röttger and Pierrehumbert, 2021)—or the finetuned task model, or both. We\n1Anonymized GitHub Repo\nsuspect that the effects of temporal misalignment will vary depending on the genre or domain of the task’s text, the nature of that task or application, and the specific time periods.\nWe focus primarily on measuring the extent of temporal misalignment on task performance. We consider eight tasks, each with datasets that span at least five years (§2.4), ranging from summarization to entity typing, a subproblem of entity recognition (Grishman and Borthwick, 1999). Notably, these task datasets span four different domains: social media, scientific articles, news, and reviews. We introduce an easily interpretable metric that summarizes the rate at which task performance degrades as function of time.\nOur research questions are:\n(Q1) how does temporal misalignment affect downstream tasks over time? (Q2) how does sensitivity to temporal misalignment vary with text domain and task? (Q3) how does temporal misalignment affect language models across domains and spans of time? (Q4) how effective is temporal adaptation, or additional pretraining on a target year, in mitigating temporal misalignment?\nWe find that temporal misalignment affects both language model generalization and task performance. We find considerable variation in degradation across text domains (§3.2) and tasks (§3.1). Over 5 years, classifiers’ F1 score can deteriorate as much as 40 points (political affiliation in Twitter) or as little as 1 point (Yelp review ratings). Two distinct tasks defined on the same domain can show different levels of degradation over time.\nWe explore domain adaptation of a language model, using temporally selected (unannotated) data, as a way to curtail temporal misalignment (Röttger and Pierrehumbert, 2021). We find that this does not offer much benefit, especially relative\nto performance that can be achieved by finetuning on temporally suitable data (i.e., from the same time period as the test data). We conclude that temporal adaptation should not be seen as a substitute for finding temporally aligned labeled data.\nThe evidence and benchmarks we offer motivate careful attention to temporal misalignment in many applications of NLP models, and further research on solutions to this problem.\nContributions. To facilitate the study of temporal misalignment phenomenon on downstream applications, we compile a suite of eight diverse tasks across four important language domains. We define an interpretable metric that summarizes temporal misalignment of a model on a task with timestamped data. Our experiments reveal key factors in how temporal misalignment affects NLP model performance."
    }, {
      "heading" : "2 Methodology Overview",
      "text" : "We begin by defining the scope of our study."
    }, {
      "heading" : "2.1 Learning Pipeline",
      "text" : "We consider a process for building an NLP model that is in widespread use by the research community, illustrated in Fig. 1. First, a (neural network) language model (LM) is pretrained on a large text collection that is not necessarily selected for topical or temporal proximity to the text of the target application (our focus is on GPT-2; Brown et al., 2020). Second, the LM is optionally adapted by continued training on a collection strategically curated for closer proximity to the target (Beltagy et al., 2019); this stage is often referred to as domain-adaptive pretraining (DAPT; Gururangan et al., 2020). Finally, the model is finetuned to minimize a taskspecific loss, using labeled data representative of what the model is expected to be exposed to in testing or deployment.\nWe study two ways in which temporal misalignment might affect the pipeline’s performance as well as straightforward ways to mitigate them.\nTask Shift and Temporal Finetuning The relationship between text inputs and target outputs may\nchange over time. To the extent that this occurs, annotated datasets used to train NLP systems in the finetuning stage will become stale over time. Due to this temporal misalignment, performance will degrade after deployment, or any in evaluations that use test data temporally distant from the training data. We seek to quantify this degradation across a range of text domains and tasks.\nLanguage Shift and Temporal Domain Adaptation Changes in language use can cause a pretrained LM, which commonly serves as the backbone for most modern NLP models, to become stale over time (Lazaridou et al., 2021), regardless of the end task. Lazaridou et al. (2021) explored temporal adaptation, continuing LM training on new text data. This is essentially the same procedure as DAPT, where the data is selected by time period. Their work focused on the LM alone, not downstream tasks; we consider both here.\nRöttger and Pierrehumbert (2021), the closest to our work, studied temporal adaptation in conjunction to finetuning for a classification task over Reddit data. They conclude that temporal adaptation does not help any more than normal DAPT. We corroborate this work and extend it by studying a wider variety of tasks over a longer span of time periods and thus are better able to draw generalizations from our results.\nWe believe that the two kinds of shift—task shift and language shift—are difficult to disentangle, and we do not attempt to do so in this work. Instead, we aim to quantify the effect of temporal misalignment on a range of NLP tasks, as well as the benefits of these two strategies."
    }, {
      "heading" : "2.2 Evaluation Methodology",
      "text" : "Our experiments are designed to measure the effect of temporal misalignment on task performance. To do so, for each task, we fix a test set within a given time period, Ttest . We vary the time period of the training data, allowing us to interpret differences in performance as a kind of “regret” relative to the performance of a model trained on data temporally aligned with Ttest .2 We consider multiple different test periods for each task. We also seek to control the effect of training dataset size. We partition training data into time periods of roughly\n2This setup avoids a confound of varying test set difficulty that we would encounter if we fixed the model and compared its performance across test datasets from different time periods.\nthe same size and always train on a single partition, keeping the training set size of each time period constant within each task. We expect that performance could be improved by accumulating training data across multiple time periods, but that would make it more difficult to achieve our research goal of quantifying the effect of temporal misalignment on performance."
    }, {
      "heading" : "2.3 Quantifying Temporal Degradation",
      "text" : "Understanding temporal misalignment requires evaluating a model’s performance across data with a range of different timestamps, which makes it difficult to compare various models in terms of their misalignment. We define a metric for temporal degradation (TD) which summarizes the overall amount of temporal misalignment on a task as a single value. In high-level terms, the TD score measures the average rate of performance deterioration (of perplexity, F1, or Rouge-L) for each time period of misalignment between the train and evaluation sets. Higher TD scores imply greater levels of performance deterioration due to misalignment.\nLet St′ t indicate the performance a model trained on timestep t′ data and evaluated on timestep t. We define D(t′ t) as:\nD(t′ t) = − (St′ t − St t)× sign(t′ − t).\nD(t′ t) is a modified difference in performance between two models.3 Fig. 2 illustrates D as a function of consecutive training time periods.\nWe find a line of best fit for D(t′ t) for all t′ using least-squares regression. The slope of this line is TD(t), the TD score for evaluation time period t. The final TD score is the average of the TD(t) across all evaluation time periods t. Further details can be found in Appendix A."
    }, {
      "heading" : "2.4 Domains, Tasks, and Datasets",
      "text" : "We describe the eight tasks and four domains used for this study. Three (out of eight) of the tasks are newly defined in this work, and all tasks required nontrivial postprocessing; we will release the corresponding datasets or postprocessing scripts publicly at publication 4. We provide examples and detailed statistics in Table 5 of Appendix C.\n3Without the modification, a task with degradation would have have positive performance gaps both t′ > t and t′ > t; the function would not be monotone and the rate of change would be harder to approximate. The modification yields a simpler visual understanding of the deviations over time.\n4Anonymized GitHub Repo\nDomain 1: Twitter Social media platforms like Twitter have been mined to study aspects of language change over time, such as the introduction or diffusion of new words (Eisenstein et al., 2014; Tamburrini et al., 2015; Wang and Goutte, 2017). We collect unlabeled data for domain adaptation by extracting a random selection of 12M tweets, spread semi-uniformly from 2015 till 2020.5 We experiment with two tasks on Twitter data:\nPolitical affiliation classification (POLIAFF) We collect English tweets dated between 2015 and 2020 from U.S. politicians with a political affiliation (Republican or Democrat). We omit any politician who changed parties over this time period or identified as independent. We consider the downstream task of detecting political affiliations, i.e., given a text of a single tweet we predict the political alignment of its author at the time of the tweet. This task can be useful for studies that involve an understanding of ideologies conveyed in text (Lin et al., 2008; Iyyer et al., 2014).\nNamed entity type classification (TWIERC) We use the Twitter NER dataset from Rijhwani and Preoţiuc-Pietro (2020). The dataset contains tweets dated from 2014 to 2019, each annotated with the mentions of named entities and their types (Person, Organization, or Location). We consider the task of typing a given mention, which is a subproblem of named entity recognition.\n5Collected via the Twitter API.\nDomain 2: Scientific Articles Scientific research produces vast amounts of text with great potential for language technologies (Wadden et al., 2020; Lo et al., 2020); it is expected to show a great deal of variation over time as ideas and terminology evolve. For adaptation to this domain, we collect unlabeled data from science documents available in Semantic Scholar’s corpus,6 which yields 650k documents, spread over a 30-year period (Ammar et al., 2018). For this domain, we study two tasks:\nMention type classification (SCIERC) We use the SciERC dataset from Luan et al. (2018) which contains entity-relation annotations for computer science paper abstracts for a relatively wide range of years (1980s to 2019). We subdivide the annotated data into time periods with roughly equal-sized numbers of papers (1980–1999, 2000–2004, 2005– 2009, 2010–2016). The task is to map a mention of a scientific concept to a type (Task, Method, Metric, Material, Other-Scientific-Term, or Generic).\nAI venue classification (AIC) We also examine temporal misalignment on the task of identifying whether a paper was published in AAAI or ICML. We group the data into roughly equal-sized time periods (2009–2011, 2012–2014, 2015–2017, and 2018–2020). This task is, loosely, a proxy for topic classification and author disambiguation applications (Subramanian et al., 2021).\nDomain 3: News Articles News articles make up a significant part of the data commonly used to train LMs (Dodge et al., 2021). News articles convey current events, suggesting strong temporal effects on topic. For adaptation, we use 9M articles from the Newsroom dataset (Grusky et al., 2018), ranging from 2009–2016.7 We experiment with three tasks on news articles:\nNewsroom summarization (NEWSUM) The Newsroom dataset provides a large quantity of high-quality summaries of news articles (Grusky et al., 2018). We group articles by years for this task (2009–2010, 2011–2012, 2013–2014, 2015–2016). Note that this task, unlike the other tasks considered here, is not a document classification task.\nPublisher classification (PUBCLS) The Newsroom dataset also provides metadata, such as publication source. We take the documents published by\n6https://api.semanticscholar.org/ corpus/\n7https://lil.nlp.cornell.edu/newsroom\nthe 3 most prolific publishers (Fox News, New York Times, and Washington Post) and train models to classify documents among them. We bin the years (2009–2010, 2011–2012, 2013–2014, 2015–2016). This task is a proxy for applications that seek to infer fact provenance (Zhang et al., 2020). We note that, unlike in our other tasks, we downsample to ensure that the labels are equally balanced.\nMedia frames classification (MFC) “Framing” often refers to the emphasis or deemphasis of different social or cultural issues in the media’s presentation of the news (Entman, 1983). Card et al. (2015) provide a dataset of news articles annotated with framing dimensions. We predict the primary frame of a document, treating the problem as a 15-way classification task. We bin by timestamp (2009–2010, 2011–2012, 2013–2014, 2015–2016).\nDomain 4: Food Reviews Food and restaurant reviews have been widely studied in NLP research. We considered this domain as a possible contrast to those above, expecting less temporal change. Using data from the Yelp Open Dataset,8 we consider one task:\nReview rating classification (YELPCLS) This is a conventional sentiment analysis task, mapping the text of a review to the numerical rating given by its author (Pang et al., 2002; Dave et al., 2003). We partition the data by year (2013 to 2019) and ensure that each timestep has a roughly equal amount of reviews."
    }, {
      "heading" : "3 Empirical Results and Analysis",
      "text" : "In this section, we summarize our experimental analysis, resulting from more than 500 experiments. In our experiments, we primarily explore the effect of temporal misalignment on GPT2 (Brown et al., 2020), a PLM often used for generation.9 We report the macro F1 score for classification tasks and Rouge-L (Lin, 2004) for NEWSUM.\nWe first focus on quantifying temporal misalignment in end tasks. As a preliminary analysis, we investigate how the marginal distribution over labels changes over time. We then study how temporal misalignment affects performance of GPT2 models in downstream tasks with temporal finetuning (Q1,Q2). We find that the amount of performance degradation can vary by task; in some cases the\n8https://www.yelp.com/dataset 9In our preliminary results, we found that BERT,\nRoBERTa, and GPT2 models showed similar patterns.\ndegradation can be severe. We then study how temporal misalignment affects PLMs. As a first step, we analyze how vocabularies change over time in our datasets. We then experiment with (Q3) how temporal misalignment affects upstream language modeling and (Q4) how effective temporal adaptation, or additional pretraining on a target year, is in mitigating misalignment. We find that while PLMs are affected by misalignment, temporal domain adaptation is not enough to mitigate temporal misalignment.\nDetails on temporal domain adaptation and finetuning, and an extended version of our results, can be found in Appendices B and D, respectively."
    }, {
      "heading" : "3.1 Temporal Misalignment in Tasks",
      "text" : "How much does misalignment affect task performance? We find that it depends on the task.\nLabel Distribution Drift We first investigate how task datasets undergo changes in the marginal distribution over labels due to time. For each task and each test period, we calculate the KL divergence between the label distributions in that period and the first test period. Full results are reported in Fig. 7 of Appendix D. In three cases, we detected notable label distribution drift: POLIAFF, AIC, and MFC.10 In POLIAFF, Republican tweets outnumbered Democratic ones by over a 2:1 ratio in 2015, but the reverse held by 2020. This observation shows that, regardless of the properties of NLP models, the nature of many tasks changes over time, if only because the output distribution changes.\nFinetuning As described in §2.4, for each task, we create training and evaluation sets associated with different time periods. We finetune GPT2 on each of the task’s training sets and evaluate each on two evaluation sets. Note that there is no domain adaptation here.\nFig. 3 shows our results on downstream tasks (with no domain adaptation). To get more reliable estimates, each number in this heatmap is an average of five independent experiments with different random seeds. A summary of the fine-tuning results, in terms of TD scores (§2.3) is in Table 1 which indicates the speed of temporal degradation, for every year that the training and evaluation data diverges. Recall that this score (applied to task\n10For other tasks, it is possible that the data collection/annotation procedures suppressed label distribution changes that would be visible in data “from the wild.”\nperformance measures) summarizes the strength of the effect of temporal misalignment on the score, using evidence from across experiments.\n(Q1) Temporal misalignment degrades task performance substantially. Fig. 3, similar to earlier work (Röttger and Pierrehumbert, 2021), shows that models trained on data from the same time period as the test data perform far better than those from the past. The performance drop is most severe for POLIAFF (TD=7.72) and PUBCLS (TD=5.45).\n(Q1) Temporal misalignment has a measurable effect on most tasks. With the exception of MFC and TWIERC tasks, all tasks see an average loss of at least 1 point for each time period that the training data diverges from the test data. For datasets like SCIERC that make use of data from three decades or more, this effect could add up.\nMoreover, 1 point of difference can be meaningful, especially for the summarization task where we measure Rouge-L. According to the leaderboard,11 the best three performing models are within a point of each other in Rouge-L (Shi et al., 2019, 2021; Mendes et al., 2019). The task has a TD score of 1.38. On average, a time period of temporal misalignment results has a larger effect on performance than changing between the three best models.\n(Q1) Performance loss from temporal misalignment occurs in both directions. Another observation in Table 3 is that degradation happens in both\n11https://lil.nlp.cornell.edu/newsroom/ index.html\nbetter. The heatmap is shaded per column, i.e., the darkest shade of orange in a cell means the cell has the highest score in that column. Mismatch between the the training and evaluation data result in massive performance drop. While all suffer from temporal degradation, its degree is a strong function of task definition. For example, YELPCLS shows minimal degradation. In contrast, POLIAFF shows major deterioration over time. Additional tables of our remaining tasks can be found in Appendix D.\ndirections (past and future). While most of the emphasis on temporal misalignment is on how to adapt our stale models/data to the present time (Dhingra et al., 2021; Lazaridou et al., 2021; Röttger and Pierrehumbert, 2021), our experiments also show that models trained on newer data can be misaligned from the past, as well. This can be important in social science applications (Abercrombie and Batista-Navarro, 2019; Soni et al., 2021), for example, where evaluation sets may come from earlier time periods than the training data. Moreover, the deterioration rates are similar in both directions.\n(Q2) Tasks, even in the same domain, are affected differently. Consider the two tasks of POLIAFF and TWIERC (both in the Twitter domain), with TD scores of 7.72 and 0.96, respectively. Of our 8 tasks, TWIERC, MFC, and YELPCLS are the most robust to temporal misalignment (TD scores of 0.96, 0.98 and 0.26, respectively). The high levels of variation show that temporal misalignment affects performance through labeled datasets, not just unlabeled pretraining data."
    }, {
      "heading" : "3.2 Temporal Misalignment in LMs",
      "text" : "As LMs are widely used in modern NLP systems, it is important to inspect how robust they are to temporal misalignment. We seek to understand how temporal misalignment affects the language modeling task in our four domains and if temporal domain adaptation helps in downstream tasks.\nVocabulary Shift We first consider an extremely simple measurement of language shift: how do vocabularies change across time periods?12 We use\n12This can be understood as a model-free way to measure covariate shift for NLP tasks that take text as input.\na similar procedure to the one Gururangan et al. (2020) used for analyzing domain similarity. Fixing a domain, we compare the (unigram) vocabularies of each pair of training sets. The vocabularies are built using the 10K most frequent terms from each time period. We note that vocabulary overlap is higher between two time periods the closer they are. Most domains see a sizeable amount of shift; however, Yelp is relatively stagnant. Fig. 4 visualizes the overlap measurement.\nTemporal Domain Adaptation We next apply DAPT to GPT2: for each domain, we continue pretraining and then evaluate perplexity. We consider how the perplexity varies with the (mis)alignment between the DAPT training data and the evaluation data. We measure the TD score, which summarizes how much performance is affected by temporal misalignment (now applied to perplexity). The results of temporal domain adaptation are in Fig. 5.\n(Q3) Domains are a major driver of temporal misalignment in LMs. Consistent with Lazaridou et al. (2021), Fig. 5 shows degradation of LM due to temporal misalignment; it further shows considerable variation by text domain. Twitter changes most rapidly, and food reviews are much slower. This observation is consistent with past work on language change in social media (Stewart and Eisenstein, 2018; Eisenstein et al., 2014). To the extent that a LM’s practical usefulness is associated with its fit to new data, researchers and practitioners should understand the temporal dynamics of their target text domains and plan LM updates accordingly.\nJoint Effects of Temporal Adaptation and Finetuning As discussed in §2, continued pretraining\nof an LM on in-domain text has been shown to improve task performance. Our prior results show that both downstream tasks and language modeling are affected by temporal misalignment. Can temporal domain adaptation help mitigate the effects of misalignment in downstream tasks?\nHere we consider how the time period of the data selected for continued pretraining affects task performance. For each task’s evaluation set, we apply DAPT twice: once with the earliest available time period’s unannotated data and once with the latest’s. We then finetune and evaluate on data from the same time periods as in the earlier experiment.\n(Q4) Temporal adaptation does not overcome degradation from temporally misaligned la-\nbeled data. In Table 2, we see small performance gains from temporal domain adaptation on LMs, and in some cases it is harmful. These observations underscore the importance of the labeled data; adjustments to the LM alone do not yet appear sufficient to mitigate the effects of temporal misalignment. In contrast to temporal domain adaptation, which does not mitigate temporal misalignment’s effects, finetuning on temporally-updated labeled data is more effective.\nThis can be observed in each task-specific subtable of in Table 2: the top-left and bottom-right quadrants (fine-tuning on time-stamp that is used for evaluation) generally lead to higher scores."
    }, {
      "heading" : "4 Limitations and Future Work",
      "text" : "We provided a well-controlled suite of experiments to study the effects of temporal misalignment on model performance. However, the setup has some drawbacks. For example, we expect that models trained on data accumulated across multiple time periods would perform well (Lazaridou et al., 2021; Röttger and Pierrehumbert, 2021; Jin et al., 2021).\nWe chose the time periods in our study so that they would each have sufficient and consistent training data sizes. However, amounts of data in a particular domain or task will fluctuate over time. Moreover, the rate of language use change may not be uniform. Future work may want to define their time periods with these two considerations in mind.\nOur findings indicate that temporal misalignment’s effects depend heavily on the task. Though not studied here, the same issues may arise in annotation efforts; consider, for example, recent work on controversy (Zhang et al., 2018) and social norms (Xu et al., 2021; Zhou et al., 2021) likely hinges on constructs that may be time sensitive. Annotations that are temporally misaligned with the\ncolor coding is proportional to the magnitude of the performances of each task (darker shade of orange indicate higher scores). It can be observed that temporal finetuning has a greater impact than temporal pretraining. Each quadrant of 3 for each task, indicating the same finetune and evaluation years, but different pretraining conditions, are mostly uniform. In contrast, we notice a sharper difference in performance when varying the finetuning year (comparing the quadrants vertically).\noriginal data being annotated may be anachronistic. An opportunity for future exploration is in the context of real-world events with sudden changes such as COVID-19 pandemic (Cao et al., 2021) or political changes, which influence tasks such as question answering (Dhingra et al., 2021; Zhang and Choi, 2021).\nContinual learning, which allows models to learn from a continuous stream of data, could also be one way to mitigate temporal misalignment. Most prior work in this space has focused on continual learning in PLMs (Gururangan et al., 2021; Jin et al., 2021) or learning disparate tasks (de Masson d'Autume et al., 2019; Huang et al.). Future work may investigate continual learning algorithms for tasks that change over time.\nWhile we found that task-specific finetuning is more effective than temporal adaptation, new labeled data can be expensive. Ways to characterize or detect changes in a task could be helpful in efficiently updating datasets (Lu et al., 2019; Webb et al., 2018). Future work can also treat dataset maintenance as an optimization problem between the cost and gains of annotating new data (Bai et al., 2021)."
    }, {
      "heading" : "5 Conclusion",
      "text" : "Changes in language use over time, and how language relates to other quantities of interest in NLP\napplications, has clear effects on the performance of those applications. We have explored how temporal misalignment between training data—both data used to train LMs and annotated data used to finetune them—affects performance across a range of NLP tasks and domains, taking advantage of datasets where timestamps are available. We compile these datasets as a benchmark for future research as well. We also introduced a summary metric, TD score, that makes it easier to compare models in terms of their temporal misalignment.\nOur experiments revealed considerable variation in temporal degradation accross tasks, more so than found in previous studies (Röttger and Pierrehumbert, 2021). These findings motivate continued study of temporal misalignment across applications of NLP, its consideration in benchmark evaluations,13 and vigilance on the part of practitioners able to monitor live system performance over time.\nNotably, we observed that continued training of LMs on temporally aligned data does not have much effect, motivating further research to find effective temporal adaptation methods that are less costly than ongoing collection of annotated/labeled datasets over time.\n13Indeed, for benchmarks where training and testing data are aligned, our findings suggest that measures of performance may be in some cases inflated."
    }, {
      "heading" : "A A Metric for Temporal Degradation",
      "text" : "Let t be the time period of the training data and t′ the time period of the evaluation data.14 We aim to summarize the general effect of temporal misalignment (the difference between t and t′) on task performance, in an interpretable way that is comparable across tasks.\nLet St′ t indicate the performance a model trained on timestamp t′ data and evaluated on the timestamp t. Let\nD(t′ t) = − (St′ t − St t)× sign(t′ − t),\nIn other words, D(t′ t) is a modified difference in performance between a aligned and misaligned models. The modification ensures that, as performance deteriorates, D increases, regardless of the direction of time between t and t′.\nOur temporal degradation (TD) score for a fixed evaluation timestamp t for models trained on a set of timestamps T is defined as:\nTD(T t′) = ∣∣∣∣∣ ∑ t∈T ( D(t′ t)− D̄ ) (t− t̄)∑\nt∈T (t− t̄)2 ∣∣∣∣∣ , where t̄ = avgt∈T t ′ and D̄ = avgt∈T D(t ′ t). This metric is the slope of a line fitting the the performance change of models trained on a variety of timestamps, when evaluated on a fixed timestamp. It can be interpreted as the average rate of performance deterioration per time period.\nFig. 6 shows three examples of TD scores from POLIAFF(the first) and YELPCLS(the latter two). These illustrate cases with and without temporal sensitivity. In practice, most examples with deterioration showed a linear trend and thus the rate of degradation was suitible to be approximated by a line. The final TD score is averaged over all evaluation years T ′.\nTD = ∑\nt∈T ′ TD(T t) n"
    }, {
      "heading" : "B Details of Model Development",
      "text" : "Training Details for Temporal Adaptation We train GPT2 over each domain and timestamp for k steps using Huggingface’s implementation of GPT2. Hyperparameter details can be seen in Table 3.\n14See examples in Fig. 3.\nHyperparameter Cls. Assign Summ. Assign\nTraining Details for Temporal Finetuning We use Huggingface’s implementation of GPT2 for finetuning for both the classification and summarization tasks. We train on Quadro RTX 800 GPUs. See Table 4 for details."
    }, {
      "heading" : "C Data Collection",
      "text" : "We describe the postprocessing and data collection in greater detail. Table 5 depicts examples and detailed statistics for our task. All data released is intended for non-commercial use.\nPOLIAFF We acquire a list of U.S. politician names and Twitter handles15. One of the authors manually annotated if the politician was a Republican or Democrat. In addition, one volunteer double checked to ensure correctness. We throw away any politician who changed parties between 2015 and 2020, any independents, and anyone suspended by Twitter (e.g., RealDonaldTrump).\n15https://files.pushshift.io/twitter/ US_PoliticalTweets.tar.gz\nAIC We randomly sample science documents in Semantic Scholar’s corpus.16 Of those, we only keep documents that (1) are published in ICML or AAAI, (2) are classified as ‘computer science’ documents, and (3) have an abstract of at least 50 tokens.\nNewsroom The following applies to the postprocessing and data selection for both supervised temporal finetuning and unsupervised temporal adaptation of PUBCLS and NEWSUM. We use the Newsroom dataset.17. We only keep articles where (1) the year in the metadata also appears in the main text and (2) no future year is mentioned in the main text.\nPUBCLS We carry out additional postprocessing and ensure that each of the three labels (Fox News, New York Times, and Washington Post) have an equal distribution across years. We do so by uniform-random downsampling."
    }, {
      "heading" : "D Extended Results",
      "text" : "We provide further results from our experiments described in Section 3.\nLabel Distribution Drift We measure how label distributions in task datasets change over time, as described in Section 3.1. For each task and each test period, we calculate the KL divergence between the label distribution of that period andthe first test period. Fig. 7 depicts our results.\nFinetuning Results We provide the full results from our fientuning experiments in Section 3.1 in Fig. 8. These results are for downstream tasks with no domain adaptation.\nFinetuning with Temporal Domain Adaptation We provide the full results from our finetuning with temporal domain adaptation in Section 3.2 in Fig. 6.\n16https://api.semanticscholar.org/ corpus/; licensed under an ODC-BY\n17https://lil.nlp.cornell.edu/newsroom/\nThe heatmap is shaded per column, i.e., the darkest shade of orange in a cell means the cell has the highest score in that column. Mismatch between the the training and evaluation data result in massive performance drop. While all suffer from temporal degradation, its degree is a strong function of task definition. For example, YELPCLS, MFC, and TWIERC show minimal degradation. In contrast, POLIAFF and NEWSUM major deterioration over time.\nmagnitude of the performances of each task (darker shade of orange indicates higher scores). We see that models that were finetuned on similar time periods performed similarly, no matter how their DAPT conditions differed."
    } ],
    "references" : [ {
      "title" : "Semantic change in the language of uk parliamentary debates",
      "author" : [ "Gavin Abercrombie", "Riza Theresa Batista-Navarro." ],
      "venue" : "Proceedings of the 1st International Workshop on Computational Approaches to Historical Language Change.",
      "citeRegEx" : "Abercrombie and Batista.Navarro.,? 2019",
      "shortCiteRegEx" : "Abercrombie and Batista.Navarro.",
      "year" : 2019
    }, {
      "title" : "Beyond word frequency: Bursts, lulls, and scaling in the temporal distributions of words",
      "author" : [ "Eduardo G Altmann", "Janet B Pierrehumbert", "Adilson E Motter." ],
      "venue" : "PLOS one, 4(11):e7678.",
      "citeRegEx" : "Altmann et al\\.,? 2009",
      "shortCiteRegEx" : "Altmann et al\\.",
      "year" : 2009
    }, {
      "title" : "Construction of the literature graph in semantic scholar",
      "author" : [ "Waleed Ammar", "Dirk Groeneveld", "Chandra Bhagavatula", "Iz Beltagy", "Miles Crawford", "Doug Downey", "Jason Dunkelberger", "Ahmed Elgohary", "Sergey Feldman", "Vu Ha" ],
      "venue" : null,
      "citeRegEx" : "Ammar et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Ammar et al\\.",
      "year" : 2018
    }, {
      "title" : "Pre-train or annotate? domain adaptation with a constrained budget",
      "author" : [ "Fan Bai", "Alan Ritter", "Wei Xu." ],
      "venue" : "arXiv preprint arXiv:2109.04711.",
      "citeRegEx" : "Bai et al\\.,? 2021",
      "shortCiteRegEx" : "Bai et al\\.",
      "year" : 2021
    }, {
      "title" : "Scibert: A pretrained language model for scientific text",
      "author" : [ "Iz Beltagy", "Kyle Lo", "Arman Cohan." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Beltagy et al\\.,? 2019",
      "shortCiteRegEx" : "Beltagy et al\\.",
      "year" : 2019
    }, {
      "title" : "Language models are few-shot learners. arXiv preprint arXiv:2005.14165",
      "author" : [ "Tom B Brown", "Benjamin Mann", "Nick Ryder", "Melanie Subbiah", "Jared Kaplan", "Prafulla Dhariwal", "Arvind Neelakantan", "Pranav Shyam", "Girish Sastry", "Amanda Askell" ],
      "venue" : null,
      "citeRegEx" : "Brown et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Brown et al\\.",
      "year" : 2020
    }, {
      "title" : "Quantifying the effects of COVID-19 on restaurant reviews",
      "author" : [ "Ivy Cao", "Zizhou Liu", "Giannis Karamanolakis", "Daniel Hsu", "Luis Gravano." ],
      "venue" : "Proceedings of the International Workshop on Natural Language Processing for Social Media, Online. As-",
      "citeRegEx" : "Cao et al\\.,? 2021",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2021
    }, {
      "title" : "The media frames corpus: Annotations of frames across issues",
      "author" : [ "Dallas Card", "Amber E. Boydstun", "Justin H. Gross", "Philip Resnik", "Noah A. Smith." ],
      "venue" : "ACL.",
      "citeRegEx" : "Card et al\\.,? 2015",
      "shortCiteRegEx" : "Card et al\\.",
      "year" : 2015
    }, {
      "title" : "Mining the peanut gallery: opinion extraction and semantic classification of product reviews",
      "author" : [ "Kushal Dave", "Steve Lawrence", "David M. Pennock." ],
      "venue" : "WWW ’03.",
      "citeRegEx" : "Dave et al\\.,? 2003",
      "shortCiteRegEx" : "Dave et al\\.",
      "year" : 2003
    }, {
      "title" : "Episodic memory in lifelong language learning",
      "author" : [ "Cyprien de Masson d'Autume", "Sebastian Ruder", "Lingpeng Kong", "Dani Yogatama." ],
      "venue" : "nips.",
      "citeRegEx" : "d.Autume et al\\.,? 2019",
      "shortCiteRegEx" : "d.Autume et al\\.",
      "year" : 2019
    }, {
      "title" : "Time-aware language models as temporal knowledge bases",
      "author" : [ "Bhuwan Dhingra", "Jeremy R. Cole", "Julian Martin Eisenschlos", "Daniel Gillick", "Jacob Eisenstein", "William W. Cohen." ],
      "venue" : "CoRR, abs/2106.15110.",
      "citeRegEx" : "Dhingra et al\\.,? 2021",
      "shortCiteRegEx" : "Dhingra et al\\.",
      "year" : 2021
    }, {
      "title" : "Documenting the english colossal clean crawled corpus",
      "author" : [ "Jesse Dodge", "Maarten Sap", "Ana Marasovic", "William Agnew", "Gabriel Ilharco", "Dirk Groeneveld", "Matt Gardner." ],
      "venue" : "arXiv preprint arXiv:2104.08758.",
      "citeRegEx" : "Dodge et al\\.,? 2021",
      "shortCiteRegEx" : "Dodge et al\\.",
      "year" : 2021
    }, {
      "title" : "Diffusion of lexical change in social media",
      "author" : [ "Jacob Eisenstein", "Brendan O’Connor", "Noah A Smith", "Eric P Xing" ],
      "venue" : "PloS one,",
      "citeRegEx" : "Eisenstein et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Eisenstein et al\\.",
      "year" : 2014
    }, {
      "title" : "Framing: Toward clarification of a fractured paradigm",
      "author" : [ "Robert M. Entman." ],
      "venue" : "Journal of Communications.",
      "citeRegEx" : "Entman.,? 1983",
      "shortCiteRegEx" : "Entman.",
      "year" : 1983
    }, {
      "title" : "A maximum entropy approach to named entity recognition",
      "author" : [ "Ralph Grishman", "Andrew Borthwick" ],
      "venue" : null,
      "citeRegEx" : "Grishman and Borthwick.,? \\Q1999\\E",
      "shortCiteRegEx" : "Grishman and Borthwick.",
      "year" : 1999
    }, {
      "title" : "Newsroom: A dataset of 1.3 million summaries with diverse extractive strategies",
      "author" : [ "Max Grusky", "Mor Naaman", "Yoav Artzi" ],
      "venue" : null,
      "citeRegEx" : "Grusky et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Grusky et al\\.",
      "year" : 2018
    }, {
      "title" : "Demix layers: Disentangling domains for modular language modeling",
      "author" : [ "Suchin Gururangan", "Mike Lewis", "Ari Holtzman", "Noah A. Smith", "Luke Zettlemoyer." ],
      "venue" : "CoRR, abs/2108.05036.",
      "citeRegEx" : "Gururangan et al\\.,? 2021",
      "shortCiteRegEx" : "Gururangan et al\\.",
      "year" : 2021
    }, {
      "title" : "Don’t stop pretraining: Adapt language models to domains and tasks",
      "author" : [ "Suchin Gururangan", "Ana Marasović", "Swabha Swayamdipta", "Kyle Lo", "Iz Beltagy", "Doug Downey", "Noah A Smith." ],
      "venue" : "ACL.",
      "citeRegEx" : "Gururangan et al\\.,? 2020",
      "shortCiteRegEx" : "Gururangan et al\\.",
      "year" : 2020
    }, {
      "title" : "Political ideology detection using recursive neural networks",
      "author" : [ "Mohit Iyyer", "Peter Enns", "Jordan Boyd-Graber", "Philip Resnik." ],
      "venue" : "ACL.",
      "citeRegEx" : "Iyyer et al\\.,? 2014",
      "shortCiteRegEx" : "Iyyer et al\\.",
      "year" : 2014
    }, {
      "title" : "Diachronic degradation of language models: Insights from social media",
      "author" : [ "Kokil Jaidka", "Niyati Chhaya", "Lyle Ungar." ],
      "venue" : "ACL.",
      "citeRegEx" : "Jaidka et al\\.,? 2018",
      "shortCiteRegEx" : "Jaidka et al\\.",
      "year" : 2018
    }, {
      "title" : "Lifelong pretraining: Continually adapting language models to emerging corpora",
      "author" : [ "Xisen Jin", "Dejiao Zhang", "Henghui Zhu", "Wei Xiao", "Shang-Wen Li", "Xiaokai Wei", "Andrew Arnold", "Xiang Ren" ],
      "venue" : null,
      "citeRegEx" : "Jin et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Jin et al\\.",
      "year" : 2021
    }, {
      "title" : "Principles of linguistic change",
      "author" : [ "W. Labov" ],
      "venue" : null,
      "citeRegEx" : "Labov.,? \\Q1994\\E",
      "shortCiteRegEx" : "Labov.",
      "year" : 1994
    }, {
      "title" : "Pitfalls of static language modelling",
      "author" : [ "Angeliki Lazaridou", "Adhiguna Kuncoro", "Elena Gribovskaya", "Devang Agrawal", "Adam Liska", "Tayfun Terzi", "Mai Gimenez", "Cyprien de Masson d’Autume", "Sebastian Ruder", "Dani Yogatama" ],
      "venue" : null,
      "citeRegEx" : "Lazaridou et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Lazaridou et al\\.",
      "year" : 2021
    }, {
      "title" : "ROUGE: A package for automatic evaluation of summaries",
      "author" : [ "Chin-Yew Lin." ],
      "venue" : "Proc. of Text Summarization Branches Out.",
      "citeRegEx" : "Lin.,? 2004",
      "shortCiteRegEx" : "Lin.",
      "year" : 2004
    }, {
      "title" : "A joint topic and perspective model for ideological discourse",
      "author" : [ "Wei-Hao Lin", "Eric P. Xing", "Alexander Hauptmann." ],
      "venue" : "ECML/PKDD.",
      "citeRegEx" : "Lin et al\\.,? 2008",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2008
    }, {
      "title" : "S2orc: The semantic scholar open research corpus",
      "author" : [ "Kyle Lo", "Lucy Lu Wang", "Mark Neumann", "Rodney Kinney", "Daniel S Weld." ],
      "venue" : "ACL.",
      "citeRegEx" : "Lo et al\\.,? 2020",
      "shortCiteRegEx" : "Lo et al\\.",
      "year" : 2020
    }, {
      "title" : "Learning under concept drift: A review",
      "author" : [ "Jie Lu", "Anjin Liu", "Fan Dong", "Feng Gu", "João Gama", "Guangquan Zhang." ],
      "venue" : "IEEE Transactions on Knowledge and Data Engineering.",
      "citeRegEx" : "Lu et al\\.,? 2019",
      "shortCiteRegEx" : "Lu et al\\.",
      "year" : 2019
    }, {
      "title" : "Multi-task identification of entities, relations, and coreference for scientific knowledge graph construction",
      "author" : [ "Yi Luan", "Luheng He", "Mari Ostendorf", "Hannaneh Hajishirzi." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Luan et al\\.,? 2018",
      "shortCiteRegEx" : "Luan et al\\.",
      "year" : 2018
    }, {
      "title" : "Jointly extracting and compressing documents with summary state representations",
      "author" : [ "Afonso Mendes", "Shashi Narayan", "Sebastião Miranda", "Zita Marinho", "André F.T. Martins", "Shay B. Cohen." ],
      "venue" : "NAACL.",
      "citeRegEx" : "Mendes et al\\.,? 2019",
      "shortCiteRegEx" : "Mendes et al\\.",
      "year" : 2019
    }, {
      "title" : "Thumbs up? sentiment classification using machine learning techniques",
      "author" : [ "Bo Pang", "Lillian Lee", "Shivakumar Vaithyanathan." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Pang et al\\.,? 2002",
      "shortCiteRegEx" : "Pang et al\\.",
      "year" : 2002
    }, {
      "title" : "Deep contextualized word representations",
      "author" : [ "Matthew Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer." ],
      "venue" : "NAACL.",
      "citeRegEx" : "Peters et al\\.,? 2018",
      "shortCiteRegEx" : "Peters et al\\.",
      "year" : 2018
    }, {
      "title" : "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "author" : [ "Colin Raffel", "Noam Shazeer", "Adam Roberts", "Katherine Lee", "Sharan Narang", "Michael Matena", "Yanqi Zhou", "Wei Li", "Peter J Liu." ],
      "venue" : "JMLR, 21:1–67.",
      "citeRegEx" : "Raffel et al\\.,? 2020",
      "shortCiteRegEx" : "Raffel et al\\.",
      "year" : 2020
    }, {
      "title" : "Temporally-informed analysis of named entity recognition",
      "author" : [ "Shruti Rijhwani", "Daniel Preoţiuc-Pietro." ],
      "venue" : "ACL.",
      "citeRegEx" : "Rijhwani and Preoţiuc.Pietro.,? 2020",
      "shortCiteRegEx" : "Rijhwani and Preoţiuc.Pietro.",
      "year" : 2020
    }, {
      "title" : "Temporal adaptation of bert and performance on downstream document classification: Insights from social media",
      "author" : [ "Paul Röttger", "Janet B Pierrehumbert." ],
      "venue" : "arXiv preprint arXiv:2104.08116.",
      "citeRegEx" : "Röttger and Pierrehumbert.,? 2021",
      "shortCiteRegEx" : "Röttger and Pierrehumbert.",
      "year" : 2021
    }, {
      "title" : "Neural abstractive text summarization with sequence-to-sequence models",
      "author" : [ "Tian Shi", "Yaser Keneshloo", "Naren Ramakrishnan", "Chandan K. Reddy." ],
      "venue" : "ACM Transactions on Data Science.",
      "citeRegEx" : "Shi et al\\.,? 2021",
      "shortCiteRegEx" : "Shi et al\\.",
      "year" : 2021
    }, {
      "title" : "LeafNATS: An open-source toolkit and live demo system for neural abstractive text summarization",
      "author" : [ "Tian Shi", "Ping Wang", "Chandan K. Reddy." ],
      "venue" : "NAACL.",
      "citeRegEx" : "Shi et al\\.,? 2019",
      "shortCiteRegEx" : "Shi et al\\.",
      "year" : 2019
    }, {
      "title" : "Abolitionist networks: Modeling language change in nineteenth-century activist newspapers",
      "author" : [ "Sandeep Soni", "Lauren Klein", "Jacob Eisenstein." ],
      "venue" : "arXiv preprint arXiv:2103.07538.",
      "citeRegEx" : "Soni et al\\.,? 2021",
      "shortCiteRegEx" : "Soni et al\\.",
      "year" : 2021
    }, {
      "title" : "Making “fetch” happen: The influence of social and linguistic context on nonstandard word growth and decline",
      "author" : [ "Ian Stewart", "Jacob Eisenstein." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Stewart and Eisenstein.,? 2018",
      "shortCiteRegEx" : "Stewart and Eisenstein.",
      "year" : 2018
    }, {
      "title" : "S2and: A benchmark and evaluation system for author name disambiguation",
      "author" : [ "Shivashankar Subramanian", "Daniel King", "Doug Downey", "Sergey Feldman." ],
      "venue" : "arXiv preprint arXiv:2103.07534.",
      "citeRegEx" : "Subramanian et al\\.,? 2021",
      "shortCiteRegEx" : "Subramanian et al\\.",
      "year" : 2021
    }, {
      "title" : "Twitter users change word usage according to conversationpartner social identity",
      "author" : [ "Nadine Tamburrini", "Marco Cinnirella", "Vincent AA Jansen", "John Bryden." ],
      "venue" : "Social Networks, 40:84–89.",
      "citeRegEx" : "Tamburrini et al\\.,? 2015",
      "shortCiteRegEx" : "Tamburrini et al\\.",
      "year" : 2015
    }, {
      "title" : "Fact or fiction: Verifying scientific claims",
      "author" : [ "David Wadden", "Shanchuan Lin", "Kyle Lo", "Lucy Lu Wang", "Madeleine van Zuylen", "Arman Cohan", "Hannaneh Hajishirzi." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Wadden et al\\.,? 2020",
      "shortCiteRegEx" : "Wadden et al\\.",
      "year" : 2020
    }, {
      "title" : "Detecting changes in twitter streams using temporal clusters of hashtags",
      "author" : [ "Yunli Wang", "Cyril Goutte." ],
      "venue" : "Proceedings of the Events and Stories in the News Workshop.",
      "citeRegEx" : "Wang and Goutte.,? 2017",
      "shortCiteRegEx" : "Wang and Goutte.",
      "year" : 2017
    }, {
      "title" : "Analyzing concept drift and shift from sample data",
      "author" : [ "Geoffrey I. Webb", "Loong Kuan Lee", "Bart Goethals", "François Petitjean." ],
      "venue" : "Data Mining and Knowledge Discovery.",
      "citeRegEx" : "Webb et al\\.,? 2018",
      "shortCiteRegEx" : "Webb et al\\.",
      "year" : 2018
    }, {
      "title" : "Detoxifying language models risks marginalizing minority voices",
      "author" : [ "Albert Xu", "Eshaan Pathak", "Eric Wallace", "Suchin Gururangan", "Maarten Sap", "Dan Klein." ],
      "venue" : "NAACL.",
      "citeRegEx" : "Xu et al\\.,? 2021",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2021
    }, {
      "title" : "Conversations gone awry: Detecting early signs of conversational failure",
      "author" : [ "Justine Zhang", "Jonathan Chang", "Cristian DanescuNiculescu-Mizil", "Lucas Dixon", "Yiqing Hua", "Dario Taraborelli", "Nithum Thain." ],
      "venue" : "ACL.",
      "citeRegEx" : "Zhang et al\\.,? 2018",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "SituatedQA: Incorporating extra-linguistic contexts into QA",
      "author" : [ "Michael J.Q. Zhang", "Eunsol Choi." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Zhang and Choi.,? 2021",
      "shortCiteRegEx" : "Zhang and Choi.",
      "year" : 2021
    }, {
      "title" : "who said it, and why?” provenance for natural language claims",
      "author" : [ "Yi Zhang", "Zachary Ives", "Dan Roth." ],
      "venue" : "ACL.",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Challenges in automated debiasing for toxic language detection",
      "author" : [ "Xuhui Zhou", "Maarten Sap", "Swabha Swayamdipta", "Yejin Choi", "Noah A. Smith." ],
      "venue" : "EACL.",
      "citeRegEx" : "Zhou et al\\.,? 2021",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2021
    } ],
    "referenceMentions" : [ {
      "referenceID" : 21,
      "context" : "Changes in the ways a language is used over time are widely attested (Labov, 1994; Altmann et al., 2009; Eisenstein et al., 2014); how these changes will affect NLP systems built from text corpora, and in particular their long-term performance, is not as well understood.",
      "startOffset" : 69,
      "endOffset" : 129
    }, {
      "referenceID" : 1,
      "context" : "Changes in the ways a language is used over time are widely attested (Labov, 1994; Altmann et al., 2009; Eisenstein et al., 2014); how these changes will affect NLP systems built from text corpora, and in particular their long-term performance, is not as well understood.",
      "startOffset" : 69,
      "endOffset" : 129
    }, {
      "referenceID" : 12,
      "context" : "Changes in the ways a language is used over time are widely attested (Labov, 1994; Altmann et al., 2009; Eisenstein et al., 2014); how these changes will affect NLP systems built from text corpora, and in particular their long-term performance, is not as well understood.",
      "startOffset" : 69,
      "endOffset" : 129
    }, {
      "referenceID" : 19,
      "context" : "In today’s pretraining-finetuning paradigm, this misalignment can affect a pretrained language model—a situation that has received recent attention (Jaidka et al., 2018; Lazaridou et al., 2021; Peters et al., 2018; Raffel et al., 2020; Röttger and Pierrehumbert, 2021)—or the finetuned task model, or both.",
      "startOffset" : 148,
      "endOffset" : 268
    }, {
      "referenceID" : 22,
      "context" : "In today’s pretraining-finetuning paradigm, this misalignment can affect a pretrained language model—a situation that has received recent attention (Jaidka et al., 2018; Lazaridou et al., 2021; Peters et al., 2018; Raffel et al., 2020; Röttger and Pierrehumbert, 2021)—or the finetuned task model, or both.",
      "startOffset" : 148,
      "endOffset" : 268
    }, {
      "referenceID" : 30,
      "context" : "In today’s pretraining-finetuning paradigm, this misalignment can affect a pretrained language model—a situation that has received recent attention (Jaidka et al., 2018; Lazaridou et al., 2021; Peters et al., 2018; Raffel et al., 2020; Röttger and Pierrehumbert, 2021)—or the finetuned task model, or both.",
      "startOffset" : 148,
      "endOffset" : 268
    }, {
      "referenceID" : 31,
      "context" : "In today’s pretraining-finetuning paradigm, this misalignment can affect a pretrained language model—a situation that has received recent attention (Jaidka et al., 2018; Lazaridou et al., 2021; Peters et al., 2018; Raffel et al., 2020; Röttger and Pierrehumbert, 2021)—or the finetuned task model, or both.",
      "startOffset" : 148,
      "endOffset" : 268
    }, {
      "referenceID" : 33,
      "context" : "In today’s pretraining-finetuning paradigm, this misalignment can affect a pretrained language model—a situation that has received recent attention (Jaidka et al., 2018; Lazaridou et al., 2021; Peters et al., 2018; Raffel et al., 2020; Röttger and Pierrehumbert, 2021)—or the finetuned task model, or both.",
      "startOffset" : 148,
      "endOffset" : 268
    }, {
      "referenceID" : 14,
      "context" : "4), ranging from summarization to entity typing, a subproblem of entity recognition (Grishman and Borthwick, 1999).",
      "startOffset" : 84,
      "endOffset" : 114
    }, {
      "referenceID" : 33,
      "context" : "We explore domain adaptation of a language model, using temporally selected (unannotated) data, as a way to curtail temporal misalignment (Röttger and Pierrehumbert, 2021).",
      "startOffset" : 138,
      "endOffset" : 171
    }, {
      "referenceID" : 5,
      "context" : "First, a (neural network) language model (LM) is pretrained on a large text collection that is not necessarily selected for topical or temporal proximity to the text of the target application (our focus is on GPT-2; Brown et al., 2020).",
      "startOffset" : 192,
      "endOffset" : 235
    }, {
      "referenceID" : 4,
      "context" : "Second, the LM is optionally adapted by continued training on a collection strategically curated for closer proximity to the target (Beltagy et al., 2019); this stage is often referred to as domain-adaptive pretraining (DAPT; Gururangan et al.",
      "startOffset" : 132,
      "endOffset" : 154
    }, {
      "referenceID" : 17,
      "context" : ", 2019); this stage is often referred to as domain-adaptive pretraining (DAPT; Gururangan et al., 2020).",
      "startOffset" : 72,
      "endOffset" : 103
    }, {
      "referenceID" : 22,
      "context" : "Language Shift and Temporal Domain Adaptation Changes in language use can cause a pretrained LM, which commonly serves as the backbone for most modern NLP models, to become stale over time (Lazaridou et al., 2021), regardless of the end task.",
      "startOffset" : 189,
      "endOffset" : 213
    }, {
      "referenceID" : 12,
      "context" : "Domain 1: Twitter Social media platforms like Twitter have been mined to study aspects of language change over time, such as the introduction or diffusion of new words (Eisenstein et al., 2014; Tamburrini et al., 2015; Wang and Goutte, 2017).",
      "startOffset" : 168,
      "endOffset" : 241
    }, {
      "referenceID" : 39,
      "context" : "Domain 1: Twitter Social media platforms like Twitter have been mined to study aspects of language change over time, such as the introduction or diffusion of new words (Eisenstein et al., 2014; Tamburrini et al., 2015; Wang and Goutte, 2017).",
      "startOffset" : 168,
      "endOffset" : 241
    }, {
      "referenceID" : 41,
      "context" : "Domain 1: Twitter Social media platforms like Twitter have been mined to study aspects of language change over time, such as the introduction or diffusion of new words (Eisenstein et al., 2014; Tamburrini et al., 2015; Wang and Goutte, 2017).",
      "startOffset" : 168,
      "endOffset" : 241
    }, {
      "referenceID" : 24,
      "context" : "This task can be useful for studies that involve an understanding of ideologies conveyed in text (Lin et al., 2008; Iyyer et al., 2014).",
      "startOffset" : 97,
      "endOffset" : 135
    }, {
      "referenceID" : 18,
      "context" : "This task can be useful for studies that involve an understanding of ideologies conveyed in text (Lin et al., 2008; Iyyer et al., 2014).",
      "startOffset" : 97,
      "endOffset" : 135
    }, {
      "referenceID" : 40,
      "context" : "Domain 2: Scientific Articles Scientific research produces vast amounts of text with great potential for language technologies (Wadden et al., 2020; Lo et al., 2020); it is expected to show a great deal of variation over time as ideas and terminology evolve.",
      "startOffset" : 127,
      "endOffset" : 165
    }, {
      "referenceID" : 25,
      "context" : "Domain 2: Scientific Articles Scientific research produces vast amounts of text with great potential for language technologies (Wadden et al., 2020; Lo et al., 2020); it is expected to show a great deal of variation over time as ideas and terminology evolve.",
      "startOffset" : 127,
      "endOffset" : 165
    }, {
      "referenceID" : 2,
      "context" : "For adaptation to this domain, we collect unlabeled data from science documents available in Semantic Scholar’s corpus,6 which yields 650k documents, spread over a 30-year period (Ammar et al., 2018).",
      "startOffset" : 179,
      "endOffset" : 199
    }, {
      "referenceID" : 38,
      "context" : "This task is, loosely, a proxy for topic classification and author disambiguation applications (Subramanian et al., 2021).",
      "startOffset" : 95,
      "endOffset" : 121
    }, {
      "referenceID" : 11,
      "context" : "Domain 3: News Articles News articles make up a significant part of the data commonly used to train LMs (Dodge et al., 2021).",
      "startOffset" : 104,
      "endOffset" : 124
    }, {
      "referenceID" : 15,
      "context" : "For adaptation, we use 9M articles from the Newsroom dataset (Grusky et al., 2018), ranging from 2009–2016.",
      "startOffset" : 61,
      "endOffset" : 82
    }, {
      "referenceID" : 15,
      "context" : "Newsroom summarization (NEWSUM) The Newsroom dataset provides a large quantity of high-quality summaries of news articles (Grusky et al., 2018).",
      "startOffset" : 122,
      "endOffset" : 143
    }, {
      "referenceID" : 46,
      "context" : "This task is a proxy for applications that seek to infer fact provenance (Zhang et al., 2020).",
      "startOffset" : 73,
      "endOffset" : 93
    }, {
      "referenceID" : 13,
      "context" : "Media frames classification (MFC) “Framing” often refers to the emphasis or deemphasis of different social or cultural issues in the media’s presentation of the news (Entman, 1983).",
      "startOffset" : 166,
      "endOffset" : 180
    }, {
      "referenceID" : 29,
      "context" : "Review rating classification (YELPCLS) This is a conventional sentiment analysis task, mapping the text of a review to the numerical rating given by its author (Pang et al., 2002; Dave et al., 2003).",
      "startOffset" : 160,
      "endOffset" : 198
    }, {
      "referenceID" : 8,
      "context" : "Review rating classification (YELPCLS) This is a conventional sentiment analysis task, mapping the text of a review to the numerical rating given by its author (Pang et al., 2002; Dave et al., 2003).",
      "startOffset" : 160,
      "endOffset" : 198
    }, {
      "referenceID" : 5,
      "context" : "In our experiments, we primarily explore the effect of temporal misalignment on GPT2 (Brown et al., 2020), a PLM often used for generation.",
      "startOffset" : 85,
      "endOffset" : 105
    }, {
      "referenceID" : 23,
      "context" : "9 We report the macro F1 score for classification tasks and Rouge-L (Lin, 2004) for NEWSUM.",
      "startOffset" : 68,
      "endOffset" : 79
    }, {
      "referenceID" : 33,
      "context" : "3, similar to earlier work (Röttger and Pierrehumbert, 2021), shows that models trained on data from the same time period as the test data perform far better than those from the past.",
      "startOffset" : 27,
      "endOffset" : 60
    }, {
      "referenceID" : 28,
      "context" : "According to the leaderboard,11 the best three performing models are within a point of each other in Rouge-L (Shi et al., 2019, 2021; Mendes et al., 2019).",
      "startOffset" : 109,
      "endOffset" : 154
    }, {
      "referenceID" : 10,
      "context" : "While most of the emphasis on temporal misalignment is on how to adapt our stale models/data to the present time (Dhingra et al., 2021; Lazaridou et al., 2021; Röttger and Pierrehumbert, 2021), our experiments also show that models trained on newer data can be misaligned from the past, as well.",
      "startOffset" : 113,
      "endOffset" : 192
    }, {
      "referenceID" : 22,
      "context" : "While most of the emphasis on temporal misalignment is on how to adapt our stale models/data to the present time (Dhingra et al., 2021; Lazaridou et al., 2021; Röttger and Pierrehumbert, 2021), our experiments also show that models trained on newer data can be misaligned from the past, as well.",
      "startOffset" : 113,
      "endOffset" : 192
    }, {
      "referenceID" : 33,
      "context" : "While most of the emphasis on temporal misalignment is on how to adapt our stale models/data to the present time (Dhingra et al., 2021; Lazaridou et al., 2021; Röttger and Pierrehumbert, 2021), our experiments also show that models trained on newer data can be misaligned from the past, as well.",
      "startOffset" : 113,
      "endOffset" : 192
    }, {
      "referenceID" : 0,
      "context" : "This can be important in social science applications (Abercrombie and Batista-Navarro, 2019; Soni et al., 2021), for example, where evaluation sets may come from earlier time periods than the training data.",
      "startOffset" : 53,
      "endOffset" : 111
    }, {
      "referenceID" : 36,
      "context" : "This can be important in social science applications (Abercrombie and Batista-Navarro, 2019; Soni et al., 2021), for example, where evaluation sets may come from earlier time periods than the training data.",
      "startOffset" : 53,
      "endOffset" : 111
    }, {
      "referenceID" : 37,
      "context" : "This observation is consistent with past work on language change in social media (Stewart and Eisenstein, 2018; Eisenstein et al., 2014).",
      "startOffset" : 81,
      "endOffset" : 136
    }, {
      "referenceID" : 12,
      "context" : "This observation is consistent with past work on language change in social media (Stewart and Eisenstein, 2018; Eisenstein et al., 2014).",
      "startOffset" : 81,
      "endOffset" : 136
    }, {
      "referenceID" : 22,
      "context" : "For example, we expect that models trained on data accumulated across multiple time periods would perform well (Lazaridou et al., 2021; Röttger and Pierrehumbert, 2021; Jin et al., 2021).",
      "startOffset" : 111,
      "endOffset" : 186
    }, {
      "referenceID" : 33,
      "context" : "For example, we expect that models trained on data accumulated across multiple time periods would perform well (Lazaridou et al., 2021; Röttger and Pierrehumbert, 2021; Jin et al., 2021).",
      "startOffset" : 111,
      "endOffset" : 186
    }, {
      "referenceID" : 20,
      "context" : "For example, we expect that models trained on data accumulated across multiple time periods would perform well (Lazaridou et al., 2021; Röttger and Pierrehumbert, 2021; Jin et al., 2021).",
      "startOffset" : 111,
      "endOffset" : 186
    }, {
      "referenceID" : 44,
      "context" : "Though not studied here, the same issues may arise in annotation efforts; consider, for example, recent work on controversy (Zhang et al., 2018) and social norms (Xu et al.",
      "startOffset" : 124,
      "endOffset" : 144
    }, {
      "referenceID" : 43,
      "context" : ", 2018) and social norms (Xu et al., 2021; Zhou et al., 2021) likely hinges on constructs that may be time sensitive.",
      "startOffset" : 25,
      "endOffset" : 61
    }, {
      "referenceID" : 47,
      "context" : ", 2018) and social norms (Xu et al., 2021; Zhou et al., 2021) likely hinges on constructs that may be time sensitive.",
      "startOffset" : 25,
      "endOffset" : 61
    }, {
      "referenceID" : 6,
      "context" : "An opportunity for future exploration is in the context of real-world events with sudden changes such as COVID-19 pandemic (Cao et al., 2021) or political changes, which influence tasks such as question answering (Dhingra et al.",
      "startOffset" : 123,
      "endOffset" : 141
    }, {
      "referenceID" : 10,
      "context" : ", 2021) or political changes, which influence tasks such as question answering (Dhingra et al., 2021; Zhang and Choi, 2021).",
      "startOffset" : 79,
      "endOffset" : 123
    }, {
      "referenceID" : 45,
      "context" : ", 2021) or political changes, which influence tasks such as question answering (Dhingra et al., 2021; Zhang and Choi, 2021).",
      "startOffset" : 79,
      "endOffset" : 123
    }, {
      "referenceID" : 16,
      "context" : "Most prior work in this space has focused on continual learning in PLMs (Gururangan et al., 2021; Jin et al., 2021) or learning disparate tasks (de Masson d'Autume et al.",
      "startOffset" : 72,
      "endOffset" : 115
    }, {
      "referenceID" : 20,
      "context" : "Most prior work in this space has focused on continual learning in PLMs (Gururangan et al., 2021; Jin et al., 2021) or learning disparate tasks (de Masson d'Autume et al.",
      "startOffset" : 72,
      "endOffset" : 115
    }, {
      "referenceID" : 26,
      "context" : "Ways to characterize or detect changes in a task could be helpful in efficiently updating datasets (Lu et al., 2019; Webb et al., 2018).",
      "startOffset" : 99,
      "endOffset" : 135
    }, {
      "referenceID" : 42,
      "context" : "Ways to characterize or detect changes in a task could be helpful in efficiently updating datasets (Lu et al., 2019; Webb et al., 2018).",
      "startOffset" : 99,
      "endOffset" : 135
    }, {
      "referenceID" : 3,
      "context" : "Future work can also treat dataset maintenance as an optimization problem between the cost and gains of annotating new data (Bai et al., 2021).",
      "startOffset" : 124,
      "endOffset" : 142
    }, {
      "referenceID" : 33,
      "context" : "Our experiments revealed considerable variation in temporal degradation accross tasks, more so than found in previous studies (Röttger and Pierrehumbert, 2021).",
      "startOffset" : 126,
      "endOffset" : 159
    } ],
    "year" : 0,
    "abstractText" : "When an NLP model is trained on text data from one time period and tested or deployed on data from another, the resulting temporal misalignment can degrade end-task performance. In this work, we establish a suite of eight diverse tasks across different domains (social media, science papers, news, and reviews) and periods of time (spanning five years or more) to quantify the effects of temporal misalignment. Our study is focused on the ubiquitous setting where a pretrained model is optionally adapted through continued domainspecific pretraining, followed by task-specific finetuning. We establish a suite of tasks across multiple domains to study temporal misalignment in modern NLP systems. We find stronger effects of temporal misalignment on task performance than have been previously reported. We also find that, while temporal adaptation through continued pretraining can help, these gains are small compared to task-specific finetuning on data from the target time period. Our findings motivate continued research to improve temporal robustness of NLP models.1",
    "creator" : null
  }
}