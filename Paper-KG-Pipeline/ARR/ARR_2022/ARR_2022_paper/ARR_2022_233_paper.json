{
  "name" : "ARR_2022_233_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "E-KAR: A Benchmark for Rationalizing Natural Language Analogical Reasoning",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Analogy holds a vital place in human cognition, driving the discovery of new insights and the justification of everyday reasoning (Johnson-Laird, 2006; Gentner and Smith, 2012; Bartha, 2013; Bengio et al., 2021). Due to their unique value in many fields such as creativity (Goel, 1997) and education (Thagard, 1992), analogy and analogical reasoning have become a focus in AI research. The grand question is, are artificial neural networks also capable of recognizing analogies?\nRelatively little attention has been paid in NLP to answer this question. The problem of recognizing analogies is mainly benchmarked in the form of (A:B::C:D) (Turney et al., 2003; Mikolov et al., 2013b; Gladkova et al., 2016; Li et al., 2018a) and targeted for testing the ability of pre-trained word embeddings. Given a tuple of terms as query (e.g.,\n1Data will be released upon the publication of this paper.\ntea:teapot:teacup) and a list of candidate answers as in Figure 1, a model needs to find the most analogous candidate to the query, which is C in the example since it matches the relations inherent in the query better than others.\nMost methods (Mikolov et al., 2013a; Levy and Goldberg, 2014; Pennington et al., 2014) hold a connectionist assumption (Feldman and Ballard, 1982) of linear analogy (Ethayarajh et al., 2019), that the relation between two words can be estimated by vector arithmetic of word embeddings. For example, ~king − ~man + ~woman = ~queen.\nHowever, current benchmarks focus on the recognition of binary analogies such as syntactic, morphological and direct semantic (e.g., is_a and synonym_of ) relations. And the analogical reasoning procedure behind them is far beyond the scope of this line of research.\nHowever, how to explain and rationalize analogical reasoning remains to be the major challenge. Psychological literature (Gick and Holyoak, 1983; Gentner, 1983; Minnameier, 2010) suggests that analogical reasoning follows the structure-mapping process. That is, a target (the domain where a problem must be solved, i.e., candidates) and a source (the domain where the analogy is drawn, i.e., the query) are matched, and the relevant features of the source have to be mapped onto the target. In Figure 1, source structures are drawn from the query and mapped onto candidates, where A, B, D all fail at certain structures. We argue that such a process can be verbalized into natural language to explain analogical reasoning.\nMoving from simply recognizing analogies to exploring human-like reasoning for neural models, we emphasize the importance of a new kind of analogical reasoning benchmark. To fill in this blank, we propose a first-of-its-kind benchmark for Explainable Knowledge-intensive Analogical Reasoning (E-KAR). We collect 1,665 analogical reasoning problems sourced from the publicly available Civil Service Examinations of China, which are challenging and knowledge-rich multiple-choice problems designed by domain experts. To justify the reasoning process, we follow the aforementioned guidelines from psychological theories and manually annotate explanations for each query and candidate answers in E-KAR. Since the annotation requires intensive involvement of knowledge and reasoning, we carefully design a double-check procedure for quality control. In summary, the contributions of this paper include:\n• We advance the traditional setting of word analogy recognition by introducing a knowledge-intensive analogical reasoning benchmark (E-KAR), which is first-of-itskind and challenging. • To justify the analogical reasoning process, we design free-text explanations according to theories on human cognition, and manually annotate them. • We define two tasks in E-KAR, i.e., analogical QA and explanation generation, and report\nthe performance of some state-of-the-art neural models. We discuss the potentials of this benchmark and hope it facilitates future research on analogical reasoning."
    }, {
      "heading" : "2 Related Work",
      "text" : "Word Analogy Recognition in NLP Benchmarks for word analogy recognition (Turney et al., 2003; Mikolov et al., 2013b; Gladkova et al., 2016; Li et al., 2018a) examine mostly linear relations between words (Ethayarajh et al., 2019). Such analogies can often be effectively solved by vector arithmetic for neural word embeddings, such as Word2Vec (Mikolov et al., 2013a) and GloVe (Pennington et al., 2014). Recent studies (Brown et al., 2020; Ushio et al., 2021) also test such ability of pre-trained language models (PLMs) (Radford et al., 2019; Devlin et al., 2019; Brown et al., 2020) on these benchmarks. An exceptional benchmark is Li et al. (2020), where they build a knowledgeenhanced analogy benchmark that leverages word sense definitions in a commonsense knowledge base (Ma and Shih, 2018). However, these benchmarks are mainly set up for evaluating learned representations, and few of them ever investigated the analogical reasoning skills for neural models. Thus, the goal of this work largely differs from this line of research, as we aim to build a knowledge-intensive benchmark to teach neural models analogical reasoning for correct thinking.\nReasoning Benchmarks from Examinations There are abundant benchmarks derived from human examinations to facilitate the study of machine reasoning (Clark et al., 2016; Schoenick et al., 2017). For example, RACE (Lai et al., 2017) is collected from the English exams for middle and high school students, focusing on skills of passage summarization and attitude analysis. ARC (Clark et al., 2018) contains natural, grade-school science questions authored for human tests. MCQA (Guo et al., 2017), GeoSQA (Huang et al., 2019) and GCRC (Tan et al., 2021) are sourced from national college entrance exams of China, measuring a comprehensive set of reasoning abilities. LogiQA (Liu et al., 2020a) consists of logical reading comprehension problems from Civil Service Exams of China, which is also our source of analogical problems. ReClor (Yu et al., 2020) and LR-LSAT (Wang et al., 2021), collected from Law School Admission Test, aim for testing logical reasoning abilities. In our work, we focus on analogical reasoning skills for\nmachines and additionally equip E-KAR with annotated explanations to rationalize reasoning.\nExplainable NLP Datasets One of the most prominent objectives in machine reasoning is giving reasons or explanations for a prediction. In current datasets for explainable NLP, such reasons can be categorized into three classes (Wiegreffe and Marasović, 2021): 1) highlights explanations (Camburu et al., 2018; Yang et al., 2018; Thorne et al., 2018; Kwiatkowski et al., 2019), which are subsets of the input elements to explain a prediction, e.g., words or sentences; 2) free-text explanations (Camburu et al., 2018; Zellers et al., 2019; Aggarwal et al., 2021) that are textual explanations for justification; 3) structured explanations (Mihaylov et al., 2018; Khot et al., 2020; Clark et al., 2020; Jhamtani and Clark, 2020; Geva et al., 2021), which are not fully free-text and generally follow certain structures such as a chain of facts. The explanations can be utilized to augment (Rajani et al., 2019), supervise (Camburu et al., 2020) and evaluate (DeYoung et al., 2020) the predictions of neural models. In this work, we phrase analogical reasoning itself as an instance of machine reasoning tasks, advancing the research on analogical reasoning from the perspectives of data collection."
    }, {
      "heading" : "3 Explainable Analogical Reasoning",
      "text" : "In this work, we consider a classic setting of analogical reasoning within NLP: recognizing word/term analogies.2 This task can be formulated as multiplechoice question-answering. Given a query tuple Q with k (two or three) terms, and m candidate answer tuples A = {Ai}mi=1, the goal is to find the most analogous one in the candidates to the query.\nWe advocate that reasoning is about giving reasons explaining a prediction. In order to teach machines to analogize as humans do, we draw inspiration from theories in cognitive psychology to design the forms of explanations."
    }, {
      "heading" : "3.1 Analogical Reasoning: A Psychological Perspective",
      "text" : "Before designing suitable forms of explanations, we introduce some important theories from cognitive psychology for a better understanding of analogical reasoning. In the psychological literature, analogical reasoning is described as a schemainduction (Gick and Holyoak, 1983) or structure-\n2Here, “term” corresponds to “word” in previous analogy benchmarks, but allows for multiple words.\nmapping (Gentner, 1983) process. Peirce (1896) claimed that analogy is a combination of abductive and inductive reasoning. Minnameier (2010) further developed the inferential process of analogy into three steps, which we take as the guidelines for designing explanations:\n1. A possibly suitable structure in the source domain is abduced from the target domain, which might also work for the target problem; 2. The specific concepts of the source structure have to be replaced by suitable target concepts (by an inductive inference); 3. The validity of the transformation is judged w.r.t. solving the target problem.\nTake Figure 1 for example. Source structures can be abduced that both term 2 (teapot) and term 3 (teacup) belong to a concept, and term 1 (tea) can be transported from term 2 to term 3. The mapping naturally reveals the validity, for example, candidate A is wrong because passengers do not follow a unidirectional transportation (i.e., from bus to taxi) but a bidirectional one."
    }, {
      "heading" : "3.2 Explanations for Analogical Reasoning",
      "text" : "Following the above guidelines, the explanations for the analogical reasoning task should also include three parts: 1) description of suitable structures for the query; 2) how the structure is mapped into candidates; and 3) reasons to justify whether the mapping is correct, such as commonsense knowledge. To this end, we define free-text explanation for analogical reasoning, which is one of the most expressive and commonly-used explanations (Wiegreffe and Marasović, 2021). We ensure the free-text explanations to be self-contained, knowledge-rich, and sufficient to solve the problem as a substitute for the original input.\nSpecifically, for each query (Q) and candidate (Ai), we define free-text explanations EQ and EAi . Following the guidelines in § 3.1, EQ should describe the best suitable inherent structure in a query. EAi should decide the correctness of candidate Ai and provide facts as support evidence. Note that the decision should be drawn by mapping candidate terms into the structure expressed in EQ correspondingly, which is analogous to template-filling.\n4 The E-KAR Benchmark\nPrevious benchmarks consider recognizing word analogies as testbeds for evaluating pre-trained\nword embeddings. In this work, we take a step forward and build a new kind of benchmark E-KAR to facilitate the study of analogical reasoning."
    }, {
      "heading" : "4.1 Dataset Collection",
      "text" : "We build our dataset upon the publicly available questions of Civil Service Exams of China (CSE), which is a comprehensive test for candidates’ critical thinking and problem-solving abilities. CSE consists of problems that test various types of reasoning skills, such as graphical reasoning, logical reasoning and comprehension (Liu et al., 2020b), analogical reasoning, etc.\nWe collect in total 1,665 analogical reasoning problems from CSE over the years. One of the prominent features in CSE problems is the intensive involvement of commonsense, encyclopedic, and idiom knowledge. For example, one needs to be aware of the commonsense that “the tide is caused by both Lunar gravity and Solar gravity”. More importantly, one needs to know a negated fact in order to reject a candidate, such as the fact that “husband is not a job” or “a car is not made of tires”. We keep mainly those requiring knowledge and logical reasoning skills. The rest is manually removed, such as ones testing mathematics, morphology, and phonics, as well as the problems with terms larger than three.\nEach problem consists of a query term tuple and four candidate answer tuples of terms, as shown in Figure 1. The dataset is randomly split into training, development, and test set at the ratio of 7:1:2. We compare E-KAR with previous benchmarks in Table 1, including SAT (Turney et al., 2003), Google (Mikolov et al., 2013b) and BATS (Gladkova et al., 2016). There are 35.3% problems with three terms in E-KAR, whereas previous ones only consist of two, making E-KAR more challenging.\nCorpus with Background Knowledge We further build a corpus to aid the understanding of terms like idioms and rare ones that current neural networks struggle to comprehend. The corpus is built upon an encyclopedia3 and a thesaurus4, which are both one of the largest and most widely-used Chinese sources of their kind. Detailed statistics of coverage are reported in Table 2. Overall, the corpus covers 89.64% of all terms in E-KAR, showing its richness for knowledge coverage."
    }, {
      "heading" : "4.2 Manual Annotation of Explanations",
      "text" : "We work with a private company for annotating the explanations defined in § 3.2. Before annotation starts, we conduct a training session for all annotators to fully understand the requirements and pick the capable ones based on a selection test. The selected workers are allocated into two teams, a team of explanation constructors and a team of checkers, where the checkers achieves better scores in the test. All of them are paid above the local minimum wage. The annotation consists of two stages: 1) the construction stage for writing explanations, and 2) the double-check stage for quality control.\nConstruction During annotation, each problem is assigned to a constructor to build five sentences of explanations: one for query and four for candidate answers. The explanations are required to be: 1) fluent and factually correct, 2) able to solve the problem on their own, and 3) knowledge-rich. To reduce the labeling difficulty, we offer them sentences from the retrieved corpus for reference, while allowing them to use the search engine for querying the Internet.\nFirst-round Checking Afterward, a problem with five annotated explanations is fed to a checker for a first-round checking. The checker decides\n3Baidu Encyclopedia (https://www.baike.baidu.com). 4Xinhua Chinese Dictionary (https://www.zdic.net).\nwhether to accept an explanation sentence according to the criteria in the construction stage. The rejected ones are sent back to the construction team for revision along with reasons to reject, which serves to re-train the construction team. The process repeats until a batch reaches 90% accuracy. Then, a second-round checking initiates.\nSecond-round Checking A verified batch is presented to authors for double-checking. Authors conduct random inspections, and unqualified annotations are sent back with reasons to the check team to fine-tune their checking criteria, which in turn regularize the construction team. The process also repeats until a batch reaches 95% accuracy.\nIn the end, the authors manually calibrate every explanation and acquire 1,665 analogical problems and a total number of 8,325 (5×1,665) free-text explanations, with an average of 31.9 characters per sentence.\n4.3 Shared Tasks in E-KAR\nWe define two shared tasks, explanation generation (EG) and multiple-choice question-answering (QA) for teaching models how to analogize. We denote input as X = (Q,A), output as Y , and explanations as E . Thus, the tasks can be formulated as PEG(E|X ) and PQA(Y|X ). Figure 2 shows the examples of input and output.\nTask 1: Analogical QA As introduced in § 3, the analogical QA is be formulated as PQA(Y|X ). The QA task requires an understanding of the relationship between the query and each of the candidates to find the correct answer. For evaluation, we directly use the accuracy of multiple-choice QA.\nNote that all candidates may be related to the query tuple from certain perspectives, the challenge lies in finding the most related one. That is, we have to identify the inherent connections and relations between terms in the query and candidates, considering properties such as linguistic features,\nmeaning, and order of terms, commonsense knowledge, etc. For example, the error for candidate D in Figure 1 can be attributed to the incorrect term order, though three terms follow a similar commonsense relationship as seen in the query. Hence, the best choice is C.\nTask 2: Explanation Generation This task aims to produce the intermediate reasoning process of analogical reasoning as seen in Figure 2(b), formulated as PEG(E|X ). Such explanations serve as training supervisions to explain and improve model predictions. As defined in § 3.2, we aim to generate EQ and EAi for each query and candidate answer, where the former serves as the abduced source structures to be mapped onto the latter. The generated text can be evaluated with text generation metrics such as ROUGE (Lin, 2004), MoverScore (Zhao et al., 2019), BERTScore (Zhang et al., 2020) and BLEURT (Sellam et al., 2020). However, great challenges remain for automatically evaluating semantic-rich text (Celikyilmaz et al., 2020)."
    }, {
      "heading" : "5 Methods",
      "text" : "We evaluate some of the state-of-the-art neural models on both tasks of E-KAR. The implementation details are reported in Appendix A."
    }, {
      "heading" : "5.1 Baselines for Analogical QA",
      "text" : "Pre-trained Methods As pre-trained-only baselines, we adopt three static word embeddings that have shown their effectiveness in previous analogy tasks: Word2Vec (Mikolov et al., 2013a), GloVe (Pennington et al., 2014) and FastText (Bojanowski et al., 2017). We also test contextualized embeddings from PLMs, including BERT (Devlin et al., 2019) and RoBERTa (Liu et al., 2019). The averaged token representation is taken as the term representation. A query or a candidate is calculated as the sum of the representations of each term pair, which is represented as the embedding vector differences (Hakami and Bollegala, 2017; Ushio et al., 2021). The candidate with the highest cosine similarity to the query is chosen as the predicted answer.\nFine-tuned Methods We also set up fine-tuned baselines with PLMs (BERT and RoBERTa). Since previous benchmarks do not have a training set, we only fine-tune the models on their development set. The query and candidates are respectively verbalized into text using simple prompts such as\n“A:B::C:D::E:F”. Each candidate is concatenated with the query into one sentence, which is fed into a PLM for contextualized representation learning. Then, averaged hidden states are fed to an MLP layer and a softmax layer for classification. Besides, the semantics of terms in the problem can be enriched with background knowledge K from the corpus. Given a term, we retrieve the first knowledge sentence from the corpus, and concatenate it to the original input. The parameters are fine-tuned during training.\nHuman Evaluation We also ask three undergraduate and graduate students to solve the randomly sampled 200 problems without any hints, and report the averaged score of them as human performance."
    }, {
      "heading" : "5.2 Baselines for Explanation Generation",
      "text" : "We formulate the EG task in a sequence-tosequence (Seq2Seq) paradigm. Although the explanation is individually specific to each query and candidate, the generator has to take into account the whole problem for generating with the best source structure (as in § 3.1) and thus finding the most analogous candidate. Thus, we feed into the model the concatenation of the query and all candidates, and the model is trained to generate different explanations by changing the prefixes, e.g., “Generate: Q/Ai”. The Seq2Seq model is instantiated with state-of-the-art pre-trained language models for Seq2Seq tasks, including BART (Lewis et al., 2020) and T5 (Raffel et al., 2020)."
    }, {
      "heading" : "6 Results and Analysis",
      "text" : "In this section, we wish to answer three questions: Q1) Can models do knowledge-intensive analogical QA? Q2) Can models generate rational reasons for analogical thinking? Q3) How do different hints help humans solve analogical problems?\nCategorization of Problems We first manually categorize the relational types of problems in E-KAR according to a pre-defined schema. Note that, unlike free text, we are unable to induce a comprehensive set of relations that covers all candidates due to the complexity of CSE problems. As a result, we carefully assign at least one relation to each query. To facilitate analysis, we also try to assign relations to each candidate and query in the development and test set, ending up covering 76% of the candidates and 100% of the queries.\nWe refer to several sources of word analogy definitions and textbooks for analogy tests (listed in Appendix B), and categorize the relations into five meta-relations (as well as their coverage in the test set) and several accompanying sub-relations:\n1. Semantic (R1, 8.88%), the similarity or difference in the meaning of terms, including synonym_of and antonym_of ; 2. Extension (R2, 41.60%), the relation between the extension of terms, including is_a, contradictory_to, etc.; 3. Intension (R3, 34.83%), terms relate to each other by inherent properties, including made_of, has_function, etc.; 4. Grammar (R4, 7.74%), the grammatical relations between terms, including subjectpredicate, head-modifier, etc.; 5. Association (R5, 6.95%), logical association between terms, including result_of, sufficient_to, etc.\nComplete sub-relations are presented in Appendix B, as well as their definitions and examples."
    }, {
      "heading" : "6.1 Can models do knowledge-intensive analogical QA?",
      "text" : "Table 3 reports the accuracy results of baseline methods on previous analogy tasks and the QA task in E-KAR. We find that contextualized word embeddings from PLMs are not very competitive against static word embeddings in previous analogy tasks, which is consistent with the findings in Peters et al. (2018). In more knowledge-rich datasets such as E-KAR, the opposite conclusion can be made, with PLMs prevailing over static word embeddings. Also, humans achieve 77.8% accuracy in E-KAR, indicating the challenge of this task as well as showing that neural models still fall far behind human performance.\nPerformance from contextualized representations can be improved in all tasks through finetuning, especially for E-KAR, where accuracy increases by roughly 5 to 6 points. When augmented with knowledge from corpus through naïve sentence concatenation, however, the accuracy drops considerably. This is probably because the first sentence of a term in the corpus only describes limited properties of the term itself, but analogical reasoning requires the deep understanding of the relationship between the terms. Also, with the concatenation of knowledge sentences, longer input distracts a model from solving the problem. We\nbelieve a more delicate way of knowledge injection in this task is worth investigating in the future. Notably, gold explanations help boost the accuracy of a RoBERTa model from 50.1% to 95.0%, showing good quality.\nError Analysis We further conduct an error analysis based on the results in E-KAR predicted by fine-tuned RoBERTa (large). The erroneous ones are classified based on the manually annotated meta-relations and sub-relations of queries, which are fine-grained analysis tools for a model’s predictions. Figure 3(a) shows that the model perform evenly bad on all meta-relations, with R2 (Extension) being the most error-prone one (only 40.3% accuracy) and R3 (Intension) being the least one (56.8% accuracy). Figure 3(b) presents the error rate of finer-grained sub-relations with more than 10 cases. We find that, consistent with Figure 3(a), the three most error-prone sub-relations is_a, part_of and juxtaposition_of all belong to R2 (Extension). Besides, the model seems to do well in linguistic knowledge, with verb-object achieving only 33.3% error rate. These findings may shed light on future directions for knowledge-injection and reasoning with language models."
    }, {
      "heading" : "6.2 Can models generate rational reasons for analogical thinking?",
      "text" : "We report the automatic evaluation results of generated explanations in Table 4. However, such results\nR1: Sem antic R2: Extension R3: Intension R4: Gram m ar R5: Association\n5.2% 3.3%\n16.9% 21.2%\n4.6%\n4.2%2.9%\n22.2%\n14.3%\n5.2%\nTrue False\n(a) Meta-relations distributions and their error ratios.\nis_a part_of\njuxtaposition_of\ncause_effect antonym_of synonym_of\n...\ncorrespond_to\nverb-object\n0 20 40 60 80\n33.3\n39.3\n0.0\n46.7\n46.7\n50.0\n51.7\n63.3\n72.0\n(b) Sub-relations in a sorted order of error rate.\nhardly mean anything due to the incapability to evaluate semantic-rich text of current automatic metrics. Therefore, we also randomly select 100 sentences generated by a BART (large) for manual inspection. Interestingly, we find the generated explanations do not contain much of the negated facts, which are important to refute a candidate, as mentioned in § 4.1. For explanations of refuted candidates, we find ∼90% gold ones contain negated facts for deciding correctness. However, the number drops to ∼23% in the generated ones. An interesting conclusion can be drawn that current generative models do not seem to know how to generate a negated fact which is still truthful, such as “feeling can not guide psychological reaction.” since feeling is a reaction.\nThe fact also questions the astonishing performance boost (from 50.1% to 95.0%) in QA by gold explanations, as it could be biased towards surfacelevel negation. To debias this, we conduct a simple ablation study by directly removing the clauses containing the negation word “不”(not) in the test set, and still achieve 90.9% in QA accuracy. These findings point to the potential of a high quality analogical reasoning system given correct generated explanations.\nTo sum up, the errors for generated explanations can be roughly categorized into three classes: 1) incapable of generating negated facts; 2) generating\nfactually incorrect statements; 3) biasing towards common patterns, such as “term 1 and term 2 have similar meanings” and “term 1 is a term 2”. For example, in Table 5, both generated EQ and EA are factually incorrect, and BART fails to generate the negated fact that “both are not exclusively made of one component.”"
    }, {
      "heading" : "6.3 How do different hints help humans solve analogical problems?",
      "text" : "We acknowledge the limitation of automatic evaluation for explanation generation and knowledge retrieval. Therefore, we hope to figure out how background knowledge and different explanations help humans solve analogical problems.\nWe ask three graduate and undergraduate students as participants to complete randomly sampled 150 analogical problems. The participants are exposed with three settings of hints (i.e., 50 problems per setting): 1) retrieved knowledge, 2) generated explanations by a BART (large), and 3) gold explanations. Participants are asked to rate each hint based on the degree of difficulty it reduces when thinking, including unhelpful (0), somewhat helpful (1, answers can be drawn partly from hints), and very helpful (2, answers can be largely drawn from hints).5\nAccording to Table 6, the gold explanations undoubtedly is the most helpful hint among them, showing its good quality. The generated explanations receives 50.7% votes of somewhat helpful (1) and 14.7% votes of very helpful (2). The retrieved knowledge achieves the worst performance in help-\n5They reach moderate inter-rater agreement with Fleiss’ κ = 0.427.\nfulness, which can be attributed to the fact that the retrieval is purely off-the-shelf. Still, more than a half cases of retrieved knowledge (54.6%) are decided to be helpful to different extent."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this work, we propose a first-of-its-kind benchmark E-KAR for explainable analogical reasoning, which sets a concrete playground and evaluation benchmark to boost the development of human-like analogical reasoning algorithms. The E-KAR benchmark is featured by its rich coverage in knowledge and well-designed free-text explanations to rationalize analogical reasoning process.\nHowever, there are still many open questions that need to be addressed. For example, humans solve the analogical problems in a trial-and-error manner, but the annotated explanations in E-KAR are mostly post-hoc and reflect only the final step of the reasoning. Such explanations cannot offer supervision for intermediate reasoning, though it is an interesting question whether an intelligent model should be deeply supervised at every step (Tafjord et al., 2021). Furthermore, E-KAR only presents one feasible explanation for each problem, whereas there may be several.\nThis benchmark also invites analogical reasoning models that can effectively interact with extra knowledge as well as better metrics for evaluating free-text explanations. It remains to be a great challenge to generate factually correct explanations as well as negated facts. Especially, the latter is relatively under-explored in the research community but of much importance. Finally, whether the analogical QA system can correctly exploit explanations and background knowledge is also worth investigating, which may intersect with researches on debiasing (Tang et al., 2020; Niu et al., 2021).\nWe hope this dataset to be a valuable supplement to future research on natural language reasoning, especially for researches on analogical reasoning and explainable NLP.\nEthical Considerations\nThis paper proposes a new kind of analogical benchmark with explanations to rationalize models’ predictions. The dataset is collected from Civil Service Exams of China, which is publicly available and has been used in other public datasets before, such as LogiQA (Liu et al., 2020a). The annotated explanations for each problem in our dataset are crowd-sourced by working with a private company. The construction team remains anonymous to the authors, and the annotation quality is guaranteed by the double-check strategy as mentioned in § 4.2. We ensure that all annotators’ privacy rights are respected in the annotation process. All annotators have been paid above local minimum wage and consented to use the datasets for research purposes covered in our paper."
    }, {
      "heading" : "B Detailed Relation Definitions",
      "text" : "For designing the relation taxonomy, we refer to a number of sources for categorizing types of analogy tests, including MAT6, Fibonicci7, Offcn Education (in Chinese)8 and Huatu Education (in Chinese)9, etc.\nThe complete set of meta-relations and subrelations are presented in Table 7.\n6http://www.west.net/s̃tewart/mat/analogies_types.htm 7https://www.fibonicci.com/verbal-reasoning/analogies-\nexamples/ 8https://www.offcn.com 9https://www.huatu.com"
    } ],
    "references" : [ {
      "title" : "Explanations for CommonsenseQA: New Dataset and Models",
      "author" : [ "Shourya Aggarwal", "Divyanshu Mandowara", "Vishwajeet Agrawal", "Dinesh Khandelwal", "Parag Singla", "Dinesh Garg." ],
      "venue" : "Proceedings of the 59th Annual Meeting of the Association",
      "citeRegEx" : "Aggarwal et al\\.,? 2021",
      "shortCiteRegEx" : "Aggarwal et al\\.",
      "year" : 2021
    }, {
      "title" : "Analogy and analogical reasoning",
      "author" : [ "Paul Bartha" ],
      "venue" : null,
      "citeRegEx" : "Bartha.,? \\Q2013\\E",
      "shortCiteRegEx" : "Bartha.",
      "year" : 2013
    }, {
      "title" : "Deep learning for ai",
      "author" : [ "Yoshua Bengio", "Yann Lecun", "Geoffrey Hinton." ],
      "venue" : "Commun. ACM, 64(7):58–65.",
      "citeRegEx" : "Bengio et al\\.,? 2021",
      "shortCiteRegEx" : "Bengio et al\\.",
      "year" : 2021
    }, {
      "title" : "Enriching word vectors with subword information",
      "author" : [ "Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 5:135–146.",
      "citeRegEx" : "Bojanowski et al\\.,? 2017",
      "shortCiteRegEx" : "Bojanowski et al\\.",
      "year" : 2017
    }, {
      "title" : "Language models are few-shot learners",
      "author" : [ "Tom Brown", "Benjamin Mann", "Nick Ryder", "Melanie Subbiah", "Jared D Kaplan", "Prafulla Dhariwal", "Arvind Neelakantan", "Pranav Shyam", "Girish Sastry", "Amanda Askell" ],
      "venue" : null,
      "citeRegEx" : "Brown et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Brown et al\\.",
      "year" : 2020
    }, {
      "title" : "e-snli: Natural language inference with natural language explanations",
      "author" : [ "Oana-Maria Camburu", "Tim Rocktäschel", "Thomas Lukasiewicz", "Phil Blunsom." ],
      "venue" : "Advances in Neural Information Processing Systems, volume 31. Curran Associates, Inc.",
      "citeRegEx" : "Camburu et al\\.,? 2018",
      "shortCiteRegEx" : "Camburu et al\\.",
      "year" : 2018
    }, {
      "title" : "Make up your mind! adversarial generation of inconsistent natural language explanations",
      "author" : [ "Oana-Maria Camburu", "Brendan Shillingford", "Pasquale Minervini", "Thomas Lukasiewicz", "Phil Blunsom." ],
      "venue" : "In",
      "citeRegEx" : "Camburu et al\\.,? 2020",
      "shortCiteRegEx" : "Camburu et al\\.",
      "year" : 2020
    }, {
      "title" : "Evaluation of text generation: A survey",
      "author" : [ "Asli Celikyilmaz", "Elizabeth Clark", "Jianfeng Gao." ],
      "venue" : "arXiv preprint arXiv:2006.14799.",
      "citeRegEx" : "Celikyilmaz et al\\.,? 2020",
      "shortCiteRegEx" : "Celikyilmaz et al\\.",
      "year" : 2020
    }, {
      "title" : "Think you have solved question answering? try arc, the ai2 reasoning challenge",
      "author" : [ "Peter Clark", "Isaac Cowhey", "Oren Etzioni", "Tushar Khot", "Ashish Sabharwal", "Carissa Schoenick", "Oyvind Tafjord." ],
      "venue" : "arXiv preprint arXiv:1803.05457.",
      "citeRegEx" : "Clark et al\\.,? 2018",
      "shortCiteRegEx" : "Clark et al\\.",
      "year" : 2018
    }, {
      "title" : "Combining retrieval, statistics, and inference to answer elementary science questions",
      "author" : [ "Peter Clark", "Oren Etzioni", "Tushar Khot", "Ashish Sabharwal", "Oyvind Tafjord", "Peter Turney", "Daniel Khashabi." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial",
      "citeRegEx" : "Clark et al\\.,? 2016",
      "shortCiteRegEx" : "Clark et al\\.",
      "year" : 2016
    }, {
      "title" : "Transformers as Soft Reasoners over Language",
      "author" : [ "Peter Clark", "Oyvind Tafjord", "Kyle Richardson." ],
      "venue" : "pages 3882–3890.",
      "citeRegEx" : "Clark et al\\.,? 2020",
      "shortCiteRegEx" : "Clark et al\\.",
      "year" : 2020
    }, {
      "title" : "Revisiting pretrained models for Chinese natural language processing",
      "author" : [ "Yiming Cui", "Wanxiang Che", "Ting Liu", "Bing Qin", "Shijin Wang", "Guoping Hu." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing:",
      "citeRegEx" : "Cui et al\\.,? 2020",
      "shortCiteRegEx" : "Cui et al\\.",
      "year" : 2020
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "ERASER: A benchmark to evaluate rationalized NLP models",
      "author" : [ "Jay DeYoung", "Sarthak Jain", "Nazneen Fatema Rajani", "Eric Lehman", "Caiming Xiong", "Richard Socher", "Byron C. Wallace." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for",
      "citeRegEx" : "DeYoung et al\\.,? 2020",
      "shortCiteRegEx" : "DeYoung et al\\.",
      "year" : 2020
    }, {
      "title" : "Towards understanding linear word analogies",
      "author" : [ "Kawin Ethayarajh", "David Duvenaud", "Graeme Hirst." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 3253–3262, Florence, Italy. Association for",
      "citeRegEx" : "Ethayarajh et al\\.,? 2019",
      "shortCiteRegEx" : "Ethayarajh et al\\.",
      "year" : 2019
    }, {
      "title" : "Connectionist models and their properties",
      "author" : [ "Jerome A Feldman", "Dana H Ballard." ],
      "venue" : "Cognitive science, 6(3):205–254.",
      "citeRegEx" : "Feldman and Ballard.,? 1982",
      "shortCiteRegEx" : "Feldman and Ballard.",
      "year" : 1982
    }, {
      "title" : "Structure-mapping: A theoretical framework for analogy",
      "author" : [ "Dedre Gentner." ],
      "venue" : "Cognitive science, 7(2):155–170. 9",
      "citeRegEx" : "Gentner.,? 1983",
      "shortCiteRegEx" : "Gentner.",
      "year" : 1983
    }, {
      "title" : "Analogical reasoning",
      "author" : [ "Dedre Gentner", "Linsey Smith." ],
      "venue" : "Encyclopedia of human behavior, 2:130– 136.",
      "citeRegEx" : "Gentner and Smith.,? 2012",
      "shortCiteRegEx" : "Gentner and Smith.",
      "year" : 2012
    }, {
      "title" : "Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies",
      "author" : [ "Mor Geva", "Daniel Khashabi", "Elad Segal", "Tushar Khot", "Dan Roth", "Jonathan Berant." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 9:346–361.",
      "citeRegEx" : "Geva et al\\.,? 2021",
      "shortCiteRegEx" : "Geva et al\\.",
      "year" : 2021
    }, {
      "title" : "Schema induction and analogical transfer",
      "author" : [ "Mary L Gick", "Keith J Holyoak." ],
      "venue" : "Cognitive psychology, 15(1):1–38.",
      "citeRegEx" : "Gick and Holyoak.,? 1983",
      "shortCiteRegEx" : "Gick and Holyoak.",
      "year" : 1983
    }, {
      "title" : "Analogy-based detection of morphological and semantic relations with word embeddings: what works and what doesn’t",
      "author" : [ "Anna Gladkova", "Aleksandr Drozd", "Satoshi Matsuoka." ],
      "venue" : "Proceedings of the NAACL Student Research Workshop, pages 8–",
      "citeRegEx" : "Gladkova et al\\.,? 2016",
      "shortCiteRegEx" : "Gladkova et al\\.",
      "year" : 2016
    }, {
      "title" : "Design, analogy, and creativity",
      "author" : [ "Ashok K Goel." ],
      "venue" : "IEEE expert, 12(3):62–70.",
      "citeRegEx" : "Goel.,? 1997",
      "shortCiteRegEx" : "Goel.",
      "year" : 1997
    }, {
      "title" : "Which is the effective way for gaokao: Information retrieval or neural networks",
      "author" : [ "Shangmin Guo", "Xiangrong Zeng", "Shizhu He", "Kang Liu", "Jun Zhao" ],
      "venue" : "In Proceedings of the 15th Conference of the European Chapter of the Association",
      "citeRegEx" : "Guo et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2017
    }, {
      "title" : "Compositional approaches for representing relations between words: A comparative study",
      "author" : [ "Huda Hakami", "Danushka Bollegala." ],
      "venue" : "KnowledgeBased Systems, 136:172–182.",
      "citeRegEx" : "Hakami and Bollegala.,? 2017",
      "shortCiteRegEx" : "Hakami and Bollegala.",
      "year" : 2017
    }, {
      "title" : "Geosqa: A benchmark for scenario-based question answering in the geography domain at high school level",
      "author" : [ "Zixian Huang", "Yulin Shen", "Xiao Li", "Gong Cheng", "Lin Zhou", "Xinyu Dai", "Yuzhong Qu" ],
      "venue" : "In Proceedings of the 2019 Conference on Empirical",
      "citeRegEx" : "Huang et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2019
    }, {
      "title" : "Learning to explain: Datasets and models for identifying valid reasoning chains in multihop question-answering",
      "author" : [ "Harsh Jhamtani", "Peter Clark." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Jhamtani and Clark.,? 2020",
      "shortCiteRegEx" : "Jhamtani and Clark.",
      "year" : 2020
    }, {
      "title" : "How we reason",
      "author" : [ "Philip Nicholas Johnson-Laird." ],
      "venue" : "Oxford University Press, USA.",
      "citeRegEx" : "Johnson.Laird.,? 2006",
      "shortCiteRegEx" : "Johnson.Laird.",
      "year" : 2006
    }, {
      "title" : "Qasc: A dataset for question answering via sentence composition",
      "author" : [ "Tushar Khot", "Peter Clark", "Michal Guerquin", "Peter Jansen", "Ashish Sabharwal." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 8082–8090.",
      "citeRegEx" : "Khot et al\\.,? 2020",
      "shortCiteRegEx" : "Khot et al\\.",
      "year" : 2020
    }, {
      "title" : "Natural questions: A benchmark for question answering research",
      "author" : [ "Jakob Uszkoreit", "Quoc Le", "Slav Petrov." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 7:452–466.",
      "citeRegEx" : "Uszkoreit et al\\.,? 2019",
      "shortCiteRegEx" : "Uszkoreit et al\\.",
      "year" : 2019
    }, {
      "title" : "Race: Large-scale reading comprehension dataset from examinations",
      "author" : [ "Guokun Lai", "Qizhe Xie", "Hanxiao Liu", "Yiming Yang", "Eduard Hovy." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 785–",
      "citeRegEx" : "Lai et al\\.,? 2017",
      "shortCiteRegEx" : "Lai et al\\.",
      "year" : 2017
    }, {
      "title" : "Linguistic regularities in sparse and explicit word representations",
      "author" : [ "Omer Levy", "Yoav Goldberg." ],
      "venue" : "Proceedings of the Eighteenth Conference on Computational Natural Language Learning, pages 171–180, Ann Arbor, Michigan. Association",
      "citeRegEx" : "Levy and Goldberg.,? 2014",
      "shortCiteRegEx" : "Levy and Goldberg.",
      "year" : 2014
    }, {
      "title" : "BART: Denoising sequence-to-sequence pretraining for natural language",
      "author" : [ "Mike Lewis", "Yinhan Liu", "Naman Goyal", "Marjan Ghazvininejad", "Abdelrahman Mohamed", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer" ],
      "venue" : null,
      "citeRegEx" : "Lewis et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Lewis et al\\.",
      "year" : 2020
    }, {
      "title" : "CA-EHN: Commonsense analogy from E-HowNet",
      "author" : [ "Peng-Hsuan Li", "Tsan-Yu Yang", "Wei-Yun Ma." ],
      "venue" : "Proceedings of the 12th Language Resources and Evaluation Conference, pages 2984–2990, Marseille, France. European Language Resources Asso-",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Analogical reasoning on Chinese morphological and semantic relations",
      "author" : [ "Shen Li", "Zhe Zhao", "Renfen Hu", "Wensi Li", "Tao Liu", "Xiaoyong Du." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short",
      "citeRegEx" : "Li et al\\.,? 2018a",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2018
    }, {
      "title" : "Analogical reasoning on chinese morphological and semantic relations",
      "author" : [ "Shen Li", "Zhe Zhao", "Renfen Hu", "Wensi Li", "Tao Liu", "Xiaoyong Du." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short",
      "citeRegEx" : "Li et al\\.,? 2018b",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2018
    }, {
      "title" : "ROUGE: A package for automatic evaluation of summaries",
      "author" : [ "Chin-Yew Lin." ],
      "venue" : "Text Summarization Branches Out, pages 74–81, Barcelona, Spain. Association for Computational Linguistics.",
      "citeRegEx" : "Lin.,? 2004",
      "shortCiteRegEx" : "Lin.",
      "year" : 2004
    }, {
      "title" : "Logiqa: A challenge dataset for machine reading comprehension with logical reasoning",
      "author" : [ "Jian Liu", "Leyang Cui", "Hanmeng Liu", "Dandan Huang", "Yile Wang", "Yue Zhang." ],
      "venue" : "IJCAI. 10",
      "citeRegEx" : "Liu et al\\.,? 2020a",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Logiqa: A challenge dataset for machine reading comprehension with logical reasoning",
      "author" : [ "Jian Liu", "Leyang Cui", "Hanmeng Liu", "Dandan Huang", "Yile Wang", "Yue Zhang." ],
      "venue" : "Proceedings of the Twenty-Ninth International Joint Conference on Ar-",
      "citeRegEx" : "Liu et al\\.,? 2020b",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Roberta: A robustly optimized bert pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "arXiv preprint arXiv:1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Extended HowNet 2.0 – an entity-relation common-sense representation model",
      "author" : [ "Wei-Yun Ma", "Yueh-Yin Shih" ],
      "venue" : "In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018),",
      "citeRegEx" : "Ma and Shih.,? \\Q2018\\E",
      "shortCiteRegEx" : "Ma and Shih.",
      "year" : 2018
    }, {
      "title" : "Can a suit of armor conduct electricity? a new dataset for open book question answering",
      "author" : [ "Todor Mihaylov", "Peter Clark", "Tushar Khot", "Ashish Sabharwal." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Mihaylov et al\\.,? 2018",
      "shortCiteRegEx" : "Mihaylov et al\\.",
      "year" : 2018
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean." ],
      "venue" : "Advances in neural information processing systems, pages 3111–3119.",
      "citeRegEx" : "Mikolov et al\\.,? 2013a",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Linguistic regularities in continuous space word representations",
      "author" : [ "Tomas Mikolov", "Wen-tau Yih", "Geoffrey Zweig." ],
      "venue" : "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human",
      "citeRegEx" : "Mikolov et al\\.,? 2013b",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Abduction, induction, and analogy",
      "author" : [ "Gerhard Minnameier." ],
      "venue" : "Model-based reasoning in science and technology, pages 107–119. Springer.",
      "citeRegEx" : "Minnameier.,? 2010",
      "shortCiteRegEx" : "Minnameier.",
      "year" : 2010
    }, {
      "title" : "Counterfactual vqa: A cause-effect look at language bias",
      "author" : [ "Yulei Niu", "Kaihua Tang", "Hanwang Zhang", "Zhiwu Lu", "Xian-Sheng Hua", "Ji-Rong Wen." ],
      "venue" : "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12700–",
      "citeRegEx" : "Niu et al\\.,? 2021",
      "shortCiteRegEx" : "Niu et al\\.",
      "year" : 2021
    }, {
      "title" : "Lessons from the history of science",
      "author" : [ "Charles S Peirce." ],
      "venue" : "C. Hartshorne, 660.",
      "citeRegEx" : "Peirce.,? 1896",
      "shortCiteRegEx" : "Peirce.",
      "year" : 1896
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher D Manning." ],
      "venue" : "Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1532–1543.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Dissecting contextual word embeddings: Architecture and representation",
      "author" : [ "Matthew E. Peters", "Mark Neumann", "Luke Zettlemoyer", "Wen-tau Yih." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Peters et al\\.,? 2018",
      "shortCiteRegEx" : "Peters et al\\.",
      "year" : 2018
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever." ],
      "venue" : "OpenAI Blog, 1(8):9.",
      "citeRegEx" : "Radford et al\\.,? 2019",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "author" : [ "Colin Raffel", "Noam Shazeer", "Adam Roberts", "Katherine Lee", "Sharan Narang", "Michael Matena", "Yanqi Zhou", "Wei Li", "Peter J Liu." ],
      "venue" : "Journal of Machine Learning Research,",
      "citeRegEx" : "Raffel et al\\.,? 2020",
      "shortCiteRegEx" : "Raffel et al\\.",
      "year" : 2020
    }, {
      "title" : "Explain yourself! leveraging language models for commonsense reasoning",
      "author" : [ "Nazneen Fatema Rajani", "Bryan McCann", "Caiming Xiong", "Richard Socher." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguis-",
      "citeRegEx" : "Rajani et al\\.,? 2019",
      "shortCiteRegEx" : "Rajani et al\\.",
      "year" : 2019
    }, {
      "title" : "Moving beyond the turing test with the allen ai science challenge",
      "author" : [ "Carissa Schoenick", "Peter Clark", "Oyvind Tafjord", "Peter Turney", "Oren Etzioni." ],
      "venue" : "Communications of the ACM, 60(9):60–64.",
      "citeRegEx" : "Schoenick et al\\.,? 2017",
      "shortCiteRegEx" : "Schoenick et al\\.",
      "year" : 2017
    }, {
      "title" : "BLEURT: Learning robust metrics for text generation",
      "author" : [ "Thibault Sellam", "Dipanjan Das", "Ankur Parikh." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 7881–7892, Online. Association for Computa-",
      "citeRegEx" : "Sellam et al\\.,? 2020",
      "shortCiteRegEx" : "Sellam et al\\.",
      "year" : 2020
    }, {
      "title" : "Cpt: A pre-trained unbalanced transformer for both chinese language understanding and generation",
      "author" : [ "Yunfan Shao", "Zhichao Geng", "Yitao Liu", "Junqi Dai", "Fei Yang", "Li Zhe", "Hujun Bao", "Xipeng Qiu." ],
      "venue" : "arXiv preprint arXiv:2109.05729.",
      "citeRegEx" : "Shao et al\\.,? 2021",
      "shortCiteRegEx" : "Shao et al\\.",
      "year" : 2021
    }, {
      "title" : "ProofWriter: Generating implications, proofs, and abductive statements over natural language",
      "author" : [ "Oyvind Tafjord", "Bhavana Dalvi", "Peter Clark." ],
      "venue" : "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3621–3634, Online.",
      "citeRegEx" : "Tafjord et al\\.,? 2021",
      "shortCiteRegEx" : "Tafjord et al\\.",
      "year" : 2021
    }, {
      "title" : "GCRC: A new challenging MRC dataset from Gaokao Chinese for explainable evaluation",
      "author" : [ "Hongye Tan", "Xiaoyue Wang", "Yu Ji", "Ru Li", "Xiaoli Li", "Zhiwei Hu", "Yunxiao Zhao", "Xiaoqi Han." ],
      "venue" : "Findings of the Association for Computational Linguis-",
      "citeRegEx" : "Tan et al\\.,? 2021",
      "shortCiteRegEx" : "Tan et al\\.",
      "year" : 2021
    }, {
      "title" : "Long-tailed classification by keeping the good and removing the bad momentum causal effect",
      "author" : [ "Kaihua Tang", "Jianqiang Huang", "Hanwang Zhang." ],
      "venue" : "Advances in Neural Information Processing 11",
      "citeRegEx" : "Tang et al\\.,? 2020",
      "shortCiteRegEx" : "Tang et al\\.",
      "year" : 2020
    }, {
      "title" : "Analogy, explanation, and education",
      "author" : [ "Paul Thagard." ],
      "venue" : "Journal of Research in science Teaching, 29(6):537–544.",
      "citeRegEx" : "Thagard.,? 1992",
      "shortCiteRegEx" : "Thagard.",
      "year" : 1992
    }, {
      "title" : "FEVER: a large-scale dataset for fact extraction and VERification",
      "author" : [ "James Thorne", "Andreas Vlachos", "Christos Christodoulopoulos", "Arpit Mittal." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of",
      "citeRegEx" : "Thorne et al\\.,? 2018",
      "shortCiteRegEx" : "Thorne et al\\.",
      "year" : 2018
    }, {
      "title" : "Combining independent modules in lexical multiple-choice problems",
      "author" : [ "Peter D Turney", "Michael L Littman", "Jeffrey Bigham", "Victor Shnayder." ],
      "venue" : "Recent Advances in Natural Language Processing III: Selected Papers from RANLP, 2003:101–110.",
      "citeRegEx" : "Turney et al\\.,? 2003",
      "shortCiteRegEx" : "Turney et al\\.",
      "year" : 2003
    }, {
      "title" : "BERT is to NLP what AlexNet is to CV: Can pre-trained language models identify analogies",
      "author" : [ "Asahi Ushio", "Luis Espinosa Anke", "Steven Schockaert", "Jose Camacho-Collados" ],
      "venue" : "In Proceedings of the 59th Annual Meeting of the Association for Compu-",
      "citeRegEx" : "Ushio et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Ushio et al\\.",
      "year" : 2021
    }, {
      "title" : "From lsat: The progress and challenges of complex reasoning",
      "author" : [ "Siyuan Wang", "Zhongkun Liu", "Wanjun Zhong", "Ming Zhou", "Zhongyu Wei", "Zhumin Chen", "Nan Duan." ],
      "venue" : "arXiv preprint arXiv:2108.00648.",
      "citeRegEx" : "Wang et al\\.,? 2021",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2021
    }, {
      "title" : "Teach me to explain: A review of datasets for explainable nlp",
      "author" : [ "Sarah Wiegreffe", "Ana Marasović." ],
      "venue" : "Proceedings of NeurIPS.",
      "citeRegEx" : "Wiegreffe and Marasović.,? 2021",
      "shortCiteRegEx" : "Wiegreffe and Marasović.",
      "year" : 2021
    }, {
      "title" : "Transformers: State-of-the-art natural language processing",
      "author" : [ "Teven Le Scao", "Sylvain Gugger", "Mariama Drame", "Quentin Lhoest", "Alexander Rush." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing:",
      "citeRegEx" : "Scao et al\\.,? 2020",
      "shortCiteRegEx" : "Scao et al\\.",
      "year" : 2020
    }, {
      "title" : "HotpotQA: A dataset for diverse, explainable multi-hop question answering",
      "author" : [ "Zhilin Yang", "Peng Qi", "Saizheng Zhang", "Yoshua Bengio", "William Cohen", "Ruslan Salakhutdinov", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 2018 Conference on Em-",
      "citeRegEx" : "Yang et al\\.,? 2018",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2018
    }, {
      "title" : "Reclor: A reading comprehension dataset requiring logical reasoning",
      "author" : [ "Weihao Yu", "Zihang Jiang", "Yanfei Dong", "Jiashi Feng." ],
      "venue" : "International Conference on Learning Representations (ICLR).",
      "citeRegEx" : "Yu et al\\.,? 2020",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2020
    }, {
      "title" : "From recognition to cognition: Visual commonsense reasoning",
      "author" : [ "Rowan Zellers", "Yonatan Bisk", "Ali Farhadi", "Yejin Choi." ],
      "venue" : "The IEEE Conference on Computer Vision and Pattern Recognition (CVPR).",
      "citeRegEx" : "Zellers et al\\.,? 2019",
      "shortCiteRegEx" : "Zellers et al\\.",
      "year" : 2019
    }, {
      "title" : "Bertscore: Evaluating text generation with bert",
      "author" : [ "Tianyi Zhang", "Varsha Kishore", "Felix Wu", "Kilian Q. Weinberger", "Yoav Artzi." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Mengzi: Towards lightweight yet ingenious pre-trained models for chinese",
      "author" : [ "Zhuosheng Zhang", "Hanqing Zhang", "Keming Chen", "Yuhang Guo", "Jingyun Hua", "Yulong Wang", "Ming Zhou" ],
      "venue" : null,
      "citeRegEx" : "Zhang et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2021
    }, {
      "title" : "MoverScore: Text generation evaluating with contextualized embeddings and earth mover distance",
      "author" : [ "Wei Zhao", "Maxime Peyrard", "Fei Liu", "Yang Gao", "Christian M. Meyer", "Steffen Eger." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in",
      "citeRegEx" : "Zhao et al\\.,? 2019",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2019
    }, {
      "title" : "B Detailed Relation Definitions For designing the relation taxonomy, we refer to a number of sources for categorizing types of analogy",
      "author" : [ "BART by Shao" ],
      "venue" : null,
      "citeRegEx" : "Shao,? \\Q2021\\E",
      "shortCiteRegEx" : "Shao",
      "year" : 2021
    } ],
    "referenceMentions" : [ {
      "referenceID" : 26,
      "context" : "Analogy holds a vital place in human cognition, driving the discovery of new insights and the justification of everyday reasoning (Johnson-Laird, 2006; Gentner and Smith, 2012; Bartha, 2013; Bengio et al., 2021).",
      "startOffset" : 130,
      "endOffset" : 211
    }, {
      "referenceID" : 17,
      "context" : "Analogy holds a vital place in human cognition, driving the discovery of new insights and the justification of everyday reasoning (Johnson-Laird, 2006; Gentner and Smith, 2012; Bartha, 2013; Bengio et al., 2021).",
      "startOffset" : 130,
      "endOffset" : 211
    }, {
      "referenceID" : 1,
      "context" : "Analogy holds a vital place in human cognition, driving the discovery of new insights and the justification of everyday reasoning (Johnson-Laird, 2006; Gentner and Smith, 2012; Bartha, 2013; Bengio et al., 2021).",
      "startOffset" : 130,
      "endOffset" : 211
    }, {
      "referenceID" : 2,
      "context" : "Analogy holds a vital place in human cognition, driving the discovery of new insights and the justification of everyday reasoning (Johnson-Laird, 2006; Gentner and Smith, 2012; Bartha, 2013; Bengio et al., 2021).",
      "startOffset" : 130,
      "endOffset" : 211
    }, {
      "referenceID" : 21,
      "context" : "Due to their unique value in many fields such as creativity (Goel, 1997) and education (Thagard, 1992), analogy and analogical reasoning have become a focus in AI research.",
      "startOffset" : 60,
      "endOffset" : 72
    }, {
      "referenceID" : 57,
      "context" : "Due to their unique value in many fields such as creativity (Goel, 1997) and education (Thagard, 1992), analogy and analogical reasoning have become a focus in AI research.",
      "startOffset" : 87,
      "endOffset" : 102
    }, {
      "referenceID" : 59,
      "context" : "The problem of recognizing analogies is mainly benchmarked in the form of (A:B::C:D) (Turney et al., 2003; Mikolov et al., 2013b; Gladkova et al., 2016; Li et al., 2018a) and targeted for testing the ability of pre-trained word embeddings.",
      "startOffset" : 85,
      "endOffset" : 170
    }, {
      "referenceID" : 42,
      "context" : "The problem of recognizing analogies is mainly benchmarked in the form of (A:B::C:D) (Turney et al., 2003; Mikolov et al., 2013b; Gladkova et al., 2016; Li et al., 2018a) and targeted for testing the ability of pre-trained word embeddings.",
      "startOffset" : 85,
      "endOffset" : 170
    }, {
      "referenceID" : 20,
      "context" : "The problem of recognizing analogies is mainly benchmarked in the form of (A:B::C:D) (Turney et al., 2003; Mikolov et al., 2013b; Gladkova et al., 2016; Li et al., 2018a) and targeted for testing the ability of pre-trained word embeddings.",
      "startOffset" : 85,
      "endOffset" : 170
    }, {
      "referenceID" : 33,
      "context" : "The problem of recognizing analogies is mainly benchmarked in the form of (A:B::C:D) (Turney et al., 2003; Mikolov et al., 2013b; Gladkova et al., 2016; Li et al., 2018a) and targeted for testing the ability of pre-trained word embeddings.",
      "startOffset" : 85,
      "endOffset" : 170
    }, {
      "referenceID" : 41,
      "context" : "Most methods (Mikolov et al., 2013a; Levy and Goldberg, 2014; Pennington et al., 2014) hold a connectionist assumption (Feldman and Ballard, 1982) of linear analogy (Ethayarajh et al.",
      "startOffset" : 13,
      "endOffset" : 86
    }, {
      "referenceID" : 30,
      "context" : "Most methods (Mikolov et al., 2013a; Levy and Goldberg, 2014; Pennington et al., 2014) hold a connectionist assumption (Feldman and Ballard, 1982) of linear analogy (Ethayarajh et al.",
      "startOffset" : 13,
      "endOffset" : 86
    }, {
      "referenceID" : 46,
      "context" : "Most methods (Mikolov et al., 2013a; Levy and Goldberg, 2014; Pennington et al., 2014) hold a connectionist assumption (Feldman and Ballard, 1982) of linear analogy (Ethayarajh et al.",
      "startOffset" : 13,
      "endOffset" : 86
    }, {
      "referenceID" : 15,
      "context" : ", 2014) hold a connectionist assumption (Feldman and Ballard, 1982) of linear analogy (Ethayarajh et al.",
      "startOffset" : 40,
      "endOffset" : 67
    }, {
      "referenceID" : 14,
      "context" : ", 2014) hold a connectionist assumption (Feldman and Ballard, 1982) of linear analogy (Ethayarajh et al., 2019), that the relation between two words can be estimated by vector arithmetic of word embeddings.",
      "startOffset" : 86,
      "endOffset" : 111
    }, {
      "referenceID" : 19,
      "context" : "Psychological literature (Gick and Holyoak, 1983; Gentner, 1983; Minnameier, 2010) suggests that analogical reasoning follows the structure-mapping",
      "startOffset" : 25,
      "endOffset" : 82
    }, {
      "referenceID" : 16,
      "context" : "Psychological literature (Gick and Holyoak, 1983; Gentner, 1983; Minnameier, 2010) suggests that analogical reasoning follows the structure-mapping",
      "startOffset" : 25,
      "endOffset" : 82
    }, {
      "referenceID" : 43,
      "context" : "Psychological literature (Gick and Holyoak, 1983; Gentner, 1983; Minnameier, 2010) suggests that analogical reasoning follows the structure-mapping",
      "startOffset" : 25,
      "endOffset" : 82
    }, {
      "referenceID" : 59,
      "context" : "Word Analogy Recognition in NLP Benchmarks for word analogy recognition (Turney et al., 2003; Mikolov et al., 2013b; Gladkova et al., 2016; Li et al., 2018a) examine mostly linear relations",
      "startOffset" : 72,
      "endOffset" : 157
    }, {
      "referenceID" : 42,
      "context" : "Word Analogy Recognition in NLP Benchmarks for word analogy recognition (Turney et al., 2003; Mikolov et al., 2013b; Gladkova et al., 2016; Li et al., 2018a) examine mostly linear relations",
      "startOffset" : 72,
      "endOffset" : 157
    }, {
      "referenceID" : 20,
      "context" : "Word Analogy Recognition in NLP Benchmarks for word analogy recognition (Turney et al., 2003; Mikolov et al., 2013b; Gladkova et al., 2016; Li et al., 2018a) examine mostly linear relations",
      "startOffset" : 72,
      "endOffset" : 157
    }, {
      "referenceID" : 33,
      "context" : "Word Analogy Recognition in NLP Benchmarks for word analogy recognition (Turney et al., 2003; Mikolov et al., 2013b; Gladkova et al., 2016; Li et al., 2018a) examine mostly linear relations",
      "startOffset" : 72,
      "endOffset" : 157
    }, {
      "referenceID" : 41,
      "context" : "Such analogies can often be effectively solved by vector arithmetic for neural word embeddings, such as Word2Vec (Mikolov et al., 2013a) and GloVe (Pennington et al.",
      "startOffset" : 113,
      "endOffset" : 136
    }, {
      "referenceID" : 48,
      "context" : ", 2021) also test such ability of pre-trained language models (PLMs) (Radford et al., 2019; Devlin et al., 2019; Brown et al., 2020) on these benchmarks.",
      "startOffset" : 69,
      "endOffset" : 132
    }, {
      "referenceID" : 12,
      "context" : ", 2021) also test such ability of pre-trained language models (PLMs) (Radford et al., 2019; Devlin et al., 2019; Brown et al., 2020) on these benchmarks.",
      "startOffset" : 69,
      "endOffset" : 132
    }, {
      "referenceID" : 4,
      "context" : ", 2021) also test such ability of pre-trained language models (PLMs) (Radford et al., 2019; Devlin et al., 2019; Brown et al., 2020) on these benchmarks.",
      "startOffset" : 69,
      "endOffset" : 132
    }, {
      "referenceID" : 39,
      "context" : "enhanced analogy benchmark that leverages word sense definitions in a commonsense knowledge base (Ma and Shih, 2018).",
      "startOffset" : 97,
      "endOffset" : 116
    }, {
      "referenceID" : 9,
      "context" : "Reasoning Benchmarks from Examinations There are abundant benchmarks derived from human examinations to facilitate the study of machine reasoning (Clark et al., 2016; Schoenick et al., 2017).",
      "startOffset" : 146,
      "endOffset" : 190
    }, {
      "referenceID" : 51,
      "context" : "Reasoning Benchmarks from Examinations There are abundant benchmarks derived from human examinations to facilitate the study of machine reasoning (Clark et al., 2016; Schoenick et al., 2017).",
      "startOffset" : 146,
      "endOffset" : 190
    }, {
      "referenceID" : 29,
      "context" : "For example, RACE (Lai et al., 2017) is collected from the English exams for middle and high school students, focusing on skills of passage summarization and attitude analysis.",
      "startOffset" : 18,
      "endOffset" : 36
    }, {
      "referenceID" : 8,
      "context" : "ARC (Clark et al., 2018) contains natural, grade-school science questions authored for human tests.",
      "startOffset" : 4,
      "endOffset" : 24
    }, {
      "referenceID" : 24,
      "context" : ", 2017), GeoSQA (Huang et al., 2019) and GCRC (Tan et al.",
      "startOffset" : 16,
      "endOffset" : 36
    }, {
      "referenceID" : 55,
      "context" : ", 2019) and GCRC (Tan et al., 2021) are sourced from national college entrance exams of China, measuring a comprehensive set of reasoning abilities.",
      "startOffset" : 17,
      "endOffset" : 35
    }, {
      "referenceID" : 36,
      "context" : "LogiQA (Liu et al., 2020a) consists of logical reading comprehension problems from Civil Service Exams of China, which is also our source of analogical problems.",
      "startOffset" : 7,
      "endOffset" : 26
    }, {
      "referenceID" : 61,
      "context" : ", 2020) and LR-LSAT (Wang et al., 2021), collected from Law School Admission Test, aim for testing logical reasoning abilities.",
      "startOffset" : 20,
      "endOffset" : 39
    }, {
      "referenceID" : 62,
      "context" : "current datasets for explainable NLP, such reasons can be categorized into three classes (Wiegreffe and Marasović, 2021): 1) highlights explanations (Camburu et al.",
      "startOffset" : 89,
      "endOffset" : 120
    }, {
      "referenceID" : 5,
      "context" : "current datasets for explainable NLP, such reasons can be categorized into three classes (Wiegreffe and Marasović, 2021): 1) highlights explanations (Camburu et al., 2018; Yang et al., 2018; Thorne et al., 2018; Kwiatkowski et al., 2019), which are subsets of the input elements to explain a prediction, e.",
      "startOffset" : 149,
      "endOffset" : 237
    }, {
      "referenceID" : 64,
      "context" : "current datasets for explainable NLP, such reasons can be categorized into three classes (Wiegreffe and Marasović, 2021): 1) highlights explanations (Camburu et al., 2018; Yang et al., 2018; Thorne et al., 2018; Kwiatkowski et al., 2019), which are subsets of the input elements to explain a prediction, e.",
      "startOffset" : 149,
      "endOffset" : 237
    }, {
      "referenceID" : 58,
      "context" : "current datasets for explainable NLP, such reasons can be categorized into three classes (Wiegreffe and Marasović, 2021): 1) highlights explanations (Camburu et al., 2018; Yang et al., 2018; Thorne et al., 2018; Kwiatkowski et al., 2019), which are subsets of the input elements to explain a prediction, e.",
      "startOffset" : 149,
      "endOffset" : 237
    }, {
      "referenceID" : 5,
      "context" : ", words or sentences; 2) free-text explanations (Camburu et al., 2018; Zellers et al., 2019; Aggarwal et al., 2021) that are textual explanations for justification; 3) structured explanations (Mihaylov et al.",
      "startOffset" : 48,
      "endOffset" : 115
    }, {
      "referenceID" : 66,
      "context" : ", words or sentences; 2) free-text explanations (Camburu et al., 2018; Zellers et al., 2019; Aggarwal et al., 2021) that are textual explanations for justification; 3) structured explanations (Mihaylov et al.",
      "startOffset" : 48,
      "endOffset" : 115
    }, {
      "referenceID" : 0,
      "context" : ", words or sentences; 2) free-text explanations (Camburu et al., 2018; Zellers et al., 2019; Aggarwal et al., 2021) that are textual explanations for justification; 3) structured explanations (Mihaylov et al.",
      "startOffset" : 48,
      "endOffset" : 115
    }, {
      "referenceID" : 50,
      "context" : "The explanations can be utilized to augment (Rajani et al., 2019), super-",
      "startOffset" : 44,
      "endOffset" : 65
    }, {
      "referenceID" : 13,
      "context" : ", 2020) and evaluate (DeYoung et al., 2020) the predictions of neural models.",
      "startOffset" : 21,
      "endOffset" : 43
    }, {
      "referenceID" : 19,
      "context" : "In the psychological literature, analogical reasoning is described as a schemainduction (Gick and Holyoak, 1983) or structure-",
      "startOffset" : 88,
      "endOffset" : 112
    }, {
      "referenceID" : 62,
      "context" : "To this end, we define free-text explanation for analogical reasoning, which is one of the most expressive and commonly-used explanations (Wiegreffe and Marasović, 2021).",
      "startOffset" : 138,
      "endOffset" : 169
    }, {
      "referenceID" : 37,
      "context" : "soning skills, such as graphical reasoning, logical reasoning and comprehension (Liu et al., 2020b), analogical reasoning, etc.",
      "startOffset" : 80,
      "endOffset" : 99
    }, {
      "referenceID" : 59,
      "context" : "We compare E-KAR with previous benchmarks in Table 1, including SAT (Turney et al., 2003), Google (Mikolov et al.",
      "startOffset" : 68,
      "endOffset" : 89
    }, {
      "referenceID" : 42,
      "context" : ", 2003), Google (Mikolov et al., 2013b) and BATS (Gladkova et al.",
      "startOffset" : 16,
      "endOffset" : 39
    }, {
      "referenceID" : 35,
      "context" : "The generated text can be evaluated with text generation metrics such as ROUGE (Lin, 2004), MoverScore (Zhao et al.",
      "startOffset" : 79,
      "endOffset" : 90
    }, {
      "referenceID" : 69,
      "context" : "The generated text can be evaluated with text generation metrics such as ROUGE (Lin, 2004), MoverScore (Zhao et al., 2019), BERTScore (Zhang et al.",
      "startOffset" : 103,
      "endOffset" : 122
    }, {
      "referenceID" : 7,
      "context" : "However, great challenges remain for automatically evaluating semantic-rich text (Celikyilmaz et al., 2020).",
      "startOffset" : 81,
      "endOffset" : 107
    }, {
      "referenceID" : 41,
      "context" : "tasks: Word2Vec (Mikolov et al., 2013a), GloVe (Pennington et al.",
      "startOffset" : 16,
      "endOffset" : 39
    }, {
      "referenceID" : 46,
      "context" : ", 2013a), GloVe (Pennington et al., 2014) and FastText (Bojanowski et al.",
      "startOffset" : 16,
      "endOffset" : 41
    }, {
      "referenceID" : 12,
      "context" : "We also test contextualized embeddings from PLMs, including BERT (Devlin et al., 2019) and RoBERTa (Liu et al.",
      "startOffset" : 65,
      "endOffset" : 86
    }, {
      "referenceID" : 23,
      "context" : "A query or a candidate is calculated as the sum of the representations of each term pair, which is represented as the embedding vector differences (Hakami and Bollegala, 2017; Ushio et al., 2021).",
      "startOffset" : 147,
      "endOffset" : 195
    }, {
      "referenceID" : 60,
      "context" : "A query or a candidate is calculated as the sum of the representations of each term pair, which is represented as the embedding vector differences (Hakami and Bollegala, 2017; Ushio et al., 2021).",
      "startOffset" : 147,
      "endOffset" : 195
    }, {
      "referenceID" : 54,
      "context" : "is an interesting question whether an intelligent model should be deeply supervised at every step (Tafjord et al., 2021).",
      "startOffset" : 98,
      "endOffset" : 120
    }, {
      "referenceID" : 56,
      "context" : "Finally, whether the analogical QA system can correctly exploit explanations and background knowledge is also worth investigating, which may intersect with researches on debiasing (Tang et al., 2020; Niu et al., 2021).",
      "startOffset" : 180,
      "endOffset" : 217
    }, {
      "referenceID" : 44,
      "context" : "Finally, whether the analogical QA system can correctly exploit explanations and background knowledge is also worth investigating, which may intersect with researches on debiasing (Tang et al., 2020; Niu et al., 2021).",
      "startOffset" : 180,
      "endOffset" : 217
    }, {
      "referenceID" : 36,
      "context" : "The dataset is collected from Civil Service Exams of China, which is publicly available and has been used in other public datasets before, such as LogiQA (Liu et al., 2020a).",
      "startOffset" : 154,
      "endOffset" : 173
    } ],
    "year" : 0,
    "abstractText" : "The ability to recognize analogies is fundamental to human cognition. Existing benchmarks to test word analogy does not reveal the underneath process of analogical reasoning of neural models. Holding the belief that models capable of reasoning should be right for the right reasons, we propose a first-of-its-kind Explainable Knowledge-intensive Analogical Reasoning benchmark (E-KAR). Our benchmark consists of 1,665 problems sourced from the Civil Service Exams, which require intensive background knowledge to solve. Besides, we design a free-text explanation scheme to explain how an analogy is drawn, and manually annotate E-KAR with 8,325 knowledgerich sentences of such explanations. Empirical results suggest that this benchmark is very challenging to some state-of-the-art models for both explanation generation and analogical question answering tasks, which invites further research in this area.1",
    "creator" : null
  }
}