{
  "name" : "ARR_2022_283_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Sentence-level Privacy for Document Embeddings",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Language models have now become ubiquitous in NLP (Devlin et al., 2019; Liu et al., 2019b; Alsentzer et al., 2019), pushing the state of the art in a variety of tasks (Strubell et al., 2018; Liu et al., 2019a). While language models capture meaning and various linguistic properties of text (Jawahar et al., 2019; Yenicelik et al., 2020), an individual’s written text can include highly sensitive information. Even if such details are not needed or used, sensitive information has been found to be vulnerable and detectable to attacks (Pan et al., 2020; Abdalla et al., 2020; Carlini et al., 2020). Reconstruction attacks (Xie and Hong, 2021) have even successfully broken through private learning schemes that rely on encryption-type methods (Huang et al., 2020).\nAs of now, there is no broad agreement on what constitutes good privacy for natural language (Kairouz et al., 2019). Huang et al. (2020) argue that different applications and models require\ndifferent privacy definitions. Several emerging works propose to apply Metric Differential Privacy (Alvim et al., 2018) at the word level (Feyisetan et al., 2019; Feyisetan and Kasiviswanathan, 2021; Carvalho et al., 2021; Qu et al., 2021; Yue et al., 2021; Xu et al., 2021) . They propose to add noise to word embeddings, such that they are indistinguishable from nearby word embeddings.\nAt the document level, however, the above definition has two areas for improvement. First, it may not offer the level of privacy desired. Having each word indistinguishable with similar words may not hide higher level concepts in the document, and may not be satisfactory for many users. Second, it may not be very interpretable or easy to communicate to end-users, since the privacy definition relies fundamentally on the choice of embedding model to determine which words are indistinguishable with a given word. This may not be clear and precise enough for end-users to grasp.\nIn this work, we propose a new privacy definition for documents: sentence privacy. This guarantee is both strong and interpretable: any sentence in a document must be indistinguishable with any other sentence. A document embedding is sentenceprivate if we can replace any single sentence in the document and have a similar probability of producing the same embedding. As such, the embedding only stores limited information unique to any given sentence. This definition is easy to communicate and strictly stronger than word-level definitions, as modifying a sentence can be changing one word.\nAlthough this definition is strong, we are able to produce unsupervised, general embeddings of documents that are useful for downstream tasks like sentiment analysis and topic classification. To achieve this we propose a novel privacy mechanism, DeepCandidate, which privately samples a high-dimensional embedding from a preselected set of candidate embeddings derived from public, non-private data. DeepCandidate works by first pretuning a sentence encoder on public data such that semantically different document embeddings are far apart from each other. Then, we approximate each candidate’s Tukey Depth within the private documents’ sentence embeddings. Deeper candidates are the most likely to be sampled to represent the private document. We evaluate DeepCandidate on three illustrative datasets, and show that these unsupervised private embeddings are useful for both sentiment analysis and topic classification as compared to baselines.\nIn summary, this work makes the following contributions to the language privacy literature:\n1. A new, strong, and interpretable privacy definition that offers complete indistinguishability to each sentence in a document. 2. A novel, unsupervised embedding technique, DeepCandidate, to generate sentence-private document embeddings. 3. An empirical assessment of DeepCandidate, demonstrating its advantage over baselines, delivering strong privacy and utility."
    }, {
      "heading" : "2 Background and Related Work",
      "text" : "Setting. We denote a ‘document’ as a sequence of sentences. Let s ∈ S be any finite-length sentence. Then, the space of all documents is X = S∗ and document x ∈ X is written as x = (s1, s2, . . . , sk)\nfor any non-negative integer k of sentences. In this work, we focus on cohesive documents of sentences written together like reviews or emails, but our methods and guarantees apply to any sequence of sentences, such as a collection of messages written by an individual over some period of time.\nOur task is to produce an embedding z ∈ Rd of any document x ∈ X such that any single sentence si ∈ x is indistinguishable with every other sentence s′i ∈ S\\si. That is, if one were to replace any single sentence in the document si ∈ x with any other sentence s′i ∈ S\\si, the probability of producing a given embedding z is similar. To achieve this, we propose a randomized embedding function (the embedding mechanism)M : X → Rd, that generates a private embedding z = M(x) that is useful for downstream tasks."
    }, {
      "heading" : "2.1 Differential Privacy",
      "text" : "The above privacy notion is inspired by Differential Privacy (DP) (Dwork, 2006). It guarantees that — whether an individual participates (dataset D) or not (dataset D′) — the probability of any output only chances by a constant factor.\nDefinition 2.1 (Differential Privacy). Given any pair of datasets D,D′ ∈ D that differ only in the information of a single individual, we say that the mechanism A : D → O, satisfies -DP if\nPr[A(D) ∈ O] ≤ e Pr[A(D′) ∈ O]\nfor any event O ⊆ O. Note that we take probability over the randomness of the mechanism A only, not the data distribution. DP has several nice properties that make it easy to work with including closure under postprocessing, an additive privacy budget (composition), and closure under group privacy guarantees\n(guarantees to a subset of multiple participants). See Dwork et al. 2014 for more details.\nWhen our output space is a discrete and finite set of alternatives to choose from O = (o1, o2, . . . , on), we may use the exponential mechanism to satisfy -DP (McSherry and Talwar, 2007). To do so, we specify a utility function over input/output pairs, u : D × O → R. The utility of choosing alternative o ∈ O when the input is dataset D ∈ D is then given by u(D, o). The sensitivity of u(·, ·) is the worst-case change in utility over pairs of neighboring datasets, ∆u = maxD,D′,o |u(D, o)− u(D′, o)|. Definition 2.2. The exponential mechanism AExp : D → O is a randomized algorithm with output distribution\nPr[AExp(D) = o] ∝ exp ( u(x, r)\n2∆u\n) ."
    }, {
      "heading" : "2.2 Related Work",
      "text" : "Natural Language Privacy. Previous work has demonstrated that NLP models and embeddings are vulnerable to reconstruction attacks (Carlini et al., 2020; Abdalla et al., 2020; Pan et al., 2020). In response there have been various efforts to design privacy-preserving techniques and definitions across NLP tasks. A line of work focuses on how to make NLP model training satisfy DP (Kerrigan et al., 2020; Bagdasaryan et al., 2019). This is distinct from our work in that it satisfies central DP – where data is first aggregated non-privately and then privacy preserving algorithms (i.e. training) are run on that data. We model this work of the local version of DP (Dwork et al., 2006), wherein each individual’s data is made private before centralizing. Our definition guarantees privacy to a single document as opposed to a single individual.\nA line of work more comparable to our approach makes documents locally private by generating a randomized version of a document that satisfies some formal privacy definition. As with the private embedding of our work, this generates a locally private representation of a given document x. The overwhelming majority of these methods satisfy an instance of Metric-DP (Alvim et al., 2018) at the word level (Feyisetan et al., 2019; Feyisetan and Kasiviswanathan, 2021; Carvalho et al., 2021; Qu et al., 2021; Yue et al., 2021; Xu et al., 2021). As discussed in the introduction, this guarantees that a document x is indistinguishable with any other document x′ produced by swapping a single word in x with a similar word. Two words are ‘similar’\nif they are close in the word embeddings space (e.g. GloVe). This guarantee is strictly weaker than our proposed definition, SentDP, which offers indistinguishability to any two documents that differ in an entire sentence.\nPrivacy-preserving embeddings. There is a large body of work on non-NLP privacy-preserving embeddings, as these embeddings have been shown to be vulnerable to attacks (Song and Raghunathan, 2020). Li and Clifton (2021) attempt to generate locally private embeddings by bounding the embedding space, and we compare with this method in our experiments. Kamath et al. (2019) propose a method for privately publishing the average of embeddings, but their algorithm is not suited to operate on the small number of samples (sentences) a given document offers. Finally, Beimel et al. (2019) propose a method for privately learning halfspaces in Rd, which is relevant to private Tukey Medians, but their method would restrict input examples (sentence embeddings) to a finite discrete set in Rd, a restriction we cannot tolerate."
    }, {
      "heading" : "3 Sentence-level Privacy",
      "text" : "We now introduce our simple, strong privacy definition, along with concepts we use to satisfy it."
    }, {
      "heading" : "3.1 Definition",
      "text" : "In this work, we adopt the local notion of DP (Dwork et al., 2006), wherein each individual’s data is guaranteed privacy locally before being reported and centralized. Our mechanism M receives a single document from a single individual, x ∈ X . We require that M provides indistinguishability between documents x, x′ differing in one sentence.\nDefinition 3.1 (Sentence Privacy, SentDP). Given any pair of documents x, x′ ∈ X that differ only in one sentence, we say that a mechanism M : X → O satisfies -SentDP if\nPr[M(x) ∈ O] ≤ e Pr[M(x′) ∈ O]\nfor any event O ⊆ O. We focus on producing an embedding of the given document x, hence the output space is O = Rd. For instance, consider the neighboring documents x = (s1, s2, . . . , sk) and x′ = (s1, s ′ 2, . . . , sk) that differ in the second sentence, i.e. s2, s′2 can be any pair of sentences in S2. This is a strong notion of privacy in comparison to existing definitions across NLP tasks. However, we\nshow that we can guarantee SentDP while still providing embeddings that are useful for downstream tasks like sentiment analysis and classification. In theory, a SentDP private embedding z should be able to encode any information from the document that is not unique to a small subset of sentences. For instance, z can reliably encode the sentiment of x as long as multiple sentences reflect the sentiment. By the group privacy property of DP, which SentDP retains, two documents differing in α sentences are α indistinguishable. So, if more sentences reflect the sentiment, the moreM can encode this into z without compromising on privacy."
    }, {
      "heading" : "3.2 Sentence Mean Embeddings",
      "text" : "Our approach is to produce a private version of the average of general-purpose sentence embeddings. By the post-processing property of DP, this embedding can be used repeatedly in any fashion desired without degrading the privacy guarantee. Our method makes use of existing pre-trained sentence encoding models. We denote this general sentence encoder as G : S → Rd. We show in our experiments that the mean of sentence embeddings,\ng(x) = ∑ si∈x G(si) , (1)\nmaintains significant information unique to the document and is useful for downstream tasks like classification and sentiment analysis.\nWe call g(x) the document embedding since it summarizes the information in document x. While there exist other definitions of document embeddings (Yang et al., 2016; Thongtan and Phienthrakul, 2019; Bianchi et al., 2020), we decide to use averaging as it is a simple and established embedding technique (Bojanowski et al., 2017; Gupta et al., 2019; Li et al., 2020)."
    }, {
      "heading" : "3.3 Tukey Depth",
      "text" : "Depth is a concept in robust statistics used to describe how central a point is to a distribution. We borrow the definition proposed by Tukey (1975):\nDefinition 3.2. Given a distribution P over Rd, the Tukey Depth of a point y ∈ Rd is\nTDP (y) = inf w∈Rd\nP{y′ : w · (y′ − y) ≥ 0} .\nIn other words, take the hyperplane orthogonal to vector w, hw, that passes through point y. Let Pw1 be the probability under P that a point lands on\none side of hw and let Pw2 be the probability that a point lands on the other side, so Pw1 +P w 2 = 1. y is considered deep if min(Pw1 , P w 2 ) is close to a half for all vectors w (and thus all h passing through y). The Tukey Median of distribution P , TMED(P ), is the set of all points with maximal Tukey Depth,\nTMED(P ) = arg max y∈Rd TDP (y) . (2)\nWe only access the distribution P through a finite sample of i.i.d. points, Y = {y1, y2, . . . , yn}. The Tukey Depth w.r.t. Y is given by\nTDY (y) = inf w∈Rd\n|{y′ ∈ Y : w · (y′ − y) ≥ 0}| ,\nand the median, TMED(Y ), maximizes the depth and is at most half the size of our sample ⌊ n 2 ⌋ .\nGenerally, finding a point in TMED(Y ) is hard; SOTA algorithms have an exponential dependency in dimension (Chan, 2004), which is a non-starter when working with high-dimensional embeddings. However, there are efficient approximations which we will take advantage of."
    }, {
      "heading" : "4 DeepCandidate",
      "text" : "While useful and general, the document embedding g(x) does not satisfy SentDP. We now turn to describing our privacy-preserving technique, DeepCandidate, which generates general, -SentDP document embeddings that preserve relevant information in g(x), and are useful for downstream tasks. To understand the nontrivial nature of this problem, we first analyze why the simplest, straightfoward approaches are insufficient.\nMotivation. Preserving privacy for high dimensional objects is known to be challenging (Kamath et al., 2019; Feyisetan and Kasiviswanathan, 2021; Zhou et al., 2009) . For instance, adding Laplace noise directly to g(x), as done to satisfy some privacy definitions (Feyisetan et al., 2019; Alvim et al., 2018), does not guarantee SentDP for any . Recall that the embedding space is all of Rd. A change in one sentence can lead to an unbounded change in g(x), since we do not put any restrictions on the general encoder G. Thus, no matter how much noise we add to g(x) we cannot satisfy SentDP.\nA straightforward workaround might be to simply truncate embeddings such that they all lie in a limited set such as a sphere or hypercube as done in prior work (Li and Clifton, 2021; Abadi et al., 2016). In doing so, we bound how far\napart embeddings can be for any two sentences, ‖G(si) − G(s′i)‖1, thus allowing us to satisfy SentDP by adding finite variance noise. However, such schemes offer poor utility due to the high dimensional nature of useful document embeddings (we confirm this in our experiments). We must add noise with standard deviation proportional to the dimension of the embedding, thus requiring an untenable degree of noise for complex encoders like BERT which embed into R768.\nOur method has three pillars: (1) sampling from a candidate set of public, non-private document embeddings to represent the private document, (2) using the Tukey median to approximate the document embedding, and (3) pre-training the sentence encoder, G, to produce relevant candidates with high Tukey depth for private document x."
    }, {
      "heading" : "4.1 Taking advantage of public data: sampling from candidates",
      "text" : "Instead of having our mechanism select a private embedding z from the entire space of Rd, we focus the mechanism to select from a set of m candidate embeddings, F , generated by m public, nonprivate documents. We assume the document x is drawn from some distribution µ over documents X . For example, if we know x is a restaurant review, µ may be the distribution over all restaurant reviews. F is then a collection of document embeddings from m publicly accessible documents xi ∼ µ,\nF = {fi = g(xi) : x1, . . . , xm iid∼ µ} .\nWe denote the corresponding distribution over fi as g(µ). By selecting documents F to be similar in nature to the private document x, we inject an advantageous inductive bias into our mechanism, which is critical to satisfy strong privacy while preserving meaningful information relevant to x."
    }, {
      "heading" : "4.2 Approximating the document embedding: The Tukey Median",
      "text" : "We now propose a novel mechanismMTD, which approximates g(x) by sampling a candidate embedding from F . MTD works by concentrating probability on candidates with high Tukey Depth w.r.t. the set of sentence embeddings Sx = {G(si) : si ∈ x}. We model sentences si from document x as i.i.d. draws from distribution νx. Then, Sx is k draws from g(νx), the distribution of sentences from νx passing throughG. Deep points are a good approximation of the mean under light assumptions.\nIf g(νx) belongs to the set of halfspace-symmetric distributions (including all elliptic distributions e.g. Gaussians), we know that its mean lies in the Tukey Median (Zhu et al., 2020).\nFormally,MTD is an instance of the exponential mechanism (Definition 2.2), and is defined by its utility function. We set the utility of a candidate document embedding fi ∈ F to be an approximation of its depth w.r.t. sentence embeddings Sx,\nu(x, fi) = T̂DSx(fi) . (3)\nThe approximation T̂DSx , which we detail in the Appendix, is necessary for computational efficiency. If the utility of fi is high, we call it a ‘deep candidate’ for sentence embeddings Sx.\nThe more candidates sampled (higher m), the higher the probability that at least one has high depth. Without privacy, we could report the deepest candidate, z = arg max\nfi∈F T̂DSx(fi). However,\nwhen preserving privacy withMTD, increasing m has diminishing returns. To see this, fix a set of sentence embeddings Sx for document x and the i.i.d. distribution over candidate embeddings fi ∼ g(µ). This induces a multinomial distribution over depth,\nuj = Pr[u(x, fi) = j],\nb k 2 c∑\nj=0\nuj = 1 ,\nwhere randomness is taken over draws of fi. For candidate set F and sentence embeddings Sx, the probability ofMTD’s selected candidate, z, having (approximated) depth j∗ is given by\nPr[u(x, z) = j∗] = aj∗e j∗/2∑b k 2 c\nj=0 aje j/2\n(4)\nwhere aj is the fraction of candidates in F with depth j. For m sufficiently large, aj concentrates around uj . Thus, while increasing m may increase the likelihood of a deep candidate existing, it does not increase the probability of sampling a deep candidate.\nFor numerical intuition, suppose m = 5000 (as in our experiments), ≥ b candidates have depth\n≥ j∗, and all other candidates have depth 0,MTD will sample one of these deep candidates w.p. ≥ 0.95 under the settings in Table 1.\nFor low < 10 (high privacy), about 1% of candidates need to have high depth (≥ 3) in order to be reliably sampled. Note that this is only possible for documents with ≥ 6 sentences. For higher ≥ 10, MTD will reliably sample low depth candidates even if there are only a few.\nFrom these remarks we draw two insights on how DeepCandidate can achieve high utility. (1) More sentences A higher k enables greater depth, and thus a higher probability of sampling deep candidates with privacy. We explore this effect in our experiments. (2) Tuned encoder By tuning the sentence encoder G for a given domain, we can modify the distribution over document embeddings g(µ) and sentence embeddings g(νx) to encourage deep candidates (high probability uj for deep j) that are relevant to document x."
    }, {
      "heading" : "4.3 Taking advantage of structure: cluster-preserving embeddings",
      "text" : "So far, we have identified that deep candidates from F can approximate g(x). To produce a good approximation, we need to ensure that 1) there reliably exist deep candidates for any given set of sentence embeddings Sx, and 2) that these deep candidates are good representatives of document x. The general sentence encoder G used may not satisfy this ‘out of the box’. If the distribution\non document embeddings g(µ) is very scattered around the instance space R768, it can be exceedingly unlikely to have a deep candidate fi among sentence embeddings Sx. On the other hand, if distribution g(µ) is tightly concentrated in one region (e.g. ‘before training’ in Figure 3), then we may reliably have many deep candidates, but several will be poor representatives of the document embedding g(x).\nTo prevent this, we propose an unsupervised, efficient, and intuitive modification to the (pretrained) sentence encoder G. We freeze the weights of G and add additional perceptron layers mapping into the same embeddings space H : Rd → Rd, producing the extended encoder G′ = H ◦G. Broadly, we train H to place similar document embeddings close together, and different embeddings far part. To do so, we leverage the assumption that a given domain’s distribution over document embeddings g(µ) can be parameterized by nc clusters, visualized as the black circles in Figure 3. H’s aim is to recode sentence embeddings such that document embedding clusters are preserved, but spaced apart from each other. By preserving clusters, we are more likely to have deep candidates (increased probability uj for high depth j). By spacing clusters apart, these deep candidates are more likely to come from the same or a nearby cluster as document x, and thus be good representatives. Note that H is domain-specific: we train separate H encoders for each dataset."
    }, {
      "heading" : "4.4 Sampling Algorithm",
      "text" : "The final component of DeepCandidate is computing the approximate depth of a candidate for use as utility in the exponential mechanism as in Eq. (3). We use a version of the approximation algorithm proposed in Gilad-Bachrach and Burges 2012. Intuitively, our algorithm computes the onedimensional depth of each fi among x’s sentence embeddings Sx on each of p random projections. The approximate depth of fi is then its lowest depth across the p projections. We are guaranteed that T̂DSx(fi) ≥ TDSx(fi). Due to space constraints, we leave the detailed description of the algorithm for the Appendix.\nTheorem 4.1. MTD satisfies -Sentence Privacy Proof follows from the fact that T̂DSx(fi) has bounded sensitivity (changing one sentence can only change depth of fi by one). We expand on this, too, in the Appendix."
    }, {
      "heading" : "5 Experiments",
      "text" : ""
    }, {
      "heading" : "5.1 Datasets",
      "text" : "We produce private, general embeddings of documents from three English-language datasets:\nGood Reads (Wan and McAuley, 2018) 60k book reviews from four categories: fantasy, history, romance, and childrens literature. Train-48k | Val-8k | Test-4k\n20 News Groups (Lang, 1995) 11239 correspondences from 20 different affinity groups. Due to similarity between several groups (e.g. comp.os.ms-windows.misc and comp.sys.ibm.pc.hardware), the dataset is partitioned into nine categories. Train-6743k | Val-2247k | Test-2249k\nIMDB (Maas et al., 2011) 29k movie reviews from the IMDB database, each labeled as a positive or negative review. Train-23k | Val-2k | Test-4k\nTo evaluate utility of these unsupervised, private embeddings, we check if they are predictive of document properties. For the Good Reads and 20 News Groups datasets, we evaluate how useful the embeddings are for topic classification. For IMDB we evaluate how useful the embeddings are for sentiment analysis (positive or negative review). Our metric for performance is test-set macro F1 score."
    }, {
      "heading" : "5.2 Training Details & Setup",
      "text" : "For the general encoder, G : S → R768, we use SBERT (Reimers and Gurevych, 2019), a version\nof BERT fine-tuned for sentence encoding. Sentence embeddings are generated by mean-pooling output tokens. In all tasks, we freeze the weights of SBERT. The cluster-preserving recoder, H , as well as every classifier is implemented as an instance of a 4-layer MLP taking 768-dimension inputs and only differing on output dimension. We denote an instance of this MLP with output dimension o as MLPo. We run 5 trials of each experiment with randomness taken over the privacy mechanisms, and plot the mean along with a ± 1 standard deviation envelope.\nDeepCandidate: The candidate set F consists of 5k document embeddings from the training set, each containing at least 8 sentences. To train G′, we find nc = 50 clusters with k-means. We train a classifier Cdc = MLPr on document embeddings g′(x) to predict class, where r is the number of classes (topics or sentiments)."
    }, {
      "heading" : "5.3 Baselines",
      "text" : "We compare the performance of DeepCandidate with 4 baselines: Non-private, Truncation, Wordlevel Metric-DP, and Random Guesser.\nNon-private: This demonstrates the usefulness of non-private sentence-mean document embeddings g(x). We generate g(x) for every document using SBERT, and then train a classifier Cnonpriv = MLPr to predict x’s label from g(x).\nTruncation: We adopt the method from Li and\nClifton 2021 to truncate (clip) sentence embeddings within a box in R768, thereby bounding sensitivity as described at the beginning of Section 4. Laplace noise is then added to each dimension. Documents with more sentences have proportionally less noise added due to the averaging operation reducing sensitivity.\nWord Metric-DP (MDP): The method from Feyisetan et al. 2019 satisfies -word-level metric DP by randomizing words. We implement MDP to produce a randomized document x′, compute g(x′) with SBERT, and predict class using Cnonpriv.\nRandom Guess: To set a bottom-line, we show the theoretical performance of a random guesser only knowing the distribution of labels."
    }, {
      "heading" : "5.4 Results & Discussion",
      "text" : "How does performance change with privacy parameter ? This is addressed in Figures 4a to 4c. Here, we observe how the test set macro F1 score changes with privacy parameter (a lower offers stronger privacy). Generally speaking, for local differential privacy, < 10 is taken to be a strong privacy regime, 10 ≤ < 20 is moderate privacy, and ≥ 25 is weak privacy. The truncation baseline mechanism does increase accuracy with increasing , but never performs much better than the random guesser. This is to be expected with high dimension embeddings, since the standard deviation of noise added increases linearly with dimension.\nThe word-level MDP mechanism performs significantly better than truncation, achieving relatively good performance for ≥ 30. There are two significant caveats, however. First, is the privacy definition: as discussed in the Introduction, for the same , word-level MDP is strictly weaker than SentDP. The second caveat is the level of at which privacy is achieved. Despite a weaker privacy definition, the MDP mechanism does not achieve competitive performance until the weakprivacy regime of . We suspect this is due to two reasons. First, is the fact that the MDP mechanism does not take advantage of contextual information in each sentence as our technique does; randomizing each word independently does not use higher level linguistic information. Second, is the fact that the MDP mechanism does not use domainspecific knowledge as our mechanism does with use of relevant candidates and domain specific sentence encodings.\nIn comparison, DeepCandidate offers strong utility across tasks and datasets for relatively low values of , even into the strong privacy regime. Beyond = 25, the performance of DeepCandidate tends to max out, approximately 10-15% below the non-private approach. This is due to the fact that DeepCandidate offers a noisy version of an approximation of the document embedding g(x) – it cannot perform any better than deterministically selecting the deepest candidate, and even this candidate may be a poor representative of x. We consider this room for improvement, since there are potentially many other ways to tune G′ and select the candidate pool F such that deep candidates are nearly always good representatives of a given document x. How does performance change with the number of sentences k? This is addressed in Figures 4d to 4f. We limit the test set to those documents with k in the listed range on the x-axis. We set = 10, the limit of the strong privacy regime. Neither baseline offers performance above that of the random guesser at this value of . DeepCandidate produces precisely the performance we expect to see: documents with more sentences result in sampling higher quality candidates, confirming the insights of Section 4.2. Across datasets and tasks, documents with more than 10-15 sentences tend to have high quality embeddings."
    }, {
      "heading" : "6 Conclusions and Future Work",
      "text" : "We introduce a strong and interpretable local privacy guarantee for documents, SentDP, along with DeepCandidate, a technique that combines principles from NLP and robust statistics to generate general -SentDP embeddings. Our experiments confirm that such methods can outperform existing approaches even with with more relaxed privacy guarantees. Previous methods have argued that it is “virtually impossible” to satisfy pure local DP (Feyisetan et al., 2019; Feyisetan and Kasiviswanathan, 2021) at the word level while capturing linguistic semantics. Our work appears to refute this notion at least for documents.\nTo follow up, we plan to explore other approaches (apart from k-means) of capturing the structure of the embedding distribution g(µ) to encourage better candidate selection. We also plan to experiment with decoding private embeddings back to documents by using novel candidates produced by a generative model trained on F ."
    }, {
      "heading" : "A Appendix",
      "text" : "A.1 Privacy Mechanism We now describe in detail our instance of the exponential mechanismMTD. Recall from Definition 2.2 that the exponential mechanism samples candidate fi ∈ F with probability\nPr[M(x) = fi] ∝ exp ( u(x, fi)\n2∆u\n) .\nThus,MTD is fully defined by its utility function, which, as listed in Equation (3), is approximate Tukey Depth,\nu(x, fi) = T̂DSx(fi) .\nOur approximation of Tukey Depth T̂DSx(fi) is described in Algorithm 1 which is an adaptation of the general median hypothesis algorithm proposed by Gilad-Bachrach and Burges (2012). As an abuse of notation, we write si to be the sentence embedding written as G(si) in the main paper.\nNote that we can precompute the projections on line 10. The runtime is O(mkp): for each of m candidates and on each of p projections, we need to compute the scalar difference with k sentence embeddings. Sampling from the multinomial distribution defined by PF then takes O(m) time.\nAdditionally note from lines 13 and 15 that utility has a maximum of 0 and a minimum of −k2 , which is a semantic change from the main paper where maximum utility is k2 and minimum is 0.\nA.2 Proof of Privacy Theorem 4.1 MTD satisfies -Sentence Privacy\nProof. It is sufficient to show that the sensitivity,\n∆u = max x,x′,fi\n|u(x, fi)− u(x′, fi)| ≤ 1 .\nLet us expand the above expression using the terms in Algorithm 1.\n∆u = max x,x′,fi |max j∈[p] uj(x, fi)− max j′∈[p]\nuj′(x ′, fi)|\n= max x,x′,fi |max j∈[p] ∣∣hj(x, fi)− k 2 ∣∣ − max j′∈[p] ∣∣hj′(x′, fi)− k 2\n∣∣| ≤ max\nfi |max j∈[p] ∣∣hj(x, fi)− k 2 ∣∣ − (\nmax j′∈[p] ∣∣hj′(x, fi)− k 2 ∣∣+ 1)| ≤ 1\nAlgorithm 1:MTD compute probabilities Input :m candidates F ,\nsentence embs. Sx = (s1, . . . , sk), number of projections p\nOutput :probability of sampling each candidate PF = [Pf1 , . . . , Pfm ]\n1 v1, . . . , vp ← random vecs. on unit sphere 2 // Project all embeddings 3 for i ∈ [k] do 4 for j ∈ [p] do 5 sji ← s ᵀ i vj 6 end for 7 end for 8 for i ∈ [m] do 9 for j ∈ [p] do\n10 f ji ← f ᵀ i vj 11 /* Compute depth of fi on\nprojection vj */\n12 hj(x, fi)← #{sjl : s j l ≥ f j i , l ∈ [k]} 13 uj(x, fi)← ∣∣hj(x, fi)− k2 ∣∣ 14 end for 15 u(x, fi)← −maxj∈[p] uj(x, fi) P̂fi ← exp( u(x, fi)/2) 16 end for 17 Ψ← ∑m i=1 P̂fi 18 for i ∈ [m] do 19 Pfi ← 1Ψ P̂fi 20 end for 21 return PF\nThe last step follows from the fact that |hj(x, fi)− hj(x\n′, fi)| ≤ 1 for all j ∈ [p]. In other words, by modifying a single sentence embedding, we can only change the number of embeddings greater than f ji on projection j by 1. So, the distance of hj(x, fi) from k2 can only change by 1 on each projection. In the ‘worst case’, the distance∣∣hj(x, fi)− k2 ∣∣ increases (or reduces) by 1 on every projection vj . Even then, the maximum distance from k2 across projections (the worst case depth) can only change by 1, giving us a sensitivity of 1.\nA.3 Experimental Details Here, we provide an extended, detailed version of section 5.\nFor the general encoder, G : S → R768, we use SBERT (Reimers and Gurevych, 2019), a version of BERT fine-tuned for sentence encoding. Sentence embeddings are generated by mean-pooling output tokens. In all tasks, we freeze the weights of SBERT. The cluster-preserving recoder, H , as well as every classifier is implemented as an instance of a 4-layer MLP taking 768-dimension inputs and only differing on output dimension. We denote an instance of this MLP with output dimension o as MLPo. We run 5 trials of each experiment with randomness taken over the privacy mechanisms, and plot the mean along with a ± 1 standard deviation envelope.\nNon-private: For our non-private baseline, we demonstrate the usefulness of sentence-mean document embeddings. First, we generate the document embeddings g(xi) for each training, validation, and test set document using SBERT, G. We then train a classifier Cnonpriv = MLPr to predict each document’s topic or sentiment, where r is the number of classes. The number of training epochs is determined with the validation set.\nDeepCandidate: We first collect the candidate set F by sampling 5k document embeddings from the subset of the training set containing at least 8 sentences. We run k-means with nc = 50 cluster centers, and label each training set document embedding ti ∈ TG with its cluster. The sentence recoder, H = MLP768 is trained on the training set along with the linear model L with the Adam optimizer and cross-entropy loss. For a given document x, its sentence embeddings Sx are passed through H , averaged together, and then passed to L to predict x’s cluster. L’s loss is then back-propagated\nthrough H . A classifier Cdc = MLPr is trained in parallel using a separate instance of the Adam optimizer to predict class from the recoded embeddings, where r is the number of classes (topics or sentiments). The number of training epochs is determined using the validation set. At test time, (generating private embeddings usingMTD), the optimal number of projections p is empirically chosen for each using the validation set.\nTruncation: The truncation baseline (Li and Clifton, 2021) requires first constraining the embedding instance space. We do so by computing the 75% median interval on each of the 768 dimensions of training document embeddings TG. Sentence embeddings are truncated at each dimension to lie in this box. In order to account for this distribution shift, a new classifier Ctrunc = MLPr is trained on truncated mean embeddings to predict class. The number of epochs is determined with the validation set. At test time, a document’s sentence embeddings Sx are truncated and averaged. We then add Laplace noise to each dimension with scale factor 768wk , where w is the width of the box on that dimension (sensitivity in DP terms). Note that the standard deviation of noise added is inversely proportional to the number of sentences in the document, due to the averaging operation reducing sensitivity.\nWord Metric-DP: Our next baseline satisfies - word-level metric DP and is adopted from (Feyisetan et al., 2019). The corresponding mechanism MDP : X → X takes as input a document x and returns a private version, x′, by randomizing each word individually. For comparison, we generate document embeddings by first randomizing the document x′ = MDP(x) as prescribed by (Feyisetan et al., 2019), and then computing its document embedding g(x′) using SBERT. At test time, we classify the word-private document embedding using Cnonpriv.\nRandom Guess: To set a bottom-line, we show the theoretical performance of a random guesser. The guesser chooses class i with probability qi equal to the fraction of i labels in the training set. The performance is then given by ∑r i=1 q 2 i .\nA.4 Reproducability Details\nWe plan to publish a repo of code used to generate the exact figures in this paper (random seeds have been set) with the final version. Since we do\nnot train the BERT base model G, our algorithms and training require relatively little computational resouces. Our system includes a single Nvidia GeForce RTX 2080 GPU and a single Intel i9 core. All of our models complete an epoch training on all datasets in less than one minute. We never do more than 20 epochs of training. All of our classifier models train (including linear model) have less than 11 million parameters. The relatively low amount of parameters is due to the fact that we freeze the underlying language model. The primary hyperparameter tuned is the number of projections p. We take the argmax value on the validation set between 10 and 100 projections. We repeat this for each value of .\nDataset preprocessing: For all datasets, we limit ourselves to documents with at least 2 sentences.\nIMDB: This dataset has pre-defined train/test splits. We use the entire training set and form the test set by randomly sampling 4,000 from the test set provided. We do this for efficiency in computing the Metric-DP baseline, which is the slowest of all algorithms performed. Since the Metric-DP baseline randomizes first, we cannot precompute the sentence embeddings G(si) – we need to compute the sentence embeddings every single time we randomize. Since we randomize for each sentence of each document at each and each k over 5 trials – this takes a considerable amount of time.\nGood Reads: This dataset as provided is quite large. We randomly sample 15000 documents from each of 4 classes, and split them into 12K training examples, 2K validation examples, and 1K test examples per class.\n20 News Groups: We preprocess this dataset to remove all header information, which may more directly tell information about document class, and only provide the model with the sentences from the main body. We use the entire dataset, and form the Train/Val/Test splits by random sampling."
    } ],
    "references" : [ {
      "title" : "Deep Learning with Differential Privacy",
      "author" : [ "Martín Abadi", "Andy Chu", "Ian Goodfellow", "H. Brendan McMahan", "Ilya Mironov", "Kunal Talwar", "Li Zhang." ],
      "venue" : "Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security,",
      "citeRegEx" : "Abadi et al\\.,? 2016",
      "shortCiteRegEx" : "Abadi et al\\.",
      "year" : 2016
    }, {
      "title" : "Exploring the PrivacyPreserving Properties of Word Embeddings: Algorithmic Validation Study",
      "author" : [ "Mohamed Abdalla", "Moustafa Abdalla", "Graeme Hirst", "Frank Rudzicz." ],
      "venue" : "Journal of Medical Internet Research, 22(7):e18055.",
      "citeRegEx" : "Abdalla et al\\.,? 2020",
      "shortCiteRegEx" : "Abdalla et al\\.",
      "year" : 2020
    }, {
      "title" : "Publicly available clinical bert embeddings",
      "author" : [ "Emily Alsentzer", "John Murphy", "William Boag", "WeiHung Weng", "Di Jindi", "Tristan Naumann", "Matthew McDermott." ],
      "venue" : "Proceedings of the 2nd Clinical Natural Language Processing Workshop, pages",
      "citeRegEx" : "Alsentzer et al\\.,? 2019",
      "shortCiteRegEx" : "Alsentzer et al\\.",
      "year" : 2019
    }, {
      "title" : "Invited Paper: Local Differential Privacy on Metric Spaces: Optimizing the Trade-Off with Utility",
      "author" : [ "Mário Alvim", "Konstantinos Chatzikokolakis", "Catuscia Palamidessi", "Anna Pazii." ],
      "venue" : "2018 IEEE 31st Computer Security Foundations Symposium (CSF),",
      "citeRegEx" : "Alvim et al\\.,? 2018",
      "shortCiteRegEx" : "Alvim et al\\.",
      "year" : 2018
    }, {
      "title" : "Differential privacy has disparate impact on model accuracy",
      "author" : [ "Eugene Bagdasaryan", "Omid Poursaeed", "Vitaly Shmatikov." ],
      "venue" : "Advances in Neural Information Processing Systems, 32:15479–15488.",
      "citeRegEx" : "Bagdasaryan et al\\.,? 2019",
      "shortCiteRegEx" : "Bagdasaryan et al\\.",
      "year" : 2019
    }, {
      "title" : "Private Center Points and Learning of Halfspaces",
      "author" : [ "Amos Beimel", "Shay Moran", "Kobbi Nissim", "Uri Stemmer." ],
      "venue" : "arXiv:1902.10731 [cs, stat]. ArXiv: 1902.10731.",
      "citeRegEx" : "Beimel et al\\.,? 2019",
      "shortCiteRegEx" : "Beimel et al\\.",
      "year" : 2019
    }, {
      "title" : "Pre-training is a hot topic: Contextualized document embeddings improve topic coherence",
      "author" : [ "Federico Bianchi", "Silvia Terragni", "Dirk Hovy." ],
      "venue" : "arXiv preprint arXiv:2004.03974.",
      "citeRegEx" : "Bianchi et al\\.,? 2020",
      "shortCiteRegEx" : "Bianchi et al\\.",
      "year" : 2020
    }, {
      "title" : "Enriching word vectors with subword information",
      "author" : [ "Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 5:135–146.",
      "citeRegEx" : "Bojanowski et al\\.,? 2017",
      "shortCiteRegEx" : "Bojanowski et al\\.",
      "year" : 2017
    }, {
      "title" : "Extracting Training Data from Large Language Models",
      "author" : [ "Nicholas Carlini", "Florian Tramer", "Eric Wallace", "Matthew Jagielski", "Ariel Herbert-Voss", "Katherine Lee", "Adam Roberts", "Tom Brown", "Dawn Song", "Ulfar Erlingsson", "Alina Oprea", "Colin Raffel" ],
      "venue" : null,
      "citeRegEx" : "Carlini et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Carlini et al\\.",
      "year" : 2020
    }, {
      "title" : "Tem: High utility metric differential privacy on text",
      "author" : [ "Ricardo Silva Carvalho", "Theodore Vasiloudis", "Oluwaseyi Feyisetan." ],
      "venue" : "arXiv preprint arXiv:2107.07928.",
      "citeRegEx" : "Carvalho et al\\.,? 2021",
      "shortCiteRegEx" : "Carvalho et al\\.",
      "year" : 2021
    }, {
      "title" : "An optimal randomized algorithm for maximum tukey depth",
      "author" : [ "Timothy M Chan." ],
      "venue" : "SODA, volume 4, pages 430–436.",
      "citeRegEx" : "Chan.,? 2004",
      "shortCiteRegEx" : "Chan.",
      "year" : 2004
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Com-",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Differential Privacy, volume 4052",
      "author" : [ "Cynthia Dwork" ],
      "venue" : null,
      "citeRegEx" : "Dwork.,? \\Q2006\\E",
      "shortCiteRegEx" : "Dwork.",
      "year" : 2006
    }, {
      "title" : "Our Data, Ourselves: Privacy Via Distributed Noise Generation",
      "author" : [ "Cynthia Dwork", "Krishnaram Kenthapadi", "Frank McSherry", "Ilya Mironov", "Moni Naor." ],
      "venue" : "Serge Vaudenay, editor, Advances in Cryptology - EUROCRYPT 2006, volume 4004, pages 486–503.",
      "citeRegEx" : "Dwork et al\\.,? 2006",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2006
    }, {
      "title" : "The algorithmic foundations of differential privacy",
      "author" : [ "Cynthia Dwork", "Aaron Roth" ],
      "venue" : "Found. Trends Theor. Comput",
      "citeRegEx" : "Dwork and Roth,? \\Q2014\\E",
      "shortCiteRegEx" : "Dwork and Roth",
      "year" : 2014
    }, {
      "title" : "Privacy- and Utility-Preserving Textual Analysis via Calibrated Multivariate Perturbations",
      "author" : [ "Oluwaseyi Feyisetan", "Borja Balle", "Thomas Drake", "Tom Diethe" ],
      "venue" : null,
      "citeRegEx" : "Feyisetan et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Feyisetan et al\\.",
      "year" : 2019
    }, {
      "title" : "Private release of text embedding vectors",
      "author" : [ "Oluwaseyi Feyisetan", "Shiva Kasiviswanathan." ],
      "venue" : "Proceedings of the First Workshop on Trustworthy Natural Language Processing, pages 15–27.",
      "citeRegEx" : "Feyisetan and Kasiviswanathan.,? 2021",
      "shortCiteRegEx" : "Feyisetan and Kasiviswanathan.",
      "year" : 2021
    }, {
      "title" : "The Median Hypothesis",
      "author" : [ "Ran Gilad-Bachrach", "Chris J.C. Burges" ],
      "venue" : null,
      "citeRegEx" : "Gilad.Bachrach and Burges.,? \\Q2012\\E",
      "shortCiteRegEx" : "Gilad.Bachrach and Burges.",
      "year" : 2012
    }, {
      "title" : "Better word embeddings by disentangling contextual n-gram information",
      "author" : [ "Prakhar Gupta", "Matteo Pagliardini", "Martin Jaggi." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-",
      "citeRegEx" : "Gupta et al\\.,? 2019",
      "shortCiteRegEx" : "Gupta et al\\.",
      "year" : 2019
    }, {
      "title" : "TextHide: Tackling data privacy in language understanding tasks",
      "author" : [ "Yangsibo Huang", "Zhao Song", "Danqi Chen", "Kai Li", "Sanjeev Arora." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 1368–1382, Online. Association",
      "citeRegEx" : "Huang et al\\.,? 2020",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2020
    }, {
      "title" : "What does bert learn about the structure of language? In ACL 2019-57th Annual Meeting of the Association for Computational Linguistics",
      "author" : [ "Ganesh Jawahar", "Benoît Sagot", "Djamé Seddah" ],
      "venue" : null,
      "citeRegEx" : "Jawahar et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Jawahar et al\\.",
      "year" : 2019
    }, {
      "title" : "Advances and open problems in federated learning",
      "author" : [ "Peter Kairouz", "H Brendan McMahan", "Brendan Avent", "Aurélien Bellet", "Mehdi Bennis", "Arjun Nitin Bhagoji", "Kallista Bonawitz", "Zachary Charles", "Graham Cormode", "Rachel Cummings" ],
      "venue" : null,
      "citeRegEx" : "Kairouz et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Kairouz et al\\.",
      "year" : 2019
    }, {
      "title" : "Privately Learning HighDimensional Distributions",
      "author" : [ "Gautam Kamath", "Jerry Li", "Vikrant Singhal", "Jonathan Ullman." ],
      "venue" : "Conference on Learning Theory, pages 1853–1902. PMLR. ISSN: 26403498.",
      "citeRegEx" : "Kamath et al\\.,? 2019",
      "shortCiteRegEx" : "Kamath et al\\.",
      "year" : 2019
    }, {
      "title" : "Differentially Private Language Models Benefit from Public Pre-training",
      "author" : [ "Gavin Kerrigan", "Dylan Slack", "Jens Tuyls." ],
      "venue" : "arXiv:2009.05886 [cs]. ArXiv: 2009.05886.",
      "citeRegEx" : "Kerrigan et al\\.,? 2020",
      "shortCiteRegEx" : "Kerrigan et al\\.",
      "year" : 2020
    }, {
      "title" : "Home Page for 20 Newsgroups Data Set",
      "author" : [ "Ken Lang" ],
      "venue" : null,
      "citeRegEx" : "Lang.,? \\Q1995\\E",
      "shortCiteRegEx" : "Lang.",
      "year" : 1995
    }, {
      "title" : "On the sentence embeddings from bert for semantic textual similarity",
      "author" : [ "Bohan Li", "Hao Zhou", "Junxian He", "Mingxuan Wang", "Yiming Yang", "Lei Li." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "Differentially Private Imaging via Latent Space Manipulation",
      "author" : [ "Tao Li", "Chris Clifton." ],
      "venue" : "arXiv:2103.05472 [cs]. ArXiv: 2103.05472.",
      "citeRegEx" : "Li and Clifton.,? 2021",
      "shortCiteRegEx" : "Li and Clifton.",
      "year" : 2021
    }, {
      "title" : "Multi-task deep neural networks for natural language understanding",
      "author" : [ "Xiaodong Liu", "Pengcheng He", "Weizhu Chen", "Jianfeng Gao." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4487–4496.",
      "citeRegEx" : "Liu et al\\.,? 2019a",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Roberta: A robustly optimized bert pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "arXiv preprint arXiv:1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019b",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Learning word vectors for sentiment analysis",
      "author" : [ "Andrew L. Maas", "Raymond E. Daly", "Peter T. Pham", "Dan Huang", "Andrew Y. Ng", "Christopher Potts." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human",
      "citeRegEx" : "Maas et al\\.,? 2011",
      "shortCiteRegEx" : "Maas et al\\.",
      "year" : 2011
    }, {
      "title" : "Mechanism Design via Differential Privacy",
      "author" : [ "Frank McSherry", "Kunal Talwar" ],
      "venue" : null,
      "citeRegEx" : "McSherry and Talwar.,? \\Q2007\\E",
      "shortCiteRegEx" : "McSherry and Talwar.",
      "year" : 2007
    }, {
      "title" : "Privacy risks of general-purpose language models",
      "author" : [ "Xudong Pan", "Mi Zhang", "Shouling Ji", "Min Yang." ],
      "venue" : "2020 IEEE Symposium on Security and Privacy (SP), pages 1314–1331. IEEE.",
      "citeRegEx" : "Pan et al\\.,? 2020",
      "shortCiteRegEx" : "Pan et al\\.",
      "year" : 2020
    }, {
      "title" : "PrivacyAdaptive BERT for Natural Language Understanding",
      "author" : [ "Chen Qu", "Weize Kong", "Liu Yang", "Mingyang Zhang", "Michael Bendersky", "Marc Najork." ],
      "venue" : "arXiv:2104.07504 [cs]. ArXiv: 2104.07504.",
      "citeRegEx" : "Qu et al\\.,? 2021",
      "shortCiteRegEx" : "Qu et al\\.",
      "year" : 2021
    }, {
      "title" : "SentenceBERT: Sentence Embeddings using Siamese BERTNetworks",
      "author" : [ "Nils Reimers", "Iryna Gurevych." ],
      "venue" : "arXiv:1908.10084 [cs]. ArXiv: 1908.10084.",
      "citeRegEx" : "Reimers and Gurevych.,? 2019",
      "shortCiteRegEx" : "Reimers and Gurevych.",
      "year" : 2019
    }, {
      "title" : "Information Leakage in Embedding Models",
      "author" : [ "Congzheng Song", "Ananth Raghunathan." ],
      "venue" : "arXiv:2004.00053 [cs, stat]. ArXiv: 2004.00053.",
      "citeRegEx" : "Song and Raghunathan.,? 2020",
      "shortCiteRegEx" : "Song and Raghunathan.",
      "year" : 2020
    }, {
      "title" : "Linguisticallyinformed self-attention for semantic role labeling",
      "author" : [ "Emma Strubell", "Patrick Verga", "Daniel Andor", "David Weiss", "Andrew McCallum." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages",
      "citeRegEx" : "Strubell et al\\.,? 2018",
      "shortCiteRegEx" : "Strubell et al\\.",
      "year" : 2018
    }, {
      "title" : "Sentiment classification using document embeddings trained with cosine similarity",
      "author" : [ "Tan Thongtan", "Tanasanee Phienthrakul." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop,",
      "citeRegEx" : "Thongtan and Phienthrakul.,? 2019",
      "shortCiteRegEx" : "Thongtan and Phienthrakul.",
      "year" : 2019
    }, {
      "title" : "Mathematics and the picturing of data",
      "author" : [ "John W Tukey." ],
      "venue" : "Proceedings of the International Congress of Mathematicians, Vancouver, 1975, volume 2, pages 523–531.",
      "citeRegEx" : "Tukey.,? 1975",
      "shortCiteRegEx" : "Tukey.",
      "year" : 1975
    }, {
      "title" : "Item recommendation on monotonic behavior chains",
      "author" : [ "Mengting Wan", "Julian J. McAuley." ],
      "venue" : "Proceedings of the 12th ACM Conference on Recommender Systems, RecSys 2018, Vancouver, BC, Canada, October 2-7, 2018, pages 86–94. ACM.",
      "citeRegEx" : "Wan and McAuley.,? 2018",
      "shortCiteRegEx" : "Wan and McAuley.",
      "year" : 2018
    }, {
      "title" : "Reconstruction attack on instance encoding for language understanding",
      "author" : [ "Shangyu Xie", "Yuan Hong." ],
      "venue" : "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 2038–2044.",
      "citeRegEx" : "Xie and Hong.,? 2021",
      "shortCiteRegEx" : "Xie and Hong.",
      "year" : 2021
    }, {
      "title" : "DensityAware Differentially Private Textual Perturbations Using Truncated Gumbel Noise",
      "author" : [ "Nan Xu", "Oluwaseyi Feyisetan", "Abhinav Aggarwal", "Zekun Xu", "Nathanael Teissier." ],
      "venue" : "The International FLAIRS Conference Proceedings, 34(1).",
      "citeRegEx" : "Xu et al\\.,? 2021",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2021
    }, {
      "title" : "Hierarchical attention networks for document classification",
      "author" : [ "Zichao Yang", "Diyi Yang", "Chris Dyer", "Xiaodong He", "Alex Smola", "Eduard Hovy." ],
      "venue" : "Proceedings of the 2016 conference of the North American chapter of the association for computational lin-",
      "citeRegEx" : "Yang et al\\.,? 2016",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2016
    }, {
      "title" : "How does bert capture semantics? a closer look at polysemous words",
      "author" : [ "David Yenicelik", "Florian Schmidt", "Yannic Kilcher." ],
      "venue" : "Proceedings of the Third BlackboxNLP Workshop on Analyzing and Interpreting Neural Networks for NLP, pages 156–162.",
      "citeRegEx" : "Yenicelik et al\\.,? 2020",
      "shortCiteRegEx" : "Yenicelik et al\\.",
      "year" : 2020
    }, {
      "title" : "Differential Privacy for Text Analytics via Natural Text Sanitization",
      "author" : [ "Xiang Yue", "Minxin Du", "Tianhao Wang", "Yaliang Li", "Huan Sun", "Sherman S.M. Chow." ],
      "venue" : "arXiv:2106.01221 [cs]. ArXiv: 2106.01221.",
      "citeRegEx" : "Yue et al\\.,? 2021",
      "shortCiteRegEx" : "Yue et al\\.",
      "year" : 2021
    }, {
      "title" : "Differential privacy with compression",
      "author" : [ "Shuheng Zhou", "Katrina Ligett", "Larry Wasserman." ],
      "venue" : "2009 IEEE International Symposium on Information Theory, pages 2718–2722. ISSN: 2157-8117.",
      "citeRegEx" : "Zhou et al\\.,? 2009",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2009
    }, {
      "title" : "When does the Tukey Median work? In 2020 IEEE International Symposium on Information Theory (ISIT), pages 1201–1206, Los Angeles, CA, USA",
      "author" : [ "Banghua Zhu", "Jiantao Jiao", "Jacob Steinhardt." ],
      "venue" : "IEEE.",
      "citeRegEx" : "Zhu et al\\.,? 2020",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 11,
      "context" : "Language models have now become ubiquitous in NLP (Devlin et al., 2019; Liu et al., 2019b; Alsentzer et al., 2019), pushing the state of the art in a variety of tasks (Strubell et al.",
      "startOffset" : 50,
      "endOffset" : 114
    }, {
      "referenceID" : 28,
      "context" : "Language models have now become ubiquitous in NLP (Devlin et al., 2019; Liu et al., 2019b; Alsentzer et al., 2019), pushing the state of the art in a variety of tasks (Strubell et al.",
      "startOffset" : 50,
      "endOffset" : 114
    }, {
      "referenceID" : 2,
      "context" : "Language models have now become ubiquitous in NLP (Devlin et al., 2019; Liu et al., 2019b; Alsentzer et al., 2019), pushing the state of the art in a variety of tasks (Strubell et al.",
      "startOffset" : 50,
      "endOffset" : 114
    }, {
      "referenceID" : 35,
      "context" : ", 2019), pushing the state of the art in a variety of tasks (Strubell et al., 2018; Liu et al., 2019a).",
      "startOffset" : 60,
      "endOffset" : 102
    }, {
      "referenceID" : 27,
      "context" : ", 2019), pushing the state of the art in a variety of tasks (Strubell et al., 2018; Liu et al., 2019a).",
      "startOffset" : 60,
      "endOffset" : 102
    }, {
      "referenceID" : 20,
      "context" : "While language models capture meaning and various linguistic properties of text (Jawahar et al., 2019; Yenicelik et al., 2020), an individual’s written text can include highly sensitive information.",
      "startOffset" : 80,
      "endOffset" : 126
    }, {
      "referenceID" : 42,
      "context" : "While language models capture meaning and various linguistic properties of text (Jawahar et al., 2019; Yenicelik et al., 2020), an individual’s written text can include highly sensitive information.",
      "startOffset" : 80,
      "endOffset" : 126
    }, {
      "referenceID" : 31,
      "context" : "Even if such details are not needed or used, sensitive information has been found to be vulnerable and detectable to attacks (Pan et al., 2020; Abdalla et al., 2020; Carlini et al., 2020).",
      "startOffset" : 125,
      "endOffset" : 187
    }, {
      "referenceID" : 1,
      "context" : "Even if such details are not needed or used, sensitive information has been found to be vulnerable and detectable to attacks (Pan et al., 2020; Abdalla et al., 2020; Carlini et al., 2020).",
      "startOffset" : 125,
      "endOffset" : 187
    }, {
      "referenceID" : 8,
      "context" : "Even if such details are not needed or used, sensitive information has been found to be vulnerable and detectable to attacks (Pan et al., 2020; Abdalla et al., 2020; Carlini et al., 2020).",
      "startOffset" : 125,
      "endOffset" : 187
    }, {
      "referenceID" : 39,
      "context" : "Reconstruction attacks (Xie and Hong, 2021) have even successfully broken through private learning schemes that rely on encryption-type methods (Huang et al.",
      "startOffset" : 23,
      "endOffset" : 43
    }, {
      "referenceID" : 19,
      "context" : "Reconstruction attacks (Xie and Hong, 2021) have even successfully broken through private learning schemes that rely on encryption-type methods (Huang et al., 2020).",
      "startOffset" : 144,
      "endOffset" : 164
    }, {
      "referenceID" : 21,
      "context" : "As of now, there is no broad agreement on what constitutes good privacy for natural language (Kairouz et al., 2019).",
      "startOffset" : 93,
      "endOffset" : 115
    }, {
      "referenceID" : 3,
      "context" : "works propose to apply Metric Differential Privacy (Alvim et al., 2018) at the word level (Feyisetan et al.",
      "startOffset" : 51,
      "endOffset" : 71
    }, {
      "referenceID" : 12,
      "context" : "The above privacy notion is inspired by Differential Privacy (DP) (Dwork, 2006).",
      "startOffset" : 66,
      "endOffset" : 79
    }, {
      "referenceID" : 30,
      "context" : ", on), we may use the exponential mechanism to satisfy -DP (McSherry and Talwar, 2007).",
      "startOffset" : 59,
      "endOffset" : 86
    }, {
      "referenceID" : 8,
      "context" : "Previous work has demonstrated that NLP models and embeddings are vulnerable to reconstruction attacks (Carlini et al., 2020; Abdalla et al., 2020; Pan et al., 2020).",
      "startOffset" : 103,
      "endOffset" : 165
    }, {
      "referenceID" : 1,
      "context" : "Previous work has demonstrated that NLP models and embeddings are vulnerable to reconstruction attacks (Carlini et al., 2020; Abdalla et al., 2020; Pan et al., 2020).",
      "startOffset" : 103,
      "endOffset" : 165
    }, {
      "referenceID" : 31,
      "context" : "Previous work has demonstrated that NLP models and embeddings are vulnerable to reconstruction attacks (Carlini et al., 2020; Abdalla et al., 2020; Pan et al., 2020).",
      "startOffset" : 103,
      "endOffset" : 165
    }, {
      "referenceID" : 23,
      "context" : "A line of work focuses on how to make NLP model training satisfy DP (Kerrigan et al., 2020; Bagdasaryan et al., 2019).",
      "startOffset" : 68,
      "endOffset" : 117
    }, {
      "referenceID" : 4,
      "context" : "A line of work focuses on how to make NLP model training satisfy DP (Kerrigan et al., 2020; Bagdasaryan et al., 2019).",
      "startOffset" : 68,
      "endOffset" : 117
    }, {
      "referenceID" : 13,
      "context" : "We model this work of the local version of DP (Dwork et al., 2006), wherein each individual’s data is made private before centralizing.",
      "startOffset" : 46,
      "endOffset" : 66
    }, {
      "referenceID" : 3,
      "context" : "The overwhelming majority of these methods satisfy an instance of Metric-DP (Alvim et al., 2018) at the word level (Feyisetan et al.",
      "startOffset" : 76,
      "endOffset" : 96
    }, {
      "referenceID" : 34,
      "context" : "There is a large body of work on non-NLP privacy-preserving embeddings, as these embeddings have been shown to be vulnerable to attacks (Song and Raghunathan, 2020).",
      "startOffset" : 136,
      "endOffset" : 164
    }, {
      "referenceID" : 13,
      "context" : "In this work, we adopt the local notion of DP (Dwork et al., 2006), wherein each individual’s data is guaranteed privacy locally before being reported and centralized.",
      "startOffset" : 46,
      "endOffset" : 66
    }, {
      "referenceID" : 41,
      "context" : "While there exist other definitions of document embeddings (Yang et al., 2016; Thongtan and Phienthrakul, 2019; Bianchi et al., 2020), we decide to",
      "startOffset" : 59,
      "endOffset" : 133
    }, {
      "referenceID" : 36,
      "context" : "While there exist other definitions of document embeddings (Yang et al., 2016; Thongtan and Phienthrakul, 2019; Bianchi et al., 2020), we decide to",
      "startOffset" : 59,
      "endOffset" : 133
    }, {
      "referenceID" : 6,
      "context" : "While there exist other definitions of document embeddings (Yang et al., 2016; Thongtan and Phienthrakul, 2019; Bianchi et al., 2020), we decide to",
      "startOffset" : 59,
      "endOffset" : 133
    }, {
      "referenceID" : 7,
      "context" : "use averaging as it is a simple and established embedding technique (Bojanowski et al., 2017; Gupta et al., 2019; Li et al., 2020).",
      "startOffset" : 68,
      "endOffset" : 130
    }, {
      "referenceID" : 18,
      "context" : "use averaging as it is a simple and established embedding technique (Bojanowski et al., 2017; Gupta et al., 2019; Li et al., 2020).",
      "startOffset" : 68,
      "endOffset" : 130
    }, {
      "referenceID" : 25,
      "context" : "use averaging as it is a simple and established embedding technique (Bojanowski et al., 2017; Gupta et al., 2019; Li et al., 2020).",
      "startOffset" : 68,
      "endOffset" : 130
    }, {
      "referenceID" : 10,
      "context" : "Generally, finding a point in TMED(Y ) is hard; SOTA algorithms have an exponential dependency in dimension (Chan, 2004), which is a non-starter when working with high-dimensional embeddings.",
      "startOffset" : 108,
      "endOffset" : 120
    }, {
      "referenceID" : 22,
      "context" : "Preserving privacy for high dimensional objects is known to be challenging (Kamath et al., 2019; Feyisetan and Kasiviswanathan, 2021; Zhou et al., 2009) .",
      "startOffset" : 75,
      "endOffset" : 152
    }, {
      "referenceID" : 16,
      "context" : "Preserving privacy for high dimensional objects is known to be challenging (Kamath et al., 2019; Feyisetan and Kasiviswanathan, 2021; Zhou et al., 2009) .",
      "startOffset" : 75,
      "endOffset" : 152
    }, {
      "referenceID" : 44,
      "context" : "Preserving privacy for high dimensional objects is known to be challenging (Kamath et al., 2019; Feyisetan and Kasiviswanathan, 2021; Zhou et al., 2009) .",
      "startOffset" : 75,
      "endOffset" : 152
    }, {
      "referenceID" : 15,
      "context" : "For instance, adding Laplace noise directly to g(x), as done to satisfy some privacy definitions (Feyisetan et al., 2019; Alvim et al., 2018), does not guarantee SentDP for any .",
      "startOffset" : 97,
      "endOffset" : 141
    }, {
      "referenceID" : 3,
      "context" : "For instance, adding Laplace noise directly to g(x), as done to satisfy some privacy definitions (Feyisetan et al., 2019; Alvim et al., 2018), does not guarantee SentDP for any .",
      "startOffset" : 97,
      "endOffset" : 141
    }, {
      "referenceID" : 26,
      "context" : "A straightforward workaround might be to simply truncate embeddings such that they all lie in a limited set such as a sphere or hypercube as done in prior work (Li and Clifton, 2021; Abadi et al., 2016).",
      "startOffset" : 160,
      "endOffset" : 202
    }, {
      "referenceID" : 0,
      "context" : "A straightforward workaround might be to simply truncate embeddings such that they all lie in a limited set such as a sphere or hypercube as done in prior work (Li and Clifton, 2021; Abadi et al., 2016).",
      "startOffset" : 160,
      "endOffset" : 202
    }, {
      "referenceID" : 45,
      "context" : "Gaussians), we know that its mean lies in the Tukey Median (Zhu et al., 2020).",
      "startOffset" : 59,
      "endOffset" : 77
    }, {
      "referenceID" : 26,
      "context" : "Figure 4: Comparison of our mechanism with two baselines: truncation (Li and Clifton, 2021) and word-level Metric DP (Feyisetan et al.",
      "startOffset" : 69,
      "endOffset" : 91
    }, {
      "referenceID" : 15,
      "context" : "Figure 4: Comparison of our mechanism with two baselines: truncation (Li and Clifton, 2021) and word-level Metric DP (Feyisetan et al., 2019) for both sentiment analysis (IMDB) and topic classification (GoodReads, 20News) on private, unsupervised embeddings.",
      "startOffset" : 117,
      "endOffset" : 141
    }, {
      "referenceID" : 38,
      "context" : "We produce private, general embeddings of documents from three English-language datasets: Good Reads (Wan and McAuley, 2018) 60k book reviews from four categories: fantasy, his-",
      "startOffset" : 101,
      "endOffset" : 124
    }, {
      "referenceID" : 24,
      "context" : "Train-48k | Val-8k | Test-4k 20 News Groups (Lang, 1995) 11239 correspondences from 20 different affinity groups.",
      "startOffset" : 44,
      "endOffset" : 56
    }, {
      "referenceID" : 29,
      "context" : "Train-6743k | Val-2247k | Test-2249k IMDB (Maas et al., 2011) 29k movie reviews from the IMDB database, each labeled as a positive",
      "startOffset" : 42,
      "endOffset" : 61
    }, {
      "referenceID" : 33,
      "context" : "For the general encoder, G : S → R768, we use SBERT (Reimers and Gurevych, 2019), a version of BERT fine-tuned for sentence encoding.",
      "startOffset" : 52,
      "endOffset" : 80
    }, {
      "referenceID" : 15,
      "context" : "Previous methods have argued that it is “virtually impossible” to satisfy pure local DP (Feyisetan et al., 2019; Feyisetan and Kasiviswanathan, 2021) at the word level while capturing linguistic semantics.",
      "startOffset" : 88,
      "endOffset" : 149
    }, {
      "referenceID" : 16,
      "context" : "Previous methods have argued that it is “virtually impossible” to satisfy pure local DP (Feyisetan et al., 2019; Feyisetan and Kasiviswanathan, 2021) at the word level while capturing linguistic semantics.",
      "startOffset" : 88,
      "endOffset" : 149
    } ],
    "year" : 0,
    "abstractText" : "User language data can contain highly sensitive personal content. As such, it is imperative to offer users a strong and interpretable privacy guarantee when learning from their data. In this work, we propose SentDP: pure local differential privacy at the sentence level for a single user document. We propose a novel technique, DeepCandidate, that combines concepts from robust statistics and language modeling to produce high-dimensional, general-purpose -SentDP document embeddings. This guarantees that any single sentence in a document can be substituted with any other sentence while keeping the embedding -indistinguishable. Our experiments indicate that these private document embeddings are useful for downstream tasks like sentiment analysis and topic classification and even outperform baseline methods with weaker guarantees like word-level Metric DP.",
    "creator" : null
  }
}