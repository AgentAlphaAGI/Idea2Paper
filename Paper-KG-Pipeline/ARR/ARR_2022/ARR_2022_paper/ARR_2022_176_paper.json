{
  "name" : "ARR_2022_176_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Ranking-Constrained Learning with Rationales for Text Classification",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Text classification has been used for numerous applications including sentiment analysis (Hemmatian and Sohrabi, 2019), information retrieval (Aggarwal and Zhai, 2012), and language identification (Jauhiainen et al., 2019). When presented with a large number of labeled documents, common text classification models demonstrate impressive results. In practical settings, however, labeled data is often scarce. Labeling documents is a tedious task that requires time and effort, thus curating a large labeled corpus can be expensive and even unrealistic.\nThere is a wide range of use cases for businesses and industry that require curating a labeled dataset for the current task before the need to move on to the next task arises. For example, consider legal case document classification where documents need to be labeled as relevant/not-relevant to the current case at hand. The next legal case requires labeling the documents as relevant/not-relevant for that particular case, and so on. Similarly, several fast-response tasks such as immediate analysis of news and social media posts for a breaking news, for a recently released product, for a policy announcement, etc., require fast curation of a small\nand yet informative labeled dataset. An effective approach to make the best use of the human’s time and maximize classifier performance with a small labeled dataset is to elicit rich feedback, in the form of rationales for classification, during the labeling process (Zaidan et al., 2007, 2008; Donahue and Grauman, 2011; Sharma and Bilgic, 2018). For sentiment classification, for example, the annotators might highlight certain segments of the text that convinced them to label the review as positive. Unlike humans, a classifier will not know which segments of the document are responsible for its label during training, until it has been presented with many training samples. Since the human annotators read the document to decide its label in the first place, they have already spent the time to find the justifications for their labeling decision; hence, previous studies have shown that the extra time needed to highlight a piece of the text as a rationale for its label is not high and is often worth more (for improving the classifier) than spending that time to label an additional document. Zaidan et al. (2007) showed that rationale annotation has low overhead, roughly twice the time required for annotating only the labels. Sharma and Bilgic (2018) showed that annotating a single document with rationales can be worth as many as 20 documents that are simply annotated with labels.\nPrior work on learning with rationales focused on one-hot encoding of the text in combination with logistic regression and support vector machines (Zaidan et al., 2007; Sharma and Bilgic, 2018), deep learning with multi-task learning (Melamud et al., 2019), and rationale-augmented attentionbased models (Bahdanau et al., 2014), which still required a large set of labeled documents. We propose a general approach that is applicable to both one-hot encoding as well as deep learning embedding representations and that is highly effective under limited labeling settings.\nThe rationale supervision can be understood as an expectation that a document should have a higher probability of belonging to its class than the same document from which the rationale(s) are removed. Motivated by this intuition, we formulate a hybrid loss function to combine classification loss with ranking constraints for rationale supervision, which serves as an effective way of directing the model’s focus to rationales during training. Our contributions in this paper include: • We formulate a general and effective learning-\nwith-rationales method for text classification. • We study its empirical effectiveness on three\nhuman-annotated text classification datasets (sentiment analysis, aviation safety, and scientific articles). • We compare our method to several baselines, and empirical findings show that it achieves the stateof-the-art results. For example, our proposed method is able to achieve 80% accuracy on the IMDb movie review dataset (Zaidan et al., 2007) with as few as 23 documents, whereas a finetuned BERT model that does not use rationales required 73 documents, and the most competitive rationale-augmented baseline required 63 documents to achieve the same level of accuracy. • We annotate a new text classification dataset with rationales and make it publicly available. The rest of the paper is organized as follows. We first discuss related work and how our work differs from previous work in Section 2. We formalize our learning with rationales approach in Section 3 and detail the experimental methodology in Section 4, followed by a discussion of the results in Section 5. We discuss the limitations and future work in Section 6 and then conclude."
    }, {
      "heading" : "2 Related Work",
      "text" : "Zaidan et al. (2007) presented one of the first approaches to learning with rationales for text classification. They proposed to utilize humanprovided rationales by converting the rationales into constraints for training support vector machines. They later extended the framework to a rationale-constrained probabilistic model (Zaidan and Eisner, 2008). Sharma and Bilgic (2018) proposed a general method to incorporate rationales into the training of any classifier by weighting the rationale features higher than the non-rationale features. However, their method relied on using a bag-of-words representation of the documents.\nAs deep learning achieved the state-of-the-art performance on text classification (e.g., (Sun et al., 2019; Devlin et al., 2018; Zhang et al., 2015; Yang et al., 2016)), recent work proposed methods specifically for training deep learning models using rationale supervision. Some methods utilized the rationales to generate rationale-augmented representations of the text while others utilized the rationales for richer supervision of the model. For instance, Zhang et al. (2016) proposed a RationaleAugmented CNN (RA-CNN) that jointly learns from the labels of the documents as well as the labels at the sentence level, by using a two-step approach. However, their approach still requires sufficient amounts of data for training a model at the sentence level to learn a valid rationale-augmented representation of a document. Errica et al. (2020) proposed a representation learning approach to leverage rationales by learning to focus on relevant input tokens in the embedding space. Bao et al. (2018) proposed a framework to derive machine attentions from human-provided rationales. Sastry and Milios (2020) defined a new attribution score for words by computing the partial derivative of the output with respect to the input in the word embedding space, and used misattribution error as an additional supervision in the loss function. Our method has two major differences from these work: i) our approach can use but does not require an attention mechanism to focus on the rationales and ii) our approach does not require learning a separate representation for the rationales.\nThe work most closely related to ours is the model proposed by Melamud et al. (2019), which jointly learns to predict the labels for text as well as the labels for each token of every input sentence by determining whether the token is part of the rationales or not. Our approach differs from theirs as our ranking loss is calculated by using only the model’s predictions, rather than introducing auxiliary learning tasks. Moreover, the approach we propose is more general: it can be used for any model that can utilize a logistic loss, ranging from a logistic regression model coupled with a one-hot encoding of words to a Long Short-Term Memory (LSTM) model coupled with word embeddings. In their same paper, Melamud et al. (2019) proposed another method that utilizes rationales by constructing rationale prototypes and rationale-biased text vectors. However, these vectors are computed using a rationale-bias function to directly estimate the\nsimilarity between words and annotated rationales without incorporating any learning, and thus this method works well only for few-shot learning."
    }, {
      "heading" : "3 Learning with Rationales",
      "text" : "Let D = {x1, x2, · · · , xn} be a set of documents. A small subset of the documents, L ⊂ D, are annotated with labels, 〈xi, yi〉 where the value of yi belongs to a label space, C = {c1, c2, · · · , ck}. yi is unknown for a much larger set of unlabeled documents, U = D \\ L, represented as 〈xi, ?〉. Each document, xi, contains a number of sentences, {si1, si2, ..., sim}, each of which is represented as a sequence of words: sij = {q1ij , q2ij , · · · , qlij}.\nIn the learning with rationales framework, a subset of the words is marked by the human annotator as rationales (i.e., justifications for the document’s assigned label). Let ri = ⋃ qlij be the set of all words that are marked as rationales within a document, xi. It is possible that none of the words are marked as rationales, and hence, ri = ∅ for such documents. In the learning-with-rationales setting, L is modified to contain 〈xi, ri, yi〉 and U represents 〈xi, ∅, ?〉. The objective is to train a model, f , that utilizes the documents xi, their labels yi, and their rationales ri during training, and uses only the documents xi at prediction time, as rationales are naturally not available for the test documents.\n3.1 Our Approach – LwR-RC\nWe first describe our proposed approach, Learning with Rationales – Ranking-Constrained (LwR–RC), and then illustrate how it can be specialized for training deep learning models. To illustrate the motivation behind our approach, consider an example document, D, that contains three sentences: “s1: The movie came out last year. s2: The plot was decent. s3: Acting was superb.”, which is labeled as ‘positive’ by the annotator. Assume for the sake of example, the annotator highlights only s3 as the rationale. Let M be a masked document that is same as the original document D, but from which the sentences containing the rationale phrases are removed. In this case, M would be missing s3. We postulate that the model should be more sure about the positive label of document D than the label of document M, since D contains the essential evidence, ‘Acting was superb’, for the ‘positive’ label, whereas M lacks that evidence. Similarly, let R be the document that contains only the rationale sentence s3. We postulate that the model should be\nmore sure about the label ‘positive’ of R than the label of M, since R provides strong evidence for the label, whereas M lacks that evidence.1\nTraditional learning without rationales approaches optimize a loss function to compute the model’s error on its predictions, e.g., a binary crossentropy classification loss, Lclf , is defined as:\nLclf = − 1 |L| ∑ i (yi · log(p(yi|xi))\n+(1− yi) · log(1− p(yi|xi))) (1)\nIn order to leverage the annotated rationales, we formalize our postulations by providing the model with two additional objectives during training. The first objective is to train the model to be more confident about the label of a document (D) than the label of the same document in which the rationales are masked (M). The second objective is to train the model to be more confident about the label of document that contains only the rationales (R) than the label of the same document in which the rationales are masked (M). We achieve these objectives by using a ranking-constrained classification approach, as described next.\nLet 〈xi, ri, yi〉 ∈ L be a training document. First, we construct an artificial document x′i by masking out all the sentences that contain rationales ri. We construct another artificial document xri consisting of only the sentences that contain rationales ri. The ranking-constrained classification approach incorporates the rationales into learning by modeling two expectations: (i) the model should be more sure of assigning the correct label yi to xi than assigning yi to x′i, because x ′ i represents a document from which the rationales have been removed, and we refer to this objective as ‘Document versus Masked document’ (DvM), where D represents xi and M represents x′i, and (ii) the model should be more sure of assigning the correct label yi to xri than assigning yi to x′i, and we refer to this objective as ‘Rationale versus Masked document’ (RvM), where R represents xri and M represents x ′ i.\nAnother possible objective can be ‘Rationale versus Document’ (RvD), however, we excluded RvD objective from our approach for the following reason. Consider the following cases for a binary (positive/negative) classification task: • Case 1: D = R+M is positive; R is positive; M is\nneutral or it contains a small amount of leftover\n1It is possible that the annotator might pick both s2 and s3 as rationales; the same arguments that D and R should be more positive than M still applies.\npositive. In this case, RvD requires R > R+M, which forces M to be negative, whereas RvM requires R > M, which does not necessarily require M to be negative. Thus, RvD is guaranteed to be the wrong approach. RvM forces R > M, but gives the model the flexibility to decide whether M is a small positive, neutral, or negative. • Case 2: D = R+M is positive; R is positive; M is negative. In this case, RvD requires R > R+M, which forces M to be negative, whereas RvM simply requires R > M. In this case, RvD is the correct choice, but RvM cannot be called the guaranteed wrong choice. • Remaining cases: The cases where D and R are negative are similar. As the cases above show, RvM is more flexible: RvM simply nudges the model in the correct direction and leaves the judgement about M to the data. RvD, on the other hand, is a more forceful approach; it forces the model to always make a judgement about M, which is the incorrect judgement in case 1. Thus, we include only the RvM and DvM objectives in our proposed approach.\nFormally, let yi ∈ {0, 1}: f(xi) = p(yi = 1 | xi) = sigmoid(Wzzi) for some parameter matrix Wz , where zi is the vector representation of xi. For modeling the DvM objective, let µi = Wzzi and µ′i = Wzz ′ i where z ′ i is the vector representation of x′i. If the correct label is yi = 1, we would like µi > 0 and µi > µ′i. If the correct label is yi = 0, we would like µi < 0 and µi < µ′i. We convert this constraint into a logistic loss, as follows:\nLiDvM = { log(1 + exp(−(µi − µ′i))), yi = 1 log(1 + exp(−(µ′i − µi))), yi = 0\n(2) Summing LiDvM over all the training instances\nand reorganizing the terms, we get:\nLDvM = − 1 |L| ∑ i (yi · log(p(yi|xi, x′i))\n+(1− yi) · log(1− p(yi|xi, x′i))) (3)\nwhere,\np(yi|xi, x′i) = 1\n1 + e−(µi−µ ′ i)\n(4)\nWe define the ranking loss similarly for the RvM component, using documents R and M and their respective scores µri = Wzz r i and µ ′ i = Wzz ′ i, where zri is the vector representation of x r i . The ranking loss LRvM is then defined as:\nLRvM = − 1 |L| ∑ i (yi · log(p(yi|xri , x′i))\n+(1− yi) · log(1− p(yi|xri , x′i))) (5)\nwhere,\np(yi|xri , x′i) = 1\n1 + e−(µ r i−µ′i)\n(6)\nWe combine the classification loss Lclf with the ranking losses, LDvM and LRvM , resulting in the main objective function for our approach: L = (1−λ1−λ2)Lclf+λ1LDvM+λ2LRvM (7) where, 0 ≤ λ1 ≤ 1, 0 ≤ λ2 ≤ 1, and λ1+λ2 ≤ 1. λ1 and λ2 are two hyper-parameters that control the importance of the classification loss and the ranking losses relative to one another. We study the effect of these hyper-parameters on the model’s performance and provide insights into their relative importance in Section 5.2. We next describe how LwR-RC can be implemented through a neural network architecture, which can be specialized to a logistic regression or to a deep learning model.\n3.1.1 LwR-RC with Deep Learning\nFigure 1 shows the deep learning architecture illustrating how the LwR-RC approach can minimize the loss function of Equation (7). For every sentence {si1, si2, ..., sim} within a document xi, we use an embedding model to create sentence embedding vectors {ti1, ti2, ..., tim}, and pass them through an average pooling layer to create a single vector, zi, representing a document. Similarly, the same sentence embedding vectors are passed through two different pooling layers to create two masked averages, z′i and z r i , representing the document without rationales and the document containing only the\nrationales, respectively. There are several strategies for aggregating many sentence vectors into a single document vector; we use the average pooling strategy for the experiments.\nThe LwR-RC approach can be used to train any model that uses cross-entropy loss functions, including logistic regression and deep neural networks. It can also work with several representations, including one-hot encoding of the words, word2vec (Mikolov et al., 2013), and doc2vec (Le and Mikolov, 2014), as well as more recent language models such as BERT (Devlin et al., 2018), RoBERTa (Liu et al., 2019), and XLNet (Yang et al., 2019). For example, if we remove the embedding layer and the hidden layers, and represent the sentences using one-hot encoding of the words, we would get a simple logistic regression classifier. If we use BERT for encoding the sentences in the embedding layer, then we can either use BERT embeddings directly or fine-tune the BERT model on downstream classification tasks by optimizing the ranking-constrained loss function."
    }, {
      "heading" : "4 Experimental Setup",
      "text" : "In this section, we describe the three datasets, several baselines, and the experimental settings."
    }, {
      "heading" : "4.1 Datasets",
      "text" : "We used two publicly available datasets: a sentiment classification dataset and an aviation safety dataset. Both datasets were annotated with labels and rationales. Additionally, we introduce a new scientific article classification dataset that we annotated with labels and rationales.\nIMDb is a movie review dataset annotated by Zaidan et al. (2007). It consists of 1,800 documents. We used 600 reviews as the training set, 600 reviews as the validation set, and 600 reviews as the test set.\nASRS is an Aviation Safety Reporting System dataset. We used the same balanced binary classification dataset created by Melamud et al. (2019), consisting of reports labeled with either ‘Proficiency’ or ‘Physical Environment.’ The original split had 386 documents for training and 392 documents for testing. We split the test set into two and use 196 documents for validation set and 196 documents for test set.\nAIvsCR contains scientific articles that we collected from arXiv and annotated with rationales. This dataset contains 2,394 documents from Arti-\nficial Intelligence (cs.AI) and Cryptography and Security (cs.CR) categories. Two annotators independently annotated 394 documents with rationales for the ground truth label, and we computed the inter-annotator agreement for the rationales in the same manner as Zaidan et al. (2007). We used 394 human-annotated documents as the training set, 1,000 documents as the validation set, and 1,000 documents as the test set. Note that the validation and test sets do not need rationales; they only need the documents and their labels for evaluation. We make this dataset publicly available, and provide a complete description of this dataset in the appendix."
    }, {
      "heading" : "4.2 Experimental Settings",
      "text" : "For training LwR-RC, we fine-tuned a pre-trained ‘bert-base-uncased’ version of the BERT (Devlin et al., 2018) model on downstream classification task using our ranking-constrained loss function. We input each sentence within a document to BERT and used the ‘[CLS]’ logits from the last hidden layer as the sentence embeddings. To fit the model into GPU (NVIDIA Quadro RTX 5000) memory, we truncated each input sentence to at most 48 tokens (including two special tokens ‘[CLS]’ and ‘[SEP]’), and each document to at most 64 sentences. We used only one hidden layer with 100 nodes in the hidden layers section of Figure 1, and used tanh as the activation function. The total number of model parameters for LwR-RC is 109,559,241. The running time of training LwRRC is similar to training a fine-tuned BERT model without using rationales; LwR-RC needs to make two more forward passes to compute µ′i and µ r i for x′i and x r i , respectively.\nWe present average learning curves over 5 different runs to assess how the models would perform under varying labeling regiments, and plot error bars showing the standard error. Each learning curve starts with a bootstrap of 5 randomly selected documents from each label. Each step of the learning curve corresponds to labeling 20 additional documents. For a fair comparison between various learning strategies, all learning strategies (our approach and the baselines) are fed the same sequence of documents. After the bootstrap phase, we run 10 more steps, and hence the budget of learning curves runs up to 10 + 20 × 10 = 210 documents. Tuning Hyper-parameters. For a fair compari-\nson between our method and the baselines, at each iteration of learning, we performed grid search to optimize the tunable hyper-parameters of each method using the held-out validation set. For LwRRC, we experimented with different pairs of hyperparameters, λ1 and λ2, whose values were selected from the set {0, 0.125, 0.25, 0.5}. We fine-tuned BERT model for LwR-RC for 10 epochs, and selected the best model across different epochs using the held-out validation set. We next discuss the details of the baselines."
    }, {
      "heading" : "4.3 Baselines",
      "text" : "We compare our approach with one Learning without Rationales (Lw/oR) baseline and four Learning with Rationales (LwR) baselines. Learning without Rationales. The Lw/oR-BERT baseline fine-tunes the BERT model for downstream classification tasks, and optimizes the model by only minimizing the classification loss function, Lclf , according to Equation (1). It is worth noting that traditional Lw/oR approaches that fine-tune BERT model on classification tasks have shown impressive performances, and therefore, Lw/oR-BERT is a strong baseline. For example, Sun et al. (2019) achieved the state-of-the-art performances on eight text classification tasks by fine-tuning the BERT model, outperforming both CNN and LSTM based models as well as using just pre-trained BERT embeddings. We observed similar trends in our experiments. Learning with Rationales Baselines. We conducted experiments using four learning-withrationales baselines from the literature. 1) Rationale-Augmented SVM (RA-SVM): This approach is Zaidan et al. (2007)’s model that translates the importance of rationales into additional constraints for training support vector machines. This method requires three hyper-parameters: regularization C for the original samples, regularization Ccontrast for the contrast samples, and margin µ between the original and contrast samples. We optimized these hyper-parameters using grid search, and selected the values of both C and Ccontrast from the set {0.01, 0.1, 1, 10, 100} and the value of µ from the set {0.01, 0.1, 1, 10}. 2) Rationale-Augmented LR (RA-LR): This approach is Sharma and Bilgic (2018)’s approach that emphasizes the rationales and de-emphasizes non-rationales in the vectorized feature matrix representation of the documents. It has three hyper-\nparameters, weight r for the rationale terms, weight o for the non-rationale terms, and regularization C. We selected the value of r from the set {1, 10, 100}, the value of o from the set {0.01, 0.1, 1}, and the value of C from the set {0.01, 0.1, 1, 10, 100} to optimize the hyper-parameters using grid search. 3) RB-BOW-PROTO and 4) RB-WAVG-BERT: These are two models proposed by Melamud et al. (2019) that achieved the state-of-the-art performance in their experiments compared to RationaleAugmented CNN (Zhang et al., 2016), RationaleAugmented SVM (Sharma and Bilgic, 2018), and ULMFiT (Howard and Ruder, 2018). RB-BOWPROTO uses a pre-trained word2vec embedding to construct rationale-biased text vectors for each class as prototypes, and then uses nearest-neighbor classification, instead of training a model to finetune the embeddings. This method has one hyperparameter, α, that controls the impact of rationale biases on the rationale-bias function. We selected the value of α from the set {1, 3, 6, 12} to optimize it using grid search. The second approach, RB-WAVG-BERT, which is more closely related to our work, fine-tunes BERT model to jointly learn the labels on documents and the labels on tokens. We fine-tuned this model for 10 epochs and selected the best model across different epochs, using the learning rate of 5e-6, as suggested by the paper. Melamud et al. (2019) found that RB-BOW-PROTO performed better under extremely-limited labeling settings, and that RB-WAVG-BERT performed better when the training size was larger; hence, we included both approaches as baselines."
    }, {
      "heading" : "5 Results",
      "text" : "We first present results comparing LwR-RC with the baselines, and then discuss the effects of the two ranking-constrained losses on the performance of LwR-RC."
    }, {
      "heading" : "5.1 Comparison with the Baselines",
      "text" : "Figure 2 presents learning curves comparing the average accuracy of the methods over five different runs with up to 210 documents for improved readability. The learning curves with a larger budget of up to 310 documents are included in the appendix. BERT vs. LwR without BERT. The Lw/oR-BERT baseline that did not use rationales but fine-tuned BERT outperforms on the IMDb and AIvsCR datasets the two LwR frameworks (RA-SVM and RA-LR) that used rationales but did not use BERT\n0 25 50 75 100 125 150 175 200 Number of training documents\n75\nAIvsCR\nembeddings. Zaidan et al. (2007) and Sharma and Bilgic (2018) showed that RA-SVM and RA-LR outperformed several Lw/oR approaches, and hence these two are strong LwR baselines. Still, a finetuned BERT model that does not use rationales is able to outperform two strong baselines that used rationales but did not utilize the BERT embeddings. This result highlights the added benefit of the “existing knowledge” that pretrained embeddings provide. BERT Baselines. RB-WAVG-BERT, the baseline that fine-tuned BERT model and utilized rationales, outperforms Lw/oR-BERT, the baseline that did not use rationales, showing the benefits of utilizing rationales with recent deep learning models. However, the improvements provided by RB-WAVGBERT become noticeable only after the model has seen enough data (e.g., more than 50 documents), which was also noted by Melamud et al. (2019). LwR-RC vs. the Best Baseline. We next turn our attention to a fairer comparison: LwR-RC versus RB-WAVG-BERT; both used and fine-tuned BERT embeddings and both utilized rationales. LwR-RC provides statistically significant improvements2 over RB-WAVG-BERT, with a p–value of less than 0.05, especially when the annotation budget is small, and it performs comparably at larger budgets. For IMDb, LwR-RC provides up to 22.3% improvements in accuracy over RB-WAVG-BERT; for ASRS, LwR-RC provides up to 21.7% improvements in accuracy over RB-WAVG-BERT. For AIvsCR dataset, Lw/oR-BERT can quickly reach 90% accuracy even without utilizing rationales, and thus the improvements provided by LwR-RC on this dataset for most training budgets are not as large as the improvements on the other two datasets; however, LwR-RC can still provide up to 8.67% improvements in accuracy over RB-WAVG-BERT. Regarding RB-BOW-PROTO, as Melamud et al. (2019) also observed, it performs well only under extremely-limited budget settings. Corresponding to the learning curves presented in Figure 2, Table 1 shows the number of annotated documents needed for training LwR-RC as well as the two fine-tuned BERT baselines, Lw/oR-BERT and RB-WAVG-BERT, to achieve a target accuracy (ranging from 65% to 90%). As Table 1 shows, LwR-RC usually needs 2 and sometimes 3 times\n2The complete t-test results are presented in the appendix.\nfewer number of annotated documents compared to Lw/oR-BERT and RB-WAVG-BERT to achieve the same level of accuracy."
    }, {
      "heading" : "5.2 The Effects of the Loss Functions",
      "text" : "We further investigate the effects of the two ranking-constrained losses. Specifically, we want to understand how LwR-RC behaves with the two ranking-constrained losses: LwR-RCDvM that uses only LDvM (setting λ1 to 0.25 and λ2 to 0 in Equation (7)), and LwR-RCRvM that uses only LRvM (setting λ1 to 0 and λ2 to 0.25 in Equation (7)). Figure 3 presents the learning curves for these settings. For the IMDb dataset, LwR-RCRvM achieves a slightly higher accuracy than LwR-RCDvM after 100 training documents. For ASRS dataset, LwRRCDvM performs the best, and for AIvsCR dataset, LwR-RCRvM performs the best.\nTo investigate it further, we provide average statistics for the number of sentences, the number of rationale sentences, and the percentage of rationale sentences within the documents for each dataset in Table 2. We observe that LwR-RCRvM performs better when the percentage of rationale sentences in documents is high, e.g., IMDb and AIvsCR datasets, and LwR-RCDvM performs better when the percentage of rationale sentences is\nlow in the documents, e.g., ASRS dataset. We hypothesize that different ranking constraints may be affected differently by a number of factors, including the budget for training documents, the diversity of rationales, the number of rationales provided for each document, how thorough the annotator was in providing rationales, and the domain, to name a few. Table 2 provides only a glimpse of such a study. An exhaustive study is needed for making a definitive conclusion about how various document and rationale statistics affect different ranking-constrained losses, which is beyond the scope of this study. However, the tuning strategy that picks the best λ parameters for LwR-RC at each iteration of learning using a validation set, and hence chooses the appropriate balance between the two loss functions, works well in practice, as was shown in Figure 2."
    }, {
      "heading" : "6 Limitations and Future Work",
      "text" : "We presented experimental results for binary classification tasks in this paper. To the best of our knowledge, prior learning-with-rationales frameworks also focused on binary classification tasks in their experiments. Extending the framework to multi-class settings is a promising future direction. Such an extension would require adapting the loss functions to multi-class settings and creating multi-class classification datasets with rationales. Extending the framework to multi-label settings where a document can be assigned more than one label, however, is more challenging, both for formulating the problem as well as annotating the datasets with rationales, because rationales need to be assigned to their respective labels, which might be more than one in a single document."
    }, {
      "heading" : "7 Conclusions",
      "text" : "We presented a novel approach to incorporate rationales as ranking-constraints into the training of classification models with cross-entropy loss. The proposed approach is general enough that it can be used for simple models, such as logistic regression with one-hot encoding of documents, as well as deep learning models combined with text embeddings. We conducted empirical evaluations comparing the proposed approach to several baselines and observed that the proposed approach outperformed the baselines in most settings, and was comparable to them at the remaining settings."
    }, {
      "heading" : "A Appendix",
      "text" : "In this section, we supplement the results presented in the paper with the following: • In the paper, we focused on experimental results\nwith a budget of up to 210 training documents. Here, we supplement the main results in the paper with a larger budget of up to 310 documents. • We present the improvements in accuracy provided by LwR-RC over the two fine-tuned BERT baselines, Lw/oR-BERT and RB-WAVG-BERT, for all three datasets at varying budgets. • We provide the results of paired t-tests comparing LwR-RC to Lw/oR-BERT and RB-WAVG-BERT. • In the paper, we provided the formulation of LwRRC for binary classification for the ease of exposition. Here, we extend the formulation of LwR-RC to multi-class classification. • We provide a complete description of the AIvsCR dataset that we collected and annotated with rationales for the ground truth labels. • Additionally, we provide the AIvsCR dataset and the other two datasets (IMDb and ASRS), as well as the source code for all the experiments in our paper with this submission as separate .zip files."
    }, {
      "heading" : "B Results with Larger Budgets",
      "text" : "In the paper, we focused on experimental results with a budget of up to 210 training documents (Figure 2). We supplement the results in Figure 2 with a larger budget of up to 310 training documents in Figure 4. As can be seen in Figure 4, the trends of all the results in the paper remain the same even with larger budgets. For IMDb and AIvsCR datasets, LwR-RC still performs better or comparably to the most competitive baseline, RBWAVG-BERT; for ASRS dataset, LwR-RC still outperforms all the baselines. However, as the number of labeled documents grows, we expect our models and the baselines to converge to a similar accuracy, as the models no longer need the human-provided rationales and can learn statistically “what is important” from a large collection of documents that are simply annotated with labels."
    }, {
      "heading" : "C Accuracy Improvements",
      "text" : "We present the improvements in accuracy provided by LwR-RC compared to the baselines for the three datasets across different training budgets. Specifically, we compare LwR-RC with the two fine-tuned BERT based approaches, Lw/oR-BERT and RB-\nWAVG-BERT. As shown in Table 3, LwR-RC provides significant improvements in accuracy over the two baselines across most training budgets: for IMDb, the improvements are up to 23.68%; for ASRS, the improvements are up to 28.31%; for AIvsCR, the improvements are up to 8.67%."
    }, {
      "heading" : "D Statistical Significance Results",
      "text" : "In this section, we provide a summary of pairwise one-tailed t-tests comparing LwR-RC with the two most competitive baselines, Lw/oR-BERT and RBWAVG-BERT, for all three datasets at varying budget regiments. Table 4 shows the p–values of onetailed paired t-tests with the alternative hypothesis “the performance of LwR-RC is better than the baseline approach\". As this result shows, LwR-RC statistically significantly outperforms both Lw/oRBERT and RB-WAVG-BERT at most budget regiments with a p–value of less than 0.05."
    }, {
      "heading" : "E Extension to Multi-class Classification",
      "text" : "In our paper, we focused on binary classification. LwR-RC, can be extended to multi-class classification with a few modifications. For multi-class classification, let yi ∈ {c1, c2, · · · , ck}: f(xi) = p(yi = c | xi) = softmax(Wzzi) for some parameter vector/matrix Wz , where c is the correct label for instance xi and zi is the vector representation of xi. Assuming that yi is encoded as onehot representation, the classification loss function, Lclf , will then change from binary cross-entropy to categorical cross-entropy:\nLclf = − 1 |L| ∑ i (yi · log(p(yi|xi))) (8) For modeling the DvM objective of LwR-RC, let µi =Wzzi and µ′i =Wzz ′ i, where z ′ i is the vector representation of x′i. Then, for the correct label c, we would like µci > 0 and µ c i > µ ′c i , which results in the following objective function:\nLDvM = − 1 |L| ∑ i (yi · log(p(yi|xi, x′i)) (9) where, p(yi|xi, x′i) = softmax(−(µi − µ′i)) (10)\nWe define the ranking loss similarly for the RvM component, this time using the R and M documents and their respective scores µri = Wzz r i and µ ′ i = Wzz ′ i, where z r i is the vector representation of x r i . The ranking loss LRvM is then defined as:\nLRvM = − 1 |L| ∑ i (yi · log(p(yi|xri , x′i)) (11)\nAIvsCR\nwhere, p(yi|xri , x′i) = softmax(−(µri − µ′i)) (12) We combine the classification loss Lclf with the ranking losses, LDvM and LRvM , resulting in the main objective function for our approach for multi-\nclass classification: L = (1− λ1 − λ2)Lclf + λ1LDvM + λ2LRvM\n(13)"
    }, {
      "heading" : "F AIvsCR Dataset Collection and Annotation",
      "text" : "In our study, we experimented with three humanannotated datasets, IMDb, ASRS, and AIvsCR. We collected and annotated the AIvsCR dataset. To construct this dataset, we first collected 6,000 articles equally from two categories, cs.AI and cs.CR, from arXiv.org using a custom search query in the arXiv API. We provide the code, including the custom search queries, that we used to collect the data from arXiv.org with the supplementary material.\nFor annotating the AIvsCR dataset, two annotators, A1 and A2, were provided with the same instructions as Zaidan et al. (2007) described in their paper: highlight the rationales at your best but do not mark everything.\nWe calculated the inter-annotator agreement for the rationales, where the rationales provided by the two annotators for the same document are considered as overlapping if they have at least one word in common, following the same manner of Zaidan et al. (2007). The relevant statistics are shown in Table 5. To make the best use of each annotator’s effort, for every document, we kept the overlapping words, phrases, and sentences between the two annotators’ highlighted rationales as the final rationales, as illustrated in the following example: • A1: rectified linear units are among the most\nwidely used activation function in a broad variety of tasks in vision. • A2: rectified linear units are among the most widely used activation function in a broad variety of tasks in vision. • Final: rectified linear units are among the most widely used activation function in a broad variety of tasks in vision."
    } ],
    "references" : [ {
      "title" : "A survey of text classification algorithms",
      "author" : [ "Charu C Aggarwal", "ChengXiang Zhai." ],
      "venue" : "Mining text data, pages 163–222. Springer.",
      "citeRegEx" : "Aggarwal and Zhai.,? 2012",
      "shortCiteRegEx" : "Aggarwal and Zhai.",
      "year" : 2012
    }, {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio." ],
      "venue" : "arXiv preprint arXiv:1409.0473.",
      "citeRegEx" : "Bahdanau et al\\.,? 2014",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2014
    }, {
      "title" : "Deriving machine attention from human rationales",
      "author" : [ "Yujia Bao", "Shiyu Chang", "Mo Yu", "Regina Barzilay." ],
      "venue" : "arXiv preprint arXiv:1808.09367.",
      "citeRegEx" : "Bao et al\\.,? 2018",
      "shortCiteRegEx" : "Bao et al\\.",
      "year" : 2018
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "Annotator rationales for visual recognition",
      "author" : [ "Jeff Donahue", "Kristen Grauman." ],
      "venue" : "2011 International Conference on Computer Vision, pages 1395– 1402. IEEE.",
      "citeRegEx" : "Donahue and Grauman.,? 2011",
      "shortCiteRegEx" : "Donahue and Grauman.",
      "year" : 2011
    }, {
      "title" : "Concept matching for low-resource classification",
      "author" : [ "Federico Errica", "Ludovic Denoyer", "Bora Edizel", "Fabio Petroni", "Vassilis Plachouras", "Fabrizio Silvestri", "Sebastian Riedel." ],
      "venue" : "arXiv preprint arXiv:2006.00937.",
      "citeRegEx" : "Errica et al\\.,? 2020",
      "shortCiteRegEx" : "Errica et al\\.",
      "year" : 2020
    }, {
      "title" : "A survey on classification techniques for opinion mining and sentiment analysis",
      "author" : [ "Fatemeh Hemmatian", "Mohammad Karim Sohrabi." ],
      "venue" : "Artificial Intelligence Review, pages 1–51.",
      "citeRegEx" : "Hemmatian and Sohrabi.,? 2019",
      "shortCiteRegEx" : "Hemmatian and Sohrabi.",
      "year" : 2019
    }, {
      "title" : "Universal language model fine-tuning for text classification",
      "author" : [ "Jeremy Howard", "Sebastian Ruder." ],
      "venue" : "arXiv preprint arXiv:1801.06146.",
      "citeRegEx" : "Howard and Ruder.,? 2018",
      "shortCiteRegEx" : "Howard and Ruder.",
      "year" : 2018
    }, {
      "title" : "Automatic language identification in texts: A survey",
      "author" : [ "Tommi Jauhiainen", "Marco Lui", "Marcos Zampieri", "Timothy Baldwin", "Krister Lindén." ],
      "venue" : "Journal of Artificial Intelligence Research, 65:675–782.",
      "citeRegEx" : "Jauhiainen et al\\.,? 2019",
      "shortCiteRegEx" : "Jauhiainen et al\\.",
      "year" : 2019
    }, {
      "title" : "Distributed representations of sentences and documents",
      "author" : [ "Quoc Le", "Tomas Mikolov." ],
      "venue" : "International conference on machine learning, pages 1188– 1196. PMLR.",
      "citeRegEx" : "Le and Mikolov.,? 2014",
      "shortCiteRegEx" : "Le and Mikolov.",
      "year" : 2014
    }, {
      "title" : "Roberta: A robustly optimized bert pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "arXiv preprint arXiv:1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Combining unsupervised pre-training and annotator rationales to improve low-shot text classification",
      "author" : [ "Oren Melamud", "Mihaela Bornea", "Ken Barker." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing",
      "citeRegEx" : "Melamud et al\\.,? 2019",
      "shortCiteRegEx" : "Melamud et al\\.",
      "year" : 2019
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean." ],
      "venue" : "arXiv preprint arXiv:1301.3781.",
      "citeRegEx" : "Mikolov et al\\.,? 2013",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Active neural learners for text with dual supervision",
      "author" : [ "Chandramouli Shama Sastry", "Evangelos E Milios." ],
      "venue" : "Neural Computing and Applications, pages 1–20.",
      "citeRegEx" : "Sastry and Milios.,? 2020",
      "shortCiteRegEx" : "Sastry and Milios.",
      "year" : 2020
    }, {
      "title" : "Learning with rationales for document classification",
      "author" : [ "Manali Sharma", "Mustafa Bilgic." ],
      "venue" : "Machine Learning, 107(5):797–824.",
      "citeRegEx" : "Sharma and Bilgic.,? 2018",
      "shortCiteRegEx" : "Sharma and Bilgic.",
      "year" : 2018
    }, {
      "title" : "How to fine-tune bert for text classification? In Chinese Computational Linguistics, pages 194– 206, Cham",
      "author" : [ "Chi Sun", "Xipeng Qiu", "Yige Xu", "Xuanjing Huang." ],
      "venue" : "Springer International Publishing.",
      "citeRegEx" : "Sun et al\\.,? 2019",
      "shortCiteRegEx" : "Sun et al\\.",
      "year" : 2019
    }, {
      "title" : "Xlnet: Generalized autoregressive pretraining for language understanding",
      "author" : [ "Zhilin Yang", "Zihang Dai", "Yiming Yang", "Jaime Carbonell", "Russ R Salakhutdinov", "Quoc V Le." ],
      "venue" : "Advances in Neural Information Processing Systems, volume 32. Curran",
      "citeRegEx" : "Yang et al\\.,? 2019",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "Hierarchical attention networks for document classification",
      "author" : [ "Zichao Yang", "Diyi Yang", "Chris Dyer", "Xiaodong He", "Alex Smola", "Eduard Hovy." ],
      "venue" : "Proceedings of the 2016 conference of the North American chapter of the association for computa-",
      "citeRegEx" : "Yang et al\\.,? 2016",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2016
    }, {
      "title" : "Modeling annotators: A generative approach to learning from annotator rationales",
      "author" : [ "Omar Zaidan", "Jason Eisner." ],
      "venue" : "Proceedings of the 2008 conference on Empirical methods in natural language processing, pages 31–40.",
      "citeRegEx" : "Zaidan and Eisner.,? 2008",
      "shortCiteRegEx" : "Zaidan and Eisner.",
      "year" : 2008
    }, {
      "title" : "Using “annotator rationales” to improve machine learning for text categorization",
      "author" : [ "Omar Zaidan", "Jason Eisner", "Christine Piatko." ],
      "venue" : "Human language technologies 2007: The conference of the North American chapter of the association for computa-",
      "citeRegEx" : "Zaidan et al\\.,? 2007",
      "shortCiteRegEx" : "Zaidan et al\\.",
      "year" : 2007
    }, {
      "title" : "Machine learning with annotator rationales to reduce annotation cost",
      "author" : [ "Omar F Zaidan", "Jason Eisner", "Christine Piatko." ],
      "venue" : "Proceedings of the NIPS* 2008 workshop on cost sensitive learning, pages 260–267.",
      "citeRegEx" : "Zaidan et al\\.,? 2008",
      "shortCiteRegEx" : "Zaidan et al\\.",
      "year" : 2008
    }, {
      "title" : "Character-level convolutional networks for text classification",
      "author" : [ "Xiang Zhang", "Junbo Zhao", "Yann LeCun." ],
      "venue" : "Advances in neural information processing systems, pages 649–657.",
      "citeRegEx" : "Zhang et al\\.,? 2015",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2015
    }, {
      "title" : "Rationale-augmented convolutional neural networks for text classification",
      "author" : [ "Ye Zhang", "Iain Marshall", "Byron C Wallace." ],
      "venue" : "Proceedings of the Conference on Empirical Methods in Natural Language Processing. Conference on Empirical Methods in",
      "citeRegEx" : "Zhang et al\\.,? 2016",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "Text classification has been used for numerous applications including sentiment analysis (Hemmatian and Sohrabi, 2019), information retrieval (Ag-",
      "startOffset" : 89,
      "endOffset" : 118
    }, {
      "referenceID" : 8,
      "context" : "garwal and Zhai, 2012), and language identification (Jauhiainen et al., 2019).",
      "startOffset" : 52,
      "endOffset" : 77
    }, {
      "referenceID" : 4,
      "context" : "An effective approach to make the best use of the human’s time and maximize classifier performance with a small labeled dataset is to elicit rich feedback, in the form of rationales for classification, during the labeling process (Zaidan et al., 2007, 2008; Donahue and Grauman, 2011; Sharma and Bilgic, 2018).",
      "startOffset" : 230,
      "endOffset" : 309
    }, {
      "referenceID" : 14,
      "context" : "An effective approach to make the best use of the human’s time and maximize classifier performance with a small labeled dataset is to elicit rich feedback, in the form of rationales for classification, during the labeling process (Zaidan et al., 2007, 2008; Donahue and Grauman, 2011; Sharma and Bilgic, 2018).",
      "startOffset" : 230,
      "endOffset" : 309
    }, {
      "referenceID" : 19,
      "context" : "Prior work on learning with rationales focused on one-hot encoding of the text in combination with logistic regression and support vector machines (Zaidan et al., 2007; Sharma and Bilgic, 2018), deep learning with multi-task learning (Melamud et al.",
      "startOffset" : 147,
      "endOffset" : 193
    }, {
      "referenceID" : 14,
      "context" : "Prior work on learning with rationales focused on one-hot encoding of the text in combination with logistic regression and support vector machines (Zaidan et al., 2007; Sharma and Bilgic, 2018), deep learning with multi-task learning (Melamud et al.",
      "startOffset" : 147,
      "endOffset" : 193
    }, {
      "referenceID" : 11,
      "context" : ", 2007; Sharma and Bilgic, 2018), deep learning with multi-task learning (Melamud et al., 2019), and rationale-augmented attentionbased models (Bahdanau et al.",
      "startOffset" : 73,
      "endOffset" : 95
    }, {
      "referenceID" : 1,
      "context" : ", 2019), and rationale-augmented attentionbased models (Bahdanau et al., 2014), which still required a large set of labeled documents.",
      "startOffset" : 55,
      "endOffset" : 78
    }, {
      "referenceID" : 19,
      "context" : "For example, our proposed method is able to achieve 80% accuracy on the IMDb movie review dataset (Zaidan et al., 2007) with as few as 23 documents, whereas a finetuned BERT model that does not use rationales required 73 documents, and the most competitive rationale-augmented baseline required 63 documents to achieve the same level of accuracy.",
      "startOffset" : 98,
      "endOffset" : 119
    }, {
      "referenceID" : 18,
      "context" : "They later extended the framework to a rationale-constrained probabilistic model (Zaidan and Eisner, 2008).",
      "startOffset" : 81,
      "endOffset" : 106
    }, {
      "referenceID" : 15,
      "context" : ", (Sun et al., 2019; Devlin et al., 2018; Zhang et al., 2015; Yang et al., 2016)), recent work proposed methods specifically for training deep learning models using rationale supervision.",
      "startOffset" : 2,
      "endOffset" : 80
    }, {
      "referenceID" : 3,
      "context" : ", (Sun et al., 2019; Devlin et al., 2018; Zhang et al., 2015; Yang et al., 2016)), recent work proposed methods specifically for training deep learning models using rationale supervision.",
      "startOffset" : 2,
      "endOffset" : 80
    }, {
      "referenceID" : 21,
      "context" : ", (Sun et al., 2019; Devlin et al., 2018; Zhang et al., 2015; Yang et al., 2016)), recent work proposed methods specifically for training deep learning models using rationale supervision.",
      "startOffset" : 2,
      "endOffset" : 80
    }, {
      "referenceID" : 17,
      "context" : ", (Sun et al., 2019; Devlin et al., 2018; Zhang et al., 2015; Yang et al., 2016)), recent work proposed methods specifically for training deep learning models using rationale supervision.",
      "startOffset" : 2,
      "endOffset" : 80
    }, {
      "referenceID" : 12,
      "context" : "It can also work with several representations, including one-hot encoding of the words, word2vec (Mikolov et al., 2013), and doc2vec (Le and Mikolov, 2014), as well as more recent language models such as BERT (Devlin et al.",
      "startOffset" : 97,
      "endOffset" : 119
    }, {
      "referenceID" : 9,
      "context" : ", 2013), and doc2vec (Le and Mikolov, 2014), as well as more recent language models such as BERT (Devlin et al.",
      "startOffset" : 21,
      "endOffset" : 43
    }, {
      "referenceID" : 3,
      "context" : ", 2013), and doc2vec (Le and Mikolov, 2014), as well as more recent language models such as BERT (Devlin et al., 2018), RoBERTa (Liu et al.",
      "startOffset" : 97,
      "endOffset" : 118
    }, {
      "referenceID" : 10,
      "context" : ", 2018), RoBERTa (Liu et al., 2019), and XLNet (Yang et al.",
      "startOffset" : 17,
      "endOffset" : 35
    }, {
      "referenceID" : 22,
      "context" : "(2019) that achieved the state-of-the-art performance in their experiments compared to RationaleAugmented CNN (Zhang et al., 2016), RationaleAugmented SVM (Sharma and Bilgic, 2018), and ULMFiT (Howard and Ruder, 2018).",
      "startOffset" : 110,
      "endOffset" : 130
    }, {
      "referenceID" : 14,
      "context" : ", 2016), RationaleAugmented SVM (Sharma and Bilgic, 2018), and ULMFiT (Howard and Ruder, 2018).",
      "startOffset" : 32,
      "endOffset" : 57
    }, {
      "referenceID" : 7,
      "context" : ", 2016), RationaleAugmented SVM (Sharma and Bilgic, 2018), and ULMFiT (Howard and Ruder, 2018).",
      "startOffset" : 70,
      "endOffset" : 94
    } ],
    "year" : 0,
    "abstractText" : "We propose a novel approach that jointly utilizes the labels and elicited rationales for text classification to speed up the training of deep learning models with limited training data. We define and optimize a ranking-constrained loss function that combines cross-entropy loss with ranking losses as rationale constraints. We evaluate our proposed rationale-augmented learning approach on three human-annotated datasets, and show that our approach provides significant improvements over classification approaches that do not utilize rationales as well as other state-of-the-art rationaleaugmented baselines.",
    "creator" : null
  }
}