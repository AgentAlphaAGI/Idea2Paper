{
  "name" : "ARR_2022_326_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Entity Linking via Explicit Mention-Mention Coreference Modeling",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Natural language corpora, such as biomedical research papers (Leaman and Lu, 2016), news articles (Milne and Witten, 2008; Hoffart et al., 2011), and, more generally, web page text (Gabrilovich et al., 2013; Lazic et al., 2015a), often contain ambiguous mentions of entities. Resolving this ambiguity requires mentions to either be linked to a knowledge base (KB) of entities or discovered as a new KB concept if no suitable entry exists. Grounded entity mentions can be beneficial for tasks such as question-answering (Das et al., 2019), semantic search (Leaman and Lu, 2016), recommendation ranking (Noia et al., 2016), and KB construction (Ling et al., 2015). The task is made particularly challenging in zero-shot settings, where not every entity has labeled training data (Lin et al., 2017; Logeswaran et al., 2019). In such settings, a common approach is to make use of entity descriptions,\ntypes, and aliases to form entity representations, which are then used for making predictions.\nLearned vector representations of entity mentions are an integral part of modern linking systems (Gillick et al., 2019; Wu et al., 2020, inter alia). These representations are used for (a) retrieving a short-list of entity candidates for a mention for use with a re-ranker (Wu et al., 2020), (b) making linking predictions directly (Zhang et al., 2021; Liu et al., 2020; Sung et al., 2020), and (c) performing coreference by clustering mentions to form entities (Logan IV et al., 2020).\nIn this work, we present a new objective and training procedure for learning mention and entity representations that explicitly models mention coreference relationships. Our proposed method uses a supervised clustering training objective based on forming a directed minimum spanning tree, or arborescence, over mentions and entities. We hypothesize that such coreference links provide a useful inductive bias because the two tasks are inherently related (Angell et al., 2021; FitzGerald et al., 2021). We thoroughly analyze the performance of the proposed training procedure in each of the aforementioned use cases on MedMentions (Mohan and Li, 2019) and ZeShEL (Logeswaran et al., 2019), two challenging datasets that require zero-shot generalization at inference.\nRetrieving Candidates. We illustrate that our approach yields mention and entity representations useful for candidate retrieval. We show improvements over baselines that use similarly parameterized models, achieving gains of at least 7.94 and 0.93 points in recall@64 over two standard dualencoder training procedures on MedMentions and ZeShEL, respectively. We also consider the linking capacity of our learned embeddings without re-ranking and find that their performance (i.e recall@1) indeed improves upon our baselines. Our best performing models show gains of 13.61 & 15.46 points in linking accuracy on MedMentions and 12.06 & 1.52 points on ZeShEL.\nLinking Predictions. We further consider the improvement in downstream training of full crossattention re-ranker models using higher quality candidates generated by our approach. We show consistent gains in linking accuracy on MedMentions, setting a new state-of-the-art with a 1.63 point gain over the previous best model. We also note that our proposed approach shows mixed results on ZeShEL, with one variant outperforming all compared models by at least 1.19 points, while the other two underperform the baselines. We analyze this behavior in a later section and discuss the characteristics of the data distribution sufficient to make our approach effective.\nCross-Document Coreference. Finally, we illustrate that the learned representations can be used to perform coreference of mentions across documents. This indicates that they could be used to discover entities in settings where there is limited or no existing knowledge base of entities."
    }, {
      "heading" : "2 Arborescence-based Training for Mention & Entity Representations",
      "text" : "In this section, we describe our proposed approach for constructing training objectives for dualencoders that model mention coreference relationships."
    }, {
      "heading" : "2.1 Problem Definition",
      "text" : "Each document d of a corpus D contains a set of entity mention spans Md = {md1,md2, . . . ,mdN}. All mentions in the corpus are given by M =⋃\nd∈D Md. Following (Logeswaran et al., 2019; Angell et al., 2021), we assume that these mentions are pre-identified spans of text.\nEntity Linking Formally, we define the task of entity linking as follows: given a knowledge base of entities E and a set of mentions M, predict an entity edi ∈ E for each mention mdi . We use e⋆ d i to refer to the ground truth entity label for mdi . Zero-Shot Linking The zero-shot task refers to the setting where there are entities in the knowledge base that do not have any labeled training data. Linking decisions must instead rely on provided information for entities, such as a descriptions, aliases, and/or entity types.\nCoreference We also consider a setting in which the KB of entities is not known in advance and entities must be discovered. For this task, we map every entity mention mdi to a cluster and assign a coreference label cdi ∈ C that is independent of the entity labels in the KB."
    }, {
      "heading" : "2.2 Coreference-based Similarity",
      "text" : "In order to jointly train both the mention and entity encoders, we define a similarity measure and an analogous procedure for sampling positive training examples that intersperses the selection of coreferent mentions and gold entities based on a singlelinkage structure formed by the representations generated by the model snapshot. We construct k-nearest neighbor graphs over coreferent mention and entity clusters, followed by the application of a pruning algorithm to generate arborescence (directed MST) structures rooted at entity nodes. In this way, the resultant edges represent pairs of positive examples used for training.\nGraph-based Dissimilarity Let G be a graph with nodes V = M ∪ E and directed edges E ⊂ V × V . Each edge (x, y) of the graph has an associated weight wx,y. We define a dissimilarity function f between two nodes u, v ∈ V to be the weight of the minimax path between the nodes, i.e.\nf(u, v) =\n{ min\np∈u⇝v max (x,y)∈p wx,y, if connected(u, v)\n∞ otherwise (1)\nwhere connected(u, v) is true if there exists a directed path from node u to v inG, and u⇝ v is the set of all paths between u and v. In words, the dissimilarity between u and v is the minimum of the largest edge weights in all paths between the two nodes, and this is often referred to as the \"bottleneck edge\". This measure has the property of emitting low dissimilarities between nodes even when the direct edge weight wu,v is high by connecting them through a chain of low-weight edges, providing an inductive bias well-suited for coreference, i.e. not all pairs of points in a cluster are nearby (Figure 1). This inductive bias is not achieved if we sum edge weights and simply find the minimum path.\nEdge Weights With this definition of dissimilarity, we now define how edge weights are calculated. We use two models: a mention-pair affinity model, ϕ : M × M → R, and a mention-entity affinity model, ψ : E × M → R. An edge between two mentions mi and mj has weight:\nwmi,mj = −ϕ(mi,mj), (2)\nand the weight of the edge from entity e to mi is:\nwe,mi = −ψ(e,mi) (3)\nEach of ϕ(·, ·) and ψ(·, ·) are independently parameterized by dual-encoder transformer models\n(Gillick et al., 2019; Humeau et al., 2019), one for mentions (EncM), and one for entities (EncE). The affinity models are simply the inner products of the associated encoded representations:\nϕ(mi,mj) = EncM(mi) TEncM(mj)\nψ(e,mi) = EncE(e) TEncM(mi)\n(4)\nFor the mention encoder, EncM, the transformer input is the surrounding mention context with the mention span marked by special tokens [START] and [END]:\n[CLS]cleft[START]mi[END]cright[SEP]\nwhere cleft and cright are the left and right contexts of the mention mi in the document. For the entity encoder, EncE, the transformer takes as input the title and description of the entity:\n[CLS]etitle[TITLE]edesc[SEP]\nIn this input, edesc is the token sequence corresponding to the description of the entity, which could include natural language text related to the entity, such as a \"wiki\" entry, a list of entity aliases, or any other available features useful in forming an entity representation."
    }, {
      "heading" : "2.3 Training Procedure",
      "text" : "We now define our approach for training the affinity models, ϕ(·, ·) and ψ(·, ·), and their associated encoders, EncM and EncE. Our objective is to optimize the dissimilarity function f(·, ·) such that the procedure infers a set of clusters that each contain exactly one entity, and every mention is assigned to the cluster containing its ground truth entity. We optimize f(·, ·) using mini-batch gradient descent by sequentially building batches of mentions B ⊂ M over the training data, where each mi ∈ B has its gold entity defined by e⋆i . We then build a graph GB with nodes consisting of each mi ∈ B, each mention coreferent to mi ∈ B, and the set of gold entities for each mi ∈ B. For every mi, we build a set of directed edges defined by\nEmi = { (e⋆i ,mℓ) ∣∣∣mℓ ∈ Me⋆i } ∪ { (mℓ,mp)\n∣∣∣mℓ,mp ∈ Me⋆i } (5) The complete set of edges in graph GB for a minibatch B is then given by E(GB) = ⋃ mi∈B Emi . Observe that the resultant edges ensure that each connected component contains exactly one entity (namely, the gold entity for the mentions in that connected component).\nForming Clusters for Positive Sampling. The graphGB is input to a constrained clustering proce-\ndure that partitions a graph G into disjoint clusters C = {C1, . . . , CM} such that each cluster contains at most one entity. There are three constraints that every C ∈ C must satisfy:\n(i) |C ∩ E| ≤ 1, (ii) ∀u, v ∈ C, connected(u, v) =⇒ f(u, v) ≤ λ, (iii) ∀u, v ∈ C, connected(u, v) ∨ connected(v, u)\nwhere λ is a hyperparameter representing the dissimilarity threshold over which edges between nodes are dropped. We set λ = ∞ during training. These constraints ensure that (i) there is at most one entity in each cluster, (ii) if u is reachable from v then every edge in the path from v to u has a weight ≤ λ, and (iii) each node in the cluster has a path connecting itself with every other node in the cluster. We solve this constrained clustering problem, i.e., partition graph G, using a process similar to Angell et al. (2021).\nSpecifically, we first remove all edges in graph G with weight greater than threshold λ. We then evaluate each edge (u, v) ∈ E in descending order of dissimilarity and check if its presence violates any of the three constraints defined above, removing the edge from E if it does. If not, we evaluate whether there is an entity in the connected component of node u, i.e. |Cu ∩ E| = 1. If |Cu ∩ E| = 1, we temporarily drop edge (u, v) and check whether v can still be reached by an entity node. If reachable, we permanently drop (u, v), maintaining the validity of constraint (i) as well as our minimax dissimilarity function f(·, ·). If an entity cannot reach v, we retain edge (u, v), preserving the connectivity of the cluster, and iterate further. Our predicted clusters are the resultant connected components in the partitioned graph G.\nUsing this clustering procedure on GB , we construct a partitioned target graph G⋆B = {E⋆mi | mi ∈ B}. We use E ⋆ mi to optimize the parametric encoder models. Note that each mention node in a target edge set E⋆mi has only one incoming edge originating from either an entity or a mention, and the selection of E⋆mi was done in a way to minimize f(·, ·) between mentions and entities with coreferent labels on the subgraph of the mini-batch.\nFor every cluster with an entity node, the edge structure is a directed analogue of the minimum spanning tree, where there exists a directed path from the entity node to every other node in the cluster. This structure is often referred to as the minimum spanning arborescence, thus lending its\nname to our method, i.e. ARBORESCENCE-based linking.\nNegative Sampling. Akin to the graph embedding objectives used by Nickel and Kiela (2018) and others, we construct our objective by sampling hard negative edges. For each mention mi ∈ B, the set of negative edges N(mi) is the k/2 lowestweight incoming edges from E \\ {e⋆i } and the k/2 lowest-weight incoming edges from M \\ Me⋆i , where k is a specified hyperparameter.\nLoss Function. We define Γ(mi) = {u | (u,mi) ∈ E∗mi} ∪ {u | (u,mi) ∈ N(mi)} to be the set of all neighbors with an outgoing edge to mi in the training graph. Let Iu,mi be the indicator variable such that Iu,mi = 1 if (u,mi) ∈ E∗mi and Iu,mi = 0 otherwise. Our loss function with respect to each mention mi ∈ B is then defined as follows:\nL(mi) = ∑\nu∈Γ(mi)\n( Iu,mi log(σu(wu,mi)) (6)\n+ (1− Iu,mi) log(1− σu(wu,mi)) ) ,\nwhere σ(·) is the softmax function over all edges in Γ(mi)× {mi}. The loss for the entire batch B is the mean of losses over all mentions in B. Optimizing this loss function requires simultaneously increasing the likelihood of the positive edges and decreasing the likelihood of the negative edges. This objective and training routine are inspired by the supervised single-linkage clustering proposed by Yadav et al. (2019), but differs in the choice of loss function and selection of negative examples. We also experimented with the standard cross-entropy loss, but found its performance subpar."
    }, {
      "heading" : "3 Experiments",
      "text" : "We are interested in investigating the following empirical research questions:\n• Does our proposed approach improve the recall of candidate generators? • Do improvements in candidate generation at training lead to improvements in downstream re-ranker models? • Does our approach result in better learned mention embeddings that can be used for coreference / discovering entities when a KB does not exist?\nExperiment Details Our experiments are run on top of BLINK (Wu et al., 2020), a PyTorch (Paszke et al., 2019) implementation of dual- and cross-encoder architectures for entity linking, with\nmodel fine-tuning performed over only BERT-base, since gains from pre-trained LM size are unrelated to our approach. For more details, see Appendix §A.1."
    }, {
      "heading" : "3.1 Datasets",
      "text" : "We run experiments on two entity linking datasets that both require generalization to unseen entities at test time. Each document in the datasets contains a set of entity mention spans, which are pre-defined using common mention detection heuristics. KB entities are composed of two metadata attributes – an entity title and description, which are natural language sequences of text. ZeShEL, additionally, contains a fine-grained type specification, which is needed due to the diverse disjoint domains contained in the dataset. The statistics for both datasets are reported in Table 2.\nMedMentions (Mohan and Li, 2019) is a collection of titles and abstractions of bio-medical research papers. The KB that is used for this dataset is the 2017AA full-version of UMLS. The validation and test sets contain both entities that are present in the training set as well as entities that are\nzero-shot (never seen at training time). We use the author-recommended ST21pv subset.\nZeShEL (Logeswaran et al., 2019) is a collection of crowd-sourced wikis, which are divided into train, validation, and test splits such that no Fandom topic overlaps across the sets. In this way, all entities that appear at validation and test time are not seen during training."
    }, {
      "heading" : "3.2 Dual-Encoder Retrieval",
      "text" : "In order to evaluate the benefit of explicitly modeling coreference relationships, we construct three variants of our proposed dual-encoder training objective, which jointly trains both the mentionmention similarity function ϕ(·, ·) and the mentionentity similarity function ψ(·, ·). We compare to baselines that only explicitly train ψ(·, ·), and rely on the structure of ϕ(·, ·) sharing representations with ψ(·, ·) to provide meaningful mentionmention similarities. Our proposed objectives are identical to each other except in how the positive training pairs are constructed, while our baselines differ in the selection of negatives.\nArborescence In this training variant, for each mention query, we first construct a fully-connected graph of the ground truth coreferent mention cluster along with the gold entity. We then apply the pruning procedure described in the previous section to compute an arborescence rooted at the entity node. From the resultant graph, each pair of a mention and its incoming-edge node (which can either be a coreferent mention or the gold entity) is then treated as a positive example for training. Following previous work by Gillick et al. (2019), we use hard negative mining with k = 10 negatives composed of equal number of mention and entities.\n1-NN Arborescence Instead of constructing a fully-connected k-NN graph over the entire gold cluster, in this variant we approximate the arborescence structure by pruning a restricted graph of\nonly the gold entity, the query mention, and the most similar within-cluster mention neighbor of the query. We keep all other details of the training procedure identical to the first variant.\n1-Rand Arborescence A third training objective we explore modifies the initial k-NN graph construction by restricting the nodes to the gold entity, the query mention, and a random withincluster mention neighbor of the query, instead of the nearest-neighbor.\nBaselines We compare to two baselines following previous work: (1) training ψ(·, ·) with random negatives (IN-BATCH NEGATIVES) where each gold entity for a mention in a training batch is treated as a negative example for all other mentions in the batch, and (2) training ψ(·, ·) with hard negatives (K-NN NEGATIVES) similar to the negative mining in our proposed methods albeit with only mention-entity positive selection.\nResults In Table 1, we report the test set recall@64 for each dual-encoder model, where the prediction is evaluated as a hit if the gold entity is retrieved in the top-64 candidates of the model. On each dataset, we additionally include the performance of candidate generators used by previous works that we compare to.\nWe find that models trained with explicit coreference relationships outperform those that incorporate this relationship only indirectly. For recall@64, our proposed methods improve over the baseline models by at least 7.94 percentage points on MedMentions and 0.93 points on ZeShEL. Even at linking, or recall@1, our proposed methods show similar improvements, with gains of 13.61 and 1.52 points over the next best baseline models. We perform a more comprehensive analysis of the dualencoder linking performance and describe our inference approach and results in Appendix §A.2 and §A.3.\nWe posit that much of the observed gains in recall using our proposed methods result from higher quality mention embeddings generated due to a wide array of surface forms available to mention queries at training. Since each training example evaluates not only the gold entity but also its coreferent mentions, this leads to better generalization of representations. We evaluate this improvement in representations in the clustering/coreference setting in Section 3.5.\nWe also provide representative examples of predictions comparing the candidates generated by our proposed ARBORESCENCE to the retriever from Angell et al. (2021) in Appendix Table 7."
    }, {
      "heading" : "3.3 Cross-Encoder Re-ranking",
      "text" : "To answer our second research question, we compare 5 cross-attention models, which are trained using entity candidates generated by the dualencoder variants discussed in the previous experiment. Training and inference batches are constructed by concatenating each mention with an entity candidate separated by a [SEP] token. Similar to Wu et al. (2020), we use the top-64 retrieved entities as hard negatives during training and as linking candidates during inference.\nResults We report the cross-encoder linking accuracy for MedMentions in Table 3. We additionally report the breakdown of accuracy on subsets of test mentions for which the ground truth entities were not evaluated (\"unseen\") during training, illustrating the zero-shot capability of the models. We also include the current state-of-the-art results by Angell et al. (2021), which uses an n-gram based model for candidate generation and two crossencoder models, one each for mention-mention and mention-entity scoring, as the re-ranker. We observe that each cross-encoder trained with candidates generated by an arborescence-based model outperforms the baselines, including the current\nSOTA by at least 0.63 points, and the best performing model – ARBORESCENCE – achieves 1.63 point gains. We note, however, that Angell et al. (2021) does better on unseen entities by 1.91 points compared to ARBORESCENCE, which might be a result of the within-document nature of their TFIDF candidate retriever.\nTable 4 contains linking results for ZeShEL, where each reported model varies only in the method used for retrieving the entity candidates, while the cross-encoder re-ranker training method is held constant (K-NN NEGATIVES with k = 64). Since ZeShEL is completely zero-shot, we do not include a seen-unseen analysis. We follow Wu et al. (2020) and report the unnormalized accuracy, which is calculated as the percentage of successes out of the total number of query mentions in the test set, and the macro-averaged unnormalized accuracy, which is a simple average of the unnormalized accuracies over the different \"worlds\", or domains, in the test set. We find that the best performing model is 1-RAND ARBORESCENCE, with a 1.19 point difference in macro-averaged accuracy over the next best model (Wu et al., 2020).\nWe also note that, unlike on MedMentions, not all of our proposed models have higher accuracy than the mention-entity baselines. Since a key motivation for the proposed arborescence-based methods is to explicitly model coreference relationships during training, we expect performance gains to be strongly correlated with the number of coreference links present within the dataset. We analyze the two datasets in terms of the number of mentions for each KB entity. This can be thought of as how large each cluster of coreferent mentions is. We report a histogram distribution in Figure 2. We find that the clusters in ZeShEL are typically very small (at most 3), whereas in MedMentions, each cluster has many more mentions with maximum sizes of\n1256, 434, and 447 across the train, validation, and test sets."
    }, {
      "heading" : "3.4 Oracle Inference",
      "text" : "In this setting, we isolate the re-ranking capability of the cross-encoder from the quality of the candidates retrieved at inference. This setting also removes the upper-bound on re-ranker accuracy by artificially injecting the ground-truth entity in the top-64 candidates retrieved at inference for each mention where retrieval failed. An additional setting we explore holds this oracle candidate set constant across each variant of the cross-encoder by taking a union over all dual-encoder candidate sets, and then proceeding to inject the ground-truth. This construction provides a way to purge the factor of candidate retrieval quality at inference, which otherwise conflates the comparison of re-ranking performance. We refer to these oracle settings as SELF and UNION, respectively.\nResults As seen in column Oracle of Table 3, the baseline models show higher linking accuracy than our proposed methods when the gold entity is guaranteed to be present in the original candidate set. However, the performance of the baseline models drops significantly (≥ 32 points) when evaluated with the UNION candidate set, while the arborescence-based models show a ± 0.9 point variation. We believe this discrepancy clearly highlights the poor quality of candidates retrieved by the baseline models compared to our proposed methods. This also explains the inflation in accuracy of the baselines on the SELF set due to the trivial discrimination task presented to the cross-encoders. We further point to linking performance on the UNION set, which provides the more challenging task of differentiating between higher quality candidates that are similar and argue that the large performance difference (≥ 26.75 points) is strongly\nindicative of the greater linking capacity of our proposed methods.\nIn Table 4, we report both the micro accuracy and macro-averaged accuracy for the two oracle sets. We observe that 1-RAND ARBO performs the best on the UNION set, but is marginally outperformed by IN-BATCH on micro accuracy on the SELF set by 0.02 points. In contrast to the fluctuation on MedMentions, the relative stability of results on the oracle candidate sets indicates that the candidates generated by each model have similar quality."
    }, {
      "heading" : "3.5 Mention Coreference",
      "text" : "We evaluate the quality of the learned mention representations for cross-document coreference. Entity labels of each mention are its ground truth cluster assignment. To form clusters, we build mentiononly arborescences using the clustering procedure described in Section 2.3, tuning the threshold value, λ, based on the validation data. In Table 5, we report the Adjusted Rand Index (ARI) clustering scores using each of the representation learning objectives using dual-encoders. For both ZeShEL and MedMentions, we report ARI on all the test mentions (denoted ALL). For MedMentions, we report two additional settings: (1) ARI when clustering mentions with ground truth entity not seen at training (denoted UNSEEN ONLY) and (2) clustering on all mentions but evaluating only on the set in (1) (denoted ALL/UNSEEN). Representations learned with the ARBORESCENCE objective performs best on each setting, aligning with the inductive bias."
    }, {
      "heading" : "4 Related Work",
      "text" : "Entity Linking Entity linking has been widely studied (Milne and Witten, 2008; Cucerzan, 2007; Lazic et al., 2015b; Gupta et al., 2017; Raiman and Raiman, 2018; Kolitsas et al., 2018; Cao et al., 2021, inter alia). Dutta and Weikum (2015) combine clustering-based cross-document coreference decisions and linking around sparse bag-of-word representations not well suited for the embedding-\nbased representations used in this work. Hoffart et al. (2011); Cheng and Roth (2013); Ganea and Hofmann (2017); Le and Titov (2018) use global objectives instead of independent predictions, measuring the compatibility of entity links. Zhang and Stratos (2021) use noise contrastive estimation to mine hard negatives for the linking task.\nCross-document Coreference Models have been developed for the cross-document coreference setting where no entity KB is known in advance (Bagga and Baldwin, 1998; Gooi and Allan, 2004; Singh et al., 2011; Barhom et al., 2019; Cattan et al., 2020; Caciularu et al., 2021; Ravenscroft et al., 2021; Logan IV et al., inter alia).\nAlternatives to Cross-Encoders Our work demonstrates how clustering-based training and prediction improves dual-encoder based models for linking and discovery. If prediction efficiency, and not training efficiency, was the only concern, one could use model distillation (Hinton et al., 2015; Izacard and Grave, 2021, inter alia). We could also consider models such as poly-encoders as an alternative to dual-encoders (Humeau et al., 2020)."
    }, {
      "heading" : "5 Conclusion",
      "text" : "We presented a novel approach for learning mention and entity representations for use in entity linking candidate generation and prediction, as well as in the discovery of new entities. Our approach uses an objective that explicitly incorporates mentionto-mention coreference relationships. We demonstrated its empirical effectiveness through analysis on two datasets, MedMentions and the Zero-Shot Entity Linking dataset. As future work, we hope to further analyze these objectives with the lens of efficiency, distillation, and domain transfer."
    }, {
      "heading" : "6 Ethical Considerations",
      "text" : "The base models, which we fine-tuned, and evaluation datasets are all publicly available. We will also make our code and models publicly available. There are several ways in which entity linking/entity resolution models could be biased and there is the potential for those biases to have harmful downstream consequences. There is a large body of work studying the biases of language models (such as those used for fine-tuning here) and coreference models. Most notably in understanding when error rates in coreference differ across certain populations (e.g., genders, races, or any entitytype more broadly). If entity linking and discovery systems are used to build / populate knowledgebases, those systems may propagate these biased predictions. This could be particularly problematic if one used such a biased knowledge-base with this realization. For instance, if entity mentions are author names on citation data and the entities are scientific authors, statistics like h-index or citation count could be biased if the algorithms used to disambiguate the author names are biased. Lastly, we note entity linking and discovery are related to surveillance and tracking in computer vision, which bear a substantial weight of ethical considerations."
    }, {
      "heading" : "A Appendix",
      "text" : "A.1 Experiment Details Our experiments are run on top of BLINK (Wu et al., 2020), a PyTorch (Paszke et al., 2019) implementation of dual- and cross-encoder architectures for entity linking, with model fine-tuning performed over only BERT-base, since gains from\npre-trained LM size are unrelated to our approach. Each training procedure is run on a single machine using 2 NVIDIA Quadro RTX 8000 GPUs. Our dual-encoder models for ZeShEL and MedMentions have 218M and 230M parameters, respectively. Each variant is optimized using mini-batch gradient descent using the Adam optimizer for 5 epochs using a mini-batch size of 128 to accumulate the gradients. Experiments with batch sizes < 128 performed poorly, possibly due to increased fluctuation of gradients, and sizes > 128 were computationally infeasible to run with our available compute resources. For ZeShEL, the dual-encoder models are trained using 192 warm-up steps and learning rates of 1e-5, 3e-5, and 3e-5 for In-batch, k-NN, and Arborescence-based models, respectively. For MedMentions, each model is trained using 464 warm-up steps and a learning rate of 3e5. All cross-encoder models are trained with a minibatch size of 2, learning rate of 2e-5, and an additional linear layer. Our MedMentions and ZeShEL cross-encoder models have 108M and 109M parameters, respectively. We use FAISS1 (Johnson et al., 2017) for fast nearest-neighbor search during graph construction at both training and inference. For MedMentions, the execution time was 70 mins to embed and index 2M entities and 120K mentions, and 20 mins to perform exact nearestneighbor search for the 120K mentions.\nA.2 Dual-Encoder Inference Procedure Building the Graph The structure of the graph G impacts the dissimilarity function by changing the paths between pairs of nodes in addition to changing which pairs of nodes are connected. We advocate for a simple, deterministic approach to construct this graph. For each mentionm, construct Em by (1) adding edges from m’s k-nearest neighbor mentions in M to m, and (2) adding an edge from m’s nearest entity to m:\nEm =\n{ (u,m) ∣∣∣ u ∈ argmink m′ ∈ M wm′,m\n∨ u = argmin e ∈ E we,m } (7) The complete collection of edges E in G is given by E(G) = ⋃ m∈MEm. There are other ways that one could conceivably pick the pairs of mentions to be connected in the graph. For example, one could use the minimum spanning tree over the mentions. This approach, however, has several drawbacks: (1)\n1https://github.com/facebookresearch/faiss\nthe directionality of nearest neighbor relationships is ignored leading to added noise in the graph, and (2) the resultant graph includes edges that clearly cross cluster boundaries due to this approach forcing all pairs of mentions to be connected.\nForming Clusters & Making Predictions To make linking decisions for each mention mdi , we assign the ID of the entity present in the mention’s cluster as the linking label (or NIL if there is no entity in the cluster). Let C(mdi ) be the predicted cluster of mention mdi , then:\nedi = { C(mdi ) ∩ E , if |C(mdi ) ∩ E| = 1 NIL, otherwise . (8)\nFurthermore, the clusters we predict for in the entity discovery setting are exactly C.\nA.3 Experiment: Dual-Encoder Linking Each model is evaluated using three inference procedures. Independent refers to predictions made using only mention-entity edges. This method was used by Wu et al. (2020) to generate candidates for a cross-encoder model trained on ZeShEL. Clustering (UNDIRECTED) refers to a hierarchical agglomerative clustering (HAC) procedure, following previous work by Angell et al. (2021), which is akin to the procedure for positive sampling used for training our arborescence-based models, but with no edge directionality. Clustering (DIRECTED) adds directed edges to the previous method. For each model, we pick the best performing inference procedure on the dev set and report the test set performance.\nWe report the linking accuracy in Table 6 but leave out models from previous works since they do not report linking accuracy of their candidate generators. We specify the inference method used in each case, chosen based on the dev set accuracy of the models. Similar to our cross-encoder results in Table 3, we report the \"seen\" and \"unseen\" performance for MedMentions."
    } ],
    "references" : [ {
      "title" : "Clusteringbased inference for biomedical entity linking",
      "author" : [ "Rico Angell", "Nicholas Monath", "Sunil Mohan", "Nishant Yadav", "Andrew McCallum." ],
      "venue" : "Conference of the North American Chapter of the Association for Computational Linguistics (NAACL).",
      "citeRegEx" : "Angell et al\\.,? 2021",
      "shortCiteRegEx" : "Angell et al\\.",
      "year" : 2021
    }, {
      "title" : "Entity-based cross-document coreferencing using the vector space model",
      "author" : [ "Amit Bagga", "Breck Baldwin." ],
      "venue" : "36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, Volume 1,",
      "citeRegEx" : "Bagga and Baldwin.,? 1998",
      "shortCiteRegEx" : "Bagga and Baldwin.",
      "year" : 1998
    }, {
      "title" : "Revisiting joint modeling of cross-document entity and event coreference resolution",
      "author" : [ "Shany Barhom", "Vered Shwartz", "Alon Eirew", "Michael Bugert", "Nils Reimers", "Ido Dagan." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computa-",
      "citeRegEx" : "Barhom et al\\.,? 2019",
      "shortCiteRegEx" : "Barhom et al\\.",
      "year" : 2019
    }, {
      "title" : "Crossdocument language modeling",
      "author" : [ "Avi Caciularu", "Arman Cohan", "Iz Beltagy", "Matthew E Peters", "Arie Cattan", "Ido Dagan." ],
      "venue" : "arXiv preprint arXiv:2101.00406.",
      "citeRegEx" : "Caciularu et al\\.,? 2021",
      "shortCiteRegEx" : "Caciularu et al\\.",
      "year" : 2021
    }, {
      "title" : "Autoregressive entity retrieval",
      "author" : [ "Nicola De Cao", "Gautier Izacard", "Sebastian Riedel", "Fabio Petroni" ],
      "venue" : null,
      "citeRegEx" : "Cao et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2021
    }, {
      "title" : "Streamlining crossdocument coreference resolution: Evaluation and modeling",
      "author" : [ "Arie Cattan", "Alon Eirew", "Gabriel Stanovsky", "Mandar Joshi", "Ido Dagan." ],
      "venue" : "arXiv preprint arXiv:2009.11032.",
      "citeRegEx" : "Cattan et al\\.,? 2020",
      "shortCiteRegEx" : "Cattan et al\\.",
      "year" : 2020
    }, {
      "title" : "Relational inference for wikification",
      "author" : [ "Xiao Cheng", "Dan Roth." ],
      "venue" : "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1787–1796, Seattle, Washington, USA. Association for Computational Linguistics.",
      "citeRegEx" : "Cheng and Roth.,? 2013",
      "shortCiteRegEx" : "Cheng and Roth.",
      "year" : 2013
    }, {
      "title" : "Large-scale named entity disambiguation based on Wikipedia data",
      "author" : [ "Silviu Cucerzan." ],
      "venue" : "Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages",
      "citeRegEx" : "Cucerzan.,? 2007",
      "shortCiteRegEx" : "Cucerzan.",
      "year" : 2007
    }, {
      "title" : "Multi-step entity-centric information retrieval for multi-hop question answering",
      "author" : [ "Rajarshi Das", "Ameya Godbole", "Dilip Kavarthapu", "Zhiyu Gong", "Abhishek Singhal", "Mo Yu", "Xiaoxiao Guo", "Tian Gao", "Hamed Zamani", "Manzil Zaheer" ],
      "venue" : null,
      "citeRegEx" : "Das et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Das et al\\.",
      "year" : 2019
    }, {
      "title" : "C3EL: A joint model for cross-document co-reference resolution and entity linking",
      "author" : [ "Sourav Dutta", "Gerhard Weikum." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 846–856, Lisbon, Portugal.",
      "citeRegEx" : "Dutta and Weikum.,? 2015",
      "shortCiteRegEx" : "Dutta and Weikum.",
      "year" : 2015
    }, {
      "title" : "Moleman: Mention-only linking of entities with a mention annotation network",
      "author" : [ "Nicholas FitzGerald", "Jan A Botha", "Daniel Gillick", "Daniel M Bikel", "Tom Kwiatkowski", "Andrew McCallum." ],
      "venue" : "arXiv preprint arXiv:2106.07352.",
      "citeRegEx" : "FitzGerald et al\\.,? 2021",
      "shortCiteRegEx" : "FitzGerald et al\\.",
      "year" : 2021
    }, {
      "title" : "Facc1: Freebase annotation of clueweb corpora, version 1 (release date 2013-06-26, format version 1, correction level",
      "author" : [ "Evgeniy Gabrilovich", "Michael Ringgaard", "Amarnag Subramanya" ],
      "venue" : null,
      "citeRegEx" : "Gabrilovich et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Gabrilovich et al\\.",
      "year" : 2013
    }, {
      "title" : "Deep joint entity disambiguation with local neural attention",
      "author" : [ "Octavian-Eugen Ganea", "Thomas Hofmann." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2619–2629, Copenhagen, Denmark. Associa-",
      "citeRegEx" : "Ganea and Hofmann.,? 2017",
      "shortCiteRegEx" : "Ganea and Hofmann.",
      "year" : 2017
    }, {
      "title" : "Learning dense representations for entity retrieval",
      "author" : [ "Dan Gillick", "Sayali Kulkarni", "Larry Lansing", "Alessandro Presta", "Jason Baldridge", "Eugene Ie", "Diego Garcia-Olano." ],
      "venue" : "Proceedings of the 23rd Conference on Computational Natural Language Learn-",
      "citeRegEx" : "Gillick et al\\.,? 2019",
      "shortCiteRegEx" : "Gillick et al\\.",
      "year" : 2019
    }, {
      "title" : "Crossdocument coreference on a large scale corpus",
      "author" : [ "Chung Heong Gooi", "James Allan." ],
      "venue" : "Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: HLT-NAACL",
      "citeRegEx" : "Gooi and Allan.,? 2004",
      "shortCiteRegEx" : "Gooi and Allan.",
      "year" : 2004
    }, {
      "title" : "Entity linking via joint encoding of types, descriptions, and context",
      "author" : [ "Nitish Gupta", "Sameer Singh", "Dan Roth." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2681–2690, Copenhagen, Denmark. Asso-",
      "citeRegEx" : "Gupta et al\\.,? 2017",
      "shortCiteRegEx" : "Gupta et al\\.",
      "year" : 2017
    }, {
      "title" : "Distilling the knowledge in a neural network",
      "author" : [ "Geoffrey Hinton", "Oriol Vinyals", "Jeff Dean." ],
      "venue" : "arXiv preprint arXiv:1503.02531.",
      "citeRegEx" : "Hinton et al\\.,? 2015",
      "shortCiteRegEx" : "Hinton et al\\.",
      "year" : 2015
    }, {
      "title" : "Robust disambiguation of named entities in text",
      "author" : [ "Johannes Hoffart", "Mohamed Amir Yosef", "Ilaria Bordino", "Hagen Fürstenau", "Manfred Pinkal", "Marc Spaniol", "Bilyana Taneva", "Stefan Thater", "Gerhard Weikum." ],
      "venue" : "Proceedings of the 2011 Conference on Em-",
      "citeRegEx" : "Hoffart et al\\.,? 2011",
      "shortCiteRegEx" : "Hoffart et al\\.",
      "year" : 2011
    }, {
      "title" : "Poly-encoders: Architectures and pre-training strategies for fast and accurate multi-sentence scoring",
      "author" : [ "Samuel Humeau", "Kurt Shuster", "Marie-Anne Lachaux", "Jason Weston." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Humeau et al\\.,? 2019",
      "shortCiteRegEx" : "Humeau et al\\.",
      "year" : 2019
    }, {
      "title" : "Poly-encoders: Architectures and pre-training strategies for fast and accurate multi-sentence scoring",
      "author" : [ "Samuel Humeau", "Kurt Shuster", "Marie-Anne Lachaux", "Jason Weston." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Humeau et al\\.,? 2020",
      "shortCiteRegEx" : "Humeau et al\\.",
      "year" : 2020
    }, {
      "title" : "Distilling knowledge from reader to retriever for question answering",
      "author" : [ "Gautier Izacard", "Edouard Grave." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Izacard and Grave.,? 2021",
      "shortCiteRegEx" : "Izacard and Grave.",
      "year" : 2021
    }, {
      "title" : "Billion-scale similarity search with gpus",
      "author" : [ "Jeff Johnson", "Matthijs Douze", "Hervé Jégou." ],
      "venue" : "arXiv preprint arXiv:1702.08734.",
      "citeRegEx" : "Johnson et al\\.,? 2017",
      "shortCiteRegEx" : "Johnson et al\\.",
      "year" : 2017
    }, {
      "title" : "End-to-end neural entity linking",
      "author" : [ "Nikolaos Kolitsas", "Octavian-Eugen Ganea", "Thomas Hofmann." ],
      "venue" : "Proceedings of the 22nd Conference on Computational Natural Language Learning, pages 519–529, Brussels, Belgium. Association for Computational",
      "citeRegEx" : "Kolitsas et al\\.,? 2018",
      "shortCiteRegEx" : "Kolitsas et al\\.",
      "year" : 2018
    }, {
      "title" : "Plato: A selective context model for entity resolution",
      "author" : [ "Nevena Lazic", "Amarnag Subramanya", "Michael Ringgaard", "Fernando Pereira." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 3:503–515.",
      "citeRegEx" : "Lazic et al\\.,? 2015a",
      "shortCiteRegEx" : "Lazic et al\\.",
      "year" : 2015
    }, {
      "title" : "Plato: A selective context model for entity resolution",
      "author" : [ "Nevena Lazic", "Amarnag Subramanya", "Michael Ringgaard", "Fernando Pereira." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 3:503–515.",
      "citeRegEx" : "Lazic et al\\.,? 2015b",
      "shortCiteRegEx" : "Lazic et al\\.",
      "year" : 2015
    }, {
      "title" : "Improving entity linking by modeling latent relations between mentions",
      "author" : [ "Phong Le", "Ivan Titov." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the",
      "citeRegEx" : "Le and Titov.,? 2018",
      "shortCiteRegEx" : "Le and Titov.",
      "year" : 2018
    }, {
      "title" : "Taggerone: joint named entity recognition and normalization with semi-markov models",
      "author" : [ "Robert Leaman", "Zhiyong Lu." ],
      "venue" : "Bioinformatics, 32(18):2839– 2846.",
      "citeRegEx" : "Leaman and Lu.,? 2016",
      "shortCiteRegEx" : "Leaman and Lu.",
      "year" : 2016
    }, {
      "title" : "List-only entity linking",
      "author" : [ "Ying Lin", "Chin-Yew Lin", "Heng Ji." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 536–541, Vancouver, Canada. Association for Computational",
      "citeRegEx" : "Lin et al\\.,? 2017",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2017
    }, {
      "title" : "Design challenges for entity linking",
      "author" : [ "Xiao Ling", "Sameer Singh", "Daniel S. Weld." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 3:315– 328.",
      "citeRegEx" : "Ling et al\\.,? 2015",
      "shortCiteRegEx" : "Ling et al\\.",
      "year" : 2015
    }, {
      "title" : "Self-alignment pretraining for biomedical entity representations",
      "author" : [ "Fangyu Liu", "Ehsan Shareghi", "Zaiqiao Meng", "Marco Basaldella", "Nigel Collier." ],
      "venue" : "arXiv preprint arXiv:2010.11784.",
      "citeRegEx" : "Liu et al\\.,? 2020",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "On importance sampling-based evaluation of latent language models",
      "author" : [ "Robert L. Logan IV", "Matt Gardner", "Sameer Singh." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 2171–2176, Online. Association",
      "citeRegEx" : "IV et al\\.,? 2020",
      "shortCiteRegEx" : "IV et al\\.",
      "year" : 2020
    }, {
      "title" : "Zero-shot entity linking by reading entity descriptions",
      "author" : [ "Lajanugen Logeswaran", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova", "Jacob Devlin", "Honglak Lee." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Logeswaran et al\\.,? 2019",
      "shortCiteRegEx" : "Logeswaran et al\\.",
      "year" : 2019
    }, {
      "title" : "Learning to link with wikipedia",
      "author" : [ "David Milne", "Ian H Witten." ],
      "venue" : "Proceedings of the 17th ACM conference on Information and knowledge management, pages 509–518.",
      "citeRegEx" : "Milne and Witten.,? 2008",
      "shortCiteRegEx" : "Milne and Witten.",
      "year" : 2008
    }, {
      "title" : "Medmentions: A large biomedical corpus annotated with umls concepts",
      "author" : [ "Sunil Mohan", "Donghui Li." ],
      "venue" : "arXiv preprint arXiv:1902.09476.",
      "citeRegEx" : "Mohan and Li.,? 2019",
      "shortCiteRegEx" : "Mohan and Li.",
      "year" : 2019
    }, {
      "title" : "Learning continuous hierarchies in the lorentz model of hyperbolic geometry",
      "author" : [ "Maximillian Nickel", "Douwe Kiela." ],
      "venue" : "International Conference on Machine Learning, pages 3779–3788. PMLR.",
      "citeRegEx" : "Nickel and Kiela.,? 2018",
      "shortCiteRegEx" : "Nickel and Kiela.",
      "year" : 2018
    }, {
      "title" : "Sprank: Semantic path-based ranking for top-n recommendations using linked open data",
      "author" : [ "Tommaso Di Noia", "Vito Claudio Ostuni", "Paolo Tomeo", "Eugenio Di Sciascio." ],
      "venue" : "ACM Transactions on Intelligent Systems and Technology (TIST), 8(1):1–34.",
      "citeRegEx" : "Noia et al\\.,? 2016",
      "shortCiteRegEx" : "Noia et al\\.",
      "year" : 2016
    }, {
      "title" : "Pytorch: An imperative style, high-performance deep learning library",
      "author" : [ "jani", "Sasank Chilamkurthy", "Benoit Steiner", "Lu Fang", "Junjie Bai", "Soumith Chintala" ],
      "venue" : "In Advances in Neural Information Processing Systems",
      "citeRegEx" : "jani et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "jani et al\\.",
      "year" : 2019
    }, {
      "title" : "Deeptype: multilingual entity linking by neural type system evolution",
      "author" : [ "Jonathan Raiman", "Olivier Raiman." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 32.",
      "citeRegEx" : "Raiman and Raiman.,? 2018",
      "shortCiteRegEx" : "Raiman and Raiman.",
      "year" : 2018
    }, {
      "title" : "Cd2cr: Co-reference resolution across documents and domains",
      "author" : [ "James Ravenscroft", "Arie Cattan", "Amanda Clare", "Ido Dagan", "Maria Liakata." ],
      "venue" : "arXiv preprint arXiv:2101.12637.",
      "citeRegEx" : "Ravenscroft et al\\.,? 2021",
      "shortCiteRegEx" : "Ravenscroft et al\\.",
      "year" : 2021
    }, {
      "title" : "Large-scale crossdocument coreference using distributed inference and hierarchical models",
      "author" : [ "Sameer Singh", "Amarnag Subramanya", "Fernando Pereira", "Andrew McCallum." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Singh et al\\.,? 2011",
      "shortCiteRegEx" : "Singh et al\\.",
      "year" : 2011
    }, {
      "title" : "Biomedical entity representations with synonym marginalization",
      "author" : [ "Mujeen Sung", "Hwisang Jeon", "Jinhyuk Lee", "Jaewoo Kang." ],
      "venue" : "arXiv preprint arXiv:2005.00239.",
      "citeRegEx" : "Sung et al\\.,? 2020",
      "shortCiteRegEx" : "Sung et al\\.",
      "year" : 2020
    }, {
      "title" : "Zero-shot entity linking with dense entity retrieval",
      "author" : [ "Ledell Wu", "Fabio Petroni", "Martin Josifoski", "Sebastian Riedel", "Luke Zettlemoyer." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Wu et al\\.,? 2020",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Supervised hierarchical clustering with exponential linkage",
      "author" : [ "Nishant Yadav", "Ari Kobren", "Nicholas Monath", "Andrew Mccallum." ],
      "venue" : "Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning",
      "citeRegEx" : "Yadav et al\\.,? 2019",
      "shortCiteRegEx" : "Yadav et al\\.",
      "year" : 2019
    }, {
      "title" : "Knowledge-rich self-supervised entity linking",
      "author" : [ "Sheng Zhang", "Hao Cheng", "Shikhar Vashishth", "Cliff Wong", "Jinfeng Xiao", "Xiaodong Liu", "Tristan Naumann", "Jianfeng Gao", "Hoifung Poon." ],
      "venue" : "arXiv preprint arXiv:2112.07887.",
      "citeRegEx" : "Zhang et al\\.,? 2021",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2021
    }, {
      "title" : "Understanding hard negatives in noise contrastive estimation",
      "author" : [ "Wenzheng Zhang", "Karl Stratos." ],
      "venue" : "arXiv preprint arXiv:2104.06245.",
      "citeRegEx" : "Zhang and Stratos.,? 2021",
      "shortCiteRegEx" : "Zhang and Stratos.",
      "year" : 2021
    } ],
    "referenceMentions" : [ {
      "referenceID" : 26,
      "context" : "Natural language corpora, such as biomedical research papers (Leaman and Lu, 2016), news articles",
      "startOffset" : 61,
      "endOffset" : 82
    }, {
      "referenceID" : 32,
      "context" : "(Milne and Witten, 2008; Hoffart et al., 2011), and, more generally, web page text (Gabrilovich et al.",
      "startOffset" : 0,
      "endOffset" : 46
    }, {
      "referenceID" : 17,
      "context" : "(Milne and Witten, 2008; Hoffart et al., 2011), and, more generally, web page text (Gabrilovich et al.",
      "startOffset" : 0,
      "endOffset" : 46
    }, {
      "referenceID" : 11,
      "context" : ", 2011), and, more generally, web page text (Gabrilovich et al., 2013; Lazic et al., 2015a), often contain ambiguous mentions of entities.",
      "startOffset" : 44,
      "endOffset" : 91
    }, {
      "referenceID" : 23,
      "context" : ", 2011), and, more generally, web page text (Gabrilovich et al., 2013; Lazic et al., 2015a), often contain ambiguous mentions of entities.",
      "startOffset" : 44,
      "endOffset" : 91
    }, {
      "referenceID" : 8,
      "context" : "Grounded entity mentions can be beneficial for tasks such as question-answering (Das et al., 2019), semantic search (Leaman and Lu, 2016), recommendation ranking (Noia et al.",
      "startOffset" : 80,
      "endOffset" : 98
    }, {
      "referenceID" : 26,
      "context" : ", 2019), semantic search (Leaman and Lu, 2016), recommendation ranking (Noia et al.",
      "startOffset" : 25,
      "endOffset" : 46
    }, {
      "referenceID" : 35,
      "context" : ", 2019), semantic search (Leaman and Lu, 2016), recommendation ranking (Noia et al., 2016), and KB construction (Ling et al.",
      "startOffset" : 71,
      "endOffset" : 90
    }, {
      "referenceID" : 27,
      "context" : "The task is made particularly challenging in zero-shot settings, where not every entity has labeled training data (Lin et al., 2017; Logeswaran et al., 2019).",
      "startOffset" : 114,
      "endOffset" : 157
    }, {
      "referenceID" : 31,
      "context" : "The task is made particularly challenging in zero-shot settings, where not every entity has labeled training data (Lin et al., 2017; Logeswaran et al., 2019).",
      "startOffset" : 114,
      "endOffset" : 157
    }, {
      "referenceID" : 41,
      "context" : "These representations are used for (a) retrieving a short-list of entity candidates for a mention for use with a re-ranker (Wu et al., 2020), (b) making linking predictions directly (Zhang et al.",
      "startOffset" : 123,
      "endOffset" : 140
    }, {
      "referenceID" : 0,
      "context" : "We hypothesize that such coreference links provide a useful inductive bias because the two tasks are inherently related (Angell et al., 2021; FitzGerald et al., 2021).",
      "startOffset" : 120,
      "endOffset" : 166
    }, {
      "referenceID" : 10,
      "context" : "We hypothesize that such coreference links provide a useful inductive bias because the two tasks are inherently related (Angell et al., 2021; FitzGerald et al., 2021).",
      "startOffset" : 120,
      "endOffset" : 166
    }, {
      "referenceID" : 33,
      "context" : "of the aforementioned use cases on MedMentions (Mohan and Li, 2019) and ZeShEL (Logeswaran et al.",
      "startOffset" : 47,
      "endOffset" : 67
    }, {
      "referenceID" : 31,
      "context" : "of the aforementioned use cases on MedMentions (Mohan and Li, 2019) and ZeShEL (Logeswaran et al., 2019), two challenging datasets that require zero-shot generalization at inference.",
      "startOffset" : 79,
      "endOffset" : 104
    }, {
      "referenceID" : 31,
      "context" : "Following (Logeswaran et al., 2019; Angell et al., 2021), we assume that these mentions are pre-identified spans of text.",
      "startOffset" : 10,
      "endOffset" : 56
    }, {
      "referenceID" : 0,
      "context" : "Following (Logeswaran et al., 2019; Angell et al., 2021), we assume that these mentions are pre-identified spans of text.",
      "startOffset" : 10,
      "endOffset" : 56
    }, {
      "referenceID" : 13,
      "context" : "(Gillick et al., 2019; Humeau et al., 2019), one for mentions (EncM), and one for entities (EncE).",
      "startOffset" : 0,
      "endOffset" : 43
    }, {
      "referenceID" : 18,
      "context" : "(Gillick et al., 2019; Humeau et al., 2019), one for mentions (EncM), and one for entities (EncE).",
      "startOffset" : 0,
      "endOffset" : 43
    }, {
      "referenceID" : 41,
      "context" : "• Does our proposed approach improve the recall of candidate generators? • Do improvements in candidate generation at training lead to improvements in downstream re-ranker models? • Does our approach result in better learned mention embeddings that can be used for coreference / discovering entities when a KB does not exist? Experiment Details Our experiments are run on top of BLINK (Wu et al., 2020), a PyTorch (Paszke et al.",
      "startOffset" : 385,
      "endOffset" : 402
    }, {
      "referenceID" : 33,
      "context" : "MedMentions (Mohan and Li, 2019) is a collection of titles and abstractions of bio-medical research papers.",
      "startOffset" : 12,
      "endOffset" : 32
    }, {
      "referenceID" : 0,
      "context" : "12 MST & K-NN (Angell et al., 2021) TF-IDF (Angell et al.",
      "startOffset" : 14,
      "endOffset" : 35
    }, {
      "referenceID" : 41,
      "context" : "72 Dual (IN-BATCH NEGATIVES) (Wu et al., 2020) - 61.",
      "startOffset" : 29,
      "endOffset" : 46
    }, {
      "referenceID" : 41,
      "context" : "19 point difference in macro-averaged accuracy over the next best model (Wu et al., 2020).",
      "startOffset" : 72,
      "endOffset" : 89
    }, {
      "referenceID" : 19,
      "context" : "We could also consider models such as poly-encoders as an alternative to dual-encoders (Humeau et al., 2020).",
      "startOffset" : 87,
      "endOffset" : 108
    } ],
    "year" : 0,
    "abstractText" : "Learning representations of entity mentions is a core component of modern entity linking systems for both candidate generation and making linking predictions. In this paper, we present and empirically analyze a novel training approach for learning mention and entity representations that is based on building minimum spanning arborescences (i.e., directed spanning trees) over mentions and entities across documents to explicitly model mention coreference relationships. We demonstrate the efficacy of our approach by showing significant improvements in both candidate generation recall and linking accuracy on the Zero-Shot Entity Linking dataset and MedMentions, the largest publicly available biomedical dataset. In addition, we show that our improvements in candidate generation yield higher quality re-ranking models downstream, setting a new SOTA result in linking accuracy on MedMentions. We further demonstrate that our improved mention representations are effective for the discovery of new entities via cross-document coreference.",
    "creator" : null
  }
}