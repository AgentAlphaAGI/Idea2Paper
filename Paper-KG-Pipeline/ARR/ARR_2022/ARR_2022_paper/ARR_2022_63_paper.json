{
  "name" : "ARR_2022_63_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Multi-Task Pre-Training for Plug-and-Play Task-Oriented Dialogue System",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Task-oriented dialogue is often decomposed into three sub-tasks: (1) dialogue state tracking (DST) for tracking user’s belief state; (2) dialogue policy learning (POL) for deciding which system action to take; (3) natural language generation (NLG) for generating dialogue response (Young et al., 2013).\nTraditional approaches (Smith and Hipp, 1995; Young et al., 2013) adopt a modularized pipeline that addresses different sub-tasks with distinct dedicated modules. In contrast, recent systems (Wen et al., 2017; Eric et al., 2017; Lei et al., 2018; Shu et al., 2019) integrate all functionalities required to hold a dialogue into neural network models. With the advances in pre-trained language models (PLMs) (Radford et al., 2019; Devlin et al., 1All code and models will be released upon publication.\n2019; Raffel et al., 2020), different systems based on PLMs have been proposed (Hosseini-Asl et al., 2020; Lin et al., 2020; Peng et al., 2021; Liu et al., 2021). Despite their differences, most existing methods formulate task-oriented dialogue as a cascaded generation problem, that is, the model can only solve latter sub-tasks by conditioning on the outputs of previous ones. For instance, to generate the response (NLG), the model must rely on the outputs of previous sub-tasks (i.e., DST and POL).\nWhile impressive results are reported (HosseiniAsl et al., 2020; Peng et al., 2021), we identify three major limitations in the cascaded formulation of their system design. (1) Firstly, as the model solves all sub-tasks in a sequential order, the errors accumulated from previous steps are propagated to latter steps (Li et al., 2017; Liu and Lane, 2018). (2) Secondly, the training data must be annotated for all sub-tasks. Such annotation requirement significantly increases the data curation overhead. More importantly, it precludes the model from using the large amount of existing data that is partially annotated (e.g., data only annotated with DST or NLG). (3) Thirdly, the results of different sub-tasks must be generated in a cascaded order which inevitably increases the system inference latency.\nIn this study, we propose a novel Plug-and-Play Task-Oriented Dialogue (PPTOD) system. Figure 1 depicts an illustration of our approach. As seen, we integrate different dialogue modules (e.g. DST, POL, and NLG) into a unified model. Motivated by the concept of in-context learning (Brown et al., 2020), to steer the model to solve different TOD sub-task, we plug a task-specific natural language instruction, termed as prompt, into the dialogue context as the model input. This way, the generations of different sub-tasks are decoupled, leading to a greater flexibility of the model that brings us at least two advantages: (1) As different sub-tasks are solved separately, the model can learn from data that is partially annotated for different sub-tasks\n(e.g., DST and NLG). (2) The outputs of different sub-tasks are generated in parallel which alleviates the problem of error accumulation and reduces the system inference latency.\nInspired by recent success of dialogue language model pre-training (Zhang et al., 2020c; Wu et al., 2020; Peng et al., 2021), we propose a dialogue multi-task pre-training strategy that equips our model with the primary TOD task completion skills. Specifically, initialized with T5 (Raffel et al., 2020), we pre-train our model on a heterogeneous set of dialog corpora that consist of partially-annotated data. To build the pre-training corpora, we collect and combine eleven human-written multi-turn dialogue corpora. The collected datasets are partially annotated for some of the TOD-related tasks, including natural language understanding (NLU), dialogue state tracking (DST), dialogue policy learning (POL), and natural language generation (NLG). In total, the pre-training corpora contain over 2.3M utterances across over 80 domains (see more details in Table 1). When applying the pre-trained PPTOD to a new task, we fine-tune it using the same learning objective as in the pre-training stage.\nWe evaluate PPTOD on a wide range of benchmark TOD tasks, including end-to-end dialogue modelling, dialogue state tracking, and intent classification. Comparisons against previous state-of-theart approaches show that PPTOD achieves better performance in both full-training and low-resource settings as judged by automatic and human evaluations. In summary, our contributions are:\n• A novel model, PPTOD, that effectively leverages pre-trained language models for task-\noriented dialogue tasks.\n• A new dialogue multi-task pre-training strategy that augments the model’s ability with heterogeneous dialogue corpora.\n• Extensive evaluations on three benchmark TOD tasks reporting state-of-the-art results in both full-training and low-resource settings.\n• In-depth analysis that further reveals the merits of our model design and the proposed multi-task pre-training strategy."
    }, {
      "heading" : "2 Related Work",
      "text" : "Task-Oriented Dialogue. Task-oriented dialogue aims at accomplishing user’s goal. Traditional systems (Williams and Young, 2007; Young et al., 2013) adopt a pipelined approach that requires dialogue state tracking for understanding user’s goal, dialogue policy learning for deciding which system action to take, and natural language generation for generating dialogue responses.\nRecently, to simplify the modelling effort, researchers have shifted their attention to building neural network models that address the TOD subtasks (Wen et al., 2017; Eric et al., 2017; Lei et al., 2018; Liang et al., 2020). With the advances in pretrained language models (PLMs), Budzianowski and Vulić (2019) first applied the GPT-2 model for the NLG task. Lin et al. (2020) and Yang et al. (2021) moved one step forward and utilized pretrained language models to solve all TOD sub-tasks conditioned on the history of oracle belief states. Based on the GPT-2 model, Hosseini-Asl et al.\n(2020) proposed a cascaded model, SimpleTOD, that addresses all TOD sub-tasks without using the oracle information. To improve the system performance, Peng et al. (2021) and Liu et al. (2021) applied dialogue pre-training over external dialogue corpora. However, both methods require the pretraining data to be fully annotated for all TOD sub-tasks (i.e., DST, POL, and NLG) which greatly limits the amount of data they can use. Additionally, Liu et al. (2021) achieved better results with noisy chanel model that requires two additional language models for outputs re-scoring. Unlike their approach, we address the task of task-oriented dialogue with a single unified model.\nLanguage Model Pre-training. The research community has witnessed remarkable progress of pre-training methods in a wide range of NLP tasks, including language understanding (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019; Yang et al., 2019) and text generation (Radford et al., 2019; Lewis et al., 2020; Raffel et al., 2020).\nIn the dialogue domain, many models are pretrained on open-domain conversational data like Reddit. Based on GPT-2, Transfertransfo (Wolf et al., 2019b) achieves good results on ConvAI-2 competition. As another extension of GPT-2, DialoGPT (Zhang et al., 2020c) performs well in generating open-domain dialogue response. ConveRT (Henderson et al., 2020) is a language model with dual-encoder built for the task of response selection. PLATO (Bao et al., 2020) pre-trains a model with discrete latent variable structure for the response generation task. Wu et al. (2020) adapts BERT with TOD pre-training and achieves strong performances on four dialogue understanding tasks.\nPre-training on Supplementary Data. Recent work (Phang et al., 2018; Aghajanyan et al., 2021) found that supplementary training on the tasks with intermediate-labelled data improves the performance of the fine-tuned models on GLUE natural language understanding benchmark (Wang et al., 2018). Our work studies a similar supplementary training setup with intermediate-labelled data for task-oriented dialogue systems. Unlike previous work, we use a single multi-task model for all relevant sub-tasks in task-oriented dialogue systems."
    }, {
      "heading" : "3 Methodology",
      "text" : "In this section, we first discuss the datasets and learning objective used in the proposed dialogue\nmulti-task pre-training. Then we introduce how to apply the pre-trained PPTOD for a new task."
    }, {
      "heading" : "3.1 Pre-training Datasets",
      "text" : "To construct the pre-training corpus, we collect eleven human-written multi-turn task-oriented dialogue corpora, including MetaLWOZ (Lee et al., 2019b), SNIPS (Coucke et al., 2018), CLINC (Larson et al., 2019), ATIS (Amin, 2019), KVRET (Eric et al., 2017), WOZ (Mrkšić et al., 2017), MSRE2E (Li et al., 2018), Frames (El Asri et al., 2017), TaskMaster (Byrne et al., 2019), and SchemaGuided (Rastogi et al., 2020). In total, there are over 2.3M utterances across 80 domains. In Table 1, we provide the details of data annotations and utterance/domain statistics of all datasets.2"
    }, {
      "heading" : "3.2 Dialogue Multi-Task Pre-training",
      "text" : "Motivated by previous work (McCann et al., 2018; Keskar et al., 2019; Raffel et al., 2020) that unify multiple NLP tasks into a common format, we cast all TOD-related tasks that we consider into the same plug-and-play text generation problem. To specify the target task, we plug a task-specific prompt into the dialogue context as the model input. Figure 1 depicts an illustration of our approach.\nIn the multi-task pre-training stage, each training sample is represented as:\nd = (zt, x, y), (1)\nwhere t denotes the TOD task that the sample d belongs to, and t ∈ {NLU,DST,POL,NLG}. zt is 2More dataset descriptions are provided in Appendix A.\nAlgorithm 1: Dialogue Multi-Task Pre-Training\nInput :Dataset D = {(zt, x, y)i}|D|i=1; model trainer T that takes batches of training data as input to optimize the model parameters Θ; maximum number of epochs emax;\n1 for epoch e = 1, ..., emax do 2 Shuffle D by mixing data from different tasks; for B in D do 3 Invoke trainer T , using one batch of training\ndata B = {(zt, x, y)k}|B|k=1 as input to optimize the model using LΘ (Eq. (2)).\n4 end 5 end\nOutput :Trained Model Θ\nthe task-specific prompt of the form “translate dialogue to A:”, with A corresponding to “user intent”, “belief state”, “dialogue act”, and “system response” for the tasks of NLU, DST, POL, and NLG, respectively. x denotes the input dialogue context which is a concatenation of all previous utterances in the dialogue - both system’s and user’s. And y denotes the target output text.\nAs an example presented in Figure 1, to perform the user intent classification task (i.e., NLU), the model is fed with the sequence “translate dialogue to user intent: [user] Tell me the weather forecast for Lecanto, Georgia.” and is trained to generate the user intent label text “[get_weather]”.\nLearning. The model is trained with a maximum likelihood objective. Given the training sample d = (zt, x, y), the objective LΘ is defined as\nLΘ = − |y|∑ i=1 logPΘ(yi|y<i; zt, x), (2)\nwhere Θ is the model parameters. In the multi-task pre-training stage, the model is trained to perform all TOD-related tasks with data annotated for different tasks. To optimize the model parameters Θ, we use mini-batch based optimization approach as shown in Algorithm 1."
    }, {
      "heading" : "3.3 Fine-Tuning to a New Task",
      "text" : "When applying the pre-trained PPTOD to a new downstream task with task-specific labelled data, we use the same learning objective Eq. (2) as in the dialogue multi-task pre-training stage."
    }, {
      "heading" : "3.4 Implementation Details",
      "text" : "In this work, we report results of PPTOD with three model sizes: PPTODsmall, PPTODbase, and PPTODlarge. These three models are initialized\nwith T5-small, T5-base, and T5-large models (Raffel et al., 2020) that contain ∼60M, ∼220M, and ∼770M parameters, respectively. We pre-train the model with different configurations on our collected pre-training corpora for 10 epochs. The training samples are truncated to ensure a maximal length of 1024. The models are trained using Adam optimizer (Kingma and Ba, 2015) with a learning rate of 5e-5 and a batch size of 128. Our implementation is based on the Huggingface Library (Wolf et al., 2019a)."
    }, {
      "heading" : "4 Experiments",
      "text" : "We test PPTOD on three benchmark TOD tasks: (1) end-to-end dialogue modelling; (2) dialogue state tracking; and (3) user intent classification."
    }, {
      "heading" : "4.1 End-to-End Dialogue Modelling",
      "text" : "End-to-end dialogue modelling aims at evaluating the model in the most realistic, fully end-to-end setting, where the generated dialogue states are used for the database search and response generation (Zhang et al., 2020b; Hosseini-Asl et al., 2020)."
    }, {
      "heading" : "4.1.1 Dataset and Evaluation Metric",
      "text" : "We conduct experiments on the benchmark MultiWOZ 2.0 (Budzianowski et al., 2018) and 2.1 (Eric et al., 2020) datasets.3 In MultiWOZ, the generation of response is not only related to the dialogue context, but also grounded on the database (DB) state. The DB state is automatically retrieved from a pre-defined database using the generated dialogue state (DST). Following previous studies, during inference, PPTOD first predicts the DST result to retrieve the DB state. Then, based on the retrieved DB state and the dialogue context, the results of POL and NLG are generated in parallel. In Section 5, we further compare the performance of our model with or without using the DB state as input.\nFor evaluation, we follow the original MultiWOZ guidance for all individual metrics: Inform, Success, and BLEU (Papineni et al., 2002). An overall measurement, i.e., combined score (Mehri et al., 2019), is also reported which is defined as Combined = (Inform + Success) × 0.5 + BLEU."
    }, {
      "heading" : "4.1.2 Baselines",
      "text" : "We compare PPTOD with several strong baselines, including Sequicity (Lei et al., 2018), MDSequicity (Zhang et al., 2020b), DAMD (Zhang 3Note that, there is no overlap between the MultiWOZ dataset and our dialogue pre-training corpora.\net al., 2020b), MinTL (Lin et al., 2020), HIERJoint (Santra et al., 2021), LABES-S2S (Zhang et al., 2020a), SimpleTOD (Hosseini-Asl et al., 2020), UBAR (Yang et al., 2021), and SOLOIST (Peng et al., 2021), TOP and TOP+Noisy Online Decoding (TOP+NOD) (Liu et al., 2021)."
    }, {
      "heading" : "4.1.3 Full Training Evaluation",
      "text" : "Table 2 shows the main results. On both MultiWOZ 2.0 and 2.1 datasets, PPTOD performs better than previous SOTA methods on seven out of eight metrics. In particular, it is worth mentioning that our model is a single architecture that does not require additional language models for re-ranking the outputs as in TOP+NOD (Liu et al., 2021)."
    }, {
      "heading" : "4.1.4 Low-Resource Evaluation",
      "text" : "To investigate the generalization ability of PPTOD, we evaluate it in a more challenging low-resource scenario. Following previous studies, we train our model on MultiWOZ 2.0 by varying the percentage of training data, ranging from 1% (∼80 samples) to 20% (∼1600 samples). We compare our model with several strong baselines, including MD-\nSequicity, DAMD, SOLOIST, and MinTL.4\nIn each low-resource setting, we train our model five times with different random seeds and different selection of training data. The average scores over five runs are presented in Table 3.5 As seen, PPTOD consistently outperforms all baseline models by a large margin. Notably, our performance gain is even larger when fewer samples are used for training. This indicates that PPTOD better leverages the prior knowledge from pre-training therefore achieving better results in the extreme low-resource settings. Furthermore, with 20% of training data, PPTOD can achieve results that are comparable to the scores of systems like SOLOIST that are trained with full dataset as reported in Table 2."
    }, {
      "heading" : "4.2 Dialogue State Tracking",
      "text" : "Next, we evaluate PPTOD for the dialogue state tracking task. The experiments are conducted on the benchmark MultiWOZ 2.0 (Budzianowski et al., 2018) and 2.1 (Eric et al., 2020) datasets. For evaluation, the joint goal accuracy is reported.\n4We did not compare results with TOP+NOD (Liu et al., 2021) since the authors did not release their code and models. 5Detailed numerical results can be found in Appendix B."
    }, {
      "heading" : "4.2.1 Full Training Evaluation",
      "text" : "We compare PPTOD with a wide range of existing methods that can be categorized into two classes: (1) classification-based approaches and (2) generation-based approaches. Table 4 shows the DST results. Compared to other generationbased approaches, PPTODlarge obtains the highest accuracy on both datasets. The performance of our model is lower than the SOTA classificationbased approaches. However, these methods operate on a fixed ontology and perform prediction over a pre-defined set of slot-value pairs (Zhang et al., 2019; Chen et al., 2020; Shan et al., 2020; Zhou et al., 2021). This idea of fixed ontology is not scalable, as in real world applications, the ontology is subject to constant change (Heck et al., 2020). In contrast, PPTOD directly generates the outputs, making it more adaptive and generalizable to new ontology labels in real world applications."
    }, {
      "heading" : "4.2.2 Low-Resource Evaluation",
      "text" : "To investigate how well PPTOD performs with limited training samples on the downstream task, we evaluate it in a simulated low-resource setting. Specifically, we train the model on MultiWOZ 2.0\nby varying the percentage of training data (i.e., 1%, 5%, 10%, and 20%). We compare PPTOD with three strong generation-based baselines, including SimpleTOD, MinTL, and SOLOIST, using the official code released by the authors.\nTable 5 shows the experimental results. As seen, in all settings, PPTOD outperforms other baselines by a large margin. In the extreme scenario, with only 1% of training data, PPTOD surpasses the strongest SOLOIST model by 18 points of accuracy. This demonstrates that our model is more generalizable and can be better applied to new tasks where the amount of training data is limited."
    }, {
      "heading" : "4.3 Intent Classification",
      "text" : "The goal of intent classification, i.e., NLU, is to classify the user’s intent based on the user’s utterance. We conduct experiments on the benchmark Banking77 dataset (Casanueva et al., 2020) that contains data with 77 different intents. Following previous studies (Casanueva et al., 2020; Peng et al., 2021), we test our model in both full training and low-resource settings. In the low-resource setting, we vary the number of training samples per intent from 10 to 30. The standard classification accuracy is reported for evaluation.\nWe compare PPTOD with several strong baselines, including BERT-Fixed, BERT-Tuned, USE+ConveRT (Casanueva et al., 2020), USE (Yang et al., 2020), ConveRT (Henderson et al., 2020), and SOLOIST (Peng et al., 2021). It is worth mentioning that all compared baselines are classification-based approach that uses classifier with a softmax layer to make the prediction over the pre-defined intent set. In contrast, as described in section §3.2, PPTOD solves the classification task as a generation problem by directly generating the text of intent label. Therefore, when adapting to a new classification task, PPTOD is more flexible and no extra model parameters are required.\nIn the experiments, we train PPTOD for five runs with different selection of training data and random\nseeds. The average scores and standard deviations are reported in Table 7. We see that PPTOD is comparable with existing methods. On low-resource-30 and full training settings, PPTODlarge achieves the best results. Our performance gains are even more remarkable given that PPTOD requires no extra parameters when solving the classification task."
    }, {
      "heading" : "5 Further Analysis",
      "text" : "In this section, we present further discussions and empirical analyses of the proposed model."
    }, {
      "heading" : "5.1 Plug-and-Play vs Cascaded Generation",
      "text" : "First, we compare our plug-and-play generation with the cascaded generation that is adopted by most existing studies. To this end, we fine-tune a T5-small model (without dialogue multi-task pretraining) on MultiWOZ 2.0 by either using the plugand-play or the cascaded formulation. Moreover, we also examine the effect of DB state on the model performance. Specifically, for the plug-and-play model, when utilizing DB state, it first predicts the dialogue state (DST) to retrieve the DB state from the pre-defined database. Then, based on the DB state and dialogue context, the output of POL and NLG are generated in parallel. When ignoring the DB state, the plug-and-play model generates DST, POL, and NLG results in a fully paralleled fashion.\nFor evaluation, we report the results on end-toend dialogue modelling task. In addition, we report the average inference latency and relative speedup of each model.6 We compare our ablated models with two strong baselines, SOLOIST and MinTL.7\nTable 6 presents the results. As seen, the plugand-play models yield better results than their cascaded counterparts. One reason is that, for cascaded models, the previously generated results are explicitly used as model input for latter sub-tasks, which leads to error accumulation. Moreover, we see that using DB state generally improves the model performance for both plug-and-play and cascaded models as it provides the model with more grounding information. Furthermore, with DB state, our plug-and-play model achieves better overall score than MinTL with an around 4× speedup. This suggests that the plug-and-play formulation benefits the model both in terms of the generation accuracy as well as the inference latency."
    }, {
      "heading" : "5.2 Multi-Task Pre-Training Investigation",
      "text" : "Next, we provide further analyses on the dialogue multi-task pre-training strategy. To quantify the importance of different pre-training data, we pre-train the T5-small model using data that is annotated for individual TOD-related task (i.e., NLU, DST, POL, and NLG). After pre-training, we then evaluate the models on three downstream TOD tasks using MultiWOZ 2.0 and Banking77 datasets. For end-to-end dialogue modelling and dialogue state tracking, we test the model in both 1% and full training settings. For intent classification, we measure the accuracy of models trained with either 10 training samples per intent or full training samples.\nTable 8 presents the results with the first row showing the performance of vanilla T5-small model. As seen, without any pre-training, the\n6The latency of each model is measured on a single Nvidia V100 GPU with a batch size of 1. 7We did not include TOP+NOD (Liu et al., 2021) for comparison as the authors did not release their code.\nvanilla T5-small model performs poorly in the lowresource setting of all evaluated tasks. This suggests that the prior knowledge from pre-training is indispensable for the model to achieve strong performances in the low-resource scenarios.\nMoreover, we see that pre-training with data annotated for individual TOD-related task helps the model to attain better result in the corresponding downstream task. For example, pre-training with DST data notably improves the model performance in the downstream DST task both in low-resource and full-training settings. Similarly, pre-training with NLG data helps the model to get better BLEU score in the end-to-end dialogue modelling task.\nLastly, we see that the PPTODsmall model attains the best results on most of the evaluation metrics. This suggests that the pre-training data with different annotations are compatible with each other and the joint utilization of all pre-training data helps the model to achieve the best overall performance."
    }, {
      "heading" : "5.3 Human Evaluation",
      "text" : "We also conduct a human evaluation with the help of graders proficient in English using an internal evaluation platform. For evaluation, we randomly selected 50 dialogue sessions from the test set of MultiWOZ 2.0 dataset. We compare the results generated by the PPTODbase model against the results from the SOLOIST model. All generated results, plus the reference, are evaluated by five graders on a 3-point Likert scale (0, 1, or 2) for each of the following features8:\n• Understanding: Whether the system correctly understands the user’s goal. • Truthfulness: Whether the system’s response is factually supported by the reference.9 • Coherency: Whether the system’s response is semantically coherent with the context.\n8More evaluation details are provided in the Appendix C. 9For this metric, we only evaluate the results of PPTOD and SOLOIST. By definition, the reference gets a score of 2.0.\n• Fluency: Whether the system’s response is grammatically fluent and easy to understand.\nTable 9 lists the results, with the first row showing strong inter-annotator agreements as measured by Fleiss′ kappa coefficient (Fleiss et al., 1971). Comparing with SOLOIST, our model achieves better scores on all metrics. Moreover, on the truthfulness and coherency metrics, our model significantly outperforms SOLOIST as judged by Sign Test (pvalue < 0.05), suggesting that PPTOD generates more factually correct and semantically coherent responses. Finally, we note that on the fluency metric, both systems perform comparably with the reference (p-value > 0.4). This shows that the fluency of such systems is largely guaranteed by the prior syntactic knowledge from pre-trained language models, which suggests that future research should focus more on the other aspects of dialog systems."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper, we propose PPTOD, a unified model that supports both task-oriented dialogue understanding and response generation in a plug-andplay manner. In addition, we introduce a new dialogue multi-task pre-training strategy to further augment our model’s ability in completing TODrelated tasks. Extensive experiments and analysis are conducted on three benchmark TOD tasks in both high-resource and low-resource settings. The automatic and human evaluations demonstrate that PPTOD outperforms the current SOTA systems in terms of various evaluation metrics."
    }, {
      "heading" : "A Dataset Details",
      "text" : "We elaborate the details of the dialogue datasets contained in the pre-training dialogue corpora.\n• MetaLWOZ (Lee et al., 2019b) is designed for improving models’ ability in generating natural language responses in unseen domains. It contains annotations for natural language generation (NLG) spanning over 47 domains.\n• SNIPS (Coucke et al., 2018) is designed to help developing models capable of understanding users’ intent (i.e., natural language understanding (NLU)). Its data consists of users’ utterances gathered by crowdsourcing with over 20 intent labels across 9 domains.\n• CLINC (Larson et al., 2019) is built for improving model’s ability in detecting out-ofscope users’ intents. It contains data with NLU annotations for 150 intents across 10 different domains.\n• ATIS (Amin, 2019) is used for building intent classification (NLU) model. It contains data with 22 user intents from the airline travel information domain.\n• KVRET (Eric et al., 2017) is a in-car personal assistant dataset with dialogues from three domains: calendar scheduling, weather information retrieval, and point-of-interest navigation. It contains annotations for user belief state (DST) and system response (NLG).\n• WOZ (Mrkšić et al., 2017) and CamRest676 (Wen et al., 2017) are collected with Wizardof-Oz procedure. They contains dialogues with DST and NLG annotations from the restaurant domain.\n• MSR-E2E (Li et al., 2018) contains dialogues from three domains, including movie-ticket booking, restaurant reservation, and taxi booking. The data are annotated for three TODrelated tasks: DST, POL, and NLG.\n• Frames (El Asri et al., 2017) contains dialogues from the trip booking domain. Its data are annotated for three TOD-related tasks, including DST, POL, and NLG.\n• TaskMaster (Byrne et al., 2019) includes dialogues from six domains. Its data is collected with Wizard-of-Oz and self-dialogue\napproaches. The dataset is annotated with DST, POL, and NLG.\n• Schema-Guided (Rastogi et al., 2020) is used for the DSTC8 (Kim et al., 2019) dialogue competition. It contains dialogues from 17 domains and it supports three TOD-related tasks, including DST, POL, and NLG."
    }, {
      "heading" : "B Low-Resource MultiWOZ Evaluation",
      "text" : "In Table 10, we show the results of our model on MultiWOZ 2.0 under different low-resource settings. To get more confident results, for each setting, we train our model for five runs with different selection of training data and different random seeds. The complete results along with the mean and standard deviations are presented in Table 10."
    }, {
      "heading" : "C Human Evaluation Guidelines",
      "text" : "Please evaluate the system’s response with respect to the following features: (1) Understanding; (2) Truthfulness; (3) Coherency; and (4) Fluency. In the following, we provide some guidelines regarding how to judge the quality of the system’s response in terms of different features.\nC.1 Understanding This metric measures whether the system’s response shows that the system is able to understand the goal and intent of the user. The definition of different scores are:\n• 2: The system completely understands the user’s goal and intent.\n• 1: The system partially understands the user’s goal and intent.\n• 0: The system does not understand the user’s goal and intent at all.\nC.2 Truthfulness This metric measures whether the system’s response is factually supported by the reference response. The definition of different scores are:\n• 2: The facts in the system’s response are all supported by or can be inferred from the reference response.\n• 1: The facts in the system’s response are partially supported by the reference response.\n• 0: The system’s response is contradicted to the facts contained in the reference response.\nC.3 Coherency This metric measures whether the system’s response is logically coherent with the dialogue context. The definition of different scores are:\n• 2: The system’s response is logically coherent with the dialogue context.\n• 1: The system’s response contains minor information that is off the topic of the dialogue context.\n• 0: The system’s response is completely irrelevant to the dialogue context.\nC.4 Fluency The metrics measures the fluency of the system’s response. The definition of different scores are:\n• 2: The system’s response is grammatically correct and easy to understand.\n• 1: The system’s response contains minor errors but they do not affect your understanding.\n• 0: The system’s response does not make sense and it is unreadable."
    }, {
      "heading" : "D Case Study",
      "text" : "Table 11 presents a generated dialogue example from the PPTODbase model. The user starts the conversation by asking for an expensive restaurant\nthat serves Indian food for dinner. PPTOD finds 14 restaurants that satisfy the user’s goal and asks the user for a preferred location. We can see that, when the user states no preference on the restaurant location, PPTPD correctly updates the dialogue state by adding the area information which is missed by the oracle information. Then the user switches the dialogue topic for booking a hotel. Through the dialogue trajectory, we see that PPTOD completes the dialogue by successfully providing the user the necessary information such as number of hotel choices (at turn 3) and the booking reference number (at turn 6). When finding the user’s booking request cannot be fulfilled (at turn 5), the models asks the user for an alternative option. Moreover, this example also demonstrates that PPTOD is able to deal with some NLU challenges displayed in the conversations. For example, at turn 4, the user already provides the information about the Gonville Hotel. But only after the user describes the intention of booking the hotel at turn 5, the model updates the name of hotel in the dialogue state based on the co-referenced information from the previous turn. Interestingly, the hotel name is ignored by the oracle dialogue state but our model correctly detects it. The dialogue understanding ability of PPTOD can also be observed in turn 6, in which it updates the hotel stay in the belief state from 2 days to 1 day after the user provides the corresponding information."
    } ],
    "references" : [ {
      "title" : "Muppet: Massive multi-task representations with pre-finetuning",
      "author" : [ "Armen Aghajanyan", "Anchit Gupta", "Akshat Shrivastava", "Xilun Chen", "Luke Zettlemoyer", "Sonal Gupta." ],
      "venue" : "CoRR, abs/2101.11038.",
      "citeRegEx" : "Aghajanyan et al\\.,? 2021",
      "shortCiteRegEx" : "Aghajanyan et al\\.",
      "year" : 2021
    }, {
      "title" : "Atis airline travel information",
      "author" : [ "Hassan Amin" ],
      "venue" : null,
      "citeRegEx" : "Amin.,? \\Q2019\\E",
      "shortCiteRegEx" : "Amin.",
      "year" : 2019
    }, {
      "title" : "PLATO: pre-trained dialogue generation model with discrete latent variable",
      "author" : [ "Siqi Bao", "Huang He", "Fan Wang", "Hua Wu", "Haifeng Wang." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online,",
      "citeRegEx" : "Bao et al\\.,? 2020",
      "shortCiteRegEx" : "Bao et al\\.",
      "year" : 2020
    }, {
      "title" : "Language models are few-shot learners",
      "author" : [ "Amodei." ],
      "venue" : "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.",
      "citeRegEx" : "Amodei.,? 2020",
      "shortCiteRegEx" : "Amodei.",
      "year" : 2020
    }, {
      "title" : "Hello, it’s GPT-2 - how can I help you? towards the use of pretrained language models for task-oriented dialogue systems",
      "author" : [ "Paweł Budzianowski", "Ivan Vulić." ],
      "venue" : "Proceedings of the 3rd Workshop on Neural Generation and Translation, pages 15–22,",
      "citeRegEx" : "Budzianowski and Vulić.,? 2019",
      "shortCiteRegEx" : "Budzianowski and Vulić.",
      "year" : 2019
    }, {
      "title" : "Multiwoz - A largescale multi-domain wizard-of-oz dataset for taskoriented dialogue modelling",
      "author" : [ "Pawel Budzianowski", "Tsung-Hsien Wen", "Bo-Hsiang Tseng", "Iñigo Casanueva", "Stefan Ultes", "Osman Ramadan", "Milica Gasic." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Budzianowski et al\\.,? 2018",
      "shortCiteRegEx" : "Budzianowski et al\\.",
      "year" : 2018
    }, {
      "title" : "Taskmaster-1: Toward a realistic and diverse dialog dataset",
      "author" : [ "Bill Byrne", "Karthik Krishnamoorthi", "Chinnadhurai Sankar", "Arvind Neelakantan", "Ben Goodrich", "Daniel Duckworth", "Semih Yavuz", "Amit Dubey", "Kyu-Young Kim", "Andy Cedilnik." ],
      "venue" : "In",
      "citeRegEx" : "Byrne et al\\.,? 2019",
      "shortCiteRegEx" : "Byrne et al\\.",
      "year" : 2019
    }, {
      "title" : "Schema-guided multi-domain dialogue state tracking with graph attention neural networks",
      "author" : [ "Lu Chen", "Boer Lv", "Chi Wang", "Su Zhu", "Bowen Tan", "Kai Yu." ],
      "venue" : "The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-",
      "citeRegEx" : "Chen et al\\.,? 2020",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2020
    }, {
      "title" : "Snips voice platform: an embedded",
      "author" : [ "Alice Coucke", "Alaa Saade", "Adrien Ball", "Théodore Bluche", "Alexandre Caulier", "David Leroy", "Clément Doumouro", "Thibault Gisselbrecht", "Francesco Caltagirone", "Thibaut Lavril", "Maël Primet", "Joseph Dureau" ],
      "venue" : null,
      "citeRegEx" : "Coucke et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Coucke et al\\.",
      "year" : 2018
    }, {
      "title" : "BERT: pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Frames: a corpus for adding memory to goal-oriented dialogue systems",
      "author" : [ "Layla El Asri", "Hannes Schulz", "Shikhar Sharma", "Jeremie Zumer", "Justin Harris", "Emery Fine", "Rahul Mehrotra", "Kaheer Suleman." ],
      "venue" : "Proceedings of the 18th Annual SIG-",
      "citeRegEx" : "Asri et al\\.,? 2017",
      "shortCiteRegEx" : "Asri et al\\.",
      "year" : 2017
    }, {
      "title" : "Multiwoz 2.1: A consolidated multidomain dialogue dataset with state corrections and",
      "author" : [ "Mihail Eric", "Rahul Goel", "Shachi Paul", "Abhishek Sethi", "Sanchit Agarwal", "Shuyang Gao", "Adarsh Kumar", "Anuj Kumar Goyal", "Peter Ku", "Dilek HakkaniTür" ],
      "venue" : null,
      "citeRegEx" : "Eric et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Eric et al\\.",
      "year" : 2020
    }, {
      "title" : "Key-value retrieval networks for task-oriented dialogue",
      "author" : [ "Mihail Eric", "Lakshmi Krishnan", "Francois Charette", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue, pages 37–49, Saarbrücken, Germany.",
      "citeRegEx" : "Eric et al\\.,? 2017",
      "shortCiteRegEx" : "Eric et al\\.",
      "year" : 2017
    }, {
      "title" : "A sequenceto-sequence approach to dialogue state tracking",
      "author" : [ "Yue Feng", "Yang Wang", "Hang Li." ],
      "venue" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 9",
      "citeRegEx" : "Feng et al\\.,? 2021",
      "shortCiteRegEx" : "Feng et al\\.",
      "year" : 2021
    }, {
      "title" : "Measuring nominal scale agreement among many raters",
      "author" : [ "J.L. Fleiss" ],
      "venue" : "Psychological Bulletin, 76(5):378–382.",
      "citeRegEx" : "Fleiss,? 1971",
      "shortCiteRegEx" : "Fleiss",
      "year" : 1971
    }, {
      "title" : "Dialog state tracking: A neural reading comprehension approach",
      "author" : [ "Shuyang Gao", "Abhishek Sethi", "Sanchit Agarwal", "Tagyoung Chung", "Dilek Hakkani-Tür." ],
      "venue" : "Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue, SIGdial",
      "citeRegEx" : "Gao et al\\.,? 2019",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2019
    }, {
      "title" : "Trippy: A triple copy strategy for value independent neural dialog state tracking",
      "author" : [ "Michael Heck", "Carel van Niekerk", "Nurul Lubis", "Christian Geishauser", "Hsien-Chin Lin", "Marco Moresi", "Milica Gasic." ],
      "venue" : "Proceedings of the 21th Annual Meeting of",
      "citeRegEx" : "Heck et al\\.,? 2020",
      "shortCiteRegEx" : "Heck et al\\.",
      "year" : 2020
    }, {
      "title" : "Convert: Efficient and accurate conversational representations from transformers",
      "author" : [ "Matthew Henderson", "Iñigo Casanueva", "Nikola Mrksic", "Pei-Hao Su", "Tsung-Hsien Wen", "Ivan Vulic." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Meth-",
      "citeRegEx" : "Henderson et al\\.,? 2020",
      "shortCiteRegEx" : "Henderson et al\\.",
      "year" : 2020
    }, {
      "title" : "A simple language model for task-oriented dialogue",
      "author" : [ "Ehsan Hosseini-Asl", "Bryan McCann", "Chien-Sheng Wu", "Semih Yavuz", "Richard Socher." ],
      "venue" : "Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Pro-",
      "citeRegEx" : "Hosseini.Asl et al\\.,? 2020",
      "shortCiteRegEx" : "Hosseini.Asl et al\\.",
      "year" : 2020
    }, {
      "title" : "Unifying question answering and text classification via span extraction",
      "author" : [ "Nitish Shirish Keskar", "Bryan McCann", "Caiming Xiong", "Richard Socher." ],
      "venue" : "CoRR, abs/1904.09286.",
      "citeRegEx" : "Keskar et al\\.,? 2019",
      "shortCiteRegEx" : "Keskar et al\\.",
      "year" : 2019
    }, {
      "title" : "The eighth dialog system technology challenge",
      "author" : [ "Hori", "Anoop Cherian", "Tim K. Marks", "Abhinav Rastogi", "Xiaoxue Zang", "Srinivas Sunkara", "Raghav Gupta." ],
      "venue" : "CoRR, abs/1911.06394.",
      "citeRegEx" : "Hori et al\\.,? 2019",
      "shortCiteRegEx" : "Hori et al\\.",
      "year" : 2019
    }, {
      "title" : "Efficient dialogue state tracking",
      "author" : [ "Sungdong Kim", "Sohee Yang", "Gyuwan Kim", "SangWoo Lee" ],
      "venue" : null,
      "citeRegEx" : "Kim et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2020
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P. Kingma", "Jimmy Ba." ],
      "venue" : "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "An evaluation dataset for intent classification",
      "author" : [ "Stefan Larson", "Anish Mahendran", "Joseph J. Peper", "Christopher Clarke", "Andrew Lee", "Parker Hill", "Jonathan K. Kummerfeld", "Kevin Leach", "Michael A. Laurenzano", "Lingjia Tang", "Jason Mars" ],
      "venue" : null,
      "citeRegEx" : "Larson et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Larson et al\\.",
      "year" : 2019
    }, {
      "title" : "SUMBT: slot-utterance matching for universal and scalable belief tracking",
      "author" : [ "Hwaran Lee", "Jinsik Lee", "Tae-Yoon Kim." ],
      "venue" : "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28- Au-",
      "citeRegEx" : "Lee et al\\.,? 2019a",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2019
    }, {
      "title" : "Multi-domain taskcompletion dialog challenge",
      "author" : [ "Sungjin Lee", "Hannes Schulz", "Adam Atkinson", "Jianfeng Gao", "Kaheer Suleman", "Layla El Asri", "Mahmoud Adada", "Minlie Huang", "Shikhar Sharma", "Wendy Tay", "Xiujun Li." ],
      "venue" : "Dialog System Tech-",
      "citeRegEx" : "Lee et al\\.,? 2019b",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2019
    }, {
      "title" : "Sequicity: Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures",
      "author" : [ "Wenqiang Lei", "Xisen Jin", "Min-Yen Kan", "Zhaochun Ren", "Xiangnan He", "Dawei Yin." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association",
      "citeRegEx" : "Lei et al\\.,? 2018",
      "shortCiteRegEx" : "Lei et al\\.",
      "year" : 2018
    }, {
      "title" : "BART: denoising sequence-to-sequence pretraining for natural language",
      "author" : [ "Mike Lewis", "Yinhan Liu", "Naman Goyal", "Marjan Ghazvininejad", "Abdelrahman Mohamed", "Omer Levy", "Veselin Stoyanov", "Luke Zettlemoyer" ],
      "venue" : null,
      "citeRegEx" : "Lewis et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Lewis et al\\.",
      "year" : 2020
    }, {
      "title" : "Investigation of language understanding impact for reinforcement learning based dialogue systems",
      "author" : [ "Xiujun Li", "Yun-Nung Chen", "Lihong Li", "Jianfeng Gao", "Asli Celikyilmaz." ],
      "venue" : "CoRR, abs/1703.07055.",
      "citeRegEx" : "Li et al\\.,? 2017",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2017
    }, {
      "title" : "MOSS: end-to-end dialog system framework with modular supervision",
      "author" : [ "Weixin Liang", "Youzhi Tian", "Chengcai Chen", "Zhou Yu." ],
      "venue" : "The ThirtyFourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Appli-",
      "citeRegEx" : "Liang et al\\.,? 2020",
      "shortCiteRegEx" : "Liang et al\\.",
      "year" : 2020
    }, {
      "title" : "Mintl: Minimalist transfer learning for task-oriented dialogue systems",
      "author" : [ "Zhaojiang Lin", "Andrea Madotto", "Genta Indra Winata", "Pascale Fung." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP",
      "citeRegEx" : "Lin et al\\.,? 2020",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2020
    }, {
      "title" : "End-to-end learning of task-oriented dialogs",
      "author" : [ "Bing Liu", "Ian R. Lane." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics, NAACLHLT 2018, New Orleans, Louisiana, USA, June 2-",
      "citeRegEx" : "Liu and Lane.,? 2018",
      "shortCiteRegEx" : "Liu and Lane.",
      "year" : 2018
    }, {
      "title" : "Pretraining the noisy channel model for taskoriented dialogue",
      "author" : [ "Qi Liu", "Lei Yu", "Laura Rimell", "Phil Blunsom." ],
      "venue" : "Trans. Assoc. Comput. Linguistics, 9:657–674.",
      "citeRegEx" : "Liu et al\\.,? 2021",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2021
    }, {
      "title" : "Roberta: A robustly optimized BERT pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "CoRR, abs/1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "The natural language decathlon: Multitask learning as question answering",
      "author" : [ "Bryan McCann", "Nitish Shirish Keskar", "Caiming Xiong", "Richard Socher." ],
      "venue" : "CoRR, abs/1806.08730.",
      "citeRegEx" : "McCann et al\\.,? 2018",
      "shortCiteRegEx" : "McCann et al\\.",
      "year" : 2018
    }, {
      "title" : "Structured fusion networks for dialog",
      "author" : [ "Shikib Mehri", "Tejas Srinivasan", "Maxine Eskénazi." ],
      "venue" : "Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue, SIGdial 2019, Stockholm, Sweden, September 11-13, 2019, pages 165–",
      "citeRegEx" : "Mehri et al\\.,? 2019",
      "shortCiteRegEx" : "Mehri et al\\.",
      "year" : 2019
    }, {
      "title" : "Neural belief tracker: Data-driven dialogue state tracking",
      "author" : [ "Nikola Mrkšić", "Diarmuid Ó Séaghdha", "Tsung-Hsien Wen", "Blaise Thomson", "Steve Young." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Vol-",
      "citeRegEx" : "Mrkšić et al\\.,? 2017",
      "shortCiteRegEx" : "Mrkšić et al\\.",
      "year" : 2017
    }, {
      "title" : "Toward scalable neural dialogue state tracking model",
      "author" : [ "Elnaz Nouri", "Ehsan Hosseini-Asl." ],
      "venue" : "CoRR, abs/1812.00899.",
      "citeRegEx" : "Nouri and Hosseini.Asl.,? 2018",
      "shortCiteRegEx" : "Nouri and Hosseini.Asl.",
      "year" : 2018
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia,",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "Soloist: Building task bots at scale with transfer learning and machine teaching",
      "author" : [ "Baolin Peng", "Chunyuan Li", "Jinchao Li", "Shahin Shayandeh", "Lars Liden", "Jianfeng Gao." ],
      "venue" : "Transactions of the Association for Computational Linguistics.",
      "citeRegEx" : "Peng et al\\.,? 2021",
      "shortCiteRegEx" : "Peng et al\\.",
      "year" : 2021
    }, {
      "title" : "Deep contextualized word representations",
      "author" : [ "Matthew E. Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Associ-",
      "citeRegEx" : "Peters et al\\.,? 2018",
      "shortCiteRegEx" : "Peters et al\\.",
      "year" : 2018
    }, {
      "title" : "Sentence encoders on stilts: Supplementary training on intermediate labeled-data tasks",
      "author" : [ "Jason Phang", "Thibault Févry", "Samuel R. Bowman." ],
      "venue" : "CoRR, abs/1811.01088.",
      "citeRegEx" : "Phang et al\\.,? 2018",
      "shortCiteRegEx" : "Phang et al\\.",
      "year" : 2018
    }, {
      "title" : "Language models are unsupervised multitask learners",
      "author" : [ "Alec Radford", "Jeff Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever" ],
      "venue" : null,
      "citeRegEx" : "Radford et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2019
    }, {
      "title" : "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "author" : [ "Colin Raffel", "Noam Shazeer", "Adam Roberts", "Katherine Lee", "Sharan Narang", "Michael Matena", "Yanqi Zhou", "Wei Li", "Peter J. Liu." ],
      "venue" : "J. Mach. Learn. Res., 21:140:1–140:67.",
      "citeRegEx" : "Raffel et al\\.,? 2020",
      "shortCiteRegEx" : "Raffel et al\\.",
      "year" : 2020
    }, {
      "title" : "Towards scalable multi-domain conversational agents: The schema-guided dialogue dataset",
      "author" : [ "Abhinav Rastogi", "Xiaoxue Zang", "Srinivas Sunkara", "Raghav Gupta", "Pranav Khaitan." ],
      "venue" : "The ThirtyFourth AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Rastogi et al\\.,? 2020",
      "shortCiteRegEx" : "Rastogi et al\\.",
      "year" : 2020
    }, {
      "title" : "Scalable and accurate dialogue state tracking via hierarchical sequence generation",
      "author" : [ "Liliang Ren", "Jianmo Ni", "Julian J. McAuley." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
      "citeRegEx" : "Ren et al\\.,? 2019",
      "shortCiteRegEx" : "Ren et al\\.",
      "year" : 2019
    }, {
      "title" : "Hierarchical transformer for task oriented dialog systems",
      "author" : [ "Bishal Santra", "Potnuru Anusha", "Pawan Goyal." ],
      "venue" : "Proceedings of the 2021 Conference 11",
      "citeRegEx" : "Santra et al\\.,? 2021",
      "shortCiteRegEx" : "Santra et al\\.",
      "year" : 2021
    }, {
      "title" : "A contextual hierarchical attention network with adaptive objective for dialogue state tracking",
      "author" : [ "Yong Shan", "Zekang Li", "Jinchao Zhang", "Fandong Meng", "Yang Feng", "Cheng Niu", "Jie Zhou." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for",
      "citeRegEx" : "Shan et al\\.,? 2020",
      "shortCiteRegEx" : "Shan et al\\.",
      "year" : 2020
    }, {
      "title" : "Flexibly-structured model for task-oriented dialogues",
      "author" : [ "Lei Shu", "Piero Molino", "Mahdi Namazifar", "Hu Xu", "Bing Liu", "Huaixiu Zheng", "Gökhan Tür." ],
      "venue" : "Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue, SIGdial",
      "citeRegEx" : "Shu et al\\.,? 2019",
      "shortCiteRegEx" : "Shu et al\\.",
      "year" : 2019
    }, {
      "title" : "Spoken Natural Language Dialog Systems: A Practical Approach",
      "author" : [ "Ronnie W. Smith", "D. Richard Hipp." ],
      "venue" : "Oxford University Press, Inc., USA.",
      "citeRegEx" : "Smith and Hipp.,? 1995",
      "shortCiteRegEx" : "Smith and Hipp.",
      "year" : 1995
    }, {
      "title" : "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
      "author" : [ "Alex Wang", "Amanpreet Singh", "Julian Michael", "Felix Hill", "Omer Levy", "Samuel R. Bowman." ],
      "venue" : "CoRR, abs/1804.07461.",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "A networkbased end-to-end trainable task-oriented dialogue system",
      "author" : [ "Tsung-Hsien Wen", "David Vandyke", "Nikola Mrkšić", "Milica Gašić", "Lina M. Rojas-Barahona", "Pei-Hao Su", "Stefan Ultes", "Steve Young." ],
      "venue" : "Proceedings of the 15th Conference of",
      "citeRegEx" : "Wen et al\\.,? 2017",
      "shortCiteRegEx" : "Wen et al\\.",
      "year" : 2017
    }, {
      "title" : "Partially observable markov decision processes for spoken dialog systems",
      "author" : [ "Jason D. Williams", "Steve J. Young." ],
      "venue" : "Comput. Speech Lang., 21(2):393– 422.",
      "citeRegEx" : "Williams and Young.,? 2007",
      "shortCiteRegEx" : "Williams and Young.",
      "year" : 2007
    }, {
      "title" : "Huggingface’s transformers: State-of-the-art natural language",
      "author" : [ "Thomas Wolf", "Lysandre Debut", "Victor Sanh", "Julien Chaumond", "Clement Delangue", "Anthony Moi", "Pierric Cistac", "Tim Rault", "Rémi Louf", "Morgan Funtowicz", "Jamie Brew" ],
      "venue" : null,
      "citeRegEx" : "Wolf et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Wolf et al\\.",
      "year" : 2019
    }, {
      "title" : "Transfertransfo: A transfer learning approach for neural network based conversational agents",
      "author" : [ "Thomas Wolf", "Victor Sanh", "Julien Chaumond", "Clement Delangue." ],
      "venue" : "CoRR, abs/1901.08149.",
      "citeRegEx" : "Wolf et al\\.,? 2019b",
      "shortCiteRegEx" : "Wolf et al\\.",
      "year" : 2019
    }, {
      "title" : "TOD-BERT: Pre-trained natural language understanding for task-oriented dialogue",
      "author" : [ "Chien-Sheng Wu", "Steven C.H. Hoi", "Richard Socher", "Caiming Xiong." ],
      "venue" : "Proceedings of the 2020 Conference on",
      "citeRegEx" : "Wu et al\\.,? 2020",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2020
    }, {
      "title" : "Transferable multi-domain state generator for task-oriented dialogue systems",
      "author" : [ "Chien-Sheng Wu", "Andrea Madotto", "Ehsan HosseiniAsl", "Caiming Xiong", "Richard Socher", "Pascale Fung." ],
      "venue" : "Proceedings of the 57th Conference of the Association",
      "citeRegEx" : "Wu et al\\.,? 2019",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2019
    }, {
      "title" : "Multilingual universal sentence encoder for semantic retrieval",
      "author" : [ "Yinfei Yang", "Daniel Cer", "Amin Ahmad", "Mandy Guo", "Jax Law", "Noah Constant", "Gustavo Hernández Ábrego", "Steve Yuan", "Chris Tar", "Yun-Hsuan Sung", "Brian Strope", "Ray Kurzweil" ],
      "venue" : null,
      "citeRegEx" : "Yang et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2020
    }, {
      "title" : "UBAR: towards fully end-to-end task-oriented dialog system with GPT-2",
      "author" : [ "Yunyi Yang", "Yunhao Li", "Xiaojun Quan." ],
      "venue" : "Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, ThirtyThird Conference on Innovative Applications of Ar-",
      "citeRegEx" : "Yang et al\\.,? 2021",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2021
    }, {
      "title" : "Xlnet: Generalized autoregressive pretraining for language understanding",
      "author" : [ "Zhilin Yang", "Zihang Dai", "Yiming Yang", "Jaime G. Carbonell", "Ruslan Salakhutdinov", "Quoc V. Le." ],
      "venue" : "Advances in Neural Information Processing Systems 32: Annual Con-",
      "citeRegEx" : "Yang et al\\.,? 2019",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "Pomdp-based statistical spoken dialog systems: A review",
      "author" : [ "Steve J. Young", "Milica Gasic", "Blaise Thomson", "Jason D. Williams." ],
      "venue" : "Proc. IEEE, 101(5):1160–1179.",
      "citeRegEx" : "Young et al\\.,? 2013",
      "shortCiteRegEx" : "Young et al\\.",
      "year" : 2013
    }, {
      "title" : "Find or classify? dual strategy for slot-value predictions on multi-domain dialog state tracking",
      "author" : [ "Jianguo Zhang", "Kazuma Hashimoto", "Chien-Sheng Wu", "Yao Wan", "Philip S. Yu", "Richard Socher", "Caiming Xiong." ],
      "venue" : "CoRR, abs/1910.03544.",
      "citeRegEx" : "Zhang et al\\.,? 2019",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    }, {
      "title" : "A probabilistic end-to-end task-oriented dialog model with latent belief states towards semisupervised learning",
      "author" : [ "Yichi Zhang", "Zhijian Ou", "Min Hu", "Junlan Feng." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Lan-",
      "citeRegEx" : "Zhang et al\\.,? 2020a",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Taskoriented dialog systems that consider multiple appropriate responses under the same context",
      "author" : [ "Yichi Zhang", "Zhijian Ou", "Zhou Yu." ],
      "venue" : "The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Ap-",
      "citeRegEx" : "Zhang et al\\.,? 2020b",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "DIALOGPT : Largescale generative pre-training for conversational response generation",
      "author" : [ "Yizhe Zhang", "Siqi Sun", "Michel Galley", "Yen-Chun Chen", "Chris Brockett", "Xiang Gao", "Jianfeng Gao", "Jingjing Liu", "Bill Dolan." ],
      "venue" : "Proceedings of the 58th An-",
      "citeRegEx" : "Zhang et al\\.,? 2020c",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Global-locally self-attentive encoder for dialogue state tracking",
      "author" : [ "Victor Zhong", "Caiming Xiong", "Richard Socher." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, ACL 2018, Melbourne, Australia, July",
      "citeRegEx" : "Zhong et al\\.,? 2018",
      "shortCiteRegEx" : "Zhong et al\\.",
      "year" : 2018
    }, {
      "title" : "Dialogue state tracking with multi-level fusion of predicted dialogue states and conversations",
      "author" : [ "Jingyao Zhou", "Haipang Wu", "Zehao Lin", "Guodun Li", "Yin Zhang." ],
      "venue" : "CoRR, abs/2107.05168.",
      "citeRegEx" : "Zhou et al\\.,? 2021",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2021
    }, {
      "title" : "Multi-domain dialogue state tracking as dynamic knowledge graph enhanced question answering",
      "author" : [ "Li Zhou", "Kevin Small." ],
      "venue" : "CoRR, abs/1911.06192. 13",
      "citeRegEx" : "Zhou and Small.,? 2019",
      "shortCiteRegEx" : "Zhou and Small.",
      "year" : 2019
    }, {
      "title" : "2018) is designed to help developing models capable of understanding users’ intent (i.e., natural language understanding (NLU))",
      "author" : [ "• SNIPS (Coucke" ],
      "venue" : null,
      "citeRegEx" : ".Coucke,? \\Q2018\\E",
      "shortCiteRegEx" : ".Coucke",
      "year" : 2018
    }, {
      "title" : "2019) is built for improving model’s ability in detecting out-ofscope users’ intents. It contains data with NLU annotations for 150 intents across 10 different domains",
      "author" : [ "• CLINC (Larson" ],
      "venue" : null,
      "citeRegEx" : ".Larson,? \\Q2019\\E",
      "shortCiteRegEx" : ".Larson",
      "year" : 2019
    }, {
      "title" : "2017) is a in-car personal assistant dataset with dialogues from three domains: calendar scheduling, weather information retrieval, and point-of-interest navigation",
      "author" : [ "• KVRET (Eric" ],
      "venue" : null,
      "citeRegEx" : ".Eric,? \\Q2017\\E",
      "shortCiteRegEx" : ".Eric",
      "year" : 2017
    } ],
    "referenceMentions" : [ {
      "referenceID" : 60,
      "context" : "Task-oriented dialogue is often decomposed into three sub-tasks: (1) dialogue state tracking (DST) for tracking user’s belief state; (2) dialogue policy learning (POL) for deciding which system action to take; (3) natural language generation (NLG) for generating dialogue response (Young et al., 2013).",
      "startOffset" : 281,
      "endOffset" : 301
    }, {
      "referenceID" : 49,
      "context" : "Traditional approaches (Smith and Hipp, 1995; Young et al., 2013) adopt a modularized pipeline that addresses different sub-tasks with distinct dedicated modules.",
      "startOffset" : 23,
      "endOffset" : 65
    }, {
      "referenceID" : 60,
      "context" : "Traditional approaches (Smith and Hipp, 1995; Young et al., 2013) adopt a modularized pipeline that addresses different sub-tasks with distinct dedicated modules.",
      "startOffset" : 23,
      "endOffset" : 65
    }, {
      "referenceID" : 51,
      "context" : "In contrast, recent systems (Wen et al., 2017; Eric et al., 2017; Lei et al., 2018; Shu et al., 2019) integrate all functionalities required to hold a dialogue into neural network models.",
      "startOffset" : 28,
      "endOffset" : 101
    }, {
      "referenceID" : 12,
      "context" : "In contrast, recent systems (Wen et al., 2017; Eric et al., 2017; Lei et al., 2018; Shu et al., 2019) integrate all functionalities required to hold a dialogue into neural network models.",
      "startOffset" : 28,
      "endOffset" : 101
    }, {
      "referenceID" : 26,
      "context" : "In contrast, recent systems (Wen et al., 2017; Eric et al., 2017; Lei et al., 2018; Shu et al., 2019) integrate all functionalities required to hold a dialogue into neural network models.",
      "startOffset" : 28,
      "endOffset" : 101
    }, {
      "referenceID" : 48,
      "context" : "In contrast, recent systems (Wen et al., 2017; Eric et al., 2017; Lei et al., 2018; Shu et al., 2019) integrate all functionalities required to hold a dialogue into neural network models.",
      "startOffset" : 28,
      "endOffset" : 101
    }, {
      "referenceID" : 18,
      "context" : ", 2020), different systems based on PLMs have been proposed (Hosseini-Asl et al., 2020; Lin et al., 2020; Peng et al., 2021; Liu et al., 2021).",
      "startOffset" : 60,
      "endOffset" : 142
    }, {
      "referenceID" : 30,
      "context" : ", 2020), different systems based on PLMs have been proposed (Hosseini-Asl et al., 2020; Lin et al., 2020; Peng et al., 2021; Liu et al., 2021).",
      "startOffset" : 60,
      "endOffset" : 142
    }, {
      "referenceID" : 39,
      "context" : ", 2020), different systems based on PLMs have been proposed (Hosseini-Asl et al., 2020; Lin et al., 2020; Peng et al., 2021; Liu et al., 2021).",
      "startOffset" : 60,
      "endOffset" : 142
    }, {
      "referenceID" : 32,
      "context" : ", 2020), different systems based on PLMs have been proposed (Hosseini-Asl et al., 2020; Lin et al., 2020; Peng et al., 2021; Liu et al., 2021).",
      "startOffset" : 60,
      "endOffset" : 142
    }, {
      "referenceID" : 39,
      "context" : "While impressive results are reported (HosseiniAsl et al., 2020; Peng et al., 2021), we identify three major limitations in the cascaded formulation of their system design.",
      "startOffset" : 38,
      "endOffset" : 83
    }, {
      "referenceID" : 28,
      "context" : "(1) Firstly, as the model solves all sub-tasks in a sequential order, the errors accumulated from previous steps are propagated to latter steps (Li et al., 2017; Liu and Lane, 2018).",
      "startOffset" : 144,
      "endOffset" : 181
    }, {
      "referenceID" : 31,
      "context" : "(1) Firstly, as the model solves all sub-tasks in a sequential order, the errors accumulated from previous steps are propagated to latter steps (Li et al., 2017; Liu and Lane, 2018).",
      "startOffset" : 144,
      "endOffset" : 181
    }, {
      "referenceID" : 64,
      "context" : "Inspired by recent success of dialogue language model pre-training (Zhang et al., 2020c; Wu et al., 2020; Peng et al., 2021), we propose a dialogue multi-task pre-training strategy that equips our model with the primary TOD task completion skills.",
      "startOffset" : 67,
      "endOffset" : 124
    }, {
      "referenceID" : 55,
      "context" : "Inspired by recent success of dialogue language model pre-training (Zhang et al., 2020c; Wu et al., 2020; Peng et al., 2021), we propose a dialogue multi-task pre-training strategy that equips our model with the primary TOD task completion skills.",
      "startOffset" : 67,
      "endOffset" : 124
    }, {
      "referenceID" : 39,
      "context" : "Inspired by recent success of dialogue language model pre-training (Zhang et al., 2020c; Wu et al., 2020; Peng et al., 2021), we propose a dialogue multi-task pre-training strategy that equips our model with the primary TOD task completion skills.",
      "startOffset" : 67,
      "endOffset" : 124
    }, {
      "referenceID" : 43,
      "context" : "Specifically, initialized with T5 (Raffel et al., 2020), we pre-train our model on a heterogeneous set of dialog corpora that consist of partially-annotated data.",
      "startOffset" : 34,
      "endOffset" : 55
    }, {
      "referenceID" : 52,
      "context" : "Traditional systems (Williams and Young, 2007; Young et al., 2013) adopt a pipelined approach that requires dialogue state tracking for understanding user’s goal, dialogue policy learning for deciding which system action to take, and natural language generation for generating dialogue responses.",
      "startOffset" : 20,
      "endOffset" : 66
    }, {
      "referenceID" : 60,
      "context" : "Traditional systems (Williams and Young, 2007; Young et al., 2013) adopt a pipelined approach that requires dialogue state tracking for understanding user’s goal, dialogue policy learning for deciding which system action to take, and natural language generation for generating dialogue responses.",
      "startOffset" : 20,
      "endOffset" : 66
    }, {
      "referenceID" : 51,
      "context" : "Recently, to simplify the modelling effort, researchers have shifted their attention to building neural network models that address the TOD subtasks (Wen et al., 2017; Eric et al., 2017; Lei et al., 2018; Liang et al., 2020).",
      "startOffset" : 149,
      "endOffset" : 224
    }, {
      "referenceID" : 12,
      "context" : "Recently, to simplify the modelling effort, researchers have shifted their attention to building neural network models that address the TOD subtasks (Wen et al., 2017; Eric et al., 2017; Lei et al., 2018; Liang et al., 2020).",
      "startOffset" : 149,
      "endOffset" : 224
    }, {
      "referenceID" : 26,
      "context" : "Recently, to simplify the modelling effort, researchers have shifted their attention to building neural network models that address the TOD subtasks (Wen et al., 2017; Eric et al., 2017; Lei et al., 2018; Liang et al., 2020).",
      "startOffset" : 149,
      "endOffset" : 224
    }, {
      "referenceID" : 29,
      "context" : "Recently, to simplify the modelling effort, researchers have shifted their attention to building neural network models that address the TOD subtasks (Wen et al., 2017; Eric et al., 2017; Lei et al., 2018; Liang et al., 2020).",
      "startOffset" : 149,
      "endOffset" : 224
    }, {
      "referenceID" : 40,
      "context" : "The research community has witnessed remarkable progress of pre-training methods in a wide range of NLP tasks, including language understanding (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019; Yang et al., 2019) and text generation (Radford et al.",
      "startOffset" : 144,
      "endOffset" : 223
    }, {
      "referenceID" : 9,
      "context" : "The research community has witnessed remarkable progress of pre-training methods in a wide range of NLP tasks, including language understanding (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019; Yang et al., 2019) and text generation (Radford et al.",
      "startOffset" : 144,
      "endOffset" : 223
    }, {
      "referenceID" : 33,
      "context" : "The research community has witnessed remarkable progress of pre-training methods in a wide range of NLP tasks, including language understanding (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019; Yang et al., 2019) and text generation (Radford et al.",
      "startOffset" : 144,
      "endOffset" : 223
    }, {
      "referenceID" : 59,
      "context" : "The research community has witnessed remarkable progress of pre-training methods in a wide range of NLP tasks, including language understanding (Peters et al., 2018; Devlin et al., 2019; Liu et al., 2019; Yang et al., 2019) and text generation (Radford et al.",
      "startOffset" : 144,
      "endOffset" : 223
    }, {
      "referenceID" : 54,
      "context" : "Based on GPT-2, Transfertransfo (Wolf et al., 2019b) achieves good results on ConvAI-2 competition.",
      "startOffset" : 32,
      "endOffset" : 52
    }, {
      "referenceID" : 64,
      "context" : "As another extension of GPT-2, DialoGPT (Zhang et al., 2020c) performs well in generating open-domain dialogue response.",
      "startOffset" : 40,
      "endOffset" : 61
    }, {
      "referenceID" : 17,
      "context" : "ConveRT (Henderson et al., 2020) is a language model with dual-encoder built for the task of response selection.",
      "startOffset" : 8,
      "endOffset" : 32
    }, {
      "referenceID" : 2,
      "context" : "PLATO (Bao et al., 2020) pre-trains a model with discrete latent variable structure for the response generation task.",
      "startOffset" : 6,
      "endOffset" : 24
    }, {
      "referenceID" : 41,
      "context" : "Recent work (Phang et al., 2018; Aghajanyan et al., 2021) found that supplementary training on the tasks with intermediate-labelled data improves the performance of the fine-tuned models on GLUE natural language understanding benchmark (Wang et al.",
      "startOffset" : 12,
      "endOffset" : 57
    }, {
      "referenceID" : 0,
      "context" : "Recent work (Phang et al., 2018; Aghajanyan et al., 2021) found that supplementary training on the tasks with intermediate-labelled data improves the performance of the fine-tuned models on GLUE natural language understanding benchmark (Wang et al.",
      "startOffset" : 12,
      "endOffset" : 57
    }, {
      "referenceID" : 50,
      "context" : ", 2021) found that supplementary training on the tasks with intermediate-labelled data improves the performance of the fine-tuned models on GLUE natural language understanding benchmark (Wang et al., 2018).",
      "startOffset" : 186,
      "endOffset" : 205
    }, {
      "referenceID" : 25,
      "context" : "To construct the pre-training corpus, we collect eleven human-written multi-turn task-oriented dialogue corpora, including MetaLWOZ (Lee et al., 2019b), SNIPS (Coucke et al.",
      "startOffset" : 132,
      "endOffset" : 151
    }, {
      "referenceID" : 8,
      "context" : ", 2019b), SNIPS (Coucke et al., 2018), CLINC (Larson et al.",
      "startOffset" : 16,
      "endOffset" : 37
    }, {
      "referenceID" : 23,
      "context" : ", 2018), CLINC (Larson et al., 2019), ATIS (Amin, 2019), KVRET (Eric et al.",
      "startOffset" : 15,
      "endOffset" : 36
    }, {
      "referenceID" : 12,
      "context" : ", 2019), ATIS (Amin, 2019), KVRET (Eric et al., 2017), WOZ (Mrkšić et al.",
      "startOffset" : 34,
      "endOffset" : 53
    }, {
      "referenceID" : 6,
      "context" : ", 2017), TaskMaster (Byrne et al., 2019), and SchemaGuided (Rastogi et al.",
      "startOffset" : 20,
      "endOffset" : 40
    }, {
      "referenceID" : 34,
      "context" : "Motivated by previous work (McCann et al., 2018; Keskar et al., 2019; Raffel et al., 2020) that unify multiple NLP tasks into a common format, we cast all TOD-related tasks that we consider into the same plug-and-play text generation problem.",
      "startOffset" : 27,
      "endOffset" : 90
    }, {
      "referenceID" : 19,
      "context" : "Motivated by previous work (McCann et al., 2018; Keskar et al., 2019; Raffel et al., 2020) that unify multiple NLP tasks into a common format, we cast all TOD-related tasks that we consider into the same plug-and-play text generation problem.",
      "startOffset" : 27,
      "endOffset" : 90
    }, {
      "referenceID" : 43,
      "context" : "Motivated by previous work (McCann et al., 2018; Keskar et al., 2019; Raffel et al., 2020) that unify multiple NLP tasks into a common format, we cast all TOD-related tasks that we consider into the same plug-and-play text generation problem.",
      "startOffset" : 27,
      "endOffset" : 90
    }, {
      "referenceID" : 43,
      "context" : "These three models are initialized with T5-small, T5-base, and T5-large models (Raffel et al., 2020) that contain ∼60M, ∼220M, and ∼770M parameters, respectively.",
      "startOffset" : 79,
      "endOffset" : 100
    }, {
      "referenceID" : 22,
      "context" : "The models are trained using Adam optimizer (Kingma and Ba, 2015) with a learning rate of 5e-5 and a batch size of 128.",
      "startOffset" : 44,
      "endOffset" : 65
    }, {
      "referenceID" : 63,
      "context" : "End-to-end dialogue modelling aims at evaluating the model in the most realistic, fully end-to-end setting, where the generated dialogue states are used for the database search and response generation (Zhang et al., 2020b; Hosseini-Asl et al., 2020).",
      "startOffset" : 201,
      "endOffset" : 249
    }, {
      "referenceID" : 18,
      "context" : "End-to-end dialogue modelling aims at evaluating the model in the most realistic, fully end-to-end setting, where the generated dialogue states are used for the database search and response generation (Zhang et al., 2020b; Hosseini-Asl et al., 2020).",
      "startOffset" : 201,
      "endOffset" : 249
    }, {
      "referenceID" : 38,
      "context" : "For evaluation, we follow the original MultiWOZ guidance for all individual metrics: Inform, Success, and BLEU (Papineni et al., 2002).",
      "startOffset" : 111,
      "endOffset" : 134
    }, {
      "referenceID" : 35,
      "context" : ", combined score (Mehri et al., 2019), is also reported which is defined as Combined = (Inform + Success) × 0.",
      "startOffset" : 17,
      "endOffset" : 37
    }, {
      "referenceID" : 26,
      "context" : "We compare PPTOD with several strong baselines, including Sequicity (Lei et al., 2018), MDSequicity (Zhang et al.",
      "startOffset" : 68,
      "endOffset" : 86
    }, {
      "referenceID" : 30,
      "context" : ", 2020b), MinTL (Lin et al., 2020), HIERJoint (Santra et al.",
      "startOffset" : 16,
      "endOffset" : 34
    }, {
      "referenceID" : 46,
      "context" : ", 2020), HIERJoint (Santra et al., 2021), LABES-S2S (Zhang et al.",
      "startOffset" : 19,
      "endOffset" : 40
    }, {
      "referenceID" : 62,
      "context" : ", 2021), LABES-S2S (Zhang et al., 2020a), SimpleTOD (Hosseini-Asl et al.",
      "startOffset" : 19,
      "endOffset" : 40
    }, {
      "referenceID" : 18,
      "context" : ", 2020a), SimpleTOD (Hosseini-Asl et al., 2020), UBAR (Yang et al.",
      "startOffset" : 20,
      "endOffset" : 47
    }, {
      "referenceID" : 58,
      "context" : ", 2020), UBAR (Yang et al., 2021), and SOLOIST (Peng et al.",
      "startOffset" : 14,
      "endOffset" : 33
    }, {
      "referenceID" : 39,
      "context" : ", 2021), and SOLOIST (Peng et al., 2021), TOP and TOP+Noisy Online Decoding (TOP+NOD) (Liu et al.",
      "startOffset" : 21,
      "endOffset" : 40
    }, {
      "referenceID" : 32,
      "context" : ", 2021), TOP and TOP+Noisy Online Decoding (TOP+NOD) (Liu et al., 2021).",
      "startOffset" : 53,
      "endOffset" : 71
    }, {
      "referenceID" : 32,
      "context" : "In particular, it is worth mentioning that our model is a single architecture that does not require additional language models for re-ranking the outputs as in TOP+NOD (Liu et al., 2021).",
      "startOffset" : 168,
      "endOffset" : 186
    }, {
      "referenceID" : 32,
      "context" : "We did not compare results with TOP+NOD (Liu et al., 2021) since the authors did not release their code and models.",
      "startOffset" : 40,
      "endOffset" : 58
    }, {
      "referenceID" : 61,
      "context" : "However, these methods operate on a fixed ontology and perform prediction over a pre-defined set of slot-value pairs (Zhang et al., 2019; Chen et al., 2020; Shan et al., 2020; Zhou et al., 2021).",
      "startOffset" : 117,
      "endOffset" : 194
    }, {
      "referenceID" : 7,
      "context" : "However, these methods operate on a fixed ontology and perform prediction over a pre-defined set of slot-value pairs (Zhang et al., 2019; Chen et al., 2020; Shan et al., 2020; Zhou et al., 2021).",
      "startOffset" : 117,
      "endOffset" : 194
    }, {
      "referenceID" : 47,
      "context" : "However, these methods operate on a fixed ontology and perform prediction over a pre-defined set of slot-value pairs (Zhang et al., 2019; Chen et al., 2020; Shan et al., 2020; Zhou et al., 2021).",
      "startOffset" : 117,
      "endOffset" : 194
    }, {
      "referenceID" : 66,
      "context" : "However, these methods operate on a fixed ontology and perform prediction over a pre-defined set of slot-value pairs (Zhang et al., 2019; Chen et al., 2020; Shan et al., 2020; Zhou et al., 2021).",
      "startOffset" : 117,
      "endOffset" : 194
    }, {
      "referenceID" : 16,
      "context" : "This idea of fixed ontology is not scalable, as in real world applications, the ontology is subject to constant change (Heck et al., 2020).",
      "startOffset" : 119,
      "endOffset" : 138
    }, {
      "referenceID" : 39,
      "context" : "Following previous studies (Casanueva et al., 2020; Peng et al., 2021), we test our model in both full training and low-resource settings.",
      "startOffset" : 27,
      "endOffset" : 70
    }, {
      "referenceID" : 57,
      "context" : ", 2020), USE (Yang et al., 2020), ConveRT (Henderson et al.",
      "startOffset" : 13,
      "endOffset" : 32
    }, {
      "referenceID" : 17,
      "context" : ", 2020), ConveRT (Henderson et al., 2020), and SOLOIST (Peng et al.",
      "startOffset" : 17,
      "endOffset" : 41
    }, {
      "referenceID" : 32,
      "context" : "(7)We did not include TOP+NOD (Liu et al., 2021) for comparison as the authors did not release their code.",
      "startOffset" : 30,
      "endOffset" : 48
    } ],
    "year" : 0,
    "abstractText" : "Pre-trained language models have been recently shown to benefit task-oriented dialogue (TOD) systems. Despite their success, existing methods often formulate this task as a cascaded generation problem which can lead to error accumulation across different sub-tasks and greater data annotation overhead. In this study, we present PPTOD, a unified plug-andplay model for task-oriented dialogue. In addition, we introduce a new dialogue multi-task pre-training strategy that allows the model to learn the primary TOD task completion skills from heterogeneous dialog corpora. We extensively test our model on three benchmark TOD tasks, including end-to-end dialogue modelling, dialogue state tracking, and intent classification. Experimental results show that PPTOD achieves new state of the art on all evaluated tasks in both high-resource and lowresource scenarios. Furthermore, comparisons against previous SOTA methods show that the responses generated by PPTOD are more factually correct and semantically coherent as judged by human annotators. 1",
    "creator" : null
  }
}