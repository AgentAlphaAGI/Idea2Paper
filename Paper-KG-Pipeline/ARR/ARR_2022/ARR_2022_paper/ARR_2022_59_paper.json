{
  "name" : "ARR_2022_59_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "THE-X: Privacy-Preserving Transformer Inference with Homomorphic Encryption",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Accompanying the revolution of pre-trained models in many NLP applications, such as sentiment analysis (Xu et al., 2019a), question answering (Yang et al., 2019b), information retrieval (Yang et al., 2019c), and text generation (Raffel et al., 2019), many related technologies have been deployed on the cloud to process user data from personal customers, small businesses, and large enterprises by industrial service providers. However, the convenience of the on-cloud pretraining technology also comes with a series of privacy challenges due to the sensitive nature of user data. For example, the input text or even text\nvector representations in user requests can leak private information, which may cause the specific user to be identified (Schwartz and Solove, 2011; Zhu and Han, 2020). This lack of privacy guarantees may impede privacy-conscious users from releasing their data to service providers. Thus, service providers may suffer from the deficiency of evolving models with user data. Besides, unintended data disclosure and other privacy breaches may result in litigation, fines, and reputation damages for service providers. These concerns spark our proposal of THE-X, to enable privacy-preserving inference of transformer.\nSpecifically, we identify two challenges for the privacy-preserving inference of pre-trained models. The first challenge is how to protect users’ plain text data from access by third-party service providers. (e.g., the clinic record or shopping history). Prior work has applied Differential Privacy (DP) (Dwork et al., 2006) and its variants to address similar privatization issues - originally for statistical databases and more recently for DL (Abadi et al., 2016) and NLP (Qu et al., 2021; Basu et al., 2021b; Fernandes et al., 2019; Lyu et al., 2020; Basu et al., 2021a). However, this solution may suffer from eavesdropping attackers. A handful of research (Zhu and Han, 2020; Zhao et al., 2020) demonstrated it possible to recover raw data from gradient leakage. Also, privacy protection could\nnever be theory-guaranteed. The second challenge is the performance concern, recent works like TextHide (Huang et al., 2020) and FedNLP (Lin et al., 2021) leverages the federated learning (Yang et al., 2019a) to train model on encrypted data, at cost of considerable performance dropping. Focusing on the privacy of training data, they have not fully explored privacy-preserving inference.\nTo solve the concerns above, we depict one practice of privacy-preserving inference in Figure 1, where a fine-tuned language model could be converted into the cloud service mode with THE-X, and process users’ data with its eyes blind. During inference, the content of the user query is anonymous to the transformer model. The results of computation are also ciphertext, which only can be decrypted by the user’s private key.\nIn addition, we need a theory-guaranteed encryption solution like the homomorphic encryption (HE) (Gentry, 2009) to convince both service providers and users of the privacy security in production scenarios. The semantic security of HE is guaranteed by lattice-based cryptography, and the HE computation results on ciphertext could be decrypted to the same results in plaintext, preventing performance reduction cost. The basic idea of homomorphic encryption is to perform computations on encrypted data without first decrypting it, which could fully ensure privacy in cloud-serving scenarios. It allows user data to be encrypted and out-sourced to commercial cloud environments for processing.\nHowever, due to the complex operations (e.g., GELU activation) in transformer-based models, the popular partially homomorphic encryption solution, which only supports addition or multiplication, can not easily be adapted into scenarios of pre-trained models. Based on HE transformer backend (Boemer et al., 2019b,a, 2020), we designed a series of approximation components to fulfill the whole inference pipeline of the mainstream transformer backbone. We evaluate THE-X for BERTtiny on the GLUE benchmark (Wang et al., 2018) and the CONLL2003 task (Sang and De Meulder, 2003). Our results show that THE-X can achieve the privacy-preserving inference with the averaged performance reduction of only 1.49%.\nOur contributions include:\n• We are the first work to explore the privacypreserving transformer inference with HE.\n• We design a practical and effective approxi-\nmation workflow for converting transformerbased models into a function that consists of fully HE operations.\n• A thorough set of experiments confirms the negligible performance reduction with our proposed THE-X approximation."
    }, {
      "heading" : "2 Background",
      "text" : ""
    }, {
      "heading" : "2.1 Security and Privacy Concern of Pre-trained Models",
      "text" : "Pre-trained models like BERT (Devlin et al., 2018) and GPT-3 (Brown et al., 2020) rely heavily on the use of plain text data to get human-like performance. Despite the remarkable achievements of pre-trained models, these state-of-the-art models can not directly answer some sensitive use cases, including the medical record (Christoph et al., 2015), search history (Shen et al., 2007) and other personally identifiable information (PII).\nTo avoid the direct computation on plain-text data, recent works like TextHide (Huang et al., 2020) and DP-finetuning (Kerrigan et al., 2020) introduce the classical federated learning and differential privacy (DP) to protect the sensitive data. However, TextHide (Huang et al., 2020) can only be applied to sentence-level tasks. Due to the mixup operation, TextHide fails to model token-level tasks like named entity recognition or semantic role labelling. DP-finetuning would greatly sacrifice the performance of fine-tuned model by 20% perplexity for a generation model like GPT-2."
    }, {
      "heading" : "2.2 Practical Homomorphic Encryption",
      "text" : "The classic definition of homomorphic encryption is a form of encryption that permits users to perform computations on its encrypted data without first decrypting it. These computations results are retained in an encrypted form, which could be decrypted into identical output produced by the same computations on the unencrypted data. Let F be a function or the entire pre-trained model, E as an encryption function, D as a decryption function. Then for any allowed plain text input x, we have:\nF (x) = D(g(E(x)) (1)\nwhere g is a constructed function to play the same role of function F , except on encrypted data. Figure 1 shows how a user performs inference using a cloud-deployed pre-trained model which is not trusted. First, the pre-trained model receives\na ciphertext encrypted by the user private key and performs inference function g on the ciphertext. Then, the server will send an encrypted result to the user, which can only be decrypted by the user key. At no point does the cloud service provider gain access to the plain text.\nThe Intel HE transformer for nGraph (Boemer et al., 2019b,a) is a Homomorphic Encryption backend to the deep learning models. Currently, it supports the CKKS (Cheon et al., 2017) encryption scheme, implemented by the Simple Encrypted Arithmetic Library (SEAL) (SEAL) from Microsoft Research. It is a research tool to demonstrate the feasibility of HE on deep learning."
    }, {
      "heading" : "2.3 Challenges of Transformer Inference with HE",
      "text" : "Some HE schemes only support a single algebraic operation, such as addition or multiplication. These are known as \"partially homomorphic\" schemes (PHE). Other schemes, called \"fully homomorphic\"(FHE), support two such as addition and multiplication. Note that composing addition and multiplication suffices to construct polynomial functions, and hence polynomial approximations to non-polynomial functions such as GELU (Hendrycks and Gimpel, 2016) or LayerNorm (Xu et al., 2019b). Notably, this limitation prevents the exact computation of any comparisonbased operations such as Max, Min, as well as common functions such as exponential or sigmoid. Finally, \"leveled homomorphic\" schemes (LHE) support addition and multiplication, only up to a fixed computational depth.\n3 THE-X: Formal Description\nThere are two core ideas in THE-X. The first one is to incorporate the user device into the HE inference, and the second is using \"simplified computation\" to approximate the non-polynomial functions.\nIn the following, we will describe how to enable homomorphic encryption of transformer-based models with THE-X."
    }, {
      "heading" : "3.1 Approximation Workflow",
      "text" : "First, we present the approximation workflow of THE-X, which consists of two stages: Standard Finetuning and LN Distill as depicted in Figure 2. Given a pre-trained modelM and corresponding downstream data, we aim to produce a fully HE supported M̄ which is fine-tuned and ready for\nAlgorithm 1: Approximation Workflow Data: labeled task data D Input: pre-trained Transformer modelM,\nsoftmax estimation model S 1 M̂ ←M (S, ReLU)\n// replace GELU and Softmax 2 while not done do 3 sample batches (xi, yi) from D 4 let (xi, yi) optimize M̂ with S frozen\nend 5 M̃ ← M̂ ⊕ Ñ\n// add the layernorm approximation 6 while not done do 7 sample batches (xi, yi) from D 8 freeze the parameters of M̃ except Ñ 9 compute k-th layernorm output Ok, Õk\n10 compute loss `k = MSELoss(Ok, Õk) 11 update Ñ with loss L = ∑ k `k\nend 12 M̄ ← M̃ N\n// discard the origin layernorm return M̄\ndeployment. The two-stage optimization of algorithm 1 aims to find the best approximation checkpoint. For computation efficiency, pre-trained models can also be fine-tuned together with the layernorm approximation, and it needs only a single optimization loop. We will discuss the schedule of the different approximation workflow in Sec 4.6. There are three major non-polynomial functions in the transformer block, where we will study in detail."
    }, {
      "heading" : "3.1.1 Gaussion Error Linear Units (GLEU)",
      "text" : "With a computation of Gaussian error, Gaussian Error Linear Units (GLEUs) (Hendrycks and Gimpel, 2020) is not suitable to serve as an active function in HE state. The Gaussian kernel includes unsupported functions like exponential. While in the implementation of the transformer, GELU is defined as a fast approximated version, where the tanh function is still non-polynomial, unsupported by HE.\nG(x) = 0.5x(1+ tanh[ √\n2/π(x+0.044715x3)]) (2)\nWe illustrate the numerical comparison between GELU and RELU in Figure 3 , where the outputs\nof GELU are very close to RELU. Hence, we propose to replace the GELU layer in the model with a ReLU activation function. Despite the Max function in ReLU, other computations are well supported by HE. To enable the computation of Max, we implement the first key idea, incorporating the user device into the inference. The server will convey ciphertext input to the user for local Max computation. Once received the connection, a user device decrypts the ciphertext input and calls the local Max function to get the results and return re-encrypted results to the server. Despite the communication cost, no plaintext is leaked during the TLS connection and semantic security is guaranteed."
    }, {
      "heading" : "3.1.2 Softmax",
      "text" : "The second non-polynomial function is softmax, which includes the exponential and division computation.\nSoftmax(xi) = exp(xi)∑ j exp(xj)\n(3)\nThe first thought to approximate softmax is to\nfind alternatives of softmax operation in transformer, which include Taylor series approximation (Vincent et al., 2014), softmax-free linear attention (Lu et al., 2021). However, both of them have some limitations. The Taylor series approximation can only approximate the exponential operation. Softmax-free linear attention utilizes newtoninverse to approximate division, but the approximation error is unbounded in full-scale attention settings.\nFor these considerations, we have no choice but to design an estimation network with addition and multiplication.\nS(xi) = xi ∗ T ( ∑ j ReLU(((xj)/2 + 1) 3)) (4)\nEquation 4 is the formal description of our softmax estimation network. Same as the approximation of GELU, ReLU operation here is realized by communication with the client. Instead of a division operation, we approximate reciprocal operation with a three-layer linear neural network denoted as T .\nTo get a better estimation of softmax, we randomly generate input tensors whose values are between [−3, 3] and use their softmax scores as MSE targets. Then we optimize the T for 100k steps with a learning rate of 1e-3 until the MSE loss drop down to 1e-6.\nAn under-explored problem here is the Infinite value of Masked Attention, where the input of softmax is always the masked attention scores. To prevent the attention of masked tokens, the origin transformer model fills the masked attention scores with negative infinity before softmax. When fed with an infinite value, the softmax estimation model may face numerical disaster. We will discuss this\nphenomenon and the corresponding solution in Sec 4.5."
    }, {
      "heading" : "3.1.3 LayerNorm",
      "text" : "Recall that the layer normalization (Ba et al., 2016) in transformer is implemented over a mini-batch of inputs, which could be formulated as:\ny = x− E[x]√ V ar[x] + ∗ γ + β (5)\nThe mean and standard deviation are calculated over division operations where the approximation is needed. γ and β are learnable affine transform parameters. To avoid the introduction of new parameters, we keep the learnable parameters while leaving the mean and standard deviation achieved by regression.\nŷ = x ◦ γ + β (6)\nThe new parameter γ predicts the value of standard deviation by regression from origin γ̂. We find the simple linear replacement is enough for values with a small scale of bias. Here γ, β ∈ R and ◦ denotes the Hadamard product.\nThe layer normalization will be applied in each multi-head attention block and after the output dense layer. So the approximation error tends to accumulate when the transformer stacks with too many layers.\nWe treat the layernorm approximation as an individual stage in Figure 1 as LN-Distill to learn from origin LN layers. A challenge here is the Attention Overflow, where the input attention score before normalization may have an unbounded scale, leading to numerical problems. We will discuss the detail of Attention Overflow in Sec 4.5."
    }, {
      "heading" : "3.1.4 Other Practical Replacement",
      "text" : "After the approximation workflow, a fine-tuned model consists of only addition and multiplication operations, which is fully compatible with homomorphic encryption. We power the model by HE transformer backend. Since the HE transformer backend could only work for TensorFlow checkpoint, any pre-trained transformers inherited from PyTorch building version need to be converted into TensorFlow format first. There are some other details worth mentioning here.\n• For the softmax(QK T\n√ dk )V operation in attention score computation, we absorb the value\nof 1√ dk into the weights of query projection layer.\n• We use a fully kernel convolution layer instead of linear projection due to the lack of supported dense operation.\n• All matrix multiplication will be converted into the element-wise style.\n• We drop the pooler layer for the unsupported operation of tanh."
    }, {
      "heading" : "3.2 Privacy-preserving Inference",
      "text" : "In this section, we describe the behavior of HE models during privacy-preserving inference. Note that inference is completed by the joint effort of the server and the user device.\nAlgorithm 2: Inference with HE Input: user plain text query Pq, private key\nK generated under server protocol, encrypted server modelM\n1 client computes embeddings: Eq ← Pq 2 client encrypts query embeddings: Cq ← Encrypt(Eq,K) 3 server forwards the model: Ci =M(Cq) 4 client handles activation: Ca = ReLU(Ci) 5 server continues forwarding: Co =M(Ca) 6 client decrypts results: Po = Decrypt(Co,K)\nIn Algorithm 2, notably absent is the support of ReLU operations, where the server exchanges the activation results with the client. However, all the communication between client and server is in ciphertext, ensuring the privacy of user queries and may prevent eavesdropping attackers from recovering private text data."
    }, {
      "heading" : "4 Experiments",
      "text" : "In this section, we design both sequence-level and token-level tasks to evaluate the approximation performance of our THE-X solution. We also discuss several identified factors which greatly affect approximation workflow."
    }, {
      "heading" : "4.1 Evaluation Tasks",
      "text" : "GLUE (Wang et al., 2018), the General Language Understanding Evaluation benchmark, is a collection of tools for evaluating the performance of models across a diverse set of existing NLU tasks.\nWe choose a subset of GLUE1 tasks, which include: MRPC (Dolan and Brockett, 2005), SST2 (Socher et al., 2013), QQP2, STS-B (Cer et al., 2017), MNLI (Williams et al., 2017), QNLI (Rajpurkar et al., 2016), and RTE (Dagan et al., 2005; Haim et al., 2006; Giampiccolo et al., 2007; Bentivogli et al., 2009).\nFollowing previous work (Devlin et al., 2018; Turc et al., 2019), we exclude the WNLI task from the GLUE benchmark. We also use the famous CoNLL-2003 (Sang and De Meulder, 2003) named entity recognition task as our additional token-level evaluation. In conclusion, we include the most varieties of NLU tasks, covering both sequencelevel and sentence-level tasks, in both regression and classification format."
    }, {
      "heading" : "4.2 Experiment Settings",
      "text" : "For computation efficiency and energy-saving consideration, we use the released BERT-tiny (Turc\n1CoLA task is not reported because of the limited capacity of BERT-tiny.\n2https://www.quora.com/profile/Ricky-Riche-2/FirstQuora-Dataset-Release-Question-Pairs\net al., 2019) as our demo model, which is a standard transformer-based language model with only 2 layers and a hidden size of 128. We provide four settings to evaluate different parts of our approximation components.\n• Baseline. In this setting, we make no replacement or approximation. We use the raw pretrained checkpoint to fine-tune on downstream tasks.\n• ReLU. We fine-tune the pre-trained model with all GELU activation replaced with ReLU.\n• ReLU-S. In addition to ReLU, we fine-tune the model with the softmax operation replaced by the softmax estimation model.\n• ReLU-S-L. We implement full approximation including a layer normalization replacement.\n• HE. We convert the fine-tuned checkpoint with HE-transformer and power the inference with SEAL backend.\nImplementation. To reduce the variance of results under different settings, we choose hyperparameters from a fixed set during approximation fine-tuning and HE inference runtime.\n• For fine-tuning the approximation components, we choose a batch size from {4, 8, 16, 32, 128} and a learning rate from 1e-4, 3e4, 3e-5, 5e-5 as mentioned in the initial bert code (Turc et al., 2019). We use an Adam optimizer with weight decay chosen from {0.05, 0.1, 0.2, 0.4, 0.5}\n• For HE evaluation, we use the HE-transformer backend, where two parameters are recommended searching by Intel, the poly modules\nand coeff-modules. We choose the poly modules degree from {1024, 2048, 4096, 8192, 16384} and choose the coeff-modules from {20, 30, 60}."
    }, {
      "heading" : "4.3 Approximation Results",
      "text" : "Table 1 shows the results of the baseline and THEX on the GLUE benchmark. The averaged performance reduction of THE-X is 1.48% when compared to the baseline model. We observe the most performance reduction comes from the approximation of layernorm, which incurs a reduction of 1.08%. The softmax estimation model contributes the least performance drop among the approximation components, for only 0.09% on average, indicating the softmax function could be well imitated by neural networks. We also find the average performance reduction of HE is quite negligible, where the slight drop may be due to the sequence truncation.\nThe results of THE-X on token-level NER task are reported in Table 2. The replacement of GELU with ReLU even improves the performance of the F1 score. We assume the slight improvement may come from unexpected bias. However, the layernorm approximation incurs the most performance reduction. We assume token-level tasks need a more detailed pattern in attention score. After all, THE-X still works well in the token-level task with a merely F1 reduction of 1.9%.\nAcross different types of tasks, we find our THEX yields the best performance on the classification tasks, including paraphrase, sentiment and NLI. Among the classification tasks, the performance of QNLI drops the least, for only 0.18%. We also find the performance drops most on the regression tasks, such as the similarity task STS-B, for 4.44% pearson correlation and 2.69% spearman correlation. We assume the regression task needs a higher numerical precision than the classification task."
    }, {
      "heading" : "4.4 Negative Infinity",
      "text" : "Recall in Equation 4, we replace softmax with a neural estimation model. To prevent the attention of masked tokens, the origin transformer model fills the masked attention scores with negative infinity before softmax, where the numerical disaster occurs in our approximation method. In Figure 4, to solve this problem, we give an empirical study of how \"negative\" the masked attention scores should be. Despite the indistinguishable F1 score change of raw model fine-tune with different\nattention mask values, the approximation method is extremely sensitive to the numerical changes. We assume the softmax estimation model fails to deal with large input values and leads to a credible performance drop. However, when the value of the attention mask becomes too small, it serves as a bias to attention scores, which also leads to a certain performance drop. We recommend using a moderate mask value between -2 and -5."
    }, {
      "heading" : "4.5 Attention Overflow",
      "text" : "Another challenge of THE-X is the attention score input of layer normalization. In most cases, the scale of multi-head attention output is very dense around [−1, 1]. However, before normalization, we also observe the attention scores are scarily sparse, with some extreme values reaching 1e4, which is difficult for our LN-distill stage. To prevent the overflow attention scores, we use the weight decay of Adam optimizer as regularization.\nIn Figure 5, we present the attention overflow phenomenon across different tasks. Without any regularization, our approximation method yields uncontrolled attention scores, leading to poor performance. As the weight decay increases, the attention scores tend to converge and benefit better approximation results. We also observe that the larger weight decay may harm the performance on NLI tasks, where the regularization could be seen as trade-off between better approximation results and higher performance upper bound. For the NER task, larger weight decay may even benefit the performance and also boost our approximation method."
    }, {
      "heading" : "4.6 Schedule of Approximation workflow",
      "text" : "There are still doubts about how to organize the several optimization steps for the best approximation performance. We investigate four schedule plans:\n• Two Stages. Where we freeze the softmax estimation model during standard fine-tuning. We select the best checkpoint to implement the second stage - distill the layer normalization network.\n• Joint FT S. We optimize the softmax estimation model during standard fine-tuning and apply the LN-distillation after.\n• Joint FT LN. We apply one-pass optimization with the softmax estimation model frozen but update the other parameters including layer normalization network. No further LNdistill will be implemented.\n• Joint FT S + LN. A total one-pass optimization with all approximation parameters updated with the model together.\nAs illustrated in Figure 6, we observe that finetuning the different approximation components individually (aka. \"Two stages\") may be a good default to keep the best performance of approximation. For the regression task STS-B, jointly finetuning the softmax estimation model and approximated layernorm even fails to fulfill the approximation pipeline, pulling the performance down to 0.4%. We assume fine-tuning different components may fall into a bi-level optimization problem and\nit is hard to achieve satisfying results. In conclusion, the softmax estimation model and the approximated layernorm are both critical components to the performance of THE-X, deserving individual optimization."
    }, {
      "heading" : "5 Conclusions",
      "text" : "We present THE-X, a practical approach to enable pre-trained transformer models to infer under homomorphic encryption. It requires several approximation components to replace the original operations in the transformer model. It imposes a slight burden in terms of performance cost but enjoys the full advantage of homomorphic encryption - the theory-guaranteed user privacy.\nWe see this as a first step in combing homomorphic encryption to address emerging privacy issues in pre-trained models. We hope our work motivates further research, including better approximation solutions on different NLP applications."
    } ],
    "references" : [ {
      "title" : "Deep learning with differential privacy",
      "author" : [ "Martin Abadi", "Andy Chu", "Ian Goodfellow", "H Brendan McMahan", "Ilya Mironov", "Kunal Talwar", "Li Zhang." ],
      "venue" : "Proceedings of the 2016 ACM SIGSAC conference on computer and communications security,",
      "citeRegEx" : "Abadi et al\\.,? 2016",
      "shortCiteRegEx" : "Abadi et al\\.",
      "year" : 2016
    }, {
      "title" : "Layer normalization",
      "author" : [ "Jimmy Lei Ba", "Jamie Ryan Kiros", "Geoffrey E Hinton." ],
      "venue" : "arXiv preprint arXiv:1607.06450.",
      "citeRegEx" : "Ba et al\\.,? 2016",
      "shortCiteRegEx" : "Ba et al\\.",
      "year" : 2016
    }, {
      "title" : "Privacy enabled financial text classification using differential privacy and federated learning",
      "author" : [ "Priyam Basu", "Tiasa Singha Roy", "Rakshit Naidu", "Zumrut Muftuoglu." ],
      "venue" : "arXiv preprint arXiv:2110.01643.",
      "citeRegEx" : "Basu et al\\.,? 2021a",
      "shortCiteRegEx" : "Basu et al\\.",
      "year" : 2021
    }, {
      "title" : "Benchmarking differential privacy and federated learning for bert models",
      "author" : [ "Priyam Basu", "Tiasa Singha Roy", "Rakshit Naidu", "Zumrut Muftuoglu", "Sahib Singh", "Fatemehsadat Mireshghallah." ],
      "venue" : "arXiv preprint arXiv:2106.13973.",
      "citeRegEx" : "Basu et al\\.,? 2021b",
      "shortCiteRegEx" : "Basu et al\\.",
      "year" : 2021
    }, {
      "title" : "The fifth pascal recognizing textual entailment challenge",
      "author" : [ "Luisa Bentivogli", "Peter Clark", "Ido Dagan", "Danilo Giampiccolo." ],
      "venue" : "TAC.",
      "citeRegEx" : "Bentivogli et al\\.,? 2009",
      "shortCiteRegEx" : "Bentivogli et al\\.",
      "year" : 2009
    }, {
      "title" : "Mp2ml: a mixed-protocol machine learning framework for private inference",
      "author" : [ "Fabian Boemer", "Rosario Cammarota", "Daniel Demmler", "Thomas Schneider", "Hossein Yalame." ],
      "venue" : "Proceedings of the 15th International Conference on Availability, Relia-",
      "citeRegEx" : "Boemer et al\\.,? 2020",
      "shortCiteRegEx" : "Boemer et al\\.",
      "year" : 2020
    }, {
      "title" : "ngraphhe2: A high-throughput framework for neural network inference on encrypted data",
      "author" : [ "Fabian Boemer", "Anamaria Costache", "Rosario Cammarota", "Casimir Wierzynski." ],
      "venue" : "Proceedings of the 7th ACM Workshop on Encrypted Computing",
      "citeRegEx" : "Boemer et al\\.,? 2019a",
      "shortCiteRegEx" : "Boemer et al\\.",
      "year" : 2019
    }, {
      "title" : "ngraph-he: a graph compiler for deep learning on homomorphically encrypted data",
      "author" : [ "Fabian Boemer", "Yixing Lao", "Rosario Cammarota", "Casimir Wierzynski." ],
      "venue" : "Proceedings of the 16th ACM International Conference on Computing Frontiers, pages",
      "citeRegEx" : "Boemer et al\\.,? 2019b",
      "shortCiteRegEx" : "Boemer et al\\.",
      "year" : 2019
    }, {
      "title" : "Language models are few-shot learners. arXiv preprint arXiv:2005.14165",
      "author" : [ "Tom B Brown", "Benjamin Mann", "Nick Ryder", "Melanie Subbiah", "Jared Kaplan", "Prafulla Dhariwal", "Arvind Neelakantan", "Pranav Shyam", "Girish Sastry", "Amanda Askell" ],
      "venue" : null,
      "citeRegEx" : "Brown et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Brown et al\\.",
      "year" : 2020
    }, {
      "title" : "Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation",
      "author" : [ "Daniel Cer", "Mona Diab", "Eneko Agirre", "Inigo LopezGazpio", "Lucia Specia." ],
      "venue" : "arXiv preprint arXiv:1708.00055.",
      "citeRegEx" : "Cer et al\\.,? 2017",
      "shortCiteRegEx" : "Cer et al\\.",
      "year" : 2017
    }, {
      "title" : "Homomorphic encryption for arithmetic of approximate numbers",
      "author" : [ "Jung Hee Cheon", "Andrey Kim", "Miran Kim", "Yongsoo Song." ],
      "venue" : "International",
      "citeRegEx" : "Cheon et al\\.,? 2017",
      "shortCiteRegEx" : "Cheon et al\\.",
      "year" : 2017
    }, {
      "title" : "Secure secondary use of clinical data with cloud-based nlp services",
      "author" : [ "J Christoph", "L Griebel", "I Leb", "I Engel", "F Köpcke", "D Toddenroth", "H-U Prokosch", "J Laufer", "K Marquardt", "M Sedlmayr." ],
      "venue" : "Methods of information in medicine, 54(03):276–",
      "citeRegEx" : "Christoph et al\\.,? 2015",
      "shortCiteRegEx" : "Christoph et al\\.",
      "year" : 2015
    }, {
      "title" : "The pascal recognising textual entailment challenge",
      "author" : [ "Ido Dagan", "Oren Glickman", "Bernardo Magnini." ],
      "venue" : "Machine Learning Challenges Workshop, pages 177–190. Springer.",
      "citeRegEx" : "Dagan et al\\.,? 2005",
      "shortCiteRegEx" : "Dagan et al\\.",
      "year" : 2005
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "Automatically constructing a corpus of sentential paraphrases",
      "author" : [ "William B Dolan", "Chris Brockett." ],
      "venue" : "Proceedings of the Third International Workshop on Paraphrasing (IWP2005).",
      "citeRegEx" : "Dolan and Brockett.,? 2005",
      "shortCiteRegEx" : "Dolan and Brockett.",
      "year" : 2005
    }, {
      "title" : "Calibrating noise to sensitivity in private data analysis",
      "author" : [ "Cynthia Dwork", "Frank McSherry", "Kobbi Nissim", "Adam Smith." ],
      "venue" : "Theory of cryptography conference, pages 265–284. Springer.",
      "citeRegEx" : "Dwork et al\\.,? 2006",
      "shortCiteRegEx" : "Dwork et al\\.",
      "year" : 2006
    }, {
      "title" : "Generalised differential privacy for text document processing",
      "author" : [ "Natasha Fernandes", "Mark Dras", "Annabelle McIver." ],
      "venue" : "International Conference on Principles of Security and Trust, pages 123–148. Springer, Cham.",
      "citeRegEx" : "Fernandes et al\\.,? 2019",
      "shortCiteRegEx" : "Fernandes et al\\.",
      "year" : 2019
    }, {
      "title" : "Fully homomorphic encryption using ideal lattices",
      "author" : [ "Craig Gentry." ],
      "venue" : "Proceedings of the forty-first annual ACM symposium on Theory of computing, pages 169–178.",
      "citeRegEx" : "Gentry.,? 2009",
      "shortCiteRegEx" : "Gentry.",
      "year" : 2009
    }, {
      "title" : "The third pascal recognizing textual entailment challenge",
      "author" : [ "Danilo Giampiccolo", "Bernardo Magnini", "Ido Dagan", "William B Dolan." ],
      "venue" : "Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing, pages 1–9.",
      "citeRegEx" : "Giampiccolo et al\\.,? 2007",
      "shortCiteRegEx" : "Giampiccolo et al\\.",
      "year" : 2007
    }, {
      "title" : "The second pascal recognising textual entailment challenge",
      "author" : [ "R Bar Haim", "Ido Dagan", "Bill Dolan", "Lisa Ferro", "Danilo Giampiccolo", "Bernardo Magnini", "Idan Szpektor." ],
      "venue" : "Proceedings of the Second PASCAL Challenges Workshop on Recognising Textual",
      "citeRegEx" : "Haim et al\\.,? 2006",
      "shortCiteRegEx" : "Haim et al\\.",
      "year" : 2006
    }, {
      "title" : "Gaussian error linear units (gelus)",
      "author" : [ "Dan Hendrycks", "Kevin Gimpel." ],
      "venue" : "arXiv preprint arXiv:1606.08415.",
      "citeRegEx" : "Hendrycks and Gimpel.,? 2016",
      "shortCiteRegEx" : "Hendrycks and Gimpel.",
      "year" : 2016
    }, {
      "title" : "Gaussian error linear units (gelus)",
      "author" : [ "Dan Hendrycks", "Kevin Gimpel" ],
      "venue" : null,
      "citeRegEx" : "Hendrycks and Gimpel.,? \\Q2020\\E",
      "shortCiteRegEx" : "Hendrycks and Gimpel.",
      "year" : 2020
    }, {
      "title" : "Texthide: Tackling data privacy in language understanding tasks",
      "author" : [ "Yangsibo Huang", "Zhao Song", "Danqi Chen", "Kai Li", "Sanjeev Arora." ],
      "venue" : "arXiv preprint arXiv:2010.06053.",
      "citeRegEx" : "Huang et al\\.,? 2020",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2020
    }, {
      "title" : "Differentially private language models benefit from public pre-training",
      "author" : [ "Gavin Kerrigan", "Dylan Slack", "Jens Tuyls." ],
      "venue" : "arXiv preprint arXiv:2009.05886.",
      "citeRegEx" : "Kerrigan et al\\.,? 2020",
      "shortCiteRegEx" : "Kerrigan et al\\.",
      "year" : 2020
    }, {
      "title" : "Fednlp: A research platform for federated learning in natural language processing",
      "author" : [ "Bill Yuchen Lin", "Chaoyang He", "Zihang Zeng", "Hulin Wang", "Yufen Huang", "Mahdi Soltanolkotabi", "Xiang Ren", "Salman Avestimehr." ],
      "venue" : "arXiv preprint",
      "citeRegEx" : "Lin et al\\.,? 2021",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2021
    }, {
      "title" : "Soft: Softmax-free transformer with linear complexity",
      "author" : [ "Jiachen Lu", "Jinghan Yao", "Junge Zhang", "Xiatian Zhu", "Hang Xu", "Weiguo Gao", "Chunjing Xu", "Tao Xiang", "Li Zhang" ],
      "venue" : null,
      "citeRegEx" : "Lu et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Lu et al\\.",
      "year" : 2021
    }, {
      "title" : "Differentially private representation for nlp: Formal guarantee and an empirical study on privacy and fairness",
      "author" : [ "Lingjuan Lyu", "Xuanli He", "Yitong Li." ],
      "venue" : "arXiv preprint arXiv:2010.01285.",
      "citeRegEx" : "Lyu et al\\.,? 2020",
      "shortCiteRegEx" : "Lyu et al\\.",
      "year" : 2020
    }, {
      "title" : "Natural language understanding with privacy-preserving bert",
      "author" : [ "Chen Qu", "Weize Kong", "Liu Yang", "Mingyang Zhang", "Michael Bendersky", "Marc Najork." ],
      "venue" : "Proceedings of the 30th ACM International Conference on Information & Knowledge Manage-",
      "citeRegEx" : "Qu et al\\.,? 2021",
      "shortCiteRegEx" : "Qu et al\\.",
      "year" : 2021
    }, {
      "title" : "Exploring the limits of transfer learning with a unified text-to-text transformer",
      "author" : [ "Colin Raffel", "Noam Shazeer", "Adam Roberts", "Katherine Lee", "Sharan Narang", "Michael Matena", "Yanqi Zhou", "Wei Li", "Peter J Liu." ],
      "venue" : "arXiv preprint arXiv:1910.10683.",
      "citeRegEx" : "Raffel et al\\.,? 2019",
      "shortCiteRegEx" : "Raffel et al\\.",
      "year" : 2019
    }, {
      "title" : "Squad: 100,000+ questions for machine comprehension of text",
      "author" : [ "Pranav Rajpurkar", "Jian Zhang", "Konstantin Lopyrev", "Percy Liang." ],
      "venue" : "arXiv preprint arXiv:1606.05250.",
      "citeRegEx" : "Rajpurkar et al\\.,? 2016",
      "shortCiteRegEx" : "Rajpurkar et al\\.",
      "year" : 2016
    }, {
      "title" : "Introduction to the conll-2003 shared task: Languageindependent named entity recognition",
      "author" : [ "Erik F Sang", "Fien De Meulder." ],
      "venue" : "arXiv preprint cs/0306050.",
      "citeRegEx" : "Sang and Meulder.,? 2003",
      "shortCiteRegEx" : "Sang and Meulder.",
      "year" : 2003
    }, {
      "title" : "The pii problem: Privacy and a new concept of personally identifiable information",
      "author" : [ "Paul M Schwartz", "Daniel J Solove." ],
      "venue" : "NYUL rev., 86:1814.",
      "citeRegEx" : "Schwartz and Solove.,? 2011",
      "shortCiteRegEx" : "Schwartz and Solove.",
      "year" : 2011
    }, {
      "title" : "Privacy protection in personalized search",
      "author" : [ "Xuehua Shen", "Bin Tan", "ChengXiang Zhai." ],
      "venue" : "ACM SIGIR Forum, volume 41, pages 4–17. ACM New York, NY, USA.",
      "citeRegEx" : "Shen et al\\.,? 2007",
      "shortCiteRegEx" : "Shen et al\\.",
      "year" : 2007
    }, {
      "title" : "Recursive deep models for semantic compositionality over a sentiment treebank",
      "author" : [ "Richard Socher", "Alex Perelygin", "Jean Wu", "Jason Chuang", "Christopher D Manning", "Andrew Y Ng", "Christopher Potts." ],
      "venue" : "Proceedings of the 2013 conference on",
      "citeRegEx" : "Socher et al\\.,? 2013",
      "shortCiteRegEx" : "Socher et al\\.",
      "year" : 2013
    }, {
      "title" : "Well-read students learn better: On the importance of pre-training compact models",
      "author" : [ "Iulia Turc", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1908.08962.",
      "citeRegEx" : "Turc et al\\.,? 2019",
      "shortCiteRegEx" : "Turc et al\\.",
      "year" : 2019
    }, {
      "title" : "Efficient exact gradient update for training deep networks with very large sparse targets",
      "author" : [ "Pascal Vincent", "Alexandre De Brébisson", "Xavier Bouthillier." ],
      "venue" : "arXiv preprint arXiv:1412.7091.",
      "citeRegEx" : "Vincent et al\\.,? 2014",
      "shortCiteRegEx" : "Vincent et al\\.",
      "year" : 2014
    }, {
      "title" : "Glue: A multi-task benchmark and analysis platform for natural language understanding",
      "author" : [ "Alex Wang", "Amanpreet Singh", "Julian Michael", "Felix Hill", "Omer Levy", "Samuel R Bowman." ],
      "venue" : "arXiv preprint arXiv:1804.07461.",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "A broad-coverage challenge corpus for sentence understanding through inference",
      "author" : [ "Adina Williams", "Nikita Nangia", "Samuel R Bowman." ],
      "venue" : "arXiv preprint arXiv:1704.05426.",
      "citeRegEx" : "Williams et al\\.,? 2017",
      "shortCiteRegEx" : "Williams et al\\.",
      "year" : 2017
    }, {
      "title" : "Bert post-training for review reading comprehension and aspect-based sentiment analysis",
      "author" : [ "Hu Xu", "Bing Liu", "Lei Shu", "Philip S Yu." ],
      "venue" : "arXiv preprint arXiv:1904.02232.",
      "citeRegEx" : "Xu et al\\.,? 2019a",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2019
    }, {
      "title" : "Understanding and improving layer normalization",
      "author" : [ "Jingjing Xu", "Xu Sun", "Zhiyuan Zhang", "Guangxiang Zhao", "Junyang Lin." ],
      "venue" : "arXiv preprint arXiv:1911.07013.",
      "citeRegEx" : "Xu et al\\.,? 2019b",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2019
    }, {
      "title" : "Federated learning",
      "author" : [ "Qiang Yang", "Yang Liu", "Yong Cheng", "Yan Kang", "Tianjian Chen", "Han Yu." ],
      "venue" : "Synthesis Lectures on Artificial Intelligence and Machine Learning, 13(3):1–207.",
      "citeRegEx" : "Yang et al\\.,? 2019a",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "End-to-end open-domain question answering with bertserini",
      "author" : [ "Wei Yang", "Yuqing Xie", "Aileen Lin", "Xingyu Li", "Luchen Tan", "Kun Xiong", "Ming Li", "Jimmy Lin." ],
      "venue" : "arXiv preprint arXiv:1902.01718.",
      "citeRegEx" : "Yang et al\\.,? 2019b",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "Simple applications of bert for ad hoc document retrieval",
      "author" : [ "Wei Yang", "Haotian Zhang", "Jimmy Lin." ],
      "venue" : "arXiv preprint arXiv:1903.10972.",
      "citeRegEx" : "Yang et al\\.,? 2019c",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "idlg: Improved deep leakage from gradients",
      "author" : [ "Bo Zhao", "Konda Reddy Mopuri", "Hakan Bilen." ],
      "venue" : "arXiv preprint arXiv:2001.02610.",
      "citeRegEx" : "Zhao et al\\.,? 2020",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2020
    }, {
      "title" : "Deep leakage from gradients",
      "author" : [ "Ligeng Zhu", "Song Han." ],
      "venue" : "Federated learning, pages 17–31. Springer.",
      "citeRegEx" : "Zhu and Han.,? 2020",
      "shortCiteRegEx" : "Zhu and Han.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 38,
      "context" : "Accompanying the revolution of pre-trained models in many NLP applications, such as sentiment analysis (Xu et al., 2019a), question answering (Yang et al.",
      "startOffset" : 103,
      "endOffset" : 121
    }, {
      "referenceID" : 41,
      "context" : ", 2019a), question answering (Yang et al., 2019b), information retrieval (Yang et al.",
      "startOffset" : 29,
      "endOffset" : 49
    }, {
      "referenceID" : 42,
      "context" : ", 2019b), information retrieval (Yang et al., 2019c), and text generation (Raffel et al.",
      "startOffset" : 32,
      "endOffset" : 52
    }, {
      "referenceID" : 28,
      "context" : ", 2019c), and text generation (Raffel et al., 2019), many related technologies have been deployed on the cloud to process user data from personal customers, small businesses, and large enterprises by industrial service providers.",
      "startOffset" : 30,
      "endOffset" : 51
    }, {
      "referenceID" : 31,
      "context" : "vector representations in user requests can leak private information, which may cause the specific user to be identified (Schwartz and Solove, 2011; Zhu and Han, 2020).",
      "startOffset" : 121,
      "endOffset" : 167
    }, {
      "referenceID" : 44,
      "context" : "vector representations in user requests can leak private information, which may cause the specific user to be identified (Schwartz and Solove, 2011; Zhu and Han, 2020).",
      "startOffset" : 121,
      "endOffset" : 167
    }, {
      "referenceID" : 15,
      "context" : "Prior work has applied Differential Privacy (DP) (Dwork et al., 2006) and its variants to address similar privatization issues - originally for statistical databases and more recently for DL (Abadi et al.",
      "startOffset" : 49,
      "endOffset" : 69
    }, {
      "referenceID" : 0,
      "context" : ", 2006) and its variants to address similar privatization issues - originally for statistical databases and more recently for DL (Abadi et al., 2016) and NLP (Qu et al.",
      "startOffset" : 129,
      "endOffset" : 149
    }, {
      "referenceID" : 44,
      "context" : "A handful of research (Zhu and Han, 2020; Zhao et al., 2020) demonstrated it possible to recover raw data from gradient leakage.",
      "startOffset" : 22,
      "endOffset" : 60
    }, {
      "referenceID" : 43,
      "context" : "A handful of research (Zhu and Han, 2020; Zhao et al., 2020) demonstrated it possible to recover raw data from gradient leakage.",
      "startOffset" : 22,
      "endOffset" : 60
    }, {
      "referenceID" : 22,
      "context" : "The second challenge is the performance concern, recent works like TextHide (Huang et al., 2020) and FedNLP (Lin et al.",
      "startOffset" : 76,
      "endOffset" : 96
    }, {
      "referenceID" : 24,
      "context" : ", 2020) and FedNLP (Lin et al., 2021) leverages the federated learning (Yang et al.",
      "startOffset" : 19,
      "endOffset" : 37
    }, {
      "referenceID" : 40,
      "context" : ", 2021) leverages the federated learning (Yang et al., 2019a) to train model on encrypted data, at cost of considerable performance dropping.",
      "startOffset" : 41,
      "endOffset" : 61
    }, {
      "referenceID" : 17,
      "context" : "In addition, we need a theory-guaranteed encryption solution like the homomorphic encryption (HE) (Gentry, 2009) to convince both service providers and users of the privacy security in production scenarios.",
      "startOffset" : 98,
      "endOffset" : 112
    }, {
      "referenceID" : 36,
      "context" : "We evaluate THE-X for BERTtiny on the GLUE benchmark (Wang et al., 2018) and the CONLL2003 task (Sang and De Meulder, 2003).",
      "startOffset" : 53,
      "endOffset" : 72
    }, {
      "referenceID" : 13,
      "context" : "Pre-trained models like BERT (Devlin et al., 2018) and GPT-3 (Brown et al.",
      "startOffset" : 29,
      "endOffset" : 50
    }, {
      "referenceID" : 8,
      "context" : ", 2018) and GPT-3 (Brown et al., 2020) rely heavily on the use of plain text data to get human-like performance.",
      "startOffset" : 18,
      "endOffset" : 38
    }, {
      "referenceID" : 11,
      "context" : "Despite the remarkable achievements of pre-trained models, these state-of-the-art models can not directly answer some sensitive use cases, including the medical record (Christoph et al., 2015), search history (Shen et al.",
      "startOffset" : 168,
      "endOffset" : 192
    }, {
      "referenceID" : 32,
      "context" : ", 2015), search history (Shen et al., 2007) and other personally identifiable information (PII).",
      "startOffset" : 24,
      "endOffset" : 43
    }, {
      "referenceID" : 22,
      "context" : "To avoid the direct computation on plain-text data, recent works like TextHide (Huang et al., 2020) and DP-finetuning (Kerrigan et al.",
      "startOffset" : 79,
      "endOffset" : 99
    }, {
      "referenceID" : 23,
      "context" : ", 2020) and DP-finetuning (Kerrigan et al., 2020) introduce the classical federated learning and differential privacy (DP) to protect the sensitive data.",
      "startOffset" : 26,
      "endOffset" : 49
    }, {
      "referenceID" : 22,
      "context" : "However, TextHide (Huang et al., 2020) can only be applied to sentence-level tasks.",
      "startOffset" : 18,
      "endOffset" : 38
    }, {
      "referenceID" : 10,
      "context" : "Currently, it supports the CKKS (Cheon et al., 2017) encryption scheme, implemented by the Simple Encrypted Arithmetic Library (SEAL) (SEAL) from Microsoft Research.",
      "startOffset" : 32,
      "endOffset" : 52
    }, {
      "referenceID" : 20,
      "context" : "Note that composing addition and multiplication suffices to construct polynomial functions, and hence polynomial approximations to non-polynomial functions such as GELU (Hendrycks and Gimpel, 2016) or LayerNorm (Xu et al.",
      "startOffset" : 169,
      "endOffset" : 197
    }, {
      "referenceID" : 39,
      "context" : "Note that composing addition and multiplication suffices to construct polynomial functions, and hence polynomial approximations to non-polynomial functions such as GELU (Hendrycks and Gimpel, 2016) or LayerNorm (Xu et al., 2019b).",
      "startOffset" : 211,
      "endOffset" : 229
    }, {
      "referenceID" : 21,
      "context" : "With a computation of Gaussian error, Gaussian Error Linear Units (GLEUs) (Hendrycks and Gimpel, 2020) is not suitable to serve as an active function in HE state.",
      "startOffset" : 74,
      "endOffset" : 102
    }, {
      "referenceID" : 35,
      "context" : "The first thought to approximate softmax is to find alternatives of softmax operation in transformer, which include Taylor series approximation (Vincent et al., 2014), softmax-free linear attention (Lu et al.",
      "startOffset" : 144,
      "endOffset" : 166
    }, {
      "referenceID" : 25,
      "context" : ", 2014), softmax-free linear attention (Lu et al., 2021).",
      "startOffset" : 39,
      "endOffset" : 56
    }, {
      "referenceID" : 1,
      "context" : "Recall that the layer normalization (Ba et al., 2016) in transformer is implemented over a mini-batch of inputs, which could be formulated as:",
      "startOffset" : 36,
      "endOffset" : 53
    }, {
      "referenceID" : 36,
      "context" : "GLUE (Wang et al., 2018), the General Language Understanding Evaluation benchmark, is a collection of tools for evaluating the performance of models across a diverse set of existing NLU tasks.",
      "startOffset" : 5,
      "endOffset" : 24
    }, {
      "referenceID" : 14,
      "context" : "We choose a subset of GLUE1 tasks, which include: MRPC (Dolan and Brockett, 2005), SST2 (Socher et al.",
      "startOffset" : 55,
      "endOffset" : 81
    }, {
      "referenceID" : 33,
      "context" : "We choose a subset of GLUE1 tasks, which include: MRPC (Dolan and Brockett, 2005), SST2 (Socher et al., 2013), QQP2, STS-B (Cer et al.",
      "startOffset" : 88,
      "endOffset" : 109
    }, {
      "referenceID" : 9,
      "context" : ", 2013), QQP2, STS-B (Cer et al., 2017), MNLI (Williams et al.",
      "startOffset" : 21,
      "endOffset" : 39
    }, {
      "referenceID" : 37,
      "context" : ", 2017), MNLI (Williams et al., 2017), QNLI (Rajpurkar et al.",
      "startOffset" : 14,
      "endOffset" : 37
    }, {
      "referenceID" : 29,
      "context" : ", 2017), QNLI (Rajpurkar et al., 2016), and RTE (Dagan et al.",
      "startOffset" : 14,
      "endOffset" : 38
    }, {
      "referenceID" : 13,
      "context" : "Following previous work (Devlin et al., 2018; Turc et al., 2019), we exclude the WNLI task from the GLUE benchmark.",
      "startOffset" : 24,
      "endOffset" : 64
    }, {
      "referenceID" : 34,
      "context" : "Following previous work (Devlin et al., 2018; Turc et al., 2019), we exclude the WNLI task from the GLUE benchmark.",
      "startOffset" : 24,
      "endOffset" : 64
    }, {
      "referenceID" : 34,
      "context" : "• For fine-tuning the approximation components, we choose a batch size from {4, 8, 16, 32, 128} and a learning rate from 1e-4, 3e4, 3e-5, 5e-5 as mentioned in the initial bert code (Turc et al., 2019).",
      "startOffset" : 181,
      "endOffset" : 200
    } ],
    "year" : 0,
    "abstractText" : "As more and more pre-trained language models adopt on-cloud deployment, the privacy issues grow quickly, mainly for the exposure of plain-text user data (e.g., search history, medical record, bank account). Privacy-preserving inference of transformer models is on the demand of cloud service users. To protect privacy, it is an attractive choice to compute only with ciphertext in homomorphic encryption (HE). However, enabling pre-trained models inference on ciphertext data is difficult due to the complex computations in transformer blocks, which are not supported by current HE tools yet. In this work, we introduce THE-X, an approximation approach for transformers, which enables privacy-preserving inference of pre-trained models developed by popular frameworks. THE-X proposes a workflow to deal with complex computation in transformer networks, including all the non-polynomial functions like GELU, softmax, and LayerNorm. Experiments reveal our proposed THEX can enable transformer inference on encrypted data for different downstream tasks, all with negligible performance drop but enjoying the theory-guaranteed privacy-preserving advantage.",
    "creator" : null
  }
}