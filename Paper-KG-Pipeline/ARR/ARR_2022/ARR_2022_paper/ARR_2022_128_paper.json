{
  "name" : "ARR_2022_128_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Zero-Shot Dependency Parsing with Worst-Case Aware Automated Curriculum Learning",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The field of multilingual NLP is booming (Agirre, 2020). This is due in no small part to large multilingual pretrained language models (PLMs) such as mBERT (Devlin et al., 2019) and XLM-RoBERTa (Conneau et al., 2020), which have been found to have surprising cross-lingual transfer capabilities in spite of receiving no cross-lingual supervision.1 Wu and Dredze (2019), for example, found mBERT to perform well in a zero-shot setting when finetuned for five different NLP tasks in different languages. There is, however, a sharp divide between languages that benefit from this transfer and languages that do not, and there is ample evidence that transfer works best between typologically similar languages (Pires et al., 2019). This means that\n1In the early days, cross-lingual transfer for dependency parsing relied on projection across word alignments (Spreyer and Kuhn, 2009; Agić et al., 2016) or delexicalized transfer of abstract syntactic features (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 2011; Cohen et al., 2011). Delexicalized transfer was later ’re-lexicalized’ by word clusters (Täckström et al., 2012) and word embeddings (Duong et al., 2015), but with the introduction of multilingual contextualized language models, transfer models no longer rely on abstract syntactic features, removing an important bottleneck for transfer approaches to scale to truly low-resource languages.\nthe majority of world languages that are truly lowresource are still left behind and inequalities in access to language technology are increasing.\nLarge multilingual PLMs are typically fine-tuned using training data from a sample of languages that is supposed to be representative of the languages that the models are later applied to. However, this is difficult to achieve in practice, as multilingual datasets are not well balanced for typological diversity and contain a skewed distribution of typological features (Ponti et al., 2021). This problem can be mitigated by using methods that sample from skewed distributions in a way that is robust to outliers.\nZhang et al. (2020) recently developed such a method. It uses curriculum learning with a worst-case-aware loss for multi-task learning. They trained their model on a subset of the GLUE benchmark (Wang et al., 2018) and tested on outlier tasks. This led to improved zero-shot performance on these outlier tasks. This method can be applied to multilingual NLP where different languages are considered different tasks. This is what we do in this work, for the case of multilingual dependency parsing. Multilingual dependency parsing is an ideal test case for this method, as the Universal Dependency treebanks (Nivre et al., 2020) are currently the manually annotated dataset that covers the most typological diversity (Ponti et al., 2021). Our research question can be formulated as such: Can worst-case aware automated curriculum learning improve zero-shot dependency parsing?"
    }, {
      "heading" : "2 Worst-Case-Aware Curriculum Learning",
      "text" : "In multi-task learning, the total loss is generally the average of losses of different tasks:\nmin θ `(θ) = min θ\n1\nn n∑ i=1 `i(θ) (1)\nwhere li is the loss of task i. The architecture we use in this paper is adapted from Zhang et al. (2020), which is an automated curriculum learning (Graves et al., 2017) framework to learn a worstcase-aware loss in a multi-task learning scenario. The architecture consists of a sampler, a buffer, a trainer and a multilingual dependency parsing model. The two main components are the sampler, which adopts a curriculum sampling strategy to dynamically sample data batches, and the trainer which uses worst-case-aware strategy to train the model. The framework repeats the following steps: (1) the sampler samples data batches of different languages to the buffer; (2) the trainer uses a worstcase strategy to train the model; (3) the automated curriculum learning strategy of the sampler is updated.\nSampling data batches We view multilingual dependency parsing as multi-task learning where parsing in each individual language is considered a task. This means that the target of the sampler at each step is to choose a data batch from one language. This is a typical multi-arm bandit problem (Even-Dar et al., 2002). The sampler should choose bandits that have higher rewards, and in our scenario, data batches that have a higher loss on the model are more likely to be selected by the sampler and therefore, in a later stage, used by the trainer. Automated curriculum learning is adopted to push a batch with its loss into the buffer at each time step. The buffer consists of n first-in-first-out queues, and each queue corresponds to a task (in our case, a language). The procedure repeats k times and, at each round, k data batches are pushed into the buffer.\nWorst-case-aware risk minimization In multilingual and multi-task learning scenarios, in which we jointly minimize our risk across n languages or tasks, we are confronted with the question of how to summarize n losses. In other words, the question is how to compare two loss vectors α and β containing losses for all tasks li, . . . ln:\nα = [`11, . . . , ` 1 n]\nand β = [`21, . . . , ` 2 n]\nThe most obvious thing to do is to minimize the mean of the n losses, asking whether ∑ `∈α ` <∑\n`∈β `. We could also, motivated by robustness (Søgaard, 2013) and fairness (Williamson\nand Menon, 2019), minimize the maximum (supremum) of the n losses, asking whether max`∈α ` < max`∈β `. Mehta et al. (2012) observed that these two loss summarizations are extremes that can be generalized by a family of multi-task loss functions that summarize the loss of n tasks as the Lp norm of the n-dimensional loss vector. Minimizing the average loss then corresponds to computing the L1 norm, i.e., asking whether |α|1 < |β|1, and minimizing the worst-case loss corresponds to computing the L∞ (supremum) norm, i.e., asking whether |α|∞ < |β|∞.\nZhang et al. (2020) present a stochastic generalization of the L∞ loss summarization and a practical approach to minimizing this family of losses through automated curriculum learning (Graves et al., 2017): The core idea behind their generalization is to optimize the worst-case loss with a certain probability, otherwise optimize the average (loss-proportional) loss with the remaining probability. The hyperparameter φ is introduced by the worst-case-aware risk minimization to trade off the balance between the worst-case and the lossproportional losses. The loss family is formally defined as:\nmin `(θ) =  min maxi(`i(θ)), p < φmin `ĩ(θ), p ≥ φ, ĩ ∼ P` (2) where p ∈ [0, 1] is a random generated rational\nnumber, and P` = `i∑ j≤n `j\nis the normalized probability distribution of task losses. If p < φ the model choose the maximum loss among all tasks, otherwise, it randomly chooses one loss according to the loss distribution. If the hyperparameter φ equals 1, the trainer updates the model with respect to the worst-case loss. On the contrary, if φ = 0, the trainer loss-proportionally samples one loss.\nSampling strategy updates The model updates its parameters with respect to the loss chosen by the trainer. After that, the sampler updates its policy according to the behavior of the trainer. At each round, the policy of the task that is selected by the trainer receives positive rewards and the policy of all other tasks that have been selected by the sampler receive negative rewards.\nThe multilingual dependency parsing model We use a standard biaffine graph-based dependency parser (Dozat and Manning, 2017). The model takes token representations of words from a contextualized language model (mBERT or XLM-R)\nas input and classifies head and dependency relations between words in the sentence. The Chu-LiuEdmonds algorithm (Chu and Liu, 1965; Edmonds, 1967) is then used to decode the score matrix into a tree. All languages share the same encoder and decoder in order to learn features from different languages, and more importantly to perform zero-shot transfer to unseen languages."
    }, {
      "heading" : "3 Experiments",
      "text" : "We base our experimental design on Üstün et al. (2020), a recent paper doing zero-shot dependency parsing with good performance on a large number of languages. They fine-tune mBERT for dependency parsing using training data from a sample of 13 typologically diverse languages from Universal Dependencies (UD; Nivre et al., 2020), listed in Table 1. For testing, they use 30 test sets from treebanks whose language has not been seen at finetuning time. We use the same training and test sets and experiment both with mBERT and XLM-R as PLMs. It is important to note that not all of the test languages have been seen by the PLMs.\nWe test worst-case aware learning with different values of φ and compare this to three main baselines: size-proportional samples batches proportionally to the data sizes of the training treebanks, uniform samples from different treebanks with equal probability, thereby effectively reducing the size of the training data, and smooth-sampling uses the smooth sampling method developed in van der Goot et al. (2021) which samples from multiple languages using a multinomial distribution. These baselines are competitive with the state-ofthe-art when using mBERT, they are within 0.2 to 0.4 LAS points from the baseline of Üstün et al. (2020) on the same test sets. When using XLM-R, they are largely above the state-of-the-art.\nWe implement all models using MaChAmp (van der Goot et al., 2021), a library for multi-task learning based on AllenNLP (Gardner et al., 2018). The library uses transformers from HuggingFace (Wolf et al., 2020). We make our code publicly available.\nOur main results are in Table 2 where we report average scores across test sets, for space reasons. Tables with results broken down by test treebank can be found in Appendix A. We can see that worstcase-aware training outperforms all of our baselines in the zero-shot setting, highlighting the effectiveness of this method. This answers positively our research question Can worst-case aware automated curriculum learning improve zero-shot dependency parsing?\nOur results using mBERT are more than 1 LAS point above the corresponding baselines. Our best model with mBERT comes close to Udapter (36.5 LAS on the same test sets) while being a lot simpler and not using external resources such as typological features, which are not always available for truly low-resource languages.\nThe results with XLM-R are much higher in general2 but the trends are similar: all our models outperform all of our baselines albeit with smaller differences (there is only a 0.4 LAS difference between our best model and the best baseline). This highlights the robustness of the XLM-R model itself. Our results with XLM-R outperform Udapter by close to 7 LAS points."
    }, {
      "heading" : "4 Varying the homogeneity of training samples",
      "text" : "We investigate the interaction between the effectiveness of worst-case learning and the represen-\n2Note, however, that the results are not directly comparable since different subsets of test languages have been seen by the two PLMs.\ntativeness of the sample of training languages. It is notoriously difficult to construct a sample of treebanks that is representative of the languages in UD (de Lhoneux et al., 2017; Schluter and Agić, 2017; de Lhoneux, 2019). We can, however, easily construct samples that are not representative, for example, by taking a sample of related languages. We expect worst-case aware learning to lead to larger improvements in cases where some language types are underrepresented in the sample. We can construct an extreme case of underrepresentation by selecting a sample of training languages that has one or more clear outliers. For example we can construct a sample of related languages, add a single unrelated language in the mix, and then evaluate on other unrelated languages. We also expect that with a typologically diverse set of training languages, worst-case aware learning should lead to larger relative improvements than with a homogeneous sample, but perhaps slightly smaller improvements than with a very skewed sample.\nWe test these hypotheses by constructing seven samples of training languages in addition to the one used so far (13LANG). We construct three different homogeneous samples using treebanks from three different genera: GERMANIC, ROMANCE and SLAVIC. We construct four skewed samples using the sample of romance languages and a language from a different language family, an outlier language: Basque (eu), Arabic (ar), Turkish (tr) and Chinese (zh). Since we keep the sample of test sets constant, we do not include training data from languages that are in the test sets. The details of which treebanks are used for each of these samples can be found in Table 5 in Appendix B.\nWe can see first that, as expected, our typologically diverse sample performs best overall. This\nindicates that it is a good sample. We can also see that, as expected, the method works best with a skewed sample: the largest gains from using worst-case learning, both in terms of absolute LAS difference and relative error reduction, are seen for a skewed sample (ROM+EU). However, contrary to expectations, the lowest gains are obtained for another skewed sample (ROM+AR). The gains are also low for ROM+TR, ROM+ZH and for GERMANIC. Additionally, there are slightly more gains from using worst-case aware learning with the SLAVIC sample than for our typologically diverse sample. These results could be due to the different scripts of the languages involved both in training and testing.\nLooking at results of the different models on individual test languages (see Figure 1 in Appendix C), we find no clear pattern of the settings in which this method works best. We do note that the method always hurts Belarusian, which is perhaps unsurprising given that it is the test treebank for which the baseline is highest. Worst-case aware learning hurts Belarusian the least when using the SLAVIC sample, indicating that, when using the other samples, the languages related to Belarusian are likely downsampled in favour of languages unrelated to it. Worst-case learning consistently helps Breton and Swiss German, indicating that the method might work best for languages that are underrepresented within their language family but not necessarily outside of it. For Swiss German, worst-case learning helps least when using the GERMANIC sample where it is less of an outlier."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this work, we have adopted a method from multitask learning which relies on automated curriculum learning to the case of multilingual dependency parsing. This method allows to dynamically optimize for parsing performance on outlier languages. We found this method to improve dependency parsing on a sample of 30 test languages in the zeroshot setting, compared to sampling data uniformly across treebanks from different languages, or proportionally to the size of the treebanks. We investigated the impact of varying the homogeneity of the sample of training treebanks on the usefulness of the method and found conflicting evidence with different samples. This leaves open questions about the relationship between the languages used for training and the ones used for testing."
    }, {
      "heading" : "A Results by treebank",
      "text" : "Results by language of the test treebanks are in Table 4."
    }, {
      "heading" : "B Training samples",
      "text" : "The training samples are summarized in Table 5."
    }, {
      "heading" : "C Results by treebank with the different samples",
      "text" : "Relative error reduction between our best worstcase aware result and the best baseline for each training sample used, with mBERT, in Figure 1."
    } ],
    "references" : [ {
      "title" : "Multilingual projection for parsing truly low-resource languages",
      "author" : [ "Željko Agić", "Anders Johannsen", "Barbara Plank", "Héctor Martínez Alonso", "Natalie Schluter", "Anders Søgaard." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 4:301–",
      "citeRegEx" : "Agić et al\\.,? 2016",
      "shortCiteRegEx" : "Agić et al\\.",
      "year" : 2016
    }, {
      "title" : "Cross-Lingual Word Embeddings",
      "author" : [ "Eneko Agirre." ],
      "venue" : "Computational Linguistics, 46(1):245–248.",
      "citeRegEx" : "Agirre.,? 2020",
      "shortCiteRegEx" : "Agirre.",
      "year" : 2020
    }, {
      "title" : "On the shortest arborescence of a directed graph",
      "author" : [ "Yoeng-Jin Chu", "Tseng-hong Liu." ],
      "venue" : "Scientia Sinica, 14:1396–1400.",
      "citeRegEx" : "Chu and Liu.,? 1965",
      "shortCiteRegEx" : "Chu and Liu.",
      "year" : 1965
    }, {
      "title" : "Unsupervised structure prediction with nonparallel multilingual guidance",
      "author" : [ "Shay B. Cohen", "Dipanjan Das", "Noah A. Smith." ],
      "venue" : "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 50–61, Edinburgh,",
      "citeRegEx" : "Cohen et al\\.,? 2011",
      "shortCiteRegEx" : "Cohen et al\\.",
      "year" : 2011
    }, {
      "title" : "Unsupervised cross-lingual representation learning at scale",
      "author" : [ "Alexis Conneau", "Kartikay Khandelwal", "Naman Goyal", "Vishrav Chaudhary", "Guillaume Wenzek", "Francisco Guzmán", "Edouard Grave", "Myle Ott", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "In",
      "citeRegEx" : "Conneau et al\\.,? 2020",
      "shortCiteRegEx" : "Conneau et al\\.",
      "year" : 2020
    }, {
      "title" : "Linguistically Informed Neural Dependency Parsing for Typologically Diverse Languages",
      "author" : [ "Miryam de Lhoneux." ],
      "venue" : "Ph.D. thesis, Uppsala University.",
      "citeRegEx" : "Lhoneux.,? 2019",
      "shortCiteRegEx" : "Lhoneux.",
      "year" : 2019
    }, {
      "title" : "Old School vs",
      "author" : [ "Miryam de Lhoneux", "Sara Stymne", "Joakim Nivre." ],
      "venue" : "New School: Comparing Transition-Based Parsers with and without Neural Network Enhancement. In Proceedings of the 15th Treebanks and Linguistic Theories Workshop (TLT),",
      "citeRegEx" : "Lhoneux et al\\.,? 2017",
      "shortCiteRegEx" : "Lhoneux et al\\.",
      "year" : 2017
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Deep Biaffine Attention for Neural Dependency Parsing",
      "author" : [ "Timothy Dozat", "Christopher Manning." ],
      "venue" : "Proceedings of the 5th International Conference on Learning Representations.",
      "citeRegEx" : "Dozat and Manning.,? 2017",
      "shortCiteRegEx" : "Dozat and Manning.",
      "year" : 2017
    }, {
      "title" : "Cross-lingual transfer for unsupervised dependency parsing without parallel data",
      "author" : [ "Long Duong", "Trevor Cohn", "Steven Bird", "Paul Cook." ],
      "venue" : "Proceedings of the Nineteenth Conference on Computational Natural Language Learning, pages 113–122, Bei-",
      "citeRegEx" : "Duong et al\\.,? 2015",
      "shortCiteRegEx" : "Duong et al\\.",
      "year" : 2015
    }, {
      "title" : "Optimum Branchings",
      "author" : [ "Jack Edmonds." ],
      "venue" : "Journal of Research of the National Bureau of Standards, 71B:233–240.",
      "citeRegEx" : "Edmonds.,? 1967",
      "shortCiteRegEx" : "Edmonds.",
      "year" : 1967
    }, {
      "title" : "Pac bounds for multi-armed bandit and markov decision processes",
      "author" : [ "Eyal Even-Dar", "Shie Mannor", "Yishay Mansour." ],
      "venue" : "International Conference on Computational Learning Theory, pages 255–270. Springer.",
      "citeRegEx" : "Even.Dar et al\\.,? 2002",
      "shortCiteRegEx" : "Even.Dar et al\\.",
      "year" : 2002
    }, {
      "title" : "AllenNLP: A deep semantic natural language processing platform",
      "author" : [ "Matt Gardner", "Joel Grus", "Mark Neumann", "Oyvind Tafjord", "Pradeep Dasigi", "Nelson F. Liu", "Matthew Peters", "Michael Schmitz", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of Workshop for",
      "citeRegEx" : "Gardner et al\\.,? 2018",
      "shortCiteRegEx" : "Gardner et al\\.",
      "year" : 2018
    }, {
      "title" : "Automated curriculum learning for neural networks",
      "author" : [ "Alex Graves", "Marc G. Bellemare", "Jacob Menick", "Remi Munos", "Koray Kavukcuoglu" ],
      "venue" : null,
      "citeRegEx" : "Graves et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Graves et al\\.",
      "year" : 2017
    }, {
      "title" : "Multi-source transfer of delexicalized dependency parsers",
      "author" : [ "Ryan McDonald", "Slav Petrov", "Keith Hall." ],
      "venue" : "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 62–72, Edinburgh, Scotland, UK. Association",
      "citeRegEx" : "McDonald et al\\.,? 2011",
      "shortCiteRegEx" : "McDonald et al\\.",
      "year" : 2011
    }, {
      "title" : "Minimax multi-task learning and a generalized loss-compositional paradigm for mtl",
      "author" : [ "Nishant Mehta", "Dongryeol Lee", "Alexander G Gray." ],
      "venue" : "Advances in Neural Information Processing Systems, pages 2150–2158.",
      "citeRegEx" : "Mehta et al\\.,? 2012",
      "shortCiteRegEx" : "Mehta et al\\.",
      "year" : 2012
    }, {
      "title" : "Universal Dependencies v2: An evergrowing multilingual treebank collection",
      "author" : [ "Joakim Nivre", "Marie-Catherine de Marneffe", "Filip Ginter", "Jan Hajič", "Christopher D. Manning", "Sampo Pyysalo", "Sebastian Schuster", "Francis Tyers", "Daniel Zeman" ],
      "venue" : null,
      "citeRegEx" : "Nivre et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Nivre et al\\.",
      "year" : 2020
    }, {
      "title" : "How multilingual is multilingual BERT? In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4996– 5001, Florence, Italy",
      "author" : [ "Telmo Pires", "Eva Schlinger", "Dan Garrette." ],
      "venue" : "Association for Computa-",
      "citeRegEx" : "Pires et al\\.,? 2019",
      "shortCiteRegEx" : "Pires et al\\.",
      "year" : 2019
    }, {
      "title" : "Minimax and neyman–Pearson meta-learning for outlier languages",
      "author" : [ "Edoardo Maria Ponti", "Rahul Aralikatte", "Disha Shrivastava", "Siva Reddy", "Anders Søgaard." ],
      "venue" : "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages",
      "citeRegEx" : "Ponti et al\\.,? 2021",
      "shortCiteRegEx" : "Ponti et al\\.",
      "year" : 2021
    }, {
      "title" : "Empirically sampling Universal Dependencies",
      "author" : [ "Natalie Schluter", "Željko Agić." ],
      "venue" : "Proceedings of the NoDaLiDa 2017 Workshop on Universal Dependencies (UDW 2017), pages 117–122, Gothenburg, Sweden. Association for Computational Lin-",
      "citeRegEx" : "Schluter and Agić.,? 2017",
      "shortCiteRegEx" : "Schluter and Agić.",
      "year" : 2017
    }, {
      "title" : "Data point selection for crosslanguage adaptation of dependency parsers",
      "author" : [ "Anders Søgaard." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 682–686, Portland, Ore-",
      "citeRegEx" : "Søgaard.,? 2011",
      "shortCiteRegEx" : "Søgaard.",
      "year" : 2011
    }, {
      "title" : "Part-of-speech tagging with antagonistic adversaries",
      "author" : [ "Anders Søgaard." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 640–644, Sofia, Bulgaria. Association for Computa-",
      "citeRegEx" : "Søgaard.,? 2013",
      "shortCiteRegEx" : "Søgaard.",
      "year" : 2013
    }, {
      "title" : "Data-driven dependency parsing of new languages using incomplete and noisy training data",
      "author" : [ "Kathrin Spreyer", "Jonas Kuhn." ],
      "venue" : "Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL-2009), pages 12–",
      "citeRegEx" : "Spreyer and Kuhn.,? 2009",
      "shortCiteRegEx" : "Spreyer and Kuhn.",
      "year" : 2009
    }, {
      "title" : "Cross-lingual word clusters for direct transfer of linguistic structure",
      "author" : [ "Oscar Täckström", "Ryan McDonald", "Jakob Uszkoreit." ],
      "venue" : "Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Hu-",
      "citeRegEx" : "Täckström et al\\.,? 2012",
      "shortCiteRegEx" : "Täckström et al\\.",
      "year" : 2012
    }, {
      "title" : "UDapter: Language adaptation for truly Universal Dependency parsing",
      "author" : [ "Ahmet Üstün", "Arianna Bisazza", "Gosse Bouma", "Gertjan van Noord." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),",
      "citeRegEx" : "Üstün et al\\.,? 2020",
      "shortCiteRegEx" : "Üstün et al\\.",
      "year" : 2020
    }, {
      "title" : "Massive choice, ample tasks (MaChAmp): A toolkit for multi-task learning in NLP",
      "author" : [ "Rob van der Goot", "Ahmet Üstün", "Alan Ramponi", "Ibrahim Sharaf", "Barbara Plank." ],
      "venue" : "Proceedings of the 16th Conference of the European Chapter of the",
      "citeRegEx" : "Goot et al\\.,? 2021",
      "shortCiteRegEx" : "Goot et al\\.",
      "year" : 2021
    }, {
      "title" : "GLUE: A multi-task benchmark and analysis platform for natural language understanding",
      "author" : [ "Alex Wang", "Amanpreet Singh", "Julian Michael", "Felix Hill", "Omer Levy", "Samuel Bowman." ],
      "venue" : "Proceedings of the 2018 EMNLP Workshop Black-",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "Fairness risk measures",
      "author" : [ "Robert Williamson", "Aditya Menon." ],
      "venue" : "Proceedings of the 36th International Conference on Machine Learning, volume 97 of Proceedings of Machine Learning Research, pages 6786–6797. PMLR.",
      "citeRegEx" : "Williamson and Menon.,? 2019",
      "shortCiteRegEx" : "Williamson and Menon.",
      "year" : 2019
    }, {
      "title" : "Transformers: State-of-the-art natural language processing",
      "author" : [ "Teven Le Scao", "Sylvain Gugger", "Mariama Drame", "Quentin Lhoest", "Alexander Rush." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing:",
      "citeRegEx" : "Scao et al\\.,? 2020",
      "shortCiteRegEx" : "Scao et al\\.",
      "year" : 2020
    }, {
      "title" : "Beto, bentz, becas: The surprising cross-lingual effectiveness of BERT",
      "author" : [ "Shijie Wu", "Mark Dredze." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natu-",
      "citeRegEx" : "Wu and Dredze.,? 2019",
      "shortCiteRegEx" : "Wu and Dredze.",
      "year" : 2019
    }, {
      "title" : "Crosslanguage parser adaptation between related languages",
      "author" : [ "Daniel Zeman", "Philip Resnik." ],
      "venue" : "Proceedings of the IJCNLP-08 Workshop on NLP for Less Privileged Languages.",
      "citeRegEx" : "Zeman and Resnik.,? 2008",
      "shortCiteRegEx" : "Zeman and Resnik.",
      "year" : 2008
    }, {
      "title" : "Worst-case-aware curriculum learning for zero and few shot transfer",
      "author" : [ "Sheng Zhang", "Xin Zhang", "Weiming Zhang", "Anders Søgaard." ],
      "venue" : "arXiv preprint arXiv:2009.11138.",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "2020) using mBERT and XLM-R",
      "author" : [ "Üstün" ],
      "venue" : null,
      "citeRegEx" : "Üstün,? \\Q2020\\E",
      "shortCiteRegEx" : "Üstün",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 29,
      "context" : "Large multilingual pretrained language models such as mBERT and XLM-RoBERTa have been found to be surprisingly effective for cross-lingual transfer of syntactic parsing models (Wu and Dredze, 2019), but only between related languages.",
      "startOffset" : 176,
      "endOffset" : 197
    }, {
      "referenceID" : 1,
      "context" : "The field of multilingual NLP is booming (Agirre, 2020).",
      "startOffset" : 41,
      "endOffset" : 55
    }, {
      "referenceID" : 7,
      "context" : "This is due in no small part to large multilingual pretrained language models (PLMs) such as mBERT (Devlin et al., 2019) and XLM-RoBERTa (Conneau et al.",
      "startOffset" : 99,
      "endOffset" : 120
    }, {
      "referenceID" : 4,
      "context" : ", 2019) and XLM-RoBERTa (Conneau et al., 2020), which have been found to have surprising cross-lingual transfer capabilities in spite of receiving no cross-lingual supervision.",
      "startOffset" : 24,
      "endOffset" : 46
    }, {
      "referenceID" : 17,
      "context" : "There is, however, a sharp divide between languages that benefit from this transfer and languages that do not, and there is ample evidence that transfer works best between typologically similar languages (Pires et al., 2019).",
      "startOffset" : 204,
      "endOffset" : 224
    }, {
      "referenceID" : 22,
      "context" : "In the early days, cross-lingual transfer for dependency parsing relied on projection across word alignments (Spreyer and Kuhn, 2009; Agić et al., 2016) or delexicalized transfer of abstract syntactic features (Zeman and Resnik, 2008; McDonald et al.",
      "startOffset" : 109,
      "endOffset" : 152
    }, {
      "referenceID" : 0,
      "context" : "In the early days, cross-lingual transfer for dependency parsing relied on projection across word alignments (Spreyer and Kuhn, 2009; Agić et al., 2016) or delexicalized transfer of abstract syntactic features (Zeman and Resnik, 2008; McDonald et al.",
      "startOffset" : 109,
      "endOffset" : 152
    }, {
      "referenceID" : 30,
      "context" : ", 2016) or delexicalized transfer of abstract syntactic features (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 2011; Cohen et al., 2011).",
      "startOffset" : 65,
      "endOffset" : 147
    }, {
      "referenceID" : 14,
      "context" : ", 2016) or delexicalized transfer of abstract syntactic features (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 2011; Cohen et al., 2011).",
      "startOffset" : 65,
      "endOffset" : 147
    }, {
      "referenceID" : 20,
      "context" : ", 2016) or delexicalized transfer of abstract syntactic features (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 2011; Cohen et al., 2011).",
      "startOffset" : 65,
      "endOffset" : 147
    }, {
      "referenceID" : 3,
      "context" : ", 2016) or delexicalized transfer of abstract syntactic features (Zeman and Resnik, 2008; McDonald et al., 2011; Søgaard, 2011; Cohen et al., 2011).",
      "startOffset" : 65,
      "endOffset" : 147
    }, {
      "referenceID" : 23,
      "context" : "Delexicalized transfer was later ’re-lexicalized’ by word clusters (Täckström et al., 2012) and word embeddings (Duong et al.",
      "startOffset" : 67,
      "endOffset" : 91
    }, {
      "referenceID" : 9,
      "context" : ", 2012) and word embeddings (Duong et al., 2015), but with the introduction of multilingual contextualized language models, transfer models no longer rely on abstract syntactic features, removing an important bottleneck for transfer approaches to scale to truly low-resource languages.",
      "startOffset" : 28,
      "endOffset" : 48
    }, {
      "referenceID" : 18,
      "context" : "However, this is difficult to achieve in practice, as multilingual datasets are not well balanced for typological diversity and contain a skewed distribution of typological features (Ponti et al., 2021).",
      "startOffset" : 182,
      "endOffset" : 202
    }, {
      "referenceID" : 26,
      "context" : "They trained their model on a subset of the GLUE benchmark (Wang et al., 2018) and tested on outlier tasks.",
      "startOffset" : 59,
      "endOffset" : 78
    }, {
      "referenceID" : 16,
      "context" : "Multilingual dependency parsing is an ideal test case for this method, as the Universal Dependency treebanks (Nivre et al., 2020) are currently the manually annotated dataset that covers the most typological diversity (Ponti et al.",
      "startOffset" : 109,
      "endOffset" : 129
    }, {
      "referenceID" : 18,
      "context" : ", 2020) are currently the manually annotated dataset that covers the most typological diversity (Ponti et al., 2021).",
      "startOffset" : 96,
      "endOffset" : 116
    }, {
      "referenceID" : 13,
      "context" : "(2020), which is an automated curriculum learning (Graves et al., 2017) framework to learn a worstcase-aware loss in a multi-task learning scenario.",
      "startOffset" : 50,
      "endOffset" : 71
    }, {
      "referenceID" : 11,
      "context" : "This is a typical multi-arm bandit problem (Even-Dar et al., 2002).",
      "startOffset" : 43,
      "endOffset" : 66
    }, {
      "referenceID" : 21,
      "context" : "We could also, motivated by robustness (Søgaard, 2013) and fairness (Williamson and Menon, 2019), minimize the maximum (supremum) of the n losses, asking whether max`∈α ` < max`∈β `.",
      "startOffset" : 39,
      "endOffset" : 54
    }, {
      "referenceID" : 27,
      "context" : "We could also, motivated by robustness (Søgaard, 2013) and fairness (Williamson and Menon, 2019), minimize the maximum (supremum) of the n losses, asking whether max`∈α ` < max`∈β `.",
      "startOffset" : 68,
      "endOffset" : 96
    }, {
      "referenceID" : 13,
      "context" : "(2020) present a stochastic generalization of the L∞ loss summarization and a practical approach to minimizing this family of losses through automated curriculum learning (Graves et al., 2017): The core idea behind their generalization is to optimize the worst-case loss with a certain probability, otherwise optimize the average (loss-proportional) loss with the remaining probability.",
      "startOffset" : 171,
      "endOffset" : 192
    }, {
      "referenceID" : 8,
      "context" : "The multilingual dependency parsing model We use a standard biaffine graph-based dependency parser (Dozat and Manning, 2017).",
      "startOffset" : 99,
      "endOffset" : 124
    }, {
      "referenceID" : 2,
      "context" : "The Chu-LiuEdmonds algorithm (Chu and Liu, 1965; Edmonds, 1967) is then used to decode the score matrix into a tree.",
      "startOffset" : 29,
      "endOffset" : 63
    }, {
      "referenceID" : 10,
      "context" : "The Chu-LiuEdmonds algorithm (Chu and Liu, 1965; Edmonds, 1967) is then used to decode the score matrix into a tree.",
      "startOffset" : 29,
      "endOffset" : 63
    }, {
      "referenceID" : 16,
      "context" : "They fine-tune mBERT for dependency parsing using training data from a sample of 13 typologically diverse languages from Universal Dependencies (UD; Nivre et al., 2020), listed in Table 1.",
      "startOffset" : 144,
      "endOffset" : 168
    }, {
      "referenceID" : 12,
      "context" : ", 2021), a library for multi-task learning based on AllenNLP (Gardner et al., 2018).",
      "startOffset" : 61,
      "endOffset" : 83
    }, {
      "referenceID" : 19,
      "context" : "It is notoriously difficult to construct a sample of treebanks that is representative of the languages in UD (de Lhoneux et al., 2017; Schluter and Agić, 2017; de Lhoneux, 2019).",
      "startOffset" : 109,
      "endOffset" : 177
    } ],
    "year" : 0,
    "abstractText" : "Large multilingual pretrained language models such as mBERT and XLM-RoBERTa have been found to be surprisingly effective for cross-lingual transfer of syntactic parsing models (Wu and Dredze, 2019), but only between related languages. However, source and training languages are rarely related, when parsing truly low-resource languages. To close this gap, we adopt a method from multi-task learning, which relies on automated curriculum learning, to dynamically optimize for parsing performance on outlier languages. We show that this approach is significantly better than uniform and size-proportional sampling in the zero-shot setting.",
    "creator" : null
  }
}