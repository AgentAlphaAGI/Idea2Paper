{
  "name" : "ARR_2022_237_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Relation extraction aims at discovering structured knowledge in the form of <subject-relationobject> triples from plain text. It is an essential task towards constructing knowledge bases, which further supporting various applications such as search engines and question answering systems. Although a lot of efforts have been made in building advanced relation extraction systems, it is still a challenging problem under certain practical scenarios where multiple entities and relations are involved, e.g., document-level relation extraction (Yao et al., 2019) and joint entity and relation extraction (Riedel et al., 2010; Gardent et al., 2017).\nExisting works mostly take the entity perspective that focuses on exploring cross-entity interactions (Xu et al., 2021; Zeng et al., 2020). They either treat relations as atomic labels specified in a final classifier (Xu et al., 2021; Zeng et al., 2020; Wang et al., 2020), or simply search for each individual relation its possible subjects and objects(Wei et al., 2020; Zheng et al., 2021). However, as an essential component, relations also interact with\n1The code will be available at https://github.com/ XXX/XXX\nentities and context, which jointly exhibit informative inter-triple correlations. e.g., the two relations capital of and located at often co-occur between the same pair of entities but with different probabilities conditioned on specific contextual clues. As a consequence, the capability to model and make full use of rich interactions across relations, entities, and context is crucial for the task.\nIn this paper, we advocate a novel joint triple perspective for relation extraction (see Figure 1 for illustration). Different from previous works that only seek to represent entities, we propose EmRel that creates, refines and leverages the Embedded representations of Relations. Specifically, we first explicitly create relation representations as embedded vectors; then refine these relation (as well as entity) representations by modeling rich relationentity-context interactions via an attention-based fusion module; and finally identify valid triples by aligning the representation of entities and relations in a joint space, where a novel alignment function based on Tucker Decomposition is designed to deliver such a purpose. This joint triple perspective actually considers entities along with relations as components of a small, context-dependent knowl-\nedge graph, and completes this graph by aligning and reasoning to extract multiple valid triples.\nTo demonstrate the advantage of the proposed EmRel framework, we conduct experiments on two specific scenarios of multi-triple extraction: document-level relation extraction(RE) and joint entity and relation extraction, with three popular datasets including DocRED (Yao et al., 2019), NYT (Riedel et al., 2010) and WebNLG (Gardent et al., 2017). The results verify the superiority of the joint triple perspective over the traditional entity perspective in multi-triple extraction. We also provide further ablation study to show the effectiveness of our fusion module and alignment function."
    }, {
      "heading" : "2 Related Works",
      "text" : "Document-level Relation Extraction Extracting multi-triples from document-level text has recently aroused increasing interests (Yao et al., 2019). Existing methods take the entity perspective that proposes various techniques to model entity interactions. Nan et al. (2020) and Zeng et al. (2020) construct an entity graph, and perform graph-level reasoning to refine the entity node representations. Xu et al. (2021) introduces entity structure as useful prior, and models such information within the transformer attention layer. Zhang et al. (2021) utilizes a segmentation network to model the interdependency among entity pairs. Therefore, inter-triple correlations are only captured at the entity level while relation-based ones are neglected.\nJoint Entity and Relation Extraction Joint entity and relation extraction is a popular task that extracts multi-triples along with their entities. Existing works can be concluded into two frameworks: one that searches for each individual relation its possible subjects and objects ( Liu et al., 2020; Wang et al., 2020;Wei et al., 2020), and the other that directly see each word as a candidate entity and assign them with relation labels (Gupta et al., 2016; Zheng et al., 2021). Both formulations do not explicitly include inter-triple correlations. Very recently, Wu and Shi (2021) proposes to model the interdependencies between entity labels and relation labels, However, such correlation is constrained within a specific word position, while EmRel exploits the global correlations among all triples and across entities, context, and relations. Li et al. (2021) introduces a translation-based function that predicts object from subject and relation, while EmRel proposes a more expressive alignment func-\ntion that models the ternary interaction of subject, relation and object."
    }, {
      "heading" : "3 Methodology",
      "text" : ""
    }, {
      "heading" : "3.1 Task Formulation",
      "text" : "We first formulate the multi-triple extraction task to suitably contains both document-level RE and joint entity and relation extraction. Given a sequence of text {wi}, a set of candidate entities E = {ei} and the pre-defined relations R = {ri}, the candidate triples can be derived as:\nT = {< s, r, o > |s, o ∈ {ei}, r ∈ {ri}} (1)\nthe target is to assign each t in T a binary label that discriminates its validity. The candidate entities can either be pre-annotated, as in document-level relation extraction, or be jointly recognized, as in joint entity and relation extraction. In the latter scenario, one prevailing solution is to directly see each word as a candidate entity, such as tagging-based methods (Wang et al., 2020) or table filling methods (Gupta et al., 2016). Here we follow Wang et al. (2020) as our baseline, and thus formulate both tasks under a unified framework that extracts multi-triples from a given candidate entity set."
    }, {
      "heading" : "3.2 EmRel",
      "text" : "EmRel consists of three modules: Representation Construction for both entities and relations, Representation Fusion that captures multi-triple correlations by modeling the informative interactions across entities, context and relations, and Representation Alignment that leverages these representations to extract triples by aligning their ternary structures (see Figure 2 for illustration).\nRepresentation Construction The entity representation is constructed similar to existing practices. We employ a text encoder, e.g., pretrained language models like BERT (Devlin et al., 2019), to obtain the contextualized representation:\n(h1, h2, ...hn) = encoder(w1, w2, ...wn) (2)\nwhich we denote as H. Then we construct each entity representation ei ∈ Rde by applying a pooling operation on its corresponding mention positions, and further map it into respective subject and object representation esi , e o i .\nWe embed the target relations R into an embedding matrix R ∈ R|R|×dr , where each row Ri,: represents a vectorized relation ri. This matrix is maintained as part of the model parameter and trained accordingly.\nRepresentation Fusion In order to jointly represent entities and relations in a shared knowledge representation space, we fuse them to be aware of each other. We adopt the attention network (Bahdanau et al., 2015) to model inter-component interactions, which has proven to be very successful in modeling rich interactions across contexts (Yu et al., 2018) or modalities (Lu et al., 2016). Specifically, we employ the canonical multi-head attention (MHA) network (Vaswani et al., 2017). Given the target representation XQ and the source representation XS , each head of MHA operates them as:\nX̂Q =Att(XQW Q,XSW K ,XSW V )\n=softmax( (XQW\nQ)(XSW K)\nT\n√ dk\n)XSW V\n(3)\nwhere X̂Q is the updated representation of XQ w.r.t. XS , all heads operate in parallel and will be concatenated together.\nIn EmRel, to exploit the comprehensive interactions across all components, we first construct\nentity/context-aware relation representation:\nR̂s =Atts2r(RW Q,EsWK ,EsWV ) R̂o =Atto2r(RW Q,EoWK ,EoWV ) R̂c =Attc2r(RW Q,HWK ,HsWV )\n(4)\nwhich are then aggregated together using layer normalization:\nR̂ = LayerNorm(R̂s + R̂o + R̂c) (5)\nwe symmetrically construct relation-aware entity representation:\nÊs =Attr2s(E sWQ,RWK ,RWV ) Êo =Attr2o(E oWQ,RWK ,RWV )\n(6)\ns, o, c are abbreviations for subject, object and context. Each attention module is wrapped with residual connection, feedforward layer, layer normalization, and is instantiated with different parameters of WQ, WK , WV to model distinguished attending patterns. The outputs of fusion module are refined representations R̂, Ês, Êo for relations, subjects and objects.\nRepresentation Alignment EmRel extracts triples by aligning their ternary components R̂, Ês, and Êo. In order to fully leverage their expressiveness, we propose factorization-based alignment\nusing Tucker decomposition (Tucker et al., 1964). We introduce a core tensor Z ∈ Rde∗dr∗de , and the validity for each < si, rk, oj > is scored as:\nφ(si, rk, oj) = σ(Z ×1 êsi ×2 r̂k ×3 êoj + bk) (7)\nwhere êsi = Ê s i,:, r̂k = R̂k,:, ê o i = Ê o j,:, and ×n indicates tensor product along the n-th mode, σ denotes sigmoid function. We compute φ for all triples in parallel using batched tensor product, and train them using cross-entropy loss:\nL = T∑ <si,rk,oj> [−1True(< si, rk, oj >) log φ(si, rk, oj)\n− 1False(< si, rk, oj >) log(1− φ(si, rk, oj))] (8)\nwhere 1 indicates the ground truth validity."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Main Results",
      "text" : "We conduct comprehensive experiments on document-level RE dataset DocRED (Yao et al., 2019) and joint entity and relation extraction dataset NYT (Riedel et al., 2010) and WebNLG (Gardent et al., 2017). The specifics about these datasets and our implementation details can be referred to Appendix. We provide our reproduced results of TPLinker (Wang et al., 2020) and the baseline system of Xu et al. (2021). Both are competitive baselines based on the entity perspective, and are directly comparable with EmRel.\nThe results (see Table 1 and Table 2) show that EmRel universally outperforms its baselines on all datasets. Respectively, +0.3 F1 for NYT∗, +0.8 F1 for WebNLG∗, +1.0 F1 for NYT and +1.1 F1 for WebNLG. On DocRED, EmRel improves the baseline by +0.95 Dev F1, +1.47 Test F1, and also outperforms several previous studies including BERT-TS (Wang et al., 2019), CorefBERT (Ye et al., 2020), LSR (Nan et al., 2020), and SSAN (Xu et al., 2021)."
    }, {
      "heading" : "4.2 Ablation Studies",
      "text" : "This section gives ablation studies on DocRED.\nOn EmRel Modules We first varify the design of EmRel modules. Table 3 shows that both fusion and alignment module contribute to the improvements. We also observe that EmRel has more robust performance across multiple runs. This can be attributed to our alignment function, which, once removed, would result in an increased standard deviation from ±0.20 to ±0.47.\nOn the Dimensionality of Relation Representations We investigate the effects of choices for dr in Fig 3. First of all, the advantage of EmRel is general across variant choices comparing to the baseline. As we gradually set a higher dr from 64 to 1024, we get improved performance for its stronger expressive capability. While we further increase dr to 2048, the performance starting to degrades, which might attribute to overfitting. Overall, the optimal dimension lies within [512, 2048], which is quite robust and also computationally acceptable."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper, we propose EmRel for multi-triple extraction. Distinguished from existing works, EmRel explicitly creates, refines, and leverages the embedded representation of relations. Notably, we design a novel alignment function that discriminates triple validity by aligning its components in a joint representation space. We conduct experiments on both document-level relation extraction and joint entity and relation extraction, to demonstrate the advantage of EmRel over its baselines.\nEmRel also provides a new joint triple perspective, where multi-triple extraction is formulated as completion of a small, context-dependent knowledge graph, with candidate entities and relations as its components. In the future, we think more intricate techniques e.g., graph-based reasoning, can be explored following such formulation."
    }, {
      "heading" : "A Benchmarks",
      "text" : "We introduce the benchmarks used in this work. Table 4 gives their detailed statistics. DocRED is constructed from Wikipedia document. It provides comprehensive human annotations for entity mentions, entity types, relational triples, along with their supporting evidences. Each document is a semantically integrate unit that centers in one concept (the title of the wiki page), resulting multiple triples with rich correlations. NYT is constructed from New York Times news articles and annotated through distant supervision. WebNLG is originally created for natural language generation task, and the sentences are written by humans to cover given triples. Both datasets have the other version denoted as NYT∗ and WebNLG∗. The texts in NYT and WebNLG are much shorter than DocRED documents. These two datasets also feature in multiple triples. Specifically, previous studies have concluded multi-triples into three specific cases:\nEPO: triples overlap with both subjects and objects, SEO: triples overlap with subject or object, and Normal: without any overlapping. In this paper, we solve all three datasets under a unified multi-triple extraction formulation with EmRel.\nB Implementation Details\nTo provide comparable results, we set hyperparameters following previous works (Wang et al., 2020; Xu et al., 2021). On NYT / WebNLG, we set learning rate as 5e-5, batch size as 24 / 6, and epoch as 100. On DocRED, we set learning rate as 3e-5, batch size as 4, and search epochs in {40, 60, 80, 100}. To produce more robust results, we further perform multiple searches using different seeds, resulting a grid search on both epochs and random seeds. The mean and standard deviation results across different seed are reported on development set. We also provide our reproduced baseline results, i.e., TPLinker Wang et al. (2020) and the baseline system of Xu et al. (2021). The former further adopts a hand-shaking strategy to decode entity spans. The dimension of embedded relation representation is set as 768 for DocRED, 128 for NYT / WebNLG2, and the number of attention heads in the fusion module is set as 4. BERT-BaseCased (Devlin et al., 2019) is used as the context encoder. All experiments are conducted on a single NIVDIA V100 or A100 GPU machine."
    }, {
      "heading" : "C Grouped Alignment",
      "text" : "The WebNLG dataset has up to 216 relations, which requires increased computational cost. Inspired by (Zheng et al., 2019), we split the alignment tensors into N groups across its dimensions to reduce the computational overhead, and re-write Eq. 7 as:\nφ(si, pk, oj) = N∑\nn=1\nZn ×1 ês,ni ×2 r̂ n k ×3 êo,nj + bk (9)\nês,ni =Ê s\ni,[(n−1) de N :n de N ]\nr̂nk =R̂k,[(n−1) dr N :n dr N ]\nêo,ni =Ê o\nj,[(n−1) de N :n de N ]\n(10)\nWe set group N to 4 for WebNLG, and 1 for other datasets (that is, without further spliting).\n2768 is identical with BERT Base hidden size, and we use 128 in NYT/WebNLG to reduce computational footprints because these two datasets involve more candidate entities."
    } ],
    "references" : [ {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio." ],
      "venue" : "ICLR 2015 : International Conference on Learning Representations 2015.",
      "citeRegEx" : "Bahdanau et al\\.,? 2015",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2015
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Creating training corpora for nlg micro-planning",
      "author" : [ "Claire Gardent", "Anastasia Shimorina", "Shashi Narayan", "Laura Perez-Beltrachini." ],
      "venue" : "55th annual meeting of the Association for Computational Linguistics (ACL).",
      "citeRegEx" : "Gardent et al\\.,? 2017",
      "shortCiteRegEx" : "Gardent et al\\.",
      "year" : 2017
    }, {
      "title" : "Table filling multi-task recurrent neural network for joint entity and relation extraction",
      "author" : [ "Pankaj Gupta", "Hinrich Schütze", "Bernt Andrassy." ],
      "venue" : "Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Techni-",
      "citeRegEx" : "Gupta et al\\.,? 2016",
      "shortCiteRegEx" : "Gupta et al\\.",
      "year" : 2016
    }, {
      "title" : "TDEER: An efficient translating decoding schema for joint extraction of entities and relations",
      "author" : [ "Xianming Li", "Xiaotian Luo", "Chenghao Dong", "Daichuan Yang", "Beidi Luan", "Zhen He." ],
      "venue" : "Proceedings of the 2021 Conference on Empir-",
      "citeRegEx" : "Li et al\\.,? 2021",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2021
    }, {
      "title" : "Attention as relation: Learning supervised multi-head self-attention for relation extraction",
      "author" : [ "Jie Liu", "Shaowei Chen", "Bingquan Wang", "Jiaxin Zhang", "Na Li", "Tong Xu." ],
      "venue" : "Proceedings of the TwentyNinth International Joint Conference on Artificial",
      "citeRegEx" : "Liu et al\\.,? 2020",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2020
    }, {
      "title" : "Hierarchical question-image co-attention for visual question answering",
      "author" : [ "Jiasen Lu", "Jianwei Yang", "Dhruv Batra", "Devi Parikh." ],
      "venue" : "Advances in neural information processing systems, 29:289–297.",
      "citeRegEx" : "Lu et al\\.,? 2016",
      "shortCiteRegEx" : "Lu et al\\.",
      "year" : 2016
    }, {
      "title" : "Reasoning with latent structure refinement for document-level relation extraction",
      "author" : [ "Guoshun Nan", "Zhijiang Guo", "Ivan Sekulic", "Wei Lu." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1546–1557, On-",
      "citeRegEx" : "Nan et al\\.,? 2020",
      "shortCiteRegEx" : "Nan et al\\.",
      "year" : 2020
    }, {
      "title" : "Modeling relations and their mentions without labeled text",
      "author" : [ "Sebastian Riedel", "Limin Yao", "Andrew McCallum." ],
      "venue" : "Joint European Conference",
      "citeRegEx" : "Riedel et al\\.,? 2010",
      "shortCiteRegEx" : "Riedel et al\\.",
      "year" : 2010
    }, {
      "title" : "The extension of factor analysis to three-dimensional matrices",
      "author" : [ "Ledyard R Tucker" ],
      "venue" : "Contributions to mathematical psychology, 110119.",
      "citeRegEx" : "Tucker,? 1964",
      "shortCiteRegEx" : "Tucker",
      "year" : 1964
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Ł ukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Fine-tune bert for docred with two-step process",
      "author" : [ "Hong Wang", "Christfried Focke", "Rob Sylvester", "Nilesh Mishra", "William Wang." ],
      "venue" : "arXiv preprint arXiv:1909.11898.",
      "citeRegEx" : "Wang et al\\.,? 2019",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "TPLinker: Single-stage joint extraction of entities and relations through token pair linking",
      "author" : [ "Yucheng Wang", "Bowen Yu", "Yueyang Zhang", "Tingwen Liu", "Hongsong Zhu", "Limin Sun." ],
      "venue" : "Proceedings of the 28th International Conference on Com-",
      "citeRegEx" : "Wang et al\\.,? 2020",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "A novel cascade binary tagging framework for relational triple extraction",
      "author" : [ "Zhepei Wei", "Jianlin Su", "Yue Wang", "Yuan Tian", "Yi Chang." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 1476–",
      "citeRegEx" : "Wei et al\\.,? 2020",
      "shortCiteRegEx" : "Wei et al\\.",
      "year" : 2020
    }, {
      "title" : "Synchronous dual network with cross-type attention for joint entity and relation extraction",
      "author" : [ "Hui Wu", "Xiaodong Shi." ],
      "venue" : "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 2769–2779, Online and",
      "citeRegEx" : "Wu and Shi.,? 2021",
      "shortCiteRegEx" : "Wu and Shi.",
      "year" : 2021
    }, {
      "title" : "Entity structure within and throughout: Modeling mention dependencies for document-level relation extraction",
      "author" : [ "Benfeng Xu", "Quan Wang", "Yajuan Lyu", "Yong Zhu", "Zhendong Mao." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence,",
      "citeRegEx" : "Xu et al\\.,? 2021",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2021
    }, {
      "title" : "DocRED: A large-scale document-level relation extraction dataset",
      "author" : [ "Yuan Yao", "Deming Ye", "Peng Li", "Xu Han", "Yankai Lin", "Zhenghao Liu", "Zhiyuan Liu", "Lixin Huang", "Jie Zhou", "Maosong Sun." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Associa-",
      "citeRegEx" : "Yao et al\\.,? 2019",
      "shortCiteRegEx" : "Yao et al\\.",
      "year" : 2019
    }, {
      "title" : "Coreferential Reasoning Learning for Language Representation",
      "author" : [ "Deming Ye", "Yankai Lin", "Jiaju Du", "Zhenghao Liu", "Peng Li", "Maosong Sun", "Zhiyuan Liu." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Process-",
      "citeRegEx" : "Ye et al\\.,? 2020",
      "shortCiteRegEx" : "Ye et al\\.",
      "year" : 2020
    }, {
      "title" : "Fast and accurate reading comprehension by combining self-attention and convolution",
      "author" : [ "Adams Wei Yu", "David Dohan", "Quoc Le", "Thang Luong", "Rui Zhao", "Kai Chen." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Yu et al\\.,? 2018",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2018
    }, {
      "title" : "Double graph based reasoning for documentlevel relation extraction",
      "author" : [ "Shuang Zeng", "Runxin Xu", "Baobao Chang", "Lei Li." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1630–1640, On-",
      "citeRegEx" : "Zeng et al\\.,? 2020",
      "shortCiteRegEx" : "Zeng et al\\.",
      "year" : 2020
    }, {
      "title" : "Document-level relation extraction as semantic segmentation",
      "author" : [ "Ningyu Zhang", "Xiang Chen", "Xin Xie", "Shumin Deng", "Chuanqi Tan", "Mosha Chen", "Fei Huang", "Luo Si", "Huajun Chen." ],
      "venue" : "Proceedings of the Thirtieth International Joint Conference on",
      "citeRegEx" : "Zhang et al\\.,? 2021",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2021
    }, {
      "title" : "Learning deep bilinear transformation for fine-grained image representation",
      "author" : [ "Heliang Zheng", "Jianlong Fu", "Zheng-Jun Zha", "Jiebo Luo." ],
      "venue" : "Advances in Neural Information Processing Systems, volume 32. Curran Associates, Inc.",
      "citeRegEx" : "Zheng et al\\.,? 2019",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2019
    }, {
      "title" : "PRGC: Potential relation and global correspondence based joint relational triple extraction",
      "author" : [ "Hengyi Zheng", "Rui Wen", "Xi Chen", "Yifan Yang", "Yunyan Zhang", "Ziheng Zhang", "Ningyu Zhang", "Bin Qin", "Xu Ming", "Yefeng Zheng." ],
      "venue" : "Proceedings of the",
      "citeRegEx" : "Zheng et al\\.,? 2021",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2021
    }, {
      "title" : "2019) is used as the context encoder. All experiments are conducted on a single NIVDIA V100 or A100 GPU machine. C Grouped Alignment The WebNLG dataset has up",
      "author" : [ "Cased (Devlin" ],
      "venue" : null,
      "citeRegEx" : ".Devlin,? \\Q2019\\E",
      "shortCiteRegEx" : ".Devlin",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 16,
      "context" : ", document-level relation extraction (Yao et al., 2019) and joint entity and relation extraction (Riedel et al.",
      "startOffset" : 37,
      "endOffset" : 55
    }, {
      "referenceID" : 8,
      "context" : ", 2019) and joint entity and relation extraction (Riedel et al., 2010; Gardent et al., 2017).",
      "startOffset" : 49,
      "endOffset" : 92
    }, {
      "referenceID" : 2,
      "context" : ", 2019) and joint entity and relation extraction (Riedel et al., 2010; Gardent et al., 2017).",
      "startOffset" : 49,
      "endOffset" : 92
    }, {
      "referenceID" : 15,
      "context" : "Existing works mostly take the entity perspective that focuses on exploring cross-entity interactions (Xu et al., 2021; Zeng et al., 2020).",
      "startOffset" : 102,
      "endOffset" : 138
    }, {
      "referenceID" : 19,
      "context" : "Existing works mostly take the entity perspective that focuses on exploring cross-entity interactions (Xu et al., 2021; Zeng et al., 2020).",
      "startOffset" : 102,
      "endOffset" : 138
    }, {
      "referenceID" : 15,
      "context" : "They either treat relations as atomic labels specified in a final classifier (Xu et al., 2021; Zeng et al., 2020; Wang et al., 2020), or simply search for each individual relation its possible subjects and objects(Wei et al.",
      "startOffset" : 77,
      "endOffset" : 132
    }, {
      "referenceID" : 19,
      "context" : "They either treat relations as atomic labels specified in a final classifier (Xu et al., 2021; Zeng et al., 2020; Wang et al., 2020), or simply search for each individual relation its possible subjects and objects(Wei et al.",
      "startOffset" : 77,
      "endOffset" : 132
    }, {
      "referenceID" : 12,
      "context" : "They either treat relations as atomic labels specified in a final classifier (Xu et al., 2021; Zeng et al., 2020; Wang et al., 2020), or simply search for each individual relation its possible subjects and objects(Wei et al.",
      "startOffset" : 77,
      "endOffset" : 132
    }, {
      "referenceID" : 13,
      "context" : ", 2020), or simply search for each individual relation its possible subjects and objects(Wei et al., 2020; Zheng et al., 2021).",
      "startOffset" : 88,
      "endOffset" : 126
    }, {
      "referenceID" : 22,
      "context" : ", 2020), or simply search for each individual relation its possible subjects and objects(Wei et al., 2020; Zheng et al., 2021).",
      "startOffset" : 88,
      "endOffset" : 126
    }, {
      "referenceID" : 16,
      "context" : "To demonstrate the advantage of the proposed EmRel framework, we conduct experiments on two specific scenarios of multi-triple extraction: document-level relation extraction(RE) and joint entity and relation extraction, with three popular datasets including DocRED (Yao et al., 2019), NYT (Riedel et al.",
      "startOffset" : 265,
      "endOffset" : 283
    }, {
      "referenceID" : 8,
      "context" : ", 2019), NYT (Riedel et al., 2010) and WebNLG (Gardent et al.",
      "startOffset" : 13,
      "endOffset" : 34
    }, {
      "referenceID" : 5,
      "context" : "Existing works can be concluded into two frameworks: one that searches for each individual relation its possible subjects and objects ( Liu et al., 2020; Wang et al., 2020;Wei et al., 2020), and the other that directly see each word as a candidate entity and assign them with relation labels (Gupta et al.",
      "startOffset" : 134,
      "endOffset" : 189
    }, {
      "referenceID" : 12,
      "context" : "Existing works can be concluded into two frameworks: one that searches for each individual relation its possible subjects and objects ( Liu et al., 2020; Wang et al., 2020;Wei et al., 2020), and the other that directly see each word as a candidate entity and assign them with relation labels (Gupta et al.",
      "startOffset" : 134,
      "endOffset" : 189
    }, {
      "referenceID" : 13,
      "context" : "Existing works can be concluded into two frameworks: one that searches for each individual relation its possible subjects and objects ( Liu et al., 2020; Wang et al., 2020;Wei et al., 2020), and the other that directly see each word as a candidate entity and assign them with relation labels (Gupta et al.",
      "startOffset" : 134,
      "endOffset" : 189
    }, {
      "referenceID" : 3,
      "context" : ", 2020), and the other that directly see each word as a candidate entity and assign them with relation labels (Gupta et al., 2016; Zheng et al., 2021).",
      "startOffset" : 110,
      "endOffset" : 150
    }, {
      "referenceID" : 22,
      "context" : ", 2020), and the other that directly see each word as a candidate entity and assign them with relation labels (Gupta et al., 2016; Zheng et al., 2021).",
      "startOffset" : 110,
      "endOffset" : 150
    }, {
      "referenceID" : 12,
      "context" : "In the latter scenario, one prevailing solution is to directly see each word as a candidate entity, such as tagging-based methods (Wang et al., 2020) or table filling methods (Gupta et al.",
      "startOffset" : 130,
      "endOffset" : 149
    }, {
      "referenceID" : 1,
      "context" : ", pretrained language models like BERT (Devlin et al., 2019), to obtain the contextualized representation:",
      "startOffset" : 39,
      "endOffset" : 60
    }, {
      "referenceID" : 0,
      "context" : "We adopt the attention network (Bahdanau et al., 2015) to model inter-component interactions, which has proven to be very successful in modeling rich interactions across contexts (Yu et al.",
      "startOffset" : 31,
      "endOffset" : 54
    }, {
      "referenceID" : 18,
      "context" : ", 2015) to model inter-component interactions, which has proven to be very successful in modeling rich interactions across contexts (Yu et al., 2018) or modalities (Lu et al.",
      "startOffset" : 132,
      "endOffset" : 149
    }, {
      "referenceID" : 10,
      "context" : "Specifically, we employ the canonical multi-head attention (MHA) network (Vaswani et al., 2017).",
      "startOffset" : 73,
      "endOffset" : 95
    }, {
      "referenceID" : 16,
      "context" : "We conduct comprehensive experiments on document-level RE dataset DocRED (Yao et al., 2019) and joint entity and relation extraction dataset NYT (Riedel et al.",
      "startOffset" : 73,
      "endOffset" : 91
    }, {
      "referenceID" : 8,
      "context" : ", 2019) and joint entity and relation extraction dataset NYT (Riedel et al., 2010) and WebNLG (Gardent et al.",
      "startOffset" : 61,
      "endOffset" : 82
    }, {
      "referenceID" : 12,
      "context" : "We provide our reproduced results of TPLinker (Wang et al., 2020) and the baseline system of Xu et al.",
      "startOffset" : 46,
      "endOffset" : 65
    }, {
      "referenceID" : 11,
      "context" : "47 Test F1, and also outperforms several previous studies including BERT-TS (Wang et al., 2019), CorefBERT (Ye et al.",
      "startOffset" : 76,
      "endOffset" : 95
    }, {
      "referenceID" : 17,
      "context" : ", 2019), CorefBERT (Ye et al., 2020), LSR (Nan et al.",
      "startOffset" : 19,
      "endOffset" : 36
    } ],
    "year" : 0,
    "abstractText" : "Multi-triple extraction is a challenging task due to the existence of informative inter-triple correlations and consequently rich interactions across the constituent entities and relations. While existing works only explore cross-entity interactions, we propose to explicitly introduce relation representation, jointly represent it with entities, and novelly align them to identify valid triples. We perform comprehensive experiments1 on document-level relation extraction and joint entity and relation extraction along with detailed ablations to demonstrate the advantage of the proposed method.",
    "creator" : null
  }
}