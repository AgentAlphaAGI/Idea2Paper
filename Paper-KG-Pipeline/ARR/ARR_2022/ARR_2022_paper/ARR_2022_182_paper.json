{
  "name" : "ARR_2022_182_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "MetaWeighting: Learning to Weight Tasks in Multi-Task Text Classification",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Multi-task Learning (MTL) simultaneously learns multiple related tasks and aims to achieve better performance than learning each task independently (Caruana, 1993; Baxter, 2000). It has achieved great success in various applications; especially, in the text classification context, MTL can significantly outperform single task learning (Liu et al., 2017; Mao et al., 2021).\nIn MTL, it is common for the including tasks to be competing. If we cannot properly balance these tasks, some tasks might dominate the training process and hurt the performance of other tasks, a phenomenon known as task imbalance. To address the task imbalance, the most widely used method is task weighting, which adaptively assigns weights on the tasks during training to balance their impacts. Various task weighting methods have been proposed and can be used in multi-task text classification, such as (Kendall et al., 2018; Sener and Koltun, 2018; Chen et al., 2018).\nHowever, existing task weighting methods compute the task weights only based on training losses or corresponding gradients. They ignore the gap\nbetween the training loss and generalization loss. To illustrate this gap, we report observations of our four-task topic classification experiment in Figure 1. The detailed experimental settings are introduced in the experiment section. Figure 1 demonstrates that training losses and generalization losses (estimated by the test losses) have different magnitudes; moreover, they have different patterns, such as a task might have largest training loss but have the lowest generalization loss among the tasks.\nThis gap causes a mismatch between the task weights and tasks’ generalization performance, which reduces effectiveness of the task weighting. To tackle this issue, this paper proposes a novel task weighting method based on a bi-level optimization problem, which aims to find task weights that explicitly optimize the generalization performance. Our proposed method computes task weights by solving this bi-level optimization problem and performs in a learning-to-learn manner; thus, dubbed MetaWeighting. MetaWeighting can improve the performance of multi-task text classification.\nTo verify our theoretical analysis and validate the superiority of MetaWeighting, we conduct experiments on two classical text classification problems: sentiment analysis (on reviews) and topic classification (on news). The results demonstrate that MetaWeighting outperforms several state-of-the-art multi-task text classification methods."
    }, {
      "heading" : "2 Related Works",
      "text" : "Existing task weighting strategies can be divided into two categories: weight adaptation methods and Pareto Optimization (PO)-based methods. The weight adaptation methods adaptively adjust the tasks’ weights during training based on pre-defined heuristic, such as uncertainty (Kendall et al., 2018), task difficulty prioritization (Guo et al., 2018), gradient normalization (Chen et al., 2018), weight average (Liu et al., 2019) and task variance regularization (Mao et al., 2021). These methods only use training losses or their gradients to compute task weights while ignores the gap between the training loss and generalization loss.\nBesides, the PO-based methods formulate MTL as a multi-objective optimization problem and aim to find an arbitrary Pareto stationary solution (Sener and Koltun, 2018; Lin et al., 2019; Mahapatra and Rajan, 2020; Lin et al., 2020; Ma et al., 2020; Mao et al., 2020). However, in these methods, the learning objectives only involve training losses; thus, they can only achieve Pareto stationary points w.r.t training losses. They also ignore the gap between the training loss and generalization loss. Moreover, (Lin et al., 2019) proposes that the PO-based methods can be also regarded as weight adaptation methods for they optimize the weighted sum of training losses as well.\nOverlooking the gap between the training loss and generalization loss would degenerate the performance of MTL. This paper proposes a novel task weighting method to solve this issue."
    }, {
      "heading" : "3 Preliminaries",
      "text" : "Consider a multi-task learning problem with T tasks over an input space X and a collection of task spaces {Yt}Tt=1. For each task, we have a set of i.i.d. training samples Dt = {xit, yit} n i=1. The training samples are sampled from an identical distribution Pt. Based on the training sets {Dt}Tt=1, we learn an MTL model from a parameterized hypothesis class H, which shares some parameters across tasks. Let θs represent the parameters shared between tasks (task-sharing parameters), while θt represent the task-specific parameters. h(·, θs, θ1, ..., θT ) : X → {Yt}Tt=1 ∈ H denotes an MTL model that learns fromH, while h(·, θs, θt) : X → Yt denotes the task-specific module in the MTL model.\nThe loss function is represented by l(·, ·) : Yt × Yt → [0, 1]T . For each task, the generaliza-\ntion loss is Lt(θ) = E(xt,yt)∼Pt l(h(xt, θs, θt), yt), and the training loss is defined as Ltrt (θ,Dt) =\n1 |Dt| ∑ (xt,yt)∈Dt l(h(xt, θs, θt), yt). In this paper, each training set Dt is randomly divided into two subsets: support set Dst and query set D q t . Correspondingly; moreover, the support loss is defined as Lst (θ,Dst ) = 1|Dst | ∑ (xt,yt)∈Dst\nl(h(xt, θs, θt), yt), and the query loss is defined as Lqt (θ,D q t ) =\n1 |Dqt | ∑ (xt,yt)∈Dqt l(h(xt, θs, θt), yt)."
    }, {
      "heading" : "3.1 Hypergradient Descent",
      "text" : "Hypergradient Descent (HD) (Almeida et al., 1998; Baydin et al., 2018) provides an efficient way to apply gradient descent on hyper-parameters. Here, we take learning rate’s HD as an example to introduce the basic form of HD. Given an objective function f(θ) and previous parameters θk−1, gradient descent-based learning typically evaluates the gradient ∇f(θk−1) and moves against it to arrive at updated parameters\nθk = θk−1 − η∇f(θk−1), (1)\nwhere η is the learning rate. HD derives an update rule for the learning rate η itself. Based on Eq. (1) and the chain rule, we have\n∂f(θk) ∂η = ∇f(θ k) · ∂(θ k−1−η∇f(θk−1)) ∂η\n= ∇f(θk) · (−∇f(θk−1)), (2)\nwith which we construct a update rule for η:\nηk+1 = ηk + β∇f(θk) · ∇f(θk−1), (3)\nintroducing β as the hypergradient step size. In this paper, we extend HD to a bi-level multi-objective optimization problem."
    }, {
      "heading" : "3.2 Common Descent Direction for Multiple Objectives",
      "text" : "When using gradient descent to jointly optimize multiple optimization objectives, we need to find a descent direction common to all the objectives. Based on the descent direction for each objective, (Désidéri, 2012) proposes a way to obtain the common descent direction, as in Theorem 1. This paper proposes a method to simultaneously optimize the tasks’ generalization loss based on Theorem 1.\nTheorem 1 ((Désidéri, 2012)). Let A be a Hilbert space of finite or infinite dimension N . Let fi(z) (1 ≤ i ≤ n ≤ N) be n smooth functions of the vector z ∈ A. and z0 a particular admissible designpoint, at which the gradient-vectors are denoted\ngi = ∇fi(z0), and\nU = {a ∈ A|a = n∑\ni=1\nλigi;λi > 0(∀i); n∑\ni=1\nλi = 1}. (4)\nLet a∗ = argmina∈Ū ‖ a ‖, where U consists of the convex hull and closure of U . Then, if a∗ 6= 0, a∗ is a descent direction common to all the objectives."
    }, {
      "heading" : "4 MetaWeighting for MTL",
      "text" : "In this section, we demonstrate the gap between existing task weighting strategies and the generalization performance of MTL in Section 4.1. This gap motivates us to proposed a MetaWeighting problem, which aims to automatically learn a task weighting strategy that can narrow this gap, in Section 4.2. Moreover, we propose an algorithm to solve the MetaWeighting problem in Section 4.3."
    }, {
      "heading" : "4.1 Gap Between Task Weighting and Generalization Performance",
      "text" : "MTL aims to improve the generalization performance of all the including tasks, which can be formulated via the following optimization problem.\nmin θ\nL(θ) = (L1(θ), ...,LT (θ))>, (5)\nBy contrast, existing task weighting strategies train a MTL model via the following objective.\nmin θ\n1 T wtLtrt (θ,Dt), (6)\nwhere the wt is adaptive during training and only depends on the training losses or their gradients. As the neural networks are usually heavily overparameterized (Allen-Zhu et al., 2019), the training losses cannot properly estimate the generalization losses. Thus, existing task weighting strategies, which tunes weights only based on the training losses, overlook the generalization losses. Obviously, there is a gap between these task weighting strategies and the generalization performance of MTL."
    }, {
      "heading" : "4.2 MetaWeighting Problem",
      "text" : "To narrow the gap between task weighting strategies and generalization performance, we propose to automatically learn task weights that can reduce the generalization losses, namely learning to weight. This learning to weight problem is formlated via the following bi-level optimization problem, dubbed MetaWeighting.\nProblem 1.\nmin w\n(L1(θ∗(w)), ...,LT (θ∗(w)))>\ns.t. θ∗(w) = argmin θ\n1\nT T∑ t=1 wtLtrt (θ,Dt) (7)\nwhere w = (w1, w2, ..., wT ). This bi-level optimization problem combines (5) and (6) together, by solving which we can obtain task weights that benefit the generalization performance of MTL.\nHowever, the generalization loss is agnostic. To properly estimate the generalization loss, we randomly divide the training set Dt into two subsets: support set Dst and query set D q t , where D s t is used to train a MTL model, and Dqt is used to estimate generalization loss of the MTL model. In Section 5, we theoretically demonstrate that query loss is a good estimator for the generalization loss; besides, in Section 6.7, experimental analysis also supports that query loss is a good estimator.\nBased on the support-query split, the MetaWeighting problem is transformed into the following form.\nProblem 2.\nmin w\n(Lq1(θ ∗(w), Dq1), ...,L q T (θ ∗(w), DqT )) >\ns.t. θ∗(w) = argmin θ\n1\nT T∑ t=1 wtLst (θ,Dst ) (8)"
    }, {
      "heading" : "4.3 MetaWeighting Algorithm",
      "text" : "In the MetaWeighting problem, the inner optimization objective is embedded within the outer optimization objective. In MTL, the inner optimization objective is to minimize the weighted sum of task-specific training losses, which is typically optimized by means of iterative gradient descent; thus, Problem 2 can be formulated by the following problem in the kth learning iteration.\nProblem 3.\nmin w\n(Lq1(θ k, Dq1), ...,L q T (θ k, DqT )) >\ns.t. θk = θk−1 − η T T∑ t=1 wt∇θLst (θk−1, Dst )\n(9)\nTo solve Problem 3, we adopt the Hypergradient Descent (HD) method. However, the original HD method (Almeida et al., 1998; Baydin et al., 2018) is proposed for single objective optimization, which can not used in our problem where a multiobjective optimization problem involves. In this\nsection, this paper proposes a novel HD method for the multi-objective optimization setting, as in the following sections."
    }, {
      "heading" : "4.3.1 Task-Specific Descent Direction",
      "text" : "The learning objective of Problem 3 involves T objectives. We aim to find a gradient direction, moving against which all the objective can be optimized. To find this gradient direction, we first find the hypergradient direction w.r.t w (denoted as dt) for each task. dt is computed by the following equation.\ndt = ∂Lqt (θk, D q t )\n∂w = ∇θLqt (θk, D q t ) ·\n∂θk\n∂w = − η\nT ∇θLqt (θk, D q t )∇θLs(θk−1, Ds).\n(10)\nwhere ∇θLs(θk−1, Ds) = (∇θLs1(θk−1, Ds1)>, ...,∇θLsT (θk−1, DsT )>). Moving against dt, the generalization loss of task t can be optimized."
    }, {
      "heading" : "4.3.2 Common Descent Direction",
      "text" : "Base on dt, in this section, we find a common gradient direction, moving against which all the objective can be optimized. Let d = (d>1 , d>2 , ..., d>T ) and dc be the common gradient direction. Theorem 1 presents that the following Eq. (11) is a common descent direction.\ndc = λ ∗d> (11)\nwhere\nλ∗ = argmin λ {‖ λd> ‖22 |λ1> = 1, λ 0},\n(12) where 1 = (1, 1, ..., 1). Eq. (12) is a typical minimum Euclidean-norm point problem. We here adopt the widely used Frank-Wolfe optimization algorithm (Jaggi, 2013), a minimum-norm-point algorithm, to solve it. The Frank-Wolfe optimization algorithm is presented in Algorithm 2."
    }, {
      "heading" : "4.3.3 MetaWeighting",
      "text" : "Moving against dc, all the objective can be optimized; thus, the update rule of w is\nwk+1 = wk − αdc. (13)\nwhere α is the step size. Based on this update rule, the task weights are automatically learnt oriented by optimizing the generalization losses.\nOverall, we propose the MetaWeighting algorithm, which is presented in algorithmic form in\nAlgorithm 1: MetaWeighting Algorithm Input: data {Dst }Tt=1 and {D q t }Tt=1, step size α\nfor updating w, Number of learning iterations K. Initialize: w0 = (1, 1, ..., 1), θ0, η. for k = 1 to K do θk = θk−1 − ηT ∑T t=1wt∇θLst (θk−1, Dst ).\nfor t = 1 to T do dt = − ηT∇θL q t (θ\nk, Dqt )∇θLs(θk−1, Ds). end for d = (d1>, d2>, ..., dT>) λ∗ = argminλ{‖ λd> ‖22 |λ1> = 1, λ 0} (calls Algorithm 2). dc = λ\n∗d>. wk+1 = wk − αdc.\nend for\nAlgorithm 2: Frank-Wolfe Algorithm Input: Number of Iterations N . Initialize: λ0 = [ 1T , ..., 1 T ].\nB = d>d. for i = 0 to N do v = arg min\nv∈{v>1=1,v 0} v>Bλ.\nγ = arg min\nγ∈[0,1] (λi+γ(v−λi))>B(λi+γ(v−λi)).\nλi+1 = (1− γ)λi + γv. end for return: λN\nAlgorithm 1. Our proposed method bridges the gap between task weighting and generalization performance of MTL."
    }, {
      "heading" : "5 Theoretical Analysis",
      "text" : "In this section, we study the generalization error bound for MTL; furthermore, we compare the bound w.r.t training loss and the bound w.r.t the query loss. The comparison presents that the query loss is a more accurate estimation of the generalization loss than the training loss.\nFirstly, we derive the generalization error bound w.r.t training loss for MTL.\nTheorem 2. Assume we have n training samples for each task. Let σ = {{σti}ni=1}Tt=1 be a sequence of binary random variables such that each σti = ±1 is independent with probability 1/2. Then, ∀δ ∈ [0, 1], for all h(·, θs, θ1, ..., θT ) ∈ H, with\nprobability of at least 1− δ:\n1 T ∑T t=1 (Lt(θ)− Ltrt (θ,Dt)) ≤ 2R(l ◦ H ◦D) + 4 √ 2 log(4/δ)\nTn .\n(14) where\nR(l◦H◦D) = Eσ sup θ ( 1 Tn T∑ t=1 n∑ i=1 σti l(h(x t i, θ), y t i). (15) is the Rademacher complexity for MTL.\nProof. The proof is provided in Appendix A.\nNext, we derive the generalization error bound w.r.t query loss for MTL.\nTheorem 3. Assume we have m training samples for each task. ∀δ ∈ [0, 1], with probability of at least 1−δ, for all h(·, θs, θ1, ..., θT ) ∈ H, we have\n1\nT T∑ t=1 (Lt(θ)−Lqt (θ,D q t )) ≤\n√ log(2/δ)\n2m . (16)\nProof. The proof is provided in Appendix A.\nComparing the bound (14) and (16), we can find that the upper bound for the query loss is tighter than that for the training loss. Taking m to be order of n, the query loss is a more accurate estimate of the generalization loss than the training loss by a factor that depends on the Rademacher complexity."
    }, {
      "heading" : "6 Experiments",
      "text" : "In this section, we perform experimental studies on sentiment analysis to evaluate the performance of our proposed MetaWeighting and verify our theoretical analysis. The implementation is based on PyTorch (Paszke et al., 2019). The code is attached in the supplementary materials."
    }, {
      "heading" : "6.1 Datasets",
      "text" : "Sentiment Analysis 1. We evaluate our algorithm on product reviews from Amazon. The dataset (Blitzer et al., 2007) contains product reviews from 14 domains, including books, DVDs, electronics, kitchen appliances and so on. We consider each domain as a binary classification task. Reviews with rating > 3 were labeled positive, those with rating < 3 were labeled negative, reviews with\n1https://www.cs.jhu.edu/~mdredze/ datasets/sentiment/\nrating = 3 are discarded as the sentiments were ambiguous and hard to predict.\nTopic Classification 2. We select 16 newsgroups from the 20 Newsgroup dataset, which is a collection of approximately 20,000 newsgroup documents that is partitioned (nearly) evenly across 20 different newsgroups, then formulate them into four 4-class classification tasks (as shown in Table 1) to evaluate the performance of our algorithm on topic classification."
    }, {
      "heading" : "6.2 Baselines",
      "text" : "We compare MASS-MTL with following baselines.\nSingle-Task Learning (STL): learning each task independently.\nUniform: learning tasks simultaneously using uniform task weights.\nUncertainty: using the uncertainty weighting method proposed by (Kendall et al., 2018).\nGradNorm: using the gradient normalization method proposed by (Chen et al., 2018).\nMGDA: using the MGDA-UB method proposed by (Sener and Koltun, 2018).\nAdvMTL: using the adversarial Multi-task Learning method proposed by (Liu et al., 2017).\nTchebycheffAdv: using the Adversarial Tchebycheff procedure proposed by (Mao et al., 2020).\nBanditMTL: using the BanditMTL method proposed by (Mao et al., 2021)."
    }, {
      "heading" : "6.3 Experimental Settings",
      "text" : "We adopt the hard parameter-sharing MTL framework (Mao et al., 2021), where the shared representation extractor is built with TextCNN or BERT; besides, the task-specific module is formulated by means of one fully connected layer ending with a softmax function. For TextCNN, we adopt Pretrained GloVe (Pennington et al., 2014) word embeddings. For BERT, we adopt the pre-trained BERT-base model (uncased) provided by Hugging\n2http://qwone.com/~jason/20Newsgroups/\n87\n88\n89\n90\n91 (%) apparel\n86\n87\n88\n89\n90\n91 (%) baby\n84\n86\n88\n(%) books\n88\n89\n90\n91\n92\n93 (%) camera_photo\n82\n84\n86\n88\n90\n(%) dvd\n84\n86\n88\n90\n(%) electronics\n88\n90\n92\n(%) health_personal_care\n84\n86\n88\n90\n(%) kitchen_housewares\n90\n91\n92\n93\n94\n95 (%) magazines\n82\n84\n86\n88 (%) music\nSin gle Uni form Adv MTLMG DA\nGra dNo\nrm Unc erta inty\nTch eby\nche ff_A\ndv\nBan ditM\nTL\nMet aW\neig htin\ng 88\n90\n92\n94\n(%) software\nSin gle Uni form Adv MTLMG DA\nGra dNo\nrm Unc erta inty\nTch eby\nche ff_A\ndv\nBan ditM\nTL\nMet aW\neig htin\ng 84\n86\n88\n90\n92 (%) sports_outdoors\nSin gle Uni form Adv MTLMG DA\nGra dNo\nrm Unc erta inty\nTch eby\nche ff_A\ndv\nBan ditM\nTL\nMet aW\neig htin\ng 85\n86\n87\n88\n89\n90\n91 (%) toys_games\nSin gle Uni form Adv MTLMG DA\nGra dNo\nrm Unc erta inty\nTch eby\nche ff_A\ndv\nBan ditM\nTL\nMet aW\neig htin\ng 86\n87\n88\n89\n90\n(%) video\nSin gle Uni form Adv MTLMG DA\nGra dNo\nrm Unc erta inty\nTch eby\nche ff_A\ndv\nBan ditM\nTL\nMet aW\neig htin\ng 86\n87\n88\n89\n90\n(%) average\nFigure 2: Classification accuracy of Single Task Learning, Uniform Scaling, AdvMTL, MGDA, GradNorm, Uncertainty, TchebycheffAdv, BanditMTL and MetaWeighting on TextCNN for the sentiment analysis dataset. Each colored cluster illustrates the classification accuracy performance of a method over 10 runs. Our proposed MetaWeighting outperforms all baselines on ten of the fourteen tasks; besides, its average performance is superior to that of all baselines.\nSin gle Uni form Adv MTLMG DA\nGra dNo\nrm Unc erta inty\nTch eby\nche ff_A\ndv\nBan ditM\nTL\nMet aW\neig htin\ng\n86.0\n87.0\n88.0\n89.0\n(%) comp\nSin gle Uni form Adv MTLMG DA\nGra dNo\nrm Unc erta inty\nTch eby\nche ff_A\ndv\nBan ditM\nTL\nMet aW\neig htin\ng 95.0\n95.5\n96.0\n96.5\n97.0\n(%) rec\nSin gle Uni form Adv MTLMG DA\nGra dNo\nrm Unc erta inty\nTch eby\nche ff_A\ndv\nBan ditM\nTL\nMet aW\neig htin\ng 94.5\n95.0\n95.5\n96.0\n96.5\n97.0 (%) sci\nSin gle Uni form Adv MTLMG DA\nGra dNo\nrm Unc erta inty\nTch eby\nche ff_A\ndv\nBan ditM\nTL\nMet aW\neig htin\ng\n85.0\n85.5\n86.0\n86.5\n87.0\n(%) talk\nSin gle Uni form Adv MTLMG DA\nGra dNo\nrm Unc erta inty\nTch eby\nche ff_A\ndv\nBan ditM\nTL\nMet aW\neig htin\ng\n90.5\n91.0\n91.5\n92.0\n(%) average\nFigure 3: Classification accuracy of Single Task Learning, Uniform Scaling, AdvMTL, MGDA, GradNorm, Uncertainty, TchebycheffAdv, BanditMTL and MetaWeighting on TextCNN for the topic classification dataset. Each colored cluster illustrates the classification accuracy performance of a method over 10 runs. Our proposed MetaWeighting outperforms all baselines in all tasks.\nFace(Wolf et al., 2020). We set α to be 0.1 and 0.5 for sentiment analysis and topic classification respectively, and the query-split radio (radio of query samples to entire training samples) to be 0.1 for both sentiment analysis and topic classification. The detailed experimental settings are introduced in the Appendix B."
    }, {
      "heading" : "6.4 Classification Performance",
      "text" : "We compare the proposed MetaWeighting with the baselines and report the results over 10 runs by plotting the classification accuracy of each task for both sentiment analysis and topic classification. The results on TextCNN are shown in Fig. 2 and\n3. Due to space limitations, we provide the results for BERT in the Appendix C. All experimental results show that our proposed MetaWeighting outperforms all baselines and achieves state-of-the-art performance."
    }, {
      "heading" : "6.5 The Impact of Query-Split Radio",
      "text" : "Let n be the size of the entire training set and m be the size of the query set. We define the querysplit radio as ρ = mn to indicate the radio of query samples to the entire training samples. From the theoretical analysis of Section 5, we can see that the query loss can estimate generalization loss more accurately when ρ increases, but increasing ρ would hurt the training process for the size of support set decreases. Therefore, ρ faces a trade-off between the performance estimation of generalization loss and training performance.\nTo investigate the impact of ρ, we record the changes in MetaWeighting’s average classification accuracy w.r.t different values of ρ in Fig. 4, where each boxplot visually illustrates the distribution of results over ten runs through displaying the data quartiles (first quartile and third quartile), minimum/maximum value and median. These experiments are conducted based on TextCNN. In this figure, as ρ increases, the average accuracy of\nMetaWeighting first increases and then decreases. It verifies our theoretical analysis. For both sentiment analysis and topic classification, setting ρ = 0.1 provides satisfactory results."
    }, {
      "heading" : "6.6 Sensitive Study on α",
      "text" : "In MetaWeighting, the step size α is a hyperparameter. To determine whether the performance of MetaWeighting is sensitive to α, we conduct experiments on the classification accuracy performance of MetaWeighting w.r.t different values of α based on the TextCNN model. The results of these experiments are presented in Figure 5 (boxplots over ten runs). As the figure shows, the performance of our proposed method is not very sensitive to α when α is within the range of 0.05 to 0.1 for sentiment analysis and 0.1 to 0.5 for topic classification. The results demonstrate that MetaWeighting can work well in a wide range of α values."
    }, {
      "heading" : "6.7 The Gap between the Training Loss, Query Loss and Generalization Loss",
      "text" : "To experimentally verify that the query loss is a good estimator for generalization loss, we record the generalization loss (estimated by test loss), query loss and training loss for each task during training and report the results in Fig. 7 and 6 for\nsentiment analysis and topic classification respectively. From these figures, we can see that there is a large gap between the training and generalization loss, and the gap between the query and generalization loss is smaller than that between the training and generalization loss. The results verify our theoretical analysis in Section 5; furthermore, they experimentally support our motivation for MetaWeighting.\nIn this section, TextCNN is used, and tasks have uniform weights during training. Fig. 1 is obtained under this setting as well."
    }, {
      "heading" : "6.8 The Evolution of Task Weights",
      "text" : "In this section, we observe the changes in task weights in the training process of MetaWeighting and compare these changes with four baselines (Uncertainty, Gradnorm, MGDA and BanditMTL). The results for sentiment analysis and topic classification are reported in Fig. 8 and 9 respectively. Due to space limitations, for sentiment analysis, we only report the results of the first four tasks here, and the results of the other ten tasks are presented\nin the Appendix D. From these figures, we can see that the weight adaption process of MetaWeighting is different with that of Uncertainty, Gradnorm, MGDA and BanditMTL. In MetaWeighting, the task weights are automatically learnt, and there is no pre-defined heuristic involved. It is verified by the evolution curves of task weights for MetaWeighting illustrated in Fig. 8 and 9, which fluctuate without any regular patterns."
    }, {
      "heading" : "7 Conclusion",
      "text" : "This paper presents that the gap between the training loss and the generalization loss, which is overlooked by existing task weighting methods, is nonnegligible; furthermore, to narrow this gap, a novel task weighting method (dubbed MetaWeighting) is proposed. MetaWeighting works in a learningto-learn manner, which automatically learns the task weights without any pre-defined heuristic and achieves state-of-the-art performance. It has the potential to forge new trends in task weighting research."
    }, {
      "heading" : "A Proof of the Theorem 2 and Theorem 3",
      "text" : "Lemma 1 (McDiarmid’s Inequality). Let V be some set and let f : V n → R be a function of n variables such that for some c > 0 , for all i ∈ [n] and for all z1, ..., zn, z′i ∈ V we have\n|f(z1, ..., zn)−f(z1, ..., zi−1, z′i, zi+1, ..., zn)| ≤ c. (17) Let Z1, ..., Zn be n independent random variables taking values in V . Then, with probability of at least 1− δ we have\n|f(Z1, ..., Zn)−E[f(Z1, ..., Zn)]| ≤ c √ n log(2/δ)\n2 . (18)\nLemma 2 (Hoeffding’s Inequality). Let z1, ..., zm be a a sequence of i.i.d. random variables and assume that for all i, E(zi) = µ and P (a ≤ zi ≤ b) = 1. Then, for any > 0\nP [∣∣∣∣∣ 1m m∑ i=1 zi − µ ∣∣∣∣∣ > ] ≤ 2exp( −2m 2 (b− a)2 ).\n(19)\nLemma 3. Assume that ∀(xit, yit), (x j t , y j t ) : |l(h(xit, θs, θt), yit)− l(h(x j t , θ s, θt), yjt )| ≤ c. Let\nRep(H, D) = sup h∈H\n1\nT T∑ t=1 (Lt(θ)− Ltrt (θ,Dt)),\n(20) then ∀δ ∈ [0, 1], with probability of at least 1− δ:\nRep(H, D) ≤ EDRep(H, D) + c √ 2 log(2/δ)\nTn .\n(21)\nProof. Let sit = (x i t, y i t). The training set for MTL is D = {{(s11, ..., sn1}, ..., {s1t , ..., snt }, ..., {s1T , ..., snT }}. For ∀t, i, replace sit with uit = (x∗t , y∗t ) ∈ Dt and create a new dataset D = {{(s11, ..., sn1}, ..., {s1t , ..., uit, ..., snt }, ..., {s1T , ..., snT }}. Let ht(·) = h(·, θs, θt). As ∀(xit, yit), (x j t , y j t ) : |l(h(xit, θs, θt), yit) − l(h(x j t , θ\ns, θt), yjt )| ≤ c, we have\nRep(H, D)−Rep(H, D) ≤ sup\nh∈H\n1 Tn |l(ht(x n t ), y n t )− l(ht(x∗t ), y∗t ))| ≤ cTn .\n(22)\nUsing the McDiarmid’s Inequality (Lemma 1), we have\nRep(H, D) ≤ EDRep(H, D) + 2cTn √ Tn log(2/δ) 2\n= EDRep(H, D) + c √ 2 log(2/δ) Tn .\n(23) We conclude our proof.\nProof of Theorem 2.\nProof. Using the standard symmetrization argument (for example, see Lemma 2.3.1 of (Aad van der Vaart, 1996) ), we have\nEDRep(H, D) ≤ 2EDR(l ◦ H ◦D). (24)\nCombining Eq. (21) and Eq. (24), with probability 1− δ/2:\nsuph∈H 1 T ∑T t=1(Lt(θ)− Ltrt (θ,Dt))\n≤ 2EDR(l ◦ H ◦D) + c √ 2 log(4/δ) Tn .\n(25)\nObviously, with probability of at least 1− δ/2, for all h ∈ H, we have\n1 T ∑T t=1(Lt(θ)− Ltrt (θ,Dt))\n≤ 2EDR(l ◦ H ◦D) + c √ 2 log(4/δ) Tn . (26)\nLet sit = (x i t, y i t). The\ntraining set for MTL is D = {{(s11, ..., sn1}, ..., {s1t , ..., snt }, ..., {s1T , ..., snT }}. For ∀t, i, replace sit with uit = (x∗t , y∗t ) ∈ Dt and create a new dataset D = {{(s11, ..., sn1}, ..., {s1t , ..., uit, ..., snt }, ..., {s1T , ..., snT }}. Let ht(·) = h(·, θs, θt). As ∀(xit, yit), (x j t , y j t ) : |l(h(xit, θs, θt), yit) − l(h(x j t , θ\ns, θt), yjt )| ≤ c, we have\nRep(H, D)−Rep(H, D) ≤ sup h∈H 1 Tn |l(ht(x n t ), y n t )− l(ht(x∗t ), y∗t ))| ≤ cTn\n(27) Using the McDiarmid’s Inequality (Lemma 1), we have that: with probability of at least 1− δ/2:\nEDR(l ◦ H ◦D) ≤ R(l ◦ H ◦D) + 2c √ 2 log(4/δ) Tn .\n(28) Based on Eq. (28) and the union bound, we have that - with probability of at least 1− δ:\n1 T ∑T t=1(Lt(θ)− Ltrt (θ,Dt))\n≤ 2R(l ◦ H ◦D) + 4c √\n2 log(4/δ) Tn .\n(29)\nIn our setting, l(·, ·) : Yt×Yt → [0, 1], then c = 1. We have\n1 T ∑T t=1(Lt(θ)− Ltrt (θ,Dt))\n≤ 2R(l ◦ H ◦D) + 4 √\n2 log(4/δ) Tn .\n(30)\nWe conclude our proof.\nBased on the Hoeffding’s Inequality (Lemma 2), we have the following theorem.\nProof of Theorem 3.\nProof. Based on the Hoeffding’s Inequality (Lemma 2) and l(·, ·) : Yt × Yt → [0, 1], for each h(·, θs, θt) ∈ Ht, we have\nP [|Lt(θ)− Lqt (θ,Dt)| > ] ≤ 2exp(−2m 2). (31) Then, with probability of at least 1−2exp(−2m 2), we have\n|Lt(θ)− Lqt (θ,Dt)| ≤ . (32)\nLet δ = 2exp(−2m 2), we have that with probability of at least 1− δ,\n|Lt(θ)− Lqt (θ,Dt)| ≤ √ log(2/δ)\n2m . (33)\nThus, for each task, Lt(θ)− Lqt (θ,Dt) ≤ √ log(2/δ)\n2m . (34)\nSince the bound for each task are independent, we have\n1\nT T∑ t=1 (Lt(θ)− Lqt (θ,Dt)) ≤ √ log(2/δ) 2m . (35)\nWe conclude our proof."
    }, {
      "heading" : "B Detailed Experimental Settings",
      "text" : "We adopt the hard parameter-sharing MTL framework (Mao et al., 2021), where the shared representation extractor is built with TextCNN or BERT; besides, the task-specific module is formulated by means of one fully connected layer ending with a softmax function. The TextCNN module is structured with three parallel convolutional layers with kernels size of 3, 5, 7 respectively. For TextCNN, we adopt Pre-trained GloVe (Pennington et al., 2014) word embeddings. By contrast, the BERT module is formulated via a pre-trained\nBERT-base model provided by Hugging Face(Wolf et al., 2020), with a hidden size of 768, 12 Transformer blocks and 12 self-attention heads.\nWe train the deep MTL network model in line with Algorithm 1. We set α to be 0.1 and 0.5 for sentiment analysis and topic classification respectively, and the query-split radio (radio of query samples to entire training samples) to be 0.1 for both sentiment analysis and topic classification. We use the Adam optimizer (Kingma and Ba, 2015). We train over 3000 epochs for TextCNN and finetune over 50 epochs for BERT. For TextCNN, the learning rate is 1e − 3 and the batch size is 256. For BERT, the learning rate is 2e − 5 , the batch size is 32, and the max sequence length is 256. For the baselines, we search over the set {1e−5, 2e−5, 5e−5, 1e−4, 5e−4, 1e−3, 5e−3} learning rates and choose the model with best performance."
    }, {
      "heading" : "C Classification Performance on BERT",
      "text" : "For the BERT-based MTL model, we compare the proposed MetaWeighting with the baselines and report the results over 10 runs by plotting the classification accuracy of each task for both sentiment analysis and topic classification in Fig. 10 and 11. AdvMTL and TchebycheffAdv are not available for BERT; thus, we do not compare with AdvMTL and compare with Tchebycheff which is TchebycheffAdv without aversarial module (Mao et al., 2021). From these figures, we can see that our proposed MetaWeighting outperforms all baselines and achieves state-of-the-art performance."
    }, {
      "heading" : "D The Evolution of Task Weights for Sentiment Analysis",
      "text" : "Fig. 12 illustrates the changes in task weights in the training process of MetaWeighting for all the tasks of sentiment analysis.\nSin gle Uni formMG DA\nTch eby\nche ff Unc erta inty Gra dNo rm Ban ditM TL\nMet aW\neig htin\ng\n86.0\n88.0\n90.0\n(%) comp\nSin gle Uni formMG DA\nTch eby\nche ff Unc erta inty Gra dNo rm Ban ditM TL\nMet aW\neig htin\ng\n94.0\n95.0\n96.0\n97.0 (%) rec\nSin gle Uni formMG DA\nTch eby\nche ff Unc erta inty Gra dNo rm Ban ditM TL\nMet aW\neig htin\ng\n95.0\n95.5\n96.0\n96.5\n97.0\n(%) sci\nSin gle Uni formMG DA\nTch eby\nche ff Unc erta inty Gra dNo rm Ban ditM TL\nMet aW\neig htin\ng\n82.0\n83.0\n84.0\n85.0\n86.0 (%) talk\nSin gle Uni formMG DA\nTch eby\nche ff Unc erta inty Gra dNo rm Ban ditM TL\nMet aW\neig htin\ng\n89.5\n90.0\n90.5\n91.0\n91.5\n92.0\n92.5 (%) average\nFigure 11: Classification accuracy of Single Task Learning, Uniform Scaling, MGDA, TchebycheffAdv, Uncertainty, GradNorm, BanditMTL and MetaWeighting on BERT for the topic classification dataset. Each colored cluster illustrates the classification accuracy performance of a method over 10 runs. Our proposed MetaWeighting outperforms all baselines on three of the four tasks; besides, its average performance is superior to that of all baselines."
    } ],
    "references" : [ {
      "title" : "Weak convergence and empirical processes",
      "author" : [ "Jon Wellner Aad van der Vaart." ],
      "venue" : "Springer.",
      "citeRegEx" : "Vaart.,? 1996",
      "shortCiteRegEx" : "Vaart.",
      "year" : 1996
    }, {
      "title" : "Learning and generalization in overparameterized neural networks, going beyond two layers",
      "author" : [ "Zeyuan Allen-Zhu", "Yuanzhi Li", "Yingyu Liang." ],
      "venue" : "NeurIPS.",
      "citeRegEx" : "Allen.Zhu et al\\.,? 2019",
      "shortCiteRegEx" : "Allen.Zhu et al\\.",
      "year" : 2019
    }, {
      "title" : "Parameter adaptation in stochastic optimization",
      "author" : [ "Luís B Almeida", "Thibault Langlois", "José D Amaral", "Alexander Plakhov." ],
      "venue" : "On-Line Learning in Neural Networks, pages 111–134. Cambridge University Press.",
      "citeRegEx" : "Almeida et al\\.,? 1998",
      "shortCiteRegEx" : "Almeida et al\\.",
      "year" : 1998
    }, {
      "title" : "A model of inductive bias learning",
      "author" : [ "Jonathan Baxter." ],
      "venue" : "Journal of artificial intelligence research, 12:149–198.",
      "citeRegEx" : "Baxter.,? 2000",
      "shortCiteRegEx" : "Baxter.",
      "year" : 2000
    }, {
      "title" : "Online learning rate adaptation with hypergradient descent",
      "author" : [ "Atilim Gunes Baydin", "Robert Cornish", "David MartínezRubio", "Mark Schmidt", "Frank Wood." ],
      "venue" : "ICLR.",
      "citeRegEx" : "Baydin et al\\.,? 2018",
      "shortCiteRegEx" : "Baydin et al\\.",
      "year" : 2018
    }, {
      "title" : "Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification",
      "author" : [ "John Blitzer", "Mark Dredze", "Fernando Pereira." ],
      "venue" : "ACL.",
      "citeRegEx" : "Blitzer et al\\.,? 2007",
      "shortCiteRegEx" : "Blitzer et al\\.",
      "year" : 2007
    }, {
      "title" : "Multitask learning: A knowledgebased source of inductive bias",
      "author" : [ "Rich Caruana." ],
      "venue" : "ICML.",
      "citeRegEx" : "Caruana.,? 1993",
      "shortCiteRegEx" : "Caruana.",
      "year" : 1993
    }, {
      "title" : "Gradnorm: Gradient normalization for adaptive loss balancing in deep multitask networks",
      "author" : [ "Zhao Chen", "Vijay Badrinarayanan", "Chen-Yu Lee", "Andrew Rabinovich." ],
      "venue" : "ICML.",
      "citeRegEx" : "Chen et al\\.,? 2018",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2018
    }, {
      "title" : "Multiple-gradient descent algorithm (mgda) for multiobjective optimization",
      "author" : [ "Jean-Antoine Désidéri." ],
      "venue" : "Comptes Rendus Mathematique, 350(56):313–318.",
      "citeRegEx" : "Désidéri.,? 2012",
      "shortCiteRegEx" : "Désidéri.",
      "year" : 2012
    }, {
      "title" : "Dynamic task prioritization for multitask learning",
      "author" : [ "Michelle Guo", "Albert Haque", "De-An Huang", "Serena Yeung", "Li Fei-Fei." ],
      "venue" : "ECCV.",
      "citeRegEx" : "Guo et al\\.,? 2018",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2018
    }, {
      "title" : "Revisiting frank-wolfe: Projectionfree sparse convex optimization",
      "author" : [ "Martin Jaggi." ],
      "venue" : "ICML.",
      "citeRegEx" : "Jaggi.,? 2013",
      "shortCiteRegEx" : "Jaggi.",
      "year" : 2013
    }, {
      "title" : "Multi-task learning using uncertainty to weigh losses for scene geometry and semantics",
      "author" : [ "Alex Kendall", "Yarin Gal", "Roberto Cipolla." ],
      "venue" : "CVPR.",
      "citeRegEx" : "Kendall et al\\.,? 2018",
      "shortCiteRegEx" : "Kendall et al\\.",
      "year" : 2018
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P. Kingma", "Jimmy Ba." ],
      "venue" : "ICLR.",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "Controllable pareto multi-task learning",
      "author" : [ "Xi Lin", "Zhiyuan Yang", "Qingfu Zhang", "Sam Kwong." ],
      "venue" : "CoRR.",
      "citeRegEx" : "Lin et al\\.,? 2020",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2020
    }, {
      "title" : "Pareto multi-task learning",
      "author" : [ "Xi Lin", "Hui-Ling Zhen", "Zhenhua Li", "Qingfu Zhang", "Sam Kwong." ],
      "venue" : "NIPS.",
      "citeRegEx" : "Lin et al\\.,? 2019",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2019
    }, {
      "title" : "Adversarial multi-task learning for text classification",
      "author" : [ "Pengfei Liu", "Xipeng Qiu", "Xuanjing Huang." ],
      "venue" : "ACL.",
      "citeRegEx" : "Liu et al\\.,? 2017",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2017
    }, {
      "title" : "End-to-end multi-task learning with attention",
      "author" : [ "Shikun Liu", "Edward Johns", "Andrew J. Davison." ],
      "venue" : "CVPR.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Efficient continuous pareto exploration in multi-task learning",
      "author" : [ "Pingchuan Ma", "Tao Du", "Wojciech Matusik." ],
      "venue" : "ICML.",
      "citeRegEx" : "Ma et al\\.,? 2020",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2020
    }, {
      "title" : "Multitask learning with user preferences: Gradient descent with controlled ascent in pareto optimization",
      "author" : [ "Debabrata Mahapatra", "Vaibhav Rajan." ],
      "venue" : "ICML.",
      "citeRegEx" : "Mahapatra and Rajan.,? 2020",
      "shortCiteRegEx" : "Mahapatra and Rajan.",
      "year" : 2020
    }, {
      "title" : "Banditmtl: Bandit-based multitask learning for text classification",
      "author" : [ "Yuren Mao", "Zekai Wang", "Weiwei Liu", "Xuemin Lin", "Wenbin Hu." ],
      "venue" : "ACL.",
      "citeRegEx" : "Mao et al\\.,? 2021",
      "shortCiteRegEx" : "Mao et al\\.",
      "year" : 2021
    }, {
      "title" : "Tchebycheff procedure for multi-task text classification",
      "author" : [ "Yuren Mao", "Shuang Yun", "Weiwei Liu", "Bo Du." ],
      "venue" : "ACL.",
      "citeRegEx" : "Mao et al\\.,? 2020",
      "shortCiteRegEx" : "Mao et al\\.",
      "year" : 2020
    }, {
      "title" : "Pytorch: An imperative style, high-performance deep learning library",
      "author" : [ "jani", "Sasank Chilamkurthy", "Benoit Steiner", "Lu Fang", "Junjie Bai", "Soumith Chintala" ],
      "venue" : "NeurIPS",
      "citeRegEx" : "jani et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "jani et al\\.",
      "year" : 2019
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher D. Manning." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Multitask learning as multi-objective optimization",
      "author" : [ "Ozan Sener", "Vladlen Koltun." ],
      "venue" : "NeurIPS.",
      "citeRegEx" : "Sener and Koltun.,? 2018",
      "shortCiteRegEx" : "Sener and Koltun.",
      "year" : 2018
    }, {
      "title" : "Transformers: State-of-the-art natural language processing",
      "author" : [ "Teven Le Scao", "Sylvain Gugger", "Mariama Drame", "Quentin Lhoest", "Alexander M. Rush." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Scao et al\\.,? 2020",
      "shortCiteRegEx" : "Scao et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "Multi-task Learning (MTL) simultaneously learns multiple related tasks and aims to achieve better performance than learning each task independently (Caruana, 1993; Baxter, 2000).",
      "startOffset" : 148,
      "endOffset" : 177
    }, {
      "referenceID" : 3,
      "context" : "Multi-task Learning (MTL) simultaneously learns multiple related tasks and aims to achieve better performance than learning each task independently (Caruana, 1993; Baxter, 2000).",
      "startOffset" : 148,
      "endOffset" : 177
    }, {
      "referenceID" : 15,
      "context" : "It has achieved great success in various applications; especially, in the text classification context, MTL can significantly outperform single task learning (Liu et al., 2017; Mao et al., 2021).",
      "startOffset" : 157,
      "endOffset" : 193
    }, {
      "referenceID" : 19,
      "context" : "It has achieved great success in various applications; especially, in the text classification context, MTL can significantly outperform single task learning (Liu et al., 2017; Mao et al., 2021).",
      "startOffset" : 157,
      "endOffset" : 193
    }, {
      "referenceID" : 11,
      "context" : "Various task weighting methods have been proposed and can be used in multi-task text classification, such as (Kendall et al., 2018; Sener and Koltun, 2018; Chen et al., 2018).",
      "startOffset" : 109,
      "endOffset" : 174
    }, {
      "referenceID" : 23,
      "context" : "Various task weighting methods have been proposed and can be used in multi-task text classification, such as (Kendall et al., 2018; Sener and Koltun, 2018; Chen et al., 2018).",
      "startOffset" : 109,
      "endOffset" : 174
    }, {
      "referenceID" : 7,
      "context" : "Various task weighting methods have been proposed and can be used in multi-task text classification, such as (Kendall et al., 2018; Sener and Koltun, 2018; Chen et al., 2018).",
      "startOffset" : 109,
      "endOffset" : 174
    }, {
      "referenceID" : 11,
      "context" : "The weight adaptation methods adaptively adjust the tasks’ weights during training based on pre-defined heuristic, such as uncertainty (Kendall et al., 2018), task difficulty prioritization (Guo et al.",
      "startOffset" : 135,
      "endOffset" : 157
    }, {
      "referenceID" : 9,
      "context" : ", 2018), task difficulty prioritization (Guo et al., 2018), gradient normalization (Chen et al.",
      "startOffset" : 40,
      "endOffset" : 58
    }, {
      "referenceID" : 7,
      "context" : ", 2018), gradient normalization (Chen et al., 2018), weight average (Liu et al.",
      "startOffset" : 32,
      "endOffset" : 51
    }, {
      "referenceID" : 16,
      "context" : ", 2018), weight average (Liu et al., 2019) and task variance regularization (Mao et al.",
      "startOffset" : 24,
      "endOffset" : 42
    }, {
      "referenceID" : 19,
      "context" : ", 2019) and task variance regularization (Mao et al., 2021).",
      "startOffset" : 41,
      "endOffset" : 59
    }, {
      "referenceID" : 23,
      "context" : "Besides, the PO-based methods formulate MTL as a multi-objective optimization problem and aim to find an arbitrary Pareto stationary solution (Sener and Koltun, 2018; Lin et al., 2019; Mahapatra and Rajan, 2020; Lin et al., 2020; Ma et al., 2020; Mao et al., 2020).",
      "startOffset" : 142,
      "endOffset" : 264
    }, {
      "referenceID" : 14,
      "context" : "Besides, the PO-based methods formulate MTL as a multi-objective optimization problem and aim to find an arbitrary Pareto stationary solution (Sener and Koltun, 2018; Lin et al., 2019; Mahapatra and Rajan, 2020; Lin et al., 2020; Ma et al., 2020; Mao et al., 2020).",
      "startOffset" : 142,
      "endOffset" : 264
    }, {
      "referenceID" : 18,
      "context" : "Besides, the PO-based methods formulate MTL as a multi-objective optimization problem and aim to find an arbitrary Pareto stationary solution (Sener and Koltun, 2018; Lin et al., 2019; Mahapatra and Rajan, 2020; Lin et al., 2020; Ma et al., 2020; Mao et al., 2020).",
      "startOffset" : 142,
      "endOffset" : 264
    }, {
      "referenceID" : 13,
      "context" : "Besides, the PO-based methods formulate MTL as a multi-objective optimization problem and aim to find an arbitrary Pareto stationary solution (Sener and Koltun, 2018; Lin et al., 2019; Mahapatra and Rajan, 2020; Lin et al., 2020; Ma et al., 2020; Mao et al., 2020).",
      "startOffset" : 142,
      "endOffset" : 264
    }, {
      "referenceID" : 17,
      "context" : "Besides, the PO-based methods formulate MTL as a multi-objective optimization problem and aim to find an arbitrary Pareto stationary solution (Sener and Koltun, 2018; Lin et al., 2019; Mahapatra and Rajan, 2020; Lin et al., 2020; Ma et al., 2020; Mao et al., 2020).",
      "startOffset" : 142,
      "endOffset" : 264
    }, {
      "referenceID" : 20,
      "context" : "Besides, the PO-based methods formulate MTL as a multi-objective optimization problem and aim to find an arbitrary Pareto stationary solution (Sener and Koltun, 2018; Lin et al., 2019; Mahapatra and Rajan, 2020; Lin et al., 2020; Ma et al., 2020; Mao et al., 2020).",
      "startOffset" : 142,
      "endOffset" : 264
    }, {
      "referenceID" : 14,
      "context" : "Moreover, (Lin et al., 2019) proposes that the PO-based methods can be also regarded as weight adaptation methods for they optimize the weighted sum of training losses as well.",
      "startOffset" : 10,
      "endOffset" : 28
    }, {
      "referenceID" : 2,
      "context" : "1 Hypergradient Descent Hypergradient Descent (HD) (Almeida et al., 1998; Baydin et al., 2018) provides an efficient way to apply gradient descent on hyper-parameters.",
      "startOffset" : 51,
      "endOffset" : 94
    }, {
      "referenceID" : 4,
      "context" : "1 Hypergradient Descent Hypergradient Descent (HD) (Almeida et al., 1998; Baydin et al., 2018) provides an efficient way to apply gradient descent on hyper-parameters.",
      "startOffset" : 51,
      "endOffset" : 94
    }, {
      "referenceID" : 8,
      "context" : "Based on the descent direction for each objective, (Désidéri, 2012) proposes a way to obtain the common descent direction, as in Theorem 1.",
      "startOffset" : 51,
      "endOffset" : 67
    }, {
      "referenceID" : 1,
      "context" : "As the neural networks are usually heavily overparameterized (Allen-Zhu et al., 2019), the training losses cannot properly estimate the generalization losses.",
      "startOffset" : 61,
      "endOffset" : 85
    }, {
      "referenceID" : 2,
      "context" : "However, the original HD method (Almeida et al., 1998; Baydin et al., 2018) is proposed for single objective optimization, which can not used in our problem where a multiobjective optimization problem involves.",
      "startOffset" : 32,
      "endOffset" : 75
    }, {
      "referenceID" : 4,
      "context" : "However, the original HD method (Almeida et al., 1998; Baydin et al., 2018) is proposed for single objective optimization, which can not used in our problem where a multiobjective optimization problem involves.",
      "startOffset" : 32,
      "endOffset" : 75
    }, {
      "referenceID" : 10,
      "context" : "We here adopt the widely used Frank-Wolfe optimization algorithm (Jaggi, 2013), a minimum-norm-point algorithm, to solve it.",
      "startOffset" : 65,
      "endOffset" : 78
    }, {
      "referenceID" : 5,
      "context" : "The dataset (Blitzer et al., 2007) contains product reviews from 14 domains, including books, DVDs, electronics, kitchen appliances and so on.",
      "startOffset" : 12,
      "endOffset" : 34
    }, {
      "referenceID" : 11,
      "context" : "Uncertainty: using the uncertainty weighting method proposed by (Kendall et al., 2018).",
      "startOffset" : 64,
      "endOffset" : 86
    }, {
      "referenceID" : 7,
      "context" : "GradNorm: using the gradient normalization method proposed by (Chen et al., 2018).",
      "startOffset" : 62,
      "endOffset" : 81
    }, {
      "referenceID" : 23,
      "context" : "MGDA: using the MGDA-UB method proposed by (Sener and Koltun, 2018).",
      "startOffset" : 43,
      "endOffset" : 67
    }, {
      "referenceID" : 15,
      "context" : "AdvMTL: using the adversarial Multi-task Learning method proposed by (Liu et al., 2017).",
      "startOffset" : 69,
      "endOffset" : 87
    }, {
      "referenceID" : 20,
      "context" : "TchebycheffAdv: using the Adversarial Tchebycheff procedure proposed by (Mao et al., 2020).",
      "startOffset" : 72,
      "endOffset" : 90
    }, {
      "referenceID" : 19,
      "context" : "BanditMTL: using the BanditMTL method proposed by (Mao et al., 2021).",
      "startOffset" : 50,
      "endOffset" : 68
    }, {
      "referenceID" : 19,
      "context" : "3 Experimental Settings We adopt the hard parameter-sharing MTL framework (Mao et al., 2021), where the shared representation extractor is built with TextCNN or BERT; besides, the task-specific module is formulated by means of one fully connected layer ending with a softmax function.",
      "startOffset" : 74,
      "endOffset" : 92
    }, {
      "referenceID" : 22,
      "context" : "For TextCNN, we adopt Pretrained GloVe (Pennington et al., 2014) word embeddings.",
      "startOffset" : 39,
      "endOffset" : 64
    } ],
    "year" : 0,
    "abstractText" : "Task weighting, which assigns weights on the including tasks during training, significantly matters the performance of Multi-task Learning (MTL); thus, recently, there has been an explosive interest in it. However, existing task weighting methods assign weights only based on the training loss, while ignoring the gap between the training loss and generalization loss. It degenerates MTL’s performance. To address this issue, the present paper proposes a novel task weighting algorithm, which automatically weights the tasks via a learning-tolearn paradigm, referred to as MetaWeighting. Extensive experiments are conducted to validate the superiority of our proposed method in multi-task text classification.",
    "creator" : null
  }
}