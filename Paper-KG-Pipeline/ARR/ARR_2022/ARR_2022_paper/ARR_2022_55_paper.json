{
  "name" : "ARR_2022_55_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Generating Authentic Adversarial Examples beyond Meaning-preserving with Doubly Round-trip Translation",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In recent years, neural machine translation (NMT) (Cho et al., 2014; Bahdanau et al., 2014; Vaswani et al., 2017) has achieved rapid advancement in the translation performance (Yang et al., 2020; Lu et al., 2021). However, the NMT model is not always stable enough, as its performance can drop significantly when small perturbations are added into the input sentences (Belinkov and Bisk, 2017; Cheng et al., 2020). Such perturbed inputs are often referred to as adversarial examples in the literature, and how to effectively generate and utilize adversarial examples for NMT is still an open question.\n1Codes are attached to submission and will be openly accessible once accepted.\nConventional approaches (Ebrahimi et al., 2018; Cheng et al., 2019) for generating NMT adversarial examples always follow the meaning-preserving assumption, i.e., an NMT adversarial example should preserve the meaning of the source sentence but destroy the translation performance drastically (Michel et al., 2019; Niu et al., 2020). With the meaning-preserving restriction, the researchers try to add perturbations on the source inputs as small as possible to ensure the meaning of the source sentence is unchanged, which severely limits the search space of the adversarial examples. Additionally, it is much problematic to craft a minor perturbation on discrete text data, since some random transformations (e.g., swap, deletion and replacement) may change, or even reverse semantics of the text data, breaking the aforementioned meaning-preserving assumption. To break this limitation, Zhang et al. (2021) introduce a new definition for NMT adversarial examples: an effective NMT adversarial example imposes minor shifting on the source and degrades the translation dramatically, would naturally lead to a semantic-destroyed round-trip translation result. Take the case in Figure 1 as an example: xδ reverses the semantics of input x by replacing “巨大 (huge)” to “轻便 (light)”. Since the semantics of x and xδ are com-\npletely different, it is unreasonable to use the original target sentence of x to evaluate the attacks directly. Therefore, Zhang et al. (2021) propose to evaluate the BLEU score between xδ and its reconstructed sentence x̂δ from the source-target-source round-trip translation (RTT), as well as the BLEU score between the original sentence x and its reconstructed sentence x̂. They take the decrease between the two BLEU scores mentioned above as the adversarial effect. Specifically, if the BLEU decrease exceeds a predefined threshold, xδ is concluded to be an adversarial example for the target NMT model.\nWhile achieving promising results by breaking the meaning-preserving limitation, there are two potential pitfalls in the work of Zhang et al. (2021): (1) Since the source-target-source RTT involves two stages, i.e., the source-to-target translation (S2T) performed by the target NMT model and target-to-source translation (T2S) performed by an auxiliary backward NMT model, we cannot decide whether the BLEU decrease is really caused by the target NMT model. As we can see from the example in Figure 1, the translation from xδ to y′δ is pretty good, but the translation from y′δ to x̂δ is really poor. We can conclude that the BLEU decrease is actually caused by the auxiliary backward model and thus xδ is not the adversarial example for the target NMT model. Even if Zhang et al. (2021) try to mitigate this problem by fine-tuning the auxiliary backward model on the test sets, we find this problem still remains. (2) They only generate the monolingual adversarial examples on the source side to attack the NMT model, without proposing methods on how to defend these adversaries and improve the robustness of the NMT model.\nTo address the issues mentioned above, we first propose a new definition for NMT adversarial examples based on Doubly Round-Trip Translation (DRTT), which can ensure the examples that meet our definition are the authentic adversarial examples for the target NMT model. Specifically, apart from the source-target-source RTT (Zhang et al., 2021), we additionally consider a target-sourcetarget RTT on the target side. The main intuition is that an effective adversarial example for the target NMT model shall cause a large BLEU decrease on the source-target-source RTT while maintaining a small BLEU decrease on target-source-target RTT. Based on this definition, we craft the candidate adversarial examples with the source-target-source\nRTT as Zhang et al. (2021), and then pick out the authentic adversaries with the target-source-target RTT. Furthermore, to solve the second problem, we introduce the masked language models (MLMs) to construct the bilingual adversarial pairs by performing phrasal replacement on the generated monolingual adversarial examples and the original target sentences synchronously, which are then utilized to train the NMT model directly. Experiments on both clean and noisy test sets (including five types of artificial and nature noise) show that the proposed approach not only generates effective adversarial examples, but also improves the robustness of the NMT model over all kinds of noises. To conclude, our main contributions are summarized as follows:\n• We propose a new definition for NMT adversarial examples based on the doubly round-trip translation, which can pick out the authentic adversarial examples for the target NMT model.\n• We introduce the masked language models to construct the bilingual adversarial pairs, which are then utilized to improve the robustness of the NMT model.\n• Extensive experiments show that the proposed approach not only improves the robustness of the NMT model on both artificial and natural noise, but also performs well on the clean test sets."
    }, {
      "heading" : "2 Related Work",
      "text" : ""
    }, {
      "heading" : "2.1 Adversarial Examples for NMT",
      "text" : "The previous approaches for constructing NMT adversarial examples can be divided into two branches: white-box and black-box. The whitebox approaches are based on the assumption that the architecture and parameters of the NMT model are accessible (Ebrahimi et al., 2018; Cheng et al., 2019; Chen et al., 2021). These methods usually achieve superior performance since they can construct and defend the adversaries tailored for the model. However, in the real application scenario, it is always impossible for us to access the inner architecture of the model. On the contrary, the black-box approaches never access to inner architecture and parameters of the model. In this line, Belinkov and Bisk (2017) rely on synthetic and naturally occurring language error to generate adversarial examples and Michel et al. (2019) propose a meaningpreserving method by swapping the word internal character. Recently, Zhang et al. (2021) craft adversarial examples beyond the meaning-preserving\nrestriction with the round-trip translation and our work builds on top of it."
    }, {
      "heading" : "2.2 Masked Language Model",
      "text" : "Masked Language Model (MLM) (Devlin et al., 2018; Conneau and Lample, 2019) has achieved state-of-the-art results on many monolingual and cross-lingual language understanding tasks. MLM randomly masks some of the tokens in the input, and then predicts those masked tokens. Recently, some work adopt MLM to do word replacement as a data augmentation strategy. Jiao et al. (2019) leverage an encoder-based MLM to predict word replacements for single-piece words. Liu et al. (2021) construct augmented sentence pairs by sampling new source phrases and corresponding target phrases with transformer-based MLMs. Following Liu et al. (2021), we introduce the transformerbased MLMs to construct the bilingual adversarial pairs. The main difference between our work and Liu et al. (2021) is that we choose to mask the adversarial phrases or words at each step and Liu et al. (2021) mask the words randomly."
    }, {
      "heading" : "3 Method",
      "text" : "In this section, we first describe our proposed definition for NMT adversarial examples, and then present the way of constructing the bilingual adversarial pairs."
    }, {
      "heading" : "3.1 Adversarial Examples for NMT",
      "text" : "For clarity, we first introduce the traditional definitions for NMT adversarial examples, i.e., the definitions based on the meaning-preserving (Michel et al., 2019; Karpukhin et al., 2019) and RTT\n(Zhang et al., 2021), and then elaborate our new definition based on DRTT. We will use the following notations: x and y denotes the source and target sentence, respectively. xδ and yδ denote the perturbed version of x and y, respectively. f(·) is the forward translation process performed by the target NMT model and g(·) is the backward translation process performed by the auxiliary backward NMT model. sim(·, ·) is a function for evaluating the similarity of two sentences, and we use BLEU (Papineni et al., 2002) as the similarity function.\nDefinition based on meaning-preserving. Suppose y′ = f(x) and y′δ = f(xδ) is the forward translation of the input x and its perturbed version xδ, respectively. xδ is an adversarial examples when it meets:{\nsim(x,xδ) > η, sim(y,y′)− sim(y,y′δ) > α,\n(1)\nwhere η is a threshold to ensure a high similarity between xδ and x, so that they can meet the meaningpreserving restriction. A larger α indicates a more strict definition of the NMT adversarial example.\nDefinition based on RTT. Zhang et al. (2021) point out that the perturbation δ may change, even reverse the meaning of x, so it is incorrect to use y as a target sentence to measure the semantic alteration on the target side. Therefore, they introduce the definition based on RTT which gets rid of the meaning-preserving restriction. The percentage decrease of similarity between x and xδ through the source-target-source RTT is regarded as the adver-\nsarial effect dsrc(x,xδ), is calculated as:\ndsrc(x,xδ) = sim(x, x̂)− sim(xδ, x̂δ)\nsim(x, x̂) , (2)\nwhere x̂ and x̂δ are reconstructed sentences generated with source-target-source RTT: x̂ = g(f(x)), x̂δ = g(f(xδ)). A large dsrc(x,xδ) indicates that the perturbed sentence xδ can not be well reconstructed by RTT when compared to the reconstruction quality of the original source sentence x, so xδ is likely to be an adversarial example.\nDefinition based on DRTT. In Eq.(2), sim(x, x̂) is a constant value given the input x and the NMT models. Therefore, the dsrc(x,xδ) is actually determined by −sim(xδ, x̂δ), which can be interpreted as the reconstruction error between xδ and x̂δ. As we mentioned above, the reconstruction error can be caused by two independent translation processes: the forward translation process f(·) performed by the target NMT model and the backward translation process g(·) performed by the auxiliary backward model. Consequently, there may be three occasions when we get a large dsrc(x,xδ): 1) A large semantic alteration in f(xδ) and a small semantic alteration in g(y′δ); 2) A large semantic alteration in f(xδ) and a large alteration in g(y′δ); 3) A small semantic alteration in f(xδ) and a large alteration in g(y′δ). We can conclude xδ is an adversarial example for the target NMT model in occasion 1 and 2, but not in occasion 3. Therefore, the definition based on RTT may contain many fake adversarial examples.\nTo address this problem, we add a target-sourcetarget RTT starting from the target side. The percentage decrease of the similarity between y and y′δ through the target-source-target RTT, denoted as dtgt(y,y′δ), is calculated as:\ndtgt(y,y ′ δ) = sim(y, ŷ)− sim(y′δ, ŷ′δ) sim(y, ŷ) , (3)\nwhere ŷ = f(g(y)) and ŷ′δ = f(g(y ′ δ)) are reconstructed sentences generated with the targetsource-target RTT. We take both dsrc(x,xδ) and dtgt(y,y ′ δ) into consideration and define xδ as an adversarial examples when it meets:{ dsrc(x,xδ) > β, dtgt(y,y ′ δ) < γ, (4)\nwhere β and γ are thresholds ranging in [−∞, 1] 2. The interpretation of this definition is intuitive:\n2It is possible that the reconstruction quality of the perturbed sentence is higher than the original one.\nif dtgt(y,y′δ) is lower than γ, we can conclude that the reconstruction error between y′δ and ŷ ′ δ is very low. Namely, we can ensure a small semantic alteration of g(y′δ). Therefore, if dsrc(x,xδ) is larger than β, we can conclude the BLEU decrease through the source-target-source RTT is caused by the target NMT model, so that we can conclude xδ is an authentic adversarial example."
    }, {
      "heading" : "3.2 Bilingual Adversarial Pair Generation",
      "text" : "Since the proposed definition breaks the meaningpreserving restriction, the adversarial examples may be semantically distant from the original source sentence. Thus, we cannot directly pair the adversarial examples with the original target sentences. In this section, we propose our approach for generating bilingual adversarial pairs, which performs the following three steps: 1) Training Masked Language Models: using monolingual and parallel data to train masked language models; 2) Phrasal Alignment: obtaining alignment between the source and target phrases; 3) Phrasal Replacement: generating bilingual adversarial pairs by performing phrasal replacement on the source and target sentences synchronously with the trained masked language models. The whole procedure is illustrated in Figure 2.\nTraining Masked Language Models. We train two kinds of masked language models, namely monolingual masked language model (M-MLM) (Devlin et al., 2018) and translation masked language model (T-MLM) (Conneau and Lample, 2019), for phrasal replacement on the source and target sentence, respectively. The M-MLM introduces a special [MASK] token which randomly masks some of the tokens from the input in a certain probability, and predict the original masked words. Following Liu et al. (2021), we train the MMLM on monolingual datasets and use an encoderdecoder Transformer model (Vaswani et al., 2017) to tackle the undetermined number of tokens during generation. The T-MLM takes the identical model structure and similar training process as the M-MLM. The main difference is T-MLM relies on the parallel corpus. T-MLM concatenates parallel sentences by a special token [SEP] and only masks words on the target side. The objective is to predict the original masked words on the target side.\nPhrasal Alignment. Phrasal alignment projects each phrase in the source sentence x to its alignment phrase in the target sentence y. We first gener-\nate the alignment between x and y using FastAlign (Dyer et al., 2013). Then we extract the phraseto-phrase alignment by the phrase extraction algorithm of NLTK3, and get a mapping function p.\nPhrasal Replacement. Given the source sentence x = {s1, s2, . . . , sn} and the target sentence y = {t1, t2, . . . , tm}, si is the i-th phrase in x, tp(i) is the p(i)-th phrase in y which is aligned to si by the mapping function p. We construct the candidate bilingual adversarial pairs (xδ,yδ) by performing the phrasal replacement on (x,y) repeatedly until c percentage phrases in x have been replaced. For each step, we select the phrase that yields the most significant reconstruction quality degradation.\nHere, we take the replacing process for si and tp(i) as an example. Considering the not attacked yet phrase si in x, we first build a candidate set Ri = {r1i , r2i , . . . , rki } for si with the prepared M-MLM. Specifically, we extract the k candidate phrases with top k highest predicted probabilities by feeding x\\i into M-MLM, where x\\i is the masked version of x by masking si. We select the best candidate r∗i for si as:\nr∗i = arg max j∈{1,··· ,k} dsrc(x,x \\i:j), (5)\nwhere x\\i:j is the noised version by replacing si with rji . With si being replaced, we need to replace tp(i) to ensure they are still semantically aligned. To this end, we feed the concatenation of x\\i:∗ and y\\p(i) into T-MLM, and choose the output phrase with the highest predicted probability as the substitute phrase for tp(i).\nFinally, to decide whether (xδ,yδ) is an authentic bilingual adversarial pair for the target NMT model, we perform a target-source-target RTT starting from the target side and calculate dtgt(y,y′δ) between y′δ and its reconstruction sentence ŷ ′ δ according to Eq.(4). We take (xδ,yδ) as an authentic bilingual adversarial pair if dsrc(x,xδ) is greater than β and dtgt(y,y′δ) is less than γ. We formalize these steps in Algorithm 1 in Appendix A.\nAfter generating adversarial data through the above steps, we combine it with original training data and use them to train the NMT model directly."
    }, {
      "heading" : "4 Experimental Settings",
      "text" : "We evaluate our model under artificial noise in Zh→En and En→De translation tasks, and under\n3https://github.com/nltk/nltk/blob/ develop/nltk/translate/phrase_based.py\nnatural noise in En→Fr translation task. The details of the experiments are elaborated in this section."
    }, {
      "heading" : "4.1 Dataset",
      "text" : "For the Zh→En task, we use the LDC corpus with 1.25M sentence pairs for training4, NIST06 for validation, and NIST 02, 03, 04, 05, 08 for testing. For the En→De task, we use the publicly available dataset WMT’17 En-De (5.85M) for training, and take the newstest16 and newstest17 for validation and testing, respectively. In En→Fr task, we follow Liu et al. (2021) to combine the WMT’19 En→Fr (36k) robustness dataset with Europarl-v7 (2M) EnFr pairs for training. We take the development set of the MTNT (Michel and Neubig, 2018) for validation and the released test set of the WMT’19 robustness task for testing. As for MLMs, we use the Chinese sentences of the parallel corpus to train the Chinese M-MLM, and use the whole parallel corpus to train Zh-En T-MLM. We train the English M-MLM with News Commentary and News Crawl 2010 (7.26M in total) monolingual corpus following Liu et al. (2021). T-MLM for En-De and En-Fr are trained with their original parallel corpus."
    }, {
      "heading" : "4.2 Model Configuration and Pre-processing",
      "text" : "The MLMs and NMT models in this paper take Transformer-base (Vaswani et al., 2017) as the backbone architecture. We implement all models base on the open-source toolkit Fairseq (Ott et al., 2019). As for hyper-parameters, β is set to 0.01 and γ is set to 0.5 for Zh→En. For En→De and En→Fr, β and γ is set to 0.5 and 0.5, respectively. The replacement ratio c is set to 0.2 following Liu et al. (2021), and the candidate number k is set to 1. The details of model configuration and the number of the generated adversarial examples are shown in the Appendix B. Following previous work, the Zh→En performance is evaluated with the BLEU (Papineni et al., 2002) score calculated by multibleu.perl script. For En→De and En→Fr, we use SacreBLEU (Post, 2018) for evaluation5."
    }, {
      "heading" : "4.3 Comparison Methods",
      "text" : "To test the effectiveness of our model, we take both meaning-preserving and meaning-changeable systems as comparison methods:\n4It is extracted from LDC data, including LDC 2002E18, 2003E07, 2003E14, 2004T08 and 2005T06.\n5nrefs:1 | case:mixed | eff:no | tok:intl | smooth:exp | version:2.0.0\nBaseline: The vanilla Transformer model for NMT (Vaswani et al., 2017). In our work, we use the baseline model to perform the forward and backward translation in the round-trip translation.\nCharSwap: Michel et al. (2019) craft a minor perturbation on word by swapping the internal character. They claim that character swaps have been shown to not affect human readers greatly, hence making them likely to be meaning-preserving.\nTCWR: Liu et al. (2021) propose the approach of translation-counterfactual word replacement which creates augmented parallel translation corpora by random sampling new source and target phrases from the masked language models.\nRTT: Zhang et al. (2021) propose to generate adversarial examples with the single round-trip translation. However, they do not provide any approach for generating the bilingual adversarial pairs. To make a fair comparison, we generate the bilingual adversarial pairs from their adversarial examples in the same way as ours."
    }, {
      "heading" : "5 Results and Analysis",
      "text" : ""
    }, {
      "heading" : "5.1 Main Results",
      "text" : "Artificial Noise. To test robustness on noisy inputs, we follow Cheng et al. (2018) to construct five types of synthetic perturbations with different noise ratios on the standard test set6: 1) Deletion: some words in the source sentence are randomly deleted; 2) Swap: some words in the source sentence are randomly swapped with their right neighbors; 3) Insertion: some words in the source sentence are randomly repeated; 4) Rep src: short for ‘replacement on src’. Some words in the source sentence are replaced with their relevant word according to the similarity of word embeddings7; 5) Rep both: short for ‘replacement on both’. Some words in the source sentence and their aligned target words are replaced by masked language models 8.\nTable 1 shows the BLEU scores of forward trans6For each test set, we report three results with noise ratio as 0.1, 0.2 and 0.3, respectively. Noise ratio 0.1 means 10 percent of the words in the source sentence are perturbed.\n7https://github.com/Embedding/ Chinese-Word-Vectors https://nlp.stanford.edu/projects/glove/\n8Each sentence has four references on NIST test sets, we only choose sb0 for replacement.\nlation results on Zh→En and En→De noisy test sets. For Zh→En, our approach achieves the best performance on 4 out of 5 types of noisy test sets. Compared to RTT, DRTT achieves the improvement up to 1.1 BLEU points averagely on deletion. For En→De, DRTT also performs best results on all types of noise except Rep src. We suppose the reason is Rep src sometimes reverses the semantics of the original sentence as we claimed above.\nSince the perturbations we introduced above may change the semantics of the source sentence, it may be problematic for us to calculate the BLEU score against the original reference sentence in Table 1. Therefore, following Zhang et al. (2021), we also report the BLEU score between the source sentence and its reconstructed version through the sourcetarget-source RTT, which is named as RTT BLEU. The intuition behind it is that: a robust NMT model translates noisy inputs well and thus has minor shifting on the round-trip translation, resulting in a high BLEU between inputs and their roundtrip translation results. Following Zhang et al. (2021), we fine-tune the backward model (vanilla Transformer model) with its test set to minimize the impact of the T2S process. As shown in Table 2, DRTT outperforms the meaning-preserving method and other methods on all types of noise\non Zh→En and En→De tasks. Considering the results of Table 1 and Table 2 together, DRTT significantly improves the robustness of NMT models under various artificial noises.\nNatural Noise. In addition to the artificial noise, we also test the performance of our model on WMT’19 En→Fr robustness test set which contains various noise in real-world text, e.g., exhibits typos, grammar errors, code-switching, etc. As shown in Table 3, DRTT yields improvements of 1.34 BLEU compared to the baseline, it proves that our approach also performs well in real noise scenario. Besides, DRTT achieves 0.63 BLEU improvement over RTT by filtering out 10% of fake adversarial examples (according to Table 5), which demonstrates that filtering out fake adversarial examples\nfurther improves the robustness of the model."
    }, {
      "heading" : "5.2 Effectiveness of Adversarial Examples",
      "text" : "In this sub-section, we evaluate the effectiveness of the generated adversarial examples on attacking the victim NMT model (i.e., the target NMT model without being trained on the generated adversarial pairs). In our approach, γ in Eq.(4) is a hyperparameter to control the strictness of our definition on generating adversarial examples. Thus, we evaluate the effectiveness of adversarial examples by studying the translation performance of the victim NMT model on the set of adversarial pairs generated with different γ. That is to say, if a sample is an adversary, it should destroy the translation performance drastically, resulting in a low BLEU score between the translation result and its paired target sentence. The average BLEU scores of the victim model on the different adversarial pair sets (generated with γ from -10 to 1 on NIST 06) are shown in Figure 3. Specifically, the average BLEU on the adversarial sets generated with γ = −10 is 8.0. When we remove the restriction of γ, i.e., the DRTT is degenerated into RTT, the average BLEU for the constructed adversarial examples reaches up to 11.2. This shows that the adversarial examples generated with lower γ (more strict restriction) attack the model more successfully. Therefore, we can select more effective adversarial examples compared to Zhang et al. (2021) by lowering the threshold γ to create a more strict definition."
    }, {
      "heading" : "5.3 Clean Test set",
      "text" : "Adding a large amount of noisy parallel data to clean training data may harm the NMT model performance on the clean test sets seriously (Khayrallah and Koehn, 2018). In this sub-section, we test the performance of the proposed model on the clean test sets and the results are presented in Table 4. The meaning-preserving method CharSwap has negative effect on clean test set while\nDRTT achieves the best translation performance on Zh→En and En→De clean test sets. It demonstrates that our approach not only improves the robustness of the NMT model, but also maintains its good performance on clean test sets."
    }, {
      "heading" : "6 Conclusion and Future Work",
      "text" : "We propose a new definition for NMT adversarial examples based on Doubly Round-Trip Translation, which can ensure the examples that meet our definition are the authentic adversarial examples. Additionally, based on this definition, we introduce the masked language models to generate bilingual adversarial pairs, which can be used to improve the robustness of the NMT model substantially. Extensive experiments on both the clean and noisy test sets show that our approach not only improves the robustness of the NMT model but also performs well on the clean test sets. In future work, we will refine the limitations of this work 9, and then explore to improve the robustness of forward and backward models simultaneously. We hope our work will provide a new perspective for future researches on adversarial examples.\n9We provide case study and limitation in the appendix C."
    }, {
      "heading" : "A Bilingual Adversarial Pair Generation",
      "text" : "Algorithm 1: Bilingual Adversarial Pair Generation Input: A sequence pair (x, y), a sampling\nprobability c, an alignment mapping p, candidate words k, masked language models M-MLM and T-MLM, thresholds β and γ.\nOutput: A bilingual adversarial pair (xδ, yδ)\n1 Function BilAdvGen(x, y): 2 while n ≤ len(x) ∗ c do 3 rji ←M-MLM (x\\i); 4 x\\i:j ← Replace(x, rji ) 5 r∗i ← arg max dsrc(x, x\\i:j) (2); 6 x\\i:∗ ← Replace(x, r∗i ) 7 Get aligned index p(i); 8 wp(i) ← T-MLM (x\\i:∗, y\\p(i)); 9 yδ ← Replace(y, wp(i))\n10 n← n+ 1 11 end 12 if dsrc(x, xδ) > β and dtgt(y, y′δ) < γ then 13 return xδ, yδ 14 end\nB Implementation Details\nAs for Zh→En, we apply the separate byte-pair encoding (BPE) (Sennrich et al., 2016) encoding with 30K merge operations for Zh and En, respectively, the peak learning rate of 5e-4, and the training step is 100K. For En→De and En→Fr, we apply the joint BPE with 32K merge operations, the learning rate of 7e-4 and the training step is 200K. The dropout ratio is 0.1. We use Adam optimizer (Kingma and Ba, 2014) with 4k warm-up steps. All models are trained on 8 NVIDIA Tesla V100 (32GB) GPUs."
    }, {
      "heading" : "C Case Study and Limitation",
      "text" : "In Table 6, we present some cases from Zh-En adversarial pairs generated by our approach. From the case 1, we can see “拥护” in the source sentence is replaced by its antonym “反对”, which reverse the meaning of the original sentence, and DRTT makes a corresponding change in the target sentence by replacing “support” with “oppose”. In the other case, DRTT replaces “良好” by its synonym “不错”, thus, “satisfactory” in the target sentence remains unchanged. From these cases, we find that DRTT can reasonably substitute phrases in source sequences based on the contexts and correctly modify the corresponding target phrases synchronously.\nAlthough the proposed approach achieves promising results, it still has limitations. A small number of authentic adversarial examples may be filtered out when the large dtgt(y,y′δ) is caused by f(x̂δ), we will ameliorate this problem in the further."
    } ],
    "references" : [ {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio." ],
      "venue" : "arXiv preprint arXiv:1409.0473.",
      "citeRegEx" : "Bahdanau et al\\.,? 2014",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2014
    }, {
      "title" : "Synthetic and natural noise both break neural machine translation",
      "author" : [ "Yonatan Belinkov", "Yonatan Bisk." ],
      "venue" : "arXiv preprint arXiv:1711.02173.",
      "citeRegEx" : "Belinkov and Bisk.,? 2017",
      "shortCiteRegEx" : "Belinkov and Bisk.",
      "year" : 2017
    }, {
      "title" : "Manifold adversarial augmentation for neural machine translation",
      "author" : [ "Guandan Chen", "Kai Fan", "Kaibo Zhang", "Boxing Chen", "Zhongqiang Huang." ],
      "venue" : "Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021, pages 3184–3189.",
      "citeRegEx" : "Chen et al\\.,? 2021",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2021
    }, {
      "title" : "Robust neural machine translation with doubly adversarial inputs",
      "author" : [ "Yong Cheng", "Lu Jiang", "Wolfgang Macherey." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4324–4333.",
      "citeRegEx" : "Cheng et al\\.,? 2019",
      "shortCiteRegEx" : "Cheng et al\\.",
      "year" : 2019
    }, {
      "title" : "AdvAug: Robust adversarial augmentation for neural machine translation",
      "author" : [ "Yong Cheng", "Lu Jiang", "Wolfgang Macherey", "Jacob Eisenstein." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 5961–",
      "citeRegEx" : "Cheng et al\\.,? 2020",
      "shortCiteRegEx" : "Cheng et al\\.",
      "year" : 2020
    }, {
      "title" : "Towards robust neural machine translation",
      "author" : [ "Yong Cheng", "Zhaopeng Tu", "Fandong Meng", "Junjie Zhai", "Yang Liu." ],
      "venue" : "arXiv preprint arXiv:1805.06130.",
      "citeRegEx" : "Cheng et al\\.,? 2018",
      "shortCiteRegEx" : "Cheng et al\\.",
      "year" : 2018
    }, {
      "title" : "Learning phrase representations using rnn encoder-decoder for statistical machine translation",
      "author" : [ "Kyunghyun Cho", "Bart van Merrienboer", "Çaglar Gülçehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Cho et al\\.,? 2014",
      "shortCiteRegEx" : "Cho et al\\.",
      "year" : 2014
    }, {
      "title" : "Crosslingual language model pretraining",
      "author" : [ "Alexis Conneau", "Guillaume Lample." ],
      "venue" : "Advances in Neural Information Processing Systems, 32:7059– 7069.",
      "citeRegEx" : "Conneau and Lample.,? 2019",
      "shortCiteRegEx" : "Conneau and Lample.",
      "year" : 2019
    }, {
      "title" : "BERT: pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "CoRR, abs/1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "A simple, fast, and effective reparameterization of ibm model 2",
      "author" : [ "Chris Dyer", "Victor Chahuneau", "Noah A Smith." ],
      "venue" : "Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human",
      "citeRegEx" : "Dyer et al\\.,? 2013",
      "shortCiteRegEx" : "Dyer et al\\.",
      "year" : 2013
    }, {
      "title" : "Hotflip: White-box adversarial examples for text classification",
      "author" : [ "Javid Ebrahimi", "Anyi Rao", "Daniel Lowd", "Dejing Dou." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages",
      "citeRegEx" : "Ebrahimi et al\\.,? 2018",
      "shortCiteRegEx" : "Ebrahimi et al\\.",
      "year" : 2018
    }, {
      "title" : "Tinybert: Distilling bert for natural language understanding",
      "author" : [ "Xiaoqi Jiao", "Yichun Yin", "Lifeng Shang", "Xin Jiang", "Xiao Chen", "Linlin Li", "Fang Wang", "Qun Liu." ],
      "venue" : "arXiv preprint arXiv:1909.10351.",
      "citeRegEx" : "Jiao et al\\.,? 2019",
      "shortCiteRegEx" : "Jiao et al\\.",
      "year" : 2019
    }, {
      "title" : "Training on synthetic noise improves robustness to natural noise in machine translation",
      "author" : [ "Vladimir Karpukhin", "Omer Levy", "Jacob Eisenstein", "Marjan Ghazvininejad." ],
      "venue" : "arXiv preprint arXiv:1902.01509.",
      "citeRegEx" : "Karpukhin et al\\.,? 2019",
      "shortCiteRegEx" : "Karpukhin et al\\.",
      "year" : 2019
    }, {
      "title" : "On the impact of various types of noise on neural machine translation",
      "author" : [ "Huda Khayrallah", "Philipp Koehn." ],
      "venue" : "Proceedings of the 2nd Workshop on Neural Machine Translation and Generation, pages 74–83.",
      "citeRegEx" : "Khayrallah and Koehn.,? 2018",
      "shortCiteRegEx" : "Khayrallah and Koehn.",
      "year" : 2018
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P Kingma", "Jimmy Ba." ],
      "venue" : "arXiv preprint arXiv:1412.6980.",
      "citeRegEx" : "Kingma and Ba.,? 2014",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2014
    }, {
      "title" : "Statistical significance tests for machine translation evaluation",
      "author" : [ "Philipp Koehn." ],
      "venue" : "Proceedings of the 2004 conference on empirical methods in natural language processing, pages 388–395.",
      "citeRegEx" : "Koehn.,? 2004",
      "shortCiteRegEx" : "Koehn.",
      "year" : 2004
    }, {
      "title" : "Counterfactual data augmentation for neural machine translation",
      "author" : [ "Qi Liu", "Matt Kusner", "Phil Blunsom." ],
      "venue" : "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Tech-",
      "citeRegEx" : "Liu et al\\.,? 2021",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2021
    }, {
      "title" : "Attention calibration for transformer in neural machine translation",
      "author" : [ "Yu Lu", "Jiali Zeng", "Jiajun Zhang", "Shuangzhi Wu", "Mu Li." ],
      "venue" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint",
      "citeRegEx" : "Lu et al\\.,? 2021",
      "shortCiteRegEx" : "Lu et al\\.",
      "year" : 2021
    }, {
      "title" : "On evaluation of adversarial perturbations for sequence-to-sequence models",
      "author" : [ "Paul Michel", "Xian Li", "Graham Neubig", "Juan Pino." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics:",
      "citeRegEx" : "Michel et al\\.,? 2019",
      "shortCiteRegEx" : "Michel et al\\.",
      "year" : 2019
    }, {
      "title" : "Mtnt: A testbed for machine translation of noisy text",
      "author" : [ "Paul Michel", "Graham Neubig." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 543– 553.",
      "citeRegEx" : "Michel and Neubig.,? 2018",
      "shortCiteRegEx" : "Michel and Neubig.",
      "year" : 2018
    }, {
      "title" : "Evaluating robustness to input perturbations for neural machine translation",
      "author" : [ "Xing Niu", "Prashant Mathur", "Georgiana f Dinu", "Yaser Al-Onaizan." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages",
      "citeRegEx" : "Niu et al\\.,? 2020",
      "shortCiteRegEx" : "Niu et al\\.",
      "year" : 2020
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "WeiJing Zhu." ],
      "venue" : "Proceedings of the 40th annual meeting of the Association for Computational Linguistics, pages 311–318.",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "A call for clarity in reporting bleu scores",
      "author" : [ "Matt Post." ],
      "venue" : "arXiv preprint arXiv:1804.08771.",
      "citeRegEx" : "Post.,? 2018",
      "shortCiteRegEx" : "Post.",
      "year" : 2018
    }, {
      "title" : "Neural machine translation of rare words with subword units",
      "author" : [ "Rico Sennrich", "Barry Haddow", "Alexandra Birch." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715–",
      "citeRegEx" : "Sennrich et al\\.,? 2016",
      "shortCiteRegEx" : "Sennrich et al\\.",
      "year" : 2016
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Łukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in neural information processing systems, pages 5998–6008.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Csp: Code-switching pre-training for neural machine translation",
      "author" : [ "Zhen Yang", "Bojie Hu", "Ambyera Han", "Shen Huang", "Qi Ju." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 2624–2636.",
      "citeRegEx" : "Yang et al\\.,? 2020",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2020
    }, {
      "title" : "Crafting adversarial examples for neural machine translation",
      "author" : [ "Xinze Zhang", "Junzhe Zhang", "Zhenhua Chen", "Kun He." ],
      "venue" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Confer-",
      "citeRegEx" : "Zhang et al\\.,? 2021",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2021
    }, {
      "title" : "2016) encoding with 30K merge operations for Zh and En, respectively, the peak learning rate of 5e-4, and the training step is 100K",
      "author" : [ "Sennrich" ],
      "venue" : "For En→De and En→Fr,",
      "citeRegEx" : "Sennrich,? \\Q2016\\E",
      "shortCiteRegEx" : "Sennrich",
      "year" : 2016
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "In recent years, neural machine translation (NMT) (Cho et al., 2014; Bahdanau et al., 2014; Vaswani et al., 2017) has achieved rapid advancement in the translation performance (Yang et al.",
      "startOffset" : 50,
      "endOffset" : 113
    }, {
      "referenceID" : 0,
      "context" : "In recent years, neural machine translation (NMT) (Cho et al., 2014; Bahdanau et al., 2014; Vaswani et al., 2017) has achieved rapid advancement in the translation performance (Yang et al.",
      "startOffset" : 50,
      "endOffset" : 113
    }, {
      "referenceID" : 24,
      "context" : "In recent years, neural machine translation (NMT) (Cho et al., 2014; Bahdanau et al., 2014; Vaswani et al., 2017) has achieved rapid advancement in the translation performance (Yang et al.",
      "startOffset" : 50,
      "endOffset" : 113
    }, {
      "referenceID" : 25,
      "context" : ", 2017) has achieved rapid advancement in the translation performance (Yang et al., 2020; Lu et al., 2021).",
      "startOffset" : 70,
      "endOffset" : 106
    }, {
      "referenceID" : 17,
      "context" : ", 2017) has achieved rapid advancement in the translation performance (Yang et al., 2020; Lu et al., 2021).",
      "startOffset" : 70,
      "endOffset" : 106
    }, {
      "referenceID" : 1,
      "context" : "However, the NMT model is not always stable enough, as its performance can drop significantly when small perturbations are added into the input sentences (Belinkov and Bisk, 2017; Cheng et al., 2020).",
      "startOffset" : 154,
      "endOffset" : 199
    }, {
      "referenceID" : 4,
      "context" : "However, the NMT model is not always stable enough, as its performance can drop significantly when small perturbations are added into the input sentences (Belinkov and Bisk, 2017; Cheng et al., 2020).",
      "startOffset" : 154,
      "endOffset" : 199
    }, {
      "referenceID" : 10,
      "context" : "Conventional approaches (Ebrahimi et al., 2018; Cheng et al., 2019) for generating NMT adversarial examples always follow the meaning-preserving assumption, i.",
      "startOffset" : 24,
      "endOffset" : 67
    }, {
      "referenceID" : 3,
      "context" : "Conventional approaches (Ebrahimi et al., 2018; Cheng et al., 2019) for generating NMT adversarial examples always follow the meaning-preserving assumption, i.",
      "startOffset" : 24,
      "endOffset" : 67
    }, {
      "referenceID" : 18,
      "context" : ", an NMT adversarial example should preserve the meaning of the source sentence but destroy the translation performance drastically (Michel et al., 2019; Niu et al., 2020).",
      "startOffset" : 132,
      "endOffset" : 171
    }, {
      "referenceID" : 20,
      "context" : ", an NMT adversarial example should preserve the meaning of the source sentence but destroy the translation performance drastically (Michel et al., 2019; Niu et al., 2020).",
      "startOffset" : 132,
      "endOffset" : 171
    }, {
      "referenceID" : 26,
      "context" : "Specifically, apart from the source-target-source RTT (Zhang et al., 2021), we additionally consider a target-sourcetarget RTT on the target side.",
      "startOffset" : 54,
      "endOffset" : 74
    }, {
      "referenceID" : 10,
      "context" : "The whitebox approaches are based on the assumption that the architecture and parameters of the NMT model are accessible (Ebrahimi et al., 2018; Cheng et al., 2019; Chen et al., 2021).",
      "startOffset" : 121,
      "endOffset" : 183
    }, {
      "referenceID" : 3,
      "context" : "The whitebox approaches are based on the assumption that the architecture and parameters of the NMT model are accessible (Ebrahimi et al., 2018; Cheng et al., 2019; Chen et al., 2021).",
      "startOffset" : 121,
      "endOffset" : 183
    }, {
      "referenceID" : 2,
      "context" : "The whitebox approaches are based on the assumption that the architecture and parameters of the NMT model are accessible (Ebrahimi et al., 2018; Cheng et al., 2019; Chen et al., 2021).",
      "startOffset" : 121,
      "endOffset" : 183
    }, {
      "referenceID" : 8,
      "context" : "Masked Language Model (MLM) (Devlin et al., 2018; Conneau and Lample, 2019) has achieved state-of-the-art results on many monolingual and cross-lingual language understanding tasks.",
      "startOffset" : 28,
      "endOffset" : 75
    }, {
      "referenceID" : 7,
      "context" : "Masked Language Model (MLM) (Devlin et al., 2018; Conneau and Lample, 2019) has achieved state-of-the-art results on many monolingual and cross-lingual language understanding tasks.",
      "startOffset" : 28,
      "endOffset" : 75
    }, {
      "referenceID" : 18,
      "context" : ", the definitions based on the meaning-preserving (Michel et al., 2019; Karpukhin et al., 2019) and RTT (Zhang et al.",
      "startOffset" : 50,
      "endOffset" : 95
    }, {
      "referenceID" : 12,
      "context" : ", the definitions based on the meaning-preserving (Michel et al., 2019; Karpukhin et al., 2019) and RTT (Zhang et al.",
      "startOffset" : 50,
      "endOffset" : 95
    }, {
      "referenceID" : 26,
      "context" : ", 2019) and RTT (Zhang et al., 2021), and then elaborate our new definition based on DRTT.",
      "startOffset" : 16,
      "endOffset" : 36
    }, {
      "referenceID" : 21,
      "context" : "sim(·, ·) is a function for evaluating the similarity of two sentences, and we use BLEU (Papineni et al., 2002) as the similarity function.",
      "startOffset" : 88,
      "endOffset" : 111
    }, {
      "referenceID" : 8,
      "context" : "We train two kinds of masked language models, namely monolingual masked language model (M-MLM) (Devlin et al., 2018) and translation masked language model (T-MLM) (Conneau and Lample, 2019), for phrasal replacement on the source and target sentence, respectively.",
      "startOffset" : 95,
      "endOffset" : 116
    }, {
      "referenceID" : 7,
      "context" : ", 2018) and translation masked language model (T-MLM) (Conneau and Lample, 2019), for phrasal replacement on the source and target sentence, respectively.",
      "startOffset" : 54,
      "endOffset" : 80
    }, {
      "referenceID" : 24,
      "context" : "(2021), we train the MMLM on monolingual datasets and use an encoderdecoder Transformer model (Vaswani et al., 2017) to tackle the undetermined number of tokens during generation.",
      "startOffset" : 94,
      "endOffset" : 116
    }, {
      "referenceID" : 9,
      "context" : "ate the alignment between x and y using FastAlign (Dyer et al., 2013).",
      "startOffset" : 50,
      "endOffset" : 69
    }, {
      "referenceID" : 19,
      "context" : "We take the development set of the MTNT (Michel and Neubig, 2018) for val-",
      "startOffset" : 40,
      "endOffset" : 65
    }, {
      "referenceID" : 24,
      "context" : "The MLMs and NMT models in this paper take Transformer-base (Vaswani et al., 2017) as the",
      "startOffset" : 60,
      "endOffset" : 82
    }, {
      "referenceID" : 21,
      "context" : "Following previous work, the Zh→En performance is evaluated with the BLEU (Papineni et al., 2002) score calculated by multibleu.",
      "startOffset" : 74,
      "endOffset" : 97
    }, {
      "referenceID" : 22,
      "context" : "For En→De and En→Fr, we use SacreBLEU (Post, 2018) for evaluation5.",
      "startOffset" : 38,
      "endOffset" : 50
    }, {
      "referenceID" : 15,
      "context" : "‘∗/∗∗’: significantly (Koehn, 2004) better than the RTT with p < 0.",
      "startOffset" : 22,
      "endOffset" : 35
    }, {
      "referenceID" : 24,
      "context" : "Baseline: The vanilla Transformer model for NMT (Vaswani et al., 2017).",
      "startOffset" : 48,
      "endOffset" : 70
    }, {
      "referenceID" : 13,
      "context" : "Adding a large amount of noisy parallel data to clean training data may harm the NMT model performance on the clean test sets seriously (Khayrallah and Koehn, 2018).",
      "startOffset" : 136,
      "endOffset" : 164
    } ],
    "year" : 0,
    "abstractText" : "Generating adversarial examples for Neural Machine Translation (NMT) with single Round-Trip Translation (RTT) has achieved promising results by releasing the meaningpreserving restriction. However, a potential pitfall for this approach is that we cannot decide whether the generated examples are adversarial to the target NMT model or the auxiliary backward one, as the reconstruction error through the RTT can be related to either. To remedy this problem, we propose a new definition for NMT adversarial examples based on the Doubly Round-Trip Translation (DRTT). Specifically, apart from the sourcetarget-source RTT, we also consider the targetsource-target one, which is utilized to pick out the authentic adversarial examples for the target NMT model. Additionally, to enhance the robustness of the NMT model, we introduce the masked language models to construct bilingual adversarial pairs based on DRTT, which are used to train the NMT model directly. Extensive experiments on both the clean and noisy test sets (including the artificial and natural noise) show that our approach substantially improves the robustness of NMT models.1",
    "creator" : null
  }
}