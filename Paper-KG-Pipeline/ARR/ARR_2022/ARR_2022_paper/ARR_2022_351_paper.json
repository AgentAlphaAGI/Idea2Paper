{
  "name" : "ARR_2022_351_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Robustly Optimized BMRC for Aspect Sentiment Triplet Extraction",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Aspect-based sentiment analysis (ABSA) is an important research area of natural language processing (NLP), which aims to mine fine-grained opinions and sentiments based on a specific aspect. In recent years, it has attracted extensive attention of researchers (Hu and Liu, 2004). ABSA includes three basic subtasks: aspect term extraction (Yin et al., 2016; Li et al., 2018; Ma et al., 2019), opinion term extraction (Liu et al., 2015; Wu et al., 2021), and aspect level sentiment classification (Wang et al., 2016; Chen et al., 2017; Jiang et al., 2019; Zhang and Qian, 2020).\nSubstantial progress has been achieved in recent studies, integrating multiple subtasks into a more complex task (Chen and Qian, 2020; He et al., 2019; Luo et al., 2019; Zhao et al., 2020). Among\nthem, aspect sentiment triplet extraction (ASTE) (Peng et al., 2020) becomes a subject of great interest, which is also the goal of our work. The details of ASTE task are shown in Figure 1. Many research efforts have been made (Xu et al., 2021; Mao et al., 2021; Chen et al., 2021), for example, using bidirectional machine reading comprehension (BMRC) for ASTE. It is a great work, but problems still remain. In the structure of BMRC, the shared classifiers may lead to query conflicts based on specific context, thus affecting the model performance. Some important strategies are also ignored, such as word segmentation, span matching and probability generation.\nIn this paper, we present a robustly optimized BMRC method for ASTE. The task is transformed into a machine reading comprehension problem. The complex correspondence between the aspect and opinion is processed through bidirectional query based on specific context. Such relationship can be effectively used to make their extraction mutually beneficial, thus facilitating better prediction of various sentiments. In order to deal with the ASTE task more efficiently, we incorporate the word segmentation and exclusive classifiers, and improve the span matching where the priority rule of the combination of probability and position relationship has been added. We also optimize the generation of probability to avoid its unilateral decrease. Our contributions can be summarized as follows:\n• Exclusive classifiers are designed in BMRC, so as to avoid the interference between dif-\nferent question answering steps and the query conflict.\n• We further advance the prediction performance by adding word segmentation, improving span matching and probability generation.\n• Extensive experiments are conducted on four benchmark datasets, where our model achieves the state-of-the-art performance."
    }, {
      "heading" : "2 Methodology",
      "text" : "In this section, we briefly review the BMRC (Chen et al., 2021), and then introduce our four improvements in detail."
    }, {
      "heading" : "2.1 BMRC",
      "text" : "BMRC can put forward the corresponding query according to the context, and the model then outputs the desired answer. Forward Query BMRC will query all aspects based on context; Then, according to the aspect of each prediction, all opinions describing it are queried from the context. Backward Query BMRC will query all opinions based on context; Then, according to the opinion of each prediction, all aspects describing it are queried from the context. Sentiment Prediction Once the aspect-opinion pairs are obtained, the sentiment queries can be constructed to predict the sentiments of the corresponding pairs according to the context.\nAfter that, the sentiments and aspect-opinion pairs are combined into triplets. The whole process is illustrated in Figure 2."
    }, {
      "heading" : "2.2 Word Segmentation",
      "text" : "We use the tokenizer based on wordpiece in BERT (Devlin et al., 2019) to segment words into subwords. Wordpiece is a common technique for word segmentation in NLP tasks.\nThe role of word segmentation has been investigated. Suppose the word \"walking\" is fed into the model, unless it appears many times in the training corpus, the model may fail to handle the word well. When similar words like \"walked\", \"walker\" or \"walks\" show up, without word segmentation, they will be treated as completely different words. However, if they are subdivided into \"walk ##ing\", \"walk ##ed\", \"walk ##er\", and \"walk ##s\", their sub-word \"walk\" contains the same semantics which is quite common during training. In\nthis sense, the model is able to learn more information through word segmentation."
    }, {
      "heading" : "2.3 Exclusive Classifiers",
      "text" : "Bidirectional queries are performed in BMRC, and the model needs to perform multiple different types of queries based on context. For example, the aspect query in forward query is different from the opinion query in backward query. The former queries all the aspects in the context, while the latter queries all the opinions in the context, requiring different entities. Another example is the aspect query in the forward query and the aspect query in the backward query. Although the entities of the two queries are the same, the latter conveys opinion information and searches for all the aspects described by it, while the former does not carry any context information, namely, all the aspects in the context.\nIn the original BMRC, all queries share one classifier. However, if different types of queries use the same classifier, it cannot serve any part very well. These different types of queries will interfere with each other and cause the query conflict. By adding exclusive classifiers, each different type of query can use a unique classifier, as shown in Figure 3, which can effectively avoid the problem of query conflict and greatly improve the performance of the model."
    }, {
      "heading" : "2.4 Span Matching",
      "text" : "Recently, there is a lot of work to deal with ABSA tasks based on span extraction (Hu et al., 2019; Xu et al., 2021), so does BMRC. After obtaining the predicted value of each position as the start or end position of span through binary classifiers, the predicted value is converted into probability using softmax function (Chen et al., 2021).\nWhen predicting the span, many start and end\npositions may be predicted, and how to match them is very important, since the matching rule will seriously affect the performance of the model. The matching should consider the relationship between probability and position, because the value of the former represents the optimistic degree of the model for the position, while the latter is the judgment of the cognition that the start and end positions of span are as close as possible, and the priority of probability is higher. So, the overview of our span matching rule is: make each end position match the start position with the highest probability after the previous end position. If there is a start position with the same probability, select the one whose position is closest to the end position."
    }, {
      "heading" : "2.5 Probability Generation",
      "text" : "Once the bidirectional queries and span matching are completed, aspects, opinions and pairs with corresponding relationship are obtained. In BMRC, the probability product of the start and end positions is taken as the probability of the span, and the probability of pair is the probability product of aspect and opinion. In this way, the probability of pair decreases unilaterally and cannot well represent the prediction of the pair by the model. For example, the probability of the four positions of pair is 0.9, while the probability of pair is 0.94 = 0.6561, which seems not so reasonable.\nBy probability generation, we can effectively solve the problem of unilateral decrease in the probability of span and pair, so that their probability can better reflect the expectation of the model. The operations are shown in Equation 1 and 2, where we balance the probability of span and pair so that their probability is within the interval of the two related probabilities. It enables us to avoid the unilateral decrease of probability, but keep more appropriate to the expectation of the model.\nP (span) = √ P (spanstart) ∗ P (spanend) (1)\nP (pair) = √ P (pairasp) ∗ P (pairopi) (2)\nThe effects of span matching and probability generation are shown in Figure 4."
    }, {
      "heading" : "3 Experiment",
      "text" : "In this section, we introduce information about the experiments, including datasets, evaluation metrics, baselines, experimental results, and ablation study."
    }, {
      "heading" : "3.1 Datasets",
      "text" : "We evaluate the model performance on ASTE-Datav1 (Peng et al., 2020) and ASTE-Data-v2 (Xu et al., 2020), which are popular benchmark datasets for ASTE task. They are derived from Laptop14, Rest14, Rest15, and Rest16 of SemEval shared challenges (Pontiki et al., 2014, 2015, 2016)."
    }, {
      "heading" : "3.2 Results",
      "text" : "We focus on the ASTE task. We conducted many experiments on the ASTE-Data-v1 and ASTEData-v2 datasets. The experimental results are shown in Tables 1, 2 respectively. In order to make a fair comparison with baselines, our F1 scores appeared at least three times in the experiments.\nIt is worth noting that we have achieved state-ofthe-art performances on the ASTE-Data-v1 and ASTE-Data-v2 datasets, indicating that our improvement further improves the performance of BMRC in dealing with ASTE task. In the Laptop14, Rest14, Rest15, and Rest16 datasets of ASTE-Data-v1, the F1 scores of our improved model are increased by 2.97, 4.20, 5.61 and 5.52 respectively compared with the original BMRC, indicating that our improvement is very effective. On\nthe Laptop14, Rest14, Rest15, and Rest16 datasets of ASTE-Data-v2, we also increased the F1 scores of the Strong baseline Span-ASTE (Xu et al., 2021) by 2.74, 0.77, 2.36 and 2.90 respectively. This indicates that our improvement is very significant."
    }, {
      "heading" : "3.3 Ablation Study",
      "text" : "Firstly, we experiment the model without improvement on the ASTE-Data-v2. The model is a reproduction based on BMRC, and then gradually superimposes the four improvements of word segmentation, exclusive classifiers, span matching and probability generation to conduct ablation experiment. This arrangement corresponds to the sequence before and after they contact the data, that is, the data will first pass through word segmentation and enter the model, the prediction value is obtained from the exclusive classifiers, and then span matching is carried out according to it. Finally, the probability generation is used to generate probabilistic representations of aspects, opinions and pairs. The datasets and various parameters of\nthe five experiments are the same. In order to make a fair comparison with baselines, our F1 scores appear at least three times in the experiments. The ablation experimental results are shown in Table 3. Each improvement advances the performance of the model, demonstrating their advantages and effectiveness."
    }, {
      "heading" : "4 Conclusion",
      "text" : "In this paper, we propose several improvements on the basis of BMRC for ASTE task, which can effectively deal with the complex correspondence among aspect, opinion and sentiment. In order to deal with the problems of the original BMRC, we add exclusive classifiers and three strategies, including word segmentation, span matching and probability generation. The proposed method is expected to handle complex ASTE task more efficiently. Extensive experiments are conducted to demonstrate the advantages of our improvements."
    } ],
    "references" : [ {
      "title" : "Recurrent attention network on memory for aspect sentiment analysis",
      "author" : [ "Peng Chen", "Zhongqian Sun", "Lidong Bing", "Wei Yang." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen,",
      "citeRegEx" : "Chen et al\\.,? 2017",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2017
    }, {
      "title" : "Bidirectional machine reading comprehension for aspect sentiment triplet extraction",
      "author" : [ "Shaowei Chen", "Yu Wang", "Jie Liu", "Yuelin Wang." ],
      "venue" : "Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Ap-",
      "citeRegEx" : "Chen et al\\.,? 2021",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2021
    }, {
      "title" : "Relation-aware collaborative learning for unified aspect-based sentiment analysis",
      "author" : [ "Zhuang Chen", "Tieyun Qian." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020, pages",
      "citeRegEx" : "Chen and Qian.,? 2020",
      "shortCiteRegEx" : "Chen and Qian.",
      "year" : 2020
    }, {
      "title" : "BERT: pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "An interactive multi-task learning network for end-to-end aspect-based sentiment analysis",
      "author" : [ "Ruidan He", "Wee Sun Lee", "Hwee Tou Ng", "Daniel Dahlmeier." ],
      "venue" : "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL",
      "citeRegEx" : "He et al\\.,? 2019",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2019
    }, {
      "title" : "Open-domain targeted sentiment analysis via span-based extraction and classification",
      "author" : [ "Minghao Hu", "Yuxing Peng", "Zhen Huang", "Dongsheng Li", "Yiwei Lv." ],
      "venue" : "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL",
      "citeRegEx" : "Hu et al\\.,? 2019",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2019
    }, {
      "title" : "Mining and summarizing customer reviews",
      "author" : [ "Minqing Hu", "Bing Liu." ],
      "venue" : "Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, Seattle, Washington, USA, August 22-25, 2004, pages 168–177. ACM.",
      "citeRegEx" : "Hu and Liu.,? 2004",
      "shortCiteRegEx" : "Hu and Liu.",
      "year" : 2004
    }, {
      "title" : "A challenge dataset and effective models for aspect-based sentiment analysis",
      "author" : [ "Qingnan Jiang", "Lei Chen", "Ruifeng Xu", "Xiang Ao", "Min Yang" ],
      "venue" : null,
      "citeRegEx" : "Jiang et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Jiang et al\\.",
      "year" : 2019
    }, {
      "title" : "Aspect term extraction with history attention and selective transformation",
      "author" : [ "Xin Li", "Lidong Bing", "Piji Li", "Wai Lam", "Zhimou Yang." ],
      "venue" : "Proceedings of the Twenty-Seventh International Joint Conference on Artificial Intelligence, IJCAI 2018, July",
      "citeRegEx" : "Li et al\\.,? 2018",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2018
    }, {
      "title" : "Fine-grained opinion mining with recurrent neural networks and word embeddings",
      "author" : [ "Pengfei Liu", "Shafiq R. Joty", "Helen M. Meng." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon,",
      "citeRegEx" : "Liu et al\\.,? 2015",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2015
    }, {
      "title" : "DOER: dual cross-shared RNN for aspect term-polarity co-extraction",
      "author" : [ "Huaishao Luo", "Tianrui Li", "Bing Liu", "Junbo Zhang." ],
      "venue" : "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July",
      "citeRegEx" : "Luo et al\\.,? 2019",
      "shortCiteRegEx" : "Luo et al\\.",
      "year" : 2019
    }, {
      "title" : "Exploring sequence-tosequence learning in aspect term extraction",
      "author" : [ "Dehong Ma", "Sujian Li", "Fangzhao Wu", "Xing Xie", "Houfeng Wang." ],
      "venue" : "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence,",
      "citeRegEx" : "Ma et al\\.,? 2019",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2019
    }, {
      "title" : "A joint training dual-mrc framework for aspect based sentiment analysis",
      "author" : [ "Yue Mao", "Yi Shen", "Chao Yu", "Longjun Cai." ],
      "venue" : "Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial",
      "citeRegEx" : "Mao et al\\.,? 2021",
      "shortCiteRegEx" : "Mao et al\\.",
      "year" : 2021
    }, {
      "title" : "Knowing what, how and why: A near complete solution for aspect-based sentiment analysis",
      "author" : [ "Haiyun Peng", "Lu Xu", "Lidong Bing", "Fei Huang", "Wei Lu", "Luo Si." ],
      "venue" : "The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The",
      "citeRegEx" : "Peng et al\\.,? 2020",
      "shortCiteRegEx" : "Peng et al\\.",
      "year" : 2020
    }, {
      "title" : "Semeval-2016 task 5: Aspect based sentiment analysis",
      "author" : [ "Marianna Apidianaki", "Xavier Tannier", "Natalia V. Loukachevitch", "Evgeniy V. Kotelnikov", "Núria Bel", "Salud María Jiménez Zafra", "Gülsen Eryigit." ],
      "venue" : "Proceedings of the 10th International Work-",
      "citeRegEx" : "Apidianaki et al\\.,? 2016",
      "shortCiteRegEx" : "Apidianaki et al\\.",
      "year" : 2016
    }, {
      "title" : "Semeval-2015 task 12: Aspect based sentiment analysis",
      "author" : [ "Maria Pontiki", "Dimitris Galanis", "Haris Papageorgiou", "Suresh Manandhar", "Ion Androutsopoulos." ],
      "venue" : "Proceedings of the 9th International Workshop on Semantic Evaluation, SemEval@NAACL-",
      "citeRegEx" : "Pontiki et al\\.,? 2015",
      "shortCiteRegEx" : "Pontiki et al\\.",
      "year" : 2015
    }, {
      "title" : "Semeval-2014 task 4: Aspect based sentiment analysis",
      "author" : [ "Maria Pontiki", "Dimitris Galanis", "John Pavlopoulos", "Harris Papageorgiou", "Ion Androutsopoulos", "Suresh Manandhar." ],
      "venue" : "Proceedings of the 8th International Workshop on Semantic Evaluation, Se-",
      "citeRegEx" : "Pontiki et al\\.,? 2014",
      "shortCiteRegEx" : "Pontiki et al\\.",
      "year" : 2014
    }, {
      "title" : "Attention-based LSTM for aspectlevel sentiment classification",
      "author" : [ "Yequan Wang", "Minlie Huang", "Xiaoyan Zhu", "Li Zhao." ],
      "venue" : "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin, Texas,",
      "citeRegEx" : "Wang et al\\.,? 2016",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2016
    }, {
      "title" : "Learn from syntax: Improving pair-wise aspect and opinion terms extraction with rich syntactic knowledge",
      "author" : [ "Shengqiong Wu", "Hao Fei", "Yafeng Ren", "Donghong Ji", "Jingye Li." ],
      "venue" : "Proceedings of the Thirtieth International Joint Conference on Artificial",
      "citeRegEx" : "Wu et al\\.,? 2021",
      "shortCiteRegEx" : "Wu et al\\.",
      "year" : 2021
    }, {
      "title" : "Learning span-level interactions for aspect sentiment triplet extraction",
      "author" : [ "Lu Xu", "Yew Ken Chia", "Lidong Bing." ],
      "venue" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on",
      "citeRegEx" : "Xu et al\\.,? 2021",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2021
    }, {
      "title" : "Position-aware tagging for aspect sentiment triplet extraction",
      "author" : [ "Lu Xu", "Hao Li", "Wei Lu", "Lidong Bing." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20, 2020, pages",
      "citeRegEx" : "Xu et al\\.,? 2020",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2020
    }, {
      "title" : "A unified generative framework",
      "author" : [ "Hang Yan", "Junqi Dai", "Tuo Ji", "Xipeng Qiu", "Zheng Zhang" ],
      "venue" : null,
      "citeRegEx" : "Yan et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Yan et al\\.",
      "year" : 2021
    }, {
      "title" : "Unsupervised word and dependency path embeddings for aspect term extraction",
      "author" : [ "Yichun Yin", "Furu Wei", "Li Dong", "Kaimeng Xu", "Ming Zhang", "Ming Zhou." ],
      "venue" : "Proceedings of the Twenty-Fifth International Joint Conference on Artificial Intelligence,",
      "citeRegEx" : "Yin et al\\.,? 2016",
      "shortCiteRegEx" : "Yin et al\\.",
      "year" : 2016
    }, {
      "title" : "Convolution over hierarchical syntactic and lexical graphs for aspect level sentiment analysis",
      "author" : [ "Mi Zhang", "Tieyun Qian." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online, November",
      "citeRegEx" : "Zhang and Qian.,? 2020",
      "shortCiteRegEx" : "Zhang and Qian.",
      "year" : 2020
    }, {
      "title" : "Spanmlt: A span-based multi-task learning framework for pair-wise aspect and opinion terms extraction",
      "author" : [ "He Zhao", "Longtao Huang", "Rong Zhang", "Quan Lu", "Hui Xue." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Lin-",
      "citeRegEx" : "Zhao et al\\.,? 2020",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "In recent years, it has attracted extensive attention of researchers (Hu and Liu, 2004).",
      "startOffset" : 69,
      "endOffset" : 87
    }, {
      "referenceID" : 22,
      "context" : "ABSA includes three basic subtasks: aspect term extraction (Yin et al., 2016; Li et al., 2018; Ma et al., 2019), opin-",
      "startOffset" : 59,
      "endOffset" : 111
    }, {
      "referenceID" : 8,
      "context" : "ABSA includes three basic subtasks: aspect term extraction (Yin et al., 2016; Li et al., 2018; Ma et al., 2019), opin-",
      "startOffset" : 59,
      "endOffset" : 111
    }, {
      "referenceID" : 11,
      "context" : "ABSA includes three basic subtasks: aspect term extraction (Yin et al., 2016; Li et al., 2018; Ma et al., 2019), opin-",
      "startOffset" : 59,
      "endOffset" : 111
    }, {
      "referenceID" : 9,
      "context" : "ion term extraction (Liu et al., 2015; Wu et al., 2021), and aspect level sentiment classification (Wang et al.",
      "startOffset" : 20,
      "endOffset" : 55
    }, {
      "referenceID" : 18,
      "context" : "ion term extraction (Liu et al., 2015; Wu et al., 2021), and aspect level sentiment classification (Wang et al.",
      "startOffset" : 20,
      "endOffset" : 55
    }, {
      "referenceID" : 17,
      "context" : ", 2021), and aspect level sentiment classification (Wang et al., 2016; Chen et al., 2017; Jiang et al., 2019; Zhang and Qian, 2020).",
      "startOffset" : 51,
      "endOffset" : 131
    }, {
      "referenceID" : 0,
      "context" : ", 2021), and aspect level sentiment classification (Wang et al., 2016; Chen et al., 2017; Jiang et al., 2019; Zhang and Qian, 2020).",
      "startOffset" : 51,
      "endOffset" : 131
    }, {
      "referenceID" : 7,
      "context" : ", 2021), and aspect level sentiment classification (Wang et al., 2016; Chen et al., 2017; Jiang et al., 2019; Zhang and Qian, 2020).",
      "startOffset" : 51,
      "endOffset" : 131
    }, {
      "referenceID" : 23,
      "context" : ", 2021), and aspect level sentiment classification (Wang et al., 2016; Chen et al., 2017; Jiang et al., 2019; Zhang and Qian, 2020).",
      "startOffset" : 51,
      "endOffset" : 131
    }, {
      "referenceID" : 2,
      "context" : "Substantial progress has been achieved in recent studies, integrating multiple subtasks into a more complex task (Chen and Qian, 2020; He et al., 2019; Luo et al., 2019; Zhao et al., 2020).",
      "startOffset" : 113,
      "endOffset" : 188
    }, {
      "referenceID" : 4,
      "context" : "Substantial progress has been achieved in recent studies, integrating multiple subtasks into a more complex task (Chen and Qian, 2020; He et al., 2019; Luo et al., 2019; Zhao et al., 2020).",
      "startOffset" : 113,
      "endOffset" : 188
    }, {
      "referenceID" : 10,
      "context" : "Substantial progress has been achieved in recent studies, integrating multiple subtasks into a more complex task (Chen and Qian, 2020; He et al., 2019; Luo et al., 2019; Zhao et al., 2020).",
      "startOffset" : 113,
      "endOffset" : 188
    }, {
      "referenceID" : 24,
      "context" : "Substantial progress has been achieved in recent studies, integrating multiple subtasks into a more complex task (Chen and Qian, 2020; He et al., 2019; Luo et al., 2019; Zhao et al., 2020).",
      "startOffset" : 113,
      "endOffset" : 188
    }, {
      "referenceID" : 13,
      "context" : "(Peng et al., 2020) becomes a subject of great interest, which is also the goal of our work.",
      "startOffset" : 0,
      "endOffset" : 19
    }, {
      "referenceID" : 19,
      "context" : "Many research efforts have been made (Xu et al., 2021; Mao et al., 2021; Chen et al., 2021), for example,",
      "startOffset" : 37,
      "endOffset" : 91
    }, {
      "referenceID" : 12,
      "context" : "Many research efforts have been made (Xu et al., 2021; Mao et al., 2021; Chen et al., 2021), for example,",
      "startOffset" : 37,
      "endOffset" : 91
    }, {
      "referenceID" : 1,
      "context" : "Many research efforts have been made (Xu et al., 2021; Mao et al., 2021; Chen et al., 2021), for example,",
      "startOffset" : 37,
      "endOffset" : 91
    }, {
      "referenceID" : 1,
      "context" : "In this section, we briefly review the BMRC (Chen et al., 2021), and then introduce our four improve-",
      "startOffset" : 44,
      "endOffset" : 63
    }, {
      "referenceID" : 3,
      "context" : "We use the tokenizer based on wordpiece in BERT (Devlin et al., 2019) to segment words into sub-",
      "startOffset" : 48,
      "endOffset" : 69
    }, {
      "referenceID" : 5,
      "context" : "Recently, there is a lot of work to deal with ABSA tasks based on span extraction (Hu et al., 2019; Xu et al., 2021), so does BMRC.",
      "startOffset" : 82,
      "endOffset" : 116
    }, {
      "referenceID" : 19,
      "context" : "Recently, there is a lot of work to deal with ABSA tasks based on span extraction (Hu et al., 2019; Xu et al., 2021), so does BMRC.",
      "startOffset" : 82,
      "endOffset" : 116
    }, {
      "referenceID" : 1,
      "context" : "After obtaining the predicted value of each position as the start or end position of span through binary classifiers, the predicted value is converted into probability using softmax function (Chen et al., 2021).",
      "startOffset" : 191,
      "endOffset" : 210
    }, {
      "referenceID" : 13,
      "context" : "We evaluate the model performance on ASTE-Datav1 (Peng et al., 2020) and ASTE-Data-v2 (Xu et al.",
      "startOffset" : 49,
      "endOffset" : 68
    }, {
      "referenceID" : 20,
      "context" : ", 2020) and ASTE-Data-v2 (Xu et al., 2020), which are popular benchmark datasets for ASTE task.",
      "startOffset" : 25,
      "endOffset" : 42
    }, {
      "referenceID" : 13,
      "context" : "Table 1: Experiments on the ASTE-Data-v1 (Peng et al., 2020) dataset.",
      "startOffset" : 41,
      "endOffset" : 60
    }, {
      "referenceID" : 20,
      "context" : "Table 2: Experiments on the ASTE-Data-v2 (Xu et al., 2020) dataset.",
      "startOffset" : 41,
      "endOffset" : 58
    }, {
      "referenceID" : 20,
      "context" : "Table 3: The performance of our four improvements on the ASTE-Data-v2 (Xu et al., 2020) dataset.",
      "startOffset" : 70,
      "endOffset" : 87
    }, {
      "referenceID" : 19,
      "context" : "of the Strong baseline Span-ASTE (Xu et al., 2021) by 2.",
      "startOffset" : 33,
      "endOffset" : 50
    } ],
    "year" : 0,
    "abstractText" : "Aspect sentiment triplet extraction (ASTE) is a challenging subtask in aspect-based sentiment analysis. It aims to explore the triplets of aspects, opinions and sentiments with complex correspondence from the context. The bidirectional machine reading comprehension (BMRC) can effectively deal with ASTE task, but several problems remains, such as query conflict and probability unilateral decrease. Therefore, this paper presents a robustly optimized BMRC method by incorporating four improvements. The word segmentation is applied to facilitate the semantic learning. Exclusive classifiers are designed to avoid the interference between different queries. A span matching rule is proposed to select the aspects and opinions that better represent the expectations of the model. The probability generation strategy is also introduced to obtain the predicted probability for aspects, opinions and aspectopinion pairs. We have conducted extensive experiments on multiple benchmark datasets, where our model achieves the state-of-the-art performance.",
    "creator" : null
  }
}