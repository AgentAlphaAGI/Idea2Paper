{
  "name" : "ARR_2022_228_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "HLDC: Hindi Legal Documents Corpus",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In recent times, the legal system in many populous countries (e.g., India) has been inundated with a large number of legal documents and pending cases (Katju, 2019). There is an imminent need for automated systems to process legal documents and help augment the legal procedures. For example, if a system could readily extract the required information from a legal document for a legal practitioner, then it would help them expedite the legal process. However, the processing of legal documents is challenging and is quite different from conventional text processing tasks. For example, legal documents are typically quite long (tens of pages), legal documents are highly unstructured and noisy (spelling and grammar mistakes, since these are typed), language in legal documents are domain-specific, and pre-trained language models do not perform well on these (Malik et al., 2021).\nTo develop legal text processing systems and address the challenges associated with the legal domain, there is a need for creating specialized legal domain corpora. In recent times, there have been efforts to develop such corpora for example, Chalkidis et al. (2019) have developed an English corpus of European Court of Justice documents, Malik et al. (2021) have developed an English corpus of Indian Supreme Court documents, Xiao et al. (2018) have developed Chinese Legal Document corpus. However, to the best of our knowledge, there does not exist any legal document corpus for the Hindi language (a language belonging to the Indo-European family and predominantly spoken in India). Hindi uses Devanagri (Wikipedia contributors, 2021) script for the writing system. Hindi is spoken by approx. 567 million people in the world (WorldData, 2021). Most of the lower (district) courts in Northern India use Hindi as the official language. However, most of the legal NLP systems that currently exist in India have been developed on English, and these do not work on Hindi legal documents (Malik et al., 2021). To address this problem, in this paper, we release a large corpus of Hindi legal documents (Hindi Legal Document Corpus) that can be used for developing NLP systems that could augment the legal practitioners by automating some of the legal processes. Further, we show a use case for the proposed corpus via a new task of bail prediction.\nIndia follows a Common Law system and has a three-tiered court system with District Courts (along with Subordinate Courts) at the lowest levels of districts, followed by High Courts at the state level and the Supreme Court at the highest level. In terms of the number of cases, district courts handle the majority of the cases. According to India’s National Judicial Data Grid, as of November 2021, there are approximately 40 million cases pending in District courts (National Ju-\ndicial Data Grid, 2021) as opposed to 5 million cases pending in High Courts. These statistics show an immediate need for developing systems that could address the problems at the grass-root levels of the Indian legal system. Out of 40 million pending cases, approximately 20 million cases are from courts where the official language is Hindi (National Judicial Data Grid, 2021). In this resource paper, we create a large corpus of about 900K Hindi legal documents. In particular, we collect documents from the state of Uttar Pradesh (U.P.), the most populous state of India with a population of approximately 237 million (PopulationU, 2021). The Hindi Legal Document Corpus (HLDC) can be used for a number of legal applications, and in this paper, we propose the task of Bail Prediction. Given a legal document with facts of the case, the task of bail prediction requires an automated system to predict if the accused should be granted bail or not. We develop baseline models for addressing the task of bail prediction. The motivation behind the task is not to replace a human judge but rather augment them in the judicial process. Given the volume of cases, if a system could present an initial analysis of the case, it would expedite the process. As told to us by legal experts and practitioners, given the economies of scale, even a small improvement in efficiency would result in a large impact. In a nutshell, we make the following main contributions in this resource paper:\n• We are first to create a Hindi Legal Documents Corpus (HLDC) of around 900K documents. These documents are cleaned and structured to make them usable for downstream applications. Moreover, this is a growing corpus, and we continue to add more legal documents to HLDC. We release the corpus, creation scripts and model implementations code with this paper.\n• As a use-case for applicability of the corpus for developing legal systems, we propose the task of Bail Prediction.\n• For the task of bail prediction, we experiment with a variety of deep learning models. We propose a multi-task learning based model based on transformer architecture. The proposed model uses extractive summarization as an auxiliary task and bail prediction as the main task."
    }, {
      "heading" : "2 Related Work",
      "text" : "In recent years there has been active interest in the application of NLP techniques to the legal domain (Zhong et al., 2020a). A number of tasks and models have been proposed, inter alia, Legal Judgment Prediction (Chalkidis et al., 2019), Legal Summarization (Bhattacharya et al., 2019; Tran et al., 2019), Prior Case Retrieval (Jackson et al., 2003; Shao et al., 2020), Legal Question Answering (Kim and Goebel, 2017), Catchphrase Extraction (Galgani et al., 2012).\nLegal Judgement Prediction (LJP) involves predicting the final decision from the facts and arguments of the case. Chalkidis et al. (2019) released 11,478 cases from the European Court of Human Rights (ECHR). It contains facts, articles violated (if any), and the importance scores. Malik et al. (2021) provided 34,816 case documents from the Supreme Court of India for the prediction task. Strickson and De La Iglesia (2020) published 4,959 documents from the U.K.’s Supreme court (the highest court of appeal).\nMajority of corpora for Legal-NLP tasks have been in English; recently, there have been efforts to address other languages as well, for example, Xiao et al. (2018), have created a large-scale Chinese criminal judgment prediction dataset with over 2.68 million legal documents. Work on Legal-NLP in languages other than English is still in its incipient stages. Our paper contributes towards these efforts by releasing corpus in Hindi.\nMajority of the work in the legal domain has focused on the higher court (Malik et al., 2021; Strickson and De La Iglesia, 2020; Zhong et al., 2020b); however, the lower courts handle the maximum number of cases. We try to address this gap by releasing a large corpus of district court level legal documents.\nSome of the recent work has explored other Legal-NLP tasks in languages other than English. Chalkidis et al. (2021) released a multilingual dataset of 65K European Union (E.U.) laws for topic classification of legal documents. The data was translated into the 23 official E.U. languages and annotated with labels from the multilingual thesaurus, EUROVOC1. Luz de Araujo et al. (2018) have released 70 documents in Portuguese for Legal Named Entity Recognition. The dataset contains specific tags for law and legal\n1https://eur-lex.europa.eu/browse/ eurovoc.html\ncases entities in addition to the normal tags for named entities like person, locations, organisation and time-entities. COLIEE (Competition on Legal Information Extraction/Entailment) tasks (Kano et al., 2019, 2017) have published legal data in Japanese, along with their English translation. The competition had two sub-tasks, a legal information retrieval task and an entailment identification task between law articles and queries. Multiple datasets in Chinese have been released for different tasks, namely Reading Comprehension (Duan et al., 2019), Similar Case Matching (Xiao et al., 2019), Question Answering (Zhong et al., 2020b). Duan et al. (2019) proposed Chinese judicial reading comprehension (CJRC) dataset with about 10K documents and almost 50K questions with answers. Zhong et al. (2020b) presented JECQA, a legal question answering dataset collected from the National Judicial Examination of China with about 26K multiple-choice questions. They augment the dataset with a database containing the legal knowledge required to answer the questions and also assign meta information to each of the questions for in-depth analysis. Xiao et al. (2019) proposed CAIL2019-SCM, a dataset containing 8,964 triplets of the case document, with the objective to identify which two cases are more similar in the triplets. Similar case matching has a crucial application as it helps to identify comparable historical cases. A historical case with similar facts often serves as a legal precedent and influences the judgement. Such historical information can be used to make the legal judgement prediction models more robust.\nKleinberg et al. (2017) proposed bail decision prediction as a good proxy to gauge if machine learning can improve human decision making. A large number of bail documents along with the binary decision (granted or denied) makes it an ideal task for automation. In this paper, we also propose the bail prediction task using the HLDC corpus."
    }, {
      "heading" : "3 Hindi Legal Document Corpus",
      "text" : "Hindi Legal Document Corpus (HLDC) is a corpus of about 900K Indian legal case documents\nin the Hindi language. The corpus is created by scraping data from the e-Courts website (a publicly available website: https:// districts.ecourts.gov.in/). All the legal documents we consider are in the public domain. We scrape case documents pertaining to the district courts located in the Indian northern state of Uttar Pradesh (U.P.). We focus mainly on the state of U.P. as it is the most populous state of India, resulting in the filing of a large number of cases in district courts. U.P. has 71 districts and about 161 district courts. U.P. is a predominantly Hindi speaking state, and consequently, the official language used in district courts is Hindi. We crawled case documents from all districts of U.P. corresponding to cases filed over two years, from May 01, 2019 to May 01, 2021. Figure 3 shows the map of U.P. and district wise variation in the number of cases. As can be seen in the plot, the western side of the state has more cases; this is possibly due to the high population and more urbanization in the western part. Table 1 shows %- wise division of different case types in HLDC. As evident from the table, majority of documents pertain to bail applications. HLDC corpus has a total of 3,797,817 unique tokens, and on average, each document has 764 tokens. HLDC Creation Pipeline: We outline the entire pipeline used to create the corpus in Figure 1. The documents on the website are originally typed in Hindi (in Devanagari script) and then scanned to PDF format and uploaded. The first step in HLDC creation is the scraping of documents from the eCourts website. We crawled a total of 1,221,950 documents. To extract Hindi text from these, we perform OCR (Optical Character Recognition) via the Tesseract tool2. Tesseract worked well for our use case as the majority of case documents were well-typed, and it outperformed other OCR libraries3. The obtained text documents were further cleaned to remove noisy documents, e.g. too short (< 32 bytes) or too long (> 8096 bytes) documents, duplicates, and English documents (de-\n2https://github.com/tesseract-ocr 3https://github.com/JaidedAI/EasyOCR\ntails in Appendix B). This resulted in a total of 912,568 documents in HLDC. We anonymized the corpus with respect to names and locations. We used a gazetteer4 along with regex-based rules for NER to anonymize the data. List of first names, last names, middle names, locations, titles like p\\EXt (Pandit: title of Priest), srjF (Sir: Sir), month names and day names were normalized to <nAm> (Naam: <name>). The gazetteer also had some common ambiguous words (these words can be names or sometimes verbs) like þAT nA (Prathna: Can refer to prayer, the action of request or name), gyA (Gaya: can refer to location name or verb), EkyA (Kiya: can refer to infinitive ‘to do’ or name), ElyA (Liya: can refer to infinitive ‘to take’ or name). These were removed. Further, we ran RNN-based Hindi NER model5 on a subset of documents to find additional entities and these were subsequently used to augment our gazetteer (details Appendix C). Phone numbers were detected using regex patterns and replaced with a <'on -n\\br> (<phone-number>) tag, numbers written in both English and Hindi were considered.\nLegal documents, particularly in lower courts, are highly unstructured and lack standardization with respect to format and sometimes even the terms used. We converted the unstructured documents to semi-structured documents. We segmented each document into a header and a body. The header contains the meta-information related to the case, for example, case number, court identifier, applicable sections of the law, etc. The body contains the facts of the case, arguments, judge’s summary, case decision and other information related to the final decision. The documents were segmented using regex and rule based approaches as described in Appendix D.\nCase Type Identification: HLDC documents were processed to obtain different case types (e.g., Bail applications, Criminal Cases). The case type was identified via the meta-data that comes with each document. However, different districts use a variation of the same case type name (e.g., Bail Application vs Bail App.). We resolved these standardization issues via manual inspection and regex-based patterns, resulting in a final list of 300 unique case types.\n4https://github.com/piyusharma95/ NER-for-Hindi, https://github.com/ balasahebgulave/Dataset-Indian-Names\n5https://github.com/flairNLP/flair\nLexical Analysis: Although Hindi is the official language, U.P. being a large and populous state, has different dialects of Hindi spoken across the state. We found evidence of this even in official legal documents. For example, the word sAEkn (Sakin: motionless) appears 11,614 times in the dataset, 63.8% occurrences of the word come from 6 districts of East U.P. (Ballia, Azamgarh, Maharajganj, Deoria, Siddharthnagar and Kushinagar). This particular variant of motionless being used most often only in East U.P. Similarly, the word gOv\\fFy (Gaushiya: cow and related animals) is mostly used in North-Western UP (Rampur, Pilibhit, Jyotiba Phule Nagar (Amroha), Bijnor, Budaun, Bareilly, Moradabad). Three districts - Muzaffarnagar, Kanshiramnagar and Pratapgarh district constitute 81.5% occurrences of the word d\\X (Dand: punishment). These districts are, however, spread across UP. An important thing to note is that words corresponding to specific districts/areas are colloquial and not part of the standard Hindi lexicon. This makes it difficult for prediction model to generalize across districts (§7). Corpus of Bail Documents: Bail is the provisional release of a suspect in any criminal offence on payment of a bail bond and/or additional restrictions. Bail cases form a large majority of cases in the lower courts, as seen in Table 1. Additionally, they are very time-sensitive as they require quick decisions. For HLDC, the ratio of bail documents to total cases in each district is shown in Figure 4. As a use-case for the corpus, we further investigated the subset of the corpus having only the bail application documents (henceforth, we call it Bail Corpus).\nHindi Bail Documents\nHeader Body Result Segmented 1. 2. 3.\nBail Denied Bail Granted 1. 2.\nDocument Segmentaion\nOutcome Identification\nJudge's Opinion Mining Bail Documents Bail Documents with Judge's\nOpinion\nBail Documents\nHeader Body Result Segmented 1. 2. 3.\nBail Denied Bail Granted 1. 2.\nDocument Segmentaion\nOutcome Identification\nJudge's Opinion Mining Bail Documents Bail Documents with Judge's\nOpinion\nFilter Bail Documents Hindi Legal Documents\nCorpus (HLDC)\nBail Document Segmentation: For the bail documents, besides th header and body, we further segmented the body part into more subsections (Figure 2). The body is further segmented into Facts and Arguments, Judge’s summary and Case Result. Facts contain the facts of the case and the defendant and prosecutor’s arguments. Most of the bail documents have a concluding paragraph where the judge summarizes their viewpoints of the case, and this constitutes the judge’s summary sub-section. The case result sub-section contains the final decision given by the judge. More details about document segmentation\nare in Appendix D. Bail Decision Extraction: Decision was extracted from Case Result Section using a rule based approach (Details in Appendix E).\nBail Amount Extraction: If bail was granted, it usually has some bail amount associated with it. We extracted this bail amount using regex patterns (Details in Appendix F).\nWe verified each step of the corpus creation pipeline (Detailed analysis in Appendix G) to ensure the quality of the data. We initially started with 363,003 bail documents across all the 71 districts of U.P., and after removing documents having segmentation errors, we have a Bail corpus with 176,849 bail documents. The bail corpus has a total of 2,342,073 unique tokens, and on average, each document has 614 tokens. A sample document segmented into various sections is shown in Appendix I."
    }, {
      "heading" : "4 HLDC: Ethical Aspects",
      "text" : "We create HLDC to promote research and automation in the legal domain dealing with underresearched and low-resource languages like Hindi. The documents that are part of HLDC are in the public domain and hence accessible to all. Given the volume of pending cases in the lower courts, our efforts are aimed towards improving the legal system, which in turn would be beneficial for millions of people. Our work is in line with some of the previous work on legal NLP, e.g., legal corpora creation and legal judgement prediction (section 2). Nevertheless, we are aware that if not handled correctly, legal AI systems developed on legal corpora can negatively impact an individual and society at large. Consequently, we took all possible steps to remove any personal information and biases in the corpus. We anonymized the corpus (section 3) with respect to names, gender information, titles, locations, times, judge’s name, petitioners and appellant’s name. As observed in previous work (Malik et al., 2021), anonymization of a judge’s name is important as there is a corre-\nlation between a case outcome and a judge name. Along with the HLDC, we also introduce the task of Bail Prediction. Bail applications constitute the bulk of the cases (§3), augmentation by an AI system can help in this case. The bail prediction task aims not to promote the development of systems that replace humans but rather the development of systems that augment humans. The bail prediction task provides only the facts of the case to predict the final decision and avoids any biases that may affect the final decision. Moreover, the Bail corpus and corresponding bail prediction systems can promote the development of explainable systems (Malik et al., 2021), we leave research on such explainable systems for future work. The legal domain is a relatively new area in NLP research, and more research and investigations are required in this area, especially concerning biases and societal impacts; for this to happen, there is a need for corpora, and in this paper, we make initial steps towards these goals."
    }, {
      "heading" : "5 Bail Prediction Task",
      "text" : "To demonstrate a possible applicability for HLDC, we propose the Bail Prediction Task, where given the facts of the case, the goal is to predict whether the bail would be granted or denied. Formally, consider a corpus of bail documents D = b1, b2, · · · , bi, where each bail document is segmented as bi = (hi, fi, ji, yi). Here, hi, fi, ji and yi represent the header, facts, judge’s summary and bail decision of the document respectively. Additionally, the facts of every document contain k sentences, more formally, fi = (s1i , s 2 i , · · · , ski ), where ski represents the k th sentence of the ith bail document. We formulate the bail prediction task as a binary classification problem. We are interested in modelling pθ(yi|fi), which is the probability of the outcome yi given the facts of a case fi. Here, yi ∈ {0, 1}, i.e., 0 if bail is denied or 1 if bail is granted."
    }, {
      "heading" : "6 Bail Prediction Models",
      "text" : "We initially experimented with off-the-shelf pretrained models trained on general-purpose texts. However, as outlined earlier (§1), the legal domain comes with its own challenges, viz. specialized legal lexicon, long documents, unstructured and noisy texts. Moreover, our corpus is from an under-resourced language (Hindi). Nevertheless, we experimented with existing fine-tuned\n(pre-trained) models and finally propose a multitask model for the bail prediction task."
    }, {
      "heading" : "6.1 Embedding Based Models",
      "text" : "We experimented with classical embedding based model Doc2Vec (Le and Mikolov, 2014) and transformer-based contextualized embeddings model IndicBERT (Kakwani et al., 2020). Doc2Vec embeddings, in our case, is trained on the train set of our corpus. The embeddings go as input to SVM and XgBoost classifiers. IndicBERT is a transformer language model trained on 12 major Indian languages. However, IndicBERT, akin to other transformer LMs, has a limitation on the input’s length (number of tokens). Inspired by Malik et al. (2021); Chalkidis et al. (2019), we experimented with fine-tuning IndicBERT in two settings: the first 512 tokens and the last 512 tokens of the document. The fine-tuned transformer with a classification head is used for bail prediction."
    }, {
      "heading" : "6.2 Summarization Based Models",
      "text" : "Given the long lengths of the documents, we experimented with prediction models that use summarization as an intermediate step. In particular, an extractive summary of a document goes as input to a fine-tuned transformer-based classifier (IndicBERT). Besides reducing the length of the document, extractive summarization helps to evaluate the salient sentences in a legal document and is a step towards developing explainable models. We experimented with both unsupervised and supervised extractive summarization models.\nFor unsupervised approaches we experimented with TF-IDF (Ramos, 2003) and TextRank (a graph based method for extracting most important sentences) (Mihalcea and Tarau, 2004). For the supervised approach, inspired by Bajaj et al. (2021), we propose the use of sentence salience classifier to extract important sentences from the document. Each document (bi = (hi, fi, ji, yi), §5) comes with a judge’s summary ji. For each sentence in the facts of the document (fi) we calculate it’s cosine similarity with judge’s summary (ji). Formally, salience of kth sentence ski is given by: salience(ski ) = cos(hji , hski\n). Here hji is contextualized distributed representation for ji obtained using multilingual sentence encoder (Reimers and Gurevych, 2020). Similarly, hski is the representation for the sentence ski . The cosine similarities\nprovides ranked list of sentences and we select top 50% sentences as salient. The salient sentences are used to train (and fine-tune) IndicBERT based classifier."
    }, {
      "heading" : "6.3 Multi-Task Learning (MTL) Model",
      "text" : "As observed during experiments, summarization based models show improvement in results (§7). Inspired by this, we propose a multi-task framework (Figure 5), where bail prediction is the main task, and sentence salience classification is the auxiliary task. The intuition is that predicting the important sentences via the auxiliary task would force the model to perform better predictions and vice-versa. Input to the model are sentences corresponding to the facts of a case: s1i , s 2 i , . . . , s k i . A multilingual sentence encoder (Reimers and Gurevych, 2020) is used to get contextualized representation of each sentence: {h1i , h2i , · · · , hki }. In addition, we append the sentence representations with a special randomly initialized CLS embedding (Devlin et al., 2019) that gets updated during model training. The CLS and sentence embeddings are fed into standard single layer transformer architecture (shared transformer)."
    }, {
      "heading" : "6.3.1 Bail Prediction Task",
      "text" : "A classification head (fully connected layer MLP) on the top of transformer CLS embedding is used to perform bail prediction. We use standard crossentropy loss (Lbail) for training."
    }, {
      "heading" : "6.3.2 Salience Classification Task",
      "text" : "We use the salience prediction head (MLP) on top of sentence representations at the output of the shared transformer. For training the auxiliary task, we use sentence salience scores obtained via co-\nsine similarity (these come from supervised summarization based model). For each sentence, we use binary-cross entropy loss (Lsalience) to predict the salience.\nBased on our empirical investigations, both the losses are equally weighted, and total loss is given by L = Lbail + Lsalience"
    }, {
      "heading" : "7 Experiments and Results",
      "text" : ""
    }, {
      "heading" : "7.1 Dataset Splits",
      "text" : "We evaluate the models in two settings: all-district performance and district-wise performance. For the first setting, the model is trained and tested on the documents coming from all districts. The train, validation and test split is 70:10:20. The districtwise setting is to test the generalization capabilities of the model. In this setting, the documents from 44 districts (randomly chosen) are used for training. Testing is done on a different set of 17 districts not present during training. The validation set has another set of 10 districts. This split corresponds to a 70:10:20 ratio. Table 2 provides the number of documents across splits. The corpus is unbalanced for the prediction class with about 60:40 ratio for positive to negative class (Table 2). All models are evaluated using standard accuracy and F1-score metric (Appendix H.1).\nImplementation Details: All models are trained using GeForce RTX 2080Ti GPUs. Models are tuned for hyper-parameters using the validation set (details in Appendix H.2)."
    }, {
      "heading" : "7.2 Results",
      "text" : "The results are shown in Table 3. As can be observed, in general, the performance of models is lower in the case of district-wise settings. This is possibly due to the lexical variation (section 3) across districts, which makes it difficult for the model to generalize. Moreover, this lexical variation corresponds to the usage of words corresponding to dialects of Hindi. Another thing to note from the results is that, in general, summarization models perform better than Doc2Vec and transformer-based models, highlighting the importance of the summarization step in the bail prediction task. The proposed end-to-end multi-task model outperforms all the baselines in the districtwise setting with 78.53% accuracy. The auxiliary task of sentence salience classification helps learn robust features during training and adds a regularization effect on the main task of bail prediction, leading to improved performance than the two-step baselines. However, in the case of an alldistrict split, the MTL model fails to beat simpler baselines like TF-IDF+IndicBERT. We hypothesize that this is due to the fact that the sentence salience training data may not be entirely correct since it is based on the cosine similarity heuristic, which may induce some noise for the auxiliary task. Additionally, there is lexical diversity present across documents from different districts. Since documents of all districts are combined in this setting, this may introduce diverse sentences, which are harder to encode for the salience classifier, while TF-IDF is able to look at the distribution of words across all documents and districts to extract salient sentences."
    }, {
      "heading" : "7.3 Error Analysis",
      "text" : "We did further analysis of the model outputs to understand failure points and figure out improvements to the bail prediction system. We observe a couple of things looking at the misclassified examples. First, the lack of standardization can manifest in unique ways. In one of the documents, we observed that all the facts and arguments seemed to point to the decision of bail granted. Our model also gauged this correctly and predicted bail granted. However, the actual result of the document showed that even though initially bail was granted because the accused failed to show up on multiple occasions, the judge overturned the decision and the final verdict was bail denied. In some instances, we also observe that even if the facts of the cases are similar the judgements can differ. We observed two cases about the illegal possession of drugs that differed only a bit in the quantity seized but had different decisions. The model is trained only on the documents and has no access to legal knowledge, hence is not able to capture such legal nuances. This provides interesting future direction, where legal knowledge is incorporated into the prediction model."
    }, {
      "heading" : "8 Future Work and Conclusion",
      "text" : "In this paper, we introduced a large corpus of legal documents for the under-resourced language Hindi: Hindi Legal Document Corpus (HLDC). We semi-structure the documents to make them amenable for further use in downstream applications. As a use-case for HLDC, we introduce the task of Bail Prediction. We experimented with several models and proposed a multi-task learning based model that predicts salient sentences as an auxiliary task and bail prediction as the main task. Results show scope for improvement that we plan to explore in future. We also plan to expand HLDC by covering other Indian Hindi speaking states. Furthermore, as a future direction, we plan to collect legal documents in other Indian languages. India has 22 official languages, but for the majority of languages, there are no legal corpora. Another interesting future direction that we would like to explore is the development of deep models infused with legal knowledge so that model is able to capture legal nuances. We plan to use the HLDC corpus for other legal tasks such as summarization and prior case retrieval."
    }, {
      "heading" : "A Data Statistics",
      "text" : ""
    }, {
      "heading" : "B Data Cleaning and Filtering",
      "text" : "1,221,950 documents were scraped from Ecourts website and 309,382 documents were removed in the cleaning and filtering process. Following rules were used to remove documents.\n• Removed blank documents (whose length is less than 32 bytes)\n• Removed duplicate documents\n• Removed too long and too short documents (>8096 bytes or <2048 bytes).\n• Removed document where majority text was in English language.\nThis resulted in 912,568 filtered case documents that constitute the Hindi Legal Document Corpus."
    }, {
      "heading" : "C NER Removal",
      "text" : "For removing names and locations, lookup was done in lists containing NER. Libraries like HindiNLP6 (which uses SequenceTagger from flair library7 which is based on an RNN model) were run on a subset of the data to find additional NER that were added to the lists. Since the Sequence-Tagger model is quite slow in processing documents, directly tagging large HLDC is not efficient. If a word was found in one of these lists then it was replaced with a <nAm> (<name>) tag. Phone numbers were replaced with <'on -n\\br> (<phone-number>) tag using the following regex\n( ( \\ + * ) ( ( 0 [ − ] * ) * | ( ( 9 1 ) * ) ) ( ( \\ d {12}) + | ( \\ d { 1 0 } ) + ) ) | \\ d {5}( [ − ] * ) \\ d {6}\nPhone numbers written in Hindi were also considered by using the same regex as above with English digits replaced with Hindi ones.\n6https://github.com/avinsit123/ HindiNLP\n7https://github.com/flairNLP/flair"
    }, {
      "heading" : "D Document Segmentation",
      "text" : "Out of 912,568 documents in HLDC, 340,280 were bail documents, these were further processed to obtain the Bail Document corpus. Bail documents were structured into different sections. We extracted these sections from the bail documents. Details are mentioned below. An example of document with different sections is shown in Table 10.\nD.1 Header\nHeader refers to the meta data related to the case, for example, DArA (IPC (Indian Penal Code) sections), TAnA (police station), case number, date of hearing, accused name, etc. Header is present at the top of the document. Header mostly ended with DArA (IPC) or TAnA (police station) details. Hence, in order to cut the document to get header, we first find the indices of DArA (IPC) and TAnA (police station), and from these indices we find the finishing word of the header. We then segment the document at the finishing word. We also include the first line of upcoming paragraph in header as it also didn’t contain case arguments but contained data like if this is the first bail application or not.\nD.2 Case Result\nCase Result refers to the end of the document where judge writes their decision. Judge either accepts the bail application or rejects it. If the judge had accepted the bail document then this section mostly also contains bail amount and bail terms for accused. We observed that result section mostly began along the following line, mAml k sm-t tLyo\\ ko d Kkr (looking at all facts of the case), the keyword tLyo\\ (facts) was very common around the start of the result section. Hence, we iterated over the indices of keyword tLyo\\ (facts) in reverse order and checked if the division at that index is correct. To check if the division is correct we look for bail result in lower half of the division, if the bail result is present, we classify that division as correct else we move to next index of tLyo\\ (facts).\nD.3 Body\nThe remaining portion of the document after removing header and result section was called body. Body section was further divided, as described below.\nD.3.1 Judge’s summary Most of the bail documents have a concluding paragraph where the judge summarizes their viewpoints of the case. To extract this, we first constructed certain regex which often precedes judge’s summary, defendant’s and prosecutor’s arguments (described in Table 5). Since the document might have intermingling of different arguments and opinions, we opted for sentence level annotation of these labels using the regex pattern. The sentences not matching any criteria are given a tag of None. Next we try to replace the None by extending the tags of the sentences to paragraph level as long as no other tag is encountered. As the judge’s opinion mostly occurs at the end, we start iterating from end and start marking the None as judge’s opinion. If a label which is neither None nor judge’s opinion is encountered, the document is discarded as we cannot extract the judge’s opinion from the document using the process defined. If the judge’s opinion label is found in reverse iteration, then we claim that judge’s opinion can be extracted. Finally, all sentences labelled as judge’s opinion either during reverse iteration or during paragraph level extension are extracted out as judge’s summary and rest of the sentences form facts and opinions for further modelling. Using the above process, following are some cases where the judge’s opinion cannot be extracted:\n1. Certain characters were mis-identified in the OCR pipeline and hence do not match the regex. 2. The segmentation of document into header, body and result caused a significant portion of the body and thus judge’s opinion to move to result section. 3. The document was written from judge’s perspective and hence judge’s summary also contains the prosecutor’s and defendant’s arguments. 4. The regex didn’t have 100% coverage.\nD.3.2 Facts and Arguments This section comprised of facts related to case, arguments from defendant and prosecutor. Mostly, this corresponds to the portion of the body after removing judge’s summary."
    }, {
      "heading" : "E Extracting Bail Decision from Result",
      "text" : "To extract the bail decision we searched for keywords in result section. Keywords like KAErj\n(dismissed) and Enr-t (invalidated) identified rejection of bail application and words like -vFkAr (accepted) identified acceptance of bail application. Table 6 lists all the tokens used for extraction."
    }, {
      "heading" : "F Extracting Bail Amount from Result",
      "text" : "In case of granted bail decision, the judge specifies bail amount. We saw that the bail amount mostly comprises of personal bond money and surety money. There can be multiple personal bonds and sureties. The bail amount we extracted refers to the sum of all the personal bond money. Bail amount was present in two forms in result section, numerical and Hindi-text. Numerical bail amount was extracted by regex matching and text bail amount was extracted by creating a mapping for it. Table 8 shows few examples of bail mapping."
    }, {
      "heading" : "G HLDC Pipeline Analysis",
      "text" : "We used a validation set (0.1% of data) to evaluate our regex based approaches, the results are in Table 7. Note that metrics used for evaluation are\nquite strict and hence the results are much lower for Judge’s summary part. The segmentation and Judge’s opinion were strictly evaluated and even a single sentence in the wrong segment reduces the accuracy. We also see that the main binary label of outcome detection (bail granted or denied) had an almost perfect accuracy of 99.4%. Nevertheless, in future we plan to improve our pipeline further by training machine learning models."
    }, {
      "heading" : "H Model Details",
      "text" : "H.1 Evaluation Metrics\nTo evaluate the performance of all the models, we use Accuracy, and F1-score, which are considered\nstandard evaluation metrics while performing classification experiments. These are mathematically described as the follows:\nAccuracy = TP + TN\nTP + TN + FP + FN\nF1 Score = 2 ∗ Precision ∗Recall Precision+Recall\nwhere TP, FP, TN, and FN denote True Positives, False Positives, True Negatives, and False Negatives, respectively. The mathematical formulation for Precision and Recall is given as follows:\nPrecision = TP\nTP + FP\nRecall = TP\nTP + FN\nH.2 Hyperparamter Tuning We used Optuna 8 for hyperparameter optimisation. Optuna allows us to easily define search spaces, select optimisation algorithms and scale with easy parallelization. We run parameter tuning on 10% of the data to identify the best parameters before retraining the model with the best parameters on the entire dataset. The best parameters are listed in Table 9.\n8https://github.com/optuna/optuna"
    }, {
      "heading" : "I Sample Segmented Document",
      "text" : "Field Example Translation\nHeader: This chunk of the document contains meta information related to the case like court hearing date, IPC sections attached, police station of complain, etc.\nFacts and Arguments: This chunk of the document contains case facts related to the case and arguments from defendant and prosecutor.\nContinued on next page"
    } ],
    "references" : [ {
      "title" : "Long document summarization in a low resource setting using",
      "author" : [ "Ahsaas Bajaj", "Pavitra Dangati", "Kalpesh Krishna", "Pradhiksha Ashok Kumar", "Rheeya Uppaal", "Bradford Windsor", "Eliot Brenner", "Dominic Dotterrer", "Rajarshi Das", "Andrew McCallum" ],
      "venue" : null,
      "citeRegEx" : "Bajaj et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Bajaj et al\\.",
      "year" : 2021
    }, {
      "title" : "A Comparative Study of Summarization Algorithms Applied to Legal Case Judgments",
      "author" : [ "Paheli Bhattacharya", "Kaustubh Hiware", "Subham Rajgaria", "Nilay Pochhi", "Kripabandhu Ghosh", "Saptarshi Ghosh." ],
      "venue" : "Leif Azzopardi, Benno Stein, Nor-",
      "citeRegEx" : "Bhattacharya et al\\.,? 2019",
      "shortCiteRegEx" : "Bhattacharya et al\\.",
      "year" : 2019
    }, {
      "title" : "Neural legal judgment prediction in English",
      "author" : [ "Ilias Chalkidis", "Ion Androutsopoulos", "Nikolaos Aletras." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 4317–4323, Florence, Italy. Association",
      "citeRegEx" : "Chalkidis et al\\.,? 2019",
      "shortCiteRegEx" : "Chalkidis et al\\.",
      "year" : 2019
    }, {
      "title" : "MultiEURLEX - a multi-lingual and multi-label legal document classification dataset for zero-shot cross-lingual transfer",
      "author" : [ "Ilias Chalkidis", "Manos Fergadiotis", "Ion Androutsopoulos." ],
      "venue" : "Proceedings of the 2021 Conference on Empirical Methods",
      "citeRegEx" : "Chalkidis et al\\.,? 2021",
      "shortCiteRegEx" : "Chalkidis et al\\.",
      "year" : 2021
    }, {
      "title" : "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "CJRC: A Reliable HumanAnnotated Benchmark DataSet for Chinese Judicial",
      "author" : [ "Xingyi Duan", "Baoxin Wang", "Ziyue Wang", "Wentao Ma", "Yiming Cui", "Dayong Wu", "Shijin Wang", "Ting Liu", "Tianxiang Huo", "Zhen Hu", "Heng Wang", "Zhiyuan Liu" ],
      "venue" : null,
      "citeRegEx" : "Duan et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Duan et al\\.",
      "year" : 2019
    }, {
      "title" : "Towards automatic generation of catchphrases for legal case reports",
      "author" : [ "Filippo Galgani", "Paul Compton", "Achim Hoffmann." ],
      "venue" : "Proceedings of the 13th International Conference on Computational",
      "citeRegEx" : "Galgani et al\\.,? 2012",
      "shortCiteRegEx" : "Galgani et al\\.",
      "year" : 2012
    }, {
      "title" : "Information extraction from case law and retrieval of prior cases",
      "author" : [ "Peter Jackson", "Khalid Al-Kofahi", "Alex Tyrrell", "Arun Vachher." ],
      "venue" : "Artificial Intelligence, 150(1):239–290. AI and Law.",
      "citeRegEx" : "Jackson et al\\.,? 2003",
      "shortCiteRegEx" : "Jackson et al\\.",
      "year" : 2003
    }, {
      "title" : "IndicNLPSuite: Monolingual corpora, evaluation benchmarks and pre-trained multilingual language models for Indian",
      "author" : [ "Divyanshu Kakwani", "Anoop Kunchukuttan", "Satish Golla", "Gokul N.C", "Avik Bhattacharyya", "Mitesh M. Khapra", "Pratyush Kumar" ],
      "venue" : null,
      "citeRegEx" : "Kakwani et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Kakwani et al\\.",
      "year" : 2020
    }, {
      "title" : "Overview of coliee 2017",
      "author" : [ "Yoshinobu Kano", "Mi-Young Kim", "Randy Goebel", "Ken Satoh." ],
      "venue" : "COLIEE@ICAIL.",
      "citeRegEx" : "Kano et al\\.,? 2017",
      "shortCiteRegEx" : "Kano et al\\.",
      "year" : 2017
    }, {
      "title" : "COLIEE-2018: Evaluation of the Competition on Legal Information Extraction and Entailment",
      "author" : [ "Yoshinobu Kano", "Mi-Young Kim", "Masaharu Yoshioka", "Yao Lu", "Juliano Rabelo", "Naoki Kiyota", "Randy Goebel", "Ken Satoh." ],
      "venue" : "Kazuhiro Kojima, Maki",
      "citeRegEx" : "Kano et al\\.,? 2019",
      "shortCiteRegEx" : "Kano et al\\.",
      "year" : 2019
    }, {
      "title" : "Backlog of cases crippling judiciary",
      "author" : [ "Justice Markandey Katju." ],
      "venue" : "https://tinyurl.com/ v4xu6mvk.",
      "citeRegEx" : "Katju.,? 2019",
      "shortCiteRegEx" : "Katju.",
      "year" : 2019
    }, {
      "title" : "Two-step cascaded textual entailment for legal bar exam question answering",
      "author" : [ "Mi-Young Kim", "Randy Goebel." ],
      "venue" : "Proceedings of the 16th edition of the International Conference on Articial Intelligence and Law, pages 283–290, London United Kingdom.",
      "citeRegEx" : "Kim and Goebel.,? 2017",
      "shortCiteRegEx" : "Kim and Goebel.",
      "year" : 2017
    }, {
      "title" : "Human Decisions and Machine Predictions",
      "author" : [ "Jon Kleinberg", "Himabindu Lakkaraju", "Jure Leskovec", "Jens Ludwig", "Sendhil Mullainathan." ],
      "venue" : "The Quarterly Journal of Economics.",
      "citeRegEx" : "Kleinberg et al\\.,? 2017",
      "shortCiteRegEx" : "Kleinberg et al\\.",
      "year" : 2017
    }, {
      "title" : "Distributed representations of sentences and documents",
      "author" : [ "Quoc Le", "Tomas Mikolov." ],
      "venue" : "Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32, ICML’14, page II–1188–II–1196. JMLR.org.",
      "citeRegEx" : "Le and Mikolov.,? 2014",
      "shortCiteRegEx" : "Le and Mikolov.",
      "year" : 2014
    }, {
      "title" : "LeNER-Br: a dataset for named entity recognition in Brazilian legal text",
      "author" : [ "Pedro H. Luz de Araujo", "Teófilo E. de Campos", "Renato R.R. de Oliveira", "Matheus Stauffer", "Samuel Couto", "Paulo Bermejo." ],
      "venue" : "International Conference on the Computational Pro-",
      "citeRegEx" : "Araujo et al\\.,? 2018",
      "shortCiteRegEx" : "Araujo et al\\.",
      "year" : 2018
    }, {
      "title" : "ILDC for CJPE: Indian legal documents corpus for court judgment prediction and explanation",
      "author" : [ "Vijit Malik", "Rishabh Sanjay", "Shubham Kumar Nigam", "Kripabandhu Ghosh", "Shouvik Kumar Guha", "Arnab Bhattacharya", "Ashutosh Modi." ],
      "venue" : "Proceed-",
      "citeRegEx" : "Malik et al\\.,? 2021",
      "shortCiteRegEx" : "Malik et al\\.",
      "year" : 2021
    }, {
      "title" : "Textrank: Bringing order into text",
      "author" : [ "Rada Mihalcea", "Paul Tarau." ],
      "venue" : "Proceedings of the 2004 conference on empirical methods in natural language processing, pages 404–411.",
      "citeRegEx" : "Mihalcea and Tarau.,? 2004",
      "shortCiteRegEx" : "Mihalcea and Tarau.",
      "year" : 2004
    }, {
      "title" : "National judicial data grid statistics",
      "author" : [ "National Judicial Data Grid." ],
      "venue" : "https://www.njdg. ecourts.gov.in/njdgnew/index.php.",
      "citeRegEx" : "Grid.,? 2021",
      "shortCiteRegEx" : "Grid.",
      "year" : 2021
    }, {
      "title" : "Population of uttar pradesh",
      "author" : [ "PopulationU." ],
      "venue" : "https://www.populationu.com/in/ uttar-pradesh-population.",
      "citeRegEx" : "PopulationU.,? 2021",
      "shortCiteRegEx" : "PopulationU.",
      "year" : 2021
    }, {
      "title" : "Using tf-idf to determine word relevance in document queries",
      "author" : [ "Juan Enrique Ramos" ],
      "venue" : null,
      "citeRegEx" : "Ramos.,? \\Q2003\\E",
      "shortCiteRegEx" : "Ramos.",
      "year" : 2003
    }, {
      "title" : "Making monolingual sentence embeddings multilingual using knowledge distillation",
      "author" : [ "Nils Reimers", "Iryna Gurevych." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4512–4525,",
      "citeRegEx" : "Reimers and Gurevych.,? 2020",
      "shortCiteRegEx" : "Reimers and Gurevych.",
      "year" : 2020
    }, {
      "title" : "BERTPLI: Modeling Paragraph-Level Interactions for Legal Case Retrieval",
      "author" : [ "Yunqiu Shao", "Jiaxin Mao", "Yiqun Liu", "Weizhi Ma", "Ken Satoh", "Min Zhang", "Shaoping Ma." ],
      "venue" : "Proceedings of the TwentyNinth International Joint Conference on Artificial",
      "citeRegEx" : "Shao et al\\.,? 2020",
      "shortCiteRegEx" : "Shao et al\\.",
      "year" : 2020
    }, {
      "title" : "Legal Judgement Prediction for UK Courts",
      "author" : [ "Benjamin Strickson", "Beatriz De La Iglesia." ],
      "venue" : "Proceedings of the 2020 The 3rd International Conference on Information Science and System, pages 204– 209, Cambridge United Kingdom. ACM.",
      "citeRegEx" : "Strickson and Iglesia.,? 2020",
      "shortCiteRegEx" : "Strickson and Iglesia.",
      "year" : 2020
    }, {
      "title" : "Building legal case retrieval systems with lexical matching and summarization using a pre-trained phrase scoring model",
      "author" : [ "Vu Tran", "Minh Le Nguyen", "Ken Satoh." ],
      "venue" : "Proceedings of the Seventeenth International Conference on Artificial Intel-",
      "citeRegEx" : "Tran et al\\.,? 2019",
      "shortCiteRegEx" : "Tran et al\\.",
      "year" : 2019
    }, {
      "title" : "Devanagari — Wikipedia, the free encyclopedia",
      "author" : [ "Wikipedia contributors." ],
      "venue" : "[Online; accessed 10-November-2021].",
      "citeRegEx" : "contributors.,? 2021",
      "shortCiteRegEx" : "contributors.",
      "year" : 2021
    }, {
      "title" : "World data info: Hindi",
      "author" : [ "WorldData." ],
      "venue" : "https://www.worlddata.info/ languages/hindi.php.",
      "citeRegEx" : "WorldData.,? 2021",
      "shortCiteRegEx" : "WorldData.",
      "year" : 2021
    }, {
      "title" : "Cail2018: A large-scale legal dataset for judgment prediction. arXiv preprint arXiv:1807.02478",
      "author" : [ "Chaojun Xiao", "Haoxi Zhong", "Zhipeng Guo", "Cunchao Tu", "Zhiyuan Liu", "Maosong Sun", "Yansong Feng", "Xianpei Han", "Zhen Hu", "Heng Wang" ],
      "venue" : null,
      "citeRegEx" : "Xiao et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Xiao et al\\.",
      "year" : 2018
    }, {
      "title" : "Cail2019-scm: A dataset of similar case matching in legal domain",
      "author" : [ "Chaojun Xiao", "Haoxi Zhong", "Zhipeng Guo", "Cunchao Tu", "Zhiyuan Liu", "Maosong Sun", "Tianyang Zhang", "Xianpei Han", "Zhen Hu", "Heng Wang", "Jianfeng Xu." ],
      "venue" : "ArXiv, abs/1911.08962.",
      "citeRegEx" : "Xiao et al\\.,? 2019",
      "shortCiteRegEx" : "Xiao et al\\.",
      "year" : 2019
    }, {
      "title" : "How does NLP benefit legal system: A summary of legal artificial intelligence",
      "author" : [ "Haoxi Zhong", "Chaojun Xiao", "Cunchao Tu", "Tianyang Zhang", "Zhiyuan Liu", "Maosong Sun." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Compu-",
      "citeRegEx" : "Zhong et al\\.,? 2020a",
      "shortCiteRegEx" : "Zhong et al\\.",
      "year" : 2020
    }, {
      "title" : "Jecqa: A legal-domain question answering dataset",
      "author" : [ "Haoxi Zhong", "Chaojun Xiao", "Cunchao Tu", "Tianyang Zhang", "Zhiyuan Liu", "Maosong Sun." ],
      "venue" : "Proceedings of AAAI. 10",
      "citeRegEx" : "Zhong et al\\.,? 2020b",
      "shortCiteRegEx" : "Zhong et al\\.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 11,
      "context" : ", India) has been inundated with a large number of legal documents and pending cases (Katju, 2019).",
      "startOffset" : 85,
      "endOffset" : 98
    }, {
      "referenceID" : 16,
      "context" : "For example, legal documents are typically quite long (tens of pages), legal documents are highly unstructured and noisy (spelling and grammar mistakes, since these are typed), language in legal documents are domain-specific, and pre-trained language models do not perform well on these (Malik et al., 2021).",
      "startOffset" : 287,
      "endOffset" : 307
    }, {
      "referenceID" : 16,
      "context" : "However, most of the legal NLP systems that currently exist in India have been developed on English, and these do not work on Hindi legal documents (Malik et al., 2021).",
      "startOffset" : 148,
      "endOffset" : 168
    }, {
      "referenceID" : 19,
      "context" : "), the most populous state of India with a population of approximately 237 million (PopulationU, 2021).",
      "startOffset" : 83,
      "endOffset" : 102
    }, {
      "referenceID" : 29,
      "context" : "In recent years there has been active interest in the application of NLP techniques to the legal domain (Zhong et al., 2020a).",
      "startOffset" : 104,
      "endOffset" : 125
    }, {
      "referenceID" : 2,
      "context" : "A number of tasks and models have been proposed, inter alia, Legal Judgment Prediction (Chalkidis et al., 2019), Legal Summarization (Bhattacharya et al.",
      "startOffset" : 87,
      "endOffset" : 111
    }, {
      "referenceID" : 1,
      "context" : ", 2019), Legal Summarization (Bhattacharya et al., 2019; Tran et al., 2019), Prior Case Retrieval (Jackson et al.",
      "startOffset" : 29,
      "endOffset" : 75
    }, {
      "referenceID" : 24,
      "context" : ", 2019), Legal Summarization (Bhattacharya et al., 2019; Tran et al., 2019), Prior Case Retrieval (Jackson et al.",
      "startOffset" : 29,
      "endOffset" : 75
    }, {
      "referenceID" : 7,
      "context" : ", 2019), Prior Case Retrieval (Jackson et al., 2003; Shao et al., 2020), Legal Question Answering (Kim and Goebel, 2017), Catchphrase Extraction (Galgani et al.",
      "startOffset" : 30,
      "endOffset" : 71
    }, {
      "referenceID" : 22,
      "context" : ", 2019), Prior Case Retrieval (Jackson et al., 2003; Shao et al., 2020), Legal Question Answering (Kim and Goebel, 2017), Catchphrase Extraction (Galgani et al.",
      "startOffset" : 30,
      "endOffset" : 71
    }, {
      "referenceID" : 12,
      "context" : ", 2020), Legal Question Answering (Kim and Goebel, 2017), Catchphrase Extraction (Galgani et al.",
      "startOffset" : 34,
      "endOffset" : 56
    }, {
      "referenceID" : 6,
      "context" : ", 2020), Legal Question Answering (Kim and Goebel, 2017), Catchphrase Extraction (Galgani et al., 2012).",
      "startOffset" : 81,
      "endOffset" : 103
    }, {
      "referenceID" : 16,
      "context" : "Majority of the work in the legal domain has focused on the higher court (Malik et al., 2021; Strickson and De La Iglesia, 2020; Zhong et al., 2020b); however, the lower courts handle the maximum number of cases.",
      "startOffset" : 73,
      "endOffset" : 149
    }, {
      "referenceID" : 30,
      "context" : "Majority of the work in the legal domain has focused on the higher court (Malik et al., 2021; Strickson and De La Iglesia, 2020; Zhong et al., 2020b); however, the lower courts handle the maximum number of cases.",
      "startOffset" : 73,
      "endOffset" : 149
    }, {
      "referenceID" : 5,
      "context" : "Multiple datasets in Chinese have been released for different tasks, namely Reading Comprehension (Duan et al., 2019), Similar Case Matching (Xiao et al.",
      "startOffset" : 98,
      "endOffset" : 117
    }, {
      "referenceID" : 28,
      "context" : ", 2019), Similar Case Matching (Xiao et al., 2019), Question Answering (Zhong et al.",
      "startOffset" : 31,
      "endOffset" : 50
    }, {
      "referenceID" : 16,
      "context" : "As observed in previous work (Malik et al., 2021), anonymization of a judge’s name is important as there is a corre-",
      "startOffset" : 29,
      "endOffset" : 49
    }, {
      "referenceID" : 16,
      "context" : "Moreover, the Bail corpus and corresponding bail prediction systems can promote the development of explainable systems (Malik et al., 2021), we leave research on such explainable systems for future work.",
      "startOffset" : 119,
      "endOffset" : 139
    }, {
      "referenceID" : 14,
      "context" : "We experimented with classical embedding based model Doc2Vec (Le and Mikolov, 2014) and transformer-based contextualized embeddings model IndicBERT (Kakwani et al.",
      "startOffset" : 61,
      "endOffset" : 83
    }, {
      "referenceID" : 8,
      "context" : "We experimented with classical embedding based model Doc2Vec (Le and Mikolov, 2014) and transformer-based contextualized embeddings model IndicBERT (Kakwani et al., 2020).",
      "startOffset" : 148,
      "endOffset" : 170
    }, {
      "referenceID" : 20,
      "context" : "For unsupervised approaches we experimented with TF-IDF (Ramos, 2003) and TextRank (a graph based method for extracting most important sentences) (Mihalcea and Tarau, 2004).",
      "startOffset" : 56,
      "endOffset" : 69
    }, {
      "referenceID" : 17,
      "context" : "For unsupervised approaches we experimented with TF-IDF (Ramos, 2003) and TextRank (a graph based method for extracting most important sentences) (Mihalcea and Tarau, 2004).",
      "startOffset" : 146,
      "endOffset" : 172
    }, {
      "referenceID" : 21,
      "context" : "Here hji is contextualized distributed representation for ji obtained using multilingual sentence encoder (Reimers and Gurevych, 2020).",
      "startOffset" : 106,
      "endOffset" : 134
    }, {
      "referenceID" : 21,
      "context" : "A multilingual sentence encoder (Reimers and Gurevych, 2020) is used to get contextualized representation of each sentence: {h(1)i , h(2)i , · · · , hi }.",
      "startOffset" : 32,
      "endOffset" : 60
    }, {
      "referenceID" : 4,
      "context" : "In addition, we append the sentence representations with a special randomly initialized CLS embedding (Devlin et al., 2019) that gets updated during model training.",
      "startOffset" : 102,
      "endOffset" : 123
    } ],
    "year" : 0,
    "abstractText" : "Populous countries (e.g., India) are burdened with a considerable backlog of legal cases. This calls for the development of automated systems that could process legal documents and augment legal practitioners. To develop such data-driven systems, there is a dearth of high-quality corpora. The problem gets even more pronounced in the case of low resource language (e.g., Hindi). In this resource paper, we introduce the Hindi Legal Documents Corpus (HLDC), a corpus of 900K legal documents in Hindi. The documents are cleaned and structured to enable the development of downstream applications. Further, as a usecase for the corpus, we introduce the task of Bail Prediction. We experiment with a battery of models and propose a multi-task learning (MTL) based model. MTL models use summarization as an auxiliary task along with bail prediction as the main task. Results on different models are indicative of the need for further research in this area.",
    "creator" : null
  }
}