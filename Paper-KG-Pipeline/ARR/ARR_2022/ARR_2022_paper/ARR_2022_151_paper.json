{
  "name" : "ARR_2022_151_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Zero-Shot Dense Retrieval with Momentum Adversarial Domain Invariant Representations",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Rather than matching texts in the bag-of-words space, Dense Retrieval (DR) methods first encode texts into a dense embedding space (Lee et al., 2019a; Karpukhin et al., 2020; Xiong et al., 2021) and then conduct text retrieval using efficient nearest neighbor search (Chen et al., 2018; Guo et al., 2020; Johnson et al., 2021). With pre-trained language models and dedicated fine-tuning techniques, the learned representation space has significantly advanced the first stage retrieval accuracy of many language systems, including web search (Xiong et al., 2021), grounded generation (Lewis et al., 2020), open domain question answering (Karpukhin et al., 2020; Izacard and Grave, 2020), etc.\nPurely using the learned embedding space for retrieval has raised concerns on the generalization ability, especially in scenarios without the luxury of dedicated supervision signals. Many have observed diminishing advantages of DR models in various datasets if they are not fine-tuned with task-specific labels, i.e., in the zero-shot setup (Thakur et al., 2021). However, in many scenarios outside commercial web search, zero-shot is the norm, since obtaining training labels is difficult and sometimes infeasible when strong expertise is necessary or privacy constraints exist.\nEven within the search system, the generalization ability of first stage DR models is notably worse than subsequent reranking models (Thakur et al., 2021). Reranking models, similar to many classification models, only require a decision boundary between relevant and irrelevant query–document pairs (q–d pairs) in the representation space. In comparison, DR needs good local alignments in the entire space to support nearest neighbor matching, which is much harder for representation learning. We illustrate this challenge in Figure 1 using t-SNE. We show learned representations from a BERTbased reranker (Nogueira and Cho, 2019) and a BERT-based dense retriever (Xiong et al., 2021), in zero-shot transfer from the web domain (Bajaj\net al., 2016) to medical (Voorhees et al., 2021). The reranking representation space yields two manifolds with a clear decision boundary: data points in the target domain naturally cluster with their corresponding classes from the source domain, leading to good generalization. In comparison, the DR representation space is more scattered: target domain data points are grouped separately from source domain points and it is nearly impossible for the learned nearest neighbor locality to generalize to the isolated target domain region. In this paper, we present Momentum Adversarial Domain Invariant Representations learning (MoDIR), to improve the generalization ability of zero-shot dense retrieval (ZeroDR). We first introduce an auxiliary domain classifier that is trained to discriminate source embeddings from target ones. Then the DR encoder is not only updated to encode queries and relevant documents together in the source domain, but also trained adversarially to confuse the domain classifier and to push for a more domain invariant embedding space. To ensure stable and efficient adversarial learning, we propose amomentummethod that trains the domain classifier with a momentum queue of embeddings saved from previous iterations.\nOur experiments evaluate the generalization ability of dense retrieval with MoDIR using 15 retrieval tasks from the BEIR benchmark (Thakur et al., 2021). On these retrieval tasks from various domains including biomedical, finance, scientific, etc., MoDIR improves the zero-shot accuracy of DPR (Karpukhin et al., 2020) and its state-of-theart (SOTA) variant ANCE (Xiong et al., 2021). On tasks where evaluation labels have sufficient coverage for DR (Thakur et al., 2021), MoDIR’s improvements are robust and significant, even without using any target domain training labels. We also verify the necessity of the proposed momentum approach, without which the domain classifier fails to capture the domain gaps, and the adversarial training does not learn domain invariant representations, resulting in little improvement in ZeroDR. We view MoDIR as an initial step of ZeroDR, and we conduct further analyses to reveal interesting properties of MoDIR and its learned embedding space. During the adversarial training process, the target domain embeddings are gradually pushed towards the source domain and eventually absorbed as a subgroup of the source. In the learned representation space, our manual examinations find various\ncases where a target domain query is located close to source queries with similar information needs. This indicates that ZeroDR’s generalization ability comes from the combination of information overlaps of source/target domains, and MoDIR’s ability to identify the right correspondence between them."
    }, {
      "heading" : "2 Related Work",
      "text" : "In this section, we recap related work in dense retrieval and adversarial domain adaptation. Dense Retrieval Different from sparse first stage retrieval models, dense retrieval with Transformerbased models (Vaswani et al., 2017) such as BERT (Devlin et al., 2019) conducts retrieval in the dense embedding space (Lee et al., 2019b; Chang et al., 2020; Guu et al., 2020; Karpukhin et al., 2020; Luan et al., 2021). Compared with its sparse counterparts, DR improves retrieval efficiency and also provides comparable or even superior effectiveness for in-domain datasets. Recently, challenges of ZeroDR have attracted much attention (Thakur et al., 2021; Zhang et al., 2021; Li and Lin, 2021). One way to improve ZeroDR is synthetic query generation (Liang et al., 2020;Ma et al., 2021), which first trains a doc2query model in the source domain and then applies the NLG model on target domain documents to generate queries. The target domain documents and generated queries form weak supervision labels for DR model training. Our method differs from them and focuses on directly improving the generalization ability of the learned representation space. AdversarialDomainAdaptation Unsupervised domain adaptation (UDA) has been studied extensively for computer vision applications. For example, maximummean discrepancy (Long et al., 2013; Tzeng et al., 2014; Sun and Saenko, 2016) measures domain difference with a pre-defined metric and explicitly minimizes the difference; adversarial domain adaptation tries to adversarially trained the main model to confuse the domain classifier (Ganin and Lempitsky, 2015; Bousmalis et al., 2016; Tzeng et al., 2017; Luo et al., 2017). MoDIR builds upon the success of these UDA methods and introduces a newmomentum learning technique that is necessary to address the unique challenges in ZeroDR."
    }, {
      "heading" : "3 Training Domain Invariant Representations for Dense Retrieval",
      "text" : "In this work, we aim to improve generalization in ZeroDR: the goal is to transfer the DRmodel from a\nsource domain to a target domain, with access to its queries and documents, but not any relevance label. This is the common case when applying DR in real-world scenarios: in target domains (e.g., medical), example queries and documents are available but relevance annotations require domain expertise, while in the source domain (e.g., web search), training signals are available at large scale (Ma et al., 2020; Thakur et al., 2021). MoDIR improves ZeroDR by encouraging DR models to learn a domain invariant representation space. In this section, we describe (1) how to train a vanilla dense retrieval model, (2) how to train a momentum domain classifier to distinguish the two domains, and (3) how to adversarially train the DR model for domain invariant representations."
    }, {
      "heading" : "3.1 Training the Dense Retrieval Model",
      "text" : "The standard design of DR is to use a dual-encoder model (Lee et al., 2019a; Karpukhin et al., 2020), where an encoder g takes as input a query/document and encodes it into a dense vector. The relevance score of a q–d pair x = (q, d) is computed using a simple similarity function:\nr(x) = sim(g(q; θg), g(d; θg)), (1)\nwhere θg is the collection of parameters of g and sim is a vector similarity function.\nThe training of DR uses labeled q-d pairs in the source domain xs = (qs, ds). With relevant q–d pair as xs+ and irrelevant pair as xs−, the encoder g is trained to minimize the ranking loss LR:\nmin θg ∑ xs+,xs− LR(r(x s+), r(xs−)), (2)\nwhere LR is a ranking loss function. Our model follows its baselineDPR/ANCE to sample irrelevant documents using BM25 or global hard negatives. Without loss of generality, other modeling designs\nare kept the same with ANCE: g is fine-tuned from RoBERTaBASE (Liu et al., 2019) and outputs the embedding of the last layer’s [CLS] token, LR is the Negative Log Likelihood (NLL) loss, and sim is the dot product."
    }, {
      "heading" : "3.2 Estimating the Domain Boundary with Momentum Domain Classifier",
      "text" : "To capture domain differences and enable adversarial learning for domain invariance, MoDIR introduces a domain classifier f to predict the probability of a query/document embedding e being source or target, and we use a linear classifier as f :\nf(e) = softmax(Wfe). (3)\nThe linear classifier has sufficient capacity to distinguish the two domains in the high-dimensional representation space—the main challenge is on training. As illustrated in Figure 1, DR’s representation space focuses more on locality than forming manifolds, and therefore it is more difficult to learn the domain boundary in this case. If we simply update f using the same amount of data points as g, f fails to accurately estimate the domain boundary; on the other hand, if we naïvely feed in more data points for f , all these data points need to be encoded by the expensive encoder g, making the training process infeasibly slow (we will empirically validate these arguments in Sections 4.3 to 4.4). To achieve the balance between accuracy and efficiency, we introduce the momentum method for the domain classifier, as shown in Figure 2. We maintain a momentum queue Q that records embeddings from multiple previous batches as the additional training data for f . Specifically, at each step, in addition to source domain training data xs, we sample q–d pairs xt from the target domain, and add embeddings of xs and xt toQ. The momentum queueQ at step k includes embeddings from source\nand target for all recent n batches:\nQk = {eq, ed|(q, d) ∈ Bk−n+1:k}, (4)\nwhereBk−n+1:k are the data points from the past n batches, including both source and target ones, and n is themomentum step. For simplicity of sampling, we use the 1:1 ratio between source/target data and also between positive/negative source data. To ensure efficiency of the momentum method, all embeddings e from Q are detached from the encoder g. Take the query qs as an example,\neqs = Φ(g(q s; θg)), (5)\nwhereΦ is the stop-gradient operator, i.e., gradients of eqs are not back propagated to θg. Since the linear classifier f is significantly smaller and faster than the transformer-based encoder g, this enables efficient training for f . At each iteration, f is updated by repetitively minimizing the following discrimination loss LD, computed with all embeddings from Q:\nmin Wf\nLD(e; f), e ∈ Q, (6)\nLD(e; f) = { − log f(e), e from source, − log(1− f(e)), e from target,\n(7)\nwhere LD is a standard classification loss. In this way, at each iteration, the domain classifier f is trained with more signals than the encoder g (the entire Q versus only one batch), ensuring accurate estimation of the domain boundary; also since Q contains detached embeddings, the training process remains efficient."
    }, {
      "heading" : "3.3 Adversarial Learning for Domain Invariant Representations",
      "text" : "With an estimated domain boundary by f , MoDIR adversarially trains the encoder g to generate domain invariant representations that f cannot distinguish, by minimizing an adversarial loss LM . Here we choose the widely used Confusion loss (Tzeng et al., 2017):\nLM (x; g, f) = − 1\n2\n( log f(g(q)) + log f(g(d))\n+ log(1− f(g(q))) + log(1− f(g(d))) ) ,\n(8)\nwhere x ∈ {xs, xt} is a q-d pair from either source or target domain. It reaches the minimum when\nthe embeddings are domain invariant and the domain classifier predict 50%-50% probability for all data. To push for domain invariance, we freeze the domain classifier and update the encoder:\nmin θg\nλ ∑\nx∈{xs,xt}\nLM (x; g, f). (9)\nWe use the hyperparameterλ to balance the learning of DR ranking in the source domain and the learning of domain invariance (Equation (2) and (9)). To summarize, for each training batch in the source domain, the domain classifier f and the encoder g are optimized by:\nmin Wf\nLD(e; f), e ∈ Q, (10)\nmin θg ∑ xs+,xs− LR(r(x s+), r(xs−))\n+ λ ∑\nx∈{xs,xt}\nLM (x; g, f), (11)\nwhere f is trained to estimate the boundary between source/target and g is trained to provide domain invariant representations while capturing relevance matching in the source domain."
    }, {
      "heading" : "4 Experiments",
      "text" : "This section describes experimental setups and evaluates the effectiveness of MoDIR. Furthermore, we dive deep into the importance of momentum training and properties of domain invariant embedding space, which provides new insights for ZeroDR."
    }, {
      "heading" : "4.1 Datasets",
      "text" : "We choose the MS MARCO passage dataset (Bajaj et al., 2016) as the source domain dataset and choose the 15 publicly available datasets from the BEIR benchmark (Thakur et al., 2021) as target domain datasets (details in Appendix A). We treat each target domain dataset separately and produce an individual model for each of them, following the ZeroDR setting described in Section 3."
    }, {
      "heading" : "4.2 Effectiveness of MoDIR",
      "text" : "We build MoDIR on top of DPR and ANCE, but it can also be applied to other DR frameworks similarly. Table 1 shows the Hole rates and nDCG scores on the BEIR benchmark; we omit the Hole rates of MoDIR since they are very similar to its baseline DPR/ANCE’s.\nWe first discuss Hole rates and baseline selection, and then discuss model effectiveness.\nHole Rates and DR Evaluation A hole is an unlabeled q–d pair retrieved by a model, and the percentage of holes among all retrieved q–d pairs is the Hole rate. Datasets with high Hole rates for dense models are less sensitive to dense models’ effectiveness (Xiong et al., 2021), and we therefore consider datasets with low Hole rates more important, since they provide more accurate measurements for ZeroDR. On the other hand, many of BEIR’s datasets are annotated with candidates generated by some sparse retrieval models at the time of dataset construction, therefore the evaluation of these datasets is biased towards sparse models. Take TREC-COVID as an example, ANCE underperforms BM25 under the original annotation, but it achieves SOTA after adding extra labels based on ANCE’s prediction (Thakur et al., 2021).\nBaselines Our baselines include BM25 (Robertson and Jones, 1976), DPR (Karpukhin et al., 2020), and ANCE (Xiong et al., 2021). The original DPR is trained on NQ (Kwiatkowski et al., 2019), but we instead train DPR onMARCO, which not only eliminates training dataset differences but also provides better overall results. BEIR also reports results of other methods, such as docT5query (Nogueira et al., 2020), TAS-B (Hofstätter et al., 2021), GenQ (Ma et al., 2021), ColBERT (Khattab and Zaharia, 2020), etc. However, they are not directly comparable with MoDIR since they involve stronger supervision signals from rerankers (TAS-B), data augmentation from expensive sequence-to-sequence models (docT5query and GenQ), and high-latency late interaction (ColBERT). MoDIR instead directly improves the generalization ability of the represen-\ntation space, and are orthogonal to these methods and can be combined for better performance. Effectiveness Comparison FromTable 1we can see that MoDIR improves DPR and ANCE’s overall effectiveness in the ZeroDR setting. On datasets with low Hole rates, which provide more accurate evaluation, the gains are significant; on datasets with high Hole rates, the gains are smaller but still stable. Moreover, to present a fair comparison in the realistic ZeroDR setting, results of MoDIR are obtainedwithout hyperparameter tuning or checkpoint selection: in the ZeroDR setting, there is no access to relevance labels in the target domain during training/validation. Therefore, for all target domain datasets, we keep most of the experimental settings the same with ANCE and evaluate checkpoints after the same number of training steps (details in Appendix B). This evaluation setup is the closest to ZeroDR in the real world, but it may not show the best empirical results for MoDIR. For example, the nDCG@10 score of ANCE+MoDIR on TRECCOVID can be as high as a SOTA 0.724(+10.7%) if we train the model for more steps (see Section 4.5)."
    }, {
      "heading" : "4.3 Effectiveness of Momentum Training: Ablation Studies",
      "text" : "Our ablation studies evaluate the importance of the momentum method and the effects of other experimental setups. We compare different training setups against vanilla ANCE, using TREC-COVID and Touché which have the best label coverage (lowest Hole rates), and show the results in Table 2.\nFirstly, we evaluate the effectiveness of not using the momentum queue: each iteration, the domain\nclassifier is trained either with a single batch n = 1, or repeat the current batch for n = 1k times. We can see that using a single batch fails to improve over ANCE, indicating the necessity of using more data to train the domain classifier; repeating the current batch also provides smaller improvements than using different batches from the queue. Secondly, we use a smaller momentum step n = 100 for momentum training, which also yields little improvement. This shows that n has to be sufficiently large for the momentum method to work, proving the necessity of our efficiency method to detach embeddings before storing them into the queue. Thirdly, we train MoDIR with two other choices of LM from Equation (9): Minimax and GAN. GAN loss is less stable as described by Tzeng et al. (2017), while Minimax performs comparatively to Confusion. This shows that MoDIR can also be applied with other domain adaptation training methods."
    }, {
      "heading" : "4.4 Convergence of Adversarial Training with Momentum",
      "text" : "In this subsection, we show how the momentum method helps adversarial training converge to a domain invariant embedding space. To quantify domain invariance, we use Domain Classification Accuracy (Domain-Acc), which includes two measurements based on the choice of domain classifier: (1) Directly take the domain classifier used in MoDIR’s training (f in Section 3.2) and record its accuracy when applied to a new batch, which leads to Local Domain-Acc. (2) Randomly initialize a new domain classifier and train it globally on source and target embeddings, which leads to Global Domain-Acc. Global Domain-Acc measures the real degree of domain invariance: it is lower when embeddings of the two domains are not easily separable. Local Domain-Acc is an approximation provided by the domain classifier f , and if there is a large gap between Local and Global\nDomain-Acc, it means that the domain boundary estimated by f is inaccurate. In Figure 3, we compare Global and Local Domain-Acc on the TREC-COVID dataset when training ANCE with/without momentum (without momentum is the single setting described in Section 4.3). With momentum, Local Domain-Acc quickly increases to be comparable with Global Domain-Acc. The domain classifier f (used in MoDIR’s training) converges quickly and Global Domain-Acc starts to decrease, showing that embeddings from the two domains become less separable. Note that Local Domain-Acc does not decrease because f has seen and memorized almost all data, while Global Domain-Acc’s domain classifier is always tested on unseen data for accurate results. This shows that momentum helps with the balance of adversarial training, ensuring its convergence towards a domain invariant representation space.\nOn the other hand, when momentum is not used, there exists a long-lasting gap between Local and Global Domain-Acc, showing that f does not capture the domain boundary well. As a result, the two domains remain (almost) linearly separable in the embedding space, as shown by the fact that Global Domain-Acc does not decrease, and the model fails to produce domain invariant representations."
    }, {
      "heading" : "4.5 Impact of Domain Invariance",
      "text" : "In this subsection, we study the behavior and benefits of ANCE+MoDIR in learning domain invari-\nance. We focus on TREC-COVID as it provides the most robust evaluation for ZeroDR. Learning Domain Invariance with Momentum We show how the momentum method gradually pushes for a domain invariant representation space. To measure how much the two domains are mixed together, we use K-Nearest Neighbor Source Percentage (KNN-Source%): We index source and target documents together; given a target domain query in the embedding space, we retrieve its top100 nearest documents from the index, and calculate the percentage of source documents from the nearest neighbors; the average percentage for all target domain queries is reported. A higher KNN-Source% means that the target domain embeddings are surrounded by more source domain ones, indicating a more domain invariant representation space. The results are in Table 3. With momentum, both KNN-Source% and nDCG gradually increase as training proceeds. This shows that when target domain embeddings are pushed towards the source domain, the ranking performance of the target do-\nmain also improves. On TREC-COVID, MoDIR eventually reaches 0.724, which is the SOTA for first stage retrievers. On the other hand, without momentum (the single setting in Section 4.3), KNNSource% and nDCG scores hardly increase. We also use t-SNE (van der Maaten and Hinton, 2008) to visualize the learned representation space at different training steps in Figure 4. Before training with MoDIR, the two domains are well separated in the representation space learned by ANCE. With more MoDIR training steps, the target domains are pushed towards the source domain and gradually becomes a subset of it. Without momentum, the two domains remain separated, which is consistent with observations from Table 3. ZeroDR Effectiveness VS Domain Invariance We study the correlation between ZeroDR ranking effectiveness and domain invariance. We use Global Domain-Acc as the indicator of domain invariance and plot it with the corresponding ZeroDR nDCG scores during training in Figure 5.\nGlobal Domain-Acc starts at near 100% and de-\ncreases as training proceeds, showing that source and target embeddings are almost linearly separable at the beginning but are gradually pushed together. ZeroDR accuracy improves as Global Domain-Acc decreases, showing that domain invariance is the source of ZeroDR’s improvements. We also record that the DR accuracy on the source domain (MARCO) decreases by nomore than 0.5%. This indicates that the high dimensional embedding space has sufficient capacity to learn domain invariant representations while maintaining relevance matching in the source domain."
    }, {
      "heading" : "4.6 Case Study",
      "text" : "We show two cases of queries from TREC-COVID and their nearest MARCO queries before and after MoDIR training in Table 4. In the first case, MoDIR pays more attention to “transmission”, and potentially retrieves more documents about the\ntransmission of diseases, thereby improving the nDCG score; documents about “coronavirus” are also likely to be retrieved by MoDIR since it is a very noticeable word. In the second case, it focuses on “mRNA” more than “vaccine”. However, since the mRNA vaccine is relatively new with few appearances in the MARCO dataset, the shift in focus fails to improve MoDIR for this query.\nThese examples help reveal the source of generalization ability on ZeroDR. For the DR models to be able to generalize, the source domain itself needs to include relevance information that resembles the target domain’s needs; if there is no such information, as in the second example, generalization becomes a hard challenge. When the source domain has such coverage, MoDIR is able to align target queries to source ones with similar information needs in its domain invariant representation space, and such alignments enable DR models to generalize."
    }, {
      "heading" : "5 Conclusion and Future Work",
      "text" : "In this paper, we present MoDIR to improve the zero-shot generalization ability of DR models. We first show that DR differs from classification in its emphases on locality in the representation space. Then we present a momentum-based adversarial training method that robustly pushes for a more domain invariant representation space. Our experiments demonstrate that MoDIR’s improvements are robust overall and significant on datasets where ZeroDR’s evaluation is more accurate. We view MoDIR as an initial step of ZeroDR, and we conduct detailed analyses on MoDIR and its learned embedding space, which provide insights to facilitate future research. How to better understand the dynamics of representation learning in ZeroDR and further improve it will be an important future direction impacting both representation learning research and real-world applications."
    }, {
      "heading" : "A Datasets Details",
      "text" : "Target domain datasets used in our experiments are collected in the BEIR benchmark (Thakur et al., 2021) and include the following domains:\n• General-domain (Wikipedia): DBPedia (Hasibi et al., 2017), HotpotQA (Yang et al., 2018), FEVER (Thorne et al., 2018), and NQ (Kwiatkowski et al., 2019).\n• Bio-medical: TREC-COVID (Voorhees et al., 2021), NFCorpus (Boteva et al., 2016), and BioASQ (Tsatsaronis et al., 2015).\n• Finance: FiQA (Maia et al., 2018).\n• Controversial arguments: Touché (Bondarenko et al., 2020) and ArguAna (Wachsmuth et al., 2018).\n• Duplicate questions: Quora (Thakur et al., 2021) and CQADupStack (Hoogeveen et al., 2015).\n• Scientific: SciFact (Wadden et al., 2020), SCIDOCS (Cohan et al., 2020), and ClimateFEVER (Diggelmann et al., 2020)"
    }, {
      "heading" : "B Detailed Experimental Settings",
      "text" : "We follow the design of ANCE for the DR encoder’s modeling and training. We initialize the encoder with the publicly released checkpoints: “ANCEwarmup” for DPR+MoDIR and “ANCE-passage” for ANCE+MoDIR.1 We randomly initialize the domain classifier. Detailed hyperparameter choices are shown in Table 5. We also use an exponential decay routine for the hyperparameter λ to improve training stability, where the value is reduced continuously and shrunk to half every 10k steps.\n1https://github.com/microsoft/ANCE."
    } ],
    "references" : [ {
      "title" : "2016. MS MARCO: A human generated machine reading comprehension",
      "author" : [ "Payal Bajaj", "Daniel Campos", "Nick Craswell", "Li Deng", "Jianfeng Gao", "Xiaodong Liu", "Rangan Majumder", "Andrew McNamara", "Bhaskar Mitra", "Tri Nguyen" ],
      "venue" : null,
      "citeRegEx" : "Bajaj et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Bajaj et al\\.",
      "year" : 2016
    }, {
      "title" : "Overview of Touché 2020",
      "author" : [ "Alexander Bondarenko", "Maik Fröbe", "Meriem Beloucif", "Lukas Gienapp", "Yamen Ajjour", "Alexander Panchenko", "Chris Biemann", "Benno Stein", "Henning Wachsmuth", "Martin Potthast", "Matthias Hagen" ],
      "venue" : null,
      "citeRegEx" : "Bondarenko et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Bondarenko et al\\.",
      "year" : 2020
    }, {
      "title" : "A full-text learning to rank dataset for medical information retrieval",
      "author" : [ "Vera Boteva", "Demian Gholipour", "Artem Sokolov", "Stefan Riezler." ],
      "venue" : "European Conference on Information Retrieval, pages 716–722. Springer.",
      "citeRegEx" : "Boteva et al\\.,? 2016",
      "shortCiteRegEx" : "Boteva et al\\.",
      "year" : 2016
    }, {
      "title" : "Domain separation networks",
      "author" : [ "KonstantinosBousmalis", "GeorgeTrigeorgis", "Nathan Silberman", "Dilip Krishnan", "Dumitru Erhan." ],
      "venue" : "Advances in Neural Information Processing Systems, volume 29. Curran Associates, Inc.",
      "citeRegEx" : "KonstantinosBousmalis et al\\.,? 2016",
      "shortCiteRegEx" : "KonstantinosBousmalis et al\\.",
      "year" : 2016
    }, {
      "title" : "Pre-training tasks for embedding-based large-scale retrieval",
      "author" : [ "Wei-Cheng Chang", "Felix X. Yu", "Yin-Wen Chang", "Yiming Yang", "Sanjiv Kumar." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Chang et al\\.,? 2020",
      "shortCiteRegEx" : "Chang et al\\.",
      "year" : 2020
    }, {
      "title" : "SPTAG: A library for fast approximate nearest neighbor search",
      "author" : [ "Qi Chen", "Haidong Wang", "Mingqin Li", "Gang Ren", "Scarlett Li", "Jeffery Zhu", "Jason Li", "Chuanjie Liu", "Lintao Zhang", "JingdongWang" ],
      "venue" : null,
      "citeRegEx" : "Chen et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2018
    }, {
      "title" : "SPECTER: Document-level representation learning using citation-informed transformers",
      "author" : [ "Arman Cohan", "Sergey Feldman", "Iz Beltagy", "Doug Downey", "Daniel Weld." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Com-",
      "citeRegEx" : "Cohan et al\\.,? 2020",
      "shortCiteRegEx" : "Cohan et al\\.",
      "year" : 2020
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "CLIMATE-FEVER: A dataset for verification of real-world climate claims",
      "author" : [ "Thomas Diggelmann", "Jordan Boyd-Graber", "Jannis Bulian", "Massimiliano Ciaramita", "Markus Leippold." ],
      "venue" : "arXiv preprint arXiv:2012.00614.",
      "citeRegEx" : "Diggelmann et al\\.,? 2020",
      "shortCiteRegEx" : "Diggelmann et al\\.",
      "year" : 2020
    }, {
      "title" : "Unsupervised domain adaptation by backpropagation",
      "author" : [ "Yaroslav Ganin", "Victor Lempitsky." ],
      "venue" : "Proceedings of the 32nd International Conference on Machine Learning, volume 37 of Proceedings of Machine Learning Research, pages 1180–1189,",
      "citeRegEx" : "Ganin and Lempitsky.,? 2015",
      "shortCiteRegEx" : "Ganin and Lempitsky.",
      "year" : 2015
    }, {
      "title" : "Accelerating large-scale inference with anisotropic vector quantization",
      "author" : [ "Ruiqi Guo", "Philip Sun", "Erik Lindgren", "Quan Geng", "David Simcha", "Felix Chern", "Sanjiv Kumar." ],
      "venue" : "Proceedings of the 37th International Conference on Machine Learning, volume",
      "citeRegEx" : "Guo et al\\.,? 2020",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2020
    }, {
      "title" : "Realm: Retrievalaugmented language model pre-training",
      "author" : [ "Kelvin Guu", "Kenton Lee", "Zora Tung", "Panupong Pasupat", "Ming-Wei Chang." ],
      "venue" : "arXiv preprint arXiv:2002.08909.",
      "citeRegEx" : "Guu et al\\.,? 2020",
      "shortCiteRegEx" : "Guu et al\\.",
      "year" : 2020
    }, {
      "title" : "Dbpedia-entity v2: A test collection for entity search",
      "author" : [ "FaeghehHasibi", "FedorNikolaev", "ChenyanXiong", "Krisztian Balog", "Svein Erik Bratsberg", "Alexander Kotov", "Jamie Callan." ],
      "venue" : "Proceedings of the 40th International ACM SIGIR Conference on Re-",
      "citeRegEx" : "FaeghehHasibi et al\\.,? 2017",
      "shortCiteRegEx" : "FaeghehHasibi et al\\.",
      "year" : 2017
    }, {
      "title" : "Efficiently teaching an effective dense retriever with balanced topic aware sampling",
      "author" : [ "Sebastian Hofstätter", "Sheng-Chieh Lin", "Jheng-Hong Yang", "Jimmy Lin", "Allan Hanbury." ],
      "venue" : "Proceedings of the 44th International ACM SIGIR Conference on",
      "citeRegEx" : "Hofstätter et al\\.,? 2021",
      "shortCiteRegEx" : "Hofstätter et al\\.",
      "year" : 2021
    }, {
      "title" : "Cqadupstack: A benchmark data set for community question-answering research",
      "author" : [ "Doris Hoogeveen", "Karin M. Verspoor", "Timothy Baldwin." ],
      "venue" : "Proceedings of the 20th Australasian Document Computing Symposium, ADCS ’15, New York, NY, USA.",
      "citeRegEx" : "Hoogeveen et al\\.,? 2015",
      "shortCiteRegEx" : "Hoogeveen et al\\.",
      "year" : 2015
    }, {
      "title" : "Leveraging passage retrieval with generative models for open domain question answering",
      "author" : [ "Gautier Izacard", "Edouard Grave." ],
      "venue" : "arXiv preprint arXiv:2007.01282.",
      "citeRegEx" : "Izacard and Grave.,? 2020",
      "shortCiteRegEx" : "Izacard and Grave.",
      "year" : 2020
    }, {
      "title" : "Billion-scale similarity search with gpus",
      "author" : [ "Jeff Johnson", "Matthijs Douze", "Hervé Jégou." ],
      "venue" : "IEEE Transactions on Big Data, 7(3):535–547.",
      "citeRegEx" : "Johnson et al\\.,? 2021",
      "shortCiteRegEx" : "Johnson et al\\.",
      "year" : 2021
    }, {
      "title" : "Dense passage retrieval for opendomain question answering",
      "author" : [ "Vladimir Karpukhin", "Barlas Oguz", "Sewon Min", "Patrick Lewis", "Ledell Wu", "Sergey Edunov", "Danqi Chen", "Wen-tauYih." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural",
      "citeRegEx" : "Karpukhin et al\\.,? 2020",
      "shortCiteRegEx" : "Karpukhin et al\\.",
      "year" : 2020
    }, {
      "title" : "Colbert: Efficient and effective passage search via contextualized late interaction over bert",
      "author" : [ "Omar Khattab", "Matei Zaharia." ],
      "venue" : "Proceedings of the 43rd 9",
      "citeRegEx" : "Khattab and Zaharia.,? 2020",
      "shortCiteRegEx" : "Khattab and Zaharia.",
      "year" : 2020
    }, {
      "title" : "Natural questions: A benchmark for question answering research",
      "author" : [ "Jakob Uszkoreit", "Quoc Le", "Slav Petrov." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 7:452–466.",
      "citeRegEx" : "Uszkoreit et al\\.,? 2019",
      "shortCiteRegEx" : "Uszkoreit et al\\.",
      "year" : 2019
    }, {
      "title" : "Latent retrieval for weakly supervised open domain question answering",
      "author" : [ "Kenton Lee", "Ming-Wei Chang", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July",
      "citeRegEx" : "Lee et al\\.,? 2019a",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2019
    }, {
      "title" : "Latent retrieval for weakly supervised open domain question answering",
      "author" : [ "Kenton Lee", "Ming-Wei Chang", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 6086–6096, Florence, Italy.",
      "citeRegEx" : "Lee et al\\.,? 2019b",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2019
    }, {
      "title" : "Retrieval-augmented generation for knowledge-intensive nlp tasks",
      "author" : [ "Patrick Lewis", "Ethan Perez", "Aleksandra Piktus", "Fabio Petroni", "Vladimir Karpukhin", "Naman Goyal", "Heinrich Küttler", "Mike Lewis", "Wen-tau Yih", "Tim Rocktäschel" ],
      "venue" : null,
      "citeRegEx" : "Lewis et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Lewis et al\\.",
      "year" : 2020
    }, {
      "title" : "Encoder adaptation of dense passage retrieval for open-domain question answering",
      "author" : [ "Minghan Li", "Jimmy Lin." ],
      "venue" : "arXiv preprint arXiv:2110.01599.",
      "citeRegEx" : "Li and Lin.,? 2021",
      "shortCiteRegEx" : "Li and Lin.",
      "year" : 2021
    }, {
      "title" : "Embedding-based zero-shot retrieval through query generation",
      "author" : [ "Davis Liang", "Peng Xu", "Siamak Shakeri", "Cicero Nogueira dos Santos", "Ramesh Nallapati", "Zhiheng Huang", "Bing Xiang." ],
      "venue" : "arXiv preprint arXiv:2009.10270.",
      "citeRegEx" : "Liang et al\\.,? 2020",
      "shortCiteRegEx" : "Liang et al\\.",
      "year" : 2020
    }, {
      "title" : "RoBERTa: A robustly optimized bert pretraining approach",
      "author" : [ "Yinhan Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "Mike Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "arXiv preprint arXiv:1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Transfer feature learning with joint distribution adaptation",
      "author" : [ "Mingsheng Long", "Jianmin Wang", "Guiguang Ding", "Jiaguang Sun", "Philip S. Yu." ],
      "venue" : "Proceedings of the IEEE International Conference on Computer Vision (ICCV).",
      "citeRegEx" : "Long et al\\.,? 2013",
      "shortCiteRegEx" : "Long et al\\.",
      "year" : 2013
    }, {
      "title" : "Sparse, dense, and attentional representations for text retrieval",
      "author" : [ "Yi Luan", "Jacob Eisenstein", "Kristina Toutanova", "Michael Collins." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 9:329–345.",
      "citeRegEx" : "Luan et al\\.,? 2021",
      "shortCiteRegEx" : "Luan et al\\.",
      "year" : 2021
    }, {
      "title" : "Label efficient learning of transferable representations acrosss domains and tasks",
      "author" : [ "Zelun Luo", "Yuliang Zou", "Judy Hoffman", "Li F FeiFei." ],
      "venue" : "Advances in Neural Information Processing Systems, volume 30. Curran Associates, Inc.",
      "citeRegEx" : "Luo et al\\.,? 2017",
      "shortCiteRegEx" : "Luo et al\\.",
      "year" : 2017
    }, {
      "title" : "Zero-shot neural retrieval via domain-targeted synthetic query generation",
      "author" : [ "JiMa", "IvanKorotkov", "YinfeiYang", "KeithHall", "andRyan McDonald" ],
      "venue" : "arXiv preprint arXiv:2004.14503",
      "citeRegEx" : "JiMa et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "JiMa et al\\.",
      "year" : 2020
    }, {
      "title" : "Zero-shot neural passage retrieval via domain-targeted synthetic question generation",
      "author" : [ "Ji Ma", "Ivan Korotkov", "Yinfei Yang", "Keith Hall", "Ryan McDonald." ],
      "venue" : "Proceedings of the 16th Conference of the European Chapter of the Association for Computa-",
      "citeRegEx" : "Ma et al\\.,? 2021",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2021
    }, {
      "title" : "Www’18 open challenge: Financial opinionmining and question answering",
      "author" : [ "Macedo Maia", "Siegfried Handschuh", "André Freitas", "Brian Davis", "Ross McDermott", "Manel Zarrouk", "Alexandra Balahur." ],
      "venue" : "Companion Proceedings of the The Web Conference",
      "citeRegEx" : "Maia et al\\.,? 2018",
      "shortCiteRegEx" : "Maia et al\\.",
      "year" : 2018
    }, {
      "title" : "Passage re-ranking with BERT",
      "author" : [ "Rodrigo Nogueira", "Kyunghyun Cho." ],
      "venue" : "arXiv preprint arXiv:1901.04085.",
      "citeRegEx" : "Nogueira and Cho.,? 2019",
      "shortCiteRegEx" : "Nogueira and Cho.",
      "year" : 2019
    }, {
      "title" : "Document ranking with a pretrained sequence-to-sequence model",
      "author" : [ "Rodrigo Nogueira", "Zhiying Jiang", "Ronak Pradeep", "Jimmy Lin." ],
      "venue" : "Findings of the Association for Computational Linguistics: EMNLP 2020, pages 708–718, Online. Association",
      "citeRegEx" : "Nogueira et al\\.,? 2020",
      "shortCiteRegEx" : "Nogueira et al\\.",
      "year" : 2020
    }, {
      "title" : "Relevance weighting of search terms",
      "author" : [ "Stephen E. Robertson", "Karen Spärck Jones." ],
      "venue" : "JASIS, 27(3):129–146.",
      "citeRegEx" : "Robertson and Jones.,? 1976",
      "shortCiteRegEx" : "Robertson and Jones.",
      "year" : 1976
    }, {
      "title" : "Deep coral: Correlation alignment for deep domain adaptation",
      "author" : [ "Baochen Sun", "Kate Saenko." ],
      "venue" : "European conference on computer vision, pages 443– 450. Springer.",
      "citeRegEx" : "Sun and Saenko.,? 2016",
      "shortCiteRegEx" : "Sun and Saenko.",
      "year" : 2016
    }, {
      "title" : "BEIR: A heterogenous benchmark for zero-shot evaluation of information retrieval models",
      "author" : [ "Nandan Thakur", "Nils Reimers", "Andreas Rücklé", "Abhishek Srivastava", "Iryna Gurevych." ],
      "venue" : "arXiv preprint arXiv:2104.08663.",
      "citeRegEx" : "Thakur et al\\.,? 2021",
      "shortCiteRegEx" : "Thakur et al\\.",
      "year" : 2021
    }, {
      "title" : "FEVER: a large-scale dataset for fact extraction and VERification",
      "author" : [ "James Thorne", "Andreas Vlachos", "Christos Christodoulopoulos", "Arpit Mittal." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of",
      "citeRegEx" : "Thorne et al\\.,? 2018",
      "shortCiteRegEx" : "Thorne et al\\.",
      "year" : 2018
    }, {
      "title" : "An overview of the BIOASQ",
      "author" : [ "los" ],
      "venue" : null,
      "citeRegEx" : "los,? \\Q2015\\E",
      "shortCiteRegEx" : "los",
      "year" : 2015
    }, {
      "title" : "Deep domain confusion",
      "author" : [ "Trevor Darrell" ],
      "venue" : null,
      "citeRegEx" : "Darrell.,? \\Q2014\\E",
      "shortCiteRegEx" : "Darrell.",
      "year" : 2014
    }, {
      "title" : "Attention is all",
      "author" : [ "Kaiser", "Illia Polosukhin" ],
      "venue" : null,
      "citeRegEx" : "Kaiser and Polosukhin.,? \\Q2017\\E",
      "shortCiteRegEx" : "Kaiser and Polosukhin.",
      "year" : 2017
    }, {
      "title" : "Fact or fiction: Veri",
      "author" : [ "Hannaneh Hajishirzi" ],
      "venue" : null,
      "citeRegEx" : "Hajishirzi.,? \\Q2020\\E",
      "shortCiteRegEx" : "Hajishirzi.",
      "year" : 2020
    }, {
      "title" : "Approximate nearest neigh",
      "author" : [ "Arnold Overwijk" ],
      "venue" : null,
      "citeRegEx" : "Overwijk.,? \\Q2021\\E",
      "shortCiteRegEx" : "Overwijk.",
      "year" : 2021
    }, {
      "title" : "Mr",
      "author" : [ "Xinyu Zhang", "Xueguang Ma", "Peng Shi", "Jimmy Lin." ],
      "venue" : "TyDi: A multi-lingual benchmark for dense retrieval. arXiv preprint arXiv:2108.08787. 11",
      "citeRegEx" : "Zhang et al\\.,? 2021",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2021
    } ],
    "referenceMentions" : [ {
      "referenceID" : 20,
      "context" : "Rather than matching texts in the bag-of-words space, Dense Retrieval (DR) methods first encode texts into a dense embedding space (Lee et al., 2019a; Karpukhin et al., 2020; Xiong et al., 2021) and then conduct text retrieval using efficient nearest neighbor search (Chen et al.",
      "startOffset" : 131,
      "endOffset" : 194
    }, {
      "referenceID" : 17,
      "context" : "Rather than matching texts in the bag-of-words space, Dense Retrieval (DR) methods first encode texts into a dense embedding space (Lee et al., 2019a; Karpukhin et al., 2020; Xiong et al., 2021) and then conduct text retrieval using efficient nearest neighbor search (Chen et al.",
      "startOffset" : 131,
      "endOffset" : 194
    }, {
      "referenceID" : 5,
      "context" : ", 2021) and then conduct text retrieval using efficient nearest neighbor search (Chen et al., 2018; Guo et al., 2020; Johnson et al., 2021).",
      "startOffset" : 80,
      "endOffset" : 139
    }, {
      "referenceID" : 10,
      "context" : ", 2021) and then conduct text retrieval using efficient nearest neighbor search (Chen et al., 2018; Guo et al., 2020; Johnson et al., 2021).",
      "startOffset" : 80,
      "endOffset" : 139
    }, {
      "referenceID" : 16,
      "context" : ", 2021) and then conduct text retrieval using efficient nearest neighbor search (Chen et al., 2018; Guo et al., 2020; Johnson et al., 2021).",
      "startOffset" : 80,
      "endOffset" : 139
    }, {
      "referenceID" : 22,
      "context" : ", 2021), grounded generation (Lewis et al., 2020), open domain question answering (Karpukhin et al.",
      "startOffset" : 29,
      "endOffset" : 49
    }, {
      "referenceID" : 17,
      "context" : ", 2020), open domain question answering (Karpukhin et al., 2020; Izacard and Grave, 2020), etc.",
      "startOffset" : 40,
      "endOffset" : 89
    }, {
      "referenceID" : 15,
      "context" : ", 2020), open domain question answering (Karpukhin et al., 2020; Izacard and Grave, 2020), etc.",
      "startOffset" : 40,
      "endOffset" : 89
    }, {
      "referenceID" : 36,
      "context" : "Even within the search system, the generalization ability of first stage DR models is notably worse than subsequent reranking models (Thakur et al., 2021).",
      "startOffset" : 133,
      "endOffset" : 154
    }, {
      "referenceID" : 32,
      "context" : "We show learned representations from a BERTbased reranker (Nogueira and Cho, 2019) and a BERT-based dense retriever (Xiong et al.",
      "startOffset" : 58,
      "endOffset" : 82
    }, {
      "referenceID" : 36,
      "context" : "trieval tasks from the BEIR benchmark (Thakur et al., 2021).",
      "startOffset" : 38,
      "endOffset" : 59
    }, {
      "referenceID" : 17,
      "context" : ", MoDIR improves the zero-shot accuracy of DPR (Karpukhin et al., 2020) and its state-of-the-",
      "startOffset" : 47,
      "endOffset" : 71
    }, {
      "referenceID" : 36,
      "context" : "On tasks where evaluation labels have sufficient coverage for DR (Thakur et al., 2021), MoDIR’s improvements are robust and significant, even without using any target domain training labels.",
      "startOffset" : 65,
      "endOffset" : 86
    }, {
      "referenceID" : 7,
      "context" : ", 2017) such as BERT (Devlin et al., 2019) conducts retrieval in the dense embedding space (Lee et al.",
      "startOffset" : 21,
      "endOffset" : 42
    }, {
      "referenceID" : 21,
      "context" : ", 2019) conducts retrieval in the dense embedding space (Lee et al., 2019b; Chang et al., 2020; Guu et al., 2020; Karpukhin et al., 2020; Luan et al., 2021).",
      "startOffset" : 56,
      "endOffset" : 156
    }, {
      "referenceID" : 4,
      "context" : ", 2019) conducts retrieval in the dense embedding space (Lee et al., 2019b; Chang et al., 2020; Guu et al., 2020; Karpukhin et al., 2020; Luan et al., 2021).",
      "startOffset" : 56,
      "endOffset" : 156
    }, {
      "referenceID" : 11,
      "context" : ", 2019) conducts retrieval in the dense embedding space (Lee et al., 2019b; Chang et al., 2020; Guu et al., 2020; Karpukhin et al., 2020; Luan et al., 2021).",
      "startOffset" : 56,
      "endOffset" : 156
    }, {
      "referenceID" : 17,
      "context" : ", 2019) conducts retrieval in the dense embedding space (Lee et al., 2019b; Chang et al., 2020; Guu et al., 2020; Karpukhin et al., 2020; Luan et al., 2021).",
      "startOffset" : 56,
      "endOffset" : 156
    }, {
      "referenceID" : 27,
      "context" : ", 2019) conducts retrieval in the dense embedding space (Lee et al., 2019b; Chang et al., 2020; Guu et al., 2020; Karpukhin et al., 2020; Luan et al., 2021).",
      "startOffset" : 56,
      "endOffset" : 156
    }, {
      "referenceID" : 36,
      "context" : "Recently, challenges of ZeroDR have attracted much attention (Thakur et al., 2021; Zhang et al., 2021; Li and Lin, 2021).",
      "startOffset" : 61,
      "endOffset" : 120
    }, {
      "referenceID" : 43,
      "context" : "Recently, challenges of ZeroDR have attracted much attention (Thakur et al., 2021; Zhang et al., 2021; Li and Lin, 2021).",
      "startOffset" : 61,
      "endOffset" : 120
    }, {
      "referenceID" : 23,
      "context" : "Recently, challenges of ZeroDR have attracted much attention (Thakur et al., 2021; Zhang et al., 2021; Li and Lin, 2021).",
      "startOffset" : 61,
      "endOffset" : 120
    }, {
      "referenceID" : 24,
      "context" : "One way to improve ZeroDR is synthetic query generation (Liang et al., 2020;Ma et al., 2021), which first trains a doc2query model in the source domain and then applies the NLG model on target domain documents to generate queries.",
      "startOffset" : 56,
      "endOffset" : 92
    }, {
      "referenceID" : 30,
      "context" : "One way to improve ZeroDR is synthetic query generation (Liang et al., 2020;Ma et al., 2021), which first trains a doc2query model in the source domain and then applies the NLG model on target domain documents to generate queries.",
      "startOffset" : 56,
      "endOffset" : 92
    }, {
      "referenceID" : 26,
      "context" : "For example, maximummean discrepancy (Long et al., 2013; Tzeng et al., 2014; Sun and Saenko, 2016) measures domain difference with a pre-defined metric and explicitly minimizes the difference; adversarial domain adaptation tries to adversarially trained the main model to confuse the domain classifier (Ganin and Lempitsky, 2015; Bousmalis et al.",
      "startOffset" : 37,
      "endOffset" : 98
    }, {
      "referenceID" : 35,
      "context" : "For example, maximummean discrepancy (Long et al., 2013; Tzeng et al., 2014; Sun and Saenko, 2016) measures domain difference with a pre-defined metric and explicitly minimizes the difference; adversarial domain adaptation tries to adversarially trained the main model to confuse the domain classifier (Ganin and Lempitsky, 2015; Bousmalis et al.",
      "startOffset" : 37,
      "endOffset" : 98
    }, {
      "referenceID" : 9,
      "context" : ", 2014; Sun and Saenko, 2016) measures domain difference with a pre-defined metric and explicitly minimizes the difference; adversarial domain adaptation tries to adversarially trained the main model to confuse the domain classifier (Ganin and Lempitsky, 2015; Bousmalis et al., 2016; Tzeng et al., 2017; Luo et al., 2017).",
      "startOffset" : 233,
      "endOffset" : 322
    }, {
      "referenceID" : 28,
      "context" : ", 2014; Sun and Saenko, 2016) measures domain difference with a pre-defined metric and explicitly minimizes the difference; adversarial domain adaptation tries to adversarially trained the main model to confuse the domain classifier (Ganin and Lempitsky, 2015; Bousmalis et al., 2016; Tzeng et al., 2017; Luo et al., 2017).",
      "startOffset" : 233,
      "endOffset" : 322
    }, {
      "referenceID" : 36,
      "context" : ", web search), training signals are available at large scale (Ma et al., 2020; Thakur et al., 2021).",
      "startOffset" : 61,
      "endOffset" : 99
    }, {
      "referenceID" : 20,
      "context" : "The standard design of DR is to use a dual-encoder model (Lee et al., 2019a; Karpukhin et al., 2020), where an encoder g takes as input a query/document and encodes it into a dense vector.",
      "startOffset" : 57,
      "endOffset" : 100
    }, {
      "referenceID" : 17,
      "context" : "The standard design of DR is to use a dual-encoder model (Lee et al., 2019a; Karpukhin et al., 2020), where an encoder g takes as input a query/document and encodes it into a dense vector.",
      "startOffset" : 57,
      "endOffset" : 100
    }, {
      "referenceID" : 25,
      "context" : "Without loss of generality, other modeling designs are kept the same with ANCE: g is fine-tuned from RoBERTaBASE (Liu et al., 2019) and outputs the embedding of the last layer’s [CLS] token, LR is the Negative Log Likelihood (NLL) loss, and sim is the dot product.",
      "startOffset" : 113,
      "endOffset" : 131
    }, {
      "referenceID" : 0,
      "context" : "We choose the MS MARCO passage dataset (Bajaj et al., 2016) as the source domain dataset and choose the 15 publicly available datasets from the BEIR benchmark (Thakur et al.",
      "startOffset" : 39,
      "endOffset" : 59
    }, {
      "referenceID" : 36,
      "context" : ", 2016) as the source domain dataset and choose the 15 publicly available datasets from the BEIR benchmark (Thakur et al., 2021) as target domain datasets (details in Appendix A).",
      "startOffset" : 107,
      "endOffset" : 128
    }, {
      "referenceID" : 36,
      "context" : "Take TREC-COVID as an example, ANCE underperforms BM25 under the original annotation, but it achieves SOTA after adding extra labels based on ANCE’s prediction (Thakur et al., 2021).",
      "startOffset" : 160,
      "endOffset" : 181
    }, {
      "referenceID" : 34,
      "context" : "Baselines Our baselines include BM25 (Robertson and Jones, 1976), DPR (Karpukhin et al.",
      "startOffset" : 37,
      "endOffset" : 64
    }, {
      "referenceID" : 17,
      "context" : "Baselines Our baselines include BM25 (Robertson and Jones, 1976), DPR (Karpukhin et al., 2020), and ANCE (Xiong et al.",
      "startOffset" : 70,
      "endOffset" : 94
    }, {
      "referenceID" : 33,
      "context" : "BEIR also reports results of other methods, such as docT5query (Nogueira et al., 2020), TAS-B (Hofstätter et al.",
      "startOffset" : 63,
      "endOffset" : 86
    }, {
      "referenceID" : 30,
      "context" : ", 2021), GenQ (Ma et al., 2021), ColBERT (Khattab and Zaharia, 2020), etc.",
      "startOffset" : 14,
      "endOffset" : 31
    } ],
    "year" : 0,
    "abstractText" : "Dense retrieval (DR) methods conduct text retrieval by first encoding texts in the embedding space and then matching them by nearest neighbor search. This requires strong locality properties from the representation space, i.e, the close allocations of each small group of relevant texts, which are hard to generalize to domains without sufficient training data. In this paper, we aim to improve the generalization ability of DR models from source training domains with rich supervision signals to target domains without any relevant labels, in the zero-shot setting. To achieve that, we propose Momentum adversarial Domain Invariant Representation learning (MoDIR), which introduces a momentum method in the DR training process to train a domain classifier distinguishing source versus target, and then adversarially updates the DR encoder to learn domain invariant representations. Our experiments show that MoDIR robustly outperforms its baselines on 10+ ranking datasets from the BEIR benchmark in the zero-shot setup, with more than 10% relative gains on datasets with enough sensitivity for DR models’ evaluation. Source code of this paper will be released.",
    "creator" : null
  }
}