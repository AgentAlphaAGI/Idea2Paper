{
  "name" : "ARR_2022_4_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Word is Worth A Thousand Dollars: Adversarial Attack on Tweets Fools Stock Prediction",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The advance of deep learning based language models are playing a more and more important role in the financial context, including convolutional neutral network (CNN) (Ding et al., 2015), recurrent neutral network (RNN) (Minh et al., 2018), long short-term memory network (LSTM) (Hiew et al., 2019; Sawhney et al., 2021; Hochreiter and Schmidhuber, 1997), graph neutral network (GNN) (Sawhney et al., 2020a,b), transformer (Yang et al., 2020), autoencoder (Xu and Cohen, 2018), etc. For example, Antweiler and Frank (2004) find that comments on Yahoo Finance can predict stock market volatility after controlling the effect of news. Cookson and Niessner (2020) also show that sentiment disagreement on Stocktwits is highly related to certain market activities. Readers can refer to these survey papers for more details (Dang et al., 2020; Zhang et al., 2018; Xing et al., 2018).\nIt is now known that text-based deep learning models can be vulnerable to adversarial attacks (Szegedy et al., 2013; Goodfellow et al., 2014).\nThe perturbation can be done at the sentence level (e.g., Xu et al., 2021; Iyyer et al., 2018; Ribeiro et al., 2018), the word level (e.g., Zhang et al., 2019; Alzantot et al., 2018; Zang et al., 2020; Jin et al., 2020; Lei et al., 2018; Zhang et al., 2021; Lin et al., 2021), or both (Chen et al., 2021). We are interested in whether such adversarial attack vulnerability also exists in stock prediction models, as these models embrace more and more user-generated public data (e.g., Twitter, Reddit, or Stocktwit (Xu and Cohen, 2018; Sawhney et al., 2021)). The adversarial robustness may be a more critical topic in the context of stock prediction as anyone can post perturbed tweets to influence forecast models. As one example, a fake news (“Two Explosions in the White House and Barack Obama is Injured”) posted by a hacker using the AssociatedPress’s Twitter account on 04/23/2013 erased $136 billion in stock market in just 60 seconds (Fisher, 2013). Although the event doesn’t fall into the category of adversarial attack, it rings the alarm for traders\nwho take information from social media to back their trading decision.\nTo our best knowledge, it is the first paper to consider the adversarial attack in the financial NLP literature. Many attack modifies benign text directly (manipulation attack) and use them as model input; However, in our case, adversarial retweets enter the model along with benign tweets (concatenation attack), which is more realistic as malicious Twitter users can not modify others’ tweets. In other words, we formulate the task as text-concatenating attack (Jia and Liang, 2017; Le et al., 2021): we implement the attack by injecting new tweets instead of manipulating existing benign tweets. Our task is inspired and mimics the retweet function on social media, and use it to feed the adversarial samples into the dataset. Despite various algorithms are proposed to generate manipulation attack, literature of concatenation attack on classification model is rare, with exceptions Le et al. (2021), Song et al. (2021) and Wang et al. (2020). Our paper provides extra evidence of their difference by investigating their performances in the domain of finance.\nThe main challenge is to craft new adversarial tweets. While the adversarial tweets can be arbitrary given that they are newly posted, we solve the task by aligning the semantics with benign tweets so that potential human and machine readers can not detect our adversarial tweets. To achieve that, we consider the generation task as a combinatorial optimization problem (Zang et al., 2020; Guo et al., 2021). Specific tweets are first selected, which are used as target of perturbation on a limit number of words within the tweets. We then examine our attack method on three financial forecast models with attack success rate, F1 and potential profit and loss as evaluation metrics. Results show that our attack method consistently achieves good success rate on the victim models. More astonishingly, the attack can cause additional loss of 23% to 32% if the investor trades on predictions of the victim models (Fig. 4)."
    }, {
      "heading" : "2 Adversarial Attack on Stock Prediction Models with Tweet Data",
      "text" : "Attack model: Adversarial tweets. In the case of Twitter, adversaries can post malicious tweets which are crafted to manipulate downstream models that take them as input. We propose to attack by posting semantically similar adversarial tweets as retweets on Twitter, so that they could be identi-\nfied as relevant information and collected as model input. For example, as shown in Fig 1, the original authentic tweet by the user wallstreetbet7821 was “$BHP announces the demerger of its noncore assets - details expected to be filled in on Tuesday.” An adversarial sentence could be “$BHP announces the demerger of its non-core assets - details expected to be exercised in on Tuesday.”. The outcome of the victim model switches to negative prediction from positive prediction when the retweet is added to the input.\nThe proposed attack method takes the practical implementation into its design consideration, thus has many advantages. First, the adversarial tweets are crafted based on carefully-selected relevant tweets, so they are more likely to pass the models’ tweet filter and enter the inference data corpus. Secondly, adversarial tweets are optimized to be semantically similar to original tweets so that they are not counterfactual and very likely fool human sanity checks as well as the Twitter’s content moderator mechanisms.\nAttack generation: Hierarchical perturbation. The challenge of our attack method centers around how to select the optimal tweets and the token perturbations with constraints of semantic similarity. In this paper, we formulate the task as a hierarchical perturbation consisting of three steps: tweet selection, word selection and word perturbation. In the first step, a set of optimal tweets is first selected as target tweets to be perturbed and retweeted. For each selected tweet in the pool, the word selection problem is then solved to find one or more best words to apply perturbation. Word and tweet budgets are also introduced to quantifies the strength of perturbation.\nWe consider word replacement and deletion for word perturbation (Garg and Ramakrishnan, 2020; Li et al., 2020). In the former case, the final step is to find the optimal candidate as replacement. Synonym as replacement is widely adopted in the word-level attack since it is a natural choice to preserve semantics (Zang et al., 2020; Dong et al., 2021; Zhang et al., 2019; Jin et al., 2020). Therefore, we replace target words with their synonyms chosen from synonym sets which contain semantically closest words measured by similarity of the GLOVE embedding (Jin et al., 2020).\nMathematical Formulation. We consider a multimodal stock forecast model f(·) that takes\ntweet collections {ct}Tt=1 and numerical factors {pt}Tt=1 as input, where t indexes the date when the data is collected. Peeking into the tweet collection, it contains |ct| tweets for date t, namely, ct = {s1t , s2t , ..., s |ct| t }. Each tweet sit is a textbased sentence of length |sit|, denoted as sit = (wi,1t , ..., w i,j t , ..., w i,|sit| t ), for i = 1, ..., |ct|. A directional financial forecast model takes domains of tweets and numerical factors as input, and yields prediction for stocks’ directional movement y ∈ {−1, 1}:\nŷt+1 = f(ct−h:t,pt−h:t), (1)\nwhere h is the looking-back window for historical data.\nThe hierarchical perturbation can be cast as a combinatorial problem for tweet selection m, word selection z and replacement selection u. The boolean vector m indicates the tweets to be selected. For i-th tweet, vector zi indicates the word to be perturbed. As for the word perturbation task, another boolean vector ui,j selects the best replacement. It follows that the hierarchical perturbation can be formulated as\nc′t = (1−m · z) · ct +m · z · u · S(ct), (2)\nwhere · denotes element-column wise product, m · z indicates the selected words in selected tweets, m · z · u indicates selected synonyms for each selected word, and S(·) is element-wise synonym generating function. Consequently, given attack loss L, generation of adversarial retweets can be formulated as the optimization program min m,z,u L(c′t ∪ ct−h:t, ct−h:t|pt−h:t, f), subject to budget constraints: a) 1Tm ≤ bs, b) 1Tzi ≤ bw, ∀i and c) 1Tui,j = 1, ∀i, j, where bs and bw denote the tweet and word budget. It is worth to stress that perturbation is only applied to the date (t) when the attack is implemented to preserve temporal order.\nTo solve the program, we follow the convex relaxation approach developed in (Srikant et al., 2021). Specifically, the boolean variables (for tweet and word selection) would be relaxed into the continuous space so that they can be optimized by gradient-based methods over a convex hull. Two main implementations of the optimization-based attack generation method are proposed: joint optimization (JO) solver and alternating greedy optimization (AGO) solver. JO calls projected gradient descent method to optimize the tweet and word\nselection variables and word replacement variables simultaneously. AGO uses an alternative optimization procedure to sequentially update the discrete selection variables and the replacement selection variables. More details on the optimization program and the solvers can be found in Appendix A."
    }, {
      "heading" : "3 Experiments",
      "text" : "Dataset & victim models. We evaluate our adversarial attack on a stock prediction dataset consisting of 10824 instances including relevant tweets and numerical features of 88 stocks from 2014 to 2016 (Xu and Cohen, 2018). Three models (Stocknet (Xu and Cohen, 2018), FinGRU based on GRU (Cho et al., 2014) and FinLSTM based on LSTM (Hochreiter and Schmidhuber, 1997)) of binary classification are considered as victims in this paper. We apply our attack to instances on which the victim models make correct prediction.\nEvaluation metrics. Attack performance is evaluated by two metrics: Attack Success Rate (ASR) and victim model’s F1 drop after attack. ASR is defined as the percentage of the attack efforts that changes the model output. The two metrics gauge the efficacy of the attack and its impact on model performance: More efficient attack leads to higher ASR and more decline of F1. Moreover, we simulate a Long-Only Buy-Hold-Sell strategy (Sawhney et al., 2021; Feng et al., 2019) with victim models, and calculate the Profit and Loss (PnL) for each simulation. Assume a portfolio starts with initial net value 1 (100%), its net value at the end of test period reflects the profitability of the trading strategy and the underlying model. Consequently, the change in PnLs measures the monetary impact of our attack. More details on the dataset, victim models and evaluation metrics are housed in Appendix B."
    }, {
      "heading" : "4 Results",
      "text" : "Attack performance with single perturbation. The experiment results for the concatenation attack with word replacement perturbation is shown in Table 1 (with tweet and word budgets both as 1). As we can see, for both JO and AGO, ASR increases by roughly 10% and F1 drops by 0.1 on average in comparison to random attack. Such performance drop is considered significant in the context of stock prediction given that the state-of-the-art prediction accuracy of interday return is only about 60%.\nEffect of attack budget. We report the effect of different attack budgets on the attack performance in Fig. 2. We observe that the more budgets allowed (perturbing more tweets and words), the better the attack performance, but the increase is not significant. It appears that the attack performance becomes saturated if we keep increasing the attack budget. In fact, the attack with budget of one tweet and one word is most cost effective, provided that it introduces minimum perturbation but achieves relatively similar ASR.\nManipulation vs concatenation attack. We focus on concatenation attack in this paper since we believe it is distinct from manipulation attack. We investigate the difference by applying the same method of tweet generation to implement manipulation attack, where the adversarial tweets replace target tweets instead. The experiment runs with one word budget and one twee budget, and the results are reported in Fig. 3.\nIt is clear that manipulation attack remarkably outperforms concatenation attack in terms of ASR and F1. Even though the success rate of concatenation attack lags behind the state-of-the-art textual at-\ntack, the manipulation attack achieves performance of the same ballpark, which demonstrates the efficacy of optimization-based attack and our solvers. More importantly, it implies that the attack is not transferable between the two tasks, documenting more evidence on language attack transferability (Yuan et al., 2021; He et al., 2021). The bottom line is that they are two different tasks under different assumptions. Researchers should take downstream scenarios into account when develop attack models.\nTrading simulation. The ultimate measure of a stock prediction model’s performance is profitability. Figure 4 plots the profit and loss of the trades with and without attack. Stocknet is adopted to support the trading strategy, and JO is deployed to generate adversarial retweets. For each simulation, net values are set as 100% at the beginning. The results show that even replacement of a single word in one tweet can cause a 32% (75%-43%) additional loss to the portfolio. Our results alert investors who use text-based stock prediction models to deploy defense systems to guard against loss caused by potential adversarial attack."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In summary, we show that financial forecast models are vulnerable to adversarial attack even if it is subject to certain physical constraints. The experiments demonstrate that our adversarial attack method consistently fools various models. Moreover, with replacement of a single word on one tweet, the attack can cause 32% additional loss to our simulated portfolio. Through studying vulnerability of financial forecast models, our goal is to raise financial community’s awareness of the model robustness. In the future, we plan to introduce more real-world constraints, including black-box attack, unknown input domains, etc."
    }, {
      "heading" : "A Mathematical Formation",
      "text" : ""
    }, {
      "heading" : "A.1 Financial Forecast Model",
      "text" : "Massive amounts of text data are generated by millions of users on Twitter every day. Among a variety of discussion, stock analysis, picking and prediction is consistently one of the trending topics. And investors often use the Twitter cashtag function (a $ symbol followed by a ticker) to organize their particular thoughts around one single stock, e.g., $AAPL, so that users can click and see the ongoing discussions. Textual data on Twitter is collectively generated by all of its users via posting tweets. Financial organizations and institutional investors often ingest the massive text data in real time and incorporate them or their latent representation into their stock prediction models.\nWe consider the multimodal stock forecast models that take tweet collections {ct}Tt=1 and numerical factors {pt}Tt=1 as input,where t indexes the date when the data is collected. The numerical factors are usually mined from historical price, fundamentals and other alternative data sources. In this paper, we assume that the domain of numerical factors is unassailable since they are directly derived from public records. Therefore, the objective of adversary is to manipulate model output by injecting perturbation to the textual domain {ct}Tt=1. Peeking into the tweet collection, it contains |ct| tweets for date t, namely, ct = {s1t , s2t , ..., s |ct| t }. Each tweet sit is a text-based sentence of length |sit|, denoted as sit = (w i,1 t , ..., w i,j t , ..., w i,|sit| t ), for i = 1, ..., |ct|. A directional financial forecast model takes domains of tweets and numerical factors as input, and yields prediction for stocks’ directional movement y ∈ {−1, 1}:\nŷt+1 = f(ct−h:t,pt−h:t), (3)\nwhere h is the looking-back window for historical data."
    }, {
      "heading" : "A.2 Attack Model",
      "text" : "Let c′t be the perturbed tweet collection at time t created by solving the hierarchical perturbation problem. To formalize the perturbation task, we introduce boolean vector variable m ∈ {0, 1}nm to indicate the tweets to be selected. If mi = 1, then i-th tweet is the target tweet to be perturbed and retweeted. Besides, for i-th tweet, vector zi ∈ {0, 1}nz indicates the word to be perturbed. As for the word perturbation task, another boolean\nvector ui,j ∈ {0, 1}nu selects the best replacement. nm and nz and nu denote the maximum amount of tweets, maximum amount of words in each tweet, and the amount of synonyms for each word, respectively. We identify deletion perturbation as a special case of replacement with ui,j,k = 1 only for padding token, so that the task degenerates to tweet selection and word selection. Let vector z ∈ {0, 1}nm×nz denote nm different zi vector, and u ∈ {0, 1}nm×nz×nu denote nm × nz different ui,j vectors. It follows that the hierarchical perturbation can be defined as\nc′t = (1−m · z) · ct +m · z · u · S(ct) s.t. 1Tm ≤ bs,\n1Tzi ≤ bw, ∀i, 1Tui,j = 1,∀i, j,\n(4)\nwhere · denotes element-column wise product, bs denotes tweet budget, bw denotes word budget and S(·) is element-wise synonym generating function.\nAdversarial retweets are the then passed into downstream financial forecast model f(·) along with benign tweets. Attack success is achieved if the adversarial tweets manage to fool the downstream model, and change the model output. Financial forecast model usually takes observation of multiple steps as input to appreciate the temporal dependence. However, adversary can only inject adversarial retweets at present time. That is, when run the model on day t to predict price movement on day t+ 1, retweets only enter tweet collection for day t; collections for days prior to t remain static. Consequently, generation of successful adversarial retweets is formulated as the following optimization program:\nmin m,z,u\nL(c′t ∪ ct−h:t, ct−h:t|pt−h:t, f)\ns.t. constraint in (4), (5)\nwhereL denotes the attack loss. We adopt the crossentropy loss for our attack since it is untargeted attack (Srikant et al., 2021). Other classificationrelated loss may be applied according to adversary’s objective. Furthermore, we also add entropybased regularization to encourage sparsity of optimization variables (Dong et al., 2021)."
    }, {
      "heading" : "A.3 Methodology",
      "text" : "The challenge of solving program (5) lies in the combinatorial and hierarchical nature. We first relax the boolean variables into continuous space so\nthat they can be solved by gradient-based solvers. A common workaround for combinatorial optimization is to solve an associated continuous optimization over convex hull (Dong et al., 2021; Srikant et al., 2021). An computationally efficient fashion is to optimize over a convex hull constructed with linear combination of candidate set, and the optimal replacement goes with word with highest weight (Dong et al., 2021). However, this approach doesn’t fit in the hierarchical tweet and word selection problem. For example, in order to select the optimal target word, one need to sum over the embedding of all words in the tweet, so the tweet collapses into embedding for one hypothetical word. Similarly, different tweets collapse to one hypothetical tweet, or one hypothetical word when one jointly selects tweets and words.\nJoint optimization solver (JO). As a remedy, we propose a joint optimization solver that combines projected gradient descent and convex hull to jointly optimize m, z and u. Replacement selection is optimized over the convex hull:\nc′t = (1−m · z) · ct +m · z · conv(u, S(ct)),\nwhere conv(u, S(ct)) = { ∑ k ûi,j,kS(wi,j,k),∀i, j},\nand\nûi,j,k = exp(ui,j,k)∑ k exp(ui,j,k) .\nThe problem of (5) is then solved by optimizing û. Unlike u, m and z are optimized directly via projected gradient descent (PGD). Moreover, when m is one-hot vector, it determines the tweets to be retweeted, and those retweets are then added into tweet collection. However, m is continuous during optimization, so we retweet all the collected tweets and add them into tweet collection, which helps generate and back-propagate gradients for all the entries of m. After the optimization is solved, we map the continuous solution into one-hot vector by selecting top bs highest mi.\nAlternating greedy optimization solver (AGO). Greedy optimization is usually computational ineffective since a vast amount of inquiries is required when we collect large amount of tweets and have high attack budget. To mitigate the problem, we alternate the optimization over m, z and u. The\naforementioned convex hull approach is adopted for finding optimal u. The difference lies on the path to solve tweet and word selection problems. More specifically, we alternatively search the optimal target tweets and words which achieve the highest increases in prediction loss. For tweet selection, we mimic the physical attack scenario, and new retweets are added into tweet collection during the greedy search. Depending on the adversary’s objective, different metrics may be used to measure the importance of each tweet and word. For example, Alzantot et al. (2018) use predicting probability to determine the selection of words; Ren et al. (2019) propose probability weighted word saliency as criterion for word selection; Jin et al. (2020) calculate the prediction change before and after deletion as word importance."
    }, {
      "heading" : "B Experimental Settings",
      "text" : ""
    }, {
      "heading" : "B.1 Dataset",
      "text" : "We evaluate our adversarial attack on a stock prediction dataset (Xu and Cohen, 2018). The dataset contains both tweets and historical prices (e.g., open, close, high, etc) for 88 stocks of 9 industries: Basic Materials, Consumer Goods, Healthcare, Services, Utilities, Conglomerates, Financial, Industrial Goods and Technology. Since we consider the task of binary classification, data instances are supposed to labelled positive and negative for upward and downward movement respectively.\nMoreover, it is observed that the dataset contains a number of instances with exceptionally minor price movements. In practice, minor movement is hard to be monetized due to the existence of transaction cost. Therefore, an upper threshold of 0.55% and a lower threshold of -0.5% are introduced. Specifically, stocks going up more than 0.55% in a day are labeled as positive, those going down more than -0.5% are labeled as negative, and the minor moves in between are filtered out. As argued in (Xu and Cohen, 2018), the particular thresholds are carefully selected to balance the two classes.\nIn addition, the sampling period spans from 01/01/2014 to 01/01/2016. We split the dataset into train and test set on a rolling basis. This special program improves the similarity between distributions of train set and test set, which is widely adopted on temporal dataset. It leaves us 9416 train instances and 1408 test instances in 7 nonconsecutive periods. For the text domain, the dataset contains\n57533 tweets in total.\nB.2 Victim Models\nStocknet. A variational Autoencoder (VAE) that takes both tweets and price as input (Xu and Cohen, 2018). Tweets are encoded in hierarchical manner within days, and then modeled sequentially along with price features. It consists of three main components in bottom-up fashion. Market Information Encoder first encodes tweets and prices to a latent representation of 50 dimensions for each day. Variational Movement Decoder infers latent vectors of 150 dimensions and then decodes stock movements. At last, a module called Attentive Temporal Auxiliary integrates temporal loss through an attention mechanism. We train the model on the dataset from scratch with the same configurations as Xu and Cohen (2018).\nFinGRU. A binary classifier that takes numerical features and tweets as input. All features are encoded sequentially by GRU (Cho et al., 2014) to exploit the temporal dependence. The model adopts the same Market Information Encoder as Stocknet. Latent representation of tweets and prices are then fed into a layer of GRU with attention mechanism to integrate temporal information. We train the model with an Adam optimizer (Kingma and Ba, 2015) and learning rate of 0.005. The checkpoint achieves the best performance on test dataset among 100 epochs is adopted as the victim model.\nFinLSTM. A binary classifier identical to FinGRU, but utilizes LSTM (Hochreiter and Schmidhuber, 1997) to encode temporal dependence. The model is trained in the same manner as FinGRU."
    }, {
      "heading" : "B.3 Evaluation Metrics",
      "text" : "Following Srikant et al. (2021), we evaulate the attack on those examples in the test set that are correctly classified by the target models. It provides direct evidence of the adversarial effect of the input perturbation and the model robustness. In the specific application of financial forecast, it makes more sense to manipulate correct prediction than incorrect ones. The following two common metrics are adopted to evaluate attack performance.\nAttack Success Rate. ASR is defined as the percentage of the attack efforts that make the victim model misclassify the instances that are originally correctly classified. Mathematically, ASR =\n∑ t δ(ŷ ′ t 6=yt)∑\nt δ(ŷt=yt) , where ŷt is the unperturbed model prediction, ŷ′t the model prediction with perturbation, and yt the ground-truth label. ASR characterizes the capability of the attack model, and higher the ASR, the better the attack.\nF1 Score. F1 gauges the prediction performance of the victim models. Since we only consider the samples that are correctly predicted, the F1 score in the case of no attack is 1. Apparently, the drop of the F1 score of caused by the perturbation demonstrates the performance of the attack method. Unlike ASR, the drops of F1 score gauge the direct impact on the model performance: more successful attack leads to lower post-attack F1 score.\nProfit and Loss. This widely-used financial indicator measures the profitability of a trading strategy. Assume that the initial net values are 1 (100%), accumulate profit and loss for each trade, we can then calculate the final net value of the portfolio and profit and loss. A binary financial forecast model can be exploited in many ways, and support various trading strategies, which usually lead to different PnLs. In this paper, we use a simple Long-Only Buy-Hold-Sell strategy (Sawhney et al., 2021; Feng et al., 2019). More specifically, we buy stock(s) on Day T if the model predicts these stocks go up on Day T + 1, hold for one day, and sell these stocks the next day no matter what prices will be, and repeat it. We do not short a stock even if the model predicts a negative move in the second day.\nBesides, when the model makes positive prediction on more than one stocks, the money is evenly invested to the stock pool of positive prediction. For example, suppose that we stand on day 4 with portfolio value 1.2. If the model gives positive prediction on 10 of 88 stocks for day 5, we invest 10% of the total wealth (0.12) to each stock, and sell them at closing prices of day 5. The process continues until the end of the test periods, and the resulting net value of the portfolio is used to calculate the profit and loss of the underlying model.\nThe buy-hold-sell strategy monetizes the prediction performance of financial forecast models by betting on the their predictions. The PnL reflects the profitability of the underlying models, even if it is usually influenced by many other confounding factors. Most importantly, the changes of PnLs caused by perturbation on the victim models only gauge the monetary consequence of our attack,\nsince all else are equal."
    }, {
      "heading" : "C Supplemental Experiment Results",
      "text" : ""
    }, {
      "heading" : "C.1 Replacement vs deletion perturbation.",
      "text" : "We report results for concatenation attack with only the replacement perturbation in the main text in Table 1. Here we also report results for the deletion perturbation in Table 2. Attacks conducted via deletion perturbation in general perform worse than the results of replacement perturbation. We observe ASRs via JO and AGO fall by 5.1% and 4.1% respectively compared with the replacement perturbation. Accordingly, F1 slightly increases as attack performance worsens. There is no significant difference between the two optimizers (JO and AGO) in the case of deletion perturbation, but JO is preferable in terms of optimization efficiency.\nMoreover, we also simulate the trading profit and loss based on FinGRU and FinLSTM. For the sake of consistency, the two models are under concatenation attack with replacement perturbation. Same as our main results, the attack is optimized by JO solver. The simulation results are reported in Figure 5, which provides further evidence for the potential monetary loss caused by our adversarial attack. Replacement perturbation again outperforms deletion perturbation in the case of FinGRU and FinLSTM."
    }, {
      "heading" : "C.2 Effect of Iteration Number",
      "text" : "We experiment with the optimizer to perform gradient descent or greedy search for up to 10 rounds before yielding the final solution. To visualize the effect of iteration, we plot the loss trajectory and ASR along with the optimization iterations in Figure 6. We also collect the average model loss of attack instances at each iteration, and then normalize the loss to set the initial loss as 1. Therefore, the loss trajectory visualization reveals the percentage loss drop during the optimization. We consider two different perturbations (replacement and deletion) under concatenation attacks. The attack is optimized with the JO solver.\nThe three charts on the first row of Figure 6 show that optimizations on all three victim models quickly converge after 4 iterations in our experiment. Accordingly, ASRs rise gradually during the first 4 iterations, but then flattens or even slides afterward. Such results suggest that our solvers can find the convergence in just a few iterations. Therefore, it makes our attack computationally effective, and insensitive to hyperparameter of iteration number."
    }, {
      "heading" : "D Regularization on Attack Loss.",
      "text" : "The experiment results reported in the main text are generated with the sparsity regularization. We\nalso run ablation experiments that remove sparsity regularization. The results are consistent with our conclusion. Furthermore, inspired by (Srikant et al., 2021), we try smoothing attack loss to stabilize the optimization. We add Gaussian noise to optimization variables and evaluate the attack 10 times. The loss average is then used as the final loss for backpropagation. The results show that loss smoothing does not contribute to attack performance in our experiment as it does in (Srikant et al., 2021)."
    }, {
      "heading" : "E Attack Word Analysis",
      "text" : "To qualitatively understand what kinds of words and tweets are being selected in the perturbation and retweet, we compare our tweet corpus and the selected word replacements with 15 corpora of different genres in Brown corpus via Linguistic Inquiry and Word Count program (LIWC) (Tausczik and Pennebaker, 2010). As Brown corpus does not have a financial genre, we also use Financial Phrase Bank (Malo et al., 2014). We then run Kmeans clustering these 18 corpora based on the feature matrix from LIWC. As shown in Figure 7, financial corpora (red), Brown general word corpus (green), and attack words (blue) are grouped into three clusters, indicating the inherent difference of those text genres. Moreover, we observe that target words identified by our solvers (red “tweet” and blue “attack words” dots) are closer to financial corpora than “random attack words”."
    }, {
      "heading" : "F Example of Adversarial Retweet",
      "text" : "Table 3 reports 10 adversarial retweets generated in concatenation attack mode with JO and AGO solver and replacement perturbation. For all the examples, the victim model predicts positive outcomes originally, and but predicts negative outcomes after adding the adversarial retweet."
    } ],
    "references" : [ {
      "title" : "Generating natural language adversarial examples",
      "author" : [ "Moustafa Alzantot", "Yash Sharma", "Ahmed Elgohary", "Bo-Jhang Ho", "Mani Srivastava", "Kai-Wei Chang." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Alzantot et al\\.,? 2018",
      "shortCiteRegEx" : "Alzantot et al\\.",
      "year" : 2018
    }, {
      "title" : "Is all that talk just noise? the information content of internet stock message boards",
      "author" : [ "Werner Antweiler", "Murray Z Frank." ],
      "venue" : "The Journal of finance, 59(3):1259–1294.",
      "citeRegEx" : "Antweiler and Frank.,? 2004",
      "shortCiteRegEx" : "Antweiler and Frank.",
      "year" : 2004
    }, {
      "title" : "Multigranularity Textual Adversarial Attack with Behavior Cloning",
      "author" : [ "Yangyi Chen", "Jin Su", "Wei Wei." ],
      "venue" : "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 4511–4526, Online and Punta Cana, Do-",
      "citeRegEx" : "Chen et al\\.,? 2021",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2021
    }, {
      "title" : "Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation",
      "author" : [ "Kyunghyun Cho", "Bart van Merriënboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio" ],
      "venue" : null,
      "citeRegEx" : "Cho et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Cho et al\\.",
      "year" : 2014
    }, {
      "title" : "Why don’t we agree? evidence from a social network of investors",
      "author" : [ "J Anthony Cookson", "Marina Niessner." ],
      "venue" : "The Journal of Finance, 75(1):173–228.",
      "citeRegEx" : "Cookson and Niessner.,? 2020",
      "shortCiteRegEx" : "Cookson and Niessner.",
      "year" : 2020
    }, {
      "title" : "Sentiment analysis based on deep learning: A comparative study",
      "author" : [ "Nhan Cach Dang", "María N Moreno-García", "Fernando De la Prieta." ],
      "venue" : "Electronics, 9(3):483.",
      "citeRegEx" : "Dang et al\\.,? 2020",
      "shortCiteRegEx" : "Dang et al\\.",
      "year" : 2020
    }, {
      "title" : "Deep learning for event-driven stock prediction",
      "author" : [ "Xiao Ding", "Yue Zhang", "Ting Liu", "Junwen Duan." ],
      "venue" : "Twenty-fourth international joint conference on artificial intelligence.",
      "citeRegEx" : "Ding et al\\.,? 2015",
      "shortCiteRegEx" : "Ding et al\\.",
      "year" : 2015
    }, {
      "title" : "Towards robustness against natural language word substitutions",
      "author" : [ "Xinshuai Dong", "Anh Tuan Luu", "Rongrong Ji", "Hong Liu." ],
      "venue" : "arXiv preprint arXiv:2107.13541.",
      "citeRegEx" : "Dong et al\\.,? 2021",
      "shortCiteRegEx" : "Dong et al\\.",
      "year" : 2021
    }, {
      "title" : "Temporal relational ranking for stock prediction",
      "author" : [ "Fuli Feng", "Xiangnan He", "Xiang Wang", "Cheng Luo", "Yiqun Liu", "Tat-Seng Chua." ],
      "venue" : "ACM Trans. Inf. Syst., 37(2).",
      "citeRegEx" : "Feng et al\\.,? 2019",
      "shortCiteRegEx" : "Feng et al\\.",
      "year" : 2019
    }, {
      "title" : "Syrian hackers claim AP hack that tipped stock market by $136 billion",
      "author" : [ "Max Fisher." ],
      "venue" : "Is it terrorism? Washington Post.",
      "citeRegEx" : "Fisher.,? 2013",
      "shortCiteRegEx" : "Fisher.",
      "year" : 2013
    }, {
      "title" : "BAE: BERT-based Adversarial Examples for Text Classification",
      "author" : [ "Siddhant Garg", "Goutham Ramakrishnan." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 6174–6181, Online. As-",
      "citeRegEx" : "Garg and Ramakrishnan.,? 2020",
      "shortCiteRegEx" : "Garg and Ramakrishnan.",
      "year" : 2020
    }, {
      "title" : "Explaining and harnessing adversarial examples",
      "author" : [ "Ian J Goodfellow", "Jonathon Shlens", "Christian Szegedy." ],
      "venue" : "arXiv preprint arXiv:1412.6572.",
      "citeRegEx" : "Goodfellow et al\\.,? 2014",
      "shortCiteRegEx" : "Goodfellow et al\\.",
      "year" : 2014
    }, {
      "title" : "Gradient-based Adversarial Attacks against Text Transformers",
      "author" : [ "Chuan Guo", "Alexandre Sablayrolles", "Hervé Jégou", "Douwe Kiela." ],
      "venue" : "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 5747–5757, Online",
      "citeRegEx" : "Guo et al\\.,? 2021",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2021
    }, {
      "title" : "Model Extraction and Adversarial Transferability, Your BERT is Vulnerable",
      "author" : [ "Xuanli He", "Lingjuan Lyu", "Lichao Sun", "Qiongkai Xu" ],
      "venue" : "In Proceedings of the 2021 Conference of the North American Chapter of the Association",
      "citeRegEx" : "He et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2021
    }, {
      "title" : "Bert-based financial sentiment index and lstm-based stock return predictability",
      "author" : [ "Joshua Zoen Git Hiew", "Xin Huang", "Hao Mou", "Duan Li", "Qi Wu", "Yabo Xu." ],
      "venue" : "arXiv preprint arXiv:1906.09024.",
      "citeRegEx" : "Hiew et al\\.,? 2019",
      "shortCiteRegEx" : "Hiew et al\\.",
      "year" : 2019
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber." ],
      "venue" : "Neural computation, 9(8):1735–1780.",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? 1997",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Adversarial example generation with syntactically controlled paraphrase networks",
      "author" : [ "Mohit Iyyer", "John Wieting", "Kevin Gimpel", "Luke Zettlemoyer." ],
      "venue" : "arXiv preprint arXiv:1804.06059.",
      "citeRegEx" : "Iyyer et al\\.,? 2018",
      "shortCiteRegEx" : "Iyyer et al\\.",
      "year" : 2018
    }, {
      "title" : "Adversarial examples for evaluating reading comprehension systems",
      "author" : [ "Robin Jia", "Percy Liang." ],
      "venue" : "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 2021–2031, Copenhagen, Denmark. Association for",
      "citeRegEx" : "Jia and Liang.,? 2017",
      "shortCiteRegEx" : "Jia and Liang.",
      "year" : 2017
    }, {
      "title" : "Is bert really robust? a strong baseline for natural language attack on text classification and entailment",
      "author" : [ "Di Jin", "Zhijing Jin", "Joey Tianyi Zhou", "Peter Szolovits." ],
      "venue" : "Proceedings of the AAAI conference on artificial intelligence, volume 34, pages",
      "citeRegEx" : "Jin et al\\.,? 2020",
      "shortCiteRegEx" : "Jin et al\\.",
      "year" : 2020
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P. Kingma", "Jimmy Ba." ],
      "venue" : "3rd International Conference on Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings.",
      "citeRegEx" : "Kingma and Ba.,? 2015",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2015
    }, {
      "title" : "A sweet rabbit hole by darcy: Using honeypots to detect universal trigger’s adversarial attacks",
      "author" : [ "Thai Le Le", "Noseong Park Park", "Dongwon Lee." ],
      "venue" : "59th Annual Meeting of the Association for Comp. Linguistics (ACL).",
      "citeRegEx" : "Le et al\\.,? 2021",
      "shortCiteRegEx" : "Le et al\\.",
      "year" : 2021
    }, {
      "title" : "Discrete adversarial attacks and submodular optimization with applications to text classification",
      "author" : [ "Qi Lei", "Lingfei Wu", "Pin-Yu Chen", "Alexandros G Dimakis", "Inderjit S Dhillon", "Michael Witbrock." ],
      "venue" : "arXiv preprint arXiv:1812.00151.",
      "citeRegEx" : "Lei et al\\.,? 2018",
      "shortCiteRegEx" : "Lei et al\\.",
      "year" : 2018
    }, {
      "title" : "BERT-ATTACK: Adversarial Attack Against BERT Using BERT",
      "author" : [ "Linyang Li", "Ruotian Ma", "Qipeng Guo", "Xiangyang Xue", "Xipeng Qiu." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages",
      "citeRegEx" : "Li et al\\.,? 2020",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2020
    }, {
      "title" : "RockNER: A Simple Method to Create Adversarial Examples for Evaluating the Robustness of Named Entity Recognition Models",
      "author" : [ "Bill Yuchen Lin", "Wenyang Gao", "Jun Yan", "Ryan Moreno", "Xiang Ren." ],
      "venue" : "Proceedings of the 2021 Conference on",
      "citeRegEx" : "Lin et al\\.,? 2021",
      "shortCiteRegEx" : "Lin et al\\.",
      "year" : 2021
    }, {
      "title" : "Good debt or bad debt: Detecting semantic orientations in economic texts",
      "author" : [ "Pekka Malo", "Ankur Sinha", "Pekka J. Korhonen", "Jyrki Wallenius", "Pyry Takala." ],
      "venue" : "Journal of the Association for Information Science and Technology, 65.",
      "citeRegEx" : "Malo et al\\.,? 2014",
      "shortCiteRegEx" : "Malo et al\\.",
      "year" : 2014
    }, {
      "title" : "Deep learning approach for short-term stock trends prediction based on twostream gated recurrent unit network",
      "author" : [ "Dang Lien Minh", "Abolghasem Sadeghi-Niaraki", "Huynh Duc Huy", "Kyungbok Min", "Hyeonjoon Moon." ],
      "venue" : "Ieee Access,",
      "citeRegEx" : "Minh et al\\.,? 2018",
      "shortCiteRegEx" : "Minh et al\\.",
      "year" : 2018
    }, {
      "title" : "Generating natural language adversarial examples through probability weighted word saliency",
      "author" : [ "Shuhuai Ren", "Yihe Deng", "Kun He", "Wanxiang Che." ],
      "venue" : "Proceedings of the 57th annual meeting of the association for computational linguistics, pages 1085–",
      "citeRegEx" : "Ren et al\\.,? 2019",
      "shortCiteRegEx" : "Ren et al\\.",
      "year" : 2019
    }, {
      "title" : "Semantically equivalent adversarial rules for debugging nlp models",
      "author" : [ "Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),",
      "citeRegEx" : "Ribeiro et al\\.,? 2018",
      "shortCiteRegEx" : "Ribeiro et al\\.",
      "year" : 2018
    }, {
      "title" : "2020a. Deep attentive learning for stock movement prediction from social media text and company correlations",
      "author" : [ "Ramit Sawhney", "Shivam Agarwal", "Arnav Wadhwa", "Rajiv Ratn Shah" ],
      "venue" : null,
      "citeRegEx" : "Sawhney et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Sawhney et al\\.",
      "year" : 2020
    }, {
      "title" : "Voltage: volatility forecasting via text-audio fusion with graph convolution networks for earnings calls",
      "author" : [ "Ramit Sawhney", "Piyush Khanna", "Arshiya Aggarwal", "Taru Jain", "Puneet Mathur", "Rajiv Shah." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical",
      "citeRegEx" : "Sawhney et al\\.,? 2020b",
      "shortCiteRegEx" : "Sawhney et al\\.",
      "year" : 2020
    }, {
      "title" : "Fast: Financial news and tweet based time aware network for stock trading",
      "author" : [ "Ramit Sawhney", "Arnav Wadhwa", "Shivam Agarwal", "Rajiv Shah." ],
      "venue" : "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Lin-",
      "citeRegEx" : "Sawhney et al\\.,? 2021",
      "shortCiteRegEx" : "Sawhney et al\\.",
      "year" : 2021
    }, {
      "title" : "Universal Adversarial Attacks with Natural Triggers for Text Classification",
      "author" : [ "Liwei Song", "Xinwei Yu", "Hsuan-Tung Peng", "Karthik Narasimhan." ],
      "venue" : "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computa-",
      "citeRegEx" : "Song et al\\.,? 2021",
      "shortCiteRegEx" : "Song et al\\.",
      "year" : 2021
    }, {
      "title" : "Generating adversarial computer programs using optimized obfuscations",
      "author" : [ "Shashank Srikant", "Sijia Liu", "Tamara Mitrovska", "Shiyu Chang", "Quanfu Fan", "Gaoyuan Zhang", "UnaMay O’Reilly" ],
      "venue" : "arXiv preprint arXiv:2103.11882",
      "citeRegEx" : "Srikant et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Srikant et al\\.",
      "year" : 2021
    }, {
      "title" : "Intriguing properties of neural networks",
      "author" : [ "Christian Szegedy", "Wojciech Zaremba", "Ilya Sutskever", "Joan Bruna", "Dumitru Erhan", "Ian Goodfellow", "Rob Fergus." ],
      "venue" : "arXiv preprint arXiv:1312.6199.",
      "citeRegEx" : "Szegedy et al\\.,? 2013",
      "shortCiteRegEx" : "Szegedy et al\\.",
      "year" : 2013
    }, {
      "title" : "The psychological meaning of words: Liwc and computerized text analysis methods",
      "author" : [ "Yla R Tausczik", "James W Pennebaker." ],
      "venue" : "Journal of language and social psychology, 29(1):24–54.",
      "citeRegEx" : "Tausczik and Pennebaker.,? 2010",
      "shortCiteRegEx" : "Tausczik and Pennebaker.",
      "year" : 2010
    }, {
      "title" : "T3: Treeautoencoder regularized adversarial text generation for targeted attack",
      "author" : [ "Boxin Wang", "Hengzhi Pei", "Boyuan Pan", "Qian Chen", "Shuohang Wang", "Bo Li." ],
      "venue" : "Proceedings of the 2020 Conference on Empirical Methods in Natural Language",
      "citeRegEx" : "Wang et al\\.,? 2020",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2020
    }, {
      "title" : "Natural language based financial forecasting: a survey",
      "author" : [ "Frank Z Xing", "Erik Cambria", "Roy E Welsch." ],
      "venue" : "Artificial Intelligence Review, 50(1):49–73.",
      "citeRegEx" : "Xing et al\\.,? 2018",
      "shortCiteRegEx" : "Xing et al\\.",
      "year" : 2018
    }, {
      "title" : "Grey-box Adversarial Attack And Defence For Sentiment Classification",
      "author" : [ "Ying Xu", "Xu Zhong", "Antonio Jimeno Yepes", "Jey Han Lau." ],
      "venue" : "Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational",
      "citeRegEx" : "Xu et al\\.,? 2021",
      "shortCiteRegEx" : "Xu et al\\.",
      "year" : 2021
    }, {
      "title" : "Stock movement prediction from tweets and historical prices",
      "author" : [ "Yumo Xu", "Shay B Cohen." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1970–1979.",
      "citeRegEx" : "Xu and Cohen.,? 2018",
      "shortCiteRegEx" : "Xu and Cohen.",
      "year" : 2018
    }, {
      "title" : "Html: Hierarchical transformerbased multi-task learning for volatility prediction",
      "author" : [ "Linyi Yang", "Tin Lok James Ng", "Barry Smyth", "Riuhai Dong." ],
      "venue" : "Proceedings of The Web Conference 2020, pages 441–451.",
      "citeRegEx" : "Yang et al\\.,? 2020",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2020
    }, {
      "title" : "On the transferability of adversarial attacks against neural text classifier",
      "author" : [ "Liping Yuan", "Xiaoqing Zheng", "Yi Zhou", "Cho-Jui Hsieh", "Kai-Wei Chang." ],
      "venue" : "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages",
      "citeRegEx" : "Yuan et al\\.,? 2021",
      "shortCiteRegEx" : "Yuan et al\\.",
      "year" : 2021
    }, {
      "title" : "Word-level textual adversarial attacking as combinatorial optimization",
      "author" : [ "Yuan Zang", "Fanchao Qi", "Chenghao Yang", "Zhiyuan Liu", "Meng Zhang", "Qun Liu", "Maosong Sun." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational",
      "citeRegEx" : "Zang et al\\.,? 2020",
      "shortCiteRegEx" : "Zang et al\\.",
      "year" : 2020
    }, {
      "title" : "Generating fluent adversarial examples for natural languages",
      "author" : [ "Huangzhao Zhang", "Hao Zhou", "Ning Miao", "Lei Li." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5564–5569, Florence, Italy. Asso-",
      "citeRegEx" : "Zhang et al\\.,? 2019",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2019
    }, {
      "title" : "Deep learning for sentiment analysis: A survey",
      "author" : [ "Lei Zhang", "Shuai Wang", "Bing Liu." ],
      "venue" : "Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery, 8(4):e1253.",
      "citeRegEx" : "Zhang et al\\.,? 2018",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "Crafting adversarial examples for neural machine translation",
      "author" : [ "Xinze Zhang", "Junzhe Zhang", "Zhenhua Chen", "Kun He." ],
      "venue" : "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Confer-",
      "citeRegEx" : "Zhang et al\\.,? 2021",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2021
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "The advance of deep learning based language models are playing a more and more important role in the financial context, including convolutional neutral network (CNN) (Ding et al., 2015), recurrent neutral network (RNN) (Minh et al.",
      "startOffset" : 166,
      "endOffset" : 185
    }, {
      "referenceID" : 25,
      "context" : ", 2015), recurrent neutral network (RNN) (Minh et al., 2018), long short-term memory network (LSTM) (Hiew et al.",
      "startOffset" : 41,
      "endOffset" : 60
    }, {
      "referenceID" : 14,
      "context" : ", 2018), long short-term memory network (LSTM) (Hiew et al., 2019; Sawhney et al., 2021; Hochreiter and Schmidhuber, 1997), graph neutral network (GNN) (Sawhney et al.",
      "startOffset" : 47,
      "endOffset" : 122
    }, {
      "referenceID" : 30,
      "context" : ", 2018), long short-term memory network (LSTM) (Hiew et al., 2019; Sawhney et al., 2021; Hochreiter and Schmidhuber, 1997), graph neutral network (GNN) (Sawhney et al.",
      "startOffset" : 47,
      "endOffset" : 122
    }, {
      "referenceID" : 15,
      "context" : ", 2018), long short-term memory network (LSTM) (Hiew et al., 2019; Sawhney et al., 2021; Hochreiter and Schmidhuber, 1997), graph neutral network (GNN) (Sawhney et al.",
      "startOffset" : 47,
      "endOffset" : 122
    }, {
      "referenceID" : 39,
      "context" : ", 2020a,b), transformer (Yang et al., 2020), autoencoder (Xu and Cohen, 2018), etc.",
      "startOffset" : 24,
      "endOffset" : 43
    }, {
      "referenceID" : 5,
      "context" : "Readers can refer to these survey papers for more details (Dang et al., 2020; Zhang et al., 2018; Xing et al., 2018).",
      "startOffset" : 58,
      "endOffset" : 116
    }, {
      "referenceID" : 43,
      "context" : "Readers can refer to these survey papers for more details (Dang et al., 2020; Zhang et al., 2018; Xing et al., 2018).",
      "startOffset" : 58,
      "endOffset" : 116
    }, {
      "referenceID" : 36,
      "context" : "Readers can refer to these survey papers for more details (Dang et al., 2020; Zhang et al., 2018; Xing et al., 2018).",
      "startOffset" : 58,
      "endOffset" : 116
    }, {
      "referenceID" : 33,
      "context" : "It is now known that text-based deep learning models can be vulnerable to adversarial attacks (Szegedy et al., 2013; Goodfellow et al., 2014).",
      "startOffset" : 94,
      "endOffset" : 141
    }, {
      "referenceID" : 11,
      "context" : "It is now known that text-based deep learning models can be vulnerable to adversarial attacks (Szegedy et al., 2013; Goodfellow et al., 2014).",
      "startOffset" : 94,
      "endOffset" : 141
    }, {
      "referenceID" : 16,
      "context" : "The perturbation can be done at the sentence level (e.g., Xu et al., 2021; Iyyer et al., 2018; Ribeiro et al., 2018), the word level (e.",
      "startOffset" : 51,
      "endOffset" : 116
    }, {
      "referenceID" : 27,
      "context" : "The perturbation can be done at the sentence level (e.g., Xu et al., 2021; Iyyer et al., 2018; Ribeiro et al., 2018), the word level (e.",
      "startOffset" : 51,
      "endOffset" : 116
    }, {
      "referenceID" : 0,
      "context" : ", 2018), the word level (e.g., Zhang et al., 2019; Alzantot et al., 2018; Zang et al., 2020; Jin et al., 2020; Lei et al., 2018; Zhang et al., 2021; Lin et al., 2021), or both (Chen et al.",
      "startOffset" : 24,
      "endOffset" : 166
    }, {
      "referenceID" : 41,
      "context" : ", 2018), the word level (e.g., Zhang et al., 2019; Alzantot et al., 2018; Zang et al., 2020; Jin et al., 2020; Lei et al., 2018; Zhang et al., 2021; Lin et al., 2021), or both (Chen et al.",
      "startOffset" : 24,
      "endOffset" : 166
    }, {
      "referenceID" : 18,
      "context" : ", 2018), the word level (e.g., Zhang et al., 2019; Alzantot et al., 2018; Zang et al., 2020; Jin et al., 2020; Lei et al., 2018; Zhang et al., 2021; Lin et al., 2021), or both (Chen et al.",
      "startOffset" : 24,
      "endOffset" : 166
    }, {
      "referenceID" : 21,
      "context" : ", 2018), the word level (e.g., Zhang et al., 2019; Alzantot et al., 2018; Zang et al., 2020; Jin et al., 2020; Lei et al., 2018; Zhang et al., 2021; Lin et al., 2021), or both (Chen et al.",
      "startOffset" : 24,
      "endOffset" : 166
    }, {
      "referenceID" : 44,
      "context" : ", 2018), the word level (e.g., Zhang et al., 2019; Alzantot et al., 2018; Zang et al., 2020; Jin et al., 2020; Lei et al., 2018; Zhang et al., 2021; Lin et al., 2021), or both (Chen et al.",
      "startOffset" : 24,
      "endOffset" : 166
    }, {
      "referenceID" : 23,
      "context" : ", 2018), the word level (e.g., Zhang et al., 2019; Alzantot et al., 2018; Zang et al., 2020; Jin et al., 2020; Lei et al., 2018; Zhang et al., 2021; Lin et al., 2021), or both (Chen et al.",
      "startOffset" : 24,
      "endOffset" : 166
    }, {
      "referenceID" : 9,
      "context" : "As one example, a fake news (“Two Explosions in the White House and Barack Obama is Injured”) posted by a hacker using the AssociatedPress’s Twitter account on 04/23/2013 erased $136 billion in stock market in just 60 seconds (Fisher, 2013).",
      "startOffset" : 226,
      "endOffset" : 240
    }, {
      "referenceID" : 17,
      "context" : "words, we formulate the task as text-concatenating attack (Jia and Liang, 2017; Le et al., 2021): we implement the attack by injecting new tweets instead of manipulating existing benign tweets.",
      "startOffset" : 58,
      "endOffset" : 96
    }, {
      "referenceID" : 20,
      "context" : "words, we formulate the task as text-concatenating attack (Jia and Liang, 2017; Le et al., 2021): we implement the attack by injecting new tweets instead of manipulating existing benign tweets.",
      "startOffset" : 58,
      "endOffset" : 96
    }, {
      "referenceID" : 41,
      "context" : "we consider the generation task as a combinatorial optimization problem (Zang et al., 2020; Guo et al., 2021).",
      "startOffset" : 72,
      "endOffset" : 109
    }, {
      "referenceID" : 12,
      "context" : "we consider the generation task as a combinatorial optimization problem (Zang et al., 2020; Guo et al., 2021).",
      "startOffset" : 72,
      "endOffset" : 109
    }, {
      "referenceID" : 10,
      "context" : "We consider word replacement and deletion for word perturbation (Garg and Ramakrishnan, 2020; Li et al., 2020).",
      "startOffset" : 64,
      "endOffset" : 110
    }, {
      "referenceID" : 22,
      "context" : "We consider word replacement and deletion for word perturbation (Garg and Ramakrishnan, 2020; Li et al., 2020).",
      "startOffset" : 64,
      "endOffset" : 110
    }, {
      "referenceID" : 41,
      "context" : "Synonym as replacement is widely adopted in the word-level attack since it is a natural choice to preserve semantics (Zang et al., 2020; Dong et al., 2021; Zhang et al., 2019; Jin et al., 2020).",
      "startOffset" : 117,
      "endOffset" : 193
    }, {
      "referenceID" : 7,
      "context" : "Synonym as replacement is widely adopted in the word-level attack since it is a natural choice to preserve semantics (Zang et al., 2020; Dong et al., 2021; Zhang et al., 2019; Jin et al., 2020).",
      "startOffset" : 117,
      "endOffset" : 193
    }, {
      "referenceID" : 42,
      "context" : "Synonym as replacement is widely adopted in the word-level attack since it is a natural choice to preserve semantics (Zang et al., 2020; Dong et al., 2021; Zhang et al., 2019; Jin et al., 2020).",
      "startOffset" : 117,
      "endOffset" : 193
    }, {
      "referenceID" : 18,
      "context" : "Synonym as replacement is widely adopted in the word-level attack since it is a natural choice to preserve semantics (Zang et al., 2020; Dong et al., 2021; Zhang et al., 2019; Jin et al., 2020).",
      "startOffset" : 117,
      "endOffset" : 193
    }, {
      "referenceID" : 18,
      "context" : "Therefore, we replace target words with their synonyms chosen from synonym sets which contain semantically closest words measured by similarity of the GLOVE embedding (Jin et al., 2020).",
      "startOffset" : 167,
      "endOffset" : 185
    }, {
      "referenceID" : 32,
      "context" : "To solve the program, we follow the convex relaxation approach developed in (Srikant et al., 2021).",
      "startOffset" : 76,
      "endOffset" : 98
    }, {
      "referenceID" : 38,
      "context" : "We evaluate our adversarial attack on a stock prediction dataset consisting of 10824 instances including relevant tweets and numerical features of 88 stocks from 2014 to 2016 (Xu and Cohen, 2018).",
      "startOffset" : 175,
      "endOffset" : 195
    }, {
      "referenceID" : 38,
      "context" : "Three models (Stocknet (Xu and Cohen, 2018), FinGRU based on GRU (Cho et al.",
      "startOffset" : 23,
      "endOffset" : 43
    }, {
      "referenceID" : 3,
      "context" : "Three models (Stocknet (Xu and Cohen, 2018), FinGRU based on GRU (Cho et al., 2014) and FinLSTM based on LSTM (Hochreiter and Schmidhuber, 1997)) of binary classification are considered as victims in this paper.",
      "startOffset" : 65,
      "endOffset" : 83
    }, {
      "referenceID" : 15,
      "context" : ", 2014) and FinLSTM based on LSTM (Hochreiter and Schmidhuber, 1997)) of binary classification are considered as victims in this paper.",
      "startOffset" : 34,
      "endOffset" : 68
    }, {
      "referenceID" : 30,
      "context" : "Moreover, we simulate a Long-Only Buy-Hold-Sell strategy (Sawhney et al., 2021; Feng et al., 2019) with vic-",
      "startOffset" : 57,
      "endOffset" : 98
    }, {
      "referenceID" : 8,
      "context" : "Moreover, we simulate a Long-Only Buy-Hold-Sell strategy (Sawhney et al., 2021; Feng et al., 2019) with vic-",
      "startOffset" : 57,
      "endOffset" : 98
    }, {
      "referenceID" : 40,
      "context" : "More importantly, it implies that the attack is not transferable between the two tasks, documenting more evidence on language attack transferability (Yuan et al., 2021; He et al., 2021).",
      "startOffset" : 149,
      "endOffset" : 185
    }, {
      "referenceID" : 13,
      "context" : "More importantly, it implies that the attack is not transferable between the two tasks, documenting more evidence on language attack transferability (Yuan et al., 2021; He et al., 2021).",
      "startOffset" : 149,
      "endOffset" : 185
    }, {
      "referenceID" : 32,
      "context" : "We adopt the crossentropy loss for our attack since it is untargeted attack (Srikant et al., 2021).",
      "startOffset" : 76,
      "endOffset" : 98
    }, {
      "referenceID" : 7,
      "context" : "Furthermore, we also add entropybased regularization to encourage sparsity of optimization variables (Dong et al., 2021).",
      "startOffset" : 101,
      "endOffset" : 120
    }, {
      "referenceID" : 7,
      "context" : "A common workaround for combinatorial optimization is to solve an associated continuous optimization over convex hull (Dong et al., 2021; Srikant et al., 2021).",
      "startOffset" : 118,
      "endOffset" : 159
    }, {
      "referenceID" : 32,
      "context" : "A common workaround for combinatorial optimization is to solve an associated continuous optimization over convex hull (Dong et al., 2021; Srikant et al., 2021).",
      "startOffset" : 118,
      "endOffset" : 159
    }, {
      "referenceID" : 7,
      "context" : "replacement goes with word with highest weight (Dong et al., 2021).",
      "startOffset" : 47,
      "endOffset" : 66
    }, {
      "referenceID" : 38,
      "context" : "As argued in (Xu and Cohen, 2018), the particular thresholds are carefully selected to balance the two classes.",
      "startOffset" : 13,
      "endOffset" : 33
    }, {
      "referenceID" : 38,
      "context" : "A variational Autoencoder (VAE) that takes both tweets and price as input (Xu and Cohen, 2018).",
      "startOffset" : 74,
      "endOffset" : 94
    }, {
      "referenceID" : 3,
      "context" : "All features are encoded sequentially by GRU (Cho et al., 2014) to exploit the temporal dependence.",
      "startOffset" : 45,
      "endOffset" : 63
    }, {
      "referenceID" : 19,
      "context" : "We train the model with an Adam optimizer (Kingma and Ba, 2015) and learning rate of 0.",
      "startOffset" : 42,
      "endOffset" : 63
    }, {
      "referenceID" : 15,
      "context" : "A binary classifier identical to FinGRU, but utilizes LSTM (Hochreiter and Schmidhuber, 1997) to encode temporal dependence.",
      "startOffset" : 59,
      "endOffset" : 93
    }, {
      "referenceID" : 30,
      "context" : "In this paper, we use a simple Long-Only Buy-Hold-Sell strategy (Sawhney et al., 2021; Feng et al., 2019).",
      "startOffset" : 64,
      "endOffset" : 105
    }, {
      "referenceID" : 8,
      "context" : "In this paper, we use a simple Long-Only Buy-Hold-Sell strategy (Sawhney et al., 2021; Feng et al., 2019).",
      "startOffset" : 64,
      "endOffset" : 105
    }, {
      "referenceID" : 32,
      "context" : "does not contribute to attack performance in our experiment as it does in (Srikant et al., 2021).",
      "startOffset" : 74,
      "endOffset" : 96
    }, {
      "referenceID" : 34,
      "context" : "To qualitatively understand what kinds of words and tweets are being selected in the perturbation and retweet, we compare our tweet corpus and the selected word replacements with 15 corpora of different genres in Brown corpus via Linguistic Inquiry and Word Count program (LIWC) (Tausczik and Pennebaker, 2010).",
      "startOffset" : 279,
      "endOffset" : 310
    }, {
      "referenceID" : 24,
      "context" : "As Brown corpus does not have a financial genre, we also use Financial Phrase Bank (Malo et al., 2014).",
      "startOffset" : 83,
      "endOffset" : 102
    } ],
    "year" : 0,
    "abstractText" : "More and more investors and machine learning models rely on social media (e.g., Twitter and Reddit) to gather information and predict movements stock prices. Although textbased models are known to be vulnerable to adversarial attacks, whether stock prediction models have similar vulnerability given necessary constraints is underexplored. In this paper, we experiment with a variety of adversarial attack configurations to fool three stock prediction victim models. We address the task of adversarial generation by solving combinatorial optimization problems with semantics and budget constraints. Our results show that the proposed attack method can achieve consistent success rates and cause significant monetary loss in trading simulation by simply concatenating a perturbed but semantically similar tweet.",
    "creator" : null
  }
}