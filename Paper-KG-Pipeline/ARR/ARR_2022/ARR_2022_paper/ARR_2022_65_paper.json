{
  "name" : "ARR_2022_65_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "MuPAD: A Chinese Multi-Domain Predicate-Argument Dataset",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "As a fundamental NLP task, semantic role labeling (SRL), also known as shallow semantic parsing, aims to capture the major semantic information of a sentence based on predicate-argument structure. Basically, SRL tries to answer “who did what to whom where and when”. Previous works have shown that SRL can help various downstream tasks including information extraction (Bastianelli et al., 2013), machine translation (Shi et al., 2016), reading comprehension (Zhang et al., 2020), plagiarism detection (Paul and Jamal, 2015), etc.\nFigure 1 gives two examples of SRL results. According to the spanning range of semantic roles, there exist two typical representation forms, i.e., word-based and span-based SRL. This work adopts\nthe word-based formulation, in which a semantic role corresponds to a single word. In contrast, spanbased SRL, adopted by most previous datasets, takes a multi-word span as a semantic role. The direction of arcs is from predicates to arguments, and the labels indicate the types of semantic roles. For example, the arc from “买(bought)” to “裙 子(dress)” with a label “patient” means that the semantic role between the predicate “买(bought)” and the argument “裙子(dress)” is “patient”.\nRecently, neural-based Chinese SRL has achieved great progress thanks to the rise of deep learning methods (Marcheggiani et al., 2017; He et al., 2018; Cai et al., 2018), especially of powerful pre-trained language models (PLMs). However, despite the significant improvements, existing studies on Chinese SRL mainly focus on the in-domain setting, where both training and test data are from the same domain (Wang et al., 2015; Guo et al., 2016b; Xia et al., 2017). SRL performance drops dramatically when the domain of test data is different from that of the training data, known as the domain adaptation problem.\nMeanwhile, with the rapid growth of usergenerated web data, cross-domain SRL has be-\ncome an important and challenging task in realistic NLP systems (Jiang and Zhai, 2007; Ramponi and Plank, 2020). However, due to the scarcity of multidomain labeled data, most current researches on SRL still focus on in-domain scenario, and make very limited progress in the domain adaptation task.\nThere are three existing publicly available Chinese SRL datasets, including Chinese Proposition Bank (CPB) (Xue and Palmer, 2005), Chinese NomBank (CNB) (Xue, 2006a), and Chinese SemBank (CSB) (Xia et al., 2017). All the above datasets are in-domain data which mainly contain canonical news texts and magazine/textbook articles, inapplicable to cross-domain research.\nIn order to facilitate future study on crossdomain SRL, this paper presents MuPAD, a multisource predicate-argument dataset in Chinese, consisting of 30,897 sentences and 92,051 predicates, from 6 different domains. Overall, MuPAD has the following important features. (1) Following CSB instead of CPB and CNB, we\nadopt a frame-free annotation methodology, considering that it requires a very high level of linguistic background for defining frames for new predicates, and a lot of new predicates may appear in non-canonical texts. (2) We explicitly annotate omitted core arguments with two special labels, i.e., “hidden-subject” and “hidden-object”, considering that it is ubiquitous that people try to avoid repetition by omitting previous content in context, especially in non-canonical Chinese texts. Figure 2 gives an example. (3) We adopt strict double annotation for each sentence in order to improve quality. If two annotators submit inconsistent results, a senior annotator determines the final answer. We also compile 53-page annotation guidelines to be studied and referenced by the annotators.\nFinally, we employ multi-task learning (MTL) framework over the popular and competitive model (Cai et al., 2018) for SRL and conduct preliminary cross-domain SRL experiments on our dataset. Moreover, we use CPB2.0 as a heterogeneous\ndataset and BERT to further boost the performance of cross-domain SRL."
    }, {
      "heading" : "2 Related Work",
      "text" : "SRL Corpora. Large-scale annotated data is a prerequisite to developing high-performance SRL systems (Fürstenau and Lapata, 2009; Xia et al., 2020). The most representative ones in English are FrameNet (Baker et al., 1998), PropBank (Kingsbury and Palmer, 2002), and NomBank (Meyers et al., 2004). FrameNet is a large-scale manually annotated semantic lexicon resource, which describes the semantic frames underlying the meanings of words. PropBank and NomBank are built by adding predicate-argument structures to the constituents of syntactic parser trees in the Penn Treebank (Marcus et al., 1993). Following FrameNet, PropBank and NomBank also use frames to guide argument and semantic role annotations. However, the development of frames is both time-consuming and labor-intensive, which requires annotators to be equipped with a strong linguistic background. Moreover, the texts of the two datasets are mainly from the news domain (Wall Street Journal). There is one widely used out-of-domain data (Brown) of PropBank (Carreras and Màrquez, 2005) that only has 426 sentences, confining the progress of English cross-domain SRL.\nFor Chinese, CPB (Xue and Palmer, 2005), CNB (Xue, 2006a), and CSB (Xia et al., 2017) are the most commonly used SRL corpora. CPB and CNB annotate predicate-argument relations to the sentences in the Chinese Treebank (Marcus et al., 1993), which also need pre-defined frames. Differently, CSB uses non-predicate-specific roles, which are defined for predicates with similar syntactic and semantic regularities. The texts of CPB and CNB are mainly from Xinhua newswire (mainland China), Hong Kong news, and Sinorama Magazine (Taiwan) (Hajic et al., 2009), and CSB texts are from online articles and news. These corpora mainly belong to the same news domain, which can hardly be used in Chinese SRL domain adaptation. Therefore, we annotate a large-scale Chinese multi-domain SRL dataset, aiming to promote the development of Chinese SRL domain adaptation.\nDomain adaptation. Domain adaptation has been an important and challenging research topic in NLP (Daumé III, 2007; Ganin and Lempitsky, 2015; Guo et al., 2016a; Kim et al., 2016, 2017; Clark et al., 2018; Zhao et al., 2018). Kim\net al. (2016) propose a neural shared-private model for the cross-domain slot sequence tagging task, which utilizes separate BiLSTM encoders to obtain domain-invariant and domain-specific representations, achieving significant improvements on all domains. Jia et al. (2019) improve the domain adaptation power of multi-task learning by utilizing domain and task embeddings to generate domainrelated and task-related model parameters, which has been proven effective for unsupervised crossdomain NER. Li et al. (2019b) present a tri-training model for cross-domain transfer learning, in which they generate additional high-quality auto-labeled training examples from unlabeled data with iterative training. To facilitate cross-domain Chinese dependency parsing research, Li et al. (2019a) present one large-scale cross-domain dataset. Based on our newly annotated multi-domain Chinese SRL data, we conduct preliminary experiments, providing a strong baseline for future work."
    }, {
      "heading" : "3 Data Annotation",
      "text" : "In this section, we describe the details of the data annotation procedure. We compile a detailed and systematic annotation guideline for annotators’ reference. Compared with previous guidelines that almost adopt span-based argument form, our guideline proposes to use word-based argument form, which is free from distinguishing the argument boundary. Moreover, our guideline does not require pre-defined frames for predicates, which are difficult and time-consuming to build and update. During the annotation process, we adopt strict double annotation for all the sentences to guarantee quality. Finally, we construct the first Chinese highquality, large-scale, multi-domain open predicateargument dataset (MuPAD) covering six domains, i.e., news, product blog, product comment, web fiction, legal, and medical domains.\nAnnotation guideline. After several months of investigation on previous SRL guidelines, we compile a frame-free guideline that adopts word-based argument and explicitly annotates omitted core arguments. We design two coarse-grained categories according to the importance of the semantic role and further divide them into 24 fine-grained labels to capture the semantic relationships between predicates and arguments, as shown in Table 1. It is worth mentioning that in order to understand the sentence more completely, we for the first time define “hidden-subject” and “hidden-object” labels\nto explicitly annotate the omitted core arguments of a predicate in a sentence. Finally, we compile a 53-page guideline with detailed illustrations of each label and corresponding concrete examples. The current version of our guideline is attached in our supplementary material. We also gradually improve our guideline according to the feedback during the annotation.\nData selection. For source domain data, we choose all the 10.3K sentences with 16.5K predicates from Chinese SemBank (Xia et al., 2017) and randomly select 6.7K sentences with 24.5 predicates from CoNLL-2009 Chinese dataset (Hajic et al., 2009), all of which are canonical newswire resources.\nFor target domain data, we select 51K predicates (14K sentences) in total from five specific domains, including product blog (PB), product comment (PC), web fiction (ZX), legal (LAW), and medical (MED) domains. Both PB and PC are noncanonical data from Taobao1, where PB is from Taobao headline website, and PC is comments on products written by users. ZX is selected from a popular Chinese fantasy novel called “Zhuxian” (ZX, known as “Jade Dynasty”). LAW is extracted from the China artificial intelligence law challenge 20182. MED is crawled from the medical sector of People’s Daily Online and Sina.com.\nWe give predicates to the annotators during the annotation process. For source domain data, we directly choose their predicates in Chinese SemBank and CoNLL-2009 Chinese dataset. For target domains, which have already been annotated with syntactic information (Li et al., 2019a), we choose their predicates according to their syntactic information and a dictionary extracted from Chinese frames3.\nQuality Control. We employ 23 undergraduate students as part-time annotators and select five annotators who have a lot of experience in data annotation as expert annotators to handle annotation inconsistency issues. Before the formal annotation, each annotator is trained for several hours to be familiar with the guideline and our annotation tool. During the annotation process, we adopt a strict double annotation workflow to guarantee the quality of the annotated data. Specifically, each task is\n1http://www.taobao.com 2http://cail.cipsc.org.cn:2018/ 3https://verbs.colorado.edu/chinese/cpb/html_frames\nrandomly assigned to two annotators to annotate independently. If the submissions from two annotators are the same, the consistent answer is taken as the final answer. Otherwise, the task is assigned to a third expert annotator to decide the final answer by comparing and analyzing the inconsistent submissions. All the annotators are paid for their work. The average salary is 28 RMB per hour.\nAnnotation tool. We build a browser-based annotation tool to support and manage the double annotation workflow of the Chinese SRL annotation task. Given a task, the annotation tool highlights the predicate with a red circle, and the annotators are asked to annotate all the arguments of the marked predicate. If the marked predicate is not common verbs, nominal verbs, or adjectives, as defined in our guideline, the annotators are asked to click a checkbox to inform us."
    }, {
      "heading" : "4 Analysis on MuPAD",
      "text" : "In this section, we analyze the MuPAD dataset from different perspectives to gain more insights.\nAnnotation consistency. As aforementioned, each task is assigned to two annotators. If the two submissions are inconsistent, a third expert annotator is asked to handle the inconsistency and decide the final results. The first two rows in Table 2 show the predicate- and argument-wise (predand arg-wise) annotation consistency ratios in all domains.\nThe pred-wise consistency ratio is defined as #PredannoA∩annoB #PredannoA∪annoB , where the denominator is the total\nnumber of predicates submitted by all annotator pairs, and the numerator is the number of predicates with consistent arguments from annotator pairs. We can see that the pred-wise annotation consistency ratios in most domains are lower than 60%. Even the highest pred-wise consistency ratio, which is achieved in the PC domain, is only 71.23%. This means that more than a quarter of the annotation tasks need to be further checked by a third expert annotator, demonstrating the difficulty of the SRL annotation task and the importance of performing strict double annotation to guarantee data quality.\nIn addition, it is worth noting that the pred-wise consistency ratio in PC domain is much higher than that in the other five domains. We believe this is related to the average number of arguments per predicate. For further investigation, we calculate the average number of arguments and find the number of average arguments per predicate is the lowest in PC domain. Therefore, it is relatively easier for the annotators to recognize the arguments in PC domain.\nThe arg-wise consistency ratio is defined as #ArgannoA∩annoB #ArgannoA∪annoB\n, where the denominator is the total number of arguments submitted by all annotator pairs, and the numerator is the number of arguments that receive the same arcs and labels from two annotators. As shown in Table 2, the arg-wise consistency ratios in most of the domains are lower than 75%, excepting that PC achieves the highest arg-wise consistency ratio of 83.63%.\nAnnotation accuracy. In the third row of Table 2, we present the argument-wise (arg-wise) annotation accuracy. The annotation accuracies in all domains are more than 80%, indicating that our guideline is reasonable, which ensures the quality of annotation data.\nTo gain more insights into the accuracy regarding different labels, we select the labels with high proportions of 5 core and 2 non-core roles according to the proportion of labels in source domain data and calculate their accuracies in Table 2. As we can see, “hidden-subject” achieves the highest average accuracy, demonstrating the omitted subject is easy to recognize. The lowest average accuracy is 82.78% on “loc”, probably because it is a non-core label with the lowest proportion of all the labels and is prone to be missed by the annotators.\nLabel distribution. Figure 2 illustrates the label distribution in all the domains. We choose 2 core labels and 2 non-core labels with high proportions in source domain data. Besides, we also choose “loc” and “hidden-object” to analyze due to their characteristic distributions in different domains. From Figure 2, we find that these target domains have different characteristics. PC and PB have more omitted core arguments (i.e., “hidden-subject” and “hidden-object”), which shows the texts in these two domains are more non-canonical.\nIn addition, LAW has more additional semantic roles than other domains, such as “time”, “loc”, etc. This is due to the fact that the elements (e.g., time and location) of legal cases in LAW should be described in detail.\nBesides, there are more “agent” roles and fewer omitted arguments in ZX, showing that ZX is more canonical. Furthermore, on the whole, the label\ndistribution of ZX and the source domain is the most similar, indicating that the knowledge of the source domain can be easier to transfer to ZX.\nLooking into the distribution of hidden-subject and hidden-object labels in all the domains, we find that hidden labels exist in all the domains, especially in non-canonical texts like PC and PB, demonstrating the necessity of annotating hidden labels. In addition, “hidden-subject” takes a higher proportion than “hidden-object” in all domains, reflecting that the subject role of the predicate in Chinese sentences is often omitted.\nDifficulty in annotation. To further analyze the difficulty in annotation, we calculate the proportion of the arguments with the same arcs but different labels from two annotators among all the arguments with the same arcs. We find that the confusion pattern “agent, expe” accounts for the largest proportion of 22.23%, which means the label “agent” is prone to be confused with “expe”. The reason for the confusion may be the part-of-speech (POS) of predicates. The part-of-speech (POS) of the predicates can affect the argument labels. However, the POS for some predicates is subtle and vague in Chinese, confusing the argument labels. Taking the sentence “纽扣(Buttons) 一天(a day) 坏(getting broken)一个(one)” as an example, “坏” may be misunderstood as an adjective and thus the argument “纽扣” is incorrectly annotated as “expe”. Actually, “坏” acts as a verb in this sentence and the correct label of “纽扣” is “agent”. The second confusion pattern is “patient, pred-patient”, with a proportion of 12.6%, due to the misunderstanding of the POS of the augment. It is also difficult for annotators to distinguish “agent” and “patient”. For example, in the sentence “新(new)\n衣服(cloths)被(was)弄脏了(soiled)”, the preposition “被” is omitted. As a result, the label of “新(new)衣服(cloths)”, which is “patient”, may be confused with “agent” due to the omission."
    }, {
      "heading" : "5 Approach",
      "text" : "Based on our newly annotated multi-domain Chinese SRL data MuPAD, we conduct preliminary experiments, aiming to provide strong benchmark results for future work. Specifically, we present a MTL approach to improve the performance of multi-domain SRL by learning from multiple heterogeneous datasets simultaneously. We also enhance the model with the contextualized word representation BERT for further improvement.\nFollowing previous works (Marcheggiani et al., 2017; He et al., 2018; Cai et al., 2018), we treat SRL parsing as a sequence labeling problem and aim to find the tag sequence ŷ with the highest score:\nŷ = argmax y∈Y(w) score(w,y) (1)\nwhere yi ∈ L is the label of the i-th word wi. L is the semantic role label set, which contains 24 semantic role labels and an extra “None” label to indicate there is no semantic relationship between the concerned word and the predicate. Y(w) represents all the possible label sequence."
    }, {
      "heading" : "5.1 Basic Biaffine Parser",
      "text" : "In this work, we adopt the widely used biaffine parser (Dozat and Manning, 2017) as our baseline, and build the MTL framework based on it. Figure 4 shows the model architecture of the biaffine parser.\nFirst, the biaffine parser takes the concatenation of the pre-trained word embedding eprei , the ran-\ndomly initialized word embedding eri , the word representation rci and the predicate embedding e p i as the input, i.e., xi = e pre i ⊕ eri ⊕ rci ⊕ e p i , where rci represents the CNN output of the word constituent characters. Then, the input representation xi is fed into a three-layer BiLSTM to obtain its context-aware representation hi. After that, two separate MLPs are applied over hi to get two lowerdimensional representation hpredi (as predicate) and hargi (as candidate arguments). Finally, the score of the label between the predicate and the argument is computed via a biaffine operation. During training, we adopt the local cross-entropy loss.\nTo obtain multi-domain results on the basic biaffine parser, we train the parser on source domain data and make predictions on target domain data using the source parser."
    }, {
      "heading" : "5.2 Combining Multi-Domain Data with MTL",
      "text" : "The goal of MTL is to improve model performance by learning the underlying common knowledge from multiple related tasks (Collobert and We-\nston, 2008; Guo et al., 2016a; Li et al., 2019a). MTL framework can be naturally used for multidomain learning by utilizing multiple heterogeneous datasets and considering each dataset as a single task to improve the performance in targetdomain dataset.\nAs shown in Figure 5, we extend the original biaffine parser to the MTL framework to accommodate multi-domain SRL. In this work, we treat our MuPAD as the target data, and treat CPB2.0 as the auxiliary data to provide additional semantic information to gain improvements in MuPAD. Specifically, the SRL parsing on MuPAD data and CPB2.0 data are considered as two separate tasks. They share the same word/predicate embeddings and BiLSTM parameters. Over the shared BiLSTMs, two separate MLPs and biaffines are employed for MuPAD and CPB2.0 SRL parsing respectively."
    }, {
      "heading" : "5.3 Enhancing with BERT",
      "text" : "Recently proposed pre-trained language model BERT (Devlin et al., 2019) has shown its great power in learning and capturing contextualized representations and has proved to be beneficial in a variety of NLP tasks, such as information retrieval (Yang et al., 2019b), question answering (Yang et al., 2019a), and word segmentation (Huang et al., 2020). In this work, we use BERT to extract the contextualized representations for words and treat them as additional features to augment the input representation, i.e., xi = e pre i ⊕ eri ⊕ rci ⊕ e p i ⊕ eBERTi ."
    }, {
      "heading" : "6 Experiments",
      "text" : "Data. For source domain data, we re-annotate 6,682 sentences randomly selected from CoNLL2009 (Hajic et al., 2009) and all the sentences from\nChinese SemBank (Xia et al., 2017) following our newly compiled guideline. For target domain data, we use our annotated MuPAD which contains 5 domains, including PB, PC, ZX, LAW, and MED. The data statistics for source and target domain data are shown in Table 3. For the auxiliary data used to provide additional semantic information to improve multi-domain SRL parsing, we randomly select 13,170 sentences with 72,616 predicates from CPB2.0 (Xue, 2006b), which is newswire data.\nEvaluation metric. We adopt the standard precision (#Argcorrect#Argpred ), recall ( #Argcorrect #Arggold ) and F1 score ( 2PRP+R ) for SRL evaluation.\nSettings. We implement the SRL model of Cai et al. (2018) with PyTorch and follow their hyperparameter settings, such as the dimensions of embeddings, learning rate, and dropout ratios. We use bert-base-chinese4 to obtain contextualized representations for words, and the dimension of the BERT representation is 768. During training, early stopping is triggered if the peak performance in dev data does not increase in 50 consecutive iterations."
    }, {
      "heading" : "6.1 Multi-Domain Results of Baseline",
      "text" : "The first row of Table 4 presents the results in the source/target domain dev/test data using the base biaffine parser trained on the source data.\nFirst, it is obvious that the performance in all the five target domains drops dramatically compared with the results on source data, with the gap of more than 18% in F1. This indicates that the model trained on source data has a challenge in making reliable predictions on target domain data due to the distributional mismatch between the different domains. Second, we find that the basic biaffine parser performs better on ZX and LAW compared with the other three target domain data, i.e., PB, PC, and MED. The probable reason is that ZX and LAW, which are novel and legal case, respectively, are more canonical in text. Therefore, ZX and LAW are more similar to the newswire source training data than the other three target domain data, leading to better performance in ZX and LAW dev/test. Third, PB has the lowest F1 score in both dev and test. This can be explained by the fact that PB is non-canonical data from Taobao headline website. The dissimilarity between the source training data and PB target data causes the low performance.\n4https://huggingface.co/bert-base-chinese"
    }, {
      "heading" : "6.2 Multi-Domain Results of MTL",
      "text" : "As shown in the second row of Table 4, benefiting from the additional semantic information provided by the auxiliary CPB2.0 data using the MTL model, the SRL performance in all the domains are improved compared with the baseline model. This indicates that the MTL model is effective in capturing and learning the underlying common knowledge from multiple heterogeneous data to gain improvements for multi-domain SRL.\nBy comparing the improvements brought by MTL model in all the domains, we find that MED data and source data obtain the largest gains by 9.65%/8.56% and 5%/5.03% in dev/test, respectively. The main reason is that both MED and source data are canonical newswire data, similar to the auxiliary newswire CPB2.0 data. The improvement in LAW is the smallest. This can be explained by the difference in the label distribution in MED and CPB2.0. For example, as mentioned in Section 4, the label “time” and “loc” account for larger proportion (13.95% and 6.14% respectively) in LAW than in other 5 domains. However, in CPB2.0, the proportions of “time” and “loc” are only 6.27% and 3.50% (about half of that in LAW), and thus cannot provide much more additional information to increase the performance of these labels."
    }, {
      "heading" : "6.3 Combining BERT",
      "text" : "The second major row of Table 4 shows the results of the baseline and MTL model combined with BERT representations. We can see that the results of both “Baseline+BERT” and “MTL+BERT” consistently increase by large margins compared with the corresponding models without BERT (as shown\nin the first major row of table 4), demonstrating the great power of BERT in contextualized representation. When comparing “MTL+BERT” with “Baseline+BERT”, we find that the MTL model with BERT gives better or comparable results in 5 of the 6 domains, with an average increase of 0.5%, showing that the MTL model is effective in utilizing multiple heterogeneous data and can complement the information obtained from BERT representations."
    }, {
      "heading" : "7 Conclusion",
      "text" : "This paper presents a Chinese multi-domain predicate-argument dataset, named as MuPAD, which consists of 30,897 sentences with 92,051 predicates and covers 6 different domains. Particularly, we adopt a frame-free annotation methodology, which does not require high-level linguistic background for defining frames for large amounts of new predicates in multi-domain data. Besides, considering the ubiquitousness of omission phenomena in Chinese, we explicitly annotate omitted core arguments with two special designed labels “hidden-subject” and “hidden-object” for better semantic understanding. To ensure annotation quality, we adopt strict double annotation and ask a third expert to handle annotation inconsistency. We also perform analysis on MuPAD from different perspectives. Finally, we conduct preliminary experiments with the MTL framework on our newly annotated MuPAD, hoping to provide benchmark results for future exploration on Chinese cross-domain SRL."
    } ],
    "references" : [ {
      "title" : "The berkeley framenet project",
      "author" : [ "Collin F Baker", "Charles J Fillmore", "John B Lowe." ],
      "venue" : "Proceedings of COLING-ACL, pages 86–90.",
      "citeRegEx" : "Baker et al\\.,? 1998",
      "shortCiteRegEx" : "Baker et al\\.",
      "year" : 1998
    }, {
      "title" : "Textual inference and meaning representation in human robot interaction",
      "author" : [ "Emanuele Bastianelli", "Giuseppe Castellucci", "Danilo Croce", "Roberto Basili." ],
      "venue" : "Proceedings of JSSP, pages 65–69.",
      "citeRegEx" : "Bastianelli et al\\.,? 2013",
      "shortCiteRegEx" : "Bastianelli et al\\.",
      "year" : 2013
    }, {
      "title" : "A full end-to-end semantic role labeler, syntacticagnostic over syntactic-aware",
      "author" : [ "Jiaxun Cai", "Shexia He", "Zuchao Li", "Hai Zhao" ],
      "venue" : "In Proceedings of COLING,",
      "citeRegEx" : "Cai et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Cai et al\\.",
      "year" : 2018
    }, {
      "title" : "Introduction to the CoNLL-2005 shared task: Semantic role labeling",
      "author" : [ "Xavier Carreras", "Lluís Màrquez." ],
      "venue" : "Proceedings of CoNLL, pages 152–164.",
      "citeRegEx" : "Carreras and Màrquez.,? 2005",
      "shortCiteRegEx" : "Carreras and Màrquez.",
      "year" : 2005
    }, {
      "title" : "Semi-supervised sequence modeling with cross-view training",
      "author" : [ "Kevin Clark", "Minh-Thang Luong", "Christopher D. Manning", "Quoc V. Le." ],
      "venue" : "Proceedings of EMNLP, pages 1914–1925.",
      "citeRegEx" : "Clark et al\\.,? 2018",
      "shortCiteRegEx" : "Clark et al\\.",
      "year" : 2018
    }, {
      "title" : "A unified architecture for natural language processing: deep neural networks with multitask learning",
      "author" : [ "Ronan Collobert", "Jason Weston." ],
      "venue" : "Proceedings of ICML, pages 160–167.",
      "citeRegEx" : "Collobert and Weston.,? 2008",
      "shortCiteRegEx" : "Collobert and Weston.",
      "year" : 2008
    }, {
      "title" : "Frustratingly easy domain adaptation",
      "author" : [ "Hal Daumé III." ],
      "venue" : "Proceedings of ACL, pages 256–263.",
      "citeRegEx" : "III.,? 2007",
      "shortCiteRegEx" : "III.",
      "year" : 2007
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of NAACL-HLT, pages 4171– 4186.",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Deep biaffine attention for neural dependency parsing",
      "author" : [ "Timothy Dozat", "Christopher D. Manning." ],
      "venue" : "Proceedings of ICLR.",
      "citeRegEx" : "Dozat and Manning.,? 2017",
      "shortCiteRegEx" : "Dozat and Manning.",
      "year" : 2017
    }, {
      "title" : "Semisupervised semantic role labeling",
      "author" : [ "Hagen Fürstenau", "Mirella Lapata." ],
      "venue" : "Proceedings of EACL, pages 220–228.",
      "citeRegEx" : "Fürstenau and Lapata.,? 2009",
      "shortCiteRegEx" : "Fürstenau and Lapata.",
      "year" : 2009
    }, {
      "title" : "Unsupervised domain adaptation by backpropagation",
      "author" : [ "Yaroslav Ganin", "Victor Lempitsky." ],
      "venue" : "Proceedings of ICML, pages 1180–1189.",
      "citeRegEx" : "Ganin and Lempitsky.,? 2015",
      "shortCiteRegEx" : "Ganin and Lempitsky.",
      "year" : 2015
    }, {
      "title" : "A universal framework for inductive transfer parsing across multi-typed treebanks",
      "author" : [ "Jiang Guo", "Wanxiang Che", "Haifeng Wang", "Ting Liu." ],
      "venue" : "Proceedings of COLING, pages 12–22.",
      "citeRegEx" : "Guo et al\\.,? 2016a",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2016
    }, {
      "title" : "A unified architecture for semantic role labeling and relation classification",
      "author" : [ "Jiang Guo", "Wanxiang Che", "Haifeng Wang", "Ting Liu", "Jun Xu." ],
      "venue" : "Proceedings of COLING, pages 1264–1274.",
      "citeRegEx" : "Guo et al\\.,? 2016b",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2016
    }, {
      "title" : "Syntax for semantic role labeling, to be, or not to be",
      "author" : [ "Shexia He", "Zuchao Li", "Hai Zhao", "Hongxiao Bai." ],
      "venue" : "Proceedings of ACL, pages 2061–2071.",
      "citeRegEx" : "He et al\\.,? 2018",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2018
    }, {
      "title" : "Towards fast and accurate neural Chinese word segmentation with multi-criteria learning",
      "author" : [ "Weipeng Huang", "Xingyi Cheng", "Kunlong Chen", "Taifeng Wang", "Wei Chu." ],
      "venue" : "Proceedings of COLING, pages 2062– 2072.",
      "citeRegEx" : "Huang et al\\.,? 2020",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2020
    }, {
      "title" : "Crossdomain NER using cross-domain language modeling",
      "author" : [ "Chen Jia", "Liang Xiao", "Yue Zhang." ],
      "venue" : "Proceedings of ACL, pages 2464–2474.",
      "citeRegEx" : "Jia et al\\.,? 2019",
      "shortCiteRegEx" : "Jia et al\\.",
      "year" : 2019
    }, {
      "title" : "Instance weighting for domain adaptation in nlp",
      "author" : [ "Jing Jiang", "Chengxiang Zhai." ],
      "venue" : "Proceedings of ACL, pages 264–271.",
      "citeRegEx" : "Jiang and Zhai.,? 2007",
      "shortCiteRegEx" : "Jiang and Zhai.",
      "year" : 2007
    }, {
      "title" : "Adversarial adaptation of synthetic or stale data",
      "author" : [ "Young-Bum Kim", "Karl Stratos", "Dongchan Kim." ],
      "venue" : "Proceedings of ACL, pages 1297–1307.",
      "citeRegEx" : "Kim et al\\.,? 2017",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2017
    }, {
      "title" : "Frustratingly easy neural domain adaptation",
      "author" : [ "Young-Bum Kim", "Karl Stratos", "Ruhi Sarikaya." ],
      "venue" : "Proceedings of COLING, pages 387–396.",
      "citeRegEx" : "Kim et al\\.,? 2016",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2016
    }, {
      "title" : "From treebank to propbank",
      "author" : [ "Paul Kingsbury", "Martha Palmer" ],
      "venue" : null,
      "citeRegEx" : "Kingsbury and Palmer.,? \\Q2002\\E",
      "shortCiteRegEx" : "Kingsbury and Palmer.",
      "year" : 2002
    }, {
      "title" : "Semi-supervised domain adaptation for dependency parsing",
      "author" : [ "Zhenghua Li", "Xue Peng", "Min Zhang", "Rui Wang", "Luo Si." ],
      "venue" : "Proceedings of ACL, pages 2386–2395.",
      "citeRegEx" : "Li et al\\.,? 2019a",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Cross-domain transfer learning for dependency parsing",
      "author" : [ "Zuchao Li", "Junru Zhou", "Hai Zhao", "Rui Wang." ],
      "venue" : "Proceedings of NLPCC, pages 835–844.",
      "citeRegEx" : "Li et al\\.,? 2019b",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "A simple and accurate syntax-agnostic neural model for dependency-based semantic role labeling",
      "author" : [ "Diego Marcheggiani", "Anton Frolov", "Ivan Titov." ],
      "venue" : "Proceedings of CoNLL, pages 411–420.",
      "citeRegEx" : "Marcheggiani et al\\.,? 2017",
      "shortCiteRegEx" : "Marcheggiani et al\\.",
      "year" : 2017
    }, {
      "title" : "Building a large annotated corpus of english: The penn treebank",
      "author" : [ "Mitchell Marcus", "Beatrice Santorini", "Mary Ann Marcinkiewicz." ],
      "venue" : "Comput. Linguistics, 19:313–330.",
      "citeRegEx" : "Marcus et al\\.,? 1993",
      "shortCiteRegEx" : "Marcus et al\\.",
      "year" : 1993
    }, {
      "title" : "Annotating noun argument structure for nombank",
      "author" : [ "Adam Meyers", "Ruth Reeves", "Catherine Macleod", "Rachel Szekely", "Veronika Zielinska", "Brian Young", "Ralph Grishman." ],
      "venue" : "Proceedings of LREC, volume 4, pages 803–806.",
      "citeRegEx" : "Meyers et al\\.,? 2004",
      "shortCiteRegEx" : "Meyers et al\\.",
      "year" : 2004
    }, {
      "title" : "An improved srl based plagiarism detection technique using sentence ranking",
      "author" : [ "Merin Paul", "Sangeetha Jamal." ],
      "venue" : "Procedia Computer Science, 46:223–230.",
      "citeRegEx" : "Paul and Jamal.,? 2015",
      "shortCiteRegEx" : "Paul and Jamal.",
      "year" : 2015
    }, {
      "title" : "Neural unsupervised domain adaptation in nlp-a survey",
      "author" : [ "Alan Ramponi", "Barbara Plank." ],
      "venue" : "Proceedings of COLING, pages 6838–6855.",
      "citeRegEx" : "Ramponi and Plank.,? 2020",
      "shortCiteRegEx" : "Ramponi and Plank.",
      "year" : 2020
    }, {
      "title" : "Knowledge-based semantic embedding for machine translation",
      "author" : [ "Chen Shi", "Shujie Liu", "Shuo Ren", "Shi Feng", "Mu Li", "Ming Zhou", "Xu Sun", "Houfeng Wang." ],
      "venue" : "Proceedings of ACL, pages 2245– 2254.",
      "citeRegEx" : "Shi et al\\.,? 2016",
      "shortCiteRegEx" : "Shi et al\\.",
      "year" : 2016
    }, {
      "title" : "Chinese semantic role labeling with bidirectional recurrent neural networks",
      "author" : [ "Zhen Wang", "Tingsong Jiang", "Baobao Chang", "Zhifang Sui." ],
      "venue" : "Proceedings of EMNLP, pages 1626–1631.",
      "citeRegEx" : "Wang et al\\.,? 2015",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2015
    }, {
      "title" : "A progressive learning approach to Chinese srl using heterogeneous data",
      "author" : [ "Qiaolin Xia", "Lei Sha", "Baobao Chang", "Zhifang Sui." ],
      "venue" : "Proceedings of ACL, pages 2069–2077.",
      "citeRegEx" : "Xia et al\\.,? 2017",
      "shortCiteRegEx" : "Xia et al\\.",
      "year" : 2017
    }, {
      "title" : "Semantic role labeling with heterogeneous syntactic knowledge",
      "author" : [ "Qingrong Xia", "Rui Wang", "Zhenghua Li", "Yue Zhang", "Min Zhang." ],
      "venue" : "Proceedings of COLING, pages 2979–2990.",
      "citeRegEx" : "Xia et al\\.,? 2020",
      "shortCiteRegEx" : "Xia et al\\.",
      "year" : 2020
    }, {
      "title" : "Annotating the predicateargument structure of Chinese nominalizations",
      "author" : [ "Nianwen Xue." ],
      "venue" : "Proceedings of LREC, pages 1382–1387.",
      "citeRegEx" : "Xue.,? 2006a",
      "shortCiteRegEx" : "Xue.",
      "year" : 2006
    }, {
      "title" : "Semantic role labeling of nominalized predicates in Chinese",
      "author" : [ "Nianwen Xue." ],
      "venue" : "Proceedings of NAACL-HLT, pages 431–438.",
      "citeRegEx" : "Xue.,? 2006b",
      "shortCiteRegEx" : "Xue.",
      "year" : 2006
    }, {
      "title" : "Automatic semantic role labeling for chinese verbs",
      "author" : [ "Nianwen Xue", "Martha Palmer." ],
      "venue" : "Proceedings of IJCAI, volume 5, pages 1160–1165.",
      "citeRegEx" : "Xue and Palmer.,? 2005",
      "shortCiteRegEx" : "Xue and Palmer.",
      "year" : 2005
    }, {
      "title" : "End-to-end open-domain question answering with bertserini",
      "author" : [ "Wei Yang", "Yuqing Xie", "Aileen Lin", "Xingyu Li", "Luchen Tan", "Kun Xiong", "Ming Li", "Jimmy Lin." ],
      "venue" : "Proceedings of NAACL-HLT, pages 72–77.",
      "citeRegEx" : "Yang et al\\.,? 2019a",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "Simple applications of bert for ad hoc document retrieval",
      "author" : [ "Wei Yang", "Haotian Zhang", "Jimmy Lin." ],
      "venue" : "volume abs/1903.10972.",
      "citeRegEx" : "Yang et al\\.,? 2019b",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "Semantics-aware BERT for language understanding",
      "author" : [ "Zhuosheng Zhang", "Yuwei Wu", "Hai Zhao", "Zuchao Li", "Shuailiang Zhang", "Xi Zhou", "Xiang Zhou." ],
      "venue" : "Proceedings of AAAI, pages 9628–9635.",
      "citeRegEx" : "Zhang et al\\.,? 2020",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2020
    }, {
      "title" : "Adversarial multiple source domain adaptation",
      "author" : [ "Han Zhao", "Shanghang Zhang", "Guanhang Wu", "José MF Moura", "Joao P Costeira", "Geoffrey J Gordon." ],
      "venue" : "Proceedings of ICLR, pages 8559–8570.",
      "citeRegEx" : "Zhao et al\\.,? 2018",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Previous works have shown that SRL can help various downstream tasks including information extraction (Bastianelli et al., 2013), machine translation (Shi et al.",
      "startOffset" : 102,
      "endOffset" : 128
    }, {
      "referenceID" : 27,
      "context" : ", 2013), machine translation (Shi et al., 2016), reading comprehension (Zhang et al.",
      "startOffset" : 29,
      "endOffset" : 47
    }, {
      "referenceID" : 36,
      "context" : ", 2016), reading comprehension (Zhang et al., 2020), plagiarism detection (Paul and Jamal, 2015), etc.",
      "startOffset" : 31,
      "endOffset" : 51
    }, {
      "referenceID" : 25,
      "context" : ", 2020), plagiarism detection (Paul and Jamal, 2015), etc.",
      "startOffset" : 30,
      "endOffset" : 52
    }, {
      "referenceID" : 22,
      "context" : "Recently, neural-based Chinese SRL has achieved great progress thanks to the rise of deep learning methods (Marcheggiani et al., 2017; He et al., 2018; Cai et al., 2018), especially of powerful pre-trained language models (PLMs).",
      "startOffset" : 107,
      "endOffset" : 169
    }, {
      "referenceID" : 13,
      "context" : "Recently, neural-based Chinese SRL has achieved great progress thanks to the rise of deep learning methods (Marcheggiani et al., 2017; He et al., 2018; Cai et al., 2018), especially of powerful pre-trained language models (PLMs).",
      "startOffset" : 107,
      "endOffset" : 169
    }, {
      "referenceID" : 2,
      "context" : "Recently, neural-based Chinese SRL has achieved great progress thanks to the rise of deep learning methods (Marcheggiani et al., 2017; He et al., 2018; Cai et al., 2018), especially of powerful pre-trained language models (PLMs).",
      "startOffset" : 107,
      "endOffset" : 169
    }, {
      "referenceID" : 28,
      "context" : "However, despite the significant improvements, existing studies on Chinese SRL mainly focus on the in-domain setting, where both training and test data are from the same domain (Wang et al., 2015; Guo et al., 2016b; Xia et al., 2017).",
      "startOffset" : 177,
      "endOffset" : 233
    }, {
      "referenceID" : 12,
      "context" : "However, despite the significant improvements, existing studies on Chinese SRL mainly focus on the in-domain setting, where both training and test data are from the same domain (Wang et al., 2015; Guo et al., 2016b; Xia et al., 2017).",
      "startOffset" : 177,
      "endOffset" : 233
    }, {
      "referenceID" : 29,
      "context" : "However, despite the significant improvements, existing studies on Chinese SRL mainly focus on the in-domain setting, where both training and test data are from the same domain (Wang et al., 2015; Guo et al., 2016b; Xia et al., 2017).",
      "startOffset" : 177,
      "endOffset" : 233
    }, {
      "referenceID" : 16,
      "context" : "come an important and challenging task in realistic NLP systems (Jiang and Zhai, 2007; Ramponi and Plank, 2020).",
      "startOffset" : 64,
      "endOffset" : 111
    }, {
      "referenceID" : 26,
      "context" : "come an important and challenging task in realistic NLP systems (Jiang and Zhai, 2007; Ramponi and Plank, 2020).",
      "startOffset" : 64,
      "endOffset" : 111
    }, {
      "referenceID" : 33,
      "context" : "There are three existing publicly available Chinese SRL datasets, including Chinese Proposition Bank (CPB) (Xue and Palmer, 2005), Chinese NomBank (CNB) (Xue, 2006a), and Chinese SemBank (CSB) (Xia et al.",
      "startOffset" : 107,
      "endOffset" : 129
    }, {
      "referenceID" : 31,
      "context" : "There are three existing publicly available Chinese SRL datasets, including Chinese Proposition Bank (CPB) (Xue and Palmer, 2005), Chinese NomBank (CNB) (Xue, 2006a), and Chinese SemBank (CSB) (Xia et al.",
      "startOffset" : 153,
      "endOffset" : 165
    }, {
      "referenceID" : 29,
      "context" : "There are three existing publicly available Chinese SRL datasets, including Chinese Proposition Bank (CPB) (Xue and Palmer, 2005), Chinese NomBank (CNB) (Xue, 2006a), and Chinese SemBank (CSB) (Xia et al., 2017).",
      "startOffset" : 193,
      "endOffset" : 211
    }, {
      "referenceID" : 2,
      "context" : "Finally, we employ multi-task learning (MTL) framework over the popular and competitive model (Cai et al., 2018) for SRL and conduct preliminary cross-domain SRL experiments on our dataset.",
      "startOffset" : 94,
      "endOffset" : 112
    }, {
      "referenceID" : 9,
      "context" : "Large-scale annotated data is a prerequisite to developing high-performance SRL systems (Fürstenau and Lapata, 2009; Xia et al., 2020).",
      "startOffset" : 88,
      "endOffset" : 134
    }, {
      "referenceID" : 30,
      "context" : "Large-scale annotated data is a prerequisite to developing high-performance SRL systems (Fürstenau and Lapata, 2009; Xia et al., 2020).",
      "startOffset" : 88,
      "endOffset" : 134
    }, {
      "referenceID" : 0,
      "context" : "The most representative ones in English are FrameNet (Baker et al., 1998), PropBank (Kingsbury and Palmer, 2002), and NomBank (Meyers et al.",
      "startOffset" : 53,
      "endOffset" : 73
    }, {
      "referenceID" : 19,
      "context" : ", 1998), PropBank (Kingsbury and Palmer, 2002), and NomBank (Meyers et al.",
      "startOffset" : 18,
      "endOffset" : 46
    }, {
      "referenceID" : 24,
      "context" : ", 1998), PropBank (Kingsbury and Palmer, 2002), and NomBank (Meyers et al., 2004).",
      "startOffset" : 60,
      "endOffset" : 81
    }, {
      "referenceID" : 23,
      "context" : "PropBank and NomBank are built by adding predicate-argument structures to the constituents of syntactic parser trees in the Penn Treebank (Marcus et al., 1993).",
      "startOffset" : 138,
      "endOffset" : 159
    }, {
      "referenceID" : 3,
      "context" : "of PropBank (Carreras and Màrquez, 2005) that only has 426 sentences, confining the progress of English cross-domain SRL.",
      "startOffset" : 12,
      "endOffset" : 40
    }, {
      "referenceID" : 33,
      "context" : "For Chinese, CPB (Xue and Palmer, 2005), CNB (Xue, 2006a), and CSB (Xia et al.",
      "startOffset" : 17,
      "endOffset" : 39
    }, {
      "referenceID" : 31,
      "context" : "For Chinese, CPB (Xue and Palmer, 2005), CNB (Xue, 2006a), and CSB (Xia et al.",
      "startOffset" : 45,
      "endOffset" : 57
    }, {
      "referenceID" : 29,
      "context" : "For Chinese, CPB (Xue and Palmer, 2005), CNB (Xue, 2006a), and CSB (Xia et al., 2017) are the most commonly used SRL corpora.",
      "startOffset" : 67,
      "endOffset" : 85
    }, {
      "referenceID" : 23,
      "context" : "CPB and CNB annotate predicate-argument relations to the sentences in the Chinese Treebank (Marcus et al., 1993), which also need pre-defined frames.",
      "startOffset" : 91,
      "endOffset" : 112
    }, {
      "referenceID" : 10,
      "context" : "Domain adaptation has been an important and challenging research topic in NLP (Daumé III, 2007; Ganin and Lempitsky, 2015; Guo et al., 2016a; Kim et al., 2016, 2017; Clark et al., 2018; Zhao et al., 2018).",
      "startOffset" : 78,
      "endOffset" : 204
    }, {
      "referenceID" : 11,
      "context" : "Domain adaptation has been an important and challenging research topic in NLP (Daumé III, 2007; Ganin and Lempitsky, 2015; Guo et al., 2016a; Kim et al., 2016, 2017; Clark et al., 2018; Zhao et al., 2018).",
      "startOffset" : 78,
      "endOffset" : 204
    }, {
      "referenceID" : 4,
      "context" : "Domain adaptation has been an important and challenging research topic in NLP (Daumé III, 2007; Ganin and Lempitsky, 2015; Guo et al., 2016a; Kim et al., 2016, 2017; Clark et al., 2018; Zhao et al., 2018).",
      "startOffset" : 78,
      "endOffset" : 204
    }, {
      "referenceID" : 37,
      "context" : "Domain adaptation has been an important and challenging research topic in NLP (Daumé III, 2007; Ganin and Lempitsky, 2015; Guo et al., 2016a; Kim et al., 2016, 2017; Clark et al., 2018; Zhao et al., 2018).",
      "startOffset" : 78,
      "endOffset" : 204
    }, {
      "referenceID" : 29,
      "context" : "5K predicates from Chinese SemBank (Xia et al., 2017) and randomly select 6.",
      "startOffset" : 35,
      "endOffset" : 53
    }, {
      "referenceID" : 20,
      "context" : "For target domains, which have already been annotated with syntactic information (Li et al., 2019a), we choose their predicates according to their syntactic information and a dictionary extracted from Chinese frames3.",
      "startOffset" : 81,
      "endOffset" : 99
    }, {
      "referenceID" : 22,
      "context" : "Following previous works (Marcheggiani et al., 2017; He et al., 2018; Cai et al., 2018), we treat SRL parsing as a sequence labeling problem and aim to find the tag sequence ŷ with the highest score:",
      "startOffset" : 25,
      "endOffset" : 87
    }, {
      "referenceID" : 13,
      "context" : "Following previous works (Marcheggiani et al., 2017; He et al., 2018; Cai et al., 2018), we treat SRL parsing as a sequence labeling problem and aim to find the tag sequence ŷ with the highest score:",
      "startOffset" : 25,
      "endOffset" : 87
    }, {
      "referenceID" : 2,
      "context" : "Following previous works (Marcheggiani et al., 2017; He et al., 2018; Cai et al., 2018), we treat SRL parsing as a sequence labeling problem and aim to find the tag sequence ŷ with the highest score:",
      "startOffset" : 25,
      "endOffset" : 87
    }, {
      "referenceID" : 8,
      "context" : "In this work, we adopt the widely used biaffine parser (Dozat and Manning, 2017) as our baseline, and build the MTL framework based on it.",
      "startOffset" : 55,
      "endOffset" : 80
    }, {
      "referenceID" : 7,
      "context" : "Recently proposed pre-trained language model BERT (Devlin et al., 2019) has shown its great power in learning and capturing contextualized representations and has proved to be beneficial in a variety of NLP tasks, such as information retrieval (Yang et al.",
      "startOffset" : 50,
      "endOffset" : 71
    }, {
      "referenceID" : 35,
      "context" : ", 2019) has shown its great power in learning and capturing contextualized representations and has proved to be beneficial in a variety of NLP tasks, such as information retrieval (Yang et al., 2019b), question answering (Yang et al.",
      "startOffset" : 180,
      "endOffset" : 200
    }, {
      "referenceID" : 34,
      "context" : ", 2019b), question answering (Yang et al., 2019a), and word segmentation (Huang et al.",
      "startOffset" : 29,
      "endOffset" : 49
    }, {
      "referenceID" : 29,
      "context" : ", 2009) and all the sentences from Chinese SemBank (Xia et al., 2017) following our newly compiled guideline.",
      "startOffset" : 51,
      "endOffset" : 69
    } ],
    "year" : 0,
    "abstractText" : "During the past decade, neural network models have made tremendous progress on indomain semantic role labeling (SRL). However, performance drops dramatically under the out-of-domain setting. In order to facilitate research on cross-domain SRL, this paper presents MuPAD, a multi-source predicateargument dataset in Chinese. MuPAD consists of 30,897 sentences and 92,051 predicates which covers 6 different domains. MuPAD exhibits three important features. 1) Based on a frame-free annotation methodology, we avoid writing complex frames for new predicates. 2) We explicitly annotate omitted core arguments to recover more complete semantic structure, considering that content omission is ubiquitous in multi-domain Chinese texts. 3) We compile 53-page annotation guidelines and adopt strict double annotation for improving data quality. This paper describes in detail the annotation methodology and process of MuPAD, and presents in-depth data analysis. We present benchmark cross-domain results on MuPAD, using Chinese Proposition Bank as a heterogeneous dataset.",
    "creator" : null
  }
}