{
  "name" : "ARR_2022_153_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Machine Translation for Livonian: Catering for 20 Speakers",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Livonian is one of the most endangered languages in Europe with just a tiny handful of speakers and virtually no publicly available corpora. In this paper we tackle the task of developing neural machine translation (NMT) between Livonian and English, with a two-fold aim: on one hand, preserving the language and on the other – enabling access to Livonian folklore, lifestories and other textual intangible heritage as well as making it easier to create further parallel corpora. We rely on Livonian’s linguistic similarity to Estonian and Latvian and collect parallel and monolingual data for the four languages for translation experiments. We combine different low-resource NMT techniques like zero-shot translation, cross-lingual transfer and synthetic data creation to reach the highest possible translation quality as well as to find which base languages are empirically more helpful for transfer to Livonian. The resulting NMT systems and the collected monolingual and parallel data, including a manually translated and verified translation benchmark, are publicly released.1"
    }, {
      "heading" : "1 Introduction",
      "text" : "Many state-of-the-art natural language processing tasks have reached admirable quality on languages with abundant linguistic resources (Vaswani et al., 2017; Conneau et al., 2018; Devlin et al., 2019). Furthermore, some neural language models and translation systems have been created for 100 and more languages (e.g. Conneau et al., 2020; Fan et al., 2021). However smaller, less or not at all spoken languages continue to struggle not only in terms of applicable computational approaches, but\n1https://opus.nlpl.eu/liv4ever.php, agreed to be kept anonymous with OPUS administration. Models and corpora will also be added to the Huggingface repository after de-anonymization (https://huggingface.co/).\nmore critically - in terms of usable resources for training natural language processing (NLP) models or even just linguistic exploration.\nIn this paper we set the goal of developing usable machine translation between English and Livonian. Currently there are over 20 fluent speakers of the language (Ernštreits, 2016). Although some digital linguistic resources exist for Livonian (including a dictionary with example sentences and a written monolingual corpus, (Ernštreits, 2016)), there is virtually no open parallel corpora with it, with the single exception of 35 parallel sentences in the OPUS Tatoeba corpus (Tiedemann, 2020).\nAt the same time, cross-lingual transfer learning has recently helped improve the performance of several low-resource NLP tasks with the support of related languages (e.g. Conneau et al., 2018; Hu et al., 2020). This also includes zero-shot translation (Johnson et al., 2017), the ability of multilingual NMT systems to translate between seen languages that were not represented in the parallel training data as a pair. The case of Livonian is especially interesting in this regard, as there are two different sources of such support: on one hand, it is a Uralic language, closely related to Estonian and Finnish. On the other hand, Livonian has taken part in forming Latvian language and Livonian speakers have historically co-existed side-by-side with Latvian speakers. As a result of mutual influence these two languages also share a number of grammatical, lexical and orthographic similarities.\nOur main contributions are two-fold. First, we collected majority of the digitally available translation examples including Livonian into a small parallel corpus (just over 10000 sentence pairs) of mostly Livonian-Latvian and LivonianEstonian sentence translations with very few (1000) Livonian-English examples. In order to create a clean benchmark for evaluating translation quality we selected a portion (about 10%) of this corpus and had it manually translated into Lat-\nvian/Estonian/English so that each sentence would have all four translations.2\nThe second half of our work focuses on neural machine translation (NMT, Vaswani et al., 2017), mainly targeting Livonian↔English. We explore several options of coping with the extremely lowresource settings and use Estonian and Latvian for cross-lingual transfer. Our experiments answer the following research questions:\n1. Can we achieve machine translation for Livonian↔English at a usable level?\n2. Which base language suits better for serving as base for cross-lingual transfer to Livonian, Estonian or Latvian?\n3. Does zero-shot multilingual translation deliver better translation quality than pivottranslation through Estonian or Latvian?\nNext we briefly describe the Livonian Language in Section 2, then introduce the collected parallel and monolingual data in Section 3. Section 4 provides the details of our NMT experiments and Section 5 concludes the paper."
    }, {
      "heading" : "2 The Livonian Language",
      "text" : "Livonian (ISO 639-3: liv) is a Finnic language indigenous to Latvia and belonging to the Uralic language family. During the 12th century Livonian was spoken across great territories in Latvia around the Gulf of Riga. Over time, Livonian areas gradually became Latvian-speaking. In the 19th century, Livonian still had approximately 2500 speakers, by\n2Translation from Livonian was a too rare and expensive service, thus we resorted to translating from one of the other three languages and instead had Livonian speakers check the results for meaning correspondence afterwords.\nthe mid-20th century around 1500 speakers. Nowadays Livonian is listed in UNESCO’s Atlas of the World’s Languages in Danger as a critically endangered language (Moseley, 2014). According to the 2011 census, there are 250 Livonians in Latvia. Although there are just over 20 people who can speak the language, the Livonian community is active in preserving and developing the Livonian heritage (Ernštreits, 2016) and language plays key role in this process (Ernštreits and Kl,ava, 2020).\nThe Livonian language developed in the contact area of Baltic and Finnic languages. Livonian and Latvian share a similar geographical location over a prolonged period of time, as a result of which they both contain traces of contact. Next to other loanwords, the Livonian loanword strata consists of words borrowed from Latvian (Suhonen, 1973; Winkler, 2014) and vice versa. The most obvious Latvian influence on Livonian grammar is found in the Livonian case system (Ernštreits and Kl,ava, 2014). Livonian has the prosodic characteristics typical of a Finnic language such as word-initial stress and the phonological opposition of short and long phoneme duration. It is the only Finnic language that differentiates lexical tones – the plain tone and the broken tone or stød – and therefore shares similar characteristics with Latvian as well as Danish (Tuisk, 2016)."
    }, {
      "heading" : "3 Collected Data",
      "text" : "The first step in developing (supervised) machine translation is collecting parallel data. While there was no pre-existing open parallel corpus with Livonian, we used all the possible sources of translations. This was limited to already digital resources, future work might include texts extracted by scanning older books and other materials.\nThe main sources of data included LivonianLatvian as well as Livonian-Estonian translations. Thus we use these two languages as base for crosslingual transfer and e.g. leave Finnish out, as there was no data for it.\nThe sources of data included:\n• the Constitution of the Republic of Latvia, translated into 9 languages, including Livonian, Estonian and English,\n• a database of dictionary entries, phrases and example sentences from the University of Latvia Livonian Institute’s website 5, with examples in Livonian, Estonian and Latvian\n• the Livonian Institute’s Facebook page posts, partially parallel between our 4 languages\n• books (Stalte, 2011; Kurs and et al., 2016; Ernštreit et al., 2020) with prefaces and content in Livonian-Estonian or Livonian-Latvian\n• and abstracts from the Journal of Estonian and Finno-Ugric Linguistics’ (JEFUL) Special Issues on Livonian Studies (2014, 2016, 2018) in Livonian, Estonian and English\nConcerning sentence alignment, the dictionary examples consisted of already aligned Livonian sentences. We aligned the rest of the data manually with the help of language experts – first on paragraph level, then on sentence level.\nThe total amount of sentences in the resulting dataset is shown in Table 1.\nWe separated balanced portions of development (503 sentences) and evaluation (749 sentences) splits from the full dataset. The splits are balanced in terms of the original source of the texts to resemble proportions from the remaining training data.\n5http://www.livones.net/\nWe hired professional translators to create translations for any missing parts so that these splits would be parallel between all four languages. We further turned to experts of the Livonian language to make sure that the newly created translations truly convey the meaning of the original text as a quality control measure.\nThe resulting benchmark and the whole corpus is published in the OPUS collection (currently, anonymously).6"
    }, {
      "heading" : "4 Machine Translation Experiments",
      "text" : "Having just over 10, 000 parallel examples constitutes extremely low-resource settings for neural machine translation. Added to this, the number of monolingual Livonian sentences (about 40, 000) is also too small for approaches like unsupervised machine translation (Artetxe et al., 2018; Lample et al., 2018).\nWe implement the support of neighboring and related languages (Estonian and Latvian) via multilingual machine translation (Johnson et al., 2017). As a first step the model is pre-trained with the larger languages (Estonian, Latvian, English) and then used as base for following experiments."
    }, {
      "heading" : "4.1 Technical Setup",
      "text" : "We used FairSeq (Ott et al., 2019) to train transformer architecture models with 6 encoder and decoder layers, 8 transformer attention heads per layer, word embeddings and hidden layers of size 512, dropout of 0.3, maximum sentence length of 128 symbols, and a batch size of 1024 words. All models were trained until they reached convergence (no improvement for 10 checkpoints) on development data. We used Sentencepiece (Kudo and Richardson, 2018) to create shared vocabular-\n6https://opus.nlpl.eu/liv4ever.php\nies of size 25,000, and SacreBLEU7 (Post, 2018) to generate BLEU scores for translations.\nBase models were trained on LV→EN, ET→EN, ET+LV→EN data, and a multilingual model using the tagged approach (Johnson et al., 2017) for translating in all directions between ENG/EST/LAT. The base models were then used as initialization for tuning on LIV→EN data. For training the base models we used all available parallel data from Opus (Tiedemann and Nygaard, 2004). To facilitate further use of the base models for tuning on Livonian data, all Livonian sentences were used in addition to other data when creating the shared vocabularies. Finally, we used the highest-scoring tuned model to perform performed backtranslation on the monolingual LIV data to generate additional training data for training the final models."
    }, {
      "heading" : "4.2 Results",
      "text" : "Table 2 shows results from MT experiments. All BLEU scores are calculated for translations of our evaluation set. We compare the base single direction MT models to our multidirection model, as well as online translations from Google Translate 8 and Neurotolge 9 to evaluate performance from ET and LV into EN. While the multilingual model was noticeably weaker, the others hold comparable results to the online systems. However, when attempting to perform zero-shot translation from LIV into EN, the ET→EN model was able to outperform LV→EN (3.22 vs. 2.20), and the multilingual model achieved a very respectable BLEU score 8.92.\nWe then turned to tuning each of these models with LIV-EN data mixed 1:1 with a random equal amount of the original training data for each of the models. In the case of the multilingual model, we also added LV/ET-LIV data to the mix. This improved all scores by 1-3 BLEU points,\n7BLEU+case.mixed+numrefs.1+smooth.exp+tok.13a+version.1.5.1 8https://translate.google.com/ - accessed on Nov. 2021 9https://neurotolge.ee/ - accessed on Nov. 2021\nbut the multilingual model remained on top with 11.62 for LIV→EN. In order to perform backtranslation models for both directions are required, so we scored the tuned multilingual model on the EN→LIV data as well, reaching 8.10 BLEU. Finally, to verify how much the tiny amount (503 sentences) of LIV-EN parallel data brings for tuning we ran a separate experiment excluding it and achieved 11.87 BLEU for LIV-EN and 8.25 BLEU for EN-LIV, which is even slightly higher than with the data there.\nFor comparison we also used the same tuned multilingual model to perform pivotal translation by first translating into ET or LV and then into the desired target language. Results from these experiments in Table 3 show that not only ET is better than LV to pivot translate between EN and LIV, but also that this approach was able to reach the highest BLEU scores so far. Tuning on the backtranslated data seemed to overwhelm the far lower amount of clean parallel data and did not produce a higher BLEU score in any direction.\nTo answer the research questions, posed in the introduction, it seems that the resulting translation quality is still far from being usable. Comparisons between the base languages have shown slight preference towards Estonian over Latvian. Interestingly, pivot-translation through Estonian showed higher translation quality than direct Livonian↔English trained in a zero-shot / few-shot manner."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this paper we presented a novel dataset for the highly endangered Livonian language, which can be useful for machine translation, language modelling and many other natural language processing and computational linguistic research tasks.\nIn our experiments we show how far one can get in training modern machine translation models with very scarce data, and which languages are more suitable for transfer learning when working with Livonian data. While perhaps not being usable as-is in any kind of production scale, the achieved BLEU scores of 13.00 and 9.47 show that some transfer of meaning can still be achieved between Livonian and English with the currently available resources."
    } ],
    "references" : [ {
      "title" : "Unsupervised statistical machine translation",
      "author" : [ "Mikel Artetxe", "Gorka Labaka", "Eneko Agirre." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3632– 3642, Brussels, Belgium. Association for Computa-",
      "citeRegEx" : "Artetxe et al\\.,? 2018",
      "shortCiteRegEx" : "Artetxe et al\\.",
      "year" : 2018
    }, {
      "title" : "Unsupervised cross-lingual representation learning at scale",
      "author" : [ "Alexis Conneau", "Kartikay Khandelwal", "Naman Goyal", "Vishrav Chaudhary", "Guillaume Wenzek", "Francisco Guzmán", "Edouard Grave", "Myle Ott", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "In",
      "citeRegEx" : "Conneau et al\\.,? 2020",
      "shortCiteRegEx" : "Conneau et al\\.",
      "year" : 2020
    }, {
      "title" : "XNLI: Evaluating cross-lingual sentence representations",
      "author" : [ "Alexis Conneau", "Ruty Rinott", "Guillaume Lample", "Adina Williams", "Samuel Bowman", "Holger Schwenk", "Veselin Stoyanov." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods",
      "citeRegEx" : "Conneau et al\\.,? 2018",
      "shortCiteRegEx" : "Conneau et al\\.",
      "year" : 2018
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Livonian in recent years",
      "author" : [ "Valts Ernštreits." ],
      "venue" : "Eesti ja soome-ugri keeleteaduse ajakiri. Journal of Estonian and Finno-Ugric Linguistics, 7(1):257–274.",
      "citeRegEx" : "Ernštreits.,? 2016",
      "shortCiteRegEx" : "Ernštreits.",
      "year" : 2016
    }, {
      "title" : "Trilium 2.0. Lı̄võ lūolkub",
      "author" : [ "Valt Ernštreit", "Baiba Damberg", "Karl Pajusalu" ],
      "venue" : "Liivi luulekogu. Lı̄biešu dzejas izlase. The International Society of Livonian Friends",
      "citeRegEx" : "Ernštreit et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Ernštreit et al\\.",
      "year" : 2020
    }, {
      "title" : "Beyond english-centric multilingual machine translation",
      "author" : [ "Angela Fan", "Shruti Bhosale", "Holger Schwenk", "Zhiyi Ma", "Ahmed El-Kishky", "Siddharth Goyal", "Mandeep Baines", "Onur Celebi", "Guillaume Wenzek", "Vishrav Chaudhary" ],
      "venue" : "Journal of Machine",
      "citeRegEx" : "Fan et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Fan et al\\.",
      "year" : 2021
    }, {
      "title" : "Xtreme: A massively multilingual multitask benchmark for evaluating cross-lingual generalisation",
      "author" : [ "Junjie Hu", "Sebastian Ruder", "Aditya Siddhant", "Graham Neubig", "Orhan Firat", "Melvin Johnson." ],
      "venue" : "International Conference on Machine",
      "citeRegEx" : "Hu et al\\.,? 2020",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2020
    }, {
      "title" : "SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing",
      "author" : [ "Taku Kudo", "John Richardson." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System",
      "citeRegEx" : "Kudo and Richardson.,? 2018",
      "shortCiteRegEx" : "Kudo and Richardson.",
      "year" : 2018
    }, {
      "title" : "Language and mind of the Livonian people",
      "author" : [ "Ott Kurs", "editors" ],
      "venue" : "Eduard Vääri’s publications on Livonians and the Livonian language,",
      "citeRegEx" : "Kurs et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Kurs et al\\.",
      "year" : 2016
    }, {
      "title" : "Phrase-based & neural unsupervised machine translation",
      "author" : [ "Guillaume Lample", "Myle Ott", "Alexis Conneau", "Ludovic Denoyer", "Marc’Aurelio Ranzato" ],
      "venue" : "In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing,",
      "citeRegEx" : "Lample et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Lample et al\\.",
      "year" : 2018
    }, {
      "title" : "Livonian–the most endangered language in europe? Eesti ja soome-ugri keeleteaduse ajakiri",
      "author" : [ "Christopher Moseley." ],
      "venue" : "Journal of Estonian and FinnoUgric Linguistics, 5(1):61–75.",
      "citeRegEx" : "Moseley.,? 2014",
      "shortCiteRegEx" : "Moseley.",
      "year" : 2014
    }, {
      "title" : "fairseq: A fast, extensible toolkit for sequence modeling",
      "author" : [ "Myle Ott", "Sergey Edunov", "Alexei Baevski", "Angela Fan", "Sam Gross", "Nathan Ng", "David Grangier", "Michael Auli." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chap-",
      "citeRegEx" : "Ott et al\\.,? 2019",
      "shortCiteRegEx" : "Ott et al\\.",
      "year" : 2019
    }, {
      "title" : "A call for clarity in reporting BLEU scores",
      "author" : [ "Matt Post." ],
      "venue" : "Proceedings of the Third Conference on Machine Translation: Research Papers, pages 186– 191, Brussels, Belgium. Association for Computational Linguistics.",
      "citeRegEx" : "Post.,? 2018",
      "shortCiteRegEx" : "Post.",
      "year" : 2018
    }, {
      "title" : "Jelzi Sõnā: ābēd ja ı̄rgandõks lugdõbrōntõz",
      "author" : [ "Kōrli Stalte." ],
      "venue" : "Jemākı̄el sel,tš.",
      "citeRegEx" : "Stalte.,? 2011",
      "shortCiteRegEx" : "Stalte.",
      "year" : 2011
    }, {
      "title" : "Die jungen lettischen lehnwörter im livischen",
      "author" : [ "Seppo Suhonen." ],
      "venue" : "Suomalais-ugrilaisen seuran toimituksia, 154. 5",
      "citeRegEx" : "Suhonen.,? 1973",
      "shortCiteRegEx" : "Suhonen.",
      "year" : 1973
    }, {
      "title" : "The tatoeba translation challenge – realistic data sets for low resource and multilingual MT",
      "author" : [ "Jörg Tiedemann." ],
      "venue" : "Proceedings of the Fifth Conference on Machine Translation, pages 1174–1182, Online. Association for Computational Linguistics.",
      "citeRegEx" : "Tiedemann.,? 2020",
      "shortCiteRegEx" : "Tiedemann.",
      "year" : 2020
    }, {
      "title" : "The OPUS corpus - parallel and free: http://logos.uio. no/opus",
      "author" : [ "Jörg Tiedemann", "Lars Nygaard" ],
      "venue" : "In Proceedings of the Fourth International Conference on Language Resources and Evaluation",
      "citeRegEx" : "Tiedemann and Nygaard.,? \\Q2004\\E",
      "shortCiteRegEx" : "Tiedemann and Nygaard.",
      "year" : 2004
    }, {
      "title" : "Main features of the livonian sound system and pronunciation",
      "author" : [ "Tuuli Tuisk." ],
      "venue" : "Eesti ja soomeugri keeleteaduse ajakiri. Journal of Estonian and Finno-Ugric Linguistics, 7(1):121–143.",
      "citeRegEx" : "Tuisk.,? 2016",
      "shortCiteRegEx" : "Tuisk.",
      "year" : 2016
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Ł ukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in Neural Information Processing Systems, volume 30.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Loanword strata in livonian",
      "author" : [ "Eberhard Winkler." ],
      "venue" : "Eesti ja soome-ugri keeleteaduse ajakiri. Journal of Estonian and Finno-Ugric Linguistics, 5(1):215– 227.",
      "citeRegEx" : "Winkler.,? 2014",
      "shortCiteRegEx" : "Winkler.",
      "year" : 2014
    } ],
    "referenceMentions" : [ {
      "referenceID" : 19,
      "context" : "Many state-of-the-art natural language processing tasks have reached admirable quality on languages with abundant linguistic resources (Vaswani et al., 2017; Conneau et al., 2018; Devlin et al., 2019).",
      "startOffset" : 135,
      "endOffset" : 200
    }, {
      "referenceID" : 2,
      "context" : "Many state-of-the-art natural language processing tasks have reached admirable quality on languages with abundant linguistic resources (Vaswani et al., 2017; Conneau et al., 2018; Devlin et al., 2019).",
      "startOffset" : 135,
      "endOffset" : 200
    }, {
      "referenceID" : 3,
      "context" : "Many state-of-the-art natural language processing tasks have reached admirable quality on languages with abundant linguistic resources (Vaswani et al., 2017; Conneau et al., 2018; Devlin et al., 2019).",
      "startOffset" : 135,
      "endOffset" : 200
    }, {
      "referenceID" : 6,
      "context" : "Furthermore, some neural language models and translation systems have been created for 100 and more languages (e.g. Conneau et al., 2020; Fan et al., 2021).",
      "startOffset" : 110,
      "endOffset" : 155
    }, {
      "referenceID" : 4,
      "context" : "Although some digital linguistic resources exist for Livonian (including a dictionary with example sentences and a written monolingual corpus, (Ernštreits, 2016)), there is virtually no open parallel corpora with it, with the single exception of 35 parallel sentences in the OPUS Tatoeba corpus (Tiedemann, 2020).",
      "startOffset" : 143,
      "endOffset" : 161
    }, {
      "referenceID" : 16,
      "context" : "Although some digital linguistic resources exist for Livonian (including a dictionary with example sentences and a written monolingual corpus, (Ernštreits, 2016)), there is virtually no open parallel corpora with it, with the single exception of 35 parallel sentences in the OPUS Tatoeba corpus (Tiedemann, 2020).",
      "startOffset" : 295,
      "endOffset" : 312
    }, {
      "referenceID" : 11,
      "context" : "Nowadays Livonian is listed in UNESCO’s Atlas of the World’s Languages in Danger as a critically endangered language (Moseley, 2014).",
      "startOffset" : 117,
      "endOffset" : 132
    }, {
      "referenceID" : 4,
      "context" : "Although there are just over 20 people who can speak the language, the Livonian community is active in preserving and developing the Livonian heritage (Ernštreits, 2016) and language plays key role in this process (Ernštreits and Kl,ava, 2020).",
      "startOffset" : 151,
      "endOffset" : 169
    }, {
      "referenceID" : 15,
      "context" : "Next to other loanwords, the Livonian loanword strata consists of words borrowed from Latvian (Suhonen, 1973; Winkler, 2014) and vice versa.",
      "startOffset" : 94,
      "endOffset" : 124
    }, {
      "referenceID" : 20,
      "context" : "Next to other loanwords, the Livonian loanword strata consists of words borrowed from Latvian (Suhonen, 1973; Winkler, 2014) and vice versa.",
      "startOffset" : 94,
      "endOffset" : 124
    }, {
      "referenceID" : 18,
      "context" : "It is the only Finnic language that differentiates lexical tones – the plain tone and the broken tone or stød – and therefore shares similar characteristics with Latvian as well as Danish (Tuisk, 2016).",
      "startOffset" : 188,
      "endOffset" : 201
    }, {
      "referenceID" : 14,
      "context" : "• books (Stalte, 2011; Kurs and et al., 2016; Ernštreit et al., 2020) with prefaces and content in Livonian-Estonian or Livonian-Latvian",
      "startOffset" : 8,
      "endOffset" : 69
    }, {
      "referenceID" : 5,
      "context" : "• books (Stalte, 2011; Kurs and et al., 2016; Ernštreit et al., 2020) with prefaces and content in Livonian-Estonian or Livonian-Latvian",
      "startOffset" : 8,
      "endOffset" : 69
    }, {
      "referenceID" : 0,
      "context" : "Added to this, the number of monolingual Livonian sentences (about 40, 000) is also too small for approaches like unsupervised machine translation (Artetxe et al., 2018; Lample et al., 2018).",
      "startOffset" : 147,
      "endOffset" : 190
    }, {
      "referenceID" : 10,
      "context" : "Added to this, the number of monolingual Livonian sentences (about 40, 000) is also too small for approaches like unsupervised machine translation (Artetxe et al., 2018; Lample et al., 2018).",
      "startOffset" : 147,
      "endOffset" : 190
    }, {
      "referenceID" : 12,
      "context" : "We used FairSeq (Ott et al., 2019) to train transformer architecture models with 6 encoder and decoder layers, 8 transformer attention heads per layer, word embeddings and hidden layers of size 512, dropout of 0.",
      "startOffset" : 16,
      "endOffset" : 34
    }, {
      "referenceID" : 8,
      "context" : "We used Sentencepiece (Kudo and Richardson, 2018) to create shared vocabular-",
      "startOffset" : 22,
      "endOffset" : 49
    }, {
      "referenceID" : 13,
      "context" : "ies of size 25,000, and SacreBLEU7 (Post, 2018) to generate BLEU scores for translations.",
      "startOffset" : 35,
      "endOffset" : 47
    }, {
      "referenceID" : 17,
      "context" : "For training the base models we used all available parallel data from Opus (Tiedemann and Nygaard, 2004).",
      "startOffset" : 75,
      "endOffset" : 104
    } ],
    "year" : 0,
    "abstractText" : "Livonian is one of the most endangered languages in Europe with just a tiny handful of speakers and virtually no publicly available corpora. In this paper we tackle the task of developing neural machine translation (NMT) between Livonian and English, with a two-fold aim: on one hand, preserving the language and on the other – enabling access to Livonian folklore, lifestories and other textual intangible heritage as well as making it easier to create further parallel corpora. We rely on Livonian’s linguistic similarity to Estonian and Latvian and collect parallel and monolingual data for the four languages for translation experiments. We combine different low-resource NMT techniques like zero-shot translation, cross-lingual transfer and synthetic data creation to reach the highest possible translation quality as well as to find which base languages are empirically more helpful for transfer to Livonian. The resulting NMT systems and the collected monolingual and parallel data, including a manually translated and verified translation benchmark, are publicly released.1",
    "creator" : null
  }
}