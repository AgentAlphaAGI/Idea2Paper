{
  "name" : "ARR_2022_103_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Many recent advances in neural models for NLP have been driven by the ability to learn from unlabeled data (Devlin et al., 2019; Liu et al., 2019b). This approach allows for training the models on large-scale corpora without the costly process of annotating them. As a result, the accuracy and complexity of state-of-the-art neural models for NLP have increased (Brown et al., 2020).\nThis trend towards unlabeled data does not have a counterpart in testing NLP models. Instead, both in-distribution testing and out-of-distribution testing (Yin et al., 2019; Teney et al., 2020) rely on comparing the model’s predictions to the ground truth. Similarly, attempts at probing the internal computation of large NLP models use supervised classifiers as a diagnostic tool (Ettinger et al., 2016; Belinkov et al., 2017).\nIn general, such extreme reliance on groundtruth data limits the quantity and quality of test cases we can produce, which is a known problem in\nthe software testing community (Barr et al., 2015). In this regard, a promising solution is metamorphic testing (Chen et al., 2018). Under this paradigm, we test the internal consistency of an NLP model by checking whether it satisfies a necessary relation of its inputs and outputs (Ribeiro et al., 2020). Consequently, metamorphic testing relies on our ability to formally express our expectations on the behaviour of an NLP model.\nStill, most of the metamorphic relations proposed in the literature target the same type of behaviour, as we show in this paper. Indeed, the majority of them are robustness relations, which require that the output of an NLP model remains stable in the face of small input perturbations (Aspillaga et al., 2020). These perturbations may involve simple typos (Belinkov and Bisk, 2018; Gao et al., 2018; Heigold et al., 2018), replacing individual words with a synonym (Li et al., 2017; Jia et al., 2019; La Malfa et al., 2020), or adding irrelevant information to the input (Tu et al., 2021). Due to their simple structure, robustness-like relations have been applied to the testing of several NLP tasks, including sentiment analysis (Ribeiro et al., 2020), machine translation (Sun and Zhou, 2018), and question answering (Chan et al., 2021). Even testing the fairness of NLP models falls in this category (Ma et al., 2020).\nAt the same time, we expect state-of-the-art NLP models to exhibit a broader range of linguistic properties than just robustness. First and foremost, NLP models should generalise systematically, i.e. their ability to understand some inputs should be intrinsically connected to their ability to understand related ones (Fodor and Pylyshyn, 1988). While the exact definition of systematic behaviour varies in the literature (Hupkes et al., 2020), a common requirement is that the model’s predictions are a result of a composition of syntactic and semantic constituents of the input (Baroni, 2020). Several supervised methods to test against such requirements exist (Et-\ntinger et al., 2016; Goodwin et al., 2020), but they all rely on comparing the model’s predictions to the ground truth. Likewise, Yanaka et al. (2021) interprets systematicity as the ability to generalise over transitive relations. Their supervised method shows that current models struggle to do so.\nIn this paper, we propose three new classes of metamorphic relations, which are designed to test the systematicity, compositionality and transitivity of NLP models. In true metamorphic fashion, our relations do not rely on ground-truth data and scale up the generation of test cases by a polynomial factor. For each proposed relation, we provide an illustrative experiment where we test state-of-theart models for the expected linguistic behaviours. More in detail, our main original contributions are:\n• Pairwise systematicity. First, we propose a general class of metamorphic relations to test the systematicity of NLP models (Section 4). The relations in this class are based on pairs of inputs, which yields a quadratic number of test cases from a single dataset. We test the pairwise systematicity of a sentiment analysis model in Section 4.1, with positive results. Then, in Section 4.2, we give a geometrical intuition of the constraints imposed by our relations on the model’s embedding space.\n• Pairwise compositionality. Second, we modify pairwise systematicity to test the presence of compositional constituents in the hidden layers of neural models (Section 5). Accordingly, we test the pairwise compositionality of a natural language inference (NLI) model in Section 5.1, and show that it does not behave in a compositional way.\n• Three-way transitivity. Third, we introduce a class of relations to test the internal transitivity of an NLP model (Section 6). These relations are defined over triplets of source inputs. In Section 6.1, we test a state-of-theart model that predicts the lexical relation of words (synonymy, hypernymy), and show that it does not behave in a transitive way.\n• Graphical notation. Fourth, we propose a formal graphical notation for NLP metamorphic relations, that efficiently expresses their internal structure (Section 2).\n• Taxonomy of existing work. Fifth, we review the existing literature on metamorphic\ntesting for NLP, and show that the relations proposed therein share the same structure with a single source input (Section 3).\nLastly, in Section 7 we conclude and outline possible future work. We discuss the ethical implications of our work in Appendix A. We provide a quick-reference guide to our contribution in Appendix B. The code of our experiments and reproducibility checklist are available at https: //doi.org/10.5281/zenodo.5703459."
    }, {
      "heading" : "2 A graphical notation for NLP metamorphic relations",
      "text" : "This section gives preliminary definitions and proposes a compact graphical notation for NLP metamorphic relations.\nDefinition 2.1 (NLP model). Let f : X → Y be a machine learning model that maps a textual input x ∈ X to a suitable output Y ∈ Y . Here, we assume that f is a neural network, and Y ≡ Rk is either a k-dimensional embedding space or the soft-max output of a k-class classifier.\nIn general, a metamorphic relation can be defined as (Chen et al., 2018):\nDefinition 2.2 (Metamorphic relation). A metamorphic relation R is a property of f across multiple inputs and outputs (x1, . . . ,xv, f(x1), . . . , f(xv)), such that R ⊆ X1 × · · · × Xv × Y1 × · · · × Yv.\nHowever, we are interested in the internal structure of such a relation. Thus, let us discriminate between two types of inputs (Chen et al., 2018):\nDefinition 2.3 (Source inputs). Given a relation R with v inputs, let (x1, . . . ,xu) with u ≤ v be the sequence of source inputs. These can be chosen freely, e.g. by extracting them from a dataset D. Definition 2.4 (Follow-up inputs). Given a relation R with u source inputs, let (xu+1, . . . ,xv) with u ≤ v be the sequence of follow-up inputs. These are computed by a transformation of the source inputs xi = Ti(x1, . . . ,xu) for i ∈ [u+ 1, v].\nFurthermore, all the relations in this paper prescribe specific conditions over the model’s output:\nDefinition 2.5 (Output property). Define P ⊆ Y1, . . . ,Yv as a relation over the output. Here, we always write it in decidable first-order logic.\nAltogether, the structure of an NLP metamorphic relation can be easily described in graphical\nform. To do so, we introduce the following compact notation (see example in Figure 1). Textual variables are represented as circles, whereas numerical variables (e.g. embeddings, softmax outputs) are squares. Moreover, source inputs are shaded in grey, while all other nodes are in white. Arrows represent the neural function f and the transformation Ti. Lastly, the output property P is linked to the relevant nodes with dashed lines."
    }, {
      "heading" : "3 A taxonomy of existing NLP metamorphic relations",
      "text" : "Most of the existing literature on NLP metamorphic testing proposes relations that fit in the structure of Figure 1. Due to their reliance on just one source input, we refer to these metamorphic relations as single-input. The individual differences among them can be ascribed to the specific transformation T and property P . The present section derives a taxonomy of existing NLP relations by organising them along these two axes T and P .\nThe transformation T is defined over the input text and thus allows for considerable creative freedom. A list of common options is presented here:\n• Character-level T . Character-level transformations are typically used to introduce noise in the input. Examples include replacing individual characters with a neighbouring one on a computer keyboard (Belinkov and Bisk, 2018) or a random one (Heigold et al., 2018). More aggressive transformations may involve swapping neighbouring characters (Belinkov and Bisk, 2018; Gao et al., 2018; Heigold et al., 2018) and shuffling a subset of the characters in a word (Belinkov and Bisk, 2018). Alternatively, a collection of real-world typos can be retrieved from datasets with edit history (e.g. Wikipedia) (Belinkov and Bisk, 2018).\n• Word-level T . A common word-level transformation involves replacing words with their synonym (Li et al., 2017). This operation has been shown to produce adversarial examples in (Jia et al., 2019; La Malfa et al., 2020). The use of antonyms has also been explored in Tu et al. (2021). In contrast, changing the gender of keywords in the input text can reveal the social biases of an NLP model (Ma et al., 2020). Similarly, swapping keywords in the context of a question-answer (QA) system can reveal inconsistent answers (Ribeiro et al., 2020).\n• Sentence-level T . Removal or concatenation of entire sentences from the input text has been tried too. Aspillaga et al. (2020) experiments with adding positive and negative tautologies at the end of the input. Similarly, Ribeiro et al. (2020) propose to concatenate both well-formed sentences and randomlygenerated URLs. More generally, the whole input text can have its sentences shuffled (Tu et al., 2021) or paraphrased (Li et al., 2017).\nRegarding the output property P , the current literature only offers three choices. We list them here, alongside their first-order logic formulation:\n• Equivalence P . Robustness relations require that the output does not change in the face of small input perturbations. Thus, we need a notion of equivalence between the source output y and its follow-up y′ (see Figure 1). For classification models, we can express it via the softmax output y=(y1, . . . , yc) as:\nPeq : ∃i ∀j 6= i (yi > yj) ∧ (y′i > y′j) (1)\nwhere i is the predicted class. In rarer cases, where the output is textual, verbatim comparison can be used (Sun and Zhou, 2018).\n• Similarity P . For other applications, the equivalence property cannot be applied. For example, when testing QA systems, we want to detect similar but not identical answers. In such cases, we can define a similarity score s(y,y′) ∈ R, e.g. cosine similarity between the embeddings of the two answers (Tu et al., 2021). With it, we can write similarity as:\nPsim : s(y,y ′) > θ (2)\nwhere θ is an arbitrary threshold chosen according to the user’s domain knowledge.\n• Order P . At the same time, we can establish an order relation between the two outputs y and y′. This order relation is useful in conjunction with transformations that have a monotonic effect on the output. For example, concatenating positive sentences to the input of a sentiment analysis system (Ribeiro et al., 2020). In such cases, let us define an order score s(y) ∈ R, and write the output property as:\nPord : s(y) < s(y ′) (3)\nIn Sections 4, 5 and 6 we employ some of the transformations T and properties P defined here as building blocks for new metamorphic relations."
    }, {
      "heading" : "4 Pairwise NLP metamorphic relations for testing systematicity",
      "text" : "We introduce a new class of metamorphic relations to test the systematicity of NLP models. Here, we take the general definition of systematicity in Fodor and Pylyshyn (1988), which states that the predictions of an NLP model across related inputs should be intrinsically connected and express it as a metamorphic relation (see Figure 2). Since we do not want to rely on ground-truth data, we first establish a baseline for the model’s behaviour by comparing its predictions across two different source inputs. Then, we perturb both source inputs via the same transformation and test whether the model’s behaviour changes accordingly.\nMore formally, we define pairwise-systematicity relations as follows. Let x1,x2 ∈ D be a pair of source inputs, and x′1,x ′ 2 their corresponding follow-up inputs via transformation T . Furthermore, denote with y1,y2,y′1,y ′ 2 the outputs produced by model f . Finally, define the output property P in the following form:\nP : Psrc(y1,y2) =⇒ Pflw(y′1,y′2) (4)\nNote that this definition does not rely on groundtruth data. In fact, we trust the model’s predictions (y1,y2) over the source inputs to establish our premise Psrc. The actual test checks whether transforming the source inputs with T produces outputs that satisfy the expected property Pfwl. Any violation of this property, i.e. when Psrc ∧ ¬Pfwl, reveals an inconsistency in the model’s predictions that breaks the user’s expectation of systematic behaviour. In Section 4.2, we give an intuitive geometrical explanation of the type of constraints imposed by pairwise-systematicity relations on the embedding space of a neural NLP model.\nA hidden advantage of metamorphic relations with multiple source inputs (see also Sections 5 and 6) is that they naturally produce more test cases than single-input ones. In the case of pairwise systematicity, each input in the pair (x1,x2) is extracted from the same dataset D. Thus, a dataset with |D| = k entries generates an O(k2) number of test cases, as opposed to O(k) for single-input relations. We see an example of this in Section 4.1."
    }, {
      "heading" : "4.1 Illustrative example: pairwise systematicity of sentiment analysis",
      "text" : "Now, let us apply the pairwise-systematicity relation structure shown in Figure 2 to a sentiment analysis task. To do so, we choose the following:\n• Transformation T . For each source input xi, we create a follow-up input x′i = T (xi) by concatenating a short sentence to it. A list of all transformations we use is in Table 1.\n• Output premise Psrc. Let spos(y1) and spos(y2) be the (positive) sentiment scores predicted by model f . Define the baseline behaviour of f as the order property Psrc=Pord between these two scores (see Equation 3).\n• Output hypothesis Pflw. Let spos(y′1) and spos(y ′ 2) be the sentiment scores of the follow-\nup inputs. We require that their order matches the one of the source inputs. More formally: Pflw=Pord and Psrc ⇐⇒ Pflw.\nOur rationale is that the sentiment of any input shifts when we concatenate additional text. If we have ground-truth information on the sentiment of the text we are adding, we can test whether our predictions shift in the expected direction. For instance, concatenating “I am very happy” should make the score of any input more positive. This is\nan example of single-input relation (see Section 3 and Ribeiro et al., 2020).\nHowever, if we do not have such ground truth, we can still test our model. We do so by considering a pair of inputs (x1,x2), and concatenating the same text to both of them. Then, whenever x1 is predicted more positive than x2, we require that its transformed version x′1 is also more positive than x′2 and vice versa. This is pairwise systematicity.\nExperiment description and results. We select a fine-tuned version of RoBERTa (Liu et al., 2019b) for sentiment analysis from the HuggingFace library.1. We choose 10,605 movie reviews from Socher et al. (2013) as our dataset D. From it, we generate all 112M+ possible source input pairs. We repeat our experiment with different neutral transformations T , and report their aggregated results in Table 1. Note how the proportion of satisfied relations (“Safety”) varies across different transformations. Yet, the model’s behaviour is fairly systematic, never exceeding 10% violations.\nWe get a different picture by counting the number of violations per each source input xi ∈ D (see Table 2). There, we can see that some inputs are more likely to make the source order Psrc(y1,y2) unstable across all the transformations T . Interestingly, a quick read through the reviews in Table 2 shows that they are all misclassified. Thus, we can conclude that pairwise-systematicity testing reveals a different issue in the model f than classic non-metamorphic testing. For this reason, we encourage practitioners to perform both types of testing on their NLP models, as it will give a clearer\n1https://huggingface.co/siebert/ sentiment-roberta-large-english\npicture of their strengths and weaknesses."
    }, {
      "heading" : "4.2 Geometric interpretation of pairwise systematicity",
      "text" : "Metamorphic relations impose constraints between the inputs and outputs while treating the model f as a black box (Chen et al., 2018). Still, in neural networks, it is possible to trace the effect of a relation R on the hidden layers. Here, we give a geometric explanation of the type of constraints pairwise-systematicity relations put on the last embedding space of a neural NLP model.\nTo this end, let us consider the relations in Section 4.1. Recall, that model f outputs a sentiment score s(y), which is a one-dimensional projection of the embedding space (see Figure 3). Accordingly, the premise Psrc and hypothesis Pflw are only concerned with the position of each embedding y along direction s. However, since the source and follow-up inputs differ due to transformation T , the two output properties Psrc and Pflw act on different points in the embedding space. Once we require that Psrc ⇐⇒ Pflw, we set the expectation that f is exceptionally consistent at mapping pairs of inputs (x1,x2) onto space Y in the same order.\nSuch expectation is met if and only if f is a systematic, though not necessarily correct, function.\nSimilar considerations apply if Psrc and Pflw are based on equality or similarity rather than order. Indeed, equality (see Equation 1) is defined over the softmax outputs, which are affine combinations of the embeddings (Bishop, 2006). In such case, the condition Psrc =⇒ Pflw translates to a requirement that if the source inputs are both mapped to the same half-space, the follow-up inputs should be too. Conversely, similarity (Equation 2) defines a measure on the embedding space. Source inputs that are within a certain threshold θ should be matched by follow-up inputs that are also close.\nThe following section introduces a class of pairwise relations where the output premise and hypothesis are defined over different embedding spaces."
    }, {
      "heading" : "5 Pairwise NLP metamorphic relations for testing compositionality",
      "text" : "Many probing works train simple supervised classifiers on top of the hidden representations of an NLP model (e.g. Hewitt and Manning, 2019).These classifiers, called probes, can reveal whether the neural model has learnt to recognise some fundamental constituents of the input language early on. The presence of such building blocks is a necessary condition for an NLP model to exhibit compositional behaviour (Baroni, 2020). Here, we propose to test the presence of compositional constituents in the hidden layers via metamorphic testing.\nConsider the graph in Figure 4. There, the neural model is split into the mathematical composition of two functions f ◦ g. More precisely, z = f(x) are the hidden representation of some hidden layer, and y = g(z) is the final output. Now, let us define\nthe output property P as follows:\nP : Phid(z1, z2) =⇒ Pout(y1,y2) (5)\nA relation in this form allows us to express whether specific precursor signals in z are expected to have a direct effect on y. In a similar way to the relations in Section 4, both the premise Phid and hypothesis Pout are established by comparing across pairs of inputs, rather than a ground-truth. In Section 5.1, we show how our technique can reveal the presence (or absence) of compositional building blocks in an NLP model."
    }, {
      "heading" : "5.1 Illustrative example: pairwise compositionality of NLI",
      "text" : "Here, we apply the metamorphic relation in Figure 4 to test a natural language inference (NLI) model. In general, the input x = (xa,xb) of an NLI model is the concatenation of two pieces of text: the premise xa and the hypothesis xb. The model’s goal is to predict whether xb logically follows from xa, i.e. their entailment.\nTo test whether the model’s predictions exhibit a compositional behaviour, we construct our test inputs according to Rozanova et al. (2021). Namely,\nwe first choose a prototypical sentence template C(`), which we call a context. Each context includes a placeholder token ` that can be replaced with some insertion text. Second, we construct each input x = (C(`a), C(`b)) by copying the same context twice with different insertions.\nFinally, we choose the contexts Ci and insertion pairs (`a, `b)j in such a way that their composition (C(`a), C(`b))ij has a well-definite entailment relation. Namely, the insertion pairs (see Table 4) are either hypernyms (⊇), hyponyms (⊆), or unrelated (none). Similarly, the contexts (see Table 3) are either upward monotone if they preserve the insertion relation, or downward monotone if they invert it. As a result, only the compositions Up(⊆) and Down(⊇) are entailed, while the rest are not.\nNow, assume that both inputs x1 and x2 in Figure 4 are based on the same context Ci. We can test whether the NLI model build its output by reasoning over the monotonicity of Ci and the lexical relation of the insertion pairs (`a, `b)j as follows:\n• Hidden premise Phid. Let z be the embeddings of the second to last layer, for the tokens corresponding to the insertions `a and `b. Train a linear probe shyp on z (Liu et al., 2019a) to predict whether `a is a hypernym of `b. Define Phid =Pord as the order property (see Equation 3) over the hypernymy scores shyp(z1) and shyp(z2) of the two inputs.\n• Output hypothesis Pout. Let sent(y) be the entailment score produced by the full neural model f ◦ g. Moreover, define Pout = Pord as the order of the two output scores sent(y1) and sent(y2). Then, consider the monotonic-\nity of the input context. If Ci is downward monotone, let Phid ⇐⇒ Pout, since more hypernymy means more entailment. If Ci is upward monotone, let Phid ⇐⇒ ¬Pout, since more hypernymy means less entailment.\nIf the NLI model f ◦ g had a compositional behaviour, the order Phid of the hypernymy scores in the hidden layer should be reflected in the order Pout of the entailment scores in the output. Here, we show that this is not the case for a popular stateof-the-art NLI model.\nExperiment description and results. We build a dataset D of 292 insertions pairs and repeat our experiment with 211 contexts, for a total of about 9M test cases. We chose a fine-tuned version of RoBERTa for NLI as our model.2 The accuracy of the hypernymy probe is 0.9881. We report the aggregated result by context in Table 3. Note how downward monotone contexts lead to less compositional behaviour: overall, we have 0.6880 successful test cases with upward contexts and only 0.4808 with downward ones. This phenomenon is known in the literature (Yanaka et al., 2019), but we show that metamorphic testing can independently detect it. If we aggregate the results by insertion pair (see Table 4), the picture does not change. The overall safety is 0.5936, which is barely above random chance. Any deviations from this baseline can be interpreted as noise."
    }, {
      "heading" : "6 Three-way NLP metamorphic relations for testing transitivity",
      "text" : "An NLP model that generalises correctly should exhibit transitive behaviour under the right circumstances Yanaka et al. (2021). That is, if the model\n2https://huggingface.co/ roberta-large-mnli\npredicts a transitive linguistic property over the input pairs (x1,x2) and (x2,x3), then it should also predict it for the pair (x1,x3). Here, we propose to test this behaviour in a metamorphic way.\nMore specifically, let us introduce the three-way transitivity relation in Figure 5. There, the three source inputs x1,x2,x3 are combined to form all possible input pairs xij = (xi,xj). Then, we can test whether their corresponding outputs are transitive with the following output property:\nP : v(y12) ∧ v(y23)⇒ v(y13) (6)\nwhere v(·) : Y → {0, 1} is the Boolean prediction of model f . Note that the output property P , being defined over three outputs, has a different structure from those in Sections 3, 4 and 5."
    }, {
      "heading" : "6.1 Illustrative example: three-way transitivity of lexical relations",
      "text" : "In this section, we apply the metamorphic structure from Figure 5 to test the transitivity of lexical semantic relations, e.g. synonymy and hypernymy (Santus et al., 2016). In general, learning these linguistic properties is crucial for solving several NLI tasks (Glockner et al., 2018). Thus, we can expect an NLP model to generalise over them in a transitive way. We can test whether this is true in the following way:\n• Transformation T . The model f we test already accepts a pair of words xij = (xi,xj) as input. Thus, T is merely a formalism here.\n• Output Property P . Property P in Equation 6 depends on the definition of v(·). Here, we train two classification heads on top of a pretrained model f . The first vsyn(·) predicts synonymy, the second vhyp(·) hypernymy.\nNote that transitivity can be tested in a supervised fashion by comparing the model’s predictions to a ground truth (Yanaka et al., 2021). In contrast, the three-way transitivity relations we propose test the internal transitivity of a model trained to predict lexical relations.\nExperiment description and results. We reproduce a state-of-the-art model for lexical relations (Wachowiak et al., 2020), which is a finetuned version of the multi-lingual transformer model xlmroberta (Conneau et al., 2020). We extract the multi-lingual test set from the CogALex_VI shared task (Santus et al., 2016), and generate a random sample of source triplets from its corpus of words, keeping those that satisfy v(y12) ∧ v(y23). We present our empirical results in Table 5, organised by the language of the source words and lexical relation v predicted by the model. As the table shows, this state-of-the-art NLP model fails to predict v(y13) in a transitive way across all languages. This is in contrast with the results of classic supervised testing in Wachowiak et al. (2020), which show that their model can predict the correct lexical relations (synonym, hypernym, antonym or random) with at least 0.5 of accuracy."
    }, {
      "heading" : "7 Conclusions and future work",
      "text" : "In this paper, we presented three new classes on metamorphic relations. Thanks to them, we could test the systematicity, compositionality and transitivity of state-of-the-art NLP models. The advantage of our approach is that it does not rely on ground-truth annotations. It can generate a polynomially larger number of test cases than supervised testing, revealing whether the NLP model under test is internally consistent.\nStill, testing is only one side of the coin. Like in recent work about robustness (Aspillaga et al., 2020), the tested models have not been trained on a metamorphic objective (e.g. as an additional loss term). We believe that doing so could improve the safety and consistency of a model’s predictions."
    }, {
      "heading" : "Appendix A. Ethics statement",
      "text" : "Intelligent systems are becoming increasingly widespread, and NLP models are often used as important components in their architecture. However, once these systems are deployed in the real world, there is a risk of them exhibiting biased, erratic or dangerous behaviour. In order to prevent such events from happening, it is crucial to perform a thorough testing and validation process. Indeed, this is one of the tenets of the ACM Code of Ethics and Professional Conduct3. Namely, paragraph 2.5 therein recites “Extraordinary care should be taken to identify and mitigate potential risks in machine learning systems.” The contributions we propose in the present paper are directed towards this goal. More specifically, we believe that metamorphic testing is a valuable tool in the model tester’s arsenal, and our contributions widen its scope of application. As a result, more instances of unwanted behaviour can be identified and addressed before their impact is felt by the end user."
    }, {
      "heading" : "Appendix B. Quick-reference guide",
      "text" : "In this paper, we discuss and compare four classes of metamorphic relations. For ease of reference, we summarise them in Tables 6, 7, 8 and 9. These tables contain the formal definitions of the transformation T and output property P , a concrete example of possible inputs, and a reference to the corresponding sections in the present paper.\n3https://www.acm.org/code-of-ethics"
    } ],
    "references" : [ {
      "title" : "Stress test evaluation of transformerbased models in natural language understanding tasks",
      "author" : [ "Carlos Aspillaga", "Andrés Carvallo", "Vladimir Araujo." ],
      "venue" : "Proceedings of the 12th Language Resources and Evaluation Conference, pages 1882–",
      "citeRegEx" : "Aspillaga et al\\.,? 2020",
      "shortCiteRegEx" : "Aspillaga et al\\.",
      "year" : 2020
    }, {
      "title" : "Linguistic generalization and compositionality in modern artificial neural networks",
      "author" : [ "Marco Baroni." ],
      "venue" : "Philosophical Transactions of the Royal Society B: Biological Sciences, 375(1791):20190307.",
      "citeRegEx" : "Baroni.,? 2020",
      "shortCiteRegEx" : "Baroni.",
      "year" : 2020
    }, {
      "title" : "The oracle problem in software testing: A survey",
      "author" : [ "Earl T. Barr", "Mark Harman", "Phil McMinn", "Muzammil Shahbaz", "Shin Yoo." ],
      "venue" : "IEEE Transactions on Software Engineering, 41(5):507–525.",
      "citeRegEx" : "Barr et al\\.,? 2015",
      "shortCiteRegEx" : "Barr et al\\.",
      "year" : 2015
    }, {
      "title" : "Synthetic and natural noise both break neural machine translation",
      "author" : [ "Yonatan Belinkov", "Yonatan Bisk." ],
      "venue" : "International Conference on Learning Representations.",
      "citeRegEx" : "Belinkov and Bisk.,? 2018",
      "shortCiteRegEx" : "Belinkov and Bisk.",
      "year" : 2018
    }, {
      "title" : "What do neural machine translation models learn about morphology? In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Vol",
      "author" : [ "Yonatan Belinkov", "Nadir Durrani", "Fahim Dalvi", "Hassan Sajjad", "James Glass" ],
      "venue" : null,
      "citeRegEx" : "Belinkov et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Belinkov et al\\.",
      "year" : 2017
    }, {
      "title" : "Pattern Recognition and Machine Learning (Information Science and Statistics)",
      "author" : [ "Christopher M. Bishop." ],
      "venue" : "Springer-Verlag, Berlin, Heidelberg.",
      "citeRegEx" : "Bishop.,? 2006",
      "shortCiteRegEx" : "Bishop.",
      "year" : 2006
    }, {
      "title" : "Breaking neural reasoning architectures with metamorphic relation-based adversarial examples",
      "author" : [ "Alvin Chan", "Lei Ma", "Felix Juefei-Xu", "Yew-Soon Ong", "Xiaofei Xie", "Minhui Xue", "Yang Liu." ],
      "venue" : "IEEE Transactions on Neural Networks and Learning Sys-",
      "citeRegEx" : "Chan et al\\.,? 2021",
      "shortCiteRegEx" : "Chan et al\\.",
      "year" : 2021
    }, {
      "title" : "Metamorphic testing: A review of challenges and opportunities",
      "author" : [ "Tsong Yueh Chen", "Fei-Ching Kuo", "Huai Liu", "Pak-Lok Poon", "Dave Towey", "T.H. Tse", "Zhi Quan Zhou." ],
      "venue" : "ACM Comput. Surv., 51(1).",
      "citeRegEx" : "Chen et al\\.,? 2018",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2018
    }, {
      "title" : "Unsupervised cross-lingual representation learning at scale",
      "author" : [ "Guzmán", "Edouard Grave", "Myle Ott", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 8440–",
      "citeRegEx" : "Guzmán et al\\.,? 2020",
      "shortCiteRegEx" : "Guzmán et al\\.",
      "year" : 2020
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Probing for semantic evidence of composition by means of simple classification tasks",
      "author" : [ "Allyson Ettinger", "Ahmed Elgohary", "Philip Resnik." ],
      "venue" : "Proceedings of the 1st Workshop on Evaluating Vector-Space Representations for NLP, pages 134–139, Berlin,",
      "citeRegEx" : "Ettinger et al\\.,? 2016",
      "shortCiteRegEx" : "Ettinger et al\\.",
      "year" : 2016
    }, {
      "title" : "Connectionism and cognitive architecture: A critical analysis",
      "author" : [ "Jerry A. Fodor", "Zenon W. Pylyshyn." ],
      "venue" : "Cognition, 28(1):3–71.",
      "citeRegEx" : "Fodor and Pylyshyn.,? 1988",
      "shortCiteRegEx" : "Fodor and Pylyshyn.",
      "year" : 1988
    }, {
      "title" : "Black-box generation of adversarial text sequences to evade deep learning classifiers",
      "author" : [ "Ji Gao", "Jack Lanchantin", "Mary Lou Soffa", "Yanjun Qi." ],
      "venue" : "2018 IEEE Security and Privacy Workshops (SPW), pages 50–56.",
      "citeRegEx" : "Gao et al\\.,? 2018",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2018
    }, {
      "title" : "Breaking NLI systems with sentences that require simple lexical inferences",
      "author" : [ "Max Glockner", "Vered Shwartz", "Yoav Goldberg." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),",
      "citeRegEx" : "Glockner et al\\.,? 2018",
      "shortCiteRegEx" : "Glockner et al\\.",
      "year" : 2018
    }, {
      "title" : "Probing linguistic systematicity",
      "author" : [ "Emily Goodwin", "Koustuv Sinha", "Timothy J. O’Donnell" ],
      "venue" : "In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,",
      "citeRegEx" : "Goodwin et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Goodwin et al\\.",
      "year" : 2020
    }, {
      "title" : "How robust are characterbased word embeddings in tagging and MT against wrod scramlbing or randdm nouse",
      "author" : [ "Georg Heigold", "Stalin Varanasi", "Günter Neumann", "Josef van Genabith" ],
      "venue" : "In Proceedings of the 13th Conference of the Association",
      "citeRegEx" : "Heigold et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Heigold et al\\.",
      "year" : 2018
    }, {
      "title" : "A structural probe for finding syntax in word representations",
      "author" : [ "John Hewitt", "Christopher D. Manning." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language",
      "citeRegEx" : "Hewitt and Manning.,? 2019",
      "shortCiteRegEx" : "Hewitt and Manning.",
      "year" : 2019
    }, {
      "title" : "Compositionality decomposed: how do neural networks generalise",
      "author" : [ "Dieuwke Hupkes", "Verna Dankers", "Mathijs Mul", "Elia Bruni" ],
      "venue" : "Journal of Artificial Intelligence Research,",
      "citeRegEx" : "Hupkes et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Hupkes et al\\.",
      "year" : 2020
    }, {
      "title" : "Certified robustness to adversarial word substitutions",
      "author" : [ "Robin Jia", "Aditi Raghunathan", "Kerem Göksel", "Percy Liang." ],
      "venue" : "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International",
      "citeRegEx" : "Jia et al\\.,? 2019",
      "shortCiteRegEx" : "Jia et al\\.",
      "year" : 2019
    }, {
      "title" : "Assessing robustness of text classification through maximal safe radius computation",
      "author" : [ "Emanuele La Malfa", "Min Wu", "Luca Laurenti", "Benjie Wang", "Anthony Hartshorn", "Marta Kwiatkowska." ],
      "venue" : "Findings of the Association for Computational Linguis-",
      "citeRegEx" : "Malfa et al\\.,? 2020",
      "shortCiteRegEx" : "Malfa et al\\.",
      "year" : 2020
    }, {
      "title" : "Robust training under linguistic adversity",
      "author" : [ "Yitong Li", "Trevor Cohn", "Timothy Baldwin." ],
      "venue" : "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 2, Short Papers, pages 21–27, Va-",
      "citeRegEx" : "Li et al\\.,? 2017",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2017
    }, {
      "title" : "Linguistic knowledge and transferability of contextual representations",
      "author" : [ "Nelson F. Liu", "Matt Gardner", "Yonatan Belinkov", "Matthew E. Peters", "Noah A. Smith." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Associ-",
      "citeRegEx" : "Liu et al\\.,? 2019a",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "RoBERTa: A robustly optimized bert pretraining approach",
      "author" : [ "Y. Liu", "Myle Ott", "Naman Goyal", "Jingfei Du", "Mandar Joshi", "Danqi Chen", "Omer Levy", "M. Lewis", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "ArXiv, abs/1907.11692.",
      "citeRegEx" : "Liu et al\\.,? 2019b",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Metamorphic testing and certified mitigation of fairness violations in NLP models",
      "author" : [ "Pingchuan Ma", "Shuai Wang", "Jin Liu." ],
      "venue" : "Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, pages 458–465. ij-",
      "citeRegEx" : "Ma et al\\.,? 2020",
      "shortCiteRegEx" : "Ma et al\\.",
      "year" : 2020
    }, {
      "title" : "Beyond accuracy: Behavioral testing of NLP models with CheckList",
      "author" : [ "Marco Tulio Ribeiro", "Tongshuang Wu", "Carlos Guestrin", "Sameer Singh." ],
      "venue" : "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pages 4902–",
      "citeRegEx" : "Ribeiro et al\\.,? 2020",
      "shortCiteRegEx" : "Ribeiro et al\\.",
      "year" : 2020
    }, {
      "title" : "Supporting context monotonicity abstractions in neural NLI models",
      "author" : [ "Julia Rozanova", "Deborah Ferreira", "Mokanarangan Thayaparan", "Marco Valentino", "André Freitas." ],
      "venue" : "CoRR, abs/2105.08008.",
      "citeRegEx" : "Rozanova et al\\.,? 2021",
      "shortCiteRegEx" : "Rozanova et al\\.",
      "year" : 2021
    }, {
      "title" : "The CogALex-V shared task on the corpus-based identification of semantic relations",
      "author" : [ "Enrico Santus", "Anna Gladkova", "Stefan Evert", "Alessandro Lenci." ],
      "venue" : "Proceedings of the 5th Workshop on Cognitive Aspects of the Lexicon (CogALex - V),",
      "citeRegEx" : "Santus et al\\.,? 2016",
      "shortCiteRegEx" : "Santus et al\\.",
      "year" : 2016
    }, {
      "title" : "Parsing with compositional vector grammars",
      "author" : [ "Richard Socher", "John Bauer", "Christopher D. Manning", "Andrew Y. Ng." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages",
      "citeRegEx" : "Socher et al\\.,? 2013",
      "shortCiteRegEx" : "Socher et al\\.",
      "year" : 2013
    }, {
      "title" : "Metamorphic testing for machine translations: Mt4mt",
      "author" : [ "Liqun Sun", "Zhi Quan Zhou." ],
      "venue" : "2018 25th Australasian Software Engineering Conference (ASWEC), pages 96–100.",
      "citeRegEx" : "Sun and Zhou.,? 2018",
      "shortCiteRegEx" : "Sun and Zhou.",
      "year" : 2018
    }, {
      "title" : "On the value of out-of-distribution testing: An example of goodhart's law",
      "author" : [ "Damien Teney", "Ehsan Abbasnejad", "Kushal Kafle", "Robik Shrestha", "Christopher Kanan", "Anton van den Hengel." ],
      "venue" : "Advances in Neural Information Processing Systems,",
      "citeRegEx" : "Teney et al\\.,? 2020",
      "shortCiteRegEx" : "Teney et al\\.",
      "year" : 2020
    }, {
      "title" : "A metamorphic testing approach for assessing question answering systems",
      "author" : [ "Kaiyi Tu", "Mingyue Jiang", "Zuohua Ding." ],
      "venue" : "Mathematics, 9(7).",
      "citeRegEx" : "Tu et al\\.,? 2021",
      "shortCiteRegEx" : "Tu et al\\.",
      "year" : 2021
    }, {
      "title" : "CogALex-VI shared task: Transrelation - a robust multilingual language model for multilingual relation identification",
      "author" : [ "Lennart Wachowiak", "Christian Lang", "Barbara Heinisch", "Dagmar Gromann." ],
      "venue" : "Proceedings of the Workshop on the Cognitive As-",
      "citeRegEx" : "Wachowiak et al\\.,? 2020",
      "shortCiteRegEx" : "Wachowiak et al\\.",
      "year" : 2020
    }, {
      "title" : "HELP: A dataset for identifying shortcomings of neural models in monotonicity reasoning",
      "author" : [ "Hitomi Yanaka", "Koji Mineshima", "Daisuke Bekki", "Kentaro Inui", "Satoshi Sekine", "Lasha Abzianidze", "Johan Bos." ],
      "venue" : "Proceedings of the Eighth Joint Con-",
      "citeRegEx" : "Yanaka et al\\.,? 2019",
      "shortCiteRegEx" : "Yanaka et al\\.",
      "year" : 2019
    }, {
      "title" : "Exploring transitivity in neural NLI models through veridicality",
      "author" : [ "Hitomi Yanaka", "Koji Mineshima", "Kentaro Inui." ],
      "venue" : "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume,",
      "citeRegEx" : "Yanaka et al\\.,? 2021",
      "shortCiteRegEx" : "Yanaka et al\\.",
      "year" : 2021
    }, {
      "title" : "Benchmarking zero-shot text classification: Datasets, evaluation and entailment approach",
      "author" : [ "Wenpeng Yin", "Jamaal Hay", "Dan Roth." ],
      "venue" : "10",
      "citeRegEx" : "Yin et al\\.,? 2019",
      "shortCiteRegEx" : "Yin et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 9,
      "context" : "Many recent advances in neural models for NLP have been driven by the ability to learn from unlabeled data (Devlin et al., 2019; Liu et al., 2019b).",
      "startOffset" : 107,
      "endOffset" : 147
    }, {
      "referenceID" : 22,
      "context" : "Many recent advances in neural models for NLP have been driven by the ability to learn from unlabeled data (Devlin et al., 2019; Liu et al., 2019b).",
      "startOffset" : 107,
      "endOffset" : 147
    }, {
      "referenceID" : 34,
      "context" : "Instead, both in-distribution testing and out-of-distribution testing (Yin et al., 2019; Teney et al., 2020) rely on comparing the model’s predictions to the ground truth.",
      "startOffset" : 70,
      "endOffset" : 108
    }, {
      "referenceID" : 29,
      "context" : "Instead, both in-distribution testing and out-of-distribution testing (Yin et al., 2019; Teney et al., 2020) rely on comparing the model’s predictions to the ground truth.",
      "startOffset" : 70,
      "endOffset" : 108
    }, {
      "referenceID" : 10,
      "context" : "Similarly, attempts at probing the internal computation of large NLP models use supervised classifiers as a diagnostic tool (Ettinger et al., 2016; Belinkov et al., 2017).",
      "startOffset" : 124,
      "endOffset" : 170
    }, {
      "referenceID" : 4,
      "context" : "Similarly, attempts at probing the internal computation of large NLP models use supervised classifiers as a diagnostic tool (Ettinger et al., 2016; Belinkov et al., 2017).",
      "startOffset" : 124,
      "endOffset" : 170
    }, {
      "referenceID" : 2,
      "context" : "In general, such extreme reliance on groundtruth data limits the quantity and quality of test cases we can produce, which is a known problem in the software testing community (Barr et al., 2015).",
      "startOffset" : 175,
      "endOffset" : 194
    }, {
      "referenceID" : 7,
      "context" : "In this regard, a promising solution is metamorphic testing (Chen et al., 2018).",
      "startOffset" : 60,
      "endOffset" : 79
    }, {
      "referenceID" : 24,
      "context" : "Under this paradigm, we test the internal consistency of an NLP model by checking whether it satisfies a necessary relation of its inputs and outputs (Ribeiro et al., 2020).",
      "startOffset" : 150,
      "endOffset" : 172
    }, {
      "referenceID" : 0,
      "context" : "Indeed, the majority of them are robustness relations, which require that the output of an NLP model remains stable in the face of small input perturbations (Aspillaga et al., 2020).",
      "startOffset" : 157,
      "endOffset" : 181
    }, {
      "referenceID" : 3,
      "context" : "These perturbations may involve simple typos (Belinkov and Bisk, 2018; Gao et al., 2018; Heigold et al., 2018), replacing individual words with a synonym (Li et al.",
      "startOffset" : 45,
      "endOffset" : 110
    }, {
      "referenceID" : 12,
      "context" : "These perturbations may involve simple typos (Belinkov and Bisk, 2018; Gao et al., 2018; Heigold et al., 2018), replacing individual words with a synonym (Li et al.",
      "startOffset" : 45,
      "endOffset" : 110
    }, {
      "referenceID" : 15,
      "context" : "These perturbations may involve simple typos (Belinkov and Bisk, 2018; Gao et al., 2018; Heigold et al., 2018), replacing individual words with a synonym (Li et al.",
      "startOffset" : 45,
      "endOffset" : 110
    }, {
      "referenceID" : 20,
      "context" : ", 2018), replacing individual words with a synonym (Li et al., 2017; Jia et al., 2019; La Malfa et al., 2020), or adding irrelevant information to the input (Tu et al.",
      "startOffset" : 51,
      "endOffset" : 109
    }, {
      "referenceID" : 18,
      "context" : ", 2018), replacing individual words with a synonym (Li et al., 2017; Jia et al., 2019; La Malfa et al., 2020), or adding irrelevant information to the input (Tu et al.",
      "startOffset" : 51,
      "endOffset" : 109
    }, {
      "referenceID" : 30,
      "context" : ", 2020), or adding irrelevant information to the input (Tu et al., 2021).",
      "startOffset" : 55,
      "endOffset" : 72
    }, {
      "referenceID" : 24,
      "context" : "Due to their simple structure, robustness-like relations have been applied to the testing of several NLP tasks, including sentiment analysis (Ribeiro et al., 2020), machine translation (Sun and Zhou, 2018), and question answering (Chan et al.",
      "startOffset" : 141,
      "endOffset" : 163
    }, {
      "referenceID" : 28,
      "context" : ", 2020), machine translation (Sun and Zhou, 2018), and question answering (Chan et al.",
      "startOffset" : 29,
      "endOffset" : 49
    }, {
      "referenceID" : 6,
      "context" : ", 2020), machine translation (Sun and Zhou, 2018), and question answering (Chan et al., 2021).",
      "startOffset" : 74,
      "endOffset" : 93
    }, {
      "referenceID" : 23,
      "context" : "Even testing the fairness of NLP models falls in this category (Ma et al., 2020).",
      "startOffset" : 63,
      "endOffset" : 80
    }, {
      "referenceID" : 11,
      "context" : "their ability to understand some inputs should be intrinsically connected to their ability to understand related ones (Fodor and Pylyshyn, 1988).",
      "startOffset" : 118,
      "endOffset" : 144
    }, {
      "referenceID" : 17,
      "context" : "While the exact definition of systematic behaviour varies in the literature (Hupkes et al., 2020), a common requirement is that the model’s predictions are a result of a composition of syntactic and semantic constituents of the input (Baroni, 2020).",
      "startOffset" : 76,
      "endOffset" : 97
    }, {
      "referenceID" : 1,
      "context" : ", 2020), a common requirement is that the model’s predictions are a result of a composition of syntactic and semantic constituents of the input (Baroni, 2020).",
      "startOffset" : 144,
      "endOffset" : 158
    }, {
      "referenceID" : 7,
      "context" : "In general, a metamorphic relation can be defined as (Chen et al., 2018):",
      "startOffset" : 53,
      "endOffset" : 72
    }, {
      "referenceID" : 7,
      "context" : "Thus, let us discriminate between two types of inputs (Chen et al., 2018):",
      "startOffset" : 54,
      "endOffset" : 73
    }, {
      "referenceID" : 3,
      "context" : "Examples include replacing individual characters with a neighbouring one on a computer keyboard (Belinkov and Bisk, 2018) or a random one (Heigold et al.",
      "startOffset" : 96,
      "endOffset" : 121
    }, {
      "referenceID" : 15,
      "context" : "Examples include replacing individual characters with a neighbouring one on a computer keyboard (Belinkov and Bisk, 2018) or a random one (Heigold et al., 2018).",
      "startOffset" : 138,
      "endOffset" : 160
    }, {
      "referenceID" : 3,
      "context" : "More aggressive transformations may involve swapping neighbouring characters (Belinkov and Bisk, 2018; Gao et al., 2018; Heigold et al., 2018) and shuffling a subset of the characters in a word (Belinkov and Bisk, 2018).",
      "startOffset" : 77,
      "endOffset" : 142
    }, {
      "referenceID" : 12,
      "context" : "More aggressive transformations may involve swapping neighbouring characters (Belinkov and Bisk, 2018; Gao et al., 2018; Heigold et al., 2018) and shuffling a subset of the characters in a word (Belinkov and Bisk, 2018).",
      "startOffset" : 77,
      "endOffset" : 142
    }, {
      "referenceID" : 15,
      "context" : "More aggressive transformations may involve swapping neighbouring characters (Belinkov and Bisk, 2018; Gao et al., 2018; Heigold et al., 2018) and shuffling a subset of the characters in a word (Belinkov and Bisk, 2018).",
      "startOffset" : 77,
      "endOffset" : 142
    }, {
      "referenceID" : 3,
      "context" : ", 2018) and shuffling a subset of the characters in a word (Belinkov and Bisk, 2018).",
      "startOffset" : 59,
      "endOffset" : 84
    }, {
      "referenceID" : 20,
      "context" : "A common word-level transformation involves replacing words with their synonym (Li et al., 2017).",
      "startOffset" : 79,
      "endOffset" : 96
    }, {
      "referenceID" : 18,
      "context" : "This operation has been shown to produce adversarial examples in (Jia et al., 2019; La Malfa et al., 2020).",
      "startOffset" : 65,
      "endOffset" : 106
    }, {
      "referenceID" : 23,
      "context" : "of keywords in the input text can reveal the social biases of an NLP model (Ma et al., 2020).",
      "startOffset" : 75,
      "endOffset" : 92
    }, {
      "referenceID" : 24,
      "context" : "Similarly, swapping keywords in the context of a question-answer (QA) system can reveal inconsistent answers (Ribeiro et al., 2020).",
      "startOffset" : 109,
      "endOffset" : 131
    }, {
      "referenceID" : 30,
      "context" : "More generally, the whole input text can have its sentences shuffled (Tu et al., 2021) or paraphrased (Li et al.",
      "startOffset" : 69,
      "endOffset" : 86
    }, {
      "referenceID" : 28,
      "context" : "In rarer cases, where the output is textual, verbatim comparison can be used (Sun and Zhou, 2018).",
      "startOffset" : 77,
      "endOffset" : 97
    }, {
      "referenceID" : 30,
      "context" : "cosine similarity between the embeddings of the two answers (Tu et al., 2021).",
      "startOffset" : 60,
      "endOffset" : 77
    }, {
      "referenceID" : 22,
      "context" : "We select a fine-tuned version of RoBERTa (Liu et al., 2019b) for sentiment analysis from the HuggingFace library.",
      "startOffset" : 42,
      "endOffset" : 61
    }, {
      "referenceID" : 7,
      "context" : "Metamorphic relations impose constraints between the inputs and outputs while treating the model f as a black box (Chen et al., 2018).",
      "startOffset" : 114,
      "endOffset" : 133
    }, {
      "referenceID" : 5,
      "context" : "Indeed, equality (see Equation 1) is defined over the softmax outputs, which are affine combinations of the embeddings (Bishop, 2006).",
      "startOffset" : 119,
      "endOffset" : 133
    }, {
      "referenceID" : 1,
      "context" : "The presence of such building blocks is a necessary condition for an NLP model to exhibit compositional behaviour (Baroni, 2020).",
      "startOffset" : 114,
      "endOffset" : 128
    }, {
      "referenceID" : 21,
      "context" : "Train a linear probe shyp on z (Liu et al., 2019a) to predict whether `a is a hypernym of `b.",
      "startOffset" : 31,
      "endOffset" : 50
    }, {
      "referenceID" : 32,
      "context" : "This phenomenon is known in the literature (Yanaka et al., 2019), but we show that metamorphic testing can independently detect it.",
      "startOffset" : 43,
      "endOffset" : 64
    }, {
      "referenceID" : 13,
      "context" : "In general, learning these linguistic properties is crucial for solving several NLI tasks (Glockner et al., 2018).",
      "startOffset" : 90,
      "endOffset" : 113
    }, {
      "referenceID" : 33,
      "context" : "Note that transitivity can be tested in a supervised fashion by comparing the model’s predictions to a ground truth (Yanaka et al., 2021).",
      "startOffset" : 116,
      "endOffset" : 137
    }, {
      "referenceID" : 31,
      "context" : "We reproduce a state-of-the-art model for lexical relations (Wachowiak et al., 2020), which is a finetuned version of the multi-lingual transformer model xlmroberta (Conneau et al.",
      "startOffset" : 60,
      "endOffset" : 84
    }, {
      "referenceID" : 26,
      "context" : "We extract the multi-lingual test set from the CogALex_VI shared task (Santus et al., 2016), and generate a random sample of source triplets from",
      "startOffset" : 70,
      "endOffset" : 91
    }, {
      "referenceID" : 0,
      "context" : "Like in recent work about robustness (Aspillaga et al., 2020), the tested models have not been trained on a metamorphic objective (e.",
      "startOffset" : 37,
      "endOffset" : 61
    } ],
    "year" : 0,
    "abstractText" : "Metamorphic testing has recently been used to check the safety of neural NLP models. Its main advantage is that it does not rely on a ground truth to generate test cases. However, existing studies are mostly concerned with robustness-like metamorphic relations, limiting the scope of linguistic properties they can test. We propose three new classes of metamorphic relations, which address the properties of systematicity, compositionality and transitivity. Unlike robustness, our relations are defined over multiple source inputs, thus increasing the number of test cases that we can produce by a polynomial factor. With them, we test the internal consistency of state-of-theart NLP models, and show that they do not always behave according to their expected linguistic properties. Lastly, we introduce a novel graphical notation that efficiently summarises the inner structure of metamorphic relations.",
    "creator" : null
  }
}