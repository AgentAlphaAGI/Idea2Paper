{
  "name" : "ARR_2022_177_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Translation Error Detection as Rationale Extraction",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Quality Estimation (QE) is the task of predicting Machine Translation (MT) quality at inference time, when no gold standard human translation is available (Blatz et al., 2004; Specia et al., 2009). QE can be framed as a word-level or a sentencelevel task. Both tasks have numerous practical applications, such as deciding whether a given MT output can be published without editing, highlighting potential critical errors. Current QE approaches fine-tune powerful representations from pre-trained multilingual encoders such as BERT (Devlin et al., 2018) or XLM-R (Conneau et al., 2019). In the recent Shared Task on QE at WMT2020 (Specia et al., 2020) these approaches have achieved very high performance at predicting sentence-level translation quality (up to 0.9 Pearson correlation with human judgements for some language pairs). How-\never, as evidenced by these results, the accuracy of word-level prediction still leaves room for improvement. This is partly due to the limited amount of training data. Word-level error annotation is especially time-consuming and expensive, as it requires work from bilingual experts. In this work we introduce a new semi-supervised approach to word-level QE that removes the need of training data at word level. To achieve this, we propose addressing QE as a rationale extraction task (Lei et al., 2016).\nExplainability is a broad area aimed at explaining predictions of machine learning models (Lipton, 2016). Rationale extraction methods achieve this by selecting a portion of the input that justifies model output for a given data point. In translation, human perception of quality is guided by the presence of translation errors (Freitag et al., 2021). We hypothesize that sentence-level QE models also rely on translation errors to make predictions. If that is the case, explanations for sentence-level predictions can be used to detect translation errors, thus removing the need for word-level labeled training data. To extract model explanations, we use post hoc rationale extraction methods (Sundararajan et al., 2017) which try to explain the predictions of a given model (as opposed to modifying its architecture or introducing constraints during training), since one of our goals is to study to what extent existing QE models rely on the same information as humans to make predictions.\nAt the same time, by using word-level errors as explanations for sentence-level QE scores, we introduce a new benchmark for evaluating explainability methods. Recent work has introduced various datasets for measuring the agreement between rationales extracted from NLP models and those provided by humans (DeYoung et al., 2019). QE is different from these datasets in various important aspects. First, it is a regression task, as opposed to binary or multiclass text classification mainly explored in previous work. Second, it is a multi-\nlingual task where the output score captures the relationship between source and target sentences. Finally, manual annotation of translation errors is a practical task with a long tradition in MT research and translation studies (Lommel et al., 2014), and thus offers an interesting alternative to human explanations collected specifically for evaluating rationale extraction methods.\nOur main contributions are:\n• We introduce a novel semi-supervised approach for word-level QE. We provide practical recipes on how feature attribution methods can be used to derive information on translation errors from sentence-level models.\n• We provide insights into the behaviour of state-of-the-art (SOTA) QE models by analysing attributions to different parts of the input sequence (source vs. target sentence, correct words vs. errors) at different hidden layers.\n• We propose to use the QE task as a new benchmark for evaluating the plausibility of feature attribution explanations, i.e. how interpretable model explanations are to humans (Jacovi and Goldberg, 2020)."
    }, {
      "heading" : "2 Background and Related Work",
      "text" : "Quality Estimation Current SOTA models in sentence-level QE, which is typically framed as a regression task, mainly use multilingual representations from pre-trained transformers (Devlin et al., 2018), notably XLM-R (Conneau et al., 2019). The input to a sentence-level QE model is a concatenation of the source and translated sentences, separated by the [SEP] token. The sequence is encoded by the pre-trained Transformer model, and the [CLS] token is passed through a multilayer perceptron (MLP) layer to obtain a sentence-level score. During fine-tuning both the parameters of the pre-trained model and the parameters corresponding to the MLP layer are updated.\nWord-level QE is typically addressed as a binary classification task, where the QE model needs to predict a binary label indicating whether a word is correct or wrong for each word in the MT output (Lee, 2020). As illustrated in Figure 1 (left), some supervised approaches use both sentence-level and word-level objectives in a multi-task setting, which results in superior performance (Kim et al., 2017;\nLee, 2020). Methods that do not require word-level training data either need access to the MT model (Rikters and Fishel, 2017; Fomicheva et al., 2020b), or still treat the problem as a supervised task but use synthetically generated data for supervision (Tuan et al., 2021).\nRationale Extraction for NLP SOTA NLP models based on deep neural networks achieve high performance in a variety of tasks, often at the cost of interpretability (Lipton, 2016). Recent work aims to address this issue by focusing on two different goals. On the one hand, the aim is to produce justifications for model predictions that are plausible to the users, in order to increase users’ trust (Ribeiro et al., 2016). On the other hand, the aim is to reveal the inner workings of the model and faithfully explain its predictions, so the explanation can be useful to model developers (Jacovi and Goldberg, 2020).\nTypically, explainability methods operate by selecting a portion of the input that justifies model prediction for a single data point. This can be done either by modifying the model architecture, or by trying to explain the predictions of a given model. The first type of approaches (a.k.a. rationalization by construction) involves imposing restrictions on the generated rationales to satisfy certain constraints, e.g. compactness (Yu et al., 2019; Chalkidis et al., 2021). Note that such restrictions often result in lower performance and indeed are not guaranteed to explain the behaviour of an unconstrained model (Jain et al., 2020). The second type of approaches (the so called post hoc) usually rely on feature attribution methods, which assign an importance value to each input feature of a network (Sundararajan et al., 2017; Schulz et al., 2020). These methods do not allow for introducing useful biases during training, but focus on faithfully explaining model behaviour.\nFeature attribution has a long tradition in image recognition tasks (Simonyan et al., 2013) and only recently have been applied to some NLP tasks, most commonly text classification (DeYoung et al., 2019). QE is fundamentally different from text classification where clues are typically separate words or phrases (Zaidan et al., 2007) which often can be considered independently of the rest of the text. This independence assumption does not hold for the task of evaluating translation quality where a word cannot be identified as a clue (e.g. translation error) without considering the surrounding context.\nFurthermore, SOTA NLP models based on contextualized representations for input words make rationale extraction especially challenging, as the representation for a given word can encode not only the word identity but also its interactions with other words in the text. Recent work has revealed various interesting properties that characterize the information flow through hidden layers in deep transformer models (Voita et al., 2019; De Cao et al., 2020; Yun et al., 2021). We provide additional insights on this topic in Section 5.2."
    }, {
      "heading" : "3 Translation Error Prediction as Rationale Extraction",
      "text" : "We propose framing semi-supervised word-level QE as rationale extraction from sentence-level QE models. Instead of training a dedicated supervised model for word-level prediction, we propose deriving word-level scores from a strong sentence-level QE model by extracting explanations for model predictions (see Figure 1 (right)). Given a trained sentence-level QE model and the test data, rationale extraction methods detect the parts of the input that are relevant for model predictions on a sampleby-sample basis. We hypothesize that words with the highest relevance scores should correspond to actual translation errors on word-level."
    }, {
      "heading" : "3.1 Approach",
      "text" : "More formally, given the source sequence xS= xS1 ,...,x S |S|, the target sequence x T=xT1 ,...,x T |T | and the QE model M(xS ,xT )=ŷ that predicts sentence MT quality, a feature attribution method produces a vector of attribution scores a= a1,...,a|S+T |, which represent the contribution of each source and target word to the prediction ŷ.\nCrucially, no word-level labels are required for training. For evaluation, the attribution scores\nare compared against binary gold labels w= w1,...,w|T |∈{0,1} indicating whether each given word in the target sequence is an error or correct.\nThe predictive models for QE explored in our experiments are built by fine-tuning multilingual representations from pre-trained transformers. Transformer model starts from context-agnostic representations consisting of positional and token embeddings. These representations are passed through a set of hidden layers where at each layer the representations are iteratively updated via multi-head attention. This allows the hidden representation for each token to encode information on other words in the sentence.\nWe note that attribution to the input tokens or to the embedding layer can hardly succeed in detecting translation errors, as those cannot be identified independently from the context given by the source and target sentence. In this work, we perform feature attribution to hidden states at different layers and analyse which layer results in attribution scores that best correspond to translation errors."
    }, {
      "heading" : "3.2 Feature Attribution Methods",
      "text" : "Feature attribution methods can be divided into those providing explanations by simplification, such as LIME (Ribeiro et al., 2016); gradientbased explanations (Sundararajan et al., 2017); and perturbation-based explanations (Schulz et al., 2020).\nWe select three popular methods for rationale extraction, which (i) do not require modifying the model architecture or re-training the model and (ii) allow attribution to hidden states. For comparison, we also use LIME which operates directly on the input text. We note that this set is not exhaustive of SOTA rationale extraction methods. Our main goal is not to conduct a comparative study of feature\nattribution methods but rather testing whether it is possible to address word-level QE as a rationale extraction task without any word-level supervision.\nLIME (Ribeiro et al., 2016) is a simplificationbased explanation technique, which fits a sparse linear model in the vicinity of each test instance, to approximate the decision boundary of the complex model.1 The data for fitting the linear model is produced by perturbing the given instance and computing model predictions. Linear model coefficients are then used as attribution scores for each input feature. For NLP tasks features correspond to input tokens and perturbation is achieved by randomly removing words from the sequence.\nInformation Bottleneck is a perturbation-based method originally proposed by Schulz et al. (2020) for the task of image recognition. The method applies the idea of information bottleneck (Tishby and Zaslavsky, 2015) for feature attribution. Specifically, it injects noise into an intermediate layer representation. The amount of noise injected at the position corresponding to each input feature is optimized to minimize the loss of the main task while at the same time maximizing the overall amount of injected noise.\nIntegrated Gradients (Sundararajan et al., 2017) is a gradient-based method similar to the traditional salience and input∗gradients approaches (Simonyan et al., 2013). The latter takes the signed partial derivatives of the output with respect to the input and multiply them by the input itself. Intuitively, this is analogous to inspecting the products of model coefficients and feature values in linear models (Sundararajan et al., 2017). Integrated gradients improves on that by defining a baseline input and computing the average gradient while the input varies along a linear path from baseline input to the actual input. The baseline is defined by the user depending on the task. For image recognition, black image is used as baseline. It is not clear what such baseline representation should be in the case of language tasks. Here, we select a zero baseline for simplicity. Better results can be achieved with a more informed choice of a baseline and we leave this to future work.2\n1We use the implementation available at https://github. com/marcotcr/lime\n2For both information bottleneck and integrated gradients method we adapt the implementation available at https: //github.com/nicola-decao/diffmask for our QE scenario. Our code will be made available upon acceptance.\nAttention Finally, we test attention as an attribution method. Self-attention mechanisms have been widely studied in the context of explainability (Jain and Wallace, 2019; Serrano and Smith, 2019; Bujel et al., 2021). To compute a single attention score for a transformer-based model with multi-head attention, we average the weights across the different attention heads."
    }, {
      "heading" : "4 Experimental Setup",
      "text" : ""
    }, {
      "heading" : "4.1 Evaluation Metrics",
      "text" : "Given a test set with both sentence-level and wordlevel gold labels, we want to measure to what extent the words with the highest attributions according to the QE model correspond to human annotations for MT errors. Note that we cannot use the evaluation metrics traditionally employed for assessing the performance of word-level QE, such as F1 score and Matthews correlation coefficient (Specia et al., 2020), as they require binary predictions while feature attribution methods return continuous scores. Instead, we rely on metrics based on class probabilities (Atanasova et al., 2020). Since attribution methods proceed on instance-by-instance basis and the scores produced for different instances are not necessarily comparable, we compute the evaluation metrics for each instance separately and average the results across all instances in the test set.\nAUC score For each instance, we compute the area under the receiver operating characteristic curve (AUC score) to compare the continuous attribution scores a against binary gold labels w. For a test set with N instances:\nAUC= 1\nN ∑ n AUCn(wn,a xT n ) (1)\nAverage Precision AUC score can be overly optimistic for imbalanced data. Therefore, we also use Average Precision (AP).\nRecall at Top-K In addition, we report the Recall-at-Top-K commonly used in information retrieval. Applied to our setting, this metric computes the proportion of words with the highest attribution that correspond to translation errors against the total number of errors in the MT output. Thus, for a given instance (we omit the instance index n here for simplicity):\nRec@TopK= 1\nk ∑ j∈e1:k wj (2)\nWhere e=argsort(ax T ) is a sequence of indices corresponding to target words sorted by attribution score from highest to lowest and k is the number of errors in the sentence. We then average the result across all instances in the test set.\nAccuracy at Top-1 Finally, we report the proportion of sentences where the word with the highest attribution in the target corresponds to a translation error.\nAcc@Top1= 1\nN\n∑ I[ae1=1] (3)\nWe note that the above metrics are not defined for sentences where all words are labelled as errors or correct. We exclude such sentences from evaluation."
    }, {
      "heading" : "4.2 Sentence-level QE",
      "text" : "For sentence-level QE, we rely on TransQuest (Ranasinghe et al., 2020b), which was one of the top submissions to the WMT20 QE Shared Task (Specia et al., 2020). To facilitate the use of feature attribution methods described above, we use our own implementation of the approach proposed by (Ranasinghe et al., 2020b,a). It achieves comparable results to the ones reported by the authors. Due to limited computational resources we use the XLM-R-base as the underlying pre-trained Transformer model. We expect that using a more powerful sentence-level model would result in higher performance."
    }, {
      "heading" : "4.3 Data",
      "text" : "We use the MLQE-PE (Multilingual Quality Estimation and Post-Editing) dataset described in\nFomicheva et al. (2020a).3 MLQE-PE provides various types of manual MT evaluation for multiple language pairs. The MT outputs were assigned a sentence-level score inspired by the Direct Assessment (DA) annotation (Graham et al., 2015; Guzmán et al., 2019) on a continuous [0, 100] scale capturing overall translation quality. In addition, the MT outputs were independently post-edited by professional translators. MT outputs and their corresponding post-edited versions were automatically aligned in order to derive word-level binary labels (“BAD” if the word was corrected, and “OK” otherwise), as well as their HTER score that corresponds to the average number of “BAD” labels in a sentence (Snover et al., 2006). We use these labels to evaluate the performance of different feature attribution approaches. We treat “BAD” labels as the positive class and “OK” labels as negative class in all of our experiments.4 We do not evaluate attribution to source words.\nIt is worth noting that word-level labels derived from post-editing do not capture error severity and do not always correspond to translation errors. However, due to the costs of collecting detailed error annotations for the substantially large amounts of data required to train SOTA models, this is a standard way of approximating error annotation in QE (Specia et al., 2020).5\nTo circumvent the above limitation, we leverage both types of sentence-level annotation (DA and HTER scores) in our experiments. We train sentence-level QE models with (i) DA scores and (ii) HTER scores. We evaluate both types of models using the word-labels derived from post-editing as described above. We then conduct evaluation as follows:\n1. We first evaluate explanations for DA-based models on the sentences with a sentence-level DA score lower than 70.6\n3https://github.com/sheffieldnlp/mlqe-pe 4The tokenization used internally by XLM-R model is different from the tokenization used for producing word-level error labels. To map the attribution scores to the word labels we take their maximum value.\n5Despite the limitations, we have chosen this dataset because it provides (i) sufficient amount of word-level training data, which allows us to compare our approach to a SOTA supervised approach; and (ii) access to the neural MT models that were used to produce the translations, thus enabling a comparison to an unsupervised glass-box approach.\n6This threshold is selected based on the annotation guidelines described in Fomicheva et al. (2020a), as the sentences assigned a score lower than 70 are guaranteed to have translation errors.\n2. We also evaluate explanations for DA-based sentence-level models on the full subset of sentences that contain at least one word-level error.\n3. Finally, we evaluate explanations for HTERbased sentence-level models on the full subset of sentences that contain at least one wordlevel error.\nInterestingly, despite the discrepancy between DA training objective and word labels derived from post-editing, explanations for DA-based models achieve better accuracy. We report the results for (1) in the main body of the paper, while (2) and (3) are reported in Appendix B.\nWe select three language pairs for our experiments: Estonian-English (Et-En), RomanianEnglish (Ro-En) and Nepali-English (Ne-En) with the best performance at sentence level achieved at WMT2020 Shared Task. Table 1 shows statistics for the respective test sets. These three language pairs present very different conditions for the task. Sentence-level model for Ro-En has much stronger performance in terms of Pearson correlation with human judgements. Ne-En has substantially lower translation quality where “BAD” words actually represent the majority class."
    }, {
      "heading" : "4.4 QE Benchmarks",
      "text" : "We consider two benchmarks for word-level QE. On the one hand, we report the results for a strong supervised model based on pre-trained representations from XLM-R adapted to predict word-level binary labels derived from post-editing. To report the metrics presented in 4.1, we use the probability of the positive class as attribution scores. On the other hand, we consider a fully unsupervised\napproach, which however, requires access to the neural MT model, that was used to generate the translations.\nBlack-box Supervised QE We use the wordlevel architecture available as part of the TransQuest toolkit (Ranasinghe et al., 2020b).7 Similarly to the sentence-level TransQuest model, it relies on XLM-Roberta-base pre-trained model finetuned for token classification task. We use XLMRoberta-base to be consistent with the sentencelevel settings.\nGlass-box Unsupervised QE Fomicheva et al. (2020b) propose to extract information from the MT system to predict translation quality in a fully unsupervised way. Following their work, we use log-probabilities from the neural MT model as attribution scores. The lower the log-probability corresponding to each word, the higher the chance that this word constitutes an error."
    }, {
      "heading" : "5 Results",
      "text" : ""
    }, {
      "heading" : "5.1 QE as Rationale Extraction",
      "text" : "Table 2 shows the performance of our approach with different rationale extraction methods, as well as SOTA word-level QE methods for the MLQE-PE dataset. For the first three methods we compute the attributions to the hidden states at each layer on the dev set and report the results for this layer on the test set. First, our semi-supervised approach with all explanation methods substantially outperforms the random baseline.8 Among the different expla-\n7https://tharindudr.github.io/TransQuest/architectures/ word_level_architecture\n8The smallest gap with respect to the random baseline is observed for Ne-En. The overall quality of the translation for this language pair is low. This setting might be less suitable\nnation methods, attention and integrated gradients achieve the best results. Second, the performance is comparable or better than the glass-box QE benchmark (MicroTransQuest) without requiring access to the neural MT model. For example, for Ro-En the AP scores achieved by the attention-based explanations and the glass-box word-level QE are 0.73 and 0.66, respectively. Third, the gap between the best-performing semi-supervised method and the supervised QE benchmark is the smallest for Ro-En, where the sentence-level QE model from which explanations are extracted is the strongest (see Table 1). Finally, on average, LIME-based explanations are substantially outperformed by the feature attribution methods. This agrees with our intuition that for the translation task where context plays a fundamental role, attribution to hidden states achieves much better performance than direct perturbation of input words.\nfor the proposed error detection methods as most of the words in the data correspond to errors, as shown in Table 1."
    }, {
      "heading" : "5.2 Analysis",
      "text" : "Feature Attribution per Layer Figure 2 shows attributions to tokens of different types across hidden layers. On the left, we show the results for a toy task, where we artificially introduced easy-todetect errors in human translations and trained a QE model with near-perfect performance to predict whether a given sentence contain errors (see Appendix A). On the right, we show the results for the the MLQE-PE Et-En test set. Similarly to the toy task, we observe that in the later layers the tokens corresponding to translation errors receive higher attribution scores. However, in the toy dataset, the source tokens have very low attributions. Here, in\ncontrast, the model appears to be relying on the source as well as the target. This aligns very well with human evaluation where both source and target sentences need to be considered in order to correctly determine translation quality.\nFigure 3 shows performance across layers for the integrated gradients method. As expected, the same layers that assign the highest attribution to the bad tokens (layers 9-11) are the ones that achieve the best performance. This finding is consistent across language pairs and attribution methods. Interestingly, this is also consistent with the findings reported in Voita et al. (2019), where they show that models trained with MLM objective encode context information in intermediate layers partially discarding the information on the identity of the input tokens which is recovered at the latest layers.\nSo far we have studied the behavior of the QE models on the sentences that contain errors. We now look at the pattern in the attributions scores for sentences which were assigned high quality by the model. We hypothesize that higher scores will be assigned to the words that are \"easy\" to translate. To test this, we select high-quality and lowquality sentences (sentences with predicted scores lower than 0.25 percentile and higher then 0.75 percentile, respectively). Figure 5 shows the average frequency with which the words occur in the neural MT training dataset. Red line corresponds to the words with the highest attribution for highquality MT sentences. Blue line corresponds to the words with the highest attribution for the lowquality MT sentences. The first plot corresponds to the source tokens and the second plot corresponds to the target tokens. As shown in the plots, when the model predicts high quality the most frequent\nwords receive the highest attribution as the information progresses through the network. By contrast when low quality is predicted by the sentence-level model, the least frequent words receive the highest attribution.\nQualitative Analysis Figure 4 shows an example. Attributions are shown for sentencepiece tokens, which is the representation used internally by XLM-R. Interestingly, both translation errors (\"You\" and \"Pilate\") and the corresponding words in the source (\"Evald\" and \"Pille\") receive higher attribution scores."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this work, we propose a new semi-supervised approach for word-level QE by exploring feature attribution methods. We show that for well performing models our results approach performance of supervised methods. We also consider the QE as rationale extraction task as a new benchmark for plausibility-based evaluation of explainability methods. We hope this work will encourage further research on improving the efficiency of word-level QE models with lightly supervised methods. This work opens many directions for future research: from improving the achieved results by tuning linear weights to combine attributions to hidden states at different layers, to exploring different underlying architectures and sentence-level training objectives."
    }, {
      "heading" : "A Toy dataset",
      "text" : "We devise a toy task to test feature attribution performance for word-level QE. We artificially introduce easy-to-detect errors in human translations and train a QE model with near-perfect performance to predict the presence/absence of such errors in a sentence. Specifically, we sample 10K/1K/1K sentence pairs from Es-En NewsCommentary dataset (train/dev/test). Next, we artificially inject errors to half of the sentences at a rate of 0.1 using the following operations: insert, delete or replace random word, or swap two words selected at random.\nWe fine-tune an XLM-R-base model for a sentence-level binary classification task where sentences that contain errors are considered as positive class, and sentences that do not contain errors are considered as negative class. The F1-score of this sentence-level classifier is 0.97. This is expected as the task is very easy."
    }, {
      "heading" : "B Performance of Rationale Extraction Methods on HTER Data",
      "text" : "Tables 4 and 5 show the performance of the proposed methods on the full subset of sentences that contain at least one word-level error for sentencelevel QE models trained with HTER and DA ground truth scores. Pearson correlation for both types of models is shown in Table 3. Interestingly, even though for Ro-En and Et-En the performance of sentence-level models is near identical, extracted rationales are more accurate for the model trained with DA judgements."
    } ],
    "references" : [ {
      "title" : "A diagnostic study of explainability techniques for text classification",
      "author" : [ "Pepa Atanasova", "Jakob Grue Simonsen", "Christina Lioma", "Isabelle Augenstein." ],
      "venue" : "arXiv preprint arXiv:2009.13295. 8",
      "citeRegEx" : "Atanasova et al\\.,? 2020",
      "shortCiteRegEx" : "Atanasova et al\\.",
      "year" : 2020
    }, {
      "title" : "Confidence estimation for machine translation",
      "author" : [ "John Blatz", "Erin Fitzgerald", "George Foster", "Simona Gandrabur", "Cyril Goutte", "Alex Kulesza", "Alberto Sanchis", "Nicola Ueffing." ],
      "venue" : "Proceedings of the 20th International Conference on Computational",
      "citeRegEx" : "Blatz et al\\.,? 2004",
      "shortCiteRegEx" : "Blatz et al\\.",
      "year" : 2004
    }, {
      "title" : "Zero-shot sequence labeling for transformerbased sentence classifiers",
      "author" : [ "Kamil Bujel", "Helen Yannakoudakis", "Marek Rei." ],
      "venue" : "Proceedings of the 6th Workshop on Representation Learning for NLP (RepL4NLP-2021), pages 195–205, Online. Associ-",
      "citeRegEx" : "Bujel et al\\.,? 2021",
      "shortCiteRegEx" : "Bujel et al\\.",
      "year" : 2021
    }, {
      "title" : "Paragraph-level rationale extraction through regularization: A case study on european court of human rights cases",
      "author" : [ "Ilias Chalkidis", "Manos Fergadiotis", "Dimitrios Tsarapatsanis", "Nikolaos Aletras", "Ion Androutsopoulos", "Prodromos Malakasiotis" ],
      "venue" : null,
      "citeRegEx" : "Chalkidis et al\\.,? \\Q2021\\E",
      "shortCiteRegEx" : "Chalkidis et al\\.",
      "year" : 2021
    }, {
      "title" : "Unsupervised cross-lingual representation learning at scale",
      "author" : [ "Alexis Conneau", "Kartikay Khandelwal", "Naman Goyal", "Vishrav Chaudhary", "Guillaume Wenzek", "Francisco Guzmán", "Edouard Grave", "Myle Ott", "Luke Zettlemoyer", "Veselin Stoyanov." ],
      "venue" : "arXiv",
      "citeRegEx" : "Conneau et al\\.,? 2019",
      "shortCiteRegEx" : "Conneau et al\\.",
      "year" : 2019
    }, {
      "title" : "How do decisions emerge across layers in neural models? interpretation with differentiable masking",
      "author" : [ "Nicola De Cao", "Michael Schlichtkrull", "Wilker Aziz", "Ivan Titov." ],
      "venue" : "arXiv preprint arXiv:2004.14992.",
      "citeRegEx" : "Cao et al\\.,? 2020",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2020
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "Eraser: A benchmark to evaluate rationalized nlp models",
      "author" : [ "Jay DeYoung", "Sarthak Jain", "Nazneen Fatema Rajani", "Eric Lehman", "Caiming Xiong", "Richard Socher", "Byron C Wallace." ],
      "venue" : "arXiv preprint arXiv:1911.03429.",
      "citeRegEx" : "DeYoung et al\\.,? 2019",
      "shortCiteRegEx" : "DeYoung et al\\.",
      "year" : 2019
    }, {
      "title" : "Mlqe-pe: A multilingual quality estimation and post-editing dataset",
      "author" : [ "Marina Fomicheva", "Shuo Sun", "Erick Fonseca", "Frédéric Blain", "Vishrav Chaudhary", "Francisco Guzmán", "Nina Lopatina", "Lucia Specia", "André FT Martins." ],
      "venue" : "arXiv preprint",
      "citeRegEx" : "Fomicheva et al\\.,? 2020a",
      "shortCiteRegEx" : "Fomicheva et al\\.",
      "year" : 2020
    }, {
      "title" : "Unsupervised quality estimation for neural machine translation",
      "author" : [ "Marina Fomicheva", "Shuo Sun", "Lisa Yankovskaya", "Frédéric Blain", "Francisco Guzmán", "Mark Fishel", "Nikolaos Aletras", "Vishrav Chaudhary", "Lucia Specia." ],
      "venue" : "arXiv preprint",
      "citeRegEx" : "Fomicheva et al\\.,? 2020b",
      "shortCiteRegEx" : "Fomicheva et al\\.",
      "year" : 2020
    }, {
      "title" : "Experts, errors, and context: A large-scale study of human evaluation for machine translation",
      "author" : [ "Markus Freitag", "George Foster", "David Grangier", "Viresh Ratnakar", "Qijun Tan", "Wolfgang Macherey." ],
      "venue" : "arXiv preprint arXiv:2104.14478.",
      "citeRegEx" : "Freitag et al\\.,? 2021",
      "shortCiteRegEx" : "Freitag et al\\.",
      "year" : 2021
    }, {
      "title" : "Can machine translation systems be evaluated by the crowd alone",
      "author" : [ "Yvette Graham", "Timothy Baldwin", "Alistair Moffat", "Justin Zobel." ],
      "venue" : "Natural Language Engineering, pages 1–28.",
      "citeRegEx" : "Graham et al\\.,? 2015",
      "shortCiteRegEx" : "Graham et al\\.",
      "year" : 2015
    }, {
      "title" : "The flores evaluation datasets for low-resource machine translation: Nepali–english and sinhala–english",
      "author" : [ "Francisco Guzmán", "Peng-Jen Chen", "Myle Ott", "Juan Pino", "Guillaume Lample", "Philipp Koehn", "Vishrav Chaudhary", "Marc’Aurelio Ranzato" ],
      "venue" : null,
      "citeRegEx" : "Guzmán et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Guzmán et al\\.",
      "year" : 2019
    }, {
      "title" : "Towards faithfully interpretable NLP systems: How should we define and evaluate faithfulness? CoRR, abs/2004.03685",
      "author" : [ "Alon Jacovi", "Yoav Goldberg" ],
      "venue" : null,
      "citeRegEx" : "Jacovi and Goldberg.,? \\Q2020\\E",
      "shortCiteRegEx" : "Jacovi and Goldberg.",
      "year" : 2020
    }, {
      "title" : "Attention is not explanation",
      "author" : [ "Sarthak Jain", "Byron C Wallace." ],
      "venue" : "arXiv preprint arXiv:1902.10186.",
      "citeRegEx" : "Jain and Wallace.,? 2019",
      "shortCiteRegEx" : "Jain and Wallace.",
      "year" : 2019
    }, {
      "title" : "Learning to faithfully rationalize by construction",
      "author" : [ "Sarthak Jain", "Sarah Wiegreffe", "Yuval Pinter", "Byron C Wallace." ],
      "venue" : "arXiv preprint arXiv:2005.00115.",
      "citeRegEx" : "Jain et al\\.,? 2020",
      "shortCiteRegEx" : "Jain et al\\.",
      "year" : 2020
    }, {
      "title" : "Predictor-estimator using multilevel task learning with stack propagation for neural quality estimation",
      "author" : [ "Hyun Kim", "Jong-Hyeok Lee", "Seung-Hoon Na." ],
      "venue" : "Proceedings of the Second Conference on Machine Translation, Volume 2: Shared Tasks Pa-",
      "citeRegEx" : "Kim et al\\.,? 2017",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2017
    }, {
      "title" : "Two-phase cross-lingual language model fine-tuning for machine translation quality estimation",
      "author" : [ "Dongjun Lee." ],
      "venue" : "Proceedings of the Fifth Conference on Machine Translation, pages 1024–1028, Online. Association for Computational Linguistics.",
      "citeRegEx" : "Lee.,? 2020",
      "shortCiteRegEx" : "Lee.",
      "year" : 2020
    }, {
      "title" : "Rationalizing neural predictions",
      "author" : [ "Tao Lei", "Regina Barzilay", "Tommi Jaakkola." ],
      "venue" : "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 107–117, Austin, Texas. Association for Computational Linguistics.",
      "citeRegEx" : "Lei et al\\.,? 2016",
      "shortCiteRegEx" : "Lei et al\\.",
      "year" : 2016
    }, {
      "title" : "The mythos of model interpretability",
      "author" : [ "Zachary Chase Lipton." ],
      "venue" : "CoRR, abs/1606.03490.",
      "citeRegEx" : "Lipton.,? 2016",
      "shortCiteRegEx" : "Lipton.",
      "year" : 2016
    }, {
      "title" : "Multidimensional quality metrics (mqm): A framework for declaring and describing translation quality metrics",
      "author" : [ "Arle Lommel", "Hans Uszkoreit", "Aljoscha Burchardt." ],
      "venue" : "Tradumàtica, (12):0455–463.",
      "citeRegEx" : "Lommel et al\\.,? 2014",
      "shortCiteRegEx" : "Lommel et al\\.",
      "year" : 2014
    }, {
      "title" : "Transquest at wmt2020: Sentence-level direct assessment",
      "author" : [ "Tharindu Ranasinghe", "Constantin Orasan", "Ruslan Mitkov." ],
      "venue" : "arXiv preprint arXiv:2010.05318.",
      "citeRegEx" : "Ranasinghe et al\\.,? 2020a",
      "shortCiteRegEx" : "Ranasinghe et al\\.",
      "year" : 2020
    }, {
      "title" : "Transquest: Translation quality estimation with cross-lingual transformers",
      "author" : [ "Tharindu Ranasinghe", "Constantin Orasan", "Ruslan Mitkov." ],
      "venue" : "arXiv preprint arXiv:2011.01536.",
      "citeRegEx" : "Ranasinghe et al\\.,? 2020b",
      "shortCiteRegEx" : "Ranasinghe et al\\.",
      "year" : 2020
    }, {
      "title" : " why should i trust you?\" explaining the predictions of any classifier",
      "author" : [ "Marco Tulio Ribeiro", "Sameer Singh", "Carlos Guestrin." ],
      "venue" : "Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining,",
      "citeRegEx" : "Ribeiro et al\\.,? 2016",
      "shortCiteRegEx" : "Ribeiro et al\\.",
      "year" : 2016
    }, {
      "title" : "Confidence through attention",
      "author" : [ "Matı̄ss Rikters", "Mark Fishel" ],
      "venue" : "arXiv preprint arXiv:1710.03743",
      "citeRegEx" : "Rikters and Fishel.,? \\Q2017\\E",
      "shortCiteRegEx" : "Rikters and Fishel.",
      "year" : 2017
    }, {
      "title" : "Restricting the flow: Information bottlenecks for attribution",
      "author" : [ "Karl Schulz", "Leon Sixt", "Federico Tombari", "Tim Landgraf." ],
      "venue" : "arXiv preprint arXiv:2001.00396.",
      "citeRegEx" : "Schulz et al\\.,? 2020",
      "shortCiteRegEx" : "Schulz et al\\.",
      "year" : 2020
    }, {
      "title" : "Is attention interpretable? arXiv preprint arXiv:1906.03731",
      "author" : [ "Sofia Serrano", "Noah A Smith" ],
      "venue" : null,
      "citeRegEx" : "Serrano and Smith.,? \\Q2019\\E",
      "shortCiteRegEx" : "Serrano and Smith.",
      "year" : 2019
    }, {
      "title" : "Deep inside convolutional networks: Visualising image classification models and saliency maps",
      "author" : [ "Karen Simonyan", "Andrea Vedaldi", "Andrew Zisserman." ],
      "venue" : "arXiv preprint arXiv:1312.6034.",
      "citeRegEx" : "Simonyan et al\\.,? 2013",
      "shortCiteRegEx" : "Simonyan et al\\.",
      "year" : 2013
    }, {
      "title" : "A study of translation edit rate with targeted human annotation",
      "author" : [ "Matthew Snover", "Bonnie Dorr", "Richard Schwartz", "Linnea Micciulla", "John Makhoul." ],
      "venue" : "Proceedings of association for machine translation in the Americas, volume 200. Citeseer.",
      "citeRegEx" : "Snover et al\\.,? 2006",
      "shortCiteRegEx" : "Snover et al\\.",
      "year" : 2006
    }, {
      "title" : "Findings of the WMT 2020 shared task on quality estimation",
      "author" : [ "Lucia Specia", "Frédéric Blain", "Marina Fomicheva", "Erick Fonseca", "Vishrav Chaudhary", "Francisco Guzmán", "André F.T. Martins." ],
      "venue" : "Proceedings of the Fifth Conference on Machine",
      "citeRegEx" : "Specia et al\\.,? 2020",
      "shortCiteRegEx" : "Specia et al\\.",
      "year" : 2020
    }, {
      "title" : "Estimating the sentence-level quality of machine translation systems",
      "author" : [ "Lucia Specia", "Nicola Cancedda", "Marc Dymetman", "Marco Turchi", "Nello Cristianini." ],
      "venue" : "Proceedings of the 13th Annual Conference of the European Association for Machine Trans-",
      "citeRegEx" : "Specia et al\\.,? 2009",
      "shortCiteRegEx" : "Specia et al\\.",
      "year" : 2009
    }, {
      "title" : "Axiomatic attribution for deep networks",
      "author" : [ "Mukund Sundararajan", "Ankur Taly", "Qiqi Yan." ],
      "venue" : "International Conference on Machine Learning, pages 3319–3328. PMLR.",
      "citeRegEx" : "Sundararajan et al\\.,? 2017",
      "shortCiteRegEx" : "Sundararajan et al\\.",
      "year" : 2017
    }, {
      "title" : "Deep learning and the information bottleneck principle",
      "author" : [ "Naftali Tishby", "Noga Zaslavsky." ],
      "venue" : "2015 IEEE Information Theory Workshop (ITW), pages 1–5. IEEE.",
      "citeRegEx" : "Tishby and Zaslavsky.,? 2015",
      "shortCiteRegEx" : "Tishby and Zaslavsky.",
      "year" : 2015
    }, {
      "title" : "Quality estimation without humanlabeled data",
      "author" : [ "Yi-Lin Tuan", "Ahmed El-Kishky", "Adithya Renduchintala", "Vishrav Chaudhary", "Francisco Guzmán", "Lucia Specia." ],
      "venue" : "arXiv preprint arXiv:2102.04020.",
      "citeRegEx" : "Tuan et al\\.,? 2021",
      "shortCiteRegEx" : "Tuan et al\\.",
      "year" : 2021
    }, {
      "title" : "The bottom-up evolution of representations in the transformer: A study with machine translation and language modeling objectives",
      "author" : [ "Elena Voita", "Rico Sennrich", "Ivan Titov." ],
      "venue" : "arXiv preprint arXiv:1909.01380.",
      "citeRegEx" : "Voita et al\\.,? 2019",
      "shortCiteRegEx" : "Voita et al\\.",
      "year" : 2019
    }, {
      "title" : "Rethinking cooperative rationalization: Introspective extraction and complement control",
      "author" : [ "Mo Yu", "Shiyu Chang", "Yang Zhang", "Tommi S Jaakkola." ],
      "venue" : "arXiv preprint arXiv:1910.13294.",
      "citeRegEx" : "Yu et al\\.,? 2019",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2019
    }, {
      "title" : "Transformer visualization via dictionary learning: contextualized embedding as a linear superposition of transformer factors",
      "author" : [ "Zeyu Yun", "Yubei Chen", "Bruno A Olshausen", "Yann LeCun." ],
      "venue" : "arXiv preprint arXiv:2103.15949.",
      "citeRegEx" : "Yun et al\\.,? 2021",
      "shortCiteRegEx" : "Yun et al\\.",
      "year" : 2021
    }, {
      "title" : "Using “annotator rationales” to improve machine learning for text categorization",
      "author" : [ "Omar Zaidan", "Jason Eisner", "Christine Piatko." ],
      "venue" : "Human language technologies 2007: The conference of the North American chapter of the association for computa-",
      "citeRegEx" : "Zaidan et al\\.,? 2007",
      "shortCiteRegEx" : "Zaidan et al\\.",
      "year" : 2007
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Quality Estimation (QE) is the task of predicting Machine Translation (MT) quality at inference time, when no gold standard human translation is available (Blatz et al., 2004; Specia et al., 2009).",
      "startOffset" : 155,
      "endOffset" : 196
    }, {
      "referenceID" : 30,
      "context" : "Quality Estimation (QE) is the task of predicting Machine Translation (MT) quality at inference time, when no gold standard human translation is available (Blatz et al., 2004; Specia et al., 2009).",
      "startOffset" : 155,
      "endOffset" : 196
    }, {
      "referenceID" : 6,
      "context" : "Current QE approaches fine-tune powerful representations from pre-trained multilingual encoders such as BERT (Devlin et al., 2018) or XLM-R (Conneau et al.",
      "startOffset" : 109,
      "endOffset" : 130
    }, {
      "referenceID" : 29,
      "context" : "In the recent Shared Task on QE at WMT2020 (Specia et al., 2020) these approaches have achieved very high performance at predicting sentence-level translation quality (up to 0.",
      "startOffset" : 43,
      "endOffset" : 64
    }, {
      "referenceID" : 18,
      "context" : "To achieve this, we propose addressing QE as a rationale extraction task (Lei et al., 2016).",
      "startOffset" : 73,
      "endOffset" : 91
    }, {
      "referenceID" : 19,
      "context" : "Explainability is a broad area aimed at explaining predictions of machine learning models (Lipton, 2016).",
      "startOffset" : 90,
      "endOffset" : 104
    }, {
      "referenceID" : 10,
      "context" : "tion, human perception of quality is guided by the presence of translation errors (Freitag et al., 2021).",
      "startOffset" : 82,
      "endOffset" : 104
    }, {
      "referenceID" : 31,
      "context" : "To extract model explanations, we use post hoc rationale extraction methods (Sundararajan et al., 2017) which try to explain the predictions of a given model (as opposed to modifying its architecture or introducing constraints during training), since one of our goals is to study to what extent existing QE models rely on the same information as humans to make predictions.",
      "startOffset" : 76,
      "endOffset" : 103
    }, {
      "referenceID" : 7,
      "context" : "Recent work has introduced various datasets for measuring the agreement between rationales extracted from NLP models and those provided by humans (DeYoung et al., 2019).",
      "startOffset" : 146,
      "endOffset" : 168
    }, {
      "referenceID" : 20,
      "context" : "Finally, manual annotation of translation errors is a practical task with a long tradition in MT research and translation studies (Lommel et al., 2014), and thus offers an interesting alternative to human explanations collected specifically for evaluating rationale extraction methods.",
      "startOffset" : 130,
      "endOffset" : 151
    }, {
      "referenceID" : 13,
      "context" : "how interpretable model explanations are to humans (Jacovi and Goldberg, 2020).",
      "startOffset" : 51,
      "endOffset" : 78
    }, {
      "referenceID" : 6,
      "context" : "Quality Estimation Current SOTA models in sentence-level QE, which is typically framed as a regression task, mainly use multilingual representations from pre-trained transformers (Devlin et al., 2018), notably XLM-R (Conneau et al.",
      "startOffset" : 179,
      "endOffset" : 200
    }, {
      "referenceID" : 17,
      "context" : "Word-level QE is typically addressed as a binary classification task, where the QE model needs to predict a binary label indicating whether a word is correct or wrong for each word in the MT output (Lee, 2020).",
      "startOffset" : 198,
      "endOffset" : 209
    }, {
      "referenceID" : 16,
      "context" : "As illustrated in Figure 1 (left), some supervised approaches use both sentence-level and word-level objectives in a multi-task setting, which results in superior performance (Kim et al., 2017; Lee, 2020).",
      "startOffset" : 175,
      "endOffset" : 204
    }, {
      "referenceID" : 17,
      "context" : "As illustrated in Figure 1 (left), some supervised approaches use both sentence-level and word-level objectives in a multi-task setting, which results in superior performance (Kim et al., 2017; Lee, 2020).",
      "startOffset" : 175,
      "endOffset" : 204
    }, {
      "referenceID" : 24,
      "context" : "Methods that do not require word-level training data either need access to the MT model (Rikters and Fishel, 2017; Fomicheva et al., 2020b), or still treat the problem as a supervised task but use synthetically generated data for supervision (Tuan et al.",
      "startOffset" : 88,
      "endOffset" : 139
    }, {
      "referenceID" : 9,
      "context" : "Methods that do not require word-level training data either need access to the MT model (Rikters and Fishel, 2017; Fomicheva et al., 2020b), or still treat the problem as a supervised task but use synthetically generated data for supervision (Tuan et al.",
      "startOffset" : 88,
      "endOffset" : 139
    }, {
      "referenceID" : 33,
      "context" : ", 2020b), or still treat the problem as a supervised task but use synthetically generated data for supervision (Tuan et al., 2021).",
      "startOffset" : 111,
      "endOffset" : 130
    }, {
      "referenceID" : 19,
      "context" : "Rationale Extraction for NLP SOTA NLP models based on deep neural networks achieve high performance in a variety of tasks, often at the cost of interpretability (Lipton, 2016).",
      "startOffset" : 161,
      "endOffset" : 175
    }, {
      "referenceID" : 13,
      "context" : "On the other hand, the aim is to reveal the inner workings of the model and faithfully explain its predictions, so the explanation can be useful to model developers (Jacovi and Goldberg, 2020).",
      "startOffset" : 165,
      "endOffset" : 192
    }, {
      "referenceID" : 15,
      "context" : "strictions often result in lower performance and indeed are not guaranteed to explain the behaviour of an unconstrained model (Jain et al., 2020).",
      "startOffset" : 126,
      "endOffset" : 145
    }, {
      "referenceID" : 31,
      "context" : "The second type of approaches (the so called post hoc) usually rely on feature attribution methods, which assign an importance value to each input feature of a network (Sundararajan et al., 2017; Schulz et al., 2020).",
      "startOffset" : 168,
      "endOffset" : 216
    }, {
      "referenceID" : 25,
      "context" : "The second type of approaches (the so called post hoc) usually rely on feature attribution methods, which assign an importance value to each input feature of a network (Sundararajan et al., 2017; Schulz et al., 2020).",
      "startOffset" : 168,
      "endOffset" : 216
    }, {
      "referenceID" : 27,
      "context" : "Feature attribution has a long tradition in image recognition tasks (Simonyan et al., 2013) and only recently have been applied to some NLP tasks, most commonly text classification (DeYoung et al.",
      "startOffset" : 68,
      "endOffset" : 91
    }, {
      "referenceID" : 7,
      "context" : ", 2013) and only recently have been applied to some NLP tasks, most commonly text classification (DeYoung et al., 2019).",
      "startOffset" : 97,
      "endOffset" : 119
    }, {
      "referenceID" : 37,
      "context" : "QE is fundamentally different from text classification where clues are typically separate words or phrases (Zaidan et al., 2007) which often can be considered independently of the rest of the text.",
      "startOffset" : 107,
      "endOffset" : 128
    }, {
      "referenceID" : 34,
      "context" : "tion flow through hidden layers in deep transformer models (Voita et al., 2019; De Cao et al., 2020; Yun et al., 2021).",
      "startOffset" : 59,
      "endOffset" : 118
    }, {
      "referenceID" : 36,
      "context" : "tion flow through hidden layers in deep transformer models (Voita et al., 2019; De Cao et al., 2020; Yun et al., 2021).",
      "startOffset" : 59,
      "endOffset" : 118
    }, {
      "referenceID" : 23,
      "context" : "Feature attribution methods can be divided into those providing explanations by simplification, such as LIME (Ribeiro et al., 2016); gradientbased explanations (Sundararajan et al.",
      "startOffset" : 109,
      "endOffset" : 131
    }, {
      "referenceID" : 31,
      "context" : ", 2016); gradientbased explanations (Sundararajan et al., 2017); and perturbation-based explanations (Schulz et al.",
      "startOffset" : 36,
      "endOffset" : 63
    }, {
      "referenceID" : 25,
      "context" : ", 2017); and perturbation-based explanations (Schulz et al., 2020).",
      "startOffset" : 45,
      "endOffset" : 66
    }, {
      "referenceID" : 23,
      "context" : "LIME (Ribeiro et al., 2016) is a simplificationbased explanation technique, which fits a sparse linear model in the vicinity of each test instance, to approximate the decision boundary of the complex model.",
      "startOffset" : 5,
      "endOffset" : 27
    }, {
      "referenceID" : 32,
      "context" : "The method applies the idea of information bottleneck (Tishby and Zaslavsky, 2015) for feature attribution.",
      "startOffset" : 54,
      "endOffset" : 82
    }, {
      "referenceID" : 31,
      "context" : "Integrated Gradients (Sundararajan et al., 2017) is a gradient-based method similar to the traditional salience and input∗gradients approaches",
      "startOffset" : 21,
      "endOffset" : 48
    }, {
      "referenceID" : 31,
      "context" : "Intuitively, this is analogous to inspecting the products of model coefficients and feature values in linear models (Sundararajan et al., 2017).",
      "startOffset" : 116,
      "endOffset" : 143
    }, {
      "referenceID" : 14,
      "context" : "Self-attention mechanisms have been widely studied in the context of explainability (Jain and Wallace, 2019; Serrano and Smith, 2019; Bujel et al., 2021).",
      "startOffset" : 84,
      "endOffset" : 153
    }, {
      "referenceID" : 26,
      "context" : "Self-attention mechanisms have been widely studied in the context of explainability (Jain and Wallace, 2019; Serrano and Smith, 2019; Bujel et al., 2021).",
      "startOffset" : 84,
      "endOffset" : 153
    }, {
      "referenceID" : 2,
      "context" : "Self-attention mechanisms have been widely studied in the context of explainability (Jain and Wallace, 2019; Serrano and Smith, 2019; Bujel et al., 2021).",
      "startOffset" : 84,
      "endOffset" : 153
    }, {
      "referenceID" : 29,
      "context" : "Note that we cannot use the evaluation metrics traditionally employed for assessing the performance of word-level QE, such as F1 score and Matthews correlation coefficient (Specia et al., 2020), as they require binary predictions while fea-",
      "startOffset" : 172,
      "endOffset" : 193
    }, {
      "referenceID" : 0,
      "context" : "Instead, we rely on metrics based on class probabilities (Atanasova et al., 2020).",
      "startOffset" : 57,
      "endOffset" : 81
    }, {
      "referenceID" : 22,
      "context" : "For sentence-level QE, we rely on TransQuest (Ranasinghe et al., 2020b), which was one of the top submissions to the WMT20 QE Shared Task (Specia et al.",
      "startOffset" : 45,
      "endOffset" : 71
    }, {
      "referenceID" : 29,
      "context" : ", 2020b), which was one of the top submissions to the WMT20 QE Shared Task (Specia et al., 2020).",
      "startOffset" : 75,
      "endOffset" : 96
    }, {
      "referenceID" : 11,
      "context" : "The MT outputs were assigned a sentence-level score inspired by the Direct Assessment (DA) annotation (Graham et al., 2015; Guzmán et al., 2019) on a continuous [0, 100] scale capturing overall translation quality.",
      "startOffset" : 102,
      "endOffset" : 144
    }, {
      "referenceID" : 12,
      "context" : "The MT outputs were assigned a sentence-level score inspired by the Direct Assessment (DA) annotation (Graham et al., 2015; Guzmán et al., 2019) on a continuous [0, 100] scale capturing overall translation quality.",
      "startOffset" : 102,
      "endOffset" : 144
    }, {
      "referenceID" : 28,
      "context" : "MT outputs and their corresponding post-edited versions were automatically aligned in order to derive word-level binary labels (“BAD” if the word was corrected, and “OK” otherwise), as well as their HTER score that corresponds to the average number of “BAD” labels in a sentence (Snover et al., 2006).",
      "startOffset" : 279,
      "endOffset" : 300
    }, {
      "referenceID" : 29,
      "context" : "However, due to the costs of collecting detailed error annotations for the substantially large amounts of data required to train SOTA models, this is a standard way of approximating error annotation in QE (Specia et al., 2020).",
      "startOffset" : 205,
      "endOffset" : 226
    }, {
      "referenceID" : 22,
      "context" : "level architecture available as part of the TransQuest toolkit (Ranasinghe et al., 2020b).",
      "startOffset" : 63,
      "endOffset" : 89
    }, {
      "referenceID" : 25,
      "context" : "Attributions are computed with the information bottleneck attribution method (Schulz et al., 2020).",
      "startOffset" : 77,
      "endOffset" : 98
    } ],
    "year" : 0,
    "abstractText" : "Recent Quality Estimation (QE) models based on multilingual pre-trained representations have achieved very competitive results in predicting the overall quality of translated sentences. However, detecting specifically which translated words are incorrect is a more challenging task, especially when dealing with limited amounts of training data. We hypothesize that, not unlike humans, successful QE models rely on translation errors to predict overall sentence quality. By exploring a set of feature attribution methods that assign relevance scores to the inputs to explain model predictions, we study the behaviour of state-of-theart sentence-level QE models and show that explanations (i.e. rationales) extracted from these models can indeed be used to detect translation errors. We therefore (i) introduce a novel semi-supervised method for word-level QE; and (ii) propose to use the QE task as a new benchmark for evaluating the plausibility of feature attribution, i.e. how interpretable model explanations are to humans.",
    "creator" : null
  }
}