{
  "name" : "ARR_2022_156_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Syntax Controlled Knowledge Graph-to-Text Generation with Order and Semantic Consistency",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Knowledge graphs (KGs) record the common sense knowledge in a structural way and have many potential applications, e.g., question answering(Saxena et al., 2020), recommendation system(Wang et al., 2021) and storytelling(Xu et al., 2021). One typical KG is shown in Figure 1, with circle nodes indicating entities and the directional edges connecting the head node to the tail node and representing the relation between connected entities. This structural representation in KG is easy for information storage while not convenient\nfor human understanding. In this paper, we focus on the task of KG-to-text generation, which aims to describe an input KG with fluent language sentences in an easy-to-understand way. Compared to the traditional text generation task, KG-to-text generation poses the extra challenge of maintaining the word authenticity in the generated sentence based on the input KG. With the word authenticity and sentence fluentness in mind, existing KG-to-text generation methods(Ribeiro et al., 2020a; KoncelKedziorski et al., 2019; Gardent et al., 2017) phrase this task as a sequence-to-sequence generation task where the KG is linearized as input sequence and decoded into sentences, and words from the KG are selected to be inserted into the decoded sentences with predicted confidence at each time step. However, when the KG is linearized into a sequence, usually simple heuristic search-based algorithms are utilized, e.g., breadth-first search (BFS) or other pre-defined rules for sorting (Li et al., 2021; Ribeiro et al., 2020a), without considering\nthe word sequence information in the ground-truth sentences. The order inference of the KG is not tightly correlated to the word sequence information in the ground-truth sentences and is generated in a disjoint prestage, while the decoded sentence is conditioned on the linearized KG order which might incur cascaded errors(Cornia et al., 2019). To tackle this problem, we extract the order information from the ground-truth sentence and use this order information to directly supervise the KG order prediction with graph structural local context. In this case, our order prediction component for KG encodes the sentence sequence prior information and will benefit the sentence generation in the follow-up stage.\nAlso, most existing methods(Li et al., 2021; Koncel-Kedziorski et al., 2019) maintain the word authenticity by maximizing the copy probability of the tokens from the KG, while ignoring the syntactic correctness and semantic relevance. A simple observation from the example in Figure1, you can find that the POS tags of most words copied from the KG are nouns. Motivated by this observation, we introduce a POS generator to guide the sentence generation process by applying the POS information as additional supervision at each time step and limit the position scope of the word selection from KG under syntactic constraint. Moreover, to further enhance semantic relevance of generated sentence, we consider the structural information and local semantic information of the KG by designing a semantic context scoring function with sliding windows of different sizes and combining the semantic context score into the word selection process at each time step of the sentence generation.\nIn summary, we propose a Syntax controlled KGto-text generation model with Order and Semantic Consistency, called S-OSC. The main contributions are summarized as follows:\n• We propose a learning-based sorting network to obtain the optimal description order from KG with graph structural context for more fluent caption generation. • We enhance the authenticity of generated sentences compared to the KG through syntactic and semantic regularization. POS tag information is incorporated into the sentence modelling, and helps to determine the word selection from KG together with one additional semantic context scoring function. • Extensive results on two benchmark datasets indicate that, our proposed S-OSC model out-\nperforms previous models and achieves new state-of-the-art performance."
    }, {
      "heading" : "2 Related Work",
      "text" : ""
    }, {
      "heading" : "2.1 KG-To-Text Generation",
      "text" : "KG-to-text generation task has been a hot research topic since the first dataset WebNLG was proposed(Gardent et al., 2017). Recent works for solving this task have two main categories. One category is using graph neural networks (Marcheggiani and Perez-Beltrachini, 2018; Ribeiro et al., 2020b; Li et al., 2021) or graph transformers (KoncelKedziorski et al., 2019) to directly capture the graph structure information and decode into sentences. E.g., the recent work (Ribeiro et al., 2020b) forms four different encoder architectures for combining local and global node context. The other category is first linearizing the KG (Ribeiro et al., 2020a; Yang et al., 2020; Gardent et al., 2017) as input and then formulating a sequence-to-sequence generation task to generate sentences. E.g., (Distiawan et al., 2018) utilizes a fixed tree traversal order to directly flatten the KG into a linearized representation. However, the structural information of the KG is not preserved when generating the KG order. In this paper, we follow the second general pipeline with local structure encoded in the order generation process."
    }, {
      "heading" : "2.2 Knowledge Graph Order Generation",
      "text" : "A line of KG-to-text models (Ribeiro et al., 2020a; Braude et al., 2021) tries to generate sentences conditioned on the KG order, where the order generation is especially important as different KG description orders can result in various generated texts. Most previous works focus on graph search-based approaches (Flanigan et al., 2016; Gardent et al., 2017; Ke et al., 2021; Li et al., 2021) for KG order generation. (Li et al., 2021) proposes to use a relation-biased breadth first search strategy to linearize the KG. These previous graph search-based approaches are heuristic without considering the word sequence information in the ground-truth sentences. Inspired by previous work (Cornia et al., 2019) which generates image caption with optimal object description order, we extract the sequence information from the ground-truth sentences and train one order prediction module to generate optimal order. Moreover, our order prediction considers the local graph structure in triplet."
    }, {
      "heading" : "2.3 Captioning with POS Tags",
      "text" : "POS tags have been used in various text generation, image captioning and video captioning to impose\nthe syntactic constraint. In (Yang and Wan, 2021), the author proposes to use POS guided softmax as the linguistic information to model posterior probabilities for enriching the diversity of the text generation. In the image caption, (Bugliarello and Elliott, 2021) claims that incorporating POS tag information in the sentence generation process consistently improves the quality of the generated text. In video captioning, (Hou et al., 2019) proposes to define the templates for POS tag sequences to represent the syntactic structure of the generated text. In KG-to-text generation task, We not only use the POS tags to ensure the syntactic accuracy of the generated text, but also use the POS tags to constrain the positions to preserve words from KGs."
    }, {
      "heading" : "2.4 Pre-Trained Language Models",
      "text" : "Pre-trained language models (PLMs) on massive corpora, such as BERT(Devlin et al., 2018), BART(Lewis et al., 2019) and T5(Raffel et al., 2019), have achieved superior performance in various natural language generative tasks, including KG-to-text generation task (Ribeiro et al., 2020a; Peters et al., 2019; Ke et al., 2021). (Ribeiro et al., 2020a) leverages the generation ability of PLMs and Linearized the KG as input to generate texts. However, these approaches don’t take extra solutions to further improve the generation ability and enhance the consistency of generated texts and KG. We also use the PLM in our model to guarantee the model generation ability, and at the same time, design extra order prediction and semantic context scoring components to maintain the order and semantic consistency. 3 Approaches In this section, we first formulate the KG-to-text generation problem setting and then elaborate the proposed S-OSC in detail."
    }, {
      "heading" : "3.1 Problem Formulation",
      "text" : "Given the input KG G, which composed of {(h1, r1, t1), · · · , (hn, rn, cn)|h∗, t∗ ∈ E , r∗ ∈ R}, where E denotes the entity set and R represents the relation set, the KG-to-text generation task aims to generate a fluent and reasonable text sequence T =< t1, t2, · · · , tk > (tk ∈ V), where V denotes the vocabulary. In this paper, we follow the general pipeline (Ribeiro et al., 2020a; Ke et al., 2021; Ribeiro et al., 2021) of linearizing the input KG into sequence Glinear =< g1, g2, · · · , gm > consisting of m tokens, and then decoding the KG token sequence into sentences."
    }, {
      "heading" : "3.2 Our Proposed S-OSC Model",
      "text" : "We propose S-OSC, illustrated in Figure 2, which consists of two main components: one learningbased sorting network for KG and one copy or prediction selection module for decoding each word in the sentences. The sorting network generates the optimal description sequence for the input KG. Based on the KG order sequence, the sentence decoder generates each word with a certain probability predicted by the copy or prediction selection module to replace the decoded word with the word in the KG. Thus, the model can maintain the word authenticity in the generated sentence compared to the KG. A key innovation in our learning-based sorting network is to unitize the sequence information extracted from the ground-truth sentence to directly supervise the optimal sequence prediction instead of heuristic search in the KG without considering the description sequence prior. Our copy or prediction selection module for decoding each word in the sentences incorporates additional POS syntactic constraint and semantic context consistency scoring function evaluating the semantic fitness of each word in its sliding windows with various sizes. The details of each module in our SOSC model are illustrated in the following sections."
    }, {
      "heading" : "3.2.1 Sorting Network",
      "text" : "The description order of the KG will affect the content of the generated sentence. In worse scenario, poor order may result in the loss of important information (see the example in Figure 6). To overcome the drawback of disjoint learning for KG order generation and sentence generation in previous heuristic-based methods (Li et al., 2021; Ribeiro et al., 2020a; Yang et al., 2020), we propose a learning-based sorting network with the order supervision extracted from the ground-truth sentence. Notably, our sorting network is based on the features from the structural Triplet Encoder, where the head-relation-tail triplet structure features are extracted through pre-trained KG embedding method TransH (Wang et al., 2014) and pre-trained language model BART (Lewis et al., 2019). Due to the variable length of the KG, we introduce a placeholder to pad it into fixed length N , which also denotes the number of possible position classes. The head-relation-tail triplet structure features Fstru are concatenated with the padding Fpad and fed through the Fully Connected (FC) layers with softmax classifier FCs to obtain Smatrix and predict\nthe sorting order Sorder.\nSmatrix = FCs([Fstru;Fpad])\nSorder = argmaxrow(Smatrix) (1)\nIn this paper, we treat the order prediction task as a classification problem, where N denotes the number of classes. Thus, we measure the crossentropy loss between the ground-truth order Gorder (see more details in supplementary material) and the sorting order Sorder:\nLsort = − N∑\nn=0\nlog(Snmatrix) ·Gnorder (2)"
    }, {
      "heading" : "3.2.2 Copy or Prediction Network",
      "text" : "To maintain the authenticity of KG words in generated sentences, the model needs to selectively copy words from KG words instead of using the predicted words from Word Decoder. Besides directly predicting the copy probability from the hidden state(Koncel-Kedziorski et al., 2019; Li et al., 2021; See et al., 2017), the Copy or Prediction Network in our S-OSC model further enhance the syntactic and semantic consistency of selected words in the decoded sentence through the incorporation of POS generator (shown in Figure 3) and semantic context scoring (shown in Figure 4). Next, we will introduce each module in detail. POS syntactic Constraint Conditioned on the KG order Gorder, we first linearize the KG by adding the tokens < Head >,< Relation >,< Tail > to the corresponding position at each triplet\nand obtain the Glinear. Then, the Word Encoder and the POS Generator take Glinear as their inputs and output the word encoding WI={wi, i ∈ 1 · · ·m} and POS tag encoding PI={pi, i ∈ 1 · · ·m} , respectively. Then, the token encoding wi and POS tag encoding pi are combined in the fusion module to get updated token encoding wi.\nwi = LN(FC([wi; pi]) + wi), (3)\nwhere LN denotes the layer normalization. The updated token encoding wi after fusion is decoded into sentence WI\n′ = {w′i, i ∈ 1 · · · k} in Word\nDecoder.\nPOS generator is supervised through POS tags pre-extracted from the sentence. The loss function is formulated as:\nLpos = − M∑ l=1 log(Pgen(pl|p1, · · · , pl−1;Sorder))\n(4) where Pgen denotes the predicted probability from POS generator. Similarly, the objective of Word-\nEncoder-Decoder is as follows: Ltoken = − K∑ j=1 log(Wgen(w ′ j |w ′ 1, · · · , w ′ j−1;WI ′ )) (5) where Wgen denotes the predicted probability of each word token. Semantic Context Scoring Besides the syntactic constraint for copied words, we also design one semantic context scoring component, illustrated in 4, to evaluate the semantic consistency of copied or predicted words in the sliding windows.\nSliding windows are generated for each word to provide the local context, e.g., the sliding window size is set to 3 in Figure 4. Padding is needed for the first several words when forming sliding windows. Word features in the sliding window are contacted to get the context information Fcontext, and are fed into the FC layers to obtain the semantic score Xsemantic.\nXsemantic = σ(FC(Fcontext)), (6)\nwhere σ denotes the sigmoid function. Word Copy Probability Prediction With our newly introduced POS token embeddings vpk and the semantic context score Xsemantic, the probability pkcopy for copying words from KG is computed as follows, and is used in testing time for final selection between predicted words from Word Decoder and words in KG at each time step when generating sentences.\ntkcopy = σ(W1vwk +W2vpk +W3sk+bcopy), (7)\npkcopy = λ ·Xsemantic + (1− λ) · tkcopy, (8) where W1, W2, W3 and bcopy are learnable parameters. vwk represents token embedding and sk represents the last hidden state of Word-Decoder at each time step. λ is a trade-off coefficient and is set as 0.3.\nThe semantic context scoring module is jointly optimized with copy probability prediction and benefits the copy probability prediction. The copy or prediction loss function is defined as:\nLcopy = − K∑ k=0 (yk · log(pkcopy) + (1− yk)\n·log(1− pkcopy))\n(9)\nwhere yk is the ground-truth 0-1 label indicating copying or predicting word at k − th time step, which is generated from KG and the ground-truth sentence (see more details in supplementary material).\nFinally, the total training loss Ltotal in our SOSC model is composed of four components: sorting loss Lsort(Eq.2), POS generation loss Lpos(Eq.4), word generation loss Ltoken(Eq.5) and copy or prediction loss Lcopy(Eq.9).\nLtotal = Ltoken + λ1Lpos + λ2Lsort + λ3Lcopy, (10)\nwhere λ1, λ2 and λ3 are the trade-off coefficients. 4 Experiments In this section, we report the comparison results with state-of-the-art methods and further analyze the performance of each component in our S-OSC model through ablation studies. We also evaluate our model performance through human evaluation and qualitative analysis."
    }, {
      "heading" : "4.1 Datasets",
      "text" : "In this paper, two benchmarks: WebNLG (Li et al., 2021) and DART (Nan et al., 2020) are utilized to evaluate the performance of our S-OSC model. WebNLG WebNLG (Li et al., 2021) is a most widely used dataset in KG-to-text generation task. Each graph is extracted from DBPedia and consists of two to seven triplets. The train/val/test splits are 7362/1389/5427. DART Compared to WebNLG, DART (Nan et al., 2020) is a larger open-domain dataset, where triples are composed of tree-structured ontology. The train/val/test splits are 30348/5097/4437."
    }, {
      "heading" : "4.2 Evaluation Metrics",
      "text" : "Following the previous works (Ribeiro et al., 2020a,b; Li et al., 2021) on WebNLG dataset, we adopt four automatic language evaluation metrics for WebNLG dataset, i.e., BLEU-4 (Papineni et al., 2002), CIDEr (Vedantam et al., 2015), Chrf++ (Popović, 2015) and ROUGE-L (Lin, 2004). Following previous works (Nan et al., 2020) on DART dataset, in addition to BLEU-4 (Papineni et al., 2002), we use four additional automatic evaluation metrics, i.e., METEOR (Banerjee and Lavie, 2005), MoverScore (Zhao et al., 2019), BERTScore (Zhang et al., 2019) and BLEURT (Sellam et al., 2020)."
    }, {
      "heading" : "4.3 Implementation Details",
      "text" : "In the sorting network, the fixed KG order length N is set to 8 and 10 for WebNLG and DART, respectively. The POS generator operates on the POS sequences parsed from ground-truth sentences via NLTK, and trains from BART-Base pretrained model (Lewis et al., 2019). For Word-EncoderDecoder, we follow the code in JointGT (Ke et al., 2021) and utilize Bart-Base with selfattention (Shaw et al., 2018). The beam search size for generating sentences in inference time is set to 5. We optimize all the parameters under the supervision of the total loss in Eq.10 using the OpenAI AdamW optimizer. The loss weights λ1, λ2 and λ3 in total training loss (Eq.10) are set to 0.7, 0.4, and 0.3, respectively. 4.4 Main Results on WebNLG and DART We compare our S-OSC model with other state-ofthe-art methods on WebNLG and DART. Results on WebNLG are shown in Table 1. It can be observed from Table 1 that our S-OSC model outperforms all the previous methods in three evaluation metrics, B-4, R-L and Chrf++ metrics, except for the CIDEr value being in the second place compared to the best performing CIDEr result reported by the model in Li et al.(Li et al., 2021). Note that our S-OSC model contains one learning-based sorting network supervised by the ground-truth order extracted from KG and the ground-truth sentence. We also report our model results under the groundtruth order during inference time (denoted as \"SOSC-GT\") which serves as the upper bound for our sorting performance. From the comparison of our model with predicted order \"S-OSC\" and our model with ground-truth order \"S-OSC-GT\", we can see that our model results with predicted order is close to the results with ground-truth order with the result gaps less than 1.3% in most metrics, which shows the advantage of our learning-based\nsorting network for generating KG description order.\nResults on DART are shown in Table 2. From previous models’ results, we can see that pretraining on the large corpus (e.g., \"T5-Large\" and \"Bart-Large\") brings significant result improvement compared to \"Seq2Seq-Att\" and \"End-to-End Transformer\". Our S-OSC model further achieves new state-of-the-art results in all five metrics compared to these pre-training based models (e.g., \"T5Large\") with B-4 score improved by 12%, METEOR score improved by 3%, Moverscore improved by 10%, BERTScore improved by 1%, and BLEURT imrpoved by 5%. This result also validates the effectiveness of our model in improving the fluentness and authenticity of the generated sentences with the proposed learning-based sorting network and consistency enhancement under the POS syntactic and semantic context constraints. Similar to the results on WebNLG, our model \"S-OSC\" with predicted order can achieve the performance close to that with ground-truth order. 4.5 Ablation study In this section, we conduct extensive experiments on WebNLG to evaluate various factors in the word copy or prediction during sentence generation, e.g., the POS generator and semantic context (SC) scoring. We compare our full \"S-OSC\" model with the following variations: without word copy component and just use the predicted word from Word Decoder at each time step (w/o CP), without POS information in copy probability prediction (w/o POS), without semantic context scoring in copy probability prediction (w/o SC), without POS tag information and semantic context scoring in copy probability prediction (w/o POS and SC) and reply on the last hidden states to predict the copy probability as in previous methods (Koncel-Kedziorski et al., 2019; See et al., 2017). From the results in Table 3, we can observe that: (1) By removing the word copy component and directly taking the predicted word from Word Decoder at each time step (w/o CP), the results drop significantly by 4% in B-4, 3% in R-L, 0.4 point in CIDEr and 3% in Chrf++. (2) We then consider incorporating the copy prediction component, but just reply on the last hidden states to predict the copy probability as in previous methods (Koncel-Kedziorski et al., 2019; See et al., 2017) without POS tag information and semantic context scoring in copy probability prediction (w/o POS and SC). The results improve a little in all the metrics compared with that of \"w/o\nCP\". (3) We then evaluate the effectiveness of POS syntactic information and semantic context scores in improving the quality of the generated sentences by removing each of them at a time.\nWhen without POS information in copy probability prediction (w/o POS), the results drop by 2% in B-4, 1.5% in R-L, 0.3 in CIDEr and 3% in Chrf++. When without semantic context scoring in copy probability prediction (w/o SC), the results drop by 2% in B-4, 1.1% in R-L, 0.2 in CIDEr and 2% in Chrf++. Both \"w/o POS\" and \"w/o SC\" improve consistently compared to previous copy policy in \"w/o POS and SC\".\nTo further reveal more details about our model performance, we conduct more ablation studies regarding the following questions. (1) How does triplet structure encoding in the sorting network help the model performance compared with direct node encoding without triplet structure context? (2) How does our model perform for different triplet numbers in KG? (3) How does the sliding window size in semantic context scoring function affect the model performance? (1) Triplet structure encoding in sorting network. To show the effect of triplet structure encoding (TS) in our sorting network, we investigate the performance of direct node encoding without triplet structure (NS), as well as our S-OSC model’s results with random order (RS). Results on WebNLG are shown in Table 4 and the upper bound result is shown with ground-truth order (GT). From Table 4, sorting with triplet structure encoding \"TS\"\noutperforms random order \"RS\" significantly, and also outperforms node encoding \"NS\" by 2% in B4, 2.3% in R-L, 0.2 in CIDEr and 1.7% in Chrf++, showing the advantage of triplet structure encoding compared to node encoding without triplet structure context. The results of DART show similar trend and are reported in supplementary material.\n(2) Different Knowledge Graph Sizes To verify the effect of our S-OSC model performance on different KG Sizes, we split the test dataset into three subsets according to the size of the KG, i.e., the number of triples in KG are less than 3, between 4 and 6, and more than 7, and report results on each subset. DART is selected for experiment due to its wide distribution of KG sizes. The results of B-4 in each subset are plotted in Figure 5, which shows that when the number of triples in KG increases, the difficulty of sorting and KG-to-text generation increases (comparing \"GT\" with \"TS\"). Also, our model’s superiority exhibits more relative improvement (comparing \"TS\" with \"NS\"). Other metric results show similar trend and are reported in supplementary material.\n(3) Sliding window size in the semantic context scoring We illustrate the B-4 results on WebNLG for different sliding window sizes in semantic context scoring function in Figure 7. As can be seen from Figure 7, the model achieves the best performances when the sliding window size is 3. Other metric results show similar trend and are reported in supplementary material. Besides, we set the sliding window size to be 3 on all experiments. 4.6 Human evaluation We conduct the human evaluation on WebNLG to further evaluate the generated text. In this paper, we adopt the same human evaluation criteria as\nin Chen et al.(Chen et al., 2019), i.e., Factual correctness including Supp (counting the number of facts that co-exist in the KG and generated text) and Cont (counting the facts in the generated texts missing from or contradicting with KG), Language naturalness including NS (evaluating the accuracy and fluentness of generated sentences). In addition to using absolute score at 5-point metric in NS, we also use relative ranking scores (named NA). We randomly select 100 knowledge graphs and ask five people to do human evaluation. Table 5 reports the results. We can observe that: the generated texts of our model are more authentic and consistent with KG than the method in Li et al. (Li et al., 2021)."
    }, {
      "heading" : "4.7 Qualitative analysis",
      "text" : "We show two qualitative examples from WebNLG and DART in Figure 6. From the example of WebNLG, we can see that the previous method in Li et al.(Li et al., 2021) generates the wrong description order with node 3 and node 2 exchanged positions. This causes the generated sentence from Li et al.(Li et al., 2021) containing the wrong text \"jusuf kalla\" noted in red color and misssing the text \"Malaysian Indian\", while our S-OSC method generates the right order and consistent sentences with ground truth. In the example from DART, though our model generates relative inferior order with node 2 and node 5 exchanged positions, relying on our strong sentence generator with syntactic constraint and semantic consistency constraint, our S-OSC model is able to generate semantic consistent sentence to the KG with the right words copied from KG. However, in this example, BartLarge(Ribeiro et al., 2020a) still misses some key word descriptions from KG, e.g., \"the final fight\non 10/28/2014\" and \"Launch Pad 0\", though conditioned on the right predicted order, showing the inferior performance of their copy or prediction module in sentence generation."
    }, {
      "heading" : "5 Conclusion",
      "text" : "This paper proposes a learning-based sorting network to obtain the optimal description order for KG-to-text generation. Additionally, our model incorporates POS generator and semantic context scoring to selectively copy words from KG and improve the word authenticity from knowledge graph in generated sentences. Extensive experiments show that our model outperforms precious state-of-the-art approaches. In the future, we will introduce casual inference into the model to further improve the reasoning ability."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 0,
    "abstractText" : "The knowledge graph (KG) stores a large amount of structural knowledge, while it is not easy for direct human understanding. Knowledge graph-to-text (KG-to-text) generation aims to generate easy-to-understand sentences from the KG, and at the same time, maintain semantic consistency between generated sentences and the KG. Existing KG-to-text generation methods phrase this task as a sequence-tosequence generation task with linearized KG as input and consider the consistency issue of the generated text and KGs through a simple selection between decoded sentence words and KG node words at each time step. However, the linearized KG order is obtained through heuristic search without data-driven optimization. In this paper, we optimize the knowledge description order prediction under the order supervision extracted from the caption and further enhance the consistency of the generated sentences and KGs through syntactic and semantic regularization. We incorporate the Part-of-Speech (POS) syntactic tags to constrain the positions to copy words from the KG and employ a semantic context scoring function to evaluate the semantic fitness for each word in its local context when decoding each word in the generated sentence. Extensive experimental results are conducted on two datasets, WebNLG and DART, and achieve state-of-the-art performances. Our code will be public upon paper acceptance.",
    "creator" : null
  }
}