[{"rid": "98ee38fd39dcf0ddfa19a3ba473c0a574213dfc3ab381f974a9d1419c4807e799d0bcaa93177f03214424c04eb2decf9916db94458c80c7d190b776a4d55f1b8", "reviewer": null, "report": {"paper_summary": "Recent works have demonstrated the knowledge-recalling capacities (robin, is a, bird) of pre-trained language models based on transformers, such as BERT, etc. In light of these findings, the authors of this paper isolate and attribute the knowledge-recalling tendencies of such models to a few neurons in the feed-forward networks (FFN) of the BERT architecture. They do so by applying the Integrated Gradients method to the hidden layers of the FFNs in BERT-base, specifically when the model receives inputs about relational knowledge. \nTo ensure that the isolated knowledge-neurons consistently capture relational knowledge, the authors use several formulations of a given knowledge triple -- for instance, using {“X was produced by Y”, “X is a product of Y”, “Y and its product X”} for the relation: (X, manufacturer, Y). As a baseline attribution score, the authors choose regular, unmodified activation scores of the neurons.\nThe authors validate their findings by proposing two main experiments: First, they ascertain the knowledge-sensitivity of the attributed neurons (for a given relation) by comparing their activations on sentences where the head (X) and the tail (Y) words mentioned in sentences that express the relation  vs. those that do not (and instead express different facts about X and Y). \nSecond, the authors demonstrate how the identified neurons can be numerically modified to update and delete relational information, showcasing notable changes in model behavior for each modification.\nThe paper’s auxiliary findings include notable improvements against the chosen baseline and  greater percentage of knowledge-neurons in deeper--as opposed to shallow--layers. ", "summary_of_strengths": "The paper makes a desirable contribution to the field of ‘BlackBox NLP’ by conducting analyses into a model that has famously been shown to recall factual knowledge, moving beyond just analyzing its outputs and instead focusing on its internal mechanistic units. In general, the paper shows innovations in: 1. Its usage of variably-phrased prompts for relational information -- to me, this truly encourages robustness in isolating neuronal-capacities. \n2. Its evaluation of the robustness of the identified neurons by differentiating knowledge-expressing sentences from lexical and syntactic co-occurrence. \n2. Its demonstration of knowledge update (and erasure) via simple modifications to the knowledge neurons, further ascertaining their sensitivity to relational information. ", "summary_of_weaknesses": "Though the paper excels as a result of its extensive analyses and evaluations, there is generally a lack of clarity in many areas: 1. It is not straightforwardly clear exactly which layer in the FFN is being subject to the experiments -- the authors do mention the intermediate layer in line 161 and Figure 2, but I think this should be made precisely clear that it is the value after applying the non-linear GELU function to input $H$ multiplied by weight matrix $W_1$. 2. Their attribution and isolation technique involves a variety of different parameters that seem to have been vaguely chosen (threshold t, prompt percentage p, and more importantly the ‘desired’ number of neurons). If the authors indeed conducted ablations for these values, they should at-least mention it in some form or the other. \n3. Going deeper in the choice of [2,5] neurons: I am unsure if having a fixed range of desired neurons (without any hypothesis) is entirely appropriate. I hope to see some sort of a justification or reasoning behind restricting this range, especially since the rest of the parameters depend upon it, i.e.,  the authors choose t and p so that the final set of neurons lie in [2, 5]. \n4. The knowledge-update equation in section 5.1 is a bit confusing: $\\mathrm{FFN}_i^{(val)}$ seems like a scalar value (the value of a single neuron in the layer), whereas the value it is assigned is composed of vectors ($\\mathbf{t}$ and $\\mathbf{t}^{\\prime}$). ", "comments,_suggestions_and_typos": "Questions to the authors: Would the knowledge-neurons remain robust when the words in a given relational prompt are mentioned but not in a knowledge-expressing manner? For instance, if one uses lexical primes in a prompt not meant for the relation, e,g., 'capital. X is a city in Y', do the neurons still robustly show low activations?\nSuggestions: Line 393-395: Having an example here would be nice. It is also not clear how the choice of $\\mathbf{t}^{\\prime}$ is being made.\nLine 505-507: “... have pointed out that the feed-forward network module also matters to Transformer” needs a little elaboration -- matters in what way? "}, "scores": {"overall": "3.5 ", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "2 = Documentary: The new datasets will be useful to study or replicate the reported research, although for other purposes they may have limited interest or limited usability. (Still a positive rating)", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "4 = From an allowed pre-existing preprint or workshop paper, I know/can guess at least one author's name.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 159], [159, 363], [363, 537], [537, 825], [825, 931], [931, 1310], [1310, 1511], [1511, 1686]], "summary_of_strengths": [[0, 263], [263, 307], [307, 310], [310, 452], [452, 456], [456, 607], [607, 611], [611, 780]], "summary_of_weaknesses": [[0, 131], [131, 134], [134, 474], [474, 687], [687, 806], [806, 810], [810, 960], [960, 1189], [1189, 1193], [1193, 1452]], "comments,_suggestions_and_typos": [[0, 168], [168, 265], [265, 336], [336, 349], [349, 401], [401, 477], [477, 630]]}}}, {"rid": "c887148d392e50e417e797b4e40da64d20880a5a4f496c5608b974f27d31d35fd052cf97f6b6e6172dfef022be61f8bdfbdea1878faf682ef9c942b1f9fab1c1", "reviewer": "Danqi Chen", "report": {"paper_summary": "The paper studies how factual knowledge is stored inside the pre-trained transformer model, and presents a knowledge attribution method to identify “knowledge neurons” in feed-forward layers. The method is based on integrated gradients and several refining steps. They apply their method on the fill-in-the-blank cloze task for BERT. By comparing to a baseline (which takes activation values as the attribution score), the authors show their identified neurons are specific to the input fact and not shared with other facts, indicating the neurons are more likely to express the specific factual knowledge. Based on the identified knowledge neurons, the paper demonstrates that the factual knowledge can be updated or erased by modifying the activation values. ", "summary_of_strengths": "- The paper is well-written and easy to follow.\n- The approach of identifying knowledge neurons makes sense to me and the experiments (e.g., suppressing or amplifying the knowledge neurons) seem well-designed to show the effectiveness of the approach.\n- The paper provides insightful studies on how knowledge is stored in pre-trained language models. Given the recent works on using pre-trained LMs to extract facts or to answer questions in a closed-book scheme, this paper can be of interest to the NLP community.\n- The paper demonstrates a new method to modify the factual knowledge in Section 5.1. The empirical results (e.g., success rates) look strong. This is an interesting addition to the related literature in this field.\n- Section 4.6 is interesting and the results are potentially useful to determine whether a sentence describes a relation between two entities or not, which might help improve auto-labeling quality in other NLP tasks based on distant supervision. ", "summary_of_weaknesses": "- In the “Updating Facts” section, although the results seem to show that modifying the neurons using the word embeddings is effective, the paper lacks a discussion on this. It is not intuitive to me that there is a connection between a neuron at a middle layer and the word embeddings (which are used at the input layer).  - Using integrated gradients to measure the attribution has been studied in existing papers. The paper also proposes post-processing steps to filter out the “false-positive” neurons, however, the paper doesn’t show how important these post-processing steps are. I think an ablation study may be needed.\n- The paper lacks details of experimental settings. For example, how are those hyperparameters ($t$, $p$, $\\lambda_1$, etc.) tuned? In table 5, why do “other relations” have a very different scale of perplexity compared to “erased relation” before erasing? Are “other relations” randomly selected?\n- The baseline method (i.e., using activation values as the attribution score) is widely used in previous studies. Although the paper empirically shows that the baseline is not as effective as the proposed method, - I expect more discussion on why using activation values is not a good idea.\n- One limitation of this study is that the paper only focuses on single-word cloze queries (as discussed in the paper). ", "comments,_suggestions_and_typos": "- Figure 3: The illustration is not clear to me. Why are there two “40%” in the figure?\n- I was confused that the paper targets single-token cloze queries or multi-token ones. I did not see a clear clarification until reading the conclusion. "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Danqi Chen, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "4 = From an allowed pre-existing preprint or workshop paper, I know/can guess at least one author's name.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 192], [192, 264], [264, 334], [334, 607], [607, 761]], "summary_of_strengths": [[0, 48], [48, 252], [252, 351], [351, 516], [516, 602], [602, 659], [659, 732], [732, 978]], "summary_of_weaknesses": [[0, 174], [174, 323], [323, 324], [324, 417], [417, 586], [586, 627], [627, 679], [679, 752], [752, 759], [759, 884], [884, 925], [925, 1040], [1040, 1217], [1217, 1337]], "comments,_suggestions_and_typos": [[0, 49], [49, 88], [88, 176], [176, 242]]}}}]