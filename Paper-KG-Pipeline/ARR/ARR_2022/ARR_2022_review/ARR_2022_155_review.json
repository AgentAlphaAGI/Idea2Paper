[{"rid": "a7b2e5cce4c1e1a8c7a4959fed755e9e0d3a73fb9dad9d5a76258f80583cb2600e57fb75a86f7b5084d87524213bc8aa51ced77e72b0a0d645a4abd320b022d9", "reviewer": null, "report": {"paper_summary": "This paper analyzes roles of image and text in the problem of claim detection, which is often the first stage of fake news detection. It introduces a novel dataset MM-Claims, which consists of tweets and corresponding images over three topics: COVID-19, Climate Change and broadly Technology. The dataset contains roughly 86 000 tweets, out of which 3400 are labeled manually by multiple annotators for the training and evaluation of multimodal models. It also evaluates strong unimodal and multimodal baselines, and analyzes the potential and drawbacks of current models. ", "summary_of_strengths": "It introduces more fine-grained labels, the tertiary claim classes and visual claim classes, in multimodal claim detection, which is the first step of fake news detection.  Also, they add 2 more topics compared to previous work. ", "summary_of_weaknesses": "1. The paper doesn't show how tertiary claim classes and visual claim classes can help in fake news detection.  So it leads to the question, why do we care the proposed label classes in claim detection? \n2. The annotated dataset size is limited for the use of largely used heavy multi-modal models. And while claims are related to 3 topics, they are still limited. \n3. Experiments include fine-tuning on ALBEF but not fine-tuning on CLIP. \n4. The dataset has conflicts in annotated data. Why not adding more annotators? ", "comments,_suggestions_and_typos": "1. Try to show the value of the dataset -- to show the use of tertiary claim classes and visual claim classes can actually help in fake news detection performance. Also, it will be interesting to see whether using the classification results on visual claim classes can help the classification performance on tertiary claim classes. \n2. Increase the number of annotators each data to avoid conflicts. If possible, annotate more data. \n3. In experiment, it can also do fine-tuning on CLIP. "}, "scores": {"overall": "2.5 ", "best_paper": "No", "datasets": "3 = Potentially useful: Someone might find the new datasets useful for their work.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 134], [134, 293], [293, 453], [453, 573]], "summary_of_strengths": [[0, 172], [172, 229]], "summary_of_weaknesses": [[0, 3], [3, 111], [111, 203], [203, 207], [207, 299], [299, 365], [365, 369], [369, 439], [439, 443], [443, 488], [488, 520]], "comments,_suggestions_and_typos": [[0, 3], [3, 164], [164, 332], [332, 336], [336, 400], [400, 433], [433, 437], [437, 488]]}}}, {"rid": "5c77cd0762b01100d344142fa9ea92d04acaabe8d4661136703a62b2a1c714e68fbffd505cfa1f15bf80b0e821c229343aa07936e10dfcdb6086b55a3d9690ec", "reviewer": "Monjoy Saha", "report": {"paper_summary": "The authors investigated the roles of image and text at the first stage of the fake news detection pipeline. ", "summary_of_strengths": "objective and Data analysis parts are stronger. ", "summary_of_weaknesses": "From the title of this manuscript, it seems that the authors mainly contributed to the dataset.  The authors mostly applied conventional approaches like SVM. ", "comments,_suggestions_and_typos": "I think it will be better if the authors highlight their methodology as well. It will be better if the authors work on advanced AI algorithms such as deep learning. ", "ethical_concerns": "The authors should take proper permission of using any images. The permission details should be mentioned in the manuscript. "}, "scores": {"overall": "3 = Good: This paper makes a reasonable contribution, and might be of interest for some (broad or narrow) sub-communities, possibly with minor revisions.", "best_paper": "No", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Monjoy Saha, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 109]], "summary_of_strengths": [[0, 48]], "summary_of_weaknesses": [[0, 96], [96, 158]], "comments,_suggestions_and_typos": [[0, 78], [78, 165]], "ethical_concerns": [[0, 63], [63, 125]]}}}]