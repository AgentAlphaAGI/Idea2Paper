[{"rid": "4bd810d53535dc50168f801c440c9d10be4ce282231ea27ba52ebb03ca7a0917c40a29b37f018d63a989598d7f21997ab055f76141a00380e11de4e3c88183ac", "reviewer": null, "report": {"paper_summary": "The paper describes the method to trace historical sound change by measuring the distance between pairs of character distributions over time. Using spelling as a necessary proxy to phonetics, the authors model phonological change through the use of diachronic character embeddings. \nThey show the viability of the proposed approach on synthetic datasets and  on real sound changes in Danish geographical names (in particular, the authors focus on lenition). ", "summary_of_strengths": "I really like how the work combines linguistic problems with data-driven solutions. Modeling sound change computationally is a rarely seen task in the NLP venues, which is sad, since it is extremely important for general historical linguistics. \nThe paper under review proposes a smart method to trace gradual phonological replacements like lenition (t -> d, k -> g, etc). It will be of great use both to linguists and to NLP practitioners interested in change detection. In fact, the paper extends the computational change detection field from only semantics to phonology. ", "summary_of_weaknesses": "1) Although the proposed method is indeed interesting, the  authors do not make any attempt to compare it to any other prior methods. They limit themselves to showing that the method produces statistically significant linear regressions. But this is, to my mind, insufficient as empirical evaluation. Why not implement a simple baseline (for example, character frequencies, etc) and compare to it? This would make the paper more persuasive.\n2) The strange results for \"p --> b\" sound change deserves more explanations beyond just noting that this is a rarer phoneme than the others. If the method is not able to trace sound change in 1/3 cases, it must be shown that it is still better than anything else (baselines).\n3) The method is entirely based on written signal (spelling). It is understandable that we lack proper phonological datasets, but I would like to see more discussion on how this spelling proxy might influence the performance of the proposed method. ", "comments,_suggestions_and_typos": "l. 066: \"phonology: Inspired by\" --> \"phonology. Inspired by\" May be, reposition Figures 1 and 2 to use the page space more efficiently?\nDid you try cosine distance instead of Euclidean? It might perform better in the end.\nThe authors several times mention \"neural methods that make use of dense character representations\" (which they don't use). I believe that the word \"neural\" is redundant here. Dense representations can be produced without using any neural networks (for example, by applying SVD to PMI vectors).\nThese papers, although not 100% on-topic, might still be mentioned in the related work: https://aclanthology.org/W19-4713/ https://aclanthology.org/W19-4732/ "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "Maybe", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "5 = Positive that my evaluation is correct. I read the paper very carefully and am familiar with related work.", "sentences": {"paper_summary": [[0, 142], [142, 282], [282, 458]], "summary_of_strengths": [[0, 84], [84, 245], [245, 373], [373, 472], [472, 574]], "summary_of_weaknesses": [[0, 134], [134, 238], [238, 301], [301, 398], [398, 441], [441, 583], [583, 718], [718, 780], [780, 967]], "comments,_suggestions_and_typos": [[0, 49], [49, 62], [62, 137], [137, 187], [187, 223], [223, 347], [347, 399], [399, 518], [518, 676]]}}}, {"rid": "fd73ac3f95e24da9f049c742dbf2f0c7ce752be24db2bccaeb657520e3dd1d7e9cc23e31cc970c9436553cd5d2b36b63826a9bd7b216c718fd2600a0508eaf1d", "reviewer": null, "report": {"paper_summary": "This paper use methods relying on spelling, using character embeddings, to detect sound change across time. They rely on three datasets to test the effectiveness of their methods: a synthetic one in a language having a simplified phonotactic system, one in Danish with synthetically generated sound change, and a real one in Danish, with known sound change. They show that they can successfully detect the selected sound changes in the datasets, and identify precisely the context of the change. ", "summary_of_strengths": "The paper is globally nice to read and introduces an interesting idea. The related works section is particularly well-written, with the right level of detail, even though some references are missing. \nThe experimental setup is sound and clear; in particular, the use of a control dataset is appreciated. ", "summary_of_weaknesses": "1) The main issue in this paper is that you only show that you can successfully detect known sound changes, and that you don’t spuriously detect them when they’re absent, thanks to the control corpus. But you might detect a lot of changes in characters embeddings using your methods, that are not related to sound change. Using your system in an exploratory fashion, to detect all possible changes and categorize them, would greatly strengthen the paper. As it is, to my understanding, there is no way to be sure that the character embeddings do not lead to detecting a lot of changes independent from phonology, and this is a major issue. Moreover, the link between spelling and sound change is not straightforward to me and should be more clearly justified.\n2) Semantic and phonological change across time should indeed take a logistic shape, as you describe in your description; your experiments also seem to show that the change in the Geo corpus is not linear. Why did you stick to a linear shape? Shoemark et al (2019) that you cite also tried a logarithmic shape, you could try it too.\n3) There is a large amount of work on semantic change using contextualized embeddings and pre-trained language models, that you do not evoke in your related works (from Mario Giulianelli, Matej Martinc…).  4) The formalism you use, a --> b / c, should be introduced more clearly from the beginning. Especially since you use it as early as in the summary, where it can’t be comprehended without prior knowledge of this formalism. The explanation at line 190 might benefit from a scheme. Similarly, some words like “plosive” might benefit from a short definition (even in a footnote) for readers not familiar with the domain. ", "comments,_suggestions_and_typos": "Nor clear how the Bin:Control effect is computed. Globally, all metrics described in Section 5 would benefit from equations.\nOverall, the localization of Tables and Figures in the paper would be more optimal to ease the reading. \nTables 2 to 4 look strange to me without lines.\nL.32: Choose only one between “since” and “however” L59-62: Add references here.\nL. 362 and 364: add “the” distance, “the” main effect.\nL. 390: in both corpora (no “the”) L. 480: repetition of “language”’. "}, "scores": {"overall": "2 = Borderline: This paper has some merit, but also significant flaws. It does not warrant publication at top-tier venues, but might still be a good pick for workshops.", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 108], [108, 358], [358, 496]], "summary_of_strengths": [[0, 71], [71, 200], [200, 304]], "summary_of_weaknesses": [[0, 201], [201, 322], [322, 455], [455, 640], [640, 760], [760, 966], [966, 1003], [1003, 1093], [1093, 1298], [1298, 1299], [1299, 1392], [1392, 1522], [1522, 1579], [1579, 1717]], "comments,_suggestions_and_typos": [[0, 50], [50, 125], [125, 229], [229, 278], [278, 330], [330, 359], [359, 414], [414, 449], [449, 484]]}}}]