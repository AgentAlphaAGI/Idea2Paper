[{"rid": "840a52764399d19ce9b6984c658c37ea23805aa2c720d9798ba08d0bca8df5c2f0084c63f2e75609d95c3db84f79486c3dbf161200a799f3285702e3941fe0a0", "reviewer": "Bowei Zou", "report": {"paper_summary": "This paper presents a new point of view that the success of neural text matching models lies in learning the length divergence bias on datasets. To this end, the paper constructs adversarial test sets to verify this conclusion. The results show that the performance of TM models on such test sets is worse. To address it, the paper conducts the same method to construct adversarial training sets and retrain TM models on them. ", "summary_of_strengths": "Verify that adding adversarial data can improve the robustness of the text matching models. ", "summary_of_weaknesses": "1. This paper seems to reduce the impact of semantic noise on text matching to \"length divergence bias\". From the first example in Table 1, it can be seen that what affects the model's prediction should be that T2 contains more other semantics (noise) such as \"Canadian\", \"University of Waterloo grads Kaheer Suleman and Sam Pasupalak\", which may lead to semantic representation drifting and then affects the TM models. In my opinion, the \"length divergence bias\" should only have a discrepancy in the length of the textual expressions rather than introducing additional semantics. \n2. Lack of details and intuitive examples of the constructed adversarial datasets. ", "comments,_suggestions_and_typos": "- Line 136-138: \"... we down-sample each category to align with the average PosRatio of the whole test set\". Could the authors provide more details about the adversarial data construction?\n- Could the authors use some specific examples to analyze why the constructed adversarial training sets can improve the robustness of the TM models? "}, "scores": {"overall": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Bowei Zou, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "3 = From the contents of the submission itself, I know/can guess at least one author's name.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 145], [145, 228], [228, 307], [307, 427]], "summary_of_strengths": [[0, 92]], "summary_of_weaknesses": [[0, 3], [3, 105], [105, 420], [420, 582], [582, 586], [586, 666]], "comments,_suggestions_and_typos": [[0, 109], [109, 189], [189, 338]]}}}, {"rid": "d420c861389d357cba32905a3ce5bdb49ac1f8cf4307e514dd57f7258c3fb92ed2ba9f8ed6236f98685df72905f399b55c3b1807531a2928752890bf72b2f7e1", "reviewer": "Steffen Eger", "report": {"paper_summary": "The paper discusses length bias for textual matching models, shows that models are prone to this bias, gives an explanation why, and proposes a solution to correct it. ", "summary_of_strengths": "- Identification of a new bias - Solution (adversarial training) to address it - Investigation of IR and \"NLP\" model settings ", "summary_of_weaknesses": "- This is the (n+1)st paper on discussing biases in models and datasets and it's not clear to me whether this specific bias hasn't been discovered before - not a single 2021 paper cited - models investigated (ESIM, etc.) are a bit old, no novel model is included - the explanation via probing is a bit trivial (this probing has been criticized btw., as unreliable [1]); it's also not clear to me why BERT performs best in the probing, but is least prone to the length diversion bias, questioning the apparent explanation - in l.237, authors write \"except for one combination\", but there are quite a few negative signs in Table 3, indicating that adversarial training is less often helpful - the losses from length bias are often small, e.g., 1 percentage point for BERT [1] https://aclanthology.org/2020.conll-1.8.pdf ", "comments,_suggestions_and_typos": "- Textual matching is also relevant for evaluation metrics [2], where similar biases (e.g., lexical overlap) are discovered. It would be interesting to extend this analysis and also consider models from such communities [2] https://aclanthology.org/2021.emnlp-main.701/ "}, "scores": {"overall": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.", "best_paper": "No", "replicability": "5 = They could easily reproduce the results.", "datasets": "3 = Potentially useful: Someone might find the new datasets useful for their work.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Steffen Eger, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 168]], "summary_of_strengths": [[0, 31], [31, 79], [79, 126]], "summary_of_weaknesses": [[0, 154], [154, 186], [186, 221], [221, 263], [263, 350], [350, 521], [521, 689], [689, 770], [770, 818]], "comments,_suggestions_and_typos": [[0, 125], [125, 220], [220, 270]]}}}]