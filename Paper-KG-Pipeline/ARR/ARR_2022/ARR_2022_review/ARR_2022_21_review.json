[{"rid": "79072edadde67d89caf411ac0ef9f114b046aace8a5afe36fdcad2b5b63344e3d746c367789ab376b445cf4a2fda759455022e9a0a764726ac243f890c83fc70", "reviewer": null, "report": {"paper_summary": "The authors present an approach for the task of discourse dependency parsing (DDP), i.e. the task of identifying the structure and relationship between EDUs in a document. They explore different contextualized representations for DDP in a Sentence-First parsing framework, where a complete discourse tree is built up sentence by sentence. In addition, the authors propose a novel method for relation identification that exploits the writing patterns that people typically use to organize discourses. Experiments show that the proposed approaches outperform the state of the art on an English and a Chinese dataset.\nCONTRIBUTIONS: (1) The authors formulate the task of relation identification in a novel sequence labeling paradigm to take advantage of the inherent structural information in the discourse. \n(2) The authors develop an approach for contextualized EDU representations to dynamically capture the information needed for the DDP task at different text granularity levels. \n(3) The authors show empirical success of their approach. ", "summary_of_strengths": "- Overall, the paper is clear in its objectives and methodology followed. The work is well structured, easy to read and follow.\n- The approach is well motivated and addresses a problem that is relevant to the community.\n- The proposed approach is tested with reasonable models and appropriate experiments. The experimental results are promising, demonstrating the effectiveness of the proposed method. ", "summary_of_weaknesses": "- Lack of illustrative examples regarding the model outputs.\n- In the evaluation, I'm missing a detailed error analysis. It would be very enlightening to add a manual error analysis to figure out the most prevalent mistakes of the different approaches. ", "comments,_suggestions_and_typos": "- l. 25/26: \"... can benefit many downstream examples\" List/Cite some examples.\n- l. 40: \"... previous studies have shown the benefit...\" Citation?\n- l. 419: stmodel udy -> model study - l. 567: We -> we "}, "scores": {"overall": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "1 = No usable datasets submitted.", "software": "4 = Useful: I would recommend the new software to other researchers or developers for their ongoing work."}, "meta": {"license": "Copyright Â© 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "2 =  Willing to defend my evaluation, but it is fairly likely that I missed some details, didn't understand some central points, or can't be sure about the novelty of the work.", "sentences": {"paper_summary": [[0, 172], [172, 339], [339, 500], [500, 615], [615, 805], [805, 982], [982, 1041]], "summary_of_strengths": [[0, 74], [74, 128], [128, 220], [220, 306], [306, 402]], "summary_of_weaknesses": [[0, 61], [61, 121], [121, 253]], "comments,_suggestions_and_typos": [[0, 80], [80, 148], [148, 185], [185, 204]]}}}]