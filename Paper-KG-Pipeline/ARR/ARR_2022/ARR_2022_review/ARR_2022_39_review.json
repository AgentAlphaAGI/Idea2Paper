[{"rid": "78daab8d16002833c5252f450de6b451f6c9021d5d1ea52cc18f5191052fe333aed46e2970e7fdd34e458a6553f3c0556bc76f44e728b420b9d9f68ee847d995", "reviewer": null, "report": {"paper_summary": "This paper introduces an auto-regressive blank infilling model based upon an encoder-decoder architecture.  The model is very similar to T5 except for (i) a generic [MASK] token is used in place of unique sentinel tokens, (ii) the [MASK] tokens can be shuffled on the decoder side of the model, and (iii) 2D positional encodings are used -- the position of the corrupted text and the tokens within the corrupted span.  This architecture is intended to address the varying performance of encoder and decoder models over natural language understanding, conditional generation and unconditional generation tasks. ", "summary_of_strengths": "- The paper is very clearly written.\n- The illustrations of easy to follow and enhance understanding of concepts.\n- Paper provides a concise and excellent review of competing architectures.\n- I believe that the model could be re-implemented from information provided in Section 2.\n- Thorough presentation of results. ", "summary_of_weaknesses": "- Result in Table 1 are substantially lower than SOTA results, casting doubt on usefulness of this approach.\n- Approach appears to be very incremental to T5, leading to questions about novelty.\n- A clearer ablation studying comparing the seven potential combinations of the three differences to T5 is missing.\n- The array of GLM models evaluated (e.g., GLM_{Doc}, GLM_{Sent}, GLM_{410M}, etc.) were not well motivated and did not add much to the presentation. ", "comments,_suggestions_and_typos": "I generally liked the paper, but I am not sure that the results (as presented) make a compelling argument to add another model to the transformer-based “pantheon of models.”  It would be great to see how larger GLM models compare to SOTA results, given that hardware resources do not appear to be a constraint.\nTypo: Should “BRET” in line 65 be “BERT”? "}, "scores": {"overall": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 107], [107, 418], [418, 610]], "summary_of_strengths": [[0, 37], [37, 114], [114, 190], [190, 281], [281, 317]], "summary_of_weaknesses": [[0, 109], [109, 194], [194, 310], [310, 394], [394, 460]], "comments,_suggestions_and_typos": [[0, 174], [174, 311], [311, 353]]}}}]