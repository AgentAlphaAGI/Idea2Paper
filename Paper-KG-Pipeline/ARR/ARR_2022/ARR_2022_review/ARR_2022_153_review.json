[{"rid": "53cd55251fe86d42f93515d1a3b5ad2c3e179f99bb18487fe36e55a858054f0e1a52c162bc04b87293c5dfe5506cb7d4d36ff741098330aa25110ba0154bd7b9", "reviewer": null, "report": {"paper_summary": "This paper studies the Machine Translation of the endangered language Livonian. The authors first collect a parallel corpus on LIV, LV, ET and EN, by assembling available digital resources and via manual translations. Then different \"base\" machine translations are trained and finetuned on the LIV->EN data. Backtranslations and pivot translation are also explored. ", "summary_of_strengths": "NMT for endangered languages is a critical and interesting research direction. The proposed parallel corpus is valuable and make great contributions to Livonian NMT. Interesting discoveries are made, e.g., the authors find that ET is a preferred pivot than LV in LIV-EN translation. ", "summary_of_weaknesses": "Some evaluations results are mixing. Please see the detailed comments below. ", "comments,_suggestions_and_typos": "Question: 1. In line 257, it's strange that including the collected LIV-EN parallel data for finetuning actually makes the NMT system perform worse. Could you provide more discussions/explanations on this?\n2. Could you provide some insight why the multilingual model is \"noticeably weaker\" (line 236) on the ET→En and LV→EN evaluations?\n3. It's interesting that the LV→EN model performs better than the ET→EN model, especially in section 2 authors mentioned that Livonian and Latvian languages are similar in many aspects.  minor: 1. Maybe the information that \"the translation is done by hired experts (section 3)\" can be added to the footnote 2 on page 2 (section 1)? I was a bit confused when first reading that footnote since I wasn't sure how the translation is done.\n2. Line 194, maybe I'm not familiar with the context, could you explain what does \"implement the support of ...\" mean?\n3. For future work, it may be worth considering adding cross-lingual contrastive learning to the training.\n4. Line 210, on what ET, EN, LV data is the Sentencepiece tokenizer obtained on? Those in the 4-language parallel corpus?\n5. Line 255: typo, \"perform performed\" "}, "scores": {"overall": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "5 = Enabling: The newly released datasets should affect other people's choice of research or development projects to undertake.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 80], [80, 218], [218, 308], [308, 366]], "summary_of_strengths": [[0, 79], [79, 166], [166, 283]], "summary_of_weaknesses": [[0, 37], [37, 77]], "comments,_suggestions_and_typos": [[0, 13], [13, 149], [149, 206], [206, 209], [209, 337], [337, 340], [340, 523], [523, 524], [524, 534], [534, 670], [670, 773], [773, 776], [776, 892], [892, 895], [895, 999], [999, 1002], [1002, 1080], [1080, 1121], [1121, 1124], [1124, 1160]]}}}, {"rid": "1adb4b5b651ccf357084a4617a07b992637c126242d143c4b1d6c96d30cf03440c6e8465ad89b4ff4ce48c8ab24fda774c8ff89dd35e8d8f1f292e5b3602eef6", "reviewer": null, "report": {"paper_summary": "This paper presents explores Livonian-English translation; Livonian is a very low-resource Uralic language with ~20 native speakers. \nThe work combines creation of a resource for Livonian (10k parallel sentences), which previously had only <100 parallel sentences available on OPUS, including a manually translated multi-way parallel evaluation set. \nThese resources are experimentally validated, and further, this work does a preliminary exploration of existing transfer techniques (fine-tuning, pivot translation, backtranslation) using monolingual and parallel resources to find which language(s) are best able to assist for transfer learning in this very low-resource setting where there are multiple languages which may be appropriate (contact languages (Latvian) vs typologically related (Estonian). \nThe resources are to be publicly released (already done anonymously on OPUS, will be further shared once able to be deanonymized). ", "summary_of_strengths": "- Collation of existing data into one resource and creation of a standardized multi-way evaluation set for Livonian will certainly assist further work on this language, and is appropriate for the ACL theme track - Experimentation on the resource provides a basis for comparison, and preliminarily looks into the contrast between contact languages and typological relatedness ", "summary_of_weaknesses": "- The experiments in the paper do not necessarily directly answer the research questions as posed in the introduction ", "comments,_suggestions_and_typos": "With an additional page, it would be nice to focus on some nice-to-have analysis to make it clearer what to take away from the experiments for those interested in this language pair, or others: *why* might there be a slight preference for pivoting through Estonian? Is this simply because the Estonian model performs slightly better than the Latvian before pivoting, and have nothing to do with the appropriateness of contact language vs typologically related language? Are there any reasons you can find for why finetuning is worse than pivoting? Are there any ways (besides downstream BLEU) to how use of a contact language or same language family affects the model?  - Table 2 layout is current a bit difficult to read; consider adding additional row and column headers saying source/target, pivot vs multilingual vs finetuning, to make it easier to match results to experiments - Would not call 8.92 a \"very respectable BLEU score\"; perhaps write that it is \"improved\" instead - The way the multilingual model's vocabulary is chosen (25k units taken from imbalanced multilingual sources, size-wise) is likely to hurt performance on Livonian-English; it might make more sense to check to see what vocabulary granularity is being used for Livonian (if all or mostly characters, for example, that suggests the multilingual vocab is not appropriate, and perhaps a set of smaller BPE vocabs for each language should be created and then joined after) "}, "scores": {"overall": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "3 = Potentially useful: Someone might find the new datasets useful for their work.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 133], [133, 350], [350, 806], [806, 938]], "summary_of_strengths": [[0, 212], [212, 375]], "summary_of_weaknesses": [[0, 118]], "comments,_suggestions_and_typos": [[0, 266], [266, 470], [470, 548], [548, 669], [669, 670], [670, 882], [882, 981], [981, 1449]]}}}]