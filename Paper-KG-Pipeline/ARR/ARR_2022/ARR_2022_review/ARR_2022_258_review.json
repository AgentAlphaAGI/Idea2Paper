[{"rid": "808d37cb33f4e1b30bef39e0130750325ed8a082fc65619495d3ddae9066f37f8d6c9c9efde77ba68e7e7bec813dede41d4d79b4e6572e083575b0f67e553bf6", "reviewer": null, "report": {"paper_summary": "The paper provides a corpus of editorial edits for Wikipedia articles, scientific articles and news. Computational models (RoBERTa, FELIX, Pegasus) are tested against the edit intention labels and the human revisions. ", "summary_of_strengths": "- defining an edit intention taxonomy and creating annotated data - testing the edit intention task with a baseline RoBERTa model - comparing human revisions and automated revisions based in 2 automated systems ", "summary_of_weaknesses": "- do not provide a new system improving over the RoBERTa baseline system for the edit intention task ", "comments,_suggestions_and_typos": "The paper provides a new data set for editorial edits with clear description on how the data set was assembled and how it can be used. \nSuggestions for improving the paper: - provide another SOTA approach for the edit-intention task going beyond the RoBERTa baseline - signal earlier that the automatic metrics do not correlate with the human metrics. The automatic evaluation configuration section is little bit hard to follow. Some of the explanations in the appendix could help to improve the readability of this section. I'm still not sure though, what Overall indicate in Table 7 - Is the FELIX system useful? First, it does not learn when the revisions are complete (having the system is Figure 2 is not very informative) and looking at the suggestions provided by the samples in the appendix, another concern may be raised. FELIX generates frequently hallucinations that potentially are contradictory to the initial text. ", "ethical_concerns": "none "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "5 = Enabling: The newly released datasets should affect other people's choice of research or development projects to undertake.", "software": "4 = Useful: I would recommend the new software to other researchers or developers for their ongoing work."}, "meta": {"license": "Copyright Â© 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 101], [101, 218]], "summary_of_strengths": [[0, 66], [66, 130], [130, 211]], "summary_of_weaknesses": [[0, 101]], "comments,_suggestions_and_typos": [[0, 135], [135, 173], [173, 267], [267, 352], [352, 429], [429, 525], [525, 585], [585, 615], [615, 831], [831, 929]], "ethical_concerns": [[0, 5]]}}}]