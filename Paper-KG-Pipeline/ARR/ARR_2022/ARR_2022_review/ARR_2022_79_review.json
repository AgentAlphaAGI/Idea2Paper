[{"rid": "15a2aa2b80b892f0c3b23a69f8f4adc0324606011eb99c3ccf7c5b3581b1d49b76343caeffd05090da8335f64be75c652b8aa6cf086f8f585cb6ba8f6e9bc956", "reviewer": null, "report": {"paper_summary": "This paper augments the standard cross-modal retrieval framework with an additional codebook. The motivation is that with the codebook, the model's behavior can be interpretable. The proposed approach improves the performance over the baseline approach by a margin. ", "summary_of_strengths": "1. I like the idea of using codebook for augmenting the cross-modal representation learning. Interpretabliity is one of the major issues in the cross-modal learning. I am glad that the author tackles this problem. \n2. The codebook update rules/policies are straightforward. It is interesting to observe that the codebook is aligned with actions in Fig. 3. ", "summary_of_weaknesses": "1. L003 mentioned the proposed framework is a self-supervised learning framework. IIUC, the model still needs cross-modal (x-modal) alignment to train. Why is the proposed framework a self-supervised learning framework? \n2. It is unclear to me how the gradient back-prop in the equation of L165? \n3. Cross-modal code matching: The key of the proposed approach is the x-modal code matching. It seems the codebook should be large enough to cover all semantic information in the dataset. I wonder how to determine the codebook space? Would the initalization of the codebook affect the performance? What is the performance under different codebook size? \n4. The proposed approach achieves higher performance than the baseline. I wonder is it due to the additional codebook or the increased model capacity? \n5. The interpretation part is a little bit confusing. Fig.3 clearly shows the codebook is aligned with the action. However, even with Fig. 3, it is still hard to interpret the output embedding of f^A_{code}. Imagine that given an embedding and a codebook, I wonder how to interpret the embedding? ", "comments,_suggestions_and_typos": "I think this paper is well-written and easy to follow. "}, "scores": {"overall": "3.5 ", "best_paper": "No", "replicability": "5 = They could easily reproduce the results.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright Â© 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 94], [94, 179], [179, 266]], "summary_of_strengths": [[0, 3], [3, 93], [93, 166], [166, 214], [214, 218], [218, 274], [274, 356]], "summary_of_weaknesses": [[0, 3], [3, 82], [82, 152], [152, 220], [220, 224], [224, 296], [296, 300], [300, 390], [390, 485], [485, 531], [531, 595], [595, 650], [650, 654], [654, 723], [723, 802], [802, 806], [806, 857], [857, 918], [918, 1100]], "comments,_suggestions_and_typos": [[0, 55]]}}}]