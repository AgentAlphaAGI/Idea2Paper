[{"rid": "46241641ba69ff159ac9a53c4a45e0e20a83d5e48e26e26f833d565f85952600976012821b66fd23a54ac9d06ad82dc154785c272a0b9888fa877a483eb41c91", "reviewer": null, "report": {"paper_summary": "The authors state that prior work encode passages for distantly supervised relation extraction exclusively one-by-one. They propose a simple BERT based architecture that processes several passages simultaneously and thus allows for inter-sentence information flow during encoding. They provide results that show that their method outperforms prior work. ", "summary_of_strengths": "1) The experimental execution of the paper is of high quality. Results are presented across four datasets and compared against several relevant/recent baselines. Further, meaningful ablation studies are presented.  2) The proposed architecture seems to work and yields performance improvements.  3) Overall the paper is well-written and easy to follow. The scope and contributions fit my expectation of a short paper. ", "summary_of_weaknesses": "1) I miss an analysis for which specific examples encoding multiple passages help. Adding an analysis where models that encode passages independently of each other fail compared to the proposed approach would be helpful. Similarly, this is a weak point in the motivation of the paper: it is not immediately clear to me why encoding passages simultaneously should be beneficial. You remain very vague here (e.g., line 046) and do not provide convincing arguments.  2) A central argument of the paper is that encoding passages simultaneously is helpful. Why do you restrict yourself to a maximum sequence length of 512 by using BERT? There is pretrained language models e.g., based on Longformer where you could encode more passages. Providing more insights how the number of passages influence performance (beyond what is mentioned in paragraph around line 243) would make the paper stronger. ", "comments,_suggestions_and_typos": "1) Why do you use uncased PLMs?  2) Potentially relevant but not cited work: Chu et al. 2021 (https://openreview.net/pdf?id=8smkJ2ekBRC), Wang et al. 2019 (https://aclanthology.org/P19-1132.pdf) 3) Please fix the bibliography and cite published versions rather than arxiv versions (e.g., Loshchilov et al. 2017). "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright Â© 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "4 = From an allowed pre-existing preprint or workshop paper, I know/can guess at least one author's name.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 119], [119, 281], [281, 354]], "summary_of_strengths": [[0, 63], [63, 162], [162, 214], [214, 215], [215, 295], [295, 296], [296, 353], [353, 418]], "summary_of_weaknesses": [[0, 83], [83, 221], [221, 378], [378, 463], [463, 464], [464, 552], [552, 632], [632, 732], [732, 892]], "comments,_suggestions_and_typos": [[0, 32], [32, 33], [33, 195], [195, 313]]}}}]