[{"rid": "e65ba8cf211a425932716cff11801f901803218f212805c16127d45aca0b00ae6cb8579cd0269d189b00f280248459bbfc3e1e3bf2e88f0ee51f2f3fc72a9ecb", "reviewer": "Kai Zhao", "report": {"paper_summary": "This paper presents a contrastive learning framework for unsupervised sentence representation learning. The proposed framework can alleviate the sampling bias in the random negative example sampling in contrastive learning. It achieves the debiased sampling by 1) adding per-example noise-based negatives and iteratively improving them by maximizing the non-uniform objective; 2) adding a similarity based filtering (based on a separate model) to remove false negatives. Empirical evaluations show the the proposed method outperforms competitive baselines on 7 semantic textual similarity tasks. ", "summary_of_strengths": "- The proposed method is intuitive and achieves good results comparing to existing methods.\n- The paper is well written and easy to follow.\n- The proposed method also achieves good performance in the few-shot setting, which makes it more useful in real practice. ", "summary_of_weaknesses": "One key motivation in the paper is to improve the quality of the sentence representations via improving uniformity. However, it is still a bit unclear to me if there is a strong correlation between uniformity and representation quality. Maybe we can perform some additional analyses to reveal this by varying negative proportion k? Note that Figure 6(b) seems to show that k does not have a high quality impact on some datasets. ", "comments,_suggestions_and_typos": "1. Figure 1: although it is very intuitive to use one random example to demonstrate the distribution of false negative examples, it would also be good to show the statistics over the whole dataset or a particular slice of the dataset. \n2. Line 414: it would be good to show the ratio of false negative examples that are filtered out. "}, "scores": {"overall": "3.5 ", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "3 = Potentially useful: Someone might find the new datasets useful for their work.", "software": "4 = Useful: I would recommend the new software to other researchers or developers for their ongoing work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Kai Zhao, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 104], [104, 224], [224, 471], [471, 596]], "summary_of_strengths": [[0, 92], [92, 140], [140, 263]], "summary_of_weaknesses": [[0, 116], [116, 237], [237, 332], [332, 429]], "comments,_suggestions_and_typos": [[0, 3], [3, 235], [235, 239], [239, 334]]}}}, {"rid": "40b2574906706ca5e25348b5c542af3de7b0872988b44f4a24091c9d1ddd37882820ec1d06a52d7cd7e386b38c13d0f23506d4cebe04b1199ba3484b538aa64f", "reviewer": "Gaurav Singh Tomar", "report": {"paper_summary": "**What is the task?**\nDebiased contrastive learning framework for unsupervised sentence representation learning **What has been done before?**\nPrevious works (contrastive learning based baselines) mostly utilize in-batch negatives to learn the uniformity, but the randomly negative sampling strategy may lead to sampling bias, such as false negatives and anisotropy representations. Different from these methods, the proposed framework adopts an in-stance weighting method for punishing false negatives and a gradient-based algorithm for generating noise-based negatives towards the most nonuniform points. In this way, the influence of false negatives can be alleviated and the model can better learn the uniformity. It finally reduces the sampling bias and improves the model performance.\n**What are the main contributions of the paper? How many of them are novel?**\n- First attempt to reduce the sampling bias in contrastive learning of unsupervised sentence representations.\n- Presented a new framework DCLR to alleviate the influence of sampling bias.\n- Experiments on 7 semantic textual similarity tasks show that our approach is more effective than competitive baselines on semantic textual similarity (STS) tasks using BERT and RoBERTa **What are the key techniques used to tackle this task?**\nThe core idea is to improve the random negative sampling strategy for alleviating the sampling bias problem.\n- A noise-based negatives generation strategy to reduce the bias caused by the anisotropy PLM-derived representations - initialize new negatives based on a Gaussian distribution and iteratively update these negatives by non-uniformity maximization.\n- An instance weighting method to reduce the bias caused by false negatives - similarity between original sentence and each negative **What are the main results? Are they significant?**\nExperiments on 7 semantic textual similarity tasks show that our approach is more effective than competitive baselines on semantic textual similarity (STS) tasks using BERT and RoBERTa ", "summary_of_strengths": "- First attempt to reduce the sampling bias in contrastive learning of unsupervised sentence representations.\n- Well-written and easy to read paper - Claims well-supported by ablation analysis and experimental results ", "summary_of_weaknesses": "See comments below ", "comments,_suggestions_and_typos": "- It is unclear which evaluation set(s) were used for Figure 3 - In section 6.1, it is unclear why and how negative sampling (DCLR) has to change. It seems DCLR is independent of the positive data augmentation strategy used.\n- Why was STS-B and SICK-R chosen for figure 4-6 and not STS-avg ?\n- How does DCLR compare with SimCSE on figure 5? "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "5 = They could easily reproduce the results.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Gaurav Singh Tomar, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 22], [22, 112], [112, 143], [143, 383], [383, 607], [607, 718], [718, 791], [791, 839], [839, 869], [869, 979], [979, 1057], [1057, 1244], [1244, 1302], [1302, 1411], [1411, 1660], [1660, 1793], [1793, 1822], [1822, 1846], [1846, 2031]], "summary_of_strengths": [[0, 110], [110, 148], [148, 218]], "summary_of_weaknesses": [[0, 19]], "comments,_suggestions_and_typos": [[0, 63], [63, 147], [147, 225], [225, 292], [292, 341]]}}}, {"rid": "0ca6429011fddc0e046ca085ea20f07cd2be767d704bd4e2c369b24f662449fdb1952acd1ebc9b2b4a6c6c50e09a2102d41e41541fcc78ea38ab262cfe66910c", "reviewer": null, "report": {"paper_summary": "The paper tries to address a new and important problem: sampling bias in contrastive learning that improper negatives (e.g. false negatives and anisotropy representation) will hurt the uniformity of the representation space. To tackle this problem, they propose DCLR framework to alleviate the influence sampling bias. Specifically, they employ 1) weighting method to punish false negatives 2) generate noise-based negatives to guarantee the uniformity of the representation space. They demonstrated the effectiveness of their method on 7 semantic textual similarity tasks. Overall, the paper is well-written and the results are encouraging. However, I am not fully convinced of the way that the authors use to identify false negatives. The authors can also do a better job at explaining why optimizing equation (3) and (4) can lead the noise-based negatives into more non-uniform semantic space. ", "summary_of_strengths": "The paper is overall well-written. The problem that the paper tries to address seems new and important. The authors  propose two methods to remediate the sampling bias issue which lead to encouraging results (main results Table 1) compared with previous approaches. ", "summary_of_weaknesses": "I am not fully convinced about the way the false negative samples are identified. In the paper, the authors proposed to use SimCSE as a complementary model and identify false negatives as negatives that have higher semantic similarity over a threshold using SimCSE representation, and punish those “false negatives” with a 0 weighting. I would argue that using similarity score alone could not identify false negatives. It only identify negatives that are very close to the original sentence semantically. In fact, those are “hard negatives” which has been shown in many contrastive works as essential in learning a high-quality representation. \nThe authors can also do a better job at explaining why starting with a Gaussian negatives and optimizing equation (3) and (4) can lead to negatives sampled from non-uniform semantic space. Any previous work or evidence to support that? ", "comments,_suggestions_and_typos": "1) In Figure 1, what is the corpus that the authors use to sample sentence pairs? \n\t\t2) In addition to STS tasks, the authors could also explore a number of downstream tasks as implemented in SentEval to evaluate the quality of sentence representations. \n\t\t3) It would be good to add statical analysis to the results in Table 1 to show significance. ", "ethical_concerns": "n/a "}, "scores": {"overall": "3.5 ", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 225], [225, 319], [319, 482], [482, 574], [574, 642], [642, 737], [737, 897]], "summary_of_strengths": [[0, 35], [35, 104], [104, 266]], "summary_of_weaknesses": [[0, 82], [82, 336], [336, 420], [420, 506], [506, 645], [645, 835], [835, 882]], "comments,_suggestions_and_typos": [[0, 82], [82, 254], [254, 350]], "ethical_concerns": [[0, 4]]}}}]