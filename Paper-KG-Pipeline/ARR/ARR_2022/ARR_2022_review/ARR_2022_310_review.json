[{"rid": "56b81ee528f4ce49d0c9de7120f8770ae0ff781efc6470c87f834ccc4c6b4f87316a09e85e77a15e71b1f749812aa965d1679b70b23bea5aad5431c3f02b6c28", "reviewer": null, "report": {"paper_summary": "The paper presents a text-infilling method for interactive machine translation. The idea enables human interaction in the form of lexical constraints while asking the NMT model to fill the remaining parts of the translation. ", "summary_of_strengths": "The paper is well written and easy to follow. \nThe experimental work is well defined and allows to correctly test the the presented method in different language pairs and data conditions. \nThe method proposed allows to fast and accurately reuse human constraints to boost post-edition performance. ", "summary_of_weaknesses": "A human evaluation of the \"gaps\" filled by the model would have been a plus for the paper. ", "comments,_suggestions_and_typos": "A better evaluation of the output produced by the proposed method would be beneficial for the reader. For instance focusing on: - How often invalid constraints are finally hypothesized by the model?\n- How grammatical are the \"filled gaps\" proposed by the model given that in principle the model does not modifies human constraints?\n- Which is the impact of using different ratios of raw/augmented sentences for training?\nTable 5 shows a performance boost of 0.68 BLEU when comparing #Raw and #Augmented. Where does the gain come from? Did you find the same (or similar) gains on the other language pairs?\nThe paper would benefit from a comparison to (or at least mentioning) related work on integrating lexical constraints: - Boosting Neural Machine Translation with Similar Translations. Jitao Xu, Josep Crego, Jean Senellart - Training Neural Machine Translation to Apply Terminology Constraints. Georgiana Dinu, Prashant Mathur, Marcello Federico, Yaser Al-Onaizan - Neural Machine Translation Decoding with Terminology Constraints. Eva Hasler, Adrià de Gispert, Gonzalo Iglesias, Bill Byrne - Levenshtein Transformer. Jiatao Gu, Changhan Wang, Jake Zhao Typos: 261: in the abve equation \"are\" used to guarantee that all "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 80], [80, 225]], "summary_of_strengths": [[0, 46], [46, 188], [188, 298]], "summary_of_weaknesses": [[0, 91]], "comments,_suggestions_and_typos": [[0, 102], [102, 128], [128, 199], [199, 332], [332, 421], [421, 504], [504, 535], [535, 605], [605, 724], [724, 789], [789, 827], [827, 899], [899, 968], [968, 1036], [1036, 1095], [1095, 1122], [1122, 1158], [1158, 1224]]}}}, {"rid": "ccd5950a83989b497920abeb7ffd406c461b2a6ee3f5271dfef096e36f5498929539d0ab29fe38c2c1810841cfa9db1de0f479539a2d99f7d7012e4889673e42", "reviewer": "Jinhua Du", "report": {"paper_summary": "This paper proposes BiTIIMT which is the Bilingual Text-infilling (BiTI) task, extending text-infilling from monolingual setting to bilingual setting and aiming to fill in missing segments in a revised translation for a given source sentence. The way to do that is simply to cast the bilingual text-infilling task as a sequence-to-sequence task and then employ the standard NMT model to perform this task. Experiments on WMT14 En-De, WMT14 En-Fr and Zh-En tasks show that the proposed model performs better than LCD in terms of translation quality and efficiency. ", "summary_of_strengths": "1. Proposes the bilingual text-infilling task and regard it as a seq-seq task; 2. Builds an improved IMT system based on the bilingual text-infilling task. ", "summary_of_weaknesses": "1. I didn't see obvious weakness of this paper. The method proposed is simple but effective. ", "comments,_suggestions_and_typos": "1 The paper is well written and easy to follow. \n2 In terms of the automatic evaluation, can authors use more metrics except BLUE to verify the results? \n3 Please do the significance test for all results. "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Jinhua Du, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 243], [243, 406], [406, 564]], "summary_of_strengths": [[0, 3], [3, 82], [82, 156]], "summary_of_weaknesses": [[0, 3], [3, 48], [48, 93]], "comments,_suggestions_and_typos": [[0, 48], [48, 153], [153, 205]]}}}, {"rid": "6e168e3515d5d2db9160c984c911780d69469fb193a879388c2c371182178f2cde272e0130f98ab0ed0996afd5484938b0bfd620a0ad5e5988e59fe539786640", "reviewer": "Prashant Mathur", "report": {"paper_summary": "This paper discusses methods to improve MT for Interactive machine translation but not in a standard sense. In IMT, usually MT predicts the next set of tokens given the prefix that has been post-edited by translators. In this paper, the authors tackle another modified use case where translators are first provided a full translation and then they are asked to post-edit portions of the translated text. Usually constrained decoding is used for such a task where model has to regenerate the beam according to the post-edited content.  Overall, I liked reading the paper because everything was stitched and motivated well throughout the paper. It does look like the paper was proof-read multiple times because I did not really find any grammatical errors. Having said that, I do think there's scope of improvement in the paper which I laid down in Weakness section. ", "summary_of_strengths": "The task of IMT is tough and authors did a good job at providing full context in the problem and how they tackle a modified IMT problem.  Latency is definitely a major component in adoption of this technology. I liked the way this paper outlined the metrics and provided motivation for it.  The approach is quite simple and very effective in terms of quality and latency. ", "summary_of_weaknesses": "Usage of data and experiment design: WMT data contain human generated references, any reason why post-edited content was not used in the paper for experiments? Post-edited content would have been much closer to what your task is and there's plenty of available data out there which is post-edited.   This task of sequence refinement has been studied well in  1. Relation to Neural Automatic Post editing models  2. Sequence Refinement part of Levenshtein Transformer (LevT) by Gu. et. al. 2019 is not discussed when it is almost the same thing although the use case is different (for Automatic Post Editing). \n3. Why was there no discussion on non-autoregressive models? Text infilling approach could indeed solved with a non-autoregressive model like LevT. What are the other methods of text infilling, why aren't those compared with your cross-lingual text-infilling approach?\nI am left with some other questions after reading the paper, I am writing them as weakness here but they are essentially points where this paper can improve.  L246: \"Then we combine the sampled data D and the trivial data D as the augmented data to train the model P in our experiments.\" what is the ratio of this combination, is it 1:1, if so are you not giving more weight text infilling problem than translation? An ablation study on this combination would have been good.  In the real-world scenario, given that the sample size is low (200), is 65.79 (BiTIIMT) significantly better than 64.05 (LCD)? Same question for edit distance cost? ", "comments,_suggestions_and_typos": "L273: \"In other words, we employ the standard beam search algorithm to yield Yb, which leads to a valid Y, without explicitly imposing the constraint during decoding\" Is this always the case in all languages? If not, can you mention the accuracy here? "}, "scores": {"overall": "3.5 ", "best_paper": "No", "replicability": "5 = They could easily reproduce the results.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Prashant Mathur, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "5 = Positive that my evaluation is correct. I read the paper very carefully and am familiar with related work.", "sentences": {"paper_summary": [[0, 108], [108, 218], [218, 404], [404, 534], [534, 535], [535, 643], [643, 755], [755, 865]], "summary_of_strengths": [[0, 137], [137, 138], [138, 210], [210, 290], [290, 291], [291, 372]], "summary_of_weaknesses": [[0, 160], [160, 298], [298, 300], [300, 362], [362, 415], [415, 481], [481, 485], [485, 609], [609, 613], [613, 671], [671, 758], [758, 879], [879, 1037], [1037, 1038], [1038, 1167], [1167, 1295], [1295, 1355], [1355, 1356], [1356, 1483], [1483, 1521]], "comments,_suggestions_and_typos": [[0, 209], [209, 252]]}}}]