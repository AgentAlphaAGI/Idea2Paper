[{"rid": "dffe09af858bbf08374d26428c32780199b342d12bd79643ef0d9171b39e2b29629a0e7200e1978d0ddebea3f6ec739fbab251559472c7da1535211a12853bef", "reviewer": "Rishabh K Iyer", "report": {"paper_summary": "The paper evaluates the effectiveness of GROUP robust algorithms in the multi-label classification scenario under temporal concept drift. Empirical analysis of the paper highlights how some group robust approaches like Spectral Decoupling, IRM are more suitable for tackling temporal concept drift and label imbalance in the multi-classification setting. ", "summary_of_strengths": "1. It is one of the initial works that analyzed the group robust algorithms' performance in the context of multi-label classification.\n2. The authors provided detailed remarks on why some group robust algorithms are more suitable for tackling the temporal drift in the context of multi-label classification. Furthermore, they pointed out some critical drawbacks of recent approaches like GROUP-DRO when applied naively.\n3. The work shows that some GROUP robust approaches like IRM can efficiently tackle the problem of temporal concept drift as well as the more computationally expensive label-attention-based approaches(WLAN). ", "summary_of_weaknesses": "1. Being an empirical evaluation paper, I am not sure whether the numbers reported are after a single run or multiple runs. If only a single run is considered, it is highly advised for the authors to report numbers along with standard deviations after multiple runs.\n2. Similarly, it is also unclear whether the hyperparameters for each GROUP-Robust algorithm are adequately tuned.\n3. The authors highlighted the problems of existing approaches like GROUP-DRO when naively applied to the multi-label classification scenario. However, It is not very helpful to compare with such naive adaptions, in my opinion. For example, one can intelligently adapt the GROUP-DRO algorithm to multi-label classification by considering multiple weights(one for each label) for each group instead of a single weight and adapting the weights based on the corresponding label binary cross-entropy loss. By assigning multiple weights, we can still assign higher weightage to minority classes rather than considering the average losses in the group.\n4. It would be valuable to the paper if authors discuss possible intelligent adaptations of existing group-robust algorithms to multi-label classification scenarios rather than just stating the problems of naive adaptations. ", "comments,_suggestions_and_typos": "See above "}, "scores": {"overall": "2 = Borderline: This paper has some merit, but also significant flaws. It does not warrant publication at top-tier venues, but might still be a good pick for workshops.", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "4 = Useful: I would recommend the new datasets to other researchers or developers for their ongoing work.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright Â© 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Rishabh K Iyer, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 138], [138, 355]], "summary_of_strengths": [[0, 3], [3, 135], [135, 138], [138, 308], [308, 420], [420, 423], [423, 628]], "summary_of_weaknesses": [[0, 3], [3, 124], [124, 267], [267, 270], [270, 382], [382, 385], [385, 525], [525, 610], [610, 884], [884, 1029], [1029, 1032], [1032, 1254]], "comments,_suggestions_and_typos": [[0, 10]]}}}]