[{"rid": "e6e25a2a9abcaacf07a6a7f69f27a7ab043412e7eab118b57f1938466438ed6641e73511e2f191c83e3f2a84e82fdce4d6e38c78f2c7361df3bc93f318ace94e", "reviewer": null, "report": {"paper_summary": "In this paper authors provided a statistical definition of phonemes, proposed a neural network based approach (information quantizer (IQ)) to improve semantic-driven phoneme discovery (SPD), and showed its theoretical guarantee. ", "summary_of_strengths": "This paper proposed a new model architecture to improve SPD, with its theoretical guarantee. Overall, this paper is well structured and written, with carefully designed experiments and analysis to show its effectiveness. ", "summary_of_weaknesses": "I think a few more details are needed to clarify experimental design/results (see details in the section below). ", "comments,_suggestions_and_typos": "1. What's the size/computation of proposed IQ, compared to baselines? Does model size/computation play a role in the performance difference shown in Tables 1, 3, 5? \n2. In Table (5b), there is a big improvement of PER for IQ. How strong are baselines for this case? \n3. There are a couple of cases that it's written as \"Figure\", but meant for \"Table\", e.g. \"Figure 3\", \"Figure 5\". "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "2 =  Willing to defend my evaluation, but it is fairly likely that I missed some details, didn't understand some central points, or can't be sure about the novelty of the work.", "sentences": {"paper_summary": [[0, 229]], "summary_of_strengths": [[0, 93], [93, 221]], "summary_of_weaknesses": [[0, 113]], "comments,_suggestions_and_typos": [[0, 3], [3, 70], [70, 165], [165, 169], [169, 226], [226, 266], [266, 270], [270, 381]]}}}, {"rid": "e99578a96cc2387fe3f9e707347043342f6257c9f841db87cb44b3a4fd772bd6774a876220bcf4795cab39b46a39d90cbc39f0199a4aa0624b7c1146c0b4ea7d", "reviewer": null, "report": {"paper_summary": "This paper focuses on the task of phoneme discovery. It proposes a statistical definition of phonemes (through their conditional distributions over word labels) and introduces a novel neural network, information quantizer, which makes use of this statistics to create a phoneme inventory from a set of words. The proposed model is reported to outperform the existing state-of-the-art speech recognition models. ", "summary_of_strengths": "The paper is well-written, the approach (specifically, defining phonemes as distributions over word labels) is rather elegant, the numerical results seem to be rather strong. ", "summary_of_weaknesses": "The amount of material (in particular, mathematical proofs) presented goes beoynd an 8-page *ACL paper, in my opinion.\nThe method is defined as \"semanti-driven\", but I think this is very misleading: the approach doesn't directly deal with semantics, but rather with word labels. If the approach was truly semantic, the model wouldn't be able to distinguish between complete synonyms.\nI do not have enough expertise to evaluate the novelty of the actual model presented. ", "comments,_suggestions_and_typos": "- Line 100: why is this a class of neural networks, and not a neural network?\n- The conclusion is extremely short, the paper could benefit from some discussion.\n- Line 476: typo, compare our models _to_ - Line 510: Figure 8 is mentioned, but the text doesn't say this is actually in the Appendix.\n- Table 3 is labelled as Figure 3. As a result, Figure 4 should be Figure 3, etc.\n- Line 431: I couldn't understand which n-grams were excluded: unigrams, bigrams, but also bigrams+trigrams? What exactly is the latter type? "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "2 =  Willing to defend my evaluation, but it is fairly likely that I missed some details, didn't understand some central points, or can't be sure about the novelty of the work.", "sentences": {"paper_summary": [[0, 53], [53, 309], [309, 411]], "summary_of_strengths": [[0, 175]], "summary_of_weaknesses": [[0, 119], [119, 279], [279, 384], [384, 470]], "comments,_suggestions_and_typos": [[0, 78], [78, 161], [161, 203], [203, 297], [297, 332], [332, 379], [379, 488], [488, 521]]}}}, {"rid": "e6fb8eb3fe2e412d84393eb755c161bfc982a11254d227cb9fab68eaa59875a156d9853356a041b0c10acf630c4f14872b3e15d3e312659e952f7fe824f4aa0a", "reviewer": null, "report": {"paper_summary": "The paper provides a statistical definition of phonemes that is almost equivalent to the linguistic definition of phonemes and proposes a NN-based method to learn a phoneme model based on the definition. More precisely speaking, the paper defines a phoneme set as a minimum set of speech segment grouping such that a replacement of phonemes results in a change in the distributions of semantic words. The mapping from speech segments to word distributions is realized by a neural network and quantization. ", "summary_of_strengths": "Significant advantages of the proposed method over several existing methods are shown in some experimental results. The theoretical validity of the proposed method is argued in detail with a lot of detailed information in the appendices. ", "summary_of_weaknesses": "Please take a look at some questions on the equations and confusing phonemes below. ", "comments,_suggestions_and_typos": "\\mathbb{Q}_K is defined at L894 as a class of functions, while Q_K is the K-th code distribution in the codebook. \\mathbb{Q}_K^NN is defined at L899. \\mathbb{Q}_K^NN must be a subclass of \\mathbb{Q}_K, because the definition of \\mathbb{Q}_K does not have any requirement on the functions q. (Question 1) Should \\hat{\\theta} and \\hat{q} of the left hand of Eq. (14) at L14 be \\hat{\\theta}_n and \\hat{q}_n? Should L905 be corrected accordingly?\n(Question 2) In L908, Q_K and Q_K^NN are mentioned. But, I suppose they should be \\mathbb{Q}_K and \\mathbb{Q}_K^NN instead. Should L910 be corrected accordingly?\n(Question 3) What is q_k in L911? I suppose it should be Q_k instead. But, even in that case, I could not follow the transformation from L910 to L911. Please clarify the transformation.\nI also have questions about confusing phonemes.  (Question 4)  What is the precise definition of “error probability” of (10a)? While the confusion between nasals /n/ and /m/ is mentioned in the main part of the paper, there seem other pairs with even higher error probabilities. Among them, the pair of /ch/ and /ah/ looks very different from each other. Why do they have such high error probabilities? "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "Maybe", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "2 =  Willing to defend my evaluation, but it is fairly likely that I missed some details, didn't understand some central points, or can't be sure about the novelty of the work.", "sentences": {"paper_summary": [[0, 204], [204, 401], [401, 506]], "summary_of_strengths": [[0, 116], [116, 238]], "summary_of_weaknesses": [[0, 84]], "comments,_suggestions_and_typos": [[0, 114], [114, 150], [150, 291], [291, 405], [405, 443], [443, 495], [495, 567], [567, 605], [605, 639], [639, 675], [675, 756], [756, 791], [791, 839], [839, 840], [840, 918], [918, 1070], [1070, 1146], [1146, 1194]]}}}, {"rid": "835a195db0c1be689413be83d94648e0e74bef41fd6a67a0009ad52dbdf91ec70629e32fe8aa0b5d350427de2d9951b3164e217fc3f379264602ec7f9a55c196", "reviewer": null, "report": {"paper_summary": "This paper presents a self-supervised framework for phoneme discovery for zero resource speech recognition. The authors present a rigorous, well thought-out algorithm. They present results on various datasets with both ground truth segmentation and a segmenter model, presenting the efficacy of their approach. ", "summary_of_strengths": "1) I enjoyed the formalism in the paper. It helps understand the reasoning behind their model. \n2) The improvements over the previous approaches are considerable with interesting analysis.  Overall good paper, I hope the authors can factor in my suggestions in their future version of the paper. ", "summary_of_weaknesses": "1) If I understand correctly there is a need to know the word and phoneme segment boundaries for this task. This is a pretty strong assumption and can be unreliable for many languages. The experimentation done by the authors use both ground truth and provided segmentation which I think is good to show that the technique works even with a segmental model. But the authors should rephrase term \"mild assumption\". \n2) Details about the model training and dataset is missing. Which will make this work accessible to a smaller set of research community. It would be great if the authors can provide code or additional details about the model. ", "comments,_suggestions_and_typos": "1) Regarding the related works -- \"there is a long line of work that use supervised, multilingual systems\" -- it would be good to acknowledge some of the older works too. \n2) Following up on that, there are works that recognize articulatory features, or directly predict phones -- mentioning some of those works would also be useful. \n3) For the results in 5b, it would be good to add some models from the above work for comparison. As different communities would be interested in different aspects of this paper. \n4) There is a recent work on unsupervised speech recognition at Neurips 2021 (https://arxiv.org/pdf/2105.11084.pdf) which does something similar but without the need for segmental acoustic models. It would be good to make a contrast or have a discussion about that for the readers to have a better understanding. "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "2 = They would be hard pressed to reproduce the results: The contribution depends on data that are simply not available outside the author's institution or consortium and/or not enough details are provided.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 108], [108, 168], [168, 311]], "summary_of_strengths": [[0, 41], [41, 95], [95, 189], [189, 190], [190, 296]], "summary_of_weaknesses": [[0, 108], [108, 185], [185, 357], [357, 413], [413, 474], [474, 551], [551, 640]], "comments,_suggestions_and_typos": [[0, 171], [171, 334], [334, 433], [433, 514], [514, 712], [712, 828]]}}}]