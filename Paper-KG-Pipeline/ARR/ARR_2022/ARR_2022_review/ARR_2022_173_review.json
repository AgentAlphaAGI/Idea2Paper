[{"rid": "b42189de64f60f690578849b96545b2508608f83cd3a43936a83658f777f600d3364f14fa3b797ec18792c0aba21e26e692f6da702953aa43663ceb7e30bc952", "reviewer": null, "report": {"paper_summary": "This paper presents a technique for adapting the learning process based on CBMI (Conditional Bilingual Mutual Information), which is defined to be the ratio of the translation probability over the language model probability for each token.  The motivation of this method is that neural models tend to already excel at producing fluent text, but sometimes fail to produce accurate translations.  Experimentally, the approach shows a small but measurable difference (according to BLEU) over the baseline with no adaptive training, and performs similarly (perhaps better) than other similar methods.  One of the models is also compared via human evaluation to the baseline, scoring with adequacy and fluency, and the technique increases adequacy more than fluency (though both are already high). ", "summary_of_strengths": "- Reasonable motivation for the technique from a theoretical view - Technique is practical, involves training a small LM model during training but no test-time overhead.\n- Many similar techniques are reviewed, briefly explained, and compared ", "summary_of_weaknesses": "- Some important details are omitted, e.g., pNMT is \"the probability output by the NMT model\" and pLM \"the probability output by an additional target-side language model\" without any real implementation details.  Are these computed using the full transformer models (embedding, encoder, decoder, softmax)?  Is the BPE vocabulary of the LM fixed to the same vocab as the NMT model?  Is the NMT model used in CMBI the one being trained, or the fixed one after 100k steps?  Learning rates and decay are also not discussed.  I have a good idea of the answer to some of these questions, but the details could be important.\n- Is the baseline transformer model only trained for 100k steps?  If so, how do we know that training for another 100-200k steps alone might not account for the score improvement.\n- Some explanations of techniques are too brief, e.g., Focal and Anti-focal loss are described exactly the same (same formula and even hyperparameters) yet give different results, Self-paced learning receives a too-brief single sentence description.  Also, section 5.4 and appendix C are not detailed enough to understand the experiment. ", "comments,_suggestions_and_typos": "- I'd like to see some discussion/visualization of learning curves, since the kind of differences in scores reported can be due to converged vs. non-converged models - Are the Self-paced learning results all from another paper?  In Table 1 only the base results are flagged as such, but in table 6, it looks like both results are.\n- Using p(x|y_<j) -- the source probability conditioned on the target prefix -- seems a strange choice.  I would think the unconditional source probability would be better.  Yet, based on Eq 7, the source probability factor is cancelled out anyway, so it doesn't really matter.\n- Eq 15 and 16 seem identical, but they are called \"focal loss\" and \"anti-focal loss\".  Shouldn't they be opposite?  Otherwise how are they different in practice… even the hyperparams from the appendix are largely the same.  Please highlight the difference in the description in Section 4.4.\n- Typo: +0.55 -> 0.54 BLEU (line 473) - Section 5.4 - What is really happening here?  How are these priors calculated and used in training?  Is this related to equation 18 (from Appendix C)?  Also, the LM prior seems to give equivalent results to the \"prior selection\" and even to the full CBMI adaptive training method, why is this LM prior not compared to the LM prior in table 1?\n- Are the CMBI values used in figure 4 and prior selection the non-normalized values - Appendix C:  hard to understand how Figure 5 is produced, since CBMI values are calculated per token, not per sentence.  Also how is equation 18 used? \nFigure 4 shows the LM prior dominating < 0, the TM prior dominating > 8, and CMBI prior dominating between them.  Why dos the \"prior selection\" method then have the TM prior between 0 and 6, and the CMBI prior above 6?  This doesn't match figure 4 (at least as labeled). "}, "scores": {"overall": "3.5 ", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "1 = No usable datasets submitted.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 240], [240, 394], [394, 597], [597, 793]], "summary_of_strengths": [[0, 66], [66, 170], [170, 242]], "summary_of_weaknesses": [[0, 212], [212, 306], [306, 381], [381, 470], [470, 520], [520, 618], [618, 683], [683, 798], [798, 1048], [1048, 1136]], "comments,_suggestions_and_typos": [[0, 166], [166, 228], [228, 331], [331, 435], [435, 504], [504, 609], [609, 696], [696, 725], [725, 833], [833, 901], [901, 939], [939, 986], [986, 1041], [1041, 1092], [1092, 1284], [1284, 1369], [1369, 1491], [1491, 1522], [1522, 1636], [1636, 1742], [1742, 1794]]}}}, {"rid": "af37dc37dc2ac7787e56d29aff57ae37121220fd8223de86a710d9cbb5115a82019f8f0add5f5fe910c8d24b027b1959488ff86591e6799075f7f16066b66f07", "reviewer": null, "report": {"paper_summary": "The paper defines a CBMI metric over the NMT source and a target word (given the target history) and then uses it to re-weight the NMT training loss. The definition is simplified to the quotient of NMT probability and the LM probability. Experiments shows that the training strategy improves the translation quality, over two training datasets, outperforming previous works. The paper further shows the method also improves the human evaluation. ", "summary_of_strengths": "- The proposed method appears to be simple, but works; - Paper appears to be well written; - Experiments comparison and analysis, human evaluation; Overall, paper did a good job in presenting and examining the effectiveness of a simple idea. ", "summary_of_weaknesses": "I think the paper (and related works) presented the works in a way that they presented a hypothesis (eg, importance of token reweighing), then conduct experiments and analysis showing the effectiveness of the method, then saying re-weighing the token importance works. After finishing reading, I felt the need to go back go re-examine the hypothesis to understand more and realized that I still don't understand the problem in a machine learning sense. The authors are encouraged to (at least) post some \"aha\" examples showing re-weighting this way indeed is the one that matters. Also, discussing and revealing the reason why NMT still needs this re-weighting even though the NMT model can in principle implicitly capture them would be really helpful. ", "comments,_suggestions_and_typos": "Please see the weakness section. "}, "scores": {"overall": "3.5 ", "best_paper": "No", "replicability": "5 = They could easily reproduce the results.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 150], [150, 238], [238, 375], [375, 446]], "summary_of_strengths": [[0, 55], [55, 91], [91, 148], [148, 242]], "summary_of_weaknesses": [[0, 269], [269, 453], [453, 581], [581, 753]], "comments,_suggestions_and_typos": [[0, 33]]}}}]