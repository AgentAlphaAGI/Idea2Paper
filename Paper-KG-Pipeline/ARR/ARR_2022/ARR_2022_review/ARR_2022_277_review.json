[{"rid": "9ad4820efd7df551e2b50da8cc6589903864c89856f5e25577f822299f6b1bb7541f4466b357bf08d97de3f9aba38fd16cbefd9eb2f797d30b1984643b4e6d3b", "reviewer": "Yi-Ling Chung", "report": {"paper_summary": "This paper discusses hype and overclaiming phenomena in NLP research. It first identifies four types of underclaiming in existing work when reporting and citing experiment results and models’ capabilities and limitations. It then describes how underclaiming can affect making progress. It further summarises the major concerns regarding advanced AI. It then follows a few suggestions on how to mitigate such issue, including making clear reports, and adopting better evaluation practices, analysis and forecasting. ", "summary_of_strengths": "This paper addresses an important issue that hasn't been broadly discussed in NLP research community. As it points out, researchers should try to adopt appropriate evaluation and analysis, and make credible conclusion about the limitations and capabilities of systems used. In addition, hype can potentially impact early researchers' understanding of progress in NLP.  I think this is a good opinionated paper, especially at nowadays where it is almost impossible to track all relevant paper on arxiv. The paper is sound and convincing. A good practice is also provided to mitigate underclaiming in writing and citations for future studies. ", "summary_of_weaknesses": "I find it difficult connecting section 5 to the issues of hype and overclaiming in general. Are they about the long-term effects of overclaiming or hype? In my opinion, it is more related to AI risk research and potential risks of misuse of AI. It would be better to add one or two sentences to explain how they are connected to overclaiming. ", "comments,_suggestions_and_typos": "An additional practice to avoid underclaiming is to define clearly, before conducting experiments, the desired behaviours of a model in order to properly evaluate if the model \"succeeds\" or \"fails\".\nNote: This paper is an opinionated paper and the replicability score does not applied, although literature used to draw the conclusion is provided. "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Yi-Ling Chung, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "2 = From social media/a talk/other informal communication, I know/can guess at least one author's name.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 70], [70, 222], [222, 286], [286, 350], [350, 515]], "summary_of_strengths": [[0, 102], [102, 274], [274, 368], [368, 369], [369, 502], [502, 537], [537, 641]], "summary_of_weaknesses": [[0, 92], [92, 154], [154, 245], [245, 343]], "comments,_suggestions_and_typos": [[0, 199], [199, 347]]}}}]