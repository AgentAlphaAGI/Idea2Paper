[{"rid": "71e7b95a72af9ac8519665285f1c20f8f8864dc212f5477ffd96c88ab2a42ae84a3e1a5eb93606189083f3c1271d360fde8eb2d0c0d81ef42c2692f8be1d897c", "reviewer": "Hongfei Jiang", "report": {"paper_summary": "The paper proposed an expert-guided heuristic linguistic adversarial augmentation that simulates the overlapping or ambiguous categories or label shift where a word or phrase can have different entity labels in different scenarios. They also proposed a challenging dataset consisting of 1000 high-quality examples to facilitate benchmarking the out-of-distribution performance of NER models.  With limited expert-guided adversarial augmented training data, the NER model’s performance was boosted on their challenge set and out-of-domain set. ", "summary_of_strengths": "They proposed a novel and valuable adversarial augmentation method that simulates the common problem of NER models facing real cases. The augmentation method boosted the performance of models on the challenge and out-of-domain sets. They empirically showed that mixing the original and guided-adversarial examples can further enhance the generalization ability of NER models consistently. ", "summary_of_weaknesses": "There are two main concerns from me . The first one is that how to generate the adversarial training set with code is not clearly discussed and  the detail of adversarial training set is not be provided. The second concern is that the reason of excluding 25% of the word phrases said in the last paragraph in 4.1 and the reason of using first 50 examples from the OntoNotes test set is not be fully discussed. ", "comments,_suggestions_and_typos": "1.  For the Appendix H section, it should be reorganized which is difficult to follow. "}, "scores": {"overall": "3.5 ", "best_paper": "No", "replicability": "2 = They would be hard pressed to reproduce the results: The contribution depends on data that are simply not available outside the author's institution or consortium and/or not enough details are provided.", "datasets": "3 = Potentially useful: Someone might find the new datasets useful for their work.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Hongfei Jiang, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 232], [232, 392], [392, 543]], "summary_of_strengths": [[0, 134], [134, 233], [233, 389]], "summary_of_weaknesses": [[0, 38], [38, 204], [204, 410]], "comments,_suggestions_and_typos": [[0, 3], [3, 87]]}}}, {"rid": "1365ba3bb748b18815796bad556f899c1a7e1567ae3e07b77e9af55445092d8fc8f017e2e5778862b669444a2c81b06f47fc112291df163f3ed90d6ba576a484", "reviewer": null, "report": {"paper_summary": "This paper introduces an expert-guided adversarial dataset for the NER problem. The paper discusses how to (manually) build such dataset in order to use it to augment the training of NER models, to make them more robust to out-of-domain shifts. \nThe paper proposes a strategy based on some transition rules to create the expert-guided dataset. The experimental results seems to confirm the utility of such dataset when testing against a Challenge Set and a Out Of Domain dataset. ", "summary_of_strengths": "- Interesting problem for the ACL community ", "summary_of_weaknesses": "- it is not clear what's the goal of the paper. Is the release of a challenging dataset or proposing an analysis of augmenting models with expert guided adversarial examples. If it is the first, ok, but the paper misses a lot of important information, and data analysis to give a sense of the quality and usefulness of such a dataset. If it is the second, it is not clear what's the novelty.\n- In general, it seems the authors want to propose a way of create a challenging set. However, what they describe seems very specific and not scalable.\n- The paper structure and writing is not sufficient ", "comments,_suggestions_and_typos": "My main concern is that it's not clear what's the goal of the paper. Also, the structure and writing should greatly improve. I believe also that the choice to go for a short paper was penalizing the authors, as it seems clear that they cut out some information that could've been useful to better understand the paper (also given the 5 pages appendix).\nDetailed comments/questions: - Line 107 data, -> data.\n- Line 161-162: this sentence is not clear.\n- Table 1: are these all the rules you defined? How the rule is applied? When you decide to make small changes to the context? For example, when you decide to add \"and her team\" as in the last example of Table 1?  - Also, it seems that all the rules change a one-token entity to a multi-token one or vice-versa. Will models be biased by this?\n- Line 183-197: not clear what you're doing here. Details cannot be in appendix.\n- What is not clear also to me is how is used the Challenge Set. If I understood correctly, the CS is created by the linguistic experts and it's used for evaluation purposes. Is this used also to augment the training material? If yes, what is the data split you used?  - Line 246-249: this sentence lacks the conclusion - Line 249: What are eligible and not eligible examples?\n- Line 251: what is p?\n- Line 253: The formula doesn't depend on p, so why the premise is \"if p=100% of the eligible example\"?\n- Line 252: Not clear what is the subject of this sentence. "}, "scores": {"overall": "2 = Borderline: This paper has some merit, but also significant flaws. It does not warrant publication at top-tier venues, but might still be a good pick for workshops.", "best_paper": "No", "replicability": "5 = They could easily reproduce the results.", "datasets": "3 = Potentially useful: Someone might find the new datasets useful for their work.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "5 = Positive that my evaluation is correct. I read the paper very carefully and am familiar with related work.", "sentences": {"paper_summary": [[0, 80], [80, 245], [245, 344], [344, 480]], "summary_of_strengths": [[0, 44]], "summary_of_weaknesses": [[0, 48], [48, 175], [175, 335], [335, 392], [392, 478], [478, 544], [544, 596]], "comments,_suggestions_and_typos": [[0, 69], [69, 125], [125, 353], [353, 382], [382, 408], [408, 452], [452, 500], [500, 525], [525, 579], [579, 665], [665, 666], [666, 764], [764, 795], [795, 845], [845, 876], [876, 941], [941, 1051], [1051, 1103], [1103, 1144], [1144, 1145], [1145, 1196], [1196, 1253], [1253, 1276], [1276, 1380], [1380, 1440]]}}}]