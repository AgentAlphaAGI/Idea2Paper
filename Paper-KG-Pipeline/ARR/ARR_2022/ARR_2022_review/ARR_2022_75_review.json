[{"rid": "4b5984ea2b596f3cf840a16829277eba0089e9ab0cda36be067694e55e48f2504675d5d05ab97006165e050c9683f0d3bb74a87bfb4c6041dfa7e9ebaff83e39", "reviewer": "Kaushal Kumar Maurya", "report": {"paper_summary": "The paper proposed a semantic and syntactic disentanglement approach based on Siamese Semantic Distangelement Model ($S^2DM$). This semantic dissociation from syntax is learned in representation obtained from the pre-trained models (mBERT and XLM-100). This decoupling model reduces the ‘violation of syntactic constraint’ and advances the answer-span boundary detection performance (for Question Answering (QA) tasks) in zero-shot cross-lingual transfer for low-resource languages. The proposed approach uses two-step training (with labeled parallel and task-specific datasets) and six linguistically inspired training losses in two combinations (models).  The Experiments are conducted on one task (QA), three datasets (MLQA, XQuAD, TyDiQA), and across nine languages. Extensive experiments and an ablation study are conducted to support the paper's claim. ", "summary_of_strengths": "1. The paper is well written and easy to follow. \n2. The proposed work is linguistically inspired and intuitive. The work or its variants (unsupervised version) may be extended to other cross-lingual/multilingual applications. \n3. The proposed approach's strength is mathematical analysis in section 3.3 and empirical analysis. The systematic study has been conducted and whenever required, the suitable argument and experiment are conducted, respectively. \n4. The paper's visual presentations (Figure-3, Figure-5, and Figure-6) are informative and thoughtful. ", "summary_of_weaknesses": "1. One problem I can notice is the scalability issue of the proposed method.  As mentioned in section 4.3, step-01 of training required labeled parallel sentences, limiting the proposed approaches to the few high-resource languages. \n2. The proposed model lacks a comparison with baseline(s) from the literature. For example, a baseline that uses external knowledge like LAKM (Yuan et al. 046 (2020); line-46) or Liang et al. (2021; line-50) can be taken. It is not necessarily the proposed model that should outperform these baselines but to get an idea of where this approach stands compared to previous work. Other possibilities to use the more popular pre-trained model like XLM-R or mT5 (encoder only). \n3. Many of the reported scores (particularly for mBERT) in Table-2,3 & 4 are close to baseline; the statistical significance test is recommended for reliability ", "comments,_suggestions_and_typos": "1. It is hard to read numbers in Figure-3 and Figure-5 with a printed copy. \n2. In Line 492, the referred table number is incorrect. \n3. Author(s) can plan to investigate the unsupervised approach as a future extension of this work which will be more promising. "}, "scores": {"overall": "3.5 ", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "5 = Enabling: The newly released datasets should affect other people's choice of research or development projects to undertake.", "software": "5 = Enabling: The newly released software should affect other people's choice of research or development projects to undertake."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Kaushal Kumar Maurya, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 127], [127, 253], [253, 483], [483, 657], [657, 658], [658, 771], [771, 859]], "summary_of_strengths": [[0, 3], [3, 49], [49, 53], [53, 113], [113, 227], [227, 231], [231, 328], [328, 457], [457, 461], [461, 561]], "summary_of_weaknesses": [[0, 3], [3, 77], [77, 233], [233, 237], [237, 313], [313, 456], [456, 612], [612, 708], [708, 712], [712, 870]], "comments,_suggestions_and_typos": [[0, 3], [3, 76], [76, 80], [80, 133], [133, 137], [137, 262]]}}}, {"rid": "a10d35763dca42f9e79c8e0caa0c46187df3879026bdd9c437fa21cb43f4713e871f77a5508c7aefe0c3ef70f3c71cddc20c64e692664edfc6ade6954ee36188", "reviewer": "Thang Vu", "report": {"paper_summary": "This paper proposes methods to enforce models to first disentangle semantic from syntax information in pre-trained models and then transfer only semantic information across languages in machine reading comprehension tasks. The authors evaluated their proposed framework on several data sets and showed very promising results. ", "summary_of_strengths": "- This paper proposes a novel and interesting idea.  - The observation and motivation from this paper could be potentially applicable to other tasks as well.  - The authors showed consistent improvement over strong baselines in several datasets.\n- The authors provide interesting qualitative analyses that give insights about the reasons why their proposed method is helpful. ", "summary_of_weaknesses": "- The authors do not promise to release their code. ", "comments,_suggestions_and_typos": "- I would like to see more in-depth analyses about the improvement, e.g. where the improvement really comes from. Does it come from data points where syntactic constraints are violated? "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Thang Vu, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 223], [223, 326]], "summary_of_strengths": [[0, 52], [52, 53], [53, 158], [158, 159], [159, 246], [246, 376]], "summary_of_weaknesses": [[0, 52]], "comments,_suggestions_and_typos": [[0, 114], [114, 186]]}}}]