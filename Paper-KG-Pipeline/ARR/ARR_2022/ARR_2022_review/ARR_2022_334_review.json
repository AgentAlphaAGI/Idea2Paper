[{"rid": "8924b9654bc4f5eec8c25568958a90d32e4d51939f66e0a0de80d2e370d7104354e52b991163b557e706f4828672df637f77e62c0bade99fbde8c4a1f0357b3b", "reviewer": null, "report": {"paper_summary": "This paper describes a methodology for collecting parallel data for the task of detoxification. This is the task of taking an offensive sentence and paraphrasing it into a so-called “neutral sentence”. The methodology is introduced by example, and by doing so creates two parallel-data datasets for detoxification. These are according to the authors the first of their kind. Along with the description of the methodology is a breakdown of the monetary costs of conducting such a resource project, which sums to a cost of 811.55$ for ~20.000 toxic → neural paraphrase samples - of these, 12.000 are unique toxic sentences. The authors train several SOTA systems on their parallel dataset and show significant improvements over unsupervised systems, emphasizing the benefits of focusing efforts on creating parallel data, as opposed utilizing non-parallel data. ", "summary_of_strengths": "1. Useful parallel dataset for the detoxification community which has no parallel datasets. \n2. Simple and reproducible methodology/pipeline for creating similar datasets. \n3. Strong and simple evidence in favor of creating parallel resources to improve detoxification systems performance as opposed to relying on non-parallel data or unsupervised systems. \n4. Informative insights into the efficacy of the pipeline. Namely, the amount of good vs bad samples is an interesting insight ", "summary_of_weaknesses": "1. Subtle biases as a result of rejecting samples:     - fetched toxic sentences for rewriting (line 215),     - toxicity classifier (line 218)     - annotator bias     These choices introduce biases into the datasets (unavoidable). The paper would benefit from attempting to quantify how useful a model trained on ParaDetox is in a more general setting. e.g. performance on other (non-parallel) toxicity datasets. \n     2. I’m uncertain about the generality of the methodology. The pricing and application are platform-specific (toloka.yandex.com) and language-specific (English). Would this be possible using another crowdsourcing platform? Or in another language? \n3. The experimental details, for the classifier and proposed Bart-model are unspecified. In particular, details regarding data splits, fine-tuning configuration, and evaluation are missing. ", "comments,_suggestions_and_typos": "### Comments and questions - How many annotators were involved in the annotation processes?\n- How many samples are enough to get reasonable results with the data produced using your pipeline? You show results on the subsets of ParaNMT, but how does performance scale with the samples in ParaDetox?\n- In the name of reproducibility: What embeddings are used to compute the cosine similarity?\n- In the paragraph on line 267, it is described that samples that the classifier scores above the threshold of 0.8 are included. How much does this affect the precision of the classifier? W.r.t. the $F_1$ score of 0.76.\n- Do you intend to share non-detoxifiable samples? This to me seems like a highly useful resource that could benefit the community. Knowing when something can’t be detoxified isn’t something that can be inherently modeled by the proposed models.\n### Style I found the nested parentheses on lines 041-043 hard to read. "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "5 = Enabling: The newly released datasets should affect other people's choice of research or development projects to undertake.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "2 =  Willing to defend my evaluation, but it is fairly likely that I missed some details, didn't understand some central points, or can't be sure about the novelty of the work.", "sentences": {"paper_summary": [[0, 96], [96, 202], [202, 315], [315, 375], [375, 622], [622, 860]], "summary_of_strengths": [[0, 3], [3, 92], [92, 96], [96, 172], [172, 176], [176, 357], [357, 361], [361, 417], [417, 485]], "summary_of_weaknesses": [[0, 3], [3, 165], [165, 233], [233, 355], [355, 415], [415, 424], [424, 479], [479, 582], [582, 643], [643, 667], [667, 671], [671, 757], [757, 858]], "comments,_suggestions_and_typos": [[0, 27], [27, 92], [92, 192], [192, 298], [298, 391], [391, 520], [520, 579], [579, 586], [586, 611], [611, 662], [662, 743], [743, 857], [857, 929]]}}}, {"rid": "3ca4f9aa9332a781138f5a19b71292b07038feb65acb13df1d8833ca7d8f20d065cba5b66955139a28ec075ac7144da285090904d4b20506acc17a908311aa10", "reviewer": "Bashar Alhafni", "report": {"paper_summary": "The authors present a new crowdsourcing pipeline to collect parallel data for the task of detoxification (i.e., a style-transfer task to convert toxic text into its non-toxic variant). The authors used their proposed pipeline to collect the first parallel English detoxification dataset (ParaDetox). ParaDetox has almost 12,000 toxic sentences where each sentence is paired with 1-3 non-toxic paraphrases. Moreover, the authors also show that their pipeline could be used to retrieve toxic and non-toxic sentence pairs from existing paraphrasing parallel datasets (e.g., ParaNMT). Furthermore, the authors demonstrated the effectiveness of their created parallel data by training various detoxification seq2seq BART-based models and showing that the trained models outperform current STOA methods. ", "summary_of_strengths": "- A novel dataset that will encourage research and development on the task of detoxification.\n- A useful pipeline that could be used to create new parallel datasets for detoxification. The pipeline also provides a faster and cheaper way to take advantage of existing parallel paraphrasing datasets to retrieve toxic/non-toxic sentence pairs.\n- Clear description of the crowdsourcing pipeline.   * Nice examples of what the data looks like. I found it very useful to understand the task. ", "summary_of_weaknesses": "- There are some technical aspects of the paper that weren't clear to me:   * L271: Was the same fine-tuned RoBERTa model, which was used as a toxicity classifier, used to embed the paraphrased sentences from ParaNMT to check their cosine similarity to decide if they should be processed through the retrieval pipeline?\n  * L292: Which BPE tokenizer are you referring to? The RoBERTa Byte-level BPE tokenizer? \n     * It wasn't clear to me if the 671 parallel sentences which were used as a blind test were part of the ParaDetox 12,000 examples or not. If not, were they created through the generation pipeline or the retrieval pipeline (i.e., from ParaNMT)? Are you planning on releasing an actual train/dev split with the dataset?\n * Hyperparameters weren't mentioned to replicate experiments for fine-tuning BART.\n * Although the Data Collection Pipeline section (Section 3) was clear, some parts of the paper were hard to follow. ", "comments,_suggestions_and_typos": "I think the paper would benefit from another round of revisions to fix some typos. It would also be helpful to the readers to know the specifics of the various experiments conducted (e.g., what embeddings were used? what BPE tokenizer? what were the hyperparameters used to fine-tune BART?) "}, "scores": {"overall": "3.5 ", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "4 = Useful: I would recommend the new datasets to other researchers or developers for their ongoing work.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Bashar Alhafni, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 185], [185, 300], [300, 406], [406, 581], [581, 798]], "summary_of_strengths": [[0, 94], [94, 185], [185, 342], [342, 393], [393, 394], [394, 440], [440, 487]], "summary_of_weaknesses": [[0, 320], [320, 372], [372, 410], [410, 553], [553, 659], [659, 733], [733, 817], [817, 934]], "comments,_suggestions_and_typos": [[0, 83], [83, 216], [216, 236], [236, 291]]}}}]