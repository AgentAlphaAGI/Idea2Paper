[{"rid": "7ac917aef92a6a0b5c771a69b843f24686f3c378588460f17676327a4c71dca0cd57261275604f27fe3755b9b53398b7e68bc9772b88f20b2a073b00cc7fc93e", "reviewer": null, "report": {"paper_summary": "This paper developed a new dataset, GlobalWOZ, a multilingual extension of the English MultiWOZ to about 20 languages through machine translation (to save cost) and replacing entities occurring in the English dataset with local entities that are most likely to be used in a foreign language (in the country where the language is spoken). They considered the following 3 use cases: (1) a foreign language speaker uses ToD in the foreign-language country (F&F), or (2) an English country (F&E), (3) an English speaker uses ToD in a foreign-language country (E&F), which are different from the traditional E&E use case where an English speaker uses ToD in an English-speaking country.  To ensure that the dataset captures more local entities in the foreign countries of interest, first, English-specific entities are replaced with a set of general-purpose placeholders, followed by the translation of the sentences (without entities), and lastly, ontologies containing definitions of dialogue acts, local entities and their attributes in the target language countries are used for placeholder replacement. The dataset created consists of high-quality test sets in 3 languages (Chinese, Spanish, and Indonesia) that have been post-edited by professional translators after machine translation. The test sets of the remaining 17 languages are machine translated.  For the experiments, they compare the performance of their approach to zero-shot evaluation when transferring from English and using translated english dataset for training. ", "summary_of_strengths": "- They introduced a very important dataset over 30 languages, they also compare the quality of the dataset that has been machine-translated with the one machine translated and post-edited by professional translators on 3 languages (Chinese, Spanish, and Indonesia).  - The paper is well-written and the experiments are quite interesting. ", "summary_of_weaknesses": "- The translation quality for low-resource languages should be discussed. For example, some low-resource languages like Swahili may give poor performance if they have not been trained on dialogue texts. ", "comments,_suggestions_and_typos": "NA "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 338], [338, 682], [682, 683], [683, 1103], [1103, 1289], [1289, 1357], [1357, 1358], [1358, 1532]], "summary_of_strengths": [[0, 266], [266, 267], [267, 338]], "summary_of_weaknesses": [[0, 74], [74, 203]], "comments,_suggestions_and_typos": [[0, 3]]}}}, {"rid": "ae976a7ae222dcfb0d0676e63c1c2ca3728c082f3b2399aa7b45248600308350e4a8a90902669a365d599c67fb1c23f7addb87ee546619ebcb045b5b007c39cd", "reviewer": "Samuel Cahyawijaya", "report": {"paper_summary": "The paper introduces GlobalWoZ, a  mutllingual task-oriented dataset built from translating MultiWoZ dataset to 20 other languages. The paper first provides deep analysis on 3 use cases for ToD (E&F, F&E, F&F) aside of English-speaker in English-speaking country. The dataset is built by generating template, translating the dialogue, and template filling with local entities based on a crawled ontology.\nThe paper shows and extensive experiments on utilizing the datasets by only including single use-case (SUC), Bi-lingual Bi-use-case (BBUC), Multilingual Bi-use-case (MBUC),Multilingual multi-use-cases (MMUC). The experiment shows the effectiveness of using the translated data on all 3 use-cases in both zero-shot and few-shot settings by applying SUC, BBUC, MBUC, and further show generalization on all use-cases using a single MMUC model.  The paper shows the importance of code-switching use-cases (i.e., E&F and F&E) and further provides interesting discussion on overestimation of translate-train baseline which is commonly used in building a practical setting of a multilingual ToD system especially on local entities. Additional experiment on the impact of training on data is also analyzed in the paper. Lastly, the paper shows that machine translated data can be a good proxy for a machine translated data with an additional human curation step, and further provide translated MultiWoZ dataset for 17 other languages. ", "summary_of_strengths": "• The paper introduces GlobalWoZ, a translated multilingual ToD dataset covering 20 languages with 3 practical use-cases of a multilingual ToD system • The paper shows extensive analysis on all 3 use-cases which provides an empirical proof on the effectiveness of the GlobalWoZ dataset and performing joint training on all the use-cases to achieve better generalization for a multilingual ToD system.\n• The paper shows a performance gap in the translate-train model (a common baseline in multilingual ToD) when the data contains local context.\n• The paper shows that a machine translated data can be a proxy for a human curated data ", "summary_of_weaknesses": "• The paper doesn’t show the quantitative differences between MT and MTPE datasets are not presented on the paper • The paper shows that machine translated data can be used as a proxy for human translated data, but only compare with post-editing approach which provides bias for the human editor. ", "comments,_suggestions_and_typos": "• The paper doesn’t show the quantitative differences between MT and MTPE datasets are not presented on the paper • The paper shows that machine translated data can be used as a proxy for human translated data, but only compare with post-editing approach which provides bias for the human editor.\n• Line 131 “another” -> “other” "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "5 = Enabling: The newly released datasets should affect other people's choice of research or development projects to undertake.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Samuel Cahyawijaya, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "4 = From an allowed pre-existing preprint or workshop paper, I know/can guess at least one author's name.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 132], [132, 264], [264, 405], [405, 614], [614, 846], [846, 847], [847, 1130], [1130, 1217], [1217, 1432]], "summary_of_strengths": [[0, 150], [150, 401], [401, 544], [544, 633]], "summary_of_weaknesses": [[0, 114], [114, 297]], "comments,_suggestions_and_typos": [[0, 114], [114, 297], [297, 329]]}}}, {"rid": "0dc642dca260bbade73371aef794093e15522e6518fe0f85f735e6ef3fbb3669c525379ae75be86eff5d694de1a10464c2a45e5ecc0bc78c4a0acd62eca5f2c1", "reviewer": null, "report": {"paper_summary": "The paper explores three unexplored usecases on multilingual task-oriented dialogue (ToD) systems where the speaker where a foreign language speaker uses ToD in the foreign-language country (F&F) or an English country (F&E), and an English speaker uses ToD in a foreign-language country (E&F). They introduced a curation method by creating a template, create the ontology, translate using machine translation, and then ask annotators to edit the translations. This method is claimed to be cost-effective. ", "summary_of_strengths": "- A new multilingual use case for ToD that can be useful for investigate the behavior of speakers living in different locations.  - The curation method is cost-effective. It requires a limited amount of post-editing efforts for a test set.\n- Extensive experiments on different scenarios. ", "summary_of_weaknesses": "- It is unclear how the human annotations process is done (for example: how many annotators per sample and the acceptance criteria).\n- The motivation of the three experimental settings is relatively weak. It can be better explained in the introduction. The settings are interesting if they are appropriately described and given a more substantial reason why they are important. For now, it looks like the authors are trying to explore new settings without supporting rationale.\n- The authors do not explore the performance drop when using local entities in the experiments. ", "comments,_suggestions_and_typos": "Comments: 1. Please add more descriptions as the authors undergo the human annotation process. \n2. It would be better to add examples for each setting.\nQuestions: 1. What are the criteria for selecting the human annotation results for the post-edit stage? Did you apply additional quality assurance after adding the entities to the samples? And, how much changes after the post-edit stage? \n2. Why did the significant performance drop occur when using local entities in the experiments? \n3. Did you manage to measure the quality of the samples you collected using the proposed method? "}, "scores": {"overall": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "1 = No usable datasets submitted.", "software": "2 = Documentary: The new software will be useful to study or replicate the reported research, although for other purposes it may have limited interest or limited usability. (Still a positive rating)"}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 294], [294, 460], [460, 505]], "summary_of_strengths": [[0, 129], [129, 130], [130, 171], [171, 240], [240, 288]], "summary_of_weaknesses": [[0, 133], [133, 205], [205, 253], [253, 378], [378, 478], [478, 574]], "comments,_suggestions_and_typos": [[0, 13], [13, 95], [95, 99], [99, 152], [152, 166], [166, 256], [256, 341], [341, 390], [390, 394], [394, 487], [487, 491], [491, 585]]}}}]