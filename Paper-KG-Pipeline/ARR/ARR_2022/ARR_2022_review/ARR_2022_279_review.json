[{"rid": "96fd755799d4fff5a34ad57c216543eab0d10560d88668d55e70fd2f08bffdcd2bd961dd8463e24c599da136cb397ee8659c9634d22e7c9ad7f9b1cf64332381", "reviewer": null, "report": {"paper_summary": "This short paper presents an empirical study of a direct-parsing approach for sentiment graphs.  The methods come from previous work but this paper adapts them to the sentiment task and shows that they perform quite well across several data sets. ", "summary_of_strengths": "+ The paper presents a method that performs well on an important task + The fact that a direct-parsing approach would provide benefits seems sensible + Because of the strong performance, the released software may be valuable to the community ", "summary_of_weaknesses": "- The paper does not appear to have methodological novelty (the paper is somewhat unclear on this score, but does not distinguish what if anything from its approach differs from the original PERIN approach) - The paper is hard to understand. It is not self-contained -- the methods are only really explained elsewhere, and I was left with several questions (some listed below) - The one design decision evaluated in the experiments is which graph encoding to use (node-centric, labeled-edge, and opinion-tuple).  The paper spends a large amount of its limited space discussing these three encodings and presenting results with each, but it is never explained why this is an important dimension to vary or why it makes sense that we see certain performance differences.\nI have a hard time evaluating this paper because it seems like the primary empirical finding, that this approach works well across several data sets, is a helpful data point for the community.  However, aside from that one piece of information, I didn't learn much from this paper, due to the issues mentioned above. ", "comments,_suggestions_and_typos": "Line 21 -- what are \"the relations\"?\nLine 52-57, how this lossy conversion causes problems seems crucial to the paper's central thesis (it is avoiding this intermediate step that is hypothesized to improve performance in this paper).  Cutting all of the material on different graph encodings in order to more clearly explain this issue in the body text (I found it hard to understand even after reading App A) would improve the paper.\nLine 70 - \"permutation-invariant,\" why is this important and permutations of what? ( must be the output structure) Line 201-205 -- This is interesting, making this statement quantitatively (probably at the example level rather than the dataset level, so for examples in the top quartile in terms of amount of nesting, we see certain larger performance gains) would be helpful.\nLine 386 (of appendix) - \"it is impossible\" -- I don't understand why.  Especially given this is in the appendix, it would help to explain exactly why this is impossible.  In general all of appendix A (like the rest of the paper) is terse to a point of being quite hard to comprehend. "}, "scores": {"overall": "2.5 ", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "4 = Useful: I would recommend the new software to other researchers or developers for their ongoing work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 96], [96, 247]], "summary_of_strengths": [[0, 242]], "summary_of_weaknesses": [[0, 207], [207, 242], [242, 377], [377, 512], [512, 769], [769, 962], [962, 1086]], "comments,_suggestions_and_typos": [[0, 37], [37, 234], [234, 435], [435, 520], [520, 550], [550, 812], [812, 883], [883, 983], [983, 1097]]}}}, {"rid": "cae04ea5a5edc93df8355c570815cbecec45d18562b5e323e53d02cb9a95394dff757192c80981f891adf14462e54a81f0786e4017a672b721801666e52f162e", "reviewer": "Rong Xiang", "report": {"paper_summary": "This paper proposed how to adapt the graph-based semantic parser PERIN to the task of structured sentiment analysis, aiming to analyze a polar expression, an optional holder, an optional sentiment target, and sentiment polarity. Based on PERIN, the weighted bipartite graph between all queries and nodes is applied to indicate the prior ordering of the graph. The proposed method advances the-state-of-the art method on 4 out of 5 standard benchmark sets. ", "summary_of_strengths": "1) This work applies the graph-based semantic parser PERIN for structured sentiment analysis with task-specific adaption, which refines the parallel queries process and gold nodes mapping. \n2) The paper is clearly written and well structured. Given the page limitation of a short paper, this paper still provides abundant information. \n3) The results of performance evaluation are quite convincing for the comparison with state-of-the-art methods and complete experimental settings. ", "summary_of_weaknesses": "1) Lacking innovation is the main weakness of this paper, though proven the usefulness of PERIN and the refinement. \n2) Due to the page limitation, this work lacks detailed analysis on Node-centric encoding, Labeled-edge encoding and Opinion-tuple encoding, which are the essential design towards SSA. ", "comments,_suggestions_and_typos": "1) In Figure 2, please indicate STEP 1,2,3,4 in the corresponding places in the diagram for better illustration. \n2) It would be better to present a few case studies for readers. "}, "scores": {"overall": "3.5 ", "best_paper": "No", "replicability": "5 = They could easily reproduce the results.", "datasets": "1 = No usable datasets submitted.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Rong Xiang, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 229], [229, 360], [360, 456]], "summary_of_strengths": [[0, 189], [189, 243], [243, 335], [335, 483]], "summary_of_weaknesses": [[0, 116], [116, 302]], "comments,_suggestions_and_typos": [[0, 113], [113, 179]]}}}]