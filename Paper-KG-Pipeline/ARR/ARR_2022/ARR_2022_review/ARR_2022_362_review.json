[{"rid": "48707583c7316f9bdc965d74a016f3ac454a4bb4d652491f806aaaa0cd705da128ab6bfbc2c6c7586fe8c7a21f6745ff15d6bc640aec03a164d04ea6b7886dd9", "reviewer": "Prashanth Vijayaraghavan", "report": {"paper_summary": "The authors perform an investigation on the effects of cross-domain classification of moral values from text. Given the specificity of the moral values  This involves experiments that evaluate a multi-label moral value classifier conducted under different cross-domain training settings that analyze the following scenarios — (a) ideal all-data training scenario, (b) generalizability, (c) transferability, and (d) catastrophic forgetting. Some of the key findings include: (i) the ability of a value classifier to generalize to novel domains when trained on multiple domains combined with a small amount of data from the novel domain, (ii) fine-tuning on a novel domain causes catastrophic forgetting of the pre-trained domains. The authors also analyze the correspondence between model predictions and the annotators agreement. The authors report that the majority of classification errors are not severe as at least one annotator agreed with the model prediction in all evaluation settings. ", "summary_of_strengths": "1. The paper is well-written and easy to understand. \n2. The paper performs a comprehensive set of evaluations for cross-domain classification and provides good explanation of all the different experimental settings . ", "summary_of_weaknesses": "1. While the paper focuses on generalizability and transferability of value classifier, however,  there needs more clarity on domain specificity. Though the paper talks briefly about the moral value expressions taking different forms in various domains, the BERT model used here doesn’t seem to take into account the domain information. Hence, the value classifier might emit the same moral value label for a moral value expression irrespective of the domain. \n2. Though the objective is not to compare classifiers but evaluate the cross-domain capability, the observation of catastrophic forgetting, despite several other reasons, could also be a result of lack of domain information leading to more misclassification errors. \n3. The evaluation sections reports results over 10 runs, but the paper doesn’t report the standard deviation that potentially provides more information about the sensitivity of the model to order or domains trained vs domains tested. \n4. The findings of the paper pretty much align with earlier understanding of how training on larger amount of data  from different or same domain helps improve generalizability or transferability. Though it is important to validate them in the moral value applications (which is limited),  it will be better if the paper clarifies what its core contributions are and how it varies from other general approaches/findings in domain adaptation or multi-task learning methods. ", "comments,_suggestions_and_typos": "More clarity on specific contributions of the paper. \nExplaining the limitations/assumptions and potential reasons behind specific findings would be useful. "}, "scores": {"overall": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "2 = Documentary: The new software will be useful to study or replicate the reported research, although for other purposes it may have limited interest or limited usability. (Still a positive rating)"}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Prashanth Vijayaraghavan, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 110], [110, 440], [440, 730], [730, 830], [830, 994]], "summary_of_strengths": [[0, 3], [3, 53], [53, 57], [57, 218]], "summary_of_weaknesses": [[0, 3], [3, 146], [146, 337], [337, 460], [460, 464], [464, 727], [727, 731], [731, 962], [962, 966], [966, 1160], [1160, 1436]], "comments,_suggestions_and_typos": [[0, 53], [53, 157]]}}}]