[{"rid": "7782092c2790c6f8049780b462c74c493bf613466e89b3cdfd3592881457879cf55c5bc05d340a47f35b26ef24bb312aefe8f178672a12d440301d04b15a8f3f", "reviewer": null, "report": {"paper_summary": "This paper presents a data augmentation with ranking-based learning for open relation extraction. In particular, the authors argued the following contributions: 1. three types of data augmentations, including back translation as positive, entity replacing as hard negative, entity swap for semi-hard negative 2. ranking-based loss function with both euclidean distance in the feature space and KL divergence in the label space. \nThe proposed model shows the state of the art results on T-REx SPO and T-REx DS ", "summary_of_strengths": "1. Results over two datasets show significant improvements over recent state-of-the-art models. \n2. Paper contains extensive results for a short paper and is easy to read. ", "summary_of_weaknesses": "1. This paper proposed three different types of data augmentation methods. Both hard negative and semi-hard negatives focus on replacing the entity mentions. However, it is not well-explained why this can help to cluster the relational expression. Does this lead to a model which focuses on entity mention detection rather than relation patterns? From my understanding, replacing entity mentions of the same context should not largely change the relation semantics.\n2. I think back translation plays a key role in this paper. I think it is necessary to add an ablation study to exclude the hard and semi-hard negatives. In particular, how does the model perform when both formula 1 and 2 only include t and t^p and use in-batch negatives (similar to contrastive learning). ", "comments,_suggestions_and_typos": "1. It is not clear to me why hard negatives and semi-hard negatives are generated from the positive sentence rather than the original sentence. Wouldn't there exist error propagation if the back translation is noisy? \n2. It seems that T-REx is a distantly supervised dataset with no human labels. am I correct? If so, is it possible to evaluate over annotated dataset? ( For example TACRED or FewRel?) "}, "scores": {"overall": "3.5 ", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 98], [98, 164], [164, 312], [312, 428], [428, 509]], "summary_of_strengths": [[0, 3], [3, 96], [96, 100], [100, 172]], "summary_of_weaknesses": [[0, 3], [3, 75], [75, 158], [158, 248], [248, 347], [347, 466], [466, 469], [469, 526], [526, 620], [620, 773]], "comments,_suggestions_and_typos": [[0, 3], [3, 144], [144, 217], [217, 221], [221, 297], [297, 311], [311, 371], [371, 402]]}}}, {"rid": "19f388a29acd478e296a556b93da193a08c35983f08334eb804d61a3b42f687cf8b7a8ad0984b98d01112105066170a4441bd5a07e61e8179253006a3cd6aeff", "reviewer": "Yixin Cao", "report": {"paper_summary": "This paper proposes to learn discriminative representations for open relation extraction. In specific, the authors first introduce three data augmentation strategies to generate positive, hard negative, and semi-hard negative samples. Then, the proposed model not only uses instance ranking to optimize each instance's relation representations but also learns relation representations by grouping them together. Experimental results demonstrate the effectiveness of the proposed method. So, I recommend accepting the paper as a short paper. ", "summary_of_strengths": "1. The presentation is clear.\n2. The experiments are convincing as compared with six SOTA baselines and three variants of the proposed model.\n3. The method is simple yet effective. ", "summary_of_weaknesses": "Does the proposed method heavily depends on the data augmentation quality? It is better to give further discussion. ", "comments,_suggestions_and_typos": "NA "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Yixin Cao, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 90], [90, 235], [235, 412], [412, 487], [487, 541]], "summary_of_strengths": [[0, 3], [3, 30], [30, 33], [33, 142], [142, 145], [145, 181]], "summary_of_weaknesses": [[0, 75], [75, 116]], "comments,_suggestions_and_typos": [[0, 3]]}}}]