[{"rid": "4c69ad0b9602535475c3a25290d0826bece581f4f5eb8810fb9a7b8c60f0b0c76d28c0a89cf9068e342e48285598bcb611cea3c2baf557ea04071079d4769f80", "reviewer": null, "report": {"paper_summary": "*(minor edits from previous review XYZ)* Text style transfer is the task of rewriting a sentence into a target style while approximately preserving its content. Modern style transfer research operates in an \"unsupervised\" setting, where no parallel training data (pairs of sentences differing in style) is available, but assume access to a large unpaired corpus in each style.\nThis paper argues that a large unpaired corpus to train style transfer systems might be hard to obtain in practice, especially in certain domains. To tackle this issue, the authors present a new meta-learning approach (DAML) which trains a style transfer system that can quickly adapt to unseen domains during inference (with a few unpaired examples). The authors build their style transfer system using a discriminative learning objective (via a style classifier) while fine-tuning T5, which they call ST5. The authors approach DAML-ST5 outperforms several baselines on sentiment transfer and Shakespeare author imitiation, and ablation studies confirm the design decisions. ", "summary_of_strengths": "*(identical to my previous review GAJd, see \"Weaknesses\" for my response to the revised manuscript)* 1. This paper tackles a practically relevant problem. While current style transfer research does not leverage supervised data, it requires a large amount of unpaired data which may not be practical to obtain in low-resource languages or domains. Hence, building style transfer systems which can quickly adapt in low-resource settings is important, since it eliminates the expensive requirement of hand-curating unpaired datasets for each low-resource domain / language.\n2. The paper presents an interesting method based on model-agnostic meta learning [1] (with modifications to make it suitable for domain adaptation) to learn a good initialization which works well across domains. During inference, the model can quickly adapt to a new domain, with decent performance with just 1% of the target domain data. Experimental results confirm the proposed approach outperforms several strong baselines. The paper also has ablation studies to justify the various design decisions used in the approach.\n[1] - https://arxiv.org/abs/1703.03400 ", "summary_of_weaknesses": "The authors presented an excellent response and addressed all the concerns in my previous review GAJd in their revised manuscript. In particular, the authors added experiments on the new Shakespeare dataset, used extra automatic metrics to evaluate their approach and found consistent trends, clarified some questions I had about the modeling, added comparisons to recent few-shot style transfer approaches.\nI have increased my score to 4. It would be nice to move some of the new results into the main body of the paper with the extra 9th page, especially the experiments on the Shakespeare dataset. ", "comments,_suggestions_and_typos": "Several references are missing their venues / journals / arXiv identifiers, you can get the correct bib entries for papers from https://aclanthology.org, Google Scholar or arXiv. "}, "scores": {"overall": "4 = This paper represents solid work, and is of significant interest for the (broad or narrow) sub-communities that might build on it.", "best_paper": "No", "datasets": "3 = Potentially useful: Someone might find the new datasets useful for their work.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright Â© 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 41], [41, 161], [161, 377], [377, 524], [524, 729], [729, 885], [885, 1053]], "summary_of_strengths": [[0, 101], [101, 104], [104, 155], [155, 347], [347, 571], [571, 574], [574, 784], [784, 911], [911, 1000], [1000, 1098], [1098, 1137]], "summary_of_weaknesses": [[0, 131], [131, 408], [408, 440], [440, 601]], "comments,_suggestions_and_typos": [[0, 179]]}}}]