[{"rid": "c4a52e021c937f2a0d0af962f63e78fb3e3afca766b2b604b0171bd8316789c106ac294ed698741761766735caf40d1a017e66290669a7ff89d881ef1f9f32db", "reviewer": "Hiroki Ouchi", "report": {"paper_summary": "- This paper works on zero-shot relation extraction. Note that the authors assume that ground-truth entities in each sentence are given as input. In other words, this task does not require identifying entities.\n- The problematic issue this paper focuses on is the difficulty of distinguishing similar but different-class relations, called “similar relations” and “similar entities” (see the details in line 71-84 and Table 1 shows some examples).\n- To mitigate this issue, the authors propose a new relation contrastive learning framework (RCL). The reason why they applied contrastive learning (particularly, instance-wise contrastive learning) to zero-shot relation extraction is that some existing studies reported its remarkable effectiveness for representation learning (see the details in line. 84-91).\n- Their proposed method achieved better performance (Table 2). Also, using dropout for augmentation is more effective than other augmentation techniques (Table 3), which is consistent with the result of Guo et al. (2021). ", "summary_of_strengths": "- Their method consistently achieves performance improvements (Table 2).  - Their proposed method is so simple that readers can reimplement their method. ", "summary_of_weaknesses": "- Their claim is not properly supported. In Section 1 (in line 71-84 and 121-124), the authors introduce the problem they want to solve, and they state as follows: “It effectively mitigates two types of similar problems: similar relations and similar entities by learning representations jointly optimized with contrastive loss and classification loss.”  It is true that they show some actual examples their method solved in Appendix (Figure 6). However, there is no quantitative evidence for supporting that their proposed method solves or mitigates the problem. Thus, readers cannot judge whether their method can mitigate the “similar relations and similar entities” problem or not. Readers would appreciate if the authors could provide quantitative results for supporting the claim.\n- The authors adopt different evaluation metrics (B^3 F1, NMI, ARI) from the standard metric (F1 score) used in many existing papers on zero-shot RE, such as Chen and Li (2021) and Levy et al. (2017). In terms of the three metrics, the state-of-the-art method, ZS-BERT, is inferior to other methods, such as Att-BiLSTM, which surprises many readers. Although it is okay to adopt the different metrics, many readers are likely to see the performance comparisons in terms of the standard F1 score as well as the three metrics.\n- The proposed method is not so new. It is true that the proposed method includes a few simple extensions for relation extraction (e.g., Softmax Layer and Concat Layer), the key idea and most parts of their method are based on existing contrastive learning methods, such as SimCSE proposed by Gao et al. (2021). So, readers would be happy if the authors specify which parts are their original extensions more clearly.  - Minor point: Some notations are confusing and undefined. Please see “Comments, Suggestions And Typos” in detail. ", "comments,_suggestions_and_typos": "- How about comparing your proposed method with existing ones by using the standard F1 score?\n- Missing references: (1) For Open Relation Extraction (in line 156), it might be better to cite the pioneering work, Bank et al. “Open Information Extraction from the Web” in Proc. of IJCAI2007. For contrastive learning in NLP, there are some existing studies. ( 2) For sequence labeling, Wiseman and Stratos “Label-Agnostic Sequence Labeling by Copying Nearest Neighbors” in Proc. of ACL2019. ( 3) For span classification such as NER, Ouchi et al. “Instance-Based Learning of Span Representations” in Proc. of ACL2020. They do not call their methods \"contrastive learning,\" but their methods are a type of instance-wise contrastive learning.\n- Notations: (1) In line 247, the subscript $i$ (in $X_i$) is not defined. ( 2) In Equation 1, the symbol $i$ is used for both the subscript and the superscript, such as $X^i_i$, which is a little bit confusing. It might be better to use different symbols. ( 3) Also, in Equation 1, the authors assume that the first entity span is $(i, j-1)$ and the second one $(k, l-1)$. It might be better to specify the entity spans and the notations. "}, "scores": {"overall": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Hiroki Ouchi, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 53], [53, 146], [146, 211], [211, 447], [447, 546], [546, 801], [801, 809], [809, 872], [872, 1031]], "summary_of_strengths": [[0, 73], [73, 74], [74, 154]], "summary_of_weaknesses": [[0, 41], [41, 354], [354, 446], [446, 564], [564, 686], [686, 787], [787, 988], [988, 1137], [1137, 1312], [1312, 1349], [1349, 1624], [1624, 1730], [1730, 1731], [1731, 1790], [1790, 1846]], "comments,_suggestions_and_typos": [[0, 94], [94, 276], [276, 290], [290, 358], [358, 477], [477, 491], [491, 603], [603, 615], [615, 738], [738, 815], [815, 950], [950, 997], [997, 1178]]}}}]