[{"rid": "3fa0b7dad4a7fd3420ae5161a9320f79e950bfefd6e18836d4ff2b5825672442ecd7cd0e4908079fc15c0769f53d5a0f28a5906778ace376acbedc959221ae76", "reviewer": null, "report": {"paper_summary": "The paper presents QuALITY, a new benchmark for question answering over long passages. All the questions are multiple-choice, composed by professional writers and validated by MTurk annotators to be answerable and unambiguous. A subset of especially challenging questions is also selected in a task where annotators answer the question under strict time constraints. The paper presents a detailed analysis of the dataset and a thorough evaluation of long-context and extractive QA models on the presented data, demonstrating that all the models are far behind human performance. ", "summary_of_strengths": "- Long-passage QA datasets are harder to collect and relatively scarce, so the new dataset would be a valuable addition to the field.\n- The data collection and annotation process is very well thought out and includes multiple validation steps. The data is further validated in qualitative and quantitative analysis.\n- The experimental part is thorough: both long-context models and extractive models are evaluated, and there are additional experiments with supplementary training data and no-context baselines. The choice of the QA baselines seems reasonable to me (although my expertise in QA is limited).  - The paper is clearly written and easy to follow, and both the data collection and the experimental evaluation are documented in detail. ", "summary_of_weaknesses": "My only (very minor) concern: the qualitative analysis is somewhat hard to understand without reading the Appendix (see comment below). That can easily be addressed given an extra page. ", "comments,_suggestions_and_typos": "- Without looking at the Appendix, I found it difficult to interpret the different reasoning strategies mentioned in Section 3.6 and Table 5. This section might read more smoothly if you include an example question or a very short explanation for a few most popular types, such as \"Description\" or \"Symbolism\". It was also not clear to me how the questions were annotated for reasoning strategy without reading the passages: was it just by looking at the question, or with the Ctrl+F type keyword search in the passage?\n- This is perhaps too much to ask, but I am very curious about the 4% where the annotator-voted gold label does not match the writer’s label. If the authors have done any analysis on why the annotators might disagree with the writer, I would love to see it!\n- L275: this inclusion criteria -> these inclusion criteria - L441: perhaps you meant Table 6, not Table 9? Not having to go to the Appendix for the results would make things easier for the reader. "}, "scores": {"overall": "4.5 ", "best_paper": "No", "datasets": "4 = Useful: I would recommend the new datasets to other researchers or developers for their ongoing work.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 87], [87, 227], [227, 367], [367, 579]], "summary_of_strengths": [[0, 134], [134, 244], [244, 316], [316, 511], [511, 607], [607, 608], [608, 746]], "summary_of_weaknesses": [[0, 136], [136, 186]], "comments,_suggestions_and_typos": [[0, 142], [142, 311], [311, 520], [520, 662], [662, 778], [778, 838], [838, 886], [886, 976]]}}}]