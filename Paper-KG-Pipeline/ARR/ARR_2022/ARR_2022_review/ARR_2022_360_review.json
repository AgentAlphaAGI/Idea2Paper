[{"rid": "97bd72cf67e40492696103ced9dcbd5066d8a3a52f3d2558764aa570e24ae2c7bedddf9ad226e624b1dabcced450f36d6bcd93ece5a871c74fa98b7e2d8145fc", "reviewer": null, "report": {"paper_summary": "This paper is about phonology of sign languages. It introduces the task of phonological property prediction, as well as a novel resource, which combines two existing data sets into a data set that can be used for training large-scale neural network models for phonological property prediction. Finally, the study presents a set of experiments, in which various models trained to perform the specified task on that data set. The results show that the task is feasible in principle, but the existing models do not reach the optimal performance. ", "summary_of_strengths": "This is paper in an area severely underexplored in the NLP community, even though sign languages are commonly used. The study seems to be well-conducted, and the paper is easy to read, I think it would be useful to include the paper in the conference. ", "summary_of_weaknesses": "It wasn't obvious to me why attention-based architectures weren't used for the task. I can imagine the NLP community would be interested in that, but that doesn't make the paper's contribution less interesting. Also, it wasn't clear to me whether the data would can be released, as this is one of the important contributions of the paper. ", "comments,_suggestions_and_typos": "- It took me a while to understand that \"sign\" and \"gloss\" refer to the same thing. Or am I still misunderstanding it?\n- I couldn't understand why a multiclass multilabel approach couldn't be presented in parallel. Was it just left for future work? I assume it would be necessary for the tokenization task that the authors mention in the conclusion, would it not? "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "3 = Potentially useful: Someone might find the new datasets useful for their work.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "2 =  Willing to defend my evaluation, but it is fairly likely that I missed some details, didn't understand some central points, or can't be sure about the novelty of the work.", "sentences": {"paper_summary": [[0, 49], [49, 294], [294, 424], [424, 543]], "summary_of_strengths": [[0, 116], [116, 252]], "summary_of_weaknesses": [[0, 85], [85, 211], [211, 339]], "comments,_suggestions_and_typos": [[0, 84], [84, 119], [119, 215], [215, 249], [249, 364]]}}}, {"rid": "f6ac79cadfa17a1adecfd96d38071e09be3cddf3ef3e1c57a6f191d1ca92c801035cdf2d0bb4c9a30f4cfe874bf54fb512a93c7baf8a57ce9d4f0c0142cd46c8", "reviewer": null, "report": {"paper_summary": "This paper aims at addressing the phonological property recognition task for sign languages. The authors take advantage of the existing datasets and annotate the data with six phonological properties. Then they train neural models based on the dataset and perform a classification task to find an optimized automatic recognition approach for these properties. Preliminary results show that neural networks present various performances towards different properties. ", "summary_of_strengths": "1. The paper structure is well organized, and the illustration is clear and cohesive. \n2. From this work, they contribute a dataset that can be further used. ", "summary_of_weaknesses": "1. When conducting the evaluation, do you consider using the F1 score instead of accuracy to have a more comprehensive understanding of model performance? \n2. I notice there is a severe imbalance with the data you annotated. I think a balanced-data experiment is needed. \n3. I would expect a more detailed error analysis in the discussion part. ", "comments,_suggestions_and_typos": "I think those properties will interact with each other so the models may easily be influenced by them together. Do you consider generating or extracting contrastive pairs during model training and testing? "}, "scores": {"overall": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "4 = Useful: I would recommend the new datasets to other researchers or developers for their ongoing work.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "2 =  Willing to defend my evaluation, but it is fairly likely that I missed some details, didn't understand some central points, or can't be sure about the novelty of the work.", "sentences": {"paper_summary": [[0, 93], [93, 201], [201, 360], [360, 465]], "summary_of_strengths": [[0, 3], [3, 86], [86, 90], [90, 158]], "summary_of_weaknesses": [[0, 3], [3, 155], [155, 159], [159, 225], [225, 271], [271, 275], [275, 345]], "comments,_suggestions_and_typos": [[0, 112], [112, 206]]}}}]