[{"rid": "f687bf77fc22ce81eb26ae866f542b52f4fe8871c15a2b837d35b614aeeb7326fbfa499f6a14ea5992326e8d901ad44c4758a5e7f8d21563e25d1cc5e78f0297", "reviewer": null, "report": {"paper_summary": "In this paper authors propose a neural singing voice beautifier (NSVB), which is based on conditional variational autoencoder (CVAE). It leverages shape-aware DTW (SADTW) for pitch correction, and latent-mapping for vocal tone improvement. NSVB supports semi-supervised learning, and a new dataset (PopBuTFy) is built. ", "summary_of_strengths": "This paper is technically sound, and it's clear written overall, with good experimental design and ablation study presented. ", "summary_of_weaknesses": "I feel the design of NVSB and some experimental results need more explanation (more information in the section below). ", "comments,_suggestions_and_typos": "1. In Figure 1, given experimental dataset have paired amateur and professional recordings from the same singer, what are the main rationals for (a) Having a separate timbre encoder module (b) SADTW takes outputs of content encoder (and not timbre encoder) as input? \n2. For results shown in Table 3, how to interpret: (a) For Chinese MOS-Q, NVSB is comparable to GT Mel A. (b) For Chinese and English MOS-V, Baseline and NVSB have overlapping 95% CI. "}, "scores": {"overall": "3.5 ", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "3 = Potentially useful: Someone might find the new datasets useful for their work.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "2 =  Willing to defend my evaluation, but it is fairly likely that I missed some details, didn't understand some central points, or can't be sure about the novelty of the work.", "sentences": {"paper_summary": [[0, 134], [134, 240], [240, 319]], "summary_of_strengths": [[0, 125]], "summary_of_weaknesses": [[0, 119]], "comments,_suggestions_and_typos": [[0, 3], [3, 267], [267, 271], [271, 452]]}}}, {"rid": "57d320091e15e914475e7958f56c78e446c7284e4da597a83bcab07a41c5521764163d098a74ebec5f7b5c02bf6aacd15944ae9b4e13d500222b555e956a7f8c", "reviewer": null, "report": {"paper_summary": "This paper proposes a novel task called singing voice beautifying, the task of improving of quality of amuteur singing performance. It includes two subtasks, automatic pitch correction and vocal tone modification. To solve this challenge, they propose a conditional variational autoencoder with adversarial training to perform singing beautifying. During inference, they also propose shape-aware dynamitc time warping to better align parallel pitch contours. To validate the model, two datasets in both Chinese and English songs were collected from professional singers.  While most neural singing models focus on automatic pitch correction, the authors also extend their model to modify vocal tone and achieves good performance. This is a contribution to the field of modeling singing. The singing dataset in two languages, if released, will be helpful for singing researchers, as singing datasets are rare. In my opinion, this is a solid work.\nThe writing is mostly clear and concise. While some sections are technical and dense, they are accessible to researchers in speech processing in general. The model details are thoroughly described and the actual parameters can be found in source code. ", "summary_of_strengths": "- The task is novel and the proposed solution is effective. Based on the evaluation results and the given audio samples, the proposed method significantly improves the quality of amuteur singing. Furthermore, the model has been evaluated in two languages, Chinese and English, strengthening their arguments.  - The authors have performed extensive evaluation using a variety of metrics, including both objective measures and subjective measures from trained singers.  - This study is open and transparent. The authors have provided code and singing samples, which is helpful for understanding and assessing the proposed method. They also promise to release the data later. ", "summary_of_weaknesses": "I see no major weaknesses. But there are some minor issues that could be improved.\n-  The description of the dataset is incomplete. It will be helpful to describe some demographic information of the singers in the dataset, such as gender and age range. What is the percetange of male and female singers? Are English songs recorded by native speakers? Male and female singers may pose slightly different challenges, so it will be good to know this. \n - Have the forced alignment results been manually checked? Montreal Forced Aligner works well with modal speech but may not work well on singing. Will this affect the evaluation results? ", "comments,_suggestions_and_typos": "- Figure 4 is not easy to interpret. All pitch contours are mixed together. Is it possible to hightly the specific areas where DTW and CTW make errors? In this way it will be easier to spot the errors and validate the alignment result.  - The same for Figure 3. Since this is a new distance measure, it might not be familiar to readers. It will be immensely helpful if a numerical example could be provided. For example, this could be \"if a points falls into region n with an angle of 30 degree, what is the numerical distance between this point and the anchor point?\" ", "ethical_concerns": "The authors have provided a list of ethical considerations in the Appendix. Based on their provided answers, I do not see any ethical concerns. "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "5 = They could easily reproduce the results.", "datasets": "4 = Useful: I would recommend the new datasets to other researchers or developers for their ongoing work.", "software": "4 = Useful: I would recommend the new software to other researchers or developers for their ongoing work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 132], [132, 214], [214, 348], [348, 459], [459, 571], [571, 572], [572, 730], [730, 787], [787, 909], [909, 946], [946, 987], [987, 1100], [1100, 1198]], "summary_of_strengths": [[0, 60], [60, 196], [196, 308], [308, 309], [309, 467], [467, 468], [468, 506], [506, 628], [628, 673]], "summary_of_weaknesses": [[0, 27], [27, 83], [83, 132], [132, 253], [253, 304], [304, 351], [351, 448], [448, 509], [509, 596], [596, 637]], "comments,_suggestions_and_typos": [[0, 37], [37, 76], [76, 152], [152, 236], [236, 237], [237, 262], [262, 337], [337, 408], [408, 569]], "ethical_concerns": [[0, 76], [76, 144]]}}}]