[{"rid": "282e34a96199086b581966dd4a855eb2daf42c4ee4338aee07c67ce21133ed2d7057e272cf0d69be13a2ec564e095fd0c05a2bc11a4879e8ae88c2deaadd2722", "reviewer": "Rujun Han", "report": {"paper_summary": "This paper uses extensive empirical experiments to study the impact of \"temporal misalignment\" on pretrained language models, across different tasks, domains, and specific time periods. ", "summary_of_strengths": "1. Research questions are well defined and have been consistent throughout the paper 2. A large number of experiments are conducted to answer research questions ", "summary_of_weaknesses": "1. Usefulness. we know very well at this point that PTLMs' performances degrade when data distribution shifts; we also know that the magnitude of degradation depends on tasks, domains, or even different models themselves. Time, as an important way to change data distribution, certainly will have that impact as many previous studies show (cited). I think this type of study is valuable, but what could elevate the paper is to propose new methods to mitigate them. The paper tries to slice data and run experiments on top of that. But I think that's likely the initial steps most researchers would do and hardly provide new directions on how to address the problem more effectively. I recommend the authors to look at some earlier works on the drift of meaning in word embedding such as \"Dynamic Embeddings for Language Evolution\" and \"Conditional Word Embedding and Hypothesis Testing via Bayes-by-Backprop,\" and see if there are possibilities to incorporate or even invent new methods to address the issue. \n2. Novelty. \n    - methods/models. The authors can look into more novel ways to address the issue as opposed to \"re-implementing\" similar studies on more data (which I appreciate, but doesn't quite contribute to novelty). \n    - metrics. F1, ROUGE, perplexity, and uni-gram overlaps are reasonable, but there are more creative and helpful metrics to measure the impact of time. Again, please look at the suggested papers above. \n3. Experimental setup. \n    - it doesn't quite make sense to me to train on future data and test on the past. In practice, we cannot go back in time. I suggest using a typical time-series forecasting set-up, that is, using a sliding window of historical data for training and test on later ones. \n    - try more PTLMs rather than just GPT2. ", "comments,_suggestions_and_typos": "Please see my comments above, additionally, 1. Line 070: Section 3.1 and then Section 3.2? \n2. Section 2.4: can move data descriptions to the appendix or shorten them. Doesn't really offer much insight. \n3. Line 190 - 191: define t1 < t2 as I suggested above and simplify the equation. \n4. Line 352: move label drift studies to the main text as they are helpful information. "}, "scores": {"overall": "2 = Borderline: This paper has some merit, but also significant flaws. It does not warrant publication at top-tier venues, but might still be a good pick for workshops.", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "2 = Documentary: The new datasets will be useful to study or replicate the reported research, although for other purposes they may have limited interest or limited usability. (Still a positive rating)", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Rujun Han, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 186]], "summary_of_strengths": [[0, 3], [3, 88], [88, 161]], "summary_of_weaknesses": [[0, 3], [3, 15], [15, 222], [222, 348], [348, 465], [465, 531], [531, 683], [683, 1009], [1009, 1013], [1013, 1022], [1022, 1045], [1045, 1232], [1232, 1248], [1248, 1388], [1388, 1438], [1438, 1442], [1442, 1462], [1462, 1549], [1549, 1589], [1589, 1735], [1735, 1780]], "comments,_suggestions_and_typos": [[0, 47], [47, 91], [91, 95], [95, 168], [168, 203], [203, 207], [207, 286], [286, 290], [290, 375]]}}}, {"rid": "0ee868efd9c31fe0c5e7ff1b9353523f40b8ff4e822cb66a2b2ebaaa3c12c53dbad6bf31751a9b0e80df90870ebb72813027df6b3ae5f9f8eebece2066002820", "reviewer": null, "report": {"paper_summary": "This paper deals with the temporal misalignment problem, which occurs when an NLP model is trained on a dataset created from data of a certain time period and tested/used for data of another time period. \nThis paper discusses the temporal misalignment problem through experiments on a number of NLP tasks with temporal misalignment. For that, TD, a metric for temporal degradation (of the task performance), is defined and used. \nThe paper presents some findings about the temporal misalignment problem, such as answers to \"how does sensitivity to temporal misalignment vary with text domain and task?\" \nThe paper brings NLP community's attention to the temporal misalignment problem. ", "summary_of_strengths": "Firstly, the paper is beneficial to the NLP community, since it will bring NLP community's attention to the temporal misalignment problem. This is particularly important because currently people in this community extensively use the pretraining-DAPT-finetuning paradigm. \nThe arguments in the paper are supported by comprehensive experiments with a number of tasks. \nThe paper is well-written and well-organized. ", "summary_of_weaknesses": "The problem caused by difference in training data and test data has been studied, although they might not focus on \"temporal\" aspect. \nThere are a number of papers, where terms like \"covariate shift\", labeling adaptation, and instance adaptation (e.g., Jiang and Zhai (2007) and Shimodaira (2000). See below). It would be interesting to see the connection between the arguments of the current paper and such papers.\n- Jiang and Zhai. Instance Weighting for Domain Adaptation in NLP. ACL. 2007.\n- Hidetoshi Shimodaira. 2000. Improving predictive inference under covariate shift by weighting the loglikelihood function. Journal of Statistical Planning and Inference, 90:227–244.\nTD score is defined in Section 2.3, but there is no intuition or justification about why it is defined like this, at least in the same section. Descriptions about intuition can be found in the later sections, so this is simply a matter of organization of the paper.  It is not clear whether TD scores for different performance metrics can be compared with each other, across different tasks. There should be a discussion on the justification (or maybe limitation).\nSome specific examples of temporal misalignment would help readers understand the paper, if they (the examples) are presented in Introduction. ", "comments,_suggestions_and_typos": "D in the text body should be in italic, consistently. "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "4 = Useful: I would recommend the new datasets to other researchers or developers for their ongoing work.", "software": "4 = Useful: I would recommend the new software to other researchers or developers for their ongoing work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 204], [204, 333], [333, 429], [429, 603], [603, 685]], "summary_of_strengths": [[0, 139], [139, 271], [271, 366], [366, 413]], "summary_of_weaknesses": [[0, 134], [134, 298], [298, 310], [310, 416], [416, 434], [434, 483], [483, 488], [488, 494], [494, 518], [518, 524], [524, 618], [618, 677], [677, 821], [821, 943], [943, 944], [944, 1069], [1069, 1142], [1142, 1285]], "comments,_suggestions_and_typos": [[0, 54]]}}}]