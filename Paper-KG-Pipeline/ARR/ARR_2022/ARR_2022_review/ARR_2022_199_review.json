[{"rid": "bc60bb1f59b42e9cc5c2accb893ee5d9795e07250fbc9a50ced0d9ca8d8bcc474b75ca8e2147cd3457dbfe70635e85f805885a281e0698c2f8cc83c8cd85487e", "reviewer": "Sungdong Kim", "report": {"paper_summary": "This paper proposes “Show, Don’t Tell” (SDT), which frames an example dialogue as a prompt for describing schema to the DST model. Unlike previous works using descriptions of given schema, The SDT uses an example dialogue that consists of context and prompt based on the schema. The experimental results show that the SDT-based models perform strongly on SGD and MultiWOZ cross-domain benchmarks. Moreover, the SDT-based models consistently outperform their baselines in various model sizes and show data efficiency and robustness. ", "summary_of_strengths": "- Simple modifications but strong results - Especially, they propose optimal input representation of API schema compared to other description-based baselines - Various analyses ", "summary_of_weaknesses": "- Creating/Selecting a dialogue containing all slots is not easy when the dialogue is especially in multi-domains. \n  - In multi-domain dialogue, the length of dialogue is often long and the information of schema is more complex. \n  - To encode whole information for the long and complex dialogue, there is another challenge regarding sequence length.\n- Moreover, the long token length of the SDT prompt yields computational complexity.\n- Limited analysis on the number of dialogue examples. ( I think it is hard to increase the number of example dialogues for the same reason.) ", "comments,_suggestions_and_typos": "- LLMs in Section 6: Did you mean the Large Language Model? I think it is not a normal expression.\n- How do the SDT prompts work on in-context learning? ( one-shot inference without gradient update using GPT-3.) "}, "scores": {"overall": "3.5 ", "best_paper": "No", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Sungdong Kim, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 131], [131, 279], [279, 397], [397, 532]], "summary_of_strengths": [[0, 42], [42, 158], [158, 177]], "summary_of_weaknesses": [[0, 115], [115, 230], [230, 352], [352, 437], [437, 494], [494, 579]], "comments,_suggestions_and_typos": [[0, 60], [60, 99], [99, 155], [155, 212]]}}}, {"rid": "0eaf565a3017cb950e6ad3cc1cf20ffc3f9a011b99b1fd470e9e0aff5d82fcf026449c5a69b152b89b7bebc2c184e3832f04cbaf8cd8ca2ad0ba0c990d67e869", "reviewer": null, "report": {"paper_summary": "This paper proposed to use a single dialog example(for per service or slot) to form an example-based prompt for schema-guided dialog state tracking. Based on T5 seq2seq fine-tuning, they compared the example-based prompt with the previous description-based prompt. The evaluation is based on two schema-guided datasets: SGD and MultiWOZ-leave-one-out, and two SOTA models for schema-guide dialog: T5-ind and T5-seq. The results showed that although the example-based prompt will take more annotation time, using example-based prompt, the fine-tuned seq2seq model will lead to better generalization to new APIs, more data-efficient, and robust to schema variations. However, some details are missing and some ablation studies are not well-designed. ", "summary_of_strengths": "On the specific schema-guided dialog state tracking task, compared to the description-based prompt, the proposed example-based prompt can generalize better to new APIs, more data-efficient and more robust to schema variation. \nThe idea of using example-based prompt for seq2seq fine-tuning seems simply focused and promising, which can be used for other seq2seq dialog state tracking settings, and may also be extended to other dialog tasks. ", "summary_of_weaknesses": "1. Some of the details and analysis are not clear, please see comments 1,2,3,4 2. Some of the ablation studies are unclear or problematic. See comments 5,6 ", "comments,_suggestions_and_typos": "1. line 130, It is confusing why SGD dataset requires manually created dialog examples for prompts; But for MultiWOZ, it just chooses the example from the training set. please explain why. \n2. line 175 seems lacking of experimental results to support it. \n3. line 121, the paper lacks details for how to design and use prompts for dialog with multi-domains/services. According to line 140,  I only can guess it split the dialog state with multi-domain/service into separate examples, correct? please explain more. If possible, please show some examples in the Appendix for easy understanding. \n4. Error analysis in 5.2 is crappy, more quantitive error analysis will help. \n5. Table 5, the models above the line are using slot descriptions, while the SDT-seq is using name only. It seems they are not directly comparable. Although we may guess that description is more robust than name or slot-IDs, as shown in previous works[1,2]. Please explain more, and also list all name-based results on SGD-X. 6. line 165, finetuning T5-seq with prompt examples is meaningless given there are only #services new examples in prompt. Instead, for the combination of using description + example, could you simply append those example-based prompt after description-based prompt.  This new experiment will help to show how the interesting combination will help.   [1]Cao, Jie, and Yi Zhang. \" A Comparative Study on Schema-Guided Dialogue State Tracking.\" Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. 2021. \n[2]Lee, H., Gupta, R., Rastogi, A., Cao, Y., Zhang, B. and Wu, Y., 2021. SGD-X: A Benchmark for Robust Generalization in Schema-Guided Dialogue Systems. arXiv preprint arXiv:2110.06800.\n7. The model names T5-ind, T5-seq are misleading. Maybe using Desc-ind/seq, Eg-ind,Demo-ind/seq? "}, "scores": {"overall": "3.5 ", "best_paper": "No", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "3 = From the contents of the submission itself, I know/can guess at least one author's name.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 149], [149, 265], [265, 416], [416, 665], [665, 748]], "summary_of_strengths": [[0, 226], [226, 442]], "summary_of_weaknesses": [[0, 3], [3, 82], [82, 139], [139, 156]], "comments,_suggestions_and_typos": [[0, 3], [3, 169], [169, 189], [189, 193], [193, 255], [255, 259], [259, 367], [367, 493], [493, 514], [514, 593], [593, 597], [597, 672], [672, 676], [676, 778], [778, 821], [821, 931], [931, 1002], [1002, 1121], [1121, 1265], [1265, 1347], [1347, 1349], [1349, 1378], [1378, 1441], [1441, 1585], [1585, 1591], [1591, 1665], [1665, 1745], [1745, 1778], [1778, 1781], [1781, 1828], [1828, 1875]]}}}]