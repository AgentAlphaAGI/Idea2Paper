[{"rid": "bd9e1f80c81f4619d7b93cff38f4ca9e4642566c30cfbbd2b934b29262b4770edd6afc39af1d95c895d124f3b8631b150c371e4af90609ab6780222f71ce8fdd", "reviewer": null, "report": {"paper_summary": "The paper suggests an alternative to attention that achieves similar results but with less electricity used. ", "summary_of_strengths": "The results seem convincing. The work seems novel and the contribution and writing clear. ", "summary_of_weaknesses": "The method helps in (theoretical?) energy consumption, but does not improve speed as GPUs do not benefit from this change. ", "comments,_suggestions_and_typos": "fixed from last version "}, "scores": {"overall": "4.5 ", "best_paper": "No", "replicability": "5 = They could easily reproduce the results.", "datasets": "1 = No usable datasets submitted.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 109]], "summary_of_strengths": [[0, 29], [29, 90]], "summary_of_weaknesses": [[0, 35], [35, 123]], "comments,_suggestions_and_typos": [[0, 24]]}}}, {"rid": "76fefdb3e81da2f7716b8344c65529682fb601fcb30e512c2cd264ba8ed875ec02276778ccc7af3cccaee247a4ebbe436135b5b6b5c57316eb6122eb6698f404", "reviewer": "Hongfei Xu", "report": {"paper_summary": "This paper presents 2 approaches to removing multiplication computation in the popular Transformer attention: 1) binary quantization of attention inputs, and 2) the use of L1 norm to compare between queries and keys. Experiments show that their approach can lead to lower energy consumption in the attention module with some losses in performance. For its weaknesses: 1. it utilizes quantization technology but does not compare with the other quantization approaches. \n2. there is still a softmax computation left in the presented approach. \n3. energy consumption is only estimated within the attention module, even though the reduction in a Transformer block is added (17%), the reduction of the full model (with the classifier) is not reported. I have concerns that the overall reduction may not be sufficiently significant. \n4. L1 norm between vectors of 2 matrices needs a high memory cost than the matrix multiplication. \n5. experiments were performed on 3 language pairs with the base setting, I wonder whether the approach can perform well in challenging settings (Transformer Big and deep Transformers). \n6. the maximum performance loss (- 0.78 BLEU) might be a significant loss. ", "summary_of_strengths": "This paper presents 2 approaches to removing multiplication computation in the popular Transformer attention: 1) binary quantization of attention inputs, and 2) the use of L1 norm to compare between queries and keys. Experiments show significantly lower energy consumption with few losses in performance. ", "summary_of_weaknesses": "1. it utilizes quantization technology but does not compare with the other quantization approaches. \n2. there is still a softmax computation left in the presented approach. \n3. energy consumption is only estimated within the attention module, even though the reduction in a Transformer block is added (17%), the reduction of the full model (with the classifier) is not reported. I have concerns that the overall reduction may not be sufficiently significant. \n4. L1 norm between vectors of 2 matrices needs a high memory cost than the matrix multiplication. \n5. experiments were performed on 3 language pairs with the base setting, I wonder whether the approach can perform well in challenging settings (Transformer Big and deep Transformers). \n6. the maximum performance loss (- 0.78 BLEU) might be a significant loss. ", "comments,_suggestions_and_typos": "It's recommended to report the overall energy reduction of the full model, conduct experiments on more language pairs and with the big setting on a few of them. "}, "scores": {"overall": "2.5 ", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Hongfei Xu, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 217], [217, 348], [348, 371], [371, 468], [468, 472], [472, 541], [541, 545], [545, 747], [747, 827], [827, 831], [831, 926], [926, 930], [930, 1112], [1112, 1116], [1116, 1188]], "summary_of_strengths": [[0, 217], [217, 305]], "summary_of_weaknesses": [[0, 3], [3, 100], [100, 104], [104, 173], [173, 177], [177, 379], [379, 459], [459, 463], [463, 558], [558, 562], [562, 744], [744, 748], [748, 820]], "comments,_suggestions_and_typos": [[0, 161]]}}}]