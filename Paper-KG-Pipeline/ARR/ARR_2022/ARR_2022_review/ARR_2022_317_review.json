[{"rid": "0113a9cd1e940411099dd650e752e34811f84ffc8cc9edb39dd3714c0e4bfad9b97c1d84f1d0c9d051f46de849a337f834dc3be749bb6d4afa3bc0393cd0ae18", "reviewer": "Arjun Reddy Akula", "report": {"paper_summary": "The authors propose an evaluation framework that probes video-text models with hard negatives. Specifically, they introduce an automated pipeline that can generate contrast sets via verb and human entity manipulation that change semantics of the textual description. In addition, the authors also collect human generated contrast sets to compare with the automatic ones. Evaluation of several video-text models on the proposed contrast sets demonstrate that the existing models show a drop in model performance (on verb antonym swaps, etc). ", "summary_of_strengths": "1) The paper is well-written and well-organized.\n2) The automatic construction of contrast sets is  interesting and nicely motivated.  3) Experiments sufficiently demonstrate the utility of the proposed contrast sets. ", "summary_of_weaknesses": "1) In section 3.1, authors mentioned that they swap gender of a person in MSR-VTT dataset. But after changing gender, how do you make sure that the sentence is still relevant for the video (for example, you might replace the word “woman” with “man”. But if the video doesn’t contain man, the sentence might become irrelevant)? Is my understanding correct?\n2) The contrast set generation discussed in section 3.3 is not very clear and the readability could be improved. For example, I did not understand as to why finetuning T5 helps in mitigating distribution shifts? Some intuition/justification could help readers to follow the key idea. \n  3) The following work is also very relevant and could be added to the related work section: Akula, A. R., Gella, S., Al-Onaizan, Y., Zhu, S. C., & Reddy, S. (2020). Words aren't enough, their order matters: On the Robustness of Grounding Visual Referring Expressions. arXiv preprint arXiv:2005.01655. ", "comments,_suggestions_and_typos": "See Weaknesses "}, "scores": {"overall": "3.5 ", "best_paper": "No", "datasets": "4 = Useful: I would recommend the new datasets to other researchers or developers for their ongoing work.", "software": "3 = Potentially useful: Someone might find the new software useful for their work."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Arjun Reddy Akula, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "5 = Positive that my evaluation is correct. I read the paper very carefully and am familiar with related work.", "sentences": {"paper_summary": [[0, 95], [95, 267], [267, 371], [371, 541]], "summary_of_strengths": [[0, 49], [49, 134], [134, 135], [135, 218]], "summary_of_weaknesses": [[0, 91], [91, 250], [250, 327], [327, 356], [356, 469], [469, 568], [568, 640], [640, 735], [735, 808], [808, 911], [911, 944]], "comments,_suggestions_and_typos": [[0, 15]]}}}, {"rid": "0d113b5b1f7e15d2596e5b18691e08a3b53b1ab2b08c31abde3996a9b1f3b0b22a3c8248b23f97199865c4e3b5e4bf22e419f7ae79846384359ca2482a417473", "reviewer": null, "report": {"paper_summary": "The paper presents an evaluation framework that probes state of the art video-text retrieval and multiple choice models (CLIP and Multi-modal Transformer based) on MSR-VTT and LSMDC. The authors build a pipeline that automatically creates contrast sets, meaning that video captions are manipulated to change their semantics while maintaining plausibility. The contrast sets are created by swiping the gender of a person or using pre-trained LMs to replace verb phrases with top K most probable phrases. They also use AMT to create human generated contrast sets and ask humans to evaluate if the automated contrast sets are valid. \nThe results show that the models performance drops significantly on contrast sets compared to original setting (the random negatives). They also show that model performance is strongly correlated with semantic proximity and stronger retrieval performance does not guarantee robustness to word-level manipulation. ", "summary_of_strengths": "The process of creating the contrast sets is clear, easy to implement and well explained. \nThe paper evaluates strong state of the art models for  video-text retrieval and multiple choice models (CLIP and Multi-modal Transformer based) on specialized datasets (MSR-VTT and LSMDC). \nThe conclusions seem to be of interest for the community and can stimulate useful future work directions. ", "summary_of_weaknesses": "Missing explanations about why the models found the automately generated contrast sets more difficult than the human contrast sets. Humans still perform well on both cases, but more analysis on why the automatic sets are difficult would be interesting. \nOverall, the results require more analysis, but for a short paper it could be enough. \nMy opinion is that this short paper could be organized better in a long paper by including the information about annotations and contrast set construction from the appendix, together with more analysis and ablations. ", "comments,_suggestions_and_typos": "N/A ", "ethical_concerns": "As stated by the authors in section 6, using a large LM is a source of bias which could propagate into their negative samples. "}, "scores": {"overall": "4 = This paper represents solid work, and is of significant interest for the (broad or narrow) sub-communities that might build on it.", "best_paper": "No", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 183], [183, 356], [356, 503], [503, 630], [630, 766], [766, 944]], "summary_of_strengths": [[0, 90], [90, 281], [281, 388]], "summary_of_weaknesses": [[0, 132], [132, 253], [253, 340], [340, 558]], "comments,_suggestions_and_typos": [[0, 4]], "ethical_concerns": [[0, 127]]}}}, {"rid": "d62d5c48321ea6327e71bf859c5cd6dd2ec557d2f79e69a6bc0bd38913c2d9ac1096e49aaf39d2bb6993f971a2e44b03ed5acc0e136cd004a1992952727e7535", "reviewer": "Saneem Ahmed Chemmengath", "report": {"paper_summary": "This paper is about evaluating video retrieval methods or video tagging methods by perturbing text inputs, kind of like how adversarial attacks work. The idea is to take the text input and replace words which is connected to person entities and verbs and make changes so the text doesn't describe the video anymore. Person entity replacements is done using rule based methods very specific to the dataset considered, for instance changing character names in text describing movie clips and flipping gender terms in other videos. To change the verb (or the action) in the text, a masked language model is used to find good replacements for verb phrases. Results shows that existing models fail on such adversarial attacks to an extent. ", "summary_of_strengths": "- Probably the first paper on adversarial attacks on Video-text models.\n- Text perturbations are indeed confusing the models.  - It is well written paper. Easy to understand even for a person who is not really working in this particular sub-area. ", "summary_of_weaknesses": "- Lack of novelty:    - Adversarial attacks by perturbing text has been done on many NLP models and image-text models. It is nicely summarized in related work of this paper. The only new effort is to take similar ideas and apply it on video-text models. \n  - Checklist (Ribeiro et. al., ACL 2020) had shown many ways to stress test NLP models and evaluate them. Video-text models could also be tested on some of those dimensions. For instance on changing NER. ", "comments,_suggestions_and_typos": "- If you could propose any type of perturbation which is specific to video-text models (and probably not that important to image-text or just text models) will be interesting to see. Otherwise, this work, just looks like a using an already existing method on this new problem (video-text) which is just coming up.\n- Is there a way to take any clue from the video to create harder negatives. "}, "scores": {"overall": "2.5 ", "best_paper": "No", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Saneem Ahmed Chemmengath, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "2 =  Willing to defend my evaluation, but it is fairly likely that I missed some details, didn't understand some central points, or can't be sure about the novelty of the work.", "sentences": {"paper_summary": [[0, 150], [150, 316], [316, 529], [529, 653], [653, 735]], "summary_of_strengths": [[0, 72], [72, 126], [126, 127], [127, 155], [155, 247]], "summary_of_weaknesses": [[0, 119], [119, 174], [174, 254], [254, 282], [282, 362], [362, 430], [430, 460]], "comments,_suggestions_and_typos": [[0, 183], [183, 314], [314, 391]]}}}]