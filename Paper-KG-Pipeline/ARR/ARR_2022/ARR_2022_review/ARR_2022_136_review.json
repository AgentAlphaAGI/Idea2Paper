[{"rid": "05c12a27fe5e8b542d89f4fceb4fdf4123059a7e59667628f54495b207535f7043c225a31b2f645e0c4b4bca553fcc7101b3d413ef2d96ba680810c986b7140e", "reviewer": null, "report": {"paper_summary": "The paper \"CBLUE: A Chinese Biomedical Language Understanding Evaluation Benchmark\" presents a benchmark of eight diverse tasks to benchmark models for BioNLP in Chinese. \nThe authors report results of 11 different PLMs and compare them to human performance. \nThe results show that there is still a performance gap between humans and NLP models. ", "summary_of_strengths": "- The authors present a diverse benchmark for BioNLP in Chinese, comprising eight different data sets.  - The benchmark comes with a rich ecosystem of baselines, a submission system and a leaderboard.\n- The authors present an extensive evaluation of different PLMs and give human baseline results. ", "summary_of_weaknesses": "- I am not quite clear on which datasets were produced by the authors and which were prior work. I feel this should be described in more detail in the paper.  - What is the source on the amount of Chinese speakers? statista claims it's 16% of the world's population (https://www.statista.com/chart/12868/the-worlds-most-spoken-languages/).\n- References to the supplementary material/appendix are missing in the main text and should be inserted in the appropriate locations. This is especially important for the data set details, as these are missing from the main text. ", "comments,_suggestions_and_typos": "- L236: Acronym IRB was not introduced - L460: specficanti-toxin -> specific anti-toxin - Alibaba QUAKE is sometimes spelled Alibaba KUAKE, is this on purpose? ", "ethical_concerns": "The paper is not very clear on the anonymisation process. I think this should be expanded in greater detail to make sure that deanonymisation is not possible. "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "4 = Useful: I would recommend the new datasets to other researchers or developers for their ongoing work.", "software": "4 = Useful: I would recommend the new software to other researchers or developers for their ongoing work."}, "meta": {"license": "Copyright Â© 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "3 = From the contents of the submission itself, I know/can guess at least one author's name.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 171], [171, 259], [259, 346]], "summary_of_strengths": [[0, 103], [103, 104], [104, 201], [201, 298]], "summary_of_weaknesses": [[0, 97], [97, 158], [158, 159], [159, 215], [215, 340], [340, 474], [474, 570]], "comments,_suggestions_and_typos": [[0, 39], [39, 88], [88, 160]], "ethical_concerns": [[0, 58], [58, 159]]}}}]