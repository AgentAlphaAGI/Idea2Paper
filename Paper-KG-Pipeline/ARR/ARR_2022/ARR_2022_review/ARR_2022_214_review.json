[{"rid": "ce03d3f5478b63fb93afb36511e6351b6ff4025b36f141e7cb937b75334b2707979dfdbe46d9a6b21421cebf387320b5cb4a780a2119f05f6b4a02ffdef2d2e9", "reviewer": "Chao Shang", "report": {"paper_summary": "This paper proposes a simple and new random intermediate layer knowledge distillation approach (RAIL-KD). The main point is to select the intermediate layers from the teacher model randomly which are distilled to the corresponding student layers. Here all layers are taken into the training without any additional parameters. So it could avoid skip and search problem and reduce the computational cost of intermediate layer distillation. The whole idea is interesting and straightforward. It is great to have many analyses in the experiments. However, I have some concerns about the performance. ", "summary_of_strengths": "1.This paper presents a new intermediate layer knowledge distillation approach with performance improvement and low computational cost.  2.This paper adds some comparisons of the current ILD methods about the efficiency and performance. The proposed RAIL-KD has a less computational overhead.  3.In the experiments, authors compare different distillation methods under many challenge datasets. ", "summary_of_weaknesses": "1.Adding the random selection is not a new idea. The randomness of the layer selection could cause the unstable of performance. It is better to show more results such as the convergence analysis. Random selection might not be the best option here.\n2.The performance is not convincing. The improvements under some settings are not significant.  3.The new approach could not find the best subset (subset mapping) since the proposed model just selects m layers randomly. But it is not clear if we should ignore it or solve it later. From my opinion, the attention-based approaches with best mapping search may achieve better performance. ", "comments,_suggestions_and_typos": "The whole approach lacks the evidences to prove the usefulness. Comparing to ALP-KD, the improvement is not significant. "}, "scores": {"overall": "2.5 ", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "2 = Documentary: The new datasets will be useful to study or replicate the reported research, although for other purposes they may have limited interest or limited usability. (Still a positive rating)", "software": "2 = Documentary: The new software will be useful to study or replicate the reported research, although for other purposes it may have limited interest or limited usability. (Still a positive rating)"}, "meta": {"license": "Copyright Â© 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Chao Shang, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design.", "sentences": {"paper_summary": [[0, 106], [106, 247], [247, 326], [326, 438], [438, 489], [489, 543], [543, 596]], "summary_of_strengths": [[0, 136], [136, 137], [137, 237], [237, 293], [293, 294], [294, 394]], "summary_of_weaknesses": [[0, 49], [49, 128], [128, 196], [196, 248], [248, 285], [285, 343], [343, 344], [344, 468], [468, 530], [530, 635]], "comments,_suggestions_and_typos": [[0, 64], [64, 121]]}}}]