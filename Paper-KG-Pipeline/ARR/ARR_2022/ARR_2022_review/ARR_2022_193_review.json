[{"rid": "3c3db4456aa5e9fedcb53f5e23389e6a7acbae10b2a9f0be318d0b0f874059c2ef715419968685cf8112022bf8fdbab4471b32a744d722f68d48b13f0e17230d", "reviewer": "Yanghui Rao", "report": {"paper_summary": "This paper used chi-squared measures, t-statistics, and raw frequency to build a token merging pre-processing step, in order to improve the results of LDA in languages without marked word boundaries. It is valuable to leverage collocations for languages without marked word boundaries (e.g., Chinese and Thai), and the experimental results indicated positive contributions of token emerging. However, this paper only compared the proposed approaches with LDA, without employing the existing similar approaches, e.g., the methods proposed in (Lau et al., 2013), as baselines. Besides, the related work section is quite sketchy. ", "summary_of_strengths": "1. The experiments were conducted on 7 languages, which was valuable to test whether representing bigrams collocations in the input could improve topic coherence or not in general. \n2. The experimental results indicated that the t-statistic and raw frequency approaches for token merging could improve the topic modeling results across 7 languages. ", "summary_of_weaknesses": "1. The descriptions of several important sentences are unclear, e.g., in “For all languages, we use the reduced version of Wikipedia database”, it is suggested to provide the links to the reduced version of Wikipedia database for all languages (except for English). To evaluate the influence of these large collocation training corpora, it is also suggested to compute the collocation measures for all bigrams on each document collection (i.e., without any external corpora). \n2. Figure 1 should be illustrated in more details. Why only show the results of three languages in Figure 1? Are the results of other languages consistent with these three languages? \n3. The related work section is quite sketchy. There are limited reviews on collocations and topic models in recent years. One of the relevant early studies was cited, i.e., (Lau et al., 2013), in which, Lau et al. compared topic models learned from unigram bag-of-words data, with topic models learned from bag-of-words data that includes preextracted bigram collocations. As shown in (Lau et al., 2013), they considered four different bigram replacement methods. Particularly, they first extracted bigrams for each document collection using the N-gram Statistics Package, identifying the top bigrams based on the Student’s t-test. Then, they used the top 1k, 10k, and 100k as the three different bigram replacement methods. Unfortunately, the above method was not employed as the baseline in this study, in order to validate the effectiveness of using large collocation training corpora to compute the collocation measures for all bigrams. ", "comments,_suggestions_and_typos": "1. The presentation can be improved, e.g., “To train word embeddings” (line 298) and “to obtain word embeddings” (line 301) are repetitive. \n2. The reference (El-Kishky et al., 2014) had been published at Proc. VLDB Endow. 8(3): 305-316 (2014). Besides, the information of reference (Merity et al., 2016) are incomplete. "}, "scores": {"overall": "2 = Borderline: This paper has some merit, but also significant flaws. It does not warrant publication at top-tier venues, but might still be a good pick for workshops.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Yanghui Rao, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 200], [200, 392], [392, 575], [575, 627]], "summary_of_strengths": [[0, 3], [3, 181], [181, 185], [185, 349]], "summary_of_weaknesses": [[0, 3], [3, 266], [266, 476], [476, 480], [480, 528], [528, 586], [586, 660], [660, 664], [664, 707], [707, 783], [783, 1034], [1034, 1125], [1125, 1293], [1293, 1386], [1386, 1602]], "comments,_suggestions_and_typos": [[0, 3], [3, 140], [140, 144], [144, 211], [211, 223], [223, 245], [245, 321]]}}}]