[{"rid": "e2d151b750ec5e241745db142043e4adaec8f5c39797faddbd71d9009424bf3570efe116b26bd3a2aa9f4bbbdaf1cbab1d492289e2fab4fb1ac545a21aa1f990", "reviewer": null, "report": {"paper_summary": "This paper borrows a idea from the optimal transport problem to propose a framework for evaluating and interpreting semantic textual similarity (STS). The authors use token-wise similarity from pre-trained language models, which differs their method from the previous sentence-wise comparisons between representations, like SimCSE. The method is simple but performs well as it defeats SimCSE on most STS and all iSTS datasets. The authors then analyze their method is both efficient and interpretable for STS. ", "summary_of_strengths": "1. The method used in this paper is simple and interesting and it’s natural to utilize word-level similarity to textual similarity.  2. The main results and analyses verify the efficiency, interpretability, and strong performance of the method.  3. The paper has been structured well to answer my questions during the reading. The explanation for the main method has been well organized to help readers understand the algorithm with ease.\n4. There is a wide range of analyses that support the claims of the authors, making this work fairly solid. ", "summary_of_weaknesses": "1. The method in this paper is quite similar to BERTScore, but the authors have not cited that paper.\n2. Figure 2 does not show the time complexity of SimCSE_{CLS} method.\n3. I am confused about the definition of \"\\vec \\mathbf{1}\" in Equation(1). ", "comments,_suggestions_and_typos": "Missing citation: BERTScore: Evaluating Text Generation with BERT (Zhang et al. 2020) For other suggestions, please refer to the weakness section. "}, "scores": {"overall": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.", "best_paper": "No", "replicability": "3 = They could reproduce the results with some difficulty. The settings of parameters are underspecified or subjectively determined, and/or the training/evaluation data are not widely available.", "datasets": "1 = No usable datasets submitted.", "software": "1 = No usable software released."}, "meta": {"license": "Copyright © 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: None, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 151], [151, 332], [332, 427], [427, 510]], "summary_of_strengths": [[0, 3], [3, 132], [132, 133], [133, 136], [136, 245], [245, 246], [246, 249], [249, 327], [327, 439], [439, 442], [442, 547]], "summary_of_weaknesses": [[0, 3], [3, 102], [102, 105], [105, 172], [172, 175], [175, 247]], "comments,_suggestions_and_typos": [[0, 147]]}}}]