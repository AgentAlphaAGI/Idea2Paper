[{"rid": "a2dbb4d1f528e4c6c48a51354adb882d3af65dffe69005a325d024c09982fd4dc72e38f8af529d3c0d8145db9095fa881f644d51f888c58b24b952fe51374be4", "reviewer": "Sheng Shen", "report": {"paper_summary": "This work proposes a multi-modal contrastive learning objective to learn text representation based on both visual and text information. Extensive experiments have been provided to show the improvement of the proposed method on seven semantic textual similarity tasks. Besides, additional analyses show that the proposed method leads to better semantical alignment of the learned sentence representation. ", "summary_of_strengths": "- The paper is well-written and clearly presented;  - The idea of using visually grounded corpus to help learn sentence representation is well-motivated and novel. Extensive experiments (with random seeds) have been provided to show the significance of the proposed methods. Detailed ablation studies and analyses have also been provided to show the impact of dataset, pre-trained model and sub-tasks;  - The idea can be potentially scaled up to many noisy image-text pairs on the web. ", "summary_of_weaknesses": "- in Table 1, it seems using Flickr textual corpus only can bring improvement for SimCSE on downstream tasks but not for using COCO, is there a detailed explanation for this? ( also, will adding additional textual data, e.g. more Wikipedia texts bring similar improvement)?  - Tan and Bansal (2020) shows the significant difference between the image-text corpus and wiki corpus (small sentence length, usually less than 77 and so on.) But the dataset statistics have not been discussed here, wondering will become a problem or not for sentence representation learning. ", "comments,_suggestions_and_typos": "See above "}, "scores": {"overall": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.", "best_paper": "No", "replicability": "4 = They could mostly reproduce the results, but there may be some variation because of sample variance or minor variations in their interpretation of the protocol or method.", "datasets": "2 = Documentary: The new datasets will be useful to study or replicate the reported research, although for other purposes they may have limited interest or limited usability. (Still a positive rating)", "software": "4 = Useful: I would recommend the new software to other researchers or developers for their ongoing work."}, "meta": {"license": "Copyright Â© 2021 administered by the Association for Computational Linguistics (ACL)\n                                on behalf of ACL content contributors: Sheng Shen, and other contributors who wish to remain anonymous.\n                                Content is made available under a Creative Commons Attribution 4.0 International Public License.", "author_identity_guess": "1 = I do not have even an educated guess about author identity.", "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings.", "sentences": {"paper_summary": [[0, 136], [136, 268], [268, 404]], "summary_of_strengths": [[0, 52], [52, 164], [164, 275], [275, 403], [403, 486]], "summary_of_weaknesses": [[0, 177], [177, 274], [274, 275], [275, 435], [435, 569]], "comments,_suggestions_and_typos": [[0, 10]]}}}]