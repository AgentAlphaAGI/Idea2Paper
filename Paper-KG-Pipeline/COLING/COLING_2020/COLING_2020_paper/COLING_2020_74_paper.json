{
  "name" : "COLING_2020_74_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "SLICE: Supersense-based Lightweight Interpretable Contextual Embeddings",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The form-meaning association relating words to their senses is a fundamental component of language. Hence, the representation of the meaning of words is an important research question in computational linguistics. Processing word meaning allows interpreting larger units such as phases and sentences. Therefore, computational lexical semantics is, explicitly or implicitly, at the core of higher-level NLP tasks such as textual understanding, information extraction, and automatic summarisation.\nMuch effort has been put in the manual and semi-automatic construction of resources encoding lexical semantics (i.e., word meaning). These include semantic lexicons with inventories of possible senses that lexical units can assume, e.g., Wordnet (Miller et al., 1990) and Babelnet (Navigli and Ponzetto, 2012), as well as sense-annotated corpora specifying which of these senses are employed in context, e.g., SemCor (Landes et al., 1998) and Eurosense (Delli Bovi et al., 2017). Because fine-grained sense distinctions are generally hard to annotate and predict (Navigli, 2009), coarse-grained tagsets, referred to as supersenses, were proposed as alternatives (Ciaramita and Johnson, 2003; Schneider et al., 2016), with positive impact on downstream applications, e.g., (Agirre et al., 2011; Flekova and Gurevych, 2015).\nAlternatively, real-numbered vectors can encode contextual co-occurrence, acting as a proxy for a lexical unit’s semantics (Harris, 1954). This principle has guided the development of numerous distributional semantic models, that is, semantic vector representations inferred from corpus co-occurrences (e.g., Landauer and Dumais (1997)). Advances in neural networks shifted the focus of computational semantics to representation learning, so as to obtain vectors as by-products of neural networks (Mikolov et al., 2013). In this booming field, a myriad of models have emerged to encode sub-lexical information (Bojanowski et al., 2017), polysemy (Neelakantan et al., 2014), and context (Peters et al., 2018; Devlin et al., 2018). These models are efficiently learned from corpora, benefiting from high-performance neural architectures and libraries. Thus, vector representations, rebranded word embeddings, have become the dominant technique to represent lexical units, at the core of state-of-the-art neural approaches.\nTraditional static embeddings, such as word2vec and Fasttext, assume that each word’s meaning can be represented as a single vector, independently of its context. While generic and reusable, these models usually conflate the different meanings of a given unit into a single vector (Camacho-Collados and Pilehvar, 2018). Contextual models, such as ELMo, GPT-2, BERT, and their variants, encode each word’s\noccurrence as a context-dependent vector, assuming that each context corresponds to a different sense (Yarowsky, 1993). In short, while static models create one generic embedding per lexical unit, contextual models provide a fine-grained distinct representation for each occurrence. Both models, but especially the latter, are increasingly complex and opaque (Rogers et al., 2020), requiring advanced techniques to help humans understand their strengths and limitations (Jawahar et al., 2019; Serrano and Smith, 2019).\nGiven this landscape, we introduce SLICE: an alternative semantic model which represents a trade-off between interpretable symbolic senses, static and contextual word embeddings. We propose a weakly supervised technique to build dense low-dimensional embeddings whose dimensions represent coarsegrained semantic classes i.e., supersenses (Sec. 3). Our lightweight model embeds both lexical units and their contexts into the same semantic space. Thus, words and their contexts are represented as two compact vectors of directly interpretable scores, one per supersense, automatically learned from a non annotated corpus. Our embeddings are assessed in a word sense disambiguation (WSD) setting (Sec. 4). Thanks to the model’s interpretability, we are able to perform a rich linguistic analysis of WSD results, providing insightful results to understand the model’s predictions (Sec. 5)."
    }, {
      "heading" : "2 Related Work",
      "text" : "Our work is positioned at the crossroads of word and sense embeddings, interpretable semantic representations, and weakly supervised WSD. We briefly review a sample of relevant work on these topics.\nWord and sense embeddings The literature on vector-space semantic representations is enormous, ranging from traditional models such as LSA (Landauer and Dumais, 1997) to sophisticated deep contextualised embeddings such as BERT (Devlin et al., 2018). Although techniques are being constantly improved, the main principle is stable across models: vectors represent a word’s usage (and meaning) based on its distributional context (Harris, 1954). Embeddings have become commonplace in NLP, as they naturally represent input (words) in state-of-the-art neural models. Although they can be randomly initialised and learned, unsupervised pre-training on raw corpora is common (Turian et al., 2010).\nEmbeddings can be pre-trained as by-products of predictive neural language models (Mikolov et al., 2013), by factorisation of the co-occurrence matrix (Landauer and Dumais, 1997; Pennington et al., 2014), etc. Sub-lexical units (character n-grams) address linguistic variability, e.g., due to rich morphology, non-standard text, and out-of-vocabulary forms (Bojanowski et al., 2017). Most of the models prior to 2018 are static, assuming a single vector per word. These models suffer from meaning conflation, i.e., a single vector is created for ambiguous units, ignoring polysemous and multi-facet words.\nAdvances in neural networks triggered the development of contextual embeddings, with representations conditioned on the surrounding words. They can be obtained using stacked recurrent layers as in ELMo (Peters et al., 2018), or attention-based transformers as in BERT (Devlin et al., 2018) and GPT-2 (Radford et al., 2018). In addition to their outstanding performances, these models address meaning conflation: contexts correspond to (slightly) different senses and are modelled with a custom embeddings. On the downside, they are computationally heavy and opaque (Rogers et al., 2020), requiring sophisticated techniques such as probing to interpret predictions (Jawahar et al., 2019).\nParticularly relevant to our work are sense embeddings (Camacho-Collados and Pilehvar, 2018), in which a lexical unit is associated to several vectors (as in contextual models), but with some generalisation across occurrences (as in static models). Unsupervised sense (multi-prototype) embeddings can be obtained by adapting the objective of the learning procedure (Neelakantan et al., 2014), or with word sense induction methods based on clustering, e.g., Panchenko et al. (2017). For interpretability, resources such as WordNet can be used to semantically enhance static embeddings (Faruqui et al., 2015) or to learn representations for WordNet synsets (Rothe and Schütze, 2015), supersenses (Flekova and Gurevych, 2016), or Babelnet senses (Camacho-Collados et al., 2016).\nInterpretable semantic representations One of the most popular sense inventories in NLP is Wordnet (Miller et al., 1990), in which words are grouped into synsets and linked to each other via lexical-semantic relations (e.g., hypernymy, synonymy). For many years, the English Wordnet has been the basis of sense-annotated corpora (Landes et al., 1998) and WSD research (Navigli, 2009). Babelnet (Navigli and\nPonzetto, 2012) is a semi-automatic multilingual lexicon similar to Wordnet and also quite popular for performing WSD in languages other than English (Moro et al., 2014).\nSupervised WSD relies on sense-annotated corpora specifying which of the senses in the inventory are employed in context (Pasini and Camacho-Collados, 2020), e.g., SemCor for English WordNet (Landes et al., 1998) and Eurosense for Babelnet (Delli Bovi et al., 2017). The fine granularity of sense inventories is often criticised as unrealistic (Navigli, 2009). One alternative is to represent senses using top-level synsets in Wordnet’s taxonomy, referred to as supersenses, reached via hypernymy relations (Ciaramita and Johnson, 2003; Schneider et al., 2016). This reduces the number of labels at the expense of missing potentially relevant distinctions. In our evaluation, we employ the FrSemCor corpus, a French corpus in which nouns have been annotated using Wordnet supersenses as semantic tags (Barque et al., 2020).\nAlthough the set of 25 Wordnet top-level categories is quite popular, alternative representations with even coarser granularity can be useful for downstream applications (Jahan et al., 2018), such as a threeway classification of adjectives (Boleda et al., 2012) or animate vs. inanimate nouns (Øvrelid, 2006). We understand supersenses as general coarse semantic distinctions. Our set of six semantic labels is related to Wordnet supersenses, but there is not a 1:1 relation between our supersenses and Wordnet’s ones.\nWeakly supervised WSD Many models have been proposed to induce lexical semantics from raw corpora without supervision, e.g., (Lin, 1998), usually performing unsupervised WSD as a by-product. Most methods rely on distributional clustering algorithms, e.g., (Biemann and Riedl, 2013). While automatically induced word senses are hard to interpret, they may be automatically labeled, for example, using hypernym-induction patterns (Ustalov et al., 2019).\nOur embedding learning procedure is not fully unsupervised, but uses weak supervision to bootstrap semantic classes from corpora. Typical or non-ambiguous words can be used to produce sense-annotated data, which in turn enable training classifiers for inducing lexical knowledge. This has been proposed in several studies, e.g., Mihalcea (2003), especially for polysemy pattern detection (Boleda et al., 2012), and adapted to semantic frame induction using predicate-argument pairs (Jauhar and Hovy, 2017).\nThe method of Thelen and Riloff (2002) is similar to ours. They learn representations for six coarse supersenses using pattern-based bootstrapping based on a small list of seed words. The features used to learn senses are based on lexical patterns, syntactic co-occurrence, web queries, etc. (Qadir and Riloff, 2012). Instead of focusing on the features, our approach is more in line with current neural methods, with features learned from the data jointly with the supersense classifiers."
    }, {
      "heading" : "3 Contextual and Lexical Signatures",
      "text" : "The heart of SLICE consists in a series of binary classifiers, one per supersense. Each classifier takes as input a context C and produces a score that indicates how likely C could be associated to a given supersense si. This score, noted csi(C), is called a context score. A context C can be associated to a d-dimensional vector, called its signature CS(C) = (cs1(C), . . . , csd(C))T , where d is the number of different supersenses.1 The classifiers are also used to model the overall tendency of a wordw to occur in contexts that are representative of a given supersense si. This information is modeled by the lexical scores lsi(w), computed by aggregating the context scores of all occurrences ofw in a large corpus. A wordw is therefore associated to a d-dimensional vector, also called its signature2 LS(w) = (ls1(w), . . . , lsd(w))T . Such vectors can be compared to word embeddings produced by deep learning methods. The difference, however, is that each dimension of a word signature corresponds to an interpretable supersense.\nAs stated above, SLICE relies on classifiers that themselves require, to be trained, supersenseannotated corpora. Such corpora, when they exist, usually are of limited size and do not allow to build reliable context and word signatures. This is why we propose a semi-supervised method not requiring annotated corpora, but a list of representative words for each supersense, easier and cheaper to constitute.\n1In our case, d = 6, but the method can be applied to any number of semantic categories d ≥ 2. 2If necessary, we use the terms lexical signature and context signature to distinguish between these objects."
    }, {
      "heading" : "3.1 Outline of the Method",
      "text" : "We use as a starting point d disjoint sets of non-ambiguous words representative of each supersense; these words are referred to as seeds. Seeds’ occurrences are deterministically annotated with their corresponding supersenses in a corpus C, yielding a pseudo-annotated corpus that is used to train d classifiers, one per supersense. More precisely, the method is composed of the following steps:\n1. Manually compile d disjoint sets S1. . .Sd of positive examples, each containing lemmas that are prototypical of supersenses s1 . . . sd.3\n2. Automatically compile d sets S−1 . . .S−d of negative examples, each containing lemmas that do not pertain to supersenses s1. . . sd. The set S−i is built by selecting lemmas randomly from ∪j 6=iSj .\n3. For each supersense si, locate in a non annotated corpus C all occurrences of the words whose lemmas are elements of Si or S−i . Words that come from Si are labelled 1 and those from S−i are labelled 0. As a result, d pseudo-annotated corpora C1. . .Cd are produced.4\n4. Train d classifiers P1. . .Pd respectively on C1. . .Cd. The classifier Pi takes as input a context C = (W,k), where W = w1 . . . w|W | is a sentence and k is the position corresponding to the pseudoannotated word. Pi(C) returns a score 0 ≤ csi(C) ≤ 1, indicating how representative context C is of class si. This score is the context score mentioned above. Contexts that are representative of class si will have scores close to 1.\n5. For each word w, extract from C all contexts C1 . . . Cn in which w occurs (contexts (W,k) such that wk = w) and predict scores cs1(Cj). . . csd(Cj), 1 ≤ j ≤ n with P1. . .Pd. For each supersense si, all scores csi(Cj), 1 ≤ j ≤ n are combined to form the lexical score lsi(w), which reflects the tendency of word w to appear in contexts representative of supersense si. Finally, w is associated to a d-dimensional vector, its lexical signature, composed of the lexical scores ls1(w) . . . lsd(w).\nThe preceding description outlines the main steps of our method, but leaves unspecified two important aspects: the nature of the classifiers Pi used to compute context scores csi(c), and the way context scores are aggregated into lexical scores lsi(w). They are discussed in the two following sections."
    }, {
      "heading" : "3.2 Context Scores",
      "text" : "For each supersense si, context scores are computed by a binary classifier Pi trained to predict the classes 0 or 1 of the positive and negative seed occurrences wk in the pseudo-annotated corpus Ci. The input of Pi is a context C = (W,k), each word wj ∈ W represented as a triple (f, l,m) where f is the surface form of the word, l its lemma and m its morphological features (e.g., number=plural). Each element of this triple is represented as a randomly initialised embedding of size 500 for f and l and 64 for m.\nThe classifiers are made of two LSTMs: a left LSTM that processes the sentence from the first word w1 to wk−1, and a right LSTM that processes the sentence backwards, from the last word w|W | to wk+1. The hidden-state vector size of both LSTMs is equal to 300. Notice that the LSTMs ignore the pseudoannotated word wk. The final states of the two LSTMs are concatenated, along with the morphological features of word wk, represented as an embedding of size 64. The resulting 664-dimensional vector is fed to a multilayer perceptron (MLP) with one hidden dense layer of size 150. The output layer is of dimension 2 corresponding to classes 0 (wk ∈ S−i ) and 1 to predict (wk ∈ Si), with softmax activation.\nThe LSTMs and the subsequent dense layer form a single network trained jointly. The loss function used to train each Pi is categorical cross entropy, and the optimiser is Adam. We use a dropout of 30% to prevent overfitting, that is, for each prediction, each lemma and form in the input have a 30% probability of being masked. The size of the batches is equal to 128, and every 30,000 examples, the accuracy on the development corpus is computed. If this accuracy is the best up to now, the model is saved, and if it does not increase for the next 10 steps of 30,000 examples, training is stopped and the best model is kept.\n3Avoiding polysemous seeds is crucial to minimise the number of (inevitable) errors in automatic annotation. 4Sentences not containing any word in Si∪S−i are discarded."
    }, {
      "heading" : "3.3 Lexical Scores",
      "text" : "Lexical scores lsi(w) reflect the tendency of word w to appear in contexts representative of class si. It is a function of the contextual scores csi(C1) . . . csi(Cn), where C1. . .Cn are all the contexts in which w occurs in the corpus C. A context C is representative of class si if its score csi(C) is close to 1 and is not representative of class si when csi(C) is close to 0. Intermediate scores, close to 0.5, are less informative, so their contribution to the lexical score should be lower than that of representative scores.\nWe use the parabolic function h(a) = (1 − 2a)2p to model this behaviour. It reaches its minimum value 0 in the range [0 . . . 1] for s = 0.5 and its maximum value 1 for s = 1 and s = 0. Parameter p controls the extent to which intermediate scores are taken into account, the higher the value of p, the less intermediate values contribute to the lexical score (in our experiments, we set p = 8). The lexical score lsi(w) is defined as the average of its context scores csi(C,j) weighted by h(csi(Cj)):\nlsi(w) = 1∑n\nj=1 h(csi(cj))\nn∑\nj=1\nh(csi(cj))× csi(cj)"
    }, {
      "heading" : "4 Experimental Setup",
      "text" : "We describe in this section the data we have used to build contextual and lexical signatures, and the data we will use in the following section to evaluate our method.\nSupersense Tagset To guarantee a sufficient scope (with respect to the size of the seed lists) and to simplify analysis, we grouped Wordnet supersenses into six coarser categories for our experiments on French nouns (details in Appendix A). Animate entity (ANI) includes nouns referring to living and animate entities, namely persons (e.g., agriculteur ‘farmer’) and animals (e.g., chiot ‘puppy’); Natural object (NAT) is for nouns referring to natural entities (e.g., étoile ‘star’), plants (e.g., peuplier ‘poplar tree’) and body parts (e.g., hanche ‘hip’); Manufactured object (MAN) is composed of nouns denoting human-made or transformed entities: artifacts (e.g., chronomètre ‘stopwatch’) or built places (e.g., isoloir ‘voting booth’); Informational object (INF) includes nouns denoting abstract objects having informational contents (e.g., théorie ‘theory’), those referring to knowledge areas (e.g., ethnologie ‘ethnology’) and financial assets (e.g., budget ‘budget’); Dynamic situation (DYN) gathers nouns denoting things that happen or that are carried out, like actions (e.g., ablation ‘removal’), activities (e.g., cyclisme ‘cycling’) and events (e.g., explosion ‘outbreak’); Stative situation (STA) is for nouns that denote properties (e.g., dignité ‘dignity’), states (e.g., endettement ‘easement’) and feelings (e.g., tendresse ‘tenderness’).\nSeeds We used data provided by the Wolf, a French lexical resource automatically built from the Princeton Wordnet (Sagot and Fišer, 2008), to draw up the six seed lists Si. A list of monosemous French nouns has been extracted from this resource and then we manually selected 200 nouns for each coarser category described above. For example, the seed list for the DYN class, contains nouns manually selected from the Wolf nouns having only one supersense among those that denote dynamic situations.\nCorpus and Preprocessing Experiments have been conducted on the frWaC corpus, which contains about 1.6 billion words crawled from the web (Baroni et al., 2009). The corpus has been POS tagged, lemmatised and morphologically analysed by an in-house parser trained on the French corpora of Universal Dependencies (Nivre et al., 2016). The corpus is divided into 55 parts of about 1M sentences each. Part 54 is used as development corpus for early stopping, all other parts are used for training.\nPositive and negative seed sets Si and S−i are split into a training set (80% of the lemmas) and a development (20% of the lemmas). The training seeds are used to annotate the training corpus, while the development seeds are used to annotate the development corpus. This is a deterministic process: each occurrence of a word in Si (resp. S−i ) is annotated as 1 (resp. 0). We artificially balance the number of training contexts in each corpus Ci to avoid biases related to different distributions of positive and negative examples. Given the seed lists Si and S−i , we count the total number of occurrences of lemmas from each list, Ni and N−i in C. If Ni < N−i , all sentences containing a lemma from Si are added to Ci. Then, sentences containing lemmas from S−i are randomly added until at least Ni occurrences from S−i appear in Ci. If N−i < Ni the seed lists are inverted. All other sentences are discarded.\nEvaluation data The FrSemCor corpus was used for evaluation (Barque et al., 2020).5 It contains manual annotations for more than 12,000 nouns in the Sequoia Treebank, a corpus of 3,009 sentences from different sources including morphological and syntactic annotations (Candito and Seddah, 2012). Noun tokens have been annotated with 24 supersenses adapted from the Wordnet supersense tagset.6 For this experiment, we used 7,188 annotated nouns: 5,160 have been used for training, 1,015 for development and 1,013 for evaluation."
    }, {
      "heading" : "5 Word Sense Disambiguation",
      "text" : "We have evaluated SLICE on a word sense disambiguation task because our model produces interpretable senses that can be directly compared to senses used in word sense annotated corpora (FrSemCor, in our case). Our model produces, for every word in context, a description of the context through the context signature, and a description of the usage of a word through its lexical signature. Comparing different ways to combine these two pieces of information is interesting from a linguistic point of view since it can can lead to interesting analyses of complex linguistic phenomena such as polysemy, multi-facet nouns, and unusual contexts (e.g., manufactured objects MAN in contexts typical of animate beings ANI).\nAs a comparison point for the performances reached by SLICE, we have used a simple baseline, which selects for every noun occurrence its most frequent supersense (MFS) in the training corpus. When the word does not occur in the training corpus, the most frequent supersense across all words is selected. This crude method gives better results as the training corpus grows, since the coverage grows with size of the training corpus and selecting the most frequent supersense is a good heuristic (Navigli, 2009).\nWe also compare our model to a state-of-the-art model in other WSD tasks: a French-specific version of BERT called FlauBERT (Le et al., 2020). We use the 1024-dimensional embeddings available in FlauBERT-large as part of the HuggingFace library.7 For each target noun, we calculate its contextualised embedding and provide it to an MLP identical to the one described in Section 5.2.\nIn our model, the decision to tag word w in context C with a given supersense is taken based on the lexical signature of w and the context signature of C.8 They are combined to yield a word-in-context signature Ψ(LS(w),CS(C)), which is also d-dimensional. The component corresponding to the highest score is selected as the predicted supersense for w in C:\nŝ(w,C) = argmax 1≤i≤d Ψi(LS(w),CS(C))\nThe main missing part in this model is the nature of function Ψ that combines lexical and contextual signatures. We discuss in the two following sections two instanciations of function Ψ."
    }, {
      "heading" : "5.1 Linear Model",
      "text" : "The linear model (LM) simply performs a linear combination of vectors LS(w) and CS(C): Ψ(LS(w),CS(C)) = αLS(w) + (1 − α)CS(C). This model has one parameter, α, which value has to be estimated on the training corpus. The accuracy on the training set for different values of α has been represented in Table 1. We observe that, when only the lexical score is taken into account (α = 1), the model achieves an accuracy of 64.3%. It is equal to 51.83% when the decision is based on the only account of the context score. The optimal value is α = 0.7, reaching an accuracy of 66.35% on the training set and an accuracy of 65% on the test set.\n5https://frsemcor.github.io/FrSemCor/ 6 The Wordnet supersenses tagset, also known as Wordnet Unique Beginners (Miller et al., 1990), is composed of 25 nominal\nsupersenses. Small adjustments have been made for the annotation of French nouns (Barque et al., 2020). 7https://huggingface.co/ 8In practice, our experiments use a word’s lemma signatures instead of surface forms.\nIn order to get a better understanding of the results obtained by the linear model, we have grouped the noun occurrences into 5 configurations, described in Table 2 and calculated the accuracy of the linear model for each of them. The configurations compare for each noun occurrence, the best lexical scoring supersense (noted L), the best contextual scoring supersense (noted C) and the correct supersense (noted R). In configuration 0, all three candidates are equal (R = L = C). In configuration 1, L is correct and C is wrong while in configuration 2, L is wrong and C is correct. In configuration 3 both L and C are wrong but they are different, while in configuration 4 they are both wrong and equal to each other. Column 5 shows the number of occurrences that fall in each category. Column 6 gives the ratio of each configuration. Column 7 shows the accuracy of LM for every configuration.\nThe table reveals that in 25% of the cases (configurations 3 and 4), both L and C are wrong and the model behaves very poorly. This was expected, since the model just makes a linear combination of the lexical and contextual scores. The model also behaves poorly in configuration 2, where C should be selected. This is due to the high value of α that tends to favour lexical scores over contextual ones. Linearly combining lexical and contextual signatures with a fixed weight is clearly not adequate."
    }, {
      "heading" : "5.2 Multilayer Perceptron",
      "text" : "In the MLP model, Ψ is a complex non linear function learned by a neural network that combines the 12 scores that constitute the lexical and contextual signatures. The model chosen is a simple MLP with two hidden layers. Its parameters are learned on the training part of FrSemCor by minimising the categorical cross entropy between the six supersenses. The MLP model achieves an accuracy of 83.02% on the test corpus, an increase of 18.02% absolute with respect to the linear model. The behaviour of the MLP model in the 5 configurations is indicated in the last column of Table 2. As one can see, the predictions made in configurations 3 and 4 are much more satisfactory. Accuracy jumps from 10% to 65% in configuration 3 and from 0% to 65% in configuration 4.\nFigure 1 shows the learning curve of SLICE+MLP, most frequent supersense, and FlauBERT models. With 300 words in the training set, the MLP model reaches an accuracy of 70%, while the MFS model reaches 31.5%. The difference between the two models decreases as the size of the training set increases. The MFS model accuracy exceeds the MLP’s when the size of the training data reaches approximately 4,000 words. FlauBERT is the best performing method after 600 words in the training set, reaching a maximum accuracy of 89.8% on the full training corpus. Notice, however, that FlauBERT embeddings are 85 times larger than ours and were trained on a corpus about 6 times larger than ours. Moreover, the analyses presented in Section 5.3 are only possible in our model, thanks to its interpretability.\nTable 3 gives a more detailed view on the MLP predictions. The table on the left hand side displays the precision, recall and F-measure for each supersense. It shows that the model behaves very differently on the different supersenses: supersense ANI obtains the best result, with an F-score of 94.59%, while STA behaves poorly and reaches an F-score of 64.86%, mainly due to its low precision. The confusion matrix on the right hand side reveals that STA is mostly confused with DYN, a confusion partly due to nouns pertaining to both categories, such as déshydratation ‘dehydration’, reconnaissance ‘recognition/gratitude’ or grossesse ‘pregnancy’."
    }, {
      "heading" : "5.3 Error Analysis",
      "text" : "A manual analysis of the results revealed that one of the key sources of errors are nouns having multiple meanings, be they polysemous or multi-facet nouns. They account for 43.4% of the lemmas involved in errors. As a reminder, polysemous nouns have distinct and mutually exclusive meanings. For example, organisme ‘body/organisation’ can denote a natural object (NAT) or an institution (ANI) but a single occurrence of this noun cannot denote both. Multi-facet nouns, on the other hand, have multiple but compatible meanings, a property that can be highlighted by copredication (Cruse, 2002; Ježek and Melloni, 2011). For instance, demande ‘request’ denotes both the request (DYN) and the subject of the request (INF). In some contexts, both facets are triggered, such as La demande effectuée par la présidente n’a pas été acceptée. ‘The request from the president was not granted’.\nTable 4 shows five cases of errors involving multiple meaning words and details their lexical and contextual scores9. In row 1, an occurrence of the polysemous noun organisme is incorrectly labelled ANI instead of NAT. An analysis of the scores reveals that although the context gives a clear preference for the correct sense (NAT), its lexical score is extremely low, while the score of sense ANI is high, provoking the selection of the incorrect sense.\nThe lexical signature of the word demande, in row 2, clearly reflects its multi facet nature, both facets (INF and DYN) obtain the best and second best scores. However, contrary to annotators, the model considered the context as more representative of the INF class.\nAnother source of errors concerns questionable annotations in the gold data, where decisions made on class delimitation can be debated. For instance, verger ‘orchard’ or potager ‘vegetable garden’ refer to natural objects, but because they are also human creations, they can occur in contexts representative of the class MAN. This is what happened in line 3 and led to the selection of this sense. It is interesting\n9Complete sentences are given in Appendix B.\nto note that the human-made aspect of this natural object seems to be captured in the lexical signature (second best score for MAN).\nGold annotation can also be questioned for nouns that are hard to classify. Notable among those are general nouns such as fait ‘fact’ or cas ‘case’, that can be used to characterise multiple referents and do not clearly pertain to one of the considered supersenses. The two occurrences of cas, rows 4 and 5, illustrate these noun properties: the best lexical score is rather low (0.68 for INF) and the gold supersenses, determined by the reference-driven annotation method, are not clearly captured in the contextual signatures.\nLinguistic phenomena responsible for the association of several meanings to a single lexical form are thus numerous: homonymy, polysemy, facets, general units having heterogeneous referents. Our interpretable embeddings allow to observe these phenomena and investigate whether these different types of ambiguity or indeterminacy appear as structural properties of our embeddings. They also allow us to take a critical look at the linguistic data we used to learn them, namely the composition of seed lists with respect to the target semantic class, the corpus used to learn lexical signatures or the method used to compute lexical scores. For example, knowing that our model does not classify organisme as NAT, surely because the word is not detected as pertaining to this class in the lexicon, leads us to the following assumptions: nouns related to the body domain may not be well represented in the seed list for NAT; or the body meaning of organisme is not enough attested in the frWac, at least in contexts discriminant for the NAT class; or the method we used to compute lexical scores does not properly take into account differences between balanced vs. biaised meanings for a given noun. In other words, our model of lexical representation opens the way to several linguistic investigations that could hopefully help the WSD task."
    }, {
      "heading" : "6 Conclusions",
      "text" : "We have presented a method to learn interpretable embeddings using as weak supervision a list of seed nouns for each supersense. We use the occurrences of seed (prototypical) nouns to train a classifier which associates contexts to supersenses. The context scores are aggregated to generate a single lexical score per supersense. Each of these scores are seen as an interpretable dimension of a dense word embedding.\nWe have evaluated our method on a WSD task to predict in-context coarse supersenses. In addition to a good performance with very little training data, our method’s interpretability allows us to analyse the results in terms of the (supersense) dimensions of the input embeddings. Moreover, our model is considerably faster and lighter than state-of-the-art contextualised embeddings, e.g., we represent inputs as a set of 12 scores whereas FlauBERT uses 1024-dimensional opaque vectors.\nWe have also built and released the lexicon containing the 10K most frequent French of the frWaC and their corresponding embeddings. We hope that this resource can be complementary to existing embeddings and lexical semantic resources. The lexicon, along with the seed lists, predictions and evaluation data are submitted with this paper and will be released on a public website upon publication.\nAs future work, we envisage integrating our embeddings in other downstream tasks such as semantic parsing. We would like generalise our method to other syntactic and semantic categories, e.g., can we build interpretable embeddings for POS tagging using seed lists of verbs, nouns, etc.? In addition, we would like to study the model’s sensitivity to the size of the list of seeds. Transformer models are a promising alternative to recurrent neural networks to focus on relevant contexts for the classifiers."
    } ],
    "references" : [ {
      "title" : "Improving dependency parsing with semantic classes",
      "author" : [ "Eneko Agirre", "Kepa Bengoetxea", "Koldo Gojenola", "Joakim Nivre." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 699–703, Portland, Oregon, USA, June. Association for Computational Linguistics.",
      "citeRegEx" : "Agirre et al\\.,? 2011",
      "shortCiteRegEx" : "Agirre et al\\.",
      "year" : 2011
    }, {
      "title" : "The wacky wide web: a collection of very large linguistically processed web-crawled corpora",
      "author" : [ "M. Baroni", "S. Bernardini", "A. Ferraresi", "E. Zanchetta." ],
      "venue" : "Language resources and evaluation, 43(3):209–226.",
      "citeRegEx" : "Baroni et al\\.,? 2009",
      "shortCiteRegEx" : "Baroni et al\\.",
      "year" : 2009
    }, {
      "title" : "Annotating a french corpus with supersenses",
      "author" : [ "L. Barque", "P. Haas", "R. Huyghe", "D. Tribout", "M. Candito", "B. Crabbé", "V. Segonne." ],
      "venue" : "Proceedings of LREC-2020.",
      "citeRegEx" : "Barque et al\\.,? 2020",
      "shortCiteRegEx" : "Barque et al\\.",
      "year" : 2020
    }, {
      "title" : "Text: now in 2d! a framework for lexical expansion with contextual similarity",
      "author" : [ "Chris Biemann", "Martin Riedl." ],
      "venue" : "Journal of Language Modelling, 1:55, 07.",
      "citeRegEx" : "Biemann and Riedl.,? 2013",
      "shortCiteRegEx" : "Biemann and Riedl.",
      "year" : 2013
    }, {
      "title" : "Enriching word vectors with subword information",
      "author" : [ "Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 5:135–146, December.",
      "citeRegEx" : "Bojanowski et al\\.,? 2017",
      "shortCiteRegEx" : "Bojanowski et al\\.",
      "year" : 2017
    }, {
      "title" : "Regular polysemy: A distributional model",
      "author" : [ "G. Boleda", "S. Padó", "J. Utt." ],
      "venue" : "Proceedings of the First Joint Conference on Lexical and Computational Semantics-Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation, pages 151–160.",
      "citeRegEx" : "Boleda et al\\.,? 2012",
      "shortCiteRegEx" : "Boleda et al\\.",
      "year" : 2012
    }, {
      "title" : "From word to sense embeddings: A survey on vector representations of meaning",
      "author" : [ "José Camacho-Collados", "Mohammad Taher Pilehvar." ],
      "venue" : "J. Artif. Intell. Res., 63:743–788.",
      "citeRegEx" : "Camacho.Collados and Pilehvar.,? 2018",
      "shortCiteRegEx" : "Camacho.Collados and Pilehvar.",
      "year" : 2018
    }, {
      "title" : "Nasari: Integrating explicit knowledge and corpus statistics for a multilingual representation of concepts and entities",
      "author" : [ "José Camacho-Collados", "Mohammad Taher Pilehvar", "Roberto Navigli." ],
      "venue" : "Artificial Intelligence, 240:36–64.",
      "citeRegEx" : "Camacho.Collados et al\\.,? 2016",
      "shortCiteRegEx" : "Camacho.Collados et al\\.",
      "year" : 2016
    }, {
      "title" : "Le corpus Sequoia : annotation syntaxique et exploitation pour l’adaptation d’analyseur par pont lexical",
      "author" : [ "M. Candito", "D. Seddah." ],
      "venue" : "Proceedings of TALN 2012, juin.",
      "citeRegEx" : "Candito and Seddah.,? 2012",
      "shortCiteRegEx" : "Candito and Seddah.",
      "year" : 2012
    }, {
      "title" : "Supersense tagging of unknown nouns in wordnet",
      "author" : [ "M. Ciaramita", "M. Johnson." ],
      "venue" : "Proceedings of the EMNLP, pages 168–175.",
      "citeRegEx" : "Ciaramita and Johnson.,? 2003",
      "shortCiteRegEx" : "Ciaramita and Johnson.",
      "year" : 2003
    }, {
      "title" : "Aspects of the micro-structure of word meaning, pages 30–51",
      "author" : [ "D.A. Cruse" ],
      "venue" : null,
      "citeRegEx" : "Cruse,? \\Q2002\\E",
      "shortCiteRegEx" : "Cruse",
      "year" : 2002
    }, {
      "title" : "EuroSense: Automatic harvesting of multilingual sense annotations from parallel text",
      "author" : [ "Claudio Delli Bovi", "Jose Camacho-Collados", "Alessandro Raganato", "Roberto Navigli." ],
      "venue" : "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 594–600, Vancouver, Canada, July. Association for Computational Linguistics.",
      "citeRegEx" : "Bovi et al\\.,? 2017",
      "shortCiteRegEx" : "Bovi et al\\.",
      "year" : 2017
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "Retrofitting word vectors to semantic lexicons",
      "author" : [ "Manaal Faruqui", "Jesse Dodge", "Sujay Kumar Jauhar", "Chris Dyer", "Eduard Hovy", "Noah A. Smith." ],
      "venue" : "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1606–1615, Denver, Colorado, May–June. Association for Computational Linguistics.",
      "citeRegEx" : "Faruqui et al\\.,? 2015",
      "shortCiteRegEx" : "Faruqui et al\\.",
      "year" : 2015
    }, {
      "title" : "Personality profiling of fictional characters using sense-level links between lexical resources",
      "author" : [ "Lucie Flekova", "Iryna Gurevych." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1805–1816, Lisbon, Portugal, September. Association for Computational Linguistics.",
      "citeRegEx" : "Flekova and Gurevych.,? 2015",
      "shortCiteRegEx" : "Flekova and Gurevych.",
      "year" : 2015
    }, {
      "title" : "Supersense embeddings: A unified model for supersense interpretation, prediction, and utilization",
      "author" : [ "Lucie Flekova", "Iryna Gurevych." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2029–2041, Berlin, Germany, August. Association for Computational Linguistics.",
      "citeRegEx" : "Flekova and Gurevych.,? 2016",
      "shortCiteRegEx" : "Flekova and Gurevych.",
      "year" : 2016
    }, {
      "title" : "Distributional structure",
      "author" : [ "Z.S. Harris." ],
      "venue" : "Word, 10:146–162.",
      "citeRegEx" : "Harris.,? 1954",
      "shortCiteRegEx" : "Harris.",
      "year" : 1954
    }, {
      "title" : "A new approach to animacy detection",
      "author" : [ "L. Jahan", "G. Chauhan", "M. Finlayson." ],
      "venue" : "Proceedings of the 27th International Conference on Computational Linguistics, pages 1–12.",
      "citeRegEx" : "Jahan et al\\.,? 2018",
      "shortCiteRegEx" : "Jahan et al\\.",
      "year" : 2018
    }, {
      "title" : "Embedded semantic lexicon induction with joint global and local optimization",
      "author" : [ "Sujay Kumar Jauhar", "Eduard Hovy." ],
      "venue" : "Proceedings of the 6th Joint Conference on Lexical and Computational Semantics (*SEM 2017), pages 209–219, Vancouver, Canada, August. Association for Computational Linguistics.",
      "citeRegEx" : "Jauhar and Hovy.,? 2017",
      "shortCiteRegEx" : "Jauhar and Hovy.",
      "year" : 2017
    }, {
      "title" : "What does BERT learn about the structure of language",
      "author" : [ "Ganesh Jawahar", "Benoı̂t Sagot", "Djamé Seddah" ],
      "venue" : "In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL",
      "citeRegEx" : "Jawahar et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Jawahar et al\\.",
      "year" : 2019
    }, {
      "title" : "Nominals, polysemy and co-predication",
      "author" : [ "E. Ježek", "C. Melloni." ],
      "venue" : "Journal of cognitive science, 12:1–31.",
      "citeRegEx" : "Ježek and Melloni.,? 2011",
      "shortCiteRegEx" : "Ježek and Melloni.",
      "year" : 2011
    }, {
      "title" : "A solution to plato’s problem: The latent semantic analysis theory of the acquisition, induction, and representation of knowledge",
      "author" : [ "Thomas K. Landauer", "Susan T. Dumais." ],
      "venue" : "Psychological Review, 104(2):211–240.",
      "citeRegEx" : "Landauer and Dumais.,? 1997",
      "shortCiteRegEx" : "Landauer and Dumais.",
      "year" : 1997
    }, {
      "title" : "FlauBERT: Unsupervised language model pretraining for French",
      "author" : [ "Hang Le", "Loı̈c Vial", "Jibril Frej", "Vincent Segonne", "Maximin Coavoux", "Benjamin Lecouteux", "Alexandre Allauzen", "Benoit Crabbé", "Laurent Besacier", "Didier Schwab" ],
      "venue" : "In Proceedings of The 12th Language Resources and Evaluation Conference,",
      "citeRegEx" : "Le et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Le et al\\.",
      "year" : 2020
    }, {
      "title" : "Automatic retrieval and clustering of similar words",
      "author" : [ "Dekang Lin." ],
      "venue" : "COLING 1998 Volume 2: The 17th International Conference on Computational Linguistics.",
      "citeRegEx" : "Lin.,? 1998",
      "shortCiteRegEx" : "Lin.",
      "year" : 1998
    }, {
      "title" : "The role of non-ambiguous words in natural language disambiguation",
      "author" : [ "R. Mihalcea." ],
      "venue" : "Proceedings of the Fourth RANLP, pages 357–366.",
      "citeRegEx" : "Mihalcea.,? 2003",
      "shortCiteRegEx" : "Mihalcea.",
      "year" : 2003
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "T. Mikolov", "K. Chen", "G. Corrado", "J. Dean." ],
      "venue" : "ICLR Workshop Papers.",
      "citeRegEx" : "Mikolov et al\\.,? 2013",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Wordnet: An online lexical database",
      "author" : [ "G. Miller", "R. Beckwith", "C. Fellbaum", "Gross D.", "K. Miller." ],
      "venue" : "International Journal of Lexicography, 4(3):235–244.",
      "citeRegEx" : "Miller et al\\.,? 1990",
      "shortCiteRegEx" : "Miller et al\\.",
      "year" : 1990
    }, {
      "title" : "Entity Linking meets Word Sense Disambiguation: a Unified Approach",
      "author" : [ "Andrea Moro", "Alessandro Raganato", "Roberto Navigli." ],
      "venue" : "Transactions of the Association for Computational Linguistics (TACL), 2:231–244.",
      "citeRegEx" : "Moro et al\\.,? 2014",
      "shortCiteRegEx" : "Moro et al\\.",
      "year" : 2014
    }, {
      "title" : "Babelnet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network",
      "author" : [ "R. Navigli", "S.P. Ponzetto." ],
      "venue" : "Artificial Intelligence, 193:217–250.",
      "citeRegEx" : "Navigli and Ponzetto.,? 2012",
      "shortCiteRegEx" : "Navigli and Ponzetto.",
      "year" : 2012
    }, {
      "title" : "Word sense disambiguation: A survey",
      "author" : [ "R. Navigli." ],
      "venue" : "ACM Computing Surveys, 41(2):1–69.",
      "citeRegEx" : "Navigli.,? 2009",
      "shortCiteRegEx" : "Navigli.",
      "year" : 2009
    }, {
      "title" : "Efficient non-parametric estimation of multiple embeddings per word in vector space",
      "author" : [ "Arvind Neelakantan", "Jeevan Shankar", "Alexandre Passos", "Andrew McCallum." ],
      "venue" : "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1059–1069, Doha, Qatar, October. Association for Computational Linguistics.",
      "citeRegEx" : "Neelakantan et al\\.,? 2014",
      "shortCiteRegEx" : "Neelakantan et al\\.",
      "year" : 2014
    }, {
      "title" : "Universal dependencies v1: A multilingual treebank collection",
      "author" : [ "Joakim Nivre", "Marie-Catherine de Marneffe", "Filip Ginter", "Yoav Goldberg", "Jan Hajic", "Christopher D. Manning", "Ryan McDonald", "Slav Petrov", "Sampo Pyysalo", "Natalia Silveira", "Reut Tsarfaty", "Daniel Zeman." ],
      "venue" : "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC 2016). European Language Resources Association (ELRA), may.",
      "citeRegEx" : "Nivre et al\\.,? 2016",
      "shortCiteRegEx" : "Nivre et al\\.",
      "year" : 2016
    }, {
      "title" : "Towards robust animacy classification using morphosyntactic distributional features",
      "author" : [ "L. Øvrelid." ],
      "venue" : "Proceedings of the Eleventh Conference of the European Chapter of the Association for Computational Linguistics: Student Research Workshop, pages 47–54.",
      "citeRegEx" : "Øvrelid.,? 2006",
      "shortCiteRegEx" : "Øvrelid.",
      "year" : 2006
    }, {
      "title" : "Unsupervised does not mean uninterpretable: The case for word sense induction and disambiguation",
      "author" : [ "Alexander Panchenko", "Eugen Ruppert", "Stefano Faralli", "Simone Paolo Ponzetto", "Chris Biemann." ],
      "venue" : "Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics: Volume 1, Long Papers, pages 86–98, Valencia, Spain, April. Association for Computational Linguistics.",
      "citeRegEx" : "Panchenko et al\\.,? 2017",
      "shortCiteRegEx" : "Panchenko et al\\.",
      "year" : 2017
    }, {
      "title" : "A short survey on sense-annotated corpora",
      "author" : [ "Tommaso Pasini", "Jose Camacho-Collados." ],
      "venue" : "Proceedings of The 12th Language Resources and Evaluation Conference, pages 5759–5765, Marseille, France, May. European Language Resources Association.",
      "citeRegEx" : "Pasini and Camacho.Collados.,? 2020",
      "shortCiteRegEx" : "Pasini and Camacho.Collados.",
      "year" : 2020
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "J. Pennington", "R. Socher", "C. Manning." ],
      "venue" : "Proceedings of the 2014 conference on empirical methods in natural language processing, pages 1532–1543.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Deep contextualized word representations",
      "author" : [ "Matthew Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 2227–2237, New Orleans, LA, USA. Association for Computational Linguistics.",
      "citeRegEx" : "Peters et al\\.,? 2018",
      "shortCiteRegEx" : "Peters et al\\.",
      "year" : 2018
    }, {
      "title" : "Ensemble-based semantic lexicon induction for semantic tagging",
      "author" : [ "Ashequl Qadir", "Ellen Riloff." ],
      "venue" : "*SEM 2012: The First Joint Conference on Lexical and Computational Semantics – Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval 2012), pages 199–208, Montréal, Canada, 7-8 June. Association for Computational Linguistics.",
      "citeRegEx" : "Qadir and Riloff.,? 2012",
      "shortCiteRegEx" : "Qadir and Riloff.",
      "year" : 2012
    }, {
      "title" : "Improving language under-standing by generative pre-training",
      "author" : [ "Alec Radford", "Karthik Narasimhan", "Tim Salimans", "Ilya Sutskever" ],
      "venue" : null,
      "citeRegEx" : "Radford et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Radford et al\\.",
      "year" : 2018
    }, {
      "title" : "A primer in bertology: What we know about how bert works",
      "author" : [ "Anna Rogers", "Olga Kovaleva", "Anna Rumshisky" ],
      "venue" : null,
      "citeRegEx" : "Rogers et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Rogers et al\\.",
      "year" : 2020
    }, {
      "title" : "AutoExtend: Extending word embeddings to embeddings for synsets and lexemes",
      "author" : [ "Sascha Rothe", "Hinrich Schütze." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1793–1803, Beijing, China, July. Association for Computational Linguistics.",
      "citeRegEx" : "Rothe and Schütze.,? 2015",
      "shortCiteRegEx" : "Rothe and Schütze.",
      "year" : 2015
    }, {
      "title" : "Building a free French wordnet from multilingual resources",
      "author" : [ "Benoı̂t Sagot", "Darja Fišer" ],
      "venue" : null,
      "citeRegEx" : "Sagot and Fišer.,? \\Q2008\\E",
      "shortCiteRegEx" : "Sagot and Fišer.",
      "year" : 2008
    }, {
      "title" : "Semeval-2016 task 10: Detecting minimal semantic units and their meanings (dimsum)",
      "author" : [ "N. Schneider", "D. Hovy", "A. Johannsen", "M. Carpuat." ],
      "venue" : "Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016), pages 546–559.",
      "citeRegEx" : "Schneider et al\\.,? 2016",
      "shortCiteRegEx" : "Schneider et al\\.",
      "year" : 2016
    }, {
      "title" : "Is attention interpretable? In Proceedings of the 57th Meeting of the Association for Computational Linguistics, pages 2931–2951, Florence, Italy",
      "author" : [ "Sofia Serrano", "Noah A. Smith." ],
      "venue" : "ACL.",
      "citeRegEx" : "Serrano and Smith.,? 2019",
      "shortCiteRegEx" : "Serrano and Smith.",
      "year" : 2019
    }, {
      "title" : "A bootstrapping method for learning semantic lexicons using extraction pattern contexts",
      "author" : [ "Michael Thelen", "Ellen Riloff." ],
      "venue" : "Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing (EMNLP 2002), pages 214–221. Association for Computational Linguistics, July.",
      "citeRegEx" : "Thelen and Riloff.,? 2002",
      "shortCiteRegEx" : "Thelen and Riloff.",
      "year" : 2002
    }, {
      "title" : "Word representations: A simple and general method for semi-supervised learning",
      "author" : [ "Joseph Turian", "Lev-Arie Ratinov", "Yoshua Bengio." ],
      "venue" : "Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 384–394, Uppsala, Sweden, July. Association for Computational Linguistics.",
      "citeRegEx" : "Turian et al\\.,? 2010",
      "shortCiteRegEx" : "Turian et al\\.",
      "year" : 2010
    }, {
      "title" : "Watset: Local-global graph clustering with applications in sense and frame induction",
      "author" : [ "Dmitry Ustalov", "Alexander Panchenko", "Chris Biemann", "Simone Paolo Ponzetto." ],
      "venue" : "Computational Linguistics, 45(3):423–479.",
      "citeRegEx" : "Ustalov et al\\.,? 2019",
      "shortCiteRegEx" : "Ustalov et al\\.",
      "year" : 2019
    }, {
      "title" : "One sense per collocation",
      "author" : [ "David Yarowsky." ],
      "venue" : "Human Language Technology: Proceedings of a Workshop Held at Plainsboro, New Jersey, March 21-24, 1993.",
      "citeRegEx" : "Yarowsky.,? 1993",
      "shortCiteRegEx" : "Yarowsky.",
      "year" : 1993
    } ],
    "referenceMentions" : [ {
      "referenceID" : 26,
      "context" : ", Wordnet (Miller et al., 1990) and Babelnet (Navigli and Ponzetto, 2012), as well as sense-annotated corpora specifying which of these senses are employed in context, e.",
      "startOffset" : 10,
      "endOffset" : 31
    }, {
      "referenceID" : 28,
      "context" : ", 1990) and Babelnet (Navigli and Ponzetto, 2012), as well as sense-annotated corpora specifying which of these senses are employed in context, e.",
      "startOffset" : 21,
      "endOffset" : 49
    }, {
      "referenceID" : 29,
      "context" : "Because fine-grained sense distinctions are generally hard to annotate and predict (Navigli, 2009), coarse-grained tagsets, referred to as supersenses, were proposed as alternatives (Ciaramita and Johnson, 2003; Schneider et al.",
      "startOffset" : 83,
      "endOffset" : 98
    }, {
      "referenceID" : 9,
      "context" : "Because fine-grained sense distinctions are generally hard to annotate and predict (Navigli, 2009), coarse-grained tagsets, referred to as supersenses, were proposed as alternatives (Ciaramita and Johnson, 2003; Schneider et al., 2016), with positive impact on downstream applications, e.",
      "startOffset" : 182,
      "endOffset" : 235
    }, {
      "referenceID" : 42,
      "context" : "Because fine-grained sense distinctions are generally hard to annotate and predict (Navigli, 2009), coarse-grained tagsets, referred to as supersenses, were proposed as alternatives (Ciaramita and Johnson, 2003; Schneider et al., 2016), with positive impact on downstream applications, e.",
      "startOffset" : 182,
      "endOffset" : 235
    }, {
      "referenceID" : 16,
      "context" : "Alternatively, real-numbered vectors can encode contextual co-occurrence, acting as a proxy for a lexical unit’s semantics (Harris, 1954).",
      "startOffset" : 123,
      "endOffset" : 137
    }, {
      "referenceID" : 25,
      "context" : "Advances in neural networks shifted the focus of computational semantics to representation learning, so as to obtain vectors as by-products of neural networks (Mikolov et al., 2013).",
      "startOffset" : 159,
      "endOffset" : 181
    }, {
      "referenceID" : 4,
      "context" : "In this booming field, a myriad of models have emerged to encode sub-lexical information (Bojanowski et al., 2017), polysemy (Neelakantan et al.",
      "startOffset" : 89,
      "endOffset" : 114
    }, {
      "referenceID" : 30,
      "context" : ", 2017), polysemy (Neelakantan et al., 2014), and context (Peters et al.",
      "startOffset" : 18,
      "endOffset" : 44
    }, {
      "referenceID" : 6,
      "context" : "While generic and reusable, these models usually conflate the different meanings of a given unit into a single vector (Camacho-Collados and Pilehvar, 2018).",
      "startOffset" : 118,
      "endOffset" : 155
    }, {
      "referenceID" : 47,
      "context" : "occurrence as a context-dependent vector, assuming that each context corresponds to a different sense (Yarowsky, 1993).",
      "startOffset" : 102,
      "endOffset" : 118
    }, {
      "referenceID" : 39,
      "context" : "Both models, but especially the latter, are increasingly complex and opaque (Rogers et al., 2020), requiring advanced techniques to help humans understand their strengths and limitations (Jawahar et al.",
      "startOffset" : 76,
      "endOffset" : 97
    }, {
      "referenceID" : 19,
      "context" : ", 2020), requiring advanced techniques to help humans understand their strengths and limitations (Jawahar et al., 2019; Serrano and Smith, 2019).",
      "startOffset" : 97,
      "endOffset" : 144
    }, {
      "referenceID" : 43,
      "context" : ", 2020), requiring advanced techniques to help humans understand their strengths and limitations (Jawahar et al., 2019; Serrano and Smith, 2019).",
      "startOffset" : 97,
      "endOffset" : 144
    }, {
      "referenceID" : 21,
      "context" : "Word and sense embeddings The literature on vector-space semantic representations is enormous, ranging from traditional models such as LSA (Landauer and Dumais, 1997) to sophisticated deep contextualised embeddings such as BERT (Devlin et al.",
      "startOffset" : 139,
      "endOffset" : 166
    }, {
      "referenceID" : 12,
      "context" : "Word and sense embeddings The literature on vector-space semantic representations is enormous, ranging from traditional models such as LSA (Landauer and Dumais, 1997) to sophisticated deep contextualised embeddings such as BERT (Devlin et al., 2018).",
      "startOffset" : 228,
      "endOffset" : 249
    }, {
      "referenceID" : 16,
      "context" : "Although techniques are being constantly improved, the main principle is stable across models: vectors represent a word’s usage (and meaning) based on its distributional context (Harris, 1954).",
      "startOffset" : 178,
      "endOffset" : 192
    }, {
      "referenceID" : 45,
      "context" : "Although they can be randomly initialised and learned, unsupervised pre-training on raw corpora is common (Turian et al., 2010).",
      "startOffset" : 106,
      "endOffset" : 127
    }, {
      "referenceID" : 25,
      "context" : "Embeddings can be pre-trained as by-products of predictive neural language models (Mikolov et al., 2013), by factorisation of the co-occurrence matrix (Landauer and Dumais, 1997; Pennington et al.",
      "startOffset" : 82,
      "endOffset" : 104
    }, {
      "referenceID" : 21,
      "context" : ", 2013), by factorisation of the co-occurrence matrix (Landauer and Dumais, 1997; Pennington et al., 2014), etc.",
      "startOffset" : 54,
      "endOffset" : 106
    }, {
      "referenceID" : 35,
      "context" : ", 2013), by factorisation of the co-occurrence matrix (Landauer and Dumais, 1997; Pennington et al., 2014), etc.",
      "startOffset" : 54,
      "endOffset" : 106
    }, {
      "referenceID" : 4,
      "context" : ", due to rich morphology, non-standard text, and out-of-vocabulary forms (Bojanowski et al., 2017).",
      "startOffset" : 73,
      "endOffset" : 98
    }, {
      "referenceID" : 36,
      "context" : "They can be obtained using stacked recurrent layers as in ELMo (Peters et al., 2018), or attention-based transformers as in BERT (Devlin et al.",
      "startOffset" : 63,
      "endOffset" : 84
    }, {
      "referenceID" : 12,
      "context" : ", 2018), or attention-based transformers as in BERT (Devlin et al., 2018) and GPT-2 (Radford et al.",
      "startOffset" : 52,
      "endOffset" : 73
    }, {
      "referenceID" : 39,
      "context" : "On the downside, they are computationally heavy and opaque (Rogers et al., 2020), requiring sophisticated techniques such as probing to interpret predictions (Jawahar et al.",
      "startOffset" : 59,
      "endOffset" : 80
    }, {
      "referenceID" : 19,
      "context" : ", 2020), requiring sophisticated techniques such as probing to interpret predictions (Jawahar et al., 2019).",
      "startOffset" : 85,
      "endOffset" : 107
    }, {
      "referenceID" : 6,
      "context" : "Particularly relevant to our work are sense embeddings (Camacho-Collados and Pilehvar, 2018), in which a lexical unit is associated to several vectors (as in contextual models), but with some generalisation across occurrences (as in static models).",
      "startOffset" : 55,
      "endOffset" : 92
    }, {
      "referenceID" : 30,
      "context" : "Unsupervised sense (multi-prototype) embeddings can be obtained by adapting the objective of the learning procedure (Neelakantan et al., 2014), or with word sense induction methods based on clustering, e.",
      "startOffset" : 116,
      "endOffset" : 142
    }, {
      "referenceID" : 13,
      "context" : "For interpretability, resources such as WordNet can be used to semantically enhance static embeddings (Faruqui et al., 2015) or to learn representations for WordNet synsets (Rothe and Schütze, 2015), supersenses (Flekova and Gurevych, 2016), or Babelnet senses (Camacho-Collados et al.",
      "startOffset" : 102,
      "endOffset" : 124
    }, {
      "referenceID" : 40,
      "context" : ", 2015) or to learn representations for WordNet synsets (Rothe and Schütze, 2015), supersenses (Flekova and Gurevych, 2016), or Babelnet senses (Camacho-Collados et al.",
      "startOffset" : 56,
      "endOffset" : 81
    }, {
      "referenceID" : 15,
      "context" : ", 2015) or to learn representations for WordNet synsets (Rothe and Schütze, 2015), supersenses (Flekova and Gurevych, 2016), or Babelnet senses (Camacho-Collados et al.",
      "startOffset" : 95,
      "endOffset" : 123
    }, {
      "referenceID" : 7,
      "context" : ", 2015) or to learn representations for WordNet synsets (Rothe and Schütze, 2015), supersenses (Flekova and Gurevych, 2016), or Babelnet senses (Camacho-Collados et al., 2016).",
      "startOffset" : 144,
      "endOffset" : 175
    }, {
      "referenceID" : 26,
      "context" : "Interpretable semantic representations One of the most popular sense inventories in NLP is Wordnet (Miller et al., 1990), in which words are grouped into synsets and linked to each other via lexical-semantic relations (e.",
      "startOffset" : 99,
      "endOffset" : 120
    }, {
      "referenceID" : 27,
      "context" : "Ponzetto, 2012) is a semi-automatic multilingual lexicon similar to Wordnet and also quite popular for performing WSD in languages other than English (Moro et al., 2014).",
      "startOffset" : 150,
      "endOffset" : 169
    }, {
      "referenceID" : 34,
      "context" : "Supervised WSD relies on sense-annotated corpora specifying which of the senses in the inventory are employed in context (Pasini and Camacho-Collados, 2020), e.",
      "startOffset" : 121,
      "endOffset" : 156
    }, {
      "referenceID" : 29,
      "context" : "The fine granularity of sense inventories is often criticised as unrealistic (Navigli, 2009).",
      "startOffset" : 77,
      "endOffset" : 92
    }, {
      "referenceID" : 9,
      "context" : "One alternative is to represent senses using top-level synsets in Wordnet’s taxonomy, referred to as supersenses, reached via hypernymy relations (Ciaramita and Johnson, 2003; Schneider et al., 2016).",
      "startOffset" : 146,
      "endOffset" : 199
    }, {
      "referenceID" : 42,
      "context" : "One alternative is to represent senses using top-level synsets in Wordnet’s taxonomy, referred to as supersenses, reached via hypernymy relations (Ciaramita and Johnson, 2003; Schneider et al., 2016).",
      "startOffset" : 146,
      "endOffset" : 199
    }, {
      "referenceID" : 2,
      "context" : "In our evaluation, we employ the FrSemCor corpus, a French corpus in which nouns have been annotated using Wordnet supersenses as semantic tags (Barque et al., 2020).",
      "startOffset" : 144,
      "endOffset" : 165
    }, {
      "referenceID" : 17,
      "context" : "Although the set of 25 Wordnet top-level categories is quite popular, alternative representations with even coarser granularity can be useful for downstream applications (Jahan et al., 2018), such as a threeway classification of adjectives (Boleda et al.",
      "startOffset" : 170,
      "endOffset" : 190
    }, {
      "referenceID" : 5,
      "context" : ", 2018), such as a threeway classification of adjectives (Boleda et al., 2012) or animate vs.",
      "startOffset" : 57,
      "endOffset" : 78
    }, {
      "referenceID" : 23,
      "context" : ", (Lin, 1998), usually performing unsupervised WSD as a by-product.",
      "startOffset" : 2,
      "endOffset" : 13
    }, {
      "referenceID" : 46,
      "context" : "While automatically induced word senses are hard to interpret, they may be automatically labeled, for example, using hypernym-induction patterns (Ustalov et al., 2019).",
      "startOffset" : 145,
      "endOffset" : 167
    }, {
      "referenceID" : 5,
      "context" : ", Mihalcea (2003), especially for polysemy pattern detection (Boleda et al., 2012), and adapted to semantic frame induction using predicate-argument pairs (Jauhar and Hovy, 2017).",
      "startOffset" : 61,
      "endOffset" : 82
    }, {
      "referenceID" : 18,
      "context" : ", 2012), and adapted to semantic frame induction using predicate-argument pairs (Jauhar and Hovy, 2017).",
      "startOffset" : 80,
      "endOffset" : 103
    }, {
      "referenceID" : 41,
      "context" : "Seeds We used data provided by the Wolf, a French lexical resource automatically built from the Princeton Wordnet (Sagot and Fišer, 2008), to draw up the six seed lists Si.",
      "startOffset" : 114,
      "endOffset" : 137
    }, {
      "referenceID" : 1,
      "context" : "6 billion words crawled from the web (Baroni et al., 2009).",
      "startOffset" : 37,
      "endOffset" : 58
    }, {
      "referenceID" : 31,
      "context" : "The corpus has been POS tagged, lemmatised and morphologically analysed by an in-house parser trained on the French corpora of Universal Dependencies (Nivre et al., 2016).",
      "startOffset" : 150,
      "endOffset" : 170
    }, {
      "referenceID" : 2,
      "context" : "Evaluation data The FrSemCor corpus was used for evaluation (Barque et al., 2020).",
      "startOffset" : 60,
      "endOffset" : 81
    }, {
      "referenceID" : 8,
      "context" : "5 It contains manual annotations for more than 12,000 nouns in the Sequoia Treebank, a corpus of 3,009 sentences from different sources including morphological and syntactic annotations (Candito and Seddah, 2012).",
      "startOffset" : 186,
      "endOffset" : 212
    }, {
      "referenceID" : 29,
      "context" : "This crude method gives better results as the training corpus grows, since the coverage grows with size of the training corpus and selecting the most frequent supersense is a good heuristic (Navigli, 2009).",
      "startOffset" : 190,
      "endOffset" : 205
    }, {
      "referenceID" : 22,
      "context" : "We also compare our model to a state-of-the-art model in other WSD tasks: a French-specific version of BERT called FlauBERT (Le et al., 2020).",
      "startOffset" : 124,
      "endOffset" : 141
    }, {
      "referenceID" : 26,
      "context" : "io/FrSemCor/ 6 The Wordnet supersenses tagset, also known as Wordnet Unique Beginners (Miller et al., 1990), is composed of 25 nominal supersenses.",
      "startOffset" : 86,
      "endOffset" : 107
    }, {
      "referenceID" : 2,
      "context" : "Small adjustments have been made for the annotation of French nouns (Barque et al., 2020).",
      "startOffset" : 68,
      "endOffset" : 89
    }, {
      "referenceID" : 10,
      "context" : "Multi-facet nouns, on the other hand, have multiple but compatible meanings, a property that can be highlighted by copredication (Cruse, 2002; Ježek and Melloni, 2011).",
      "startOffset" : 129,
      "endOffset" : 167
    }, {
      "referenceID" : 20,
      "context" : "Multi-facet nouns, on the other hand, have multiple but compatible meanings, a property that can be highlighted by copredication (Cruse, 2002; Ježek and Melloni, 2011).",
      "startOffset" : 129,
      "endOffset" : 167
    } ],
    "year" : 2020,
    "abstractText" : "Contextualised embeddings such as BERT have become de facto state-of-the-art references in many NLP applications, thanks to their impressive performances. However, their opaqueness makes it hard to interpret their behaviour. SLICE is a hybrid model that combines supersense labels with contextual embeddings. We introduce a weakly supervised method to learn interpretable embeddings from raw corpora and a small lists of seed words. Our model is able to represent both a word and its context as embeddings into the same compact space, whose dimensions correspond to interpretable supersenses. We assess the model in a task of word sense disambiguation for French nouns. The little amount of supervision required makes it particularly well suited for low-resourced languages. Thanks to its interpretability, we perform linguistic analyses about the predicted supersenses in terms of input word and context representations.",
    "creator" : "TeX"
  }
}