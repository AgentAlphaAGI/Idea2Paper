{
  "name" : "COLING_2020_13_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "TWEETSUM: Event oriented Social Summarization Dataset",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Social media has become an important real-time information source, especially during emergencies, natural disasters and other hot events. According to a new Pew Research Center survey, social media has surpassed traditional news platforms (such as TV and radio) as a news source for Americans: about twothirds of American adults (68%) get news via social media. Among all major social media sites, Twitter is still the site Americans most commonly use for news, with 71% of Twitter’s users get their news from Twitter. However, it can often be daunting to catch up with the most recent contents due to high volume and velocity of tweets. Hence, social summarization aiming to acquire the most representative and concise information from massive tweets when a hot event happens is particularly urgent.\nIn recent years, many large-scale summarization datasets have been proposed such as New York Times (Sandhaus, 2008), Gigaword (Napoles et al., 2012), NEWSROOM (Grusky et al., 2018) and CNN/DAILYMAIL (Nallapati et al., 2016). However, most of these datasets focus on formal document summarization. Actually, social media text has many different characteristics from formal documents: 1) Short. The length of a tweet is limited to 280 words, which is much shorter than formal document. 2) Informal. Tweets usually contains informal expressions such as abbrivations, typos, special symbols and so on, which make tweets more difficult to deal with. 3) Social signal. There are different kinds of social signals on social media such as hashtags, urls and emojis. 4) Potential relations. Tweets are generated by users and hence have potential connections through user relationship. Because of these characteristics, traditional summarization methods often do not perform well on social media.\nThough there exists some social media summarization datasets(Hu et al., 2015; Avinesh et al., 2018; Duan et al., 2012; Cao et al., 2016; Nguyen et al., 2018). However, these datasets only consider the text on social media and ignore the potential social signals on social network. In a social context, the\ninteractions between friends are obviously different from that between strangers. This phenomenon demonstrates that social relationship can affect user behavior patterns and consequently affect the tweets content they post. This inspires us to consider integrating social relations relevant signals when analyzing social information.\nIn this paper, we construct an event-oriented large-scale dataset with user relations for social summarization called TWEETSUM. It contains 12 real world hot events with a total of 44,034 tweets and 11,240 users. In summary, this paper provides the following contributions: (1) Construct an event-oriented social media summarization dataset, TWEETSUM, which contains social signals. To our knowledge, it is the first summarization dataset that contains user relationships relevant social signals, such as hashtags and user profiles and so on; (2) Create expert summaries for each socail event and verified the existence of sociological theory in real data, including social consistency and contagion; (3) Evaluate the performance of typical extractive summarization models on our TWEETSUM dataset to provide benchmarks and validate the effectiveness of the dataset."
    }, {
      "heading" : "2 TWEETSUM DATASET",
      "text" : ""
    }, {
      "heading" : "2.1 Task and Data Collection",
      "text" : "Tweets summarization aims to find a group of representative tweets for a specifc topic. Given a collection of tweets about an event T = [t1; t2; .....; tm], our goal is to extract a set of tweets S = [s1; s2; ...; sn] (n << m), which contain as much important information and as little redundant information as possible at the same time (Rudrapal et al., 2018).\nThe dataset is created using the public Twitter data collected by University of Illinois1 as the raw data. The detailed process of data collection is shown summarized as follows: (1) We first select twelve hot events happened in May, June and July 2011, including sports, technology and science, natural disasters, politics, terrorist attacks and so on. The events selected should satisfy the following conditions: (i) Widely spread on the Internet and cause a heated discussion on social media; (ii) Last longer than 30 days; (iii) Be impressive to news providers. (2) Since each hot event can have multiple hashtags, such as “#nba” and “#nbafinals”, we then search the tweets which contain any of these hashtags or any of the keywords obtained by getting rid of “#” from hashtags. (3) After obtaining the event-oriented data, we carefully preprocess the data as follows: (i) Merge identical tweets; (ii) Remove tweets whose length are shorter than 3 other than hashtags, keywords, mentions, URLs and stop words; (iii) Delete tweets whose author has no connection with others. (4) For each event, we further collect user profiles and user relationships. We filter users whose degree is smaller than 1 and obtain 11,240 users with their relations. Finally, we collect user profiles including User ID, historical tweets records, Tweet timestamp and Retweet Count.\n2.2 Expert Summaries Creation\n0.60000\nTWEETSUM\nTo verify summarization performance, we create expert summaries for each event. Specifically, for each of the 12 events, we ask annotators to select most representative 25 tweets as expert summary. Since different annotators have different understandings of the same event, we ask 4 annotators to create expert summary individually for each event in order to eliminate the subjective factors of users and improve the objectivity and accuracy of expert summary. To\nevaluate the quality of all expert summaries, we further ask 3 other annotators to score all summaries in range [1, 5] based on the coverage, diversity and readability. If only 0-6 tweets are satisfactory, the summary is scored as 1, 6-12 tweets as 2 scores, 12-18 tweets as 3 scores, 18-24 tweets as 4 scores. If all tweets are good, the score is 5. We remain the summaries with scores greater than or equal to 3 and\n1https://wiki.illinois.edu/wiki/display/forward/Dataset-UDI-TwitterCrawl-Aug20\nrequire modifications to those low-quality summaries until they meet the criteria. In order to ensure the agreement of multiple expert summaries of each event, we conduct the mutual evaluation among them, and the results are shown in Figure 1."
    }, {
      "heading" : "3 Data Properties and Analysis",
      "text" : "In this section, we introduce each part of the TWEETSUM dataset in detail. The dataset consists of 12 hot events, each of which contains four parts: tweets text, user relations, user profiles, and manually created expert summaries. The detailed statistics of each part are shown in Table 1. Due to the limited space, we only show the statistics of four events.\nIndicated by social theories, i.e. consistency (Abelson, 1983) and homophily (Mcpherson et al., 2001), social relations will affect the user behaviors and consequently influence the content. User relations are the unique property of our dataset compared with other summarization datasets.\nWe visualize the structure of one events social network and the result is shown in Figure 2. Users and their relationships constitute an undirected graph G(V,E), where V is user set and E is relation set. We observe some homophily groups, which may indicate that users being friends tend to share similar opinions or topics. We further analyze the words overlap ratio\nbetween friends and strangers respectively. Figure 3 shows the 1-gram and 2-gram overlap ratio under all 12 events. The average 1-gram and 2-gram overlap ratio between friends (26.92% and 4.01%) are consistently higher than that between strangers (25.40% and 3.45%), which demonstrates the impact of social relations on user behavior. We further conduct two sample t-test where null hypothesis H0 means there is no difference between tweets posted by friends and those randomly selected tweets, while alternative hypothesis H1 means the distance between tweets posted by friends is smaller than that of randomly selected tweets. We define the distance of two tweets as : Dij = ||ti − tj ||2, where ti is the TFIDF representation of the i-th tweet. The p-value shown in Table 1 suggests to reject H0, which demonstrates the influence of social relation on the tweet content.\n4 Experiments\n4.1 Compared methods\nTo verify the effectiveness of our TWEETSUM dataset, we choose some typical extractive summarization methods as baseline methods. (1) Expert: denotes the average mutual assessment of expert summaries. (2) Random: selects tweets randomly from each hot events set to form summaries. (3) LexRank: adopts PageRank-like algorithm to rank and select tweets (Erkan and Radev, 2004). (4) LSA: exploits SVD (Gong and Liu, 2001) and selects the highest-ranked tweets from each singular vector. (5) MDSS: uses two-level sparse representation model (Liu et al., 2015). (6) DSDR:\nuses data reconstruction method (He et al., 2012). (7) SNSR: integrates the social relationship into a unified sparse coding optimization framework(He and Duan, 2018). (8) Fine-Tuning BERT: We fine\ntune the pre-trained BERT model (Devlin et al., 2018) and learn representations for tweets. Summaries are choosen according to cosine similarity."
    }, {
      "heading" : "4.2 Evaluation Methodologies",
      "text" : "ROUGE is the most commonly used evaluation metric in summarization task, which counts number of overlapping units such as n-gram, word sequences and word pairs between the machine-generated summary and reference summaries. (Lin and Hovy, 2003) proposed different ROUGE matrices. Here, we use the F-measures of ROUGE-1, 2, ROUGE-L and ROUGE-SU* as our evaluation metric."
    }, {
      "heading" : "4.3 Results and Discussions",
      "text" : "Table 2 shows the performance of different baselines on our dataset. As we can see, all of these models have improvement over the Random baseline, especially SNSR model, which achieves the best performance and outperforms the Random baseline with an absolute gain of 3.31% R-1, 4.45% R-2, 3.57% R-L and 3.39% R-SU*. The main reason is that SNSR captures social relations among tweets.\nHowever, the imporvment of other models are not as significant as SNSR. The reason is that most of these models are designed for formal documents such as news articles, thus not suitable for tweets. The neural network based model bert has a strong ability in feature extraction. However, the BERT model still lags behind the best model. There are mainly three reasons: 1) Learning an efficient tweet representation still remains a big challenge since tweets are short and noisy. 2) It only considers text content and ignores relations among tweets. 3) The sum-\nmary selection strategy is relatively simple. To further prove the effectiveness of social relations, we remove the relation component of SNSR (indicated by -social), which brings performance deterioration.\nAs we discussed above, there are multiple types of social signals in social media which can provide various kinds of additional information. These heterogeneous signals contain a large amount of information, which is conducive to generating summaries. This inspires us to further explore to integrate these additional signals to improve social summarization."
    }, {
      "heading" : "5 Conclusion and Future Work",
      "text" : "In this paper, we construct an event-oriented social media summarization dataset, called TWEETSUM. To better explore how social signals help social summarization, we filter some outliers, keeping social network dense to some extent, and conduct experiments to verify the influence of social signals on user generated content. We further analyze the characteristics of this dataset in detail and validate the influence of social relations on tweets content selection. Both traditional summarization methods and neural network-based methods are tested on our dataset. More research space can be extended based on this dataset."
    } ],
    "references" : [ {
      "title" : "Whatever became of consistency theory",
      "author" : [ "Robert P Abelson." ],
      "venue" : "Personality and Social Psychology Bulletin, 9(1):37–54.",
      "citeRegEx" : "Abelson.,? 1983",
      "shortCiteRegEx" : "Abelson.",
      "year" : 1983
    }, {
      "title" : "Live blog corpus for summarization",
      "author" : [ "PVS Avinesh", "Maxime Peyrard", "Christian M Meyer." ],
      "venue" : "LREC.",
      "citeRegEx" : "Avinesh et al\\.,? 2018",
      "shortCiteRegEx" : "Avinesh et al\\.",
      "year" : 2018
    }, {
      "title" : "Tgsum: Build tweet guided multi-document summarization dataset",
      "author" : [ "Ziqiang Cao", "Chengyao Chen", "Wenjie Li", "Sujian Li", "Furu Wei", "Ming Zhou." ],
      "venue" : "AAAI.",
      "citeRegEx" : "Cao et al\\.,? 2016",
      "shortCiteRegEx" : "Cao et al\\.",
      "year" : 2016
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "Twitter topic summarization by ranking tweets using social influence and content quality",
      "author" : [ "Yajuan Duan", "Zhumin Chen", "Furu Wei", "Zhou Ming", "Heung Yeung Shum." ],
      "venue" : "COLING.",
      "citeRegEx" : "Duan et al\\.,? 2012",
      "shortCiteRegEx" : "Duan et al\\.",
      "year" : 2012
    }, {
      "title" : "Lexrank: Graph-based lexical centrality as salience in text summarization",
      "author" : [ "G. Erkan", "D.R. Radev." ],
      "venue" : "Journal of Artificial Intelligence Research, 22:457–479.",
      "citeRegEx" : "Erkan and Radev.,? 2004",
      "shortCiteRegEx" : "Erkan and Radev.",
      "year" : 2004
    }, {
      "title" : "Generic text summarization using relevance measure and latent semantic analysis",
      "author" : [ "Yihong Gong", "Xin Liu." ],
      "venue" : "SIGIR, pages 19–25.",
      "citeRegEx" : "Gong and Liu.,? 2001",
      "shortCiteRegEx" : "Gong and Liu.",
      "year" : 2001
    }, {
      "title" : "Newsroom: A dataset of 1.3 million summaries with diverse extractive strategies",
      "author" : [ "Max Grusky", "Mor Naaman", "Yoav Artzi" ],
      "venue" : null,
      "citeRegEx" : "Grusky et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Grusky et al\\.",
      "year" : 2018
    }, {
      "title" : "Twitter summarization based on social network and sparse reconstruction",
      "author" : [ "Ruifang He", "Xingyi Duan." ],
      "venue" : "AAAI.",
      "citeRegEx" : "He and Duan.,? 2018",
      "shortCiteRegEx" : "He and Duan.",
      "year" : 2018
    }, {
      "title" : "Document summarization based on data reconstruction",
      "author" : [ "Zhanying He", "Chun Chen", "Jiajun Bu", "Can Wang", "Lijun Zhang", "Deng Cai", "Xiaofei He." ],
      "venue" : "AAAI, pages 620–626.",
      "citeRegEx" : "He et al\\.,? 2012",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2012
    }, {
      "title" : "Lcsts: A large scale chinese short text summarization dataset",
      "author" : [ "Baotian Hu", "Qingcai Chen", "Fangze Zhu" ],
      "venue" : null,
      "citeRegEx" : "Hu et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2015
    }, {
      "title" : "Automatic evaluation of summaries using n-gram co-occurrence statistics",
      "author" : [ "Chin-Yew Lin", "Eduard H. Hovy." ],
      "venue" : "HLT-NAACL.",
      "citeRegEx" : "Lin and Hovy.,? 2003",
      "shortCiteRegEx" : "Lin and Hovy.",
      "year" : 2003
    }, {
      "title" : "Multi-document summarization based on two-level sparse representation model",
      "author" : [ "He Liu", "Hongliang Yu", "Zhi-Hong Deng." ],
      "venue" : "AAAI.",
      "citeRegEx" : "Liu et al\\.,? 2015",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2015
    }, {
      "title" : "Birds of a feather: Homophily in social networks",
      "author" : [ "Miller Mcpherson", "Lynn Smithlovin", "James M Cook." ],
      "venue" : "Review of Sociology, 27(1).",
      "citeRegEx" : "Mcpherson et al\\.,? 2001",
      "shortCiteRegEx" : "Mcpherson et al\\.",
      "year" : 2001
    }, {
      "title" : "Abstractive text summarization using sequence-to-sequence rnns and beyond",
      "author" : [ "Ramesh Nallapati", "Bowen Zhou", "Cicero Nogueira Dos Santos", "Caglar Gulcehre", "Bing Xiang." ],
      "venue" : "SIGNLL.",
      "citeRegEx" : "Nallapati et al\\.,? 2016",
      "shortCiteRegEx" : "Nallapati et al\\.",
      "year" : 2016
    }, {
      "title" : "Annotated gigaword",
      "author" : [ "Courtney Napoles", "Matthew Gormley", "Benjamin Van Durme." ],
      "venue" : "Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction, pages 95–100.",
      "citeRegEx" : "Napoles et al\\.,? 2012",
      "shortCiteRegEx" : "Napoles et al\\.",
      "year" : 2012
    }, {
      "title" : "Tsix: A human-involvedcreation dataset for tweet summarization",
      "author" : [ "Minh-Tien Nguyen", "Dac Viet Lai", "Huy-Tien Nguyen", "Minh-Le Nguyen." ],
      "venue" : "LREC.",
      "citeRegEx" : "Nguyen et al\\.,? 2018",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2018
    }, {
      "title" : "A survey on automatic twitter event summarization",
      "author" : [ "Dwijen Rudrapal", "Amitava Das", "Baby Bhattacharya." ],
      "venue" : "JIPS, 14(1):79–100.",
      "citeRegEx" : "Rudrapal et al\\.,? 2018",
      "shortCiteRegEx" : "Rudrapal et al\\.",
      "year" : 2018
    }, {
      "title" : "The new york times annotated corpus",
      "author" : [ "Evan Sandhaus." ],
      "venue" : "Linguistic Data Consortium, Philadelphia, 6(12).",
      "citeRegEx" : "Sandhaus.,? 2008",
      "shortCiteRegEx" : "Sandhaus.",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 18,
      "context" : "In recent years, many large-scale summarization datasets have been proposed such as New York Times (Sandhaus, 2008), Gigaword (Napoles et al.",
      "startOffset" : 99,
      "endOffset" : 115
    }, {
      "referenceID" : 15,
      "context" : "In recent years, many large-scale summarization datasets have been proposed such as New York Times (Sandhaus, 2008), Gigaword (Napoles et al., 2012), NEWSROOM (Grusky et al.",
      "startOffset" : 126,
      "endOffset" : 148
    }, {
      "referenceID" : 7,
      "context" : ", 2012), NEWSROOM (Grusky et al., 2018) and CNN/DAILYMAIL (Nallapati et al.",
      "startOffset" : 18,
      "endOffset" : 39
    }, {
      "referenceID" : 10,
      "context" : "Though there exists some social media summarization datasets(Hu et al., 2015; Avinesh et al., 2018; Duan et al., 2012; Cao et al., 2016; Nguyen et al., 2018).",
      "startOffset" : 60,
      "endOffset" : 157
    }, {
      "referenceID" : 1,
      "context" : "Though there exists some social media summarization datasets(Hu et al., 2015; Avinesh et al., 2018; Duan et al., 2012; Cao et al., 2016; Nguyen et al., 2018).",
      "startOffset" : 60,
      "endOffset" : 157
    }, {
      "referenceID" : 4,
      "context" : "Though there exists some social media summarization datasets(Hu et al., 2015; Avinesh et al., 2018; Duan et al., 2012; Cao et al., 2016; Nguyen et al., 2018).",
      "startOffset" : 60,
      "endOffset" : 157
    }, {
      "referenceID" : 2,
      "context" : "Though there exists some social media summarization datasets(Hu et al., 2015; Avinesh et al., 2018; Duan et al., 2012; Cao et al., 2016; Nguyen et al., 2018).",
      "startOffset" : 60,
      "endOffset" : 157
    }, {
      "referenceID" : 16,
      "context" : "Though there exists some social media summarization datasets(Hu et al., 2015; Avinesh et al., 2018; Duan et al., 2012; Cao et al., 2016; Nguyen et al., 2018).",
      "startOffset" : 60,
      "endOffset" : 157
    }, {
      "referenceID" : 17,
      "context" : "; sn] (n << m), which contain as much important information and as little redundant information as possible at the same time (Rudrapal et al., 2018).",
      "startOffset" : 125,
      "endOffset" : 148
    }, {
      "referenceID" : 0,
      "context" : "consistency (Abelson, 1983) and homophily (Mcpherson et al.",
      "startOffset" : 12,
      "endOffset" : 27
    }, {
      "referenceID" : 13,
      "context" : "consistency (Abelson, 1983) and homophily (Mcpherson et al., 2001), social relations will affect the user behaviors and consequently influence the content.",
      "startOffset" : 42,
      "endOffset" : 66
    }, {
      "referenceID" : 5,
      "context" : "(3) LexRank: adopts PageRank-like algorithm to rank and select tweets (Erkan and Radev, 2004).",
      "startOffset" : 70,
      "endOffset" : 93
    }, {
      "referenceID" : 6,
      "context" : "(4) LSA: exploits SVD (Gong and Liu, 2001) and selects the highest-ranked tweets from each singular vector.",
      "startOffset" : 22,
      "endOffset" : 42
    }, {
      "referenceID" : 12,
      "context" : "(5) MDSS: uses two-level sparse representation model (Liu et al., 2015).",
      "startOffset" : 53,
      "endOffset" : 71
    }, {
      "referenceID" : 9,
      "context" : "(6) DSDR: uses data reconstruction method (He et al., 2012).",
      "startOffset" : 42,
      "endOffset" : 59
    }, {
      "referenceID" : 8,
      "context" : "(7) SNSR: integrates the social relationship into a unified sparse coding optimization framework(He and Duan, 2018).",
      "startOffset" : 96,
      "endOffset" : 115
    }, {
      "referenceID" : 3,
      "context" : "tune the pre-trained BERT model (Devlin et al., 2018) and learn representations for tweets.",
      "startOffset" : 32,
      "endOffset" : 53
    }, {
      "referenceID" : 11,
      "context" : "(Lin and Hovy, 2003) proposed different ROUGE matrices.",
      "startOffset" : 0,
      "endOffset" : 20
    } ],
    "year" : 2020,
    "abstractText" : "With social media becoming popular, a vast of short and noisy messages are produced by millions of users when a hot event happens. Developing social summarization systems becomes more and more critical for people to quickly grasp core and essential information. However, the publicly available and high-quality large scale dataset under social media situation is rare. Constructing such corpus is not easy and very expensive since short texts have very complex social characteristics. Though there exist some datasets, they only consider the text on social media and ignore the potential user relations relevant signals on social network. In this paper, we construct TWEETSUM, a new event-oriented dataset for social summarization. The original data is collected from twitter and contains 12 real world hot events with a total of 44,034 tweets and 11,240 users. We create expert summaries for each event, and we also have the annotation quality evaluation. In addition, we collect additional social signals (i.e. user relations, hashtags and user profiles) and further establish user relation network for each event. To our knowledge, it is the first event-oriented social summarization dataset that contains social relationships. Besides the detailed dataset description, we show the performance of several typical extractive summarization methods on TWEETSUM to establish baselines. For further researches, we will release this dataset to the public.",
    "creator" : "TeX"
  }
}