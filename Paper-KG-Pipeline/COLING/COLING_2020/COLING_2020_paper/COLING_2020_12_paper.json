{
  "name" : "COLING_2020_12_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Exploring the Value of Personalized Word Embeddings",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Word embeddings have become ubiquitous in natural language processing applications. Usually, embeddings are trained from a large corpus of news or web data that contains writing from many sources and authors (Mikolov et al., 2013; Pennington et al., 2014). These embeddings capture syntactic and semantic properties of the language of all authors who contributed to this corpus.\nMulti-source corpora provide large volumes of data, but they may not lead to the ideal representations for individuals. For instance, the word “hometown” may have a different representation for different individuals. For some, it may relate to words such as “hills,” “trees,” and “family,” whereas for others may be more strongly connected to “ocean,” “beach,” and “friends.” These personalized representations differ among individuals, and also differ from a more generic representation that often tends to capture words that are semantically related at concept level, such as “city,” “town,” or “place.”\nIn this paper, we present the idea of personalized word embeddings. We explore differences in personalized word representations using a corpus of English Reddit posts that contains a large number of posts per author (to be released). We use the embeddings to initialize a language model and show that personalization leads to better results than generic embeddings. One potential application of this work is personalized text generation for auto-completion to speed up text entry. Another application is dialog systems that follow the speaking style of certain professionals (e.g., counselors, advisors). Finally, personalized word representations could particularly help users with atypical writing styles that are not currently well served by models trained to suit the majority."
    }, {
      "heading" : "2 Related Work",
      "text" : "Prior work has considered user embeddings, where one vector is learned for each user in the data (we learn a set of vectors per user, one for each word in the vocabulary). User embeddings have been used for dialog generation (Li et al., 2016), query auto-completion (Jaech and Ostendorf, 2018), authorship attribution (Ebrahimi and Dou, 2016), and sarcasm detection (Kolchinski and Potts, 2018). Amer et al. (2016) learn a set of embeddings from the books that a user adds to their profile. Some approaches also use network information (Zeng et al., 2017; Huang et al., 2016).\nPersonalization has been studied for marketing, webpage layout, recommendations, query completion, and dialog (Eirinaki and Vazirgiannis, 2003; Das et al., 2007). Welch et al. (2019b) and Welch et al.\n(2019a) explored predicting response time, common messages, and author relationships from personal conversation data. Zhang et al. (2018) conditioned dialog systems on artificially constructed personas and Madotto et al. (2019) used meta-learning to improve this process. Goal-oriented dialog has used demographics (i.e. age, gender) to condition system response generation, showing that this relatively coarse grained personalization improves system performance (Joshi et al., 2017)."
    }, {
      "heading" : "3 Personalized Word Embeddings",
      "text" : "Definition. Personalized word embeddings are vector representations of words derived from the text produced by a single author. We use the text produced by a Reddit user s in their comments Cs to create their word embeddings. We apply the method described below to this set and produce an embedding matrix, Cs 7→ W |V |×ks , where V is the vocabulary and k represents the embedding dimension.\nJoint Learning of Personal and Generic Word Embeddings. We jointly learn a generic embedding matrix and an embedding matrix for each author, inspired by Bamman et al. (2014). Each matrix W ∈ R|V |×k has a row for each vocabulary word and a k-dimensional vector for each embedding. The hidden layer is calculated as h = wᵀWgeneric +wᵀWs where w represents the one-hot encoding of a word and s represents an author. This is a modified skip-gram architecture (Mikolov et al., 2013), which sums two terms so that back-propagation updates the generic matrix and a author-specific matrix. It allows the generic matrix to benefit from all data while learning author-specific deviations in the same space.\nDataset. We use data for the 100 most active users1 in a corpus collected from Reddit.These users have from 49k to 249k posts, with 73k on average. Posts contain 29 tokens on avererage and come from 3.6k subreddits. The largest fraction (18.6%) belong to the subreddit AskReddit; the next two largest are blog and politics with 4.8% and 4.7% of the comments respectively.\nWe use the set of messages from all 100 authors to generate embeddings for all words that occur at least five times (across all users). This yields a vocabulary of 177k words. We learn 100-dimensional embeddings with an initial learning rate of 0.025 and a window size of five, using L2 regularization due to the increased number of parameters (tuned in preliminary experiments. Using this method, we learn 101 embeddings for each word – a generic representation, and a separate representation for each user."
    }, {
      "heading" : "4 Differences across Individual Word Representations and Usages",
      "text" : "Individuals use the same word in different ways in different contexts. Examining these differences can give insight into individual topic and style preferences, and word associations. To illustrate these differences, in Table 1, we show different ways that two users in our dataset use the word “health.” Though these words may be used in similar contexts, the meaning of, and topics associated with these words is often different for each user, which affects the words we would expect to come after it. These preferences are reflected in the top neighbors for the word “health” for each user.\nTo gain a deeper understanding of these differences, we analyze personal and generic embeddings for specific word groups based on the Linguistic Inquiry and Word Count (LIWC) lexicon (Pennebaker et al., 2001) and part-of-speech (POS) tags. This analysis can help us understand what types of words tend to have different representations across users and are therefore more personal in nature. We POS tag the messages with the Stanford CoreNLP tagger (Toutanova et al., 2003; Manning et al., 2014). For\n1We excluded users that appear on a https://www.reddit.com/r/autowikibot/wiki/redditbotspublic list of bots or who appear to be automated based on manual inspection.\neach word in the vocabulary, we assign a tag if the tagger gives the same tag at least 95% of the time, otherwise the word is ignored. LIWC categories are looked up in the lexicon that contains words and word stems and a word may have multiple categories, in which case it counts toward each.\nWe look at the proportion of word types in the 5k most dissimilar words for each user. We define word similarity as the cosine distance between a word’s generic embedding and its author-specific embedding. We break this into subsets and look at how the distribution changes as we approach the most dissimilar words. A visualization is provided in Figure 1. We find the set of most dissimilar words includes more function words, words relating to space and time (Relativ), cognitive processes (CogProc), and social words, as well as more adjectives and nouns. This suggests that these types of words may tend to have more personal usage than other types. These results are consistent with prior work that has found function words are effective for recognizing style and measuring style similarity (Gonzales et al., 2010) and for authorship attribution (Mosteller and Wallace, 1963; Gamon, 2004; Argamon et al., 2003)."
    }, {
      "heading" : "5 Language Modeling",
      "text" : "Our first test case for personalized word embeddings is language modeling. We train language models on our data with our embeddings as input. We use Merity et al. (2018b; Merity et al. (2018a) as our baseline language model. It is an autoregressive language model that has state-of-the-art results by combining regularization techniques and has been widely used. Although more recent models can achieve better perplexities on standard benchmarks (Melis et al., 2019; Dai et al., 2019), we find that not all models have code available or that they take far more time to run than Merity et al. (2018b)’s model. We use the same hidden layer sizes and drop-out rates as in their original experiments, but untie the weights of the encoder and decoder as that gave better performance in preliminary experiments.\nTo use our personalized embeddings, we modify the architecture to take as input the concatenation of the personalized user-specific embedding and the generic embedding for each word. The same embedding dropout mask is applied to both word embeddings. The embeddings are trained on all available user data, but the more computationally expensive language models are not. We use a subsample of our dataset with 1,000 posts for each user and an 80/10/10 split for training, validation, and testing. The same splits are used for generic and personalized models, varying only the embedding layer.\nTo measure the ability of our models to predict the next word, we use two metrics: (1) mean reciprocal rank (MRR), calculated as one divided by the rank of the correct word choice in the descending list of next word probabilities and averaged over all instances, and (2) perplexity.\nSingle User Embeddings. We also consider an approach in which just one vector is learned for each user (rather than one for each user-word pair). This is an approach widely used in previous work (Kolchinski and Potts, 2018; Li et al., 2016). This user vector is concatenated to the generic word embedding.\nThe results in Table 3 suggest that using the combined personalized and generic embeddings improves performance significantly over single vector user representations and over generic embeddings.\nWe can also analyze accuracy when predicting words belonging to particular parts of speech and LIWC categories. Our intuition is that a model that uses personalized word embeddings would be better at predicting words belonging to the four LIWC categories whose words are most distant from the generic space. Tables 2a and 2b show that for almost all categories, the personalized word embeddings lead to the best performance, though for relativity words, single user vectors performs slightly better."
    }, {
      "heading" : "6 Authorship Attribution",
      "text" : "We also use a language model trained with personalized word embeddings to perform the task of authorship attribution.2 We build a language model for each author using a sample of 10k posts for training and 1k for validation. We then hold out another sample of 1k posts to use for authorship attribution. The language models for all authors are separately run on the held out set, and the model with the lowest perplexity is then chosen as the assigned author. Table 3 shows there is a statistically significant improvement for our personalized embeddings method. This is a difficult task with 100 classes, so the accuracy is low, but the MRR suggests the correct author is usually in the top 3 model choices."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this paper, we explored personalized word embeddings. Using a large corpus of Reddit comments, we generated personalized word embeddings for 100 individuals, and performed analyses of the differences between personalized and generic embeddings for specific groups of words. We showed that using personalized word embeddings to initialize a language model improves perplexity over a model that uses generic word embeddings or one that only learns single vectors for each user as has been frequently done in previous work. Further, we showed that the embeddings can be used to improve performance on authorship attribution. We will release the code and data to support future work on personalization.\n2Note that we do not consider datasets such as Kestemont et al. (2019) because they do not provide the volume of data needed for our approach and our goal is to compare generic and personalized embeddings, not to set a new state-of-the-art."
    } ],
    "references" : [ {
      "title" : "Toward word embedding for personalized information retrieval",
      "author" : [ "Nawal Ould Amer", "Philippe Mulhem", "Mathias Géry." ],
      "venue" : "Neu-IR: The SIGIR 2016 Workshop on Neural Information Retrieval.",
      "citeRegEx" : "Amer et al\\.,? 2016",
      "shortCiteRegEx" : "Amer et al\\.",
      "year" : 2016
    }, {
      "title" : "Style mining of electronic messages for multiple authorship discrimination: First results",
      "author" : [ "Shlomo Argamon", "Marin Šarić", "Sterling S Stein." ],
      "venue" : "Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 475–480. ACM.",
      "citeRegEx" : "Argamon et al\\.,? 2003",
      "shortCiteRegEx" : "Argamon et al\\.",
      "year" : 2003
    }, {
      "title" : "Distributed representations of geographically situated language",
      "author" : [ "David Bamman", "Chris Dyer", "Noah A Smith." ],
      "venue" : "Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), volume 2, pages 828–834.",
      "citeRegEx" : "Bamman et al\\.,? 2014",
      "shortCiteRegEx" : "Bamman et al\\.",
      "year" : 2014
    }, {
      "title" : "Transformer-XL: Attentive language models beyond a fixed-length context",
      "author" : [ "Zihang Dai", "Zhilin Yang", "Yiming Yang", "Jaime Carbonell", "Quoc Le", "Ruslan Salakhutdinov." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 2978–2988, Florence, Italy, July. Association for Computational Linguistics.",
      "citeRegEx" : "Dai et al\\.,? 2019",
      "shortCiteRegEx" : "Dai et al\\.",
      "year" : 2019
    }, {
      "title" : "Google news personalization: scalable online collaborative filtering",
      "author" : [ "Abhinandan S Das", "Mayur Datar", "Ashutosh Garg", "Shyam Rajaram." ],
      "venue" : "Proceedings of the 16th international conference on World Wide Web, pages 271–280. ACM.",
      "citeRegEx" : "Das et al\\.,? 2007",
      "shortCiteRegEx" : "Das et al\\.",
      "year" : 2007
    }, {
      "title" : "Personalized semantic word vectors",
      "author" : [ "Javid Ebrahimi", "Dejing Dou." ],
      "venue" : "Proceedings of the 25th ACM International on Conference on Information and Knowledge Management, pages 1925–1928. ACM.",
      "citeRegEx" : "Ebrahimi and Dou.,? 2016",
      "shortCiteRegEx" : "Ebrahimi and Dou.",
      "year" : 2016
    }, {
      "title" : "Web mining for web personalization",
      "author" : [ "Magdalini Eirinaki", "Michalis Vazirgiannis." ],
      "venue" : "ACM Transactions on Internet Technology (TOIT), 3(1):1–27.",
      "citeRegEx" : "Eirinaki and Vazirgiannis.,? 2003",
      "shortCiteRegEx" : "Eirinaki and Vazirgiannis.",
      "year" : 2003
    }, {
      "title" : "Linguistic correlates of style: Authorship classification with deep linguistic analysis features",
      "author" : [ "Michael Gamon." ],
      "venue" : "Proceedings of the 20th International Conference on Computational Linguistics, page 611. Association for Computational Linguistics.",
      "citeRegEx" : "Gamon.,? 2004",
      "shortCiteRegEx" : "Gamon.",
      "year" : 2004
    }, {
      "title" : "Language style matching as a predictor of social dynamics in small groups",
      "author" : [ "Amy L Gonzales", "Jeffrey T Hancock", "James W Pennebaker." ],
      "venue" : "Communication Research, 37(1):3–19.",
      "citeRegEx" : "Gonzales et al\\.,? 2010",
      "shortCiteRegEx" : "Gonzales et al\\.",
      "year" : 2010
    }, {
      "title" : "Enriching cold start personalized language model using social network information",
      "author" : [ "Yu-Yang Huang", "Rui Yan", "Tsung-Ting Kuo", "Shou-De Lin." ],
      "venue" : "International Journal of Computational Linguistics & Chinese Language Processing, Volume 21, Number 1, June 2016.",
      "citeRegEx" : "Huang et al\\.,? 2016",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2016
    }, {
      "title" : "Personalized language model for query auto-completion",
      "author" : [ "Aaron Jaech", "Mari Ostendorf." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 700–705, Melbourne, Australia, July. Association for Computational Linguistics.",
      "citeRegEx" : "Jaech and Ostendorf.,? 2018",
      "shortCiteRegEx" : "Jaech and Ostendorf.",
      "year" : 2018
    }, {
      "title" : "Personalization in goal-oriented dialog",
      "author" : [ "Chaitanya K Joshi", "Fei Mi", "Boi Faltings." ],
      "venue" : "arXiv preprint arXiv:1706.07503.",
      "citeRegEx" : "Joshi et al\\.,? 2017",
      "shortCiteRegEx" : "Joshi et al\\.",
      "year" : 2017
    }, {
      "title" : "Overview of the Cross-domain Authorship Attribution Task at PAN 2019",
      "author" : [ "Mike Kestemont", "Efstathios Stamatatos", "Enrique Manjavacas", "Walter Daelemans", "Martin Potthast", "Benno Stein." ],
      "venue" : "CLEF 2019 Labs and Workshops, Notebook Papers.",
      "citeRegEx" : "Kestemont et al\\.,? 2019",
      "shortCiteRegEx" : "Kestemont et al\\.",
      "year" : 2019
    }, {
      "title" : "Representing social media users for sarcasm detection",
      "author" : [ "Y. Alex Kolchinski", "Christopher Potts." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1115–1121, Brussels, Belgium, October-November. Association for Computational Linguistics.",
      "citeRegEx" : "Kolchinski and Potts.,? 2018",
      "shortCiteRegEx" : "Kolchinski and Potts.",
      "year" : 2018
    }, {
      "title" : "A personabased neural conversation model",
      "author" : [ "Jiwei Li", "Michel Galley", "Chris Brockett", "Georgios P Spithourakis", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL).",
      "citeRegEx" : "Li et al\\.,? 2016",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Personalizing dialogue agents via meta-learning",
      "author" : [ "Andrea Madotto", "Zhaojiang Lin", "Chien-Sheng Wu", "Pascale Fung." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 5454–5459, Florence, Italy, July. Association for Computational Linguistics.",
      "citeRegEx" : "Madotto et al\\.,? 2019",
      "shortCiteRegEx" : "Madotto et al\\.",
      "year" : 2019
    }, {
      "title" : "The stanford corenlp natural language processing toolkit",
      "author" : [ "Christopher Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven Bethard", "David McClosky." ],
      "venue" : "Proceedings of 52nd annual meeting of the association for computational linguistics: system demonstrations, pages 55–60.",
      "citeRegEx" : "Manning et al\\.,? 2014",
      "shortCiteRegEx" : "Manning et al\\.",
      "year" : 2014
    }, {
      "title" : "Mogrifier lstm",
      "author" : [ "Gábor Melis", "Tomáš Kočiskỳ", "Phil Blunsom." ],
      "venue" : "arXiv preprint arXiv:1909.01792.",
      "citeRegEx" : "Melis et al\\.,? 2019",
      "shortCiteRegEx" : "Melis et al\\.",
      "year" : 2019
    }, {
      "title" : "An analysis of neural language modeling at multiple scales",
      "author" : [ "Stephen Merity", "Nitish Shirish Keskar", "Richard Socher." ],
      "venue" : "arXiv preprint arXiv:1803.08240.",
      "citeRegEx" : "Merity et al\\.,? 2018a",
      "shortCiteRegEx" : "Merity et al\\.",
      "year" : 2018
    }, {
      "title" : "Regularizing and optimizing LSTM language models",
      "author" : [ "Stephen Merity", "Nitish Shirish Keskar", "Richard Socher." ],
      "venue" : "International Conference on Learning Representations (ICLR).",
      "citeRegEx" : "Merity et al\\.,? 2018b",
      "shortCiteRegEx" : "Merity et al\\.",
      "year" : 2018
    }, {
      "title" : "Efficient estimation of word representations in vector space",
      "author" : [ "Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean." ],
      "venue" : "International Conference on Learning Representations (ICLR).",
      "citeRegEx" : "Mikolov et al\\.,? 2013",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Inference in an authorship problem: A comparative study of discrimination methods applied to the authorship of the disputed federalist papers",
      "author" : [ "Frederick Mosteller", "David L Wallace." ],
      "venue" : "Journal of the American Statistical Association, 58(302):275–309.",
      "citeRegEx" : "Mosteller and Wallace.,? 1963",
      "shortCiteRegEx" : "Mosteller and Wallace.",
      "year" : 1963
    }, {
      "title" : "Linguistic inquiry and word count: Liwc 2001",
      "author" : [ "James W Pennebaker", "Martha E Francis", "Roger J Booth." ],
      "venue" : "Mahway: Lawrence Erlbaum Associates, 71(2001):2001.",
      "citeRegEx" : "Pennebaker et al\\.,? 2001",
      "shortCiteRegEx" : "Pennebaker et al\\.",
      "year" : 2001
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher Manning." ],
      "venue" : "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543, Doha, Qatar, October. Association for Computational Linguistics.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Feature-rich part-of-speech tagging with a cyclic dependency network",
      "author" : [ "Kristina Toutanova", "Dan Klein", "Christopher D Manning", "Yoram Singer." ],
      "venue" : "Proceedings of the 2003 conference of the North American chapter of the association for computational linguistics on human language technology (NAACL-HLT), pages 173–180. Association for computational Linguistics.",
      "citeRegEx" : "Toutanova et al\\.,? 2003",
      "shortCiteRegEx" : "Toutanova et al\\.",
      "year" : 2003
    }, {
      "title" : "Learning from personal longitudinal dialog data",
      "author" : [ "Charles Welch", "Verónica Pérez-Rosas", "Jonathan K. Kummerfeld", "Rada Mihalcea." ],
      "venue" : "IEEE Intelligent systems, 34(4).",
      "citeRegEx" : "Welch et al\\.,? 2019a",
      "shortCiteRegEx" : "Welch et al\\.",
      "year" : 2019
    }, {
      "title" : "Look who’s talking: Inferring speaker attributes from personal longitudinal dialog",
      "author" : [ "Charles Welch", "Verónica Pérez-Rosas", "Jonathan K. Kummerfeld", "Rada Mihalcea." ],
      "venue" : "Proceedings of the 20th International Conference on Computational Linguistics and Intelligent Text Processing (CICLing), La Rochelle, France.",
      "citeRegEx" : "Welch et al\\.,? 2019b",
      "shortCiteRegEx" : "Welch et al\\.",
      "year" : 2019
    }, {
      "title" : "Socialized word embeddings",
      "author" : [ "Ziqian Zeng", "Yichun Yin", "Yangqiu Song", "Ming Zhang." ],
      "venue" : "International Joint Conferences on Artificial Intelligence, pages 3915–3921.",
      "citeRegEx" : "Zeng et al\\.,? 2017",
      "shortCiteRegEx" : "Zeng et al\\.",
      "year" : 2017
    }, {
      "title" : "Personalizing dialogue agents: I have a dog, do you have pets too? Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL)",
      "author" : [ "Saizheng Zhang", "Emily Dinan", "Jack Urbanek", "Arthur Szlam", "Douwe Kiela", "Jason Weston" ],
      "venue" : null,
      "citeRegEx" : "Zhang et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 20,
      "context" : "Usually, embeddings are trained from a large corpus of news or web data that contains writing from many sources and authors (Mikolov et al., 2013; Pennington et al., 2014).",
      "startOffset" : 124,
      "endOffset" : 171
    }, {
      "referenceID" : 23,
      "context" : "Usually, embeddings are trained from a large corpus of news or web data that contains writing from many sources and authors (Mikolov et al., 2013; Pennington et al., 2014).",
      "startOffset" : 124,
      "endOffset" : 171
    }, {
      "referenceID" : 14,
      "context" : "User embeddings have been used for dialog generation (Li et al., 2016), query auto-completion (Jaech and Ostendorf, 2018), authorship attribution (Ebrahimi and Dou, 2016), and sarcasm detection (Kolchinski and Potts, 2018).",
      "startOffset" : 53,
      "endOffset" : 70
    }, {
      "referenceID" : 10,
      "context" : ", 2016), query auto-completion (Jaech and Ostendorf, 2018), authorship attribution (Ebrahimi and Dou, 2016), and sarcasm detection (Kolchinski and Potts, 2018).",
      "startOffset" : 31,
      "endOffset" : 58
    }, {
      "referenceID" : 5,
      "context" : ", 2016), query auto-completion (Jaech and Ostendorf, 2018), authorship attribution (Ebrahimi and Dou, 2016), and sarcasm detection (Kolchinski and Potts, 2018).",
      "startOffset" : 83,
      "endOffset" : 107
    }, {
      "referenceID" : 13,
      "context" : ", 2016), query auto-completion (Jaech and Ostendorf, 2018), authorship attribution (Ebrahimi and Dou, 2016), and sarcasm detection (Kolchinski and Potts, 2018).",
      "startOffset" : 131,
      "endOffset" : 159
    }, {
      "referenceID" : 27,
      "context" : "Some approaches also use network information (Zeng et al., 2017; Huang et al., 2016).",
      "startOffset" : 45,
      "endOffset" : 84
    }, {
      "referenceID" : 9,
      "context" : "Some approaches also use network information (Zeng et al., 2017; Huang et al., 2016).",
      "startOffset" : 45,
      "endOffset" : 84
    }, {
      "referenceID" : 6,
      "context" : "Personalization has been studied for marketing, webpage layout, recommendations, query completion, and dialog (Eirinaki and Vazirgiannis, 2003; Das et al., 2007).",
      "startOffset" : 110,
      "endOffset" : 161
    }, {
      "referenceID" : 4,
      "context" : "Personalization has been studied for marketing, webpage layout, recommendations, query completion, and dialog (Eirinaki and Vazirgiannis, 2003; Das et al., 2007).",
      "startOffset" : 110,
      "endOffset" : 161
    }, {
      "referenceID" : 11,
      "context" : "age, gender) to condition system response generation, showing that this relatively coarse grained personalization improves system performance (Joshi et al., 2017).",
      "startOffset" : 142,
      "endOffset" : 162
    }, {
      "referenceID" : 20,
      "context" : "This is a modified skip-gram architecture (Mikolov et al., 2013), which sums two terms so that back-propagation updates the generic matrix and a author-specific matrix.",
      "startOffset" : 42,
      "endOffset" : 64
    }, {
      "referenceID" : 22,
      "context" : "To gain a deeper understanding of these differences, we analyze personal and generic embeddings for specific word groups based on the Linguistic Inquiry and Word Count (LIWC) lexicon (Pennebaker et al., 2001) and part-of-speech (POS) tags.",
      "startOffset" : 183,
      "endOffset" : 208
    }, {
      "referenceID" : 24,
      "context" : "We POS tag the messages with the Stanford CoreNLP tagger (Toutanova et al., 2003; Manning et al., 2014).",
      "startOffset" : 57,
      "endOffset" : 103
    }, {
      "referenceID" : 16,
      "context" : "We POS tag the messages with the Stanford CoreNLP tagger (Toutanova et al., 2003; Manning et al., 2014).",
      "startOffset" : 57,
      "endOffset" : 103
    }, {
      "referenceID" : 8,
      "context" : "These results are consistent with prior work that has found function words are effective for recognizing style and measuring style similarity (Gonzales et al., 2010) and for authorship attribution (Mosteller and Wallace, 1963; Gamon, 2004; Argamon et al.",
      "startOffset" : 142,
      "endOffset" : 165
    }, {
      "referenceID" : 21,
      "context" : ", 2010) and for authorship attribution (Mosteller and Wallace, 1963; Gamon, 2004; Argamon et al., 2003).",
      "startOffset" : 39,
      "endOffset" : 103
    }, {
      "referenceID" : 7,
      "context" : ", 2010) and for authorship attribution (Mosteller and Wallace, 1963; Gamon, 2004; Argamon et al., 2003).",
      "startOffset" : 39,
      "endOffset" : 103
    }, {
      "referenceID" : 1,
      "context" : ", 2010) and for authorship attribution (Mosteller and Wallace, 1963; Gamon, 2004; Argamon et al., 2003).",
      "startOffset" : 39,
      "endOffset" : 103
    }, {
      "referenceID" : 17,
      "context" : "Although more recent models can achieve better perplexities on standard benchmarks (Melis et al., 2019; Dai et al., 2019), we find that not all models have code available or that they take far more time to run than Merity et al.",
      "startOffset" : 83,
      "endOffset" : 121
    }, {
      "referenceID" : 3,
      "context" : "Although more recent models can achieve better perplexities on standard benchmarks (Melis et al., 2019; Dai et al., 2019), we find that not all models have code available or that they take far more time to run than Merity et al.",
      "startOffset" : 83,
      "endOffset" : 121
    }, {
      "referenceID" : 13,
      "context" : "This is an approach widely used in previous work (Kolchinski and Potts, 2018; Li et al., 2016).",
      "startOffset" : 49,
      "endOffset" : 94
    }, {
      "referenceID" : 14,
      "context" : "This is an approach widely used in previous work (Kolchinski and Potts, 2018; Li et al., 2016).",
      "startOffset" : 49,
      "endOffset" : 94
    } ],
    "year" : 2020,
    "abstractText" : "In this paper, we introduce personalized word embeddings, and examine their value for language modeling. We compare the performance of our proposed prediction model when using personalized versus generic word representations, and study how these representations can be leveraged for improved performance. We provide insight into what types of words can be more accurately predicted when building personalized models. Our results show that a subset of words belonging to specific psycholinguistic categories tend to vary more in their representations across users and that combining generic and personalized word embeddings yields the best performance, with a 4.7% relative reduction in perplexity. Additionally, we show that a language model using personalized word embeddings can be effectively used for authorship attribution.",
    "creator" : "TeX"
  }
}