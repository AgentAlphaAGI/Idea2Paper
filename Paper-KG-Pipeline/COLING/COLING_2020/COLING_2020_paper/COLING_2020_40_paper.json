{
  "name" : "COLING_2020_40_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Neural Automated Essay Scoring Incorporating Handcrafted Features",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "In various assessment fields, essay-writing tests have attracted much attention as a way to measure practical higher-order abilities such as logical thinking, critical reasoning, and creative-thinking skills (Hussein et al., 2019). In essay-writing tests, test-takers are required to write essays about a given topic, and human raters grade those essays based on a scoring rubric. However, because the scoring process takes much time and effort, it is hard to grade large numbers of essays (Hussein et al., 2019). Further, subjectivity in human scoring can reduce accuracy (Amorim et al., 2018). Automated essay scoring (AES), which utilizes natural language processing and machine learning techniques to automatically grade essays, is one method for resolving these problems.\nMany AES methods have been developed over the past decades, and can generally be categorized as feature-engineering and neural-network approaches (Hussein et al., 2019; Ke and Ng, 2019). The featureengineering approach predicts scores using handcrafted features such as essay length or spelling errors (e.g., (Amorim et al., 2018; Dascalu et al., 2017; Mark D. Shermis, 2016; Nguyen and Litman, 2018)). The advantages of this approach include interpretability and explainability. However, this approach generally requires extensive effort for engineering effective features to achieve high scoring accuracy for various essays.\nTo obviate the need for feature engineering, a neural-network approach that automatically extracts features using deep neural networks (DNNs) has recently attracted attention. Many DNN-AES models have been proposed and have achieved high accuracy (Alikaniotis et al., 2016; Taghipour and Ng, 2016; Dasgupta et al., 2018; Farag et al., 2018; Jin et al., 2018; Mesgar and Strube, 2018; Wang et al., 2018; Mim et al., 2019; Nadeem et al., 2019).\nThese two approaches can be viewed as complementary rather than competing, because they provide different advantages. Specifically, the neural-network approach can extract dataset-specific features\nfrom word sequence patterns, whereas the feature-engineering approach can use existing effective features that are difficult to extract using DNNs from only word sequence information. To obtain both benefits, Dasgupta et al. (2018) proposed a hybrid method that integrates both approaches. This method is formulated as a DNN-AES model with an additional recurrent neural network (RNN) that processes a sequence of handcrafted sentence-level features. This method provides state-of-the-art accuracy, but has the following drawbacks:\n1. It cannot incorporate effective essay-level features developed in previous AES researches.\n2. It greatly increases the numbers of model parameters and tuning parameters, increasing the difficulty of model training.\n3. It has an additional RNN that processes sequences of handcrafted sentence-level features, enabling extension to various DNN-AES models complex.\nTo resolve these problems, we propose a new hybrid method that integrates handcrafted essay-level features into a DNN-AES model. Specifically, our method concatenates handcrafted essay-level features to a distributed essay representation vector, which is obtained from an intermediate layer of a DNN-AES model. The advantages of our method are as follows:\n1. It can incorporate various existing essay-level features for which effectiveness has been shown.\n2. The number of required additional parameters is only the number of incorporated essay-level features, and there are no additional hand-tuned parameters.\n3. It can be easily applied to various DNN-AES models, because conventional models commonly have a layer that produces a distributed essay-representation vector.\nOur model is a simple DNN-AES extension, but experimental results on real-world benchmark data show that it significantly improves accuracy."
    }, {
      "heading" : "2 Automated essay scoring methods",
      "text" : "This section briefly reviews conventional AES methods based on the feature-engineering and neuralnetwork approaches."
    }, {
      "heading" : "2.1 Feature-engineering approach",
      "text" : "Following the first AES method, Project Essay Grade (PEG) (Page, 2003), many feature engineering– based AES methods have been developed, including Intelligent Essay Assessor (IEA) (Foltz et al., 2013), e-rater (Attali and Burstein, 2006), the Bayesian Essay Test Score sYstem (BETSY) (Rudner and Liang, 2002), and IntelliMetric (Schultz, 2013). These methods have been applied to various actual tests. For example, e-rater, a popular commercial AES, now plays the role of a second rater in the Test of English as a Foreign Language (TOEFL) and the Graduate Record Examination (GRE).\nThese AES methods predict scores by supervised machine learning models using handcrafted features. For instance, PEG and e-rater use multiple regression models, and Phandi et al. (2015) used a correlated Bayesian linear-ridge-regression model. BETSY and Larkey (1998) perform AES using classification models. Other recent works solve AES by using preference-ranking models (Yannakoudakis et al., 2011; Chen and He, 2013).\nThe features used in previous research differ among the methods, ranging from simple features (e.g., word or essay length) to more complex ones (e.g., readability or grammatical errors). Table 1 shows examples of representative features (Phandi et al., 2015; Ke and Ng, 2019)."
    }, {
      "heading" : "2.2 Neural-network approach",
      "text" : "This section introduces two DNN-AES models as AES methods based on the neural-network approach: the most popular model, which uses a long short-term memory (LSTM), and an advanced model based on the transformer architecture.\nTable 1: Representative handcrafted features.\nFeature Type Examples Length-based features Numbers of characters, words, sentences, and punctuation symbols. Average word lengths. Syntactic features Numbers of nouns, verbs, adverbs, adjectives, and conjunctions. Parse tree depth. Grammatical error rates. Word-based features Numbers of useful n-grams and stemmed n-grams. Numbers of spelling errors, sentiment words, and modals. Readability features Numbers of difficult words and syllables. Readability indices, such as\nFlesch–Kincaid reading ease (Kincaid et al., 1975), Gunning fog (Whisner, 2004), or SMOG index (Fitzsimmons et al., 2010).\nSemantic feature Semantic similarity based on latent semantic analysis (Foltz et al., 2013). Histogram-based features computed by pointwise mutual information (Klebanov and Flor, 2013). Argumentation feature Numbers of claims and premises. Argument tree depth as estimated using argument mining techniques (Nguyen and Litman, 2018). Prompt-relevant feature Number of words in essays for a prompt."
    }, {
      "heading" : "2.3 LSTM-based model",
      "text" : "The LSTM-based model (Alikaniotis et al., 2016), which was the first DNN-AES model, predicts essay scores through the multi-layered neural networks shown in Fig. 1 by inputting essay word sequences. Letting V = {1, · · · , V } be a vocabulary list, an essay j is defined as a list of vocabulary words {wji ∈ V | i = {1, · · · , nj}}, where wji is a V -dimensional one-hot representation of the i-th word in essay j and nj is the number of words in essay j. This model processes word sequences through the following layers:\nLookup table layer: This layer transforms each word in a given essay into a D-dimensional wordembedding representation, in which words with the same meaning have similar representations. Specifically, letting A be a D× V -dimensional embeddings matrix, the word-embedding representation xji corresponding to wji ∈ Wj is calculable as the dot product A ·wji.\nRecurrent layer: This layer is an LSTM network that outputs a vector at each timestep to capture longdistance word dependencies. Specifically, this layer transforms sequence {xj1,xj2, · · · ,xjnj} to an LSTM output sequence Hj = {hj1,hj2, · · · ,hjnj}. A single-layer unidirectional LSTM is generally used, but bidirectional or multilayered LSTMs are also often used. A convolution neural network is optionally used before the recurrent layer to capture n-gram-level textual dependencies.\nPooling layer: This layer transforms recurrent layer outputs Hj into a fixed-length vector. Mean-overtime (MoT) pooling, which calculates an average vector Mj = 1nj ∑nj i=1 hji, is generally used.\nOther frequently used pooling methods include the last pool, which uses the last output of the recurrent layer hjnj , and a pooling-with-attention mechanism.\nLinear layer with sigmoid activation: This layer projects pooling-layer output Mj to a scalar value in the range [0, 1] by the sigmoid function σ(WMj + b), where W is a weight matrix and b is a bias.\nModel training is conducted by backpropagation with a mean square error (MSE) loss function using a training dataset in which scores are normalized to a [0, 1] scale. During the prediction phase, predicted scores are rescaled to the original score range. This model has been used as the basis model in various current DNN-AES models (e.g., (Dasgupta et al., 2018; Farag et al., 2018; Jin et al., 2018; Mesgar and Strube, 2018; Wang et al., 2018; Mim et al., 2019; Nadeem et al., 2019))."
    }, {
      "heading" : "2.4 Transformer-based model",
      "text" : "Transformer-based architectures have recently attracted attention as an alternative approach to RNN for processing sequential data. Specifically, bidirectional encoder representations from transformers (BERT), a pre-trained multilayer bidirectional transformer network (Vaswani et al., 2017) released by the Google AI Language team, have achieved state-of-the-art results in various NLP tasks, such as question answering, named entity recognition, natural language inference, and text classification (Devlin et al., 2019). BERT was also applied to AES (Rodriguez et al., 2019) and automated short-answer grading (Liu et al., 2019; Sung et al., 2019) in 2019, and demonstrated good performance.\nTransformers are a neural network architecture designed to handle ordered data sequences using an attention mechanism. Specifically, transformers consist of multiple layers (called transformer blocks), each containing a multi-head self-attention mechanism and a position-wise fully connected feed-forward network. See Ref. (Vaswani et al., 2017) for details of this architecture.\nBERT is trained in pre-training and fine-tuning steps. Pre-training is conducted on huge amounts of unlabeled text data over two tasks, masked language modeling and next-sentence prediction, the former predicting the identities of words that have been masked out of the input text and the latter predicting whether two given sentences are adjacent.\nUsing BERT for a target NLP task, including AES, requires fine-tuning (retraining), which is conducted from a task-specific supervised dataset after initializing model parameters to pre-trained values. When using BERT for regression or classification tasks such as AES, input texts require preprocessing, namely adding a special token (“[CLS]”) to the beginning of each text. BERT output corresponding to this token is used as a fixed-length distributed text representation (Devlin et al., 2019). We can thus conduct target regression or classification tasks based on the text representation. In this study, we assume the use of the linear layer with sigmoid activation, described in the previous subsection, to predict essay scores from the text representation (Fig. 2)."
    }, {
      "heading" : "3 Hybrid method",
      "text" : "The feature-engineering approach and the neural-network approach can be viewed as complementary rather than competing approaches, because as mentioned in Section 1 they provide different advantages. To receive both benefits, Dasgupta et al. (2018) proposed a hybrid method that integrates the two approaches.\nFigure 3 shows the model architecture of the hybrid method. As that figure shows, it mainly consists of two DNNs. One processes word sequences in a given essay in the same way as the conventional LSTMbased DNN-AES model. Specifically, it transforms a word sequence Wj to a hidden vector Hj , which is a fixed-length distributed essay representation, through the lookup table layer, recurrent layer, and pooling layer. The other DNN processes a sequence of handcrafted sentence-level features. Letting the\nj-th essay have Nj sentences, and letting sentence-level features for the n-th essay sentence be fjn, the feature sequence Fj = {fj1,fj2, · · · ,fjNj} is transformed to a fixed-length hidden vector H f j through a recurrent layer and a pooling layer. (Note that the original article used an LSTM for the recurrent layer and attention pooling for the pooling layer.) Finally, inputting a concatenated vector [Hj ;Hfj ], the linear layer with sigmoid activation produces a predicted score.\nThis method has provided higher accuracy than feature engineering–based methods or DNN-based methods. However, it has the following drawbacks.\n1. It cannot incorporate essay-level features developed in conventional AES research.\n2. It has far more model and tuning parameters than does a base DNN-AES model. Specifically, letting the number of handcrafted sentence-level features be f , and the hidden variable size of the LSTM in the recurrent layer be d, this method requires at least (4df + d2 + 5d) additional parameters, and further parameters are required if attention pooling is used. It also requires tuning parameters for the LSTM and the pooling layer, making model training more difficult.\n3. It requires an additional RNN for processing sequences of handcrafted sentence-level features, making implementation with transformer-based models and other DNN-AES models complex."
    }, {
      "heading" : "4 Proposed method",
      "text" : "To resolve the above problems, we propose a new hybrid method that incorporates handcrafted essaylevel features to a DNN-AES model.\nOur method concatenates handcrafted essay-level features to the distributed essay representation Hj , which is the input vector for the last linear layer in conventional DNN-AES models. Letting essay-level features for the j-th essay be F oj , the proposed method projects the concatenated vector [Hj ;F oj ] to a scalar value by using a sigmoid function, as in conventional DNN-AES models.\nThe proposed method can be easily applied to existing DNN-AES models, because they commonly have a layer that produces a distributed essay representation before the last linear layer. As examples, Figs. 4, 5, and 6 show model architectures for LSTM, BERT, and conventional hybrid models integrating essay-level features.\nThe proposed method can incorporate various existing essay-level features for which effectiveness has been shown. As essay-level features, this study uses the 25 features presented in Table 2, which have been widely used in various AES studies. We assume that the feature values are standardized to fulfill the condition of mean 0 and standard deviation 1.0.\nAnother advantage of our method is that it only requires additional weight parameters in the last linear layer, and the number of additional parameters is only the number of incorporated essay-level features F oj , as compared with the basis DNN-AES model. It requires no additional hand-tuned parameters."
    }, {
      "heading" : "5 Experiments",
      "text" : "This section demonstrates the effectiveness of the proposed method using real-world benchmark data."
    }, {
      "heading" : "5.1 Experimental procedures",
      "text" : "This study employed the automated student assessment prize (ASAP) dataset, which is widely used as benchmark data in AES research. The ASAP dataset provides eight sets of essays, each set associated with a prompt. Essays were written by students in grades 7–10. Table 3 summarizes numbers of essays, score ranges, and averaged essay length for each prompt.\nUsing this dataset, we evaluated score prediction accuracies through five-fold cross-validation for each prompt. The accuracy metric was the quadratic weighted Kappa (QWK), which examines agreement between predicted scores and ground truth. We conducted this experiment for the LSTM-based model\n(Fig. 1), the BERT-based model (Fig. 2), Dasgupta’s hybrid model (Fig. 3), and the proposed method with these models (Figs. 4, 5, and 6). In the LSTM-based model, we used a single-layer LSTM, a twolayer LSTM, and a bidirectional LSTM for the recurrent layer. We used last pooling as the pooling layer for these LSTM-based models, and also examined MoT pooling for the single-layer LSTM-based model. As sentence features for Dasgupta’s hybrid model, we used features similar to the essay-level features shown in Table 2 after two modifications: 1) For length-based features, we removed the number and average length of sentences. 2) We removed the SMOG index from the readability features, because it is not definable for a sentence. We also examined a logistic regression model using essay-level features as a method based on the feature-engineering approach.\nWe implemented the models in the Python programming language with the Keras library. As the embedding matrix, we used Glove (Pennington et al., 2014) with 50 dimensions. We set LSTMs’ hiddenvariable dimension to 300, the mini-batch size to 32, and the maximum epochs to 50. We used dropout regularization to avoid overfitting, with dropout probabilities for lookup table layer output and pooling layer output set to 0.5. The recurrent dropout probability was set to 0.2. We used the Adam optimization algorithm (Kingma and Ba, 2014) to minimize the mean squared error (MSE) loss function over the training data. For the BERT model, we used a base-sized pre-trained model."
    }, {
      "heading" : "5.2 Experimental results",
      "text" : "Table 4 shows the experimental results. Comparing accuracy among prompts, accuracy tends to be higher for prompts in which the average essay length is short (e.g., prompts 3, 4, 5, 6, and 7) than those with long essays (e.g., prompts 1, 2, and 8). This tendency is consistent with previous studies.\nComparing the conventional DNN-AES models shows that the LSTM-based model with MoT pooling\nhas higher performance than models with last pooling, which is also consistent with previous studies (Alikaniotis et al., 2016; Riordan et al., 2017). BERT outperforms the LSTM-based models, as in other BERT applications including automated short-answer grading (Devlin et al., 2019; Liu et al., 2019; Lun et al., 2020; Sung et al., 2019). As Dasgupta et al. (2018) reported, the conventional hybrid model shows the highest accuracy among the conventional models.\nTable 4 shows that by incorporating handcrafted essay-level features, the proposed method drastically improves accuracy of all base DNN-AES models. We conducted paired t-tests to examine whether averaged performance of the proposed method is significantly higher than base model performance. The results, shown in the “p-value” column in Table 4, indicate that the proposed method improved performance at the 5% significance level for the LSTM- and BERT-based models, and at the 10% significance level for the conventional hybrid model.\nComparing the proposed method with the logistic regression model (a feature-engineering approach), the proposed model improved averaged accuracy in all cases. The paired t-test between the logistic regression model and the proposed method shows that averaged QWKs of the proposed method using LSTM with MoT pooling and the conventional hybrid model were higher at the 5% significance level, and that of the BERT-based proposed method was higher at the 1% significance level.\nIn all cases, the proposed method using the BERT model provided the highest accuracy. To confirm whether the handcrafted essay-level features were effective, Table 5 shows weight parameter values in the final linear layer of the BERT-based proposed model. In the table, the row Distributed representation shows the average values of the absolute weight parameters for the 300-dimensional essay distributed representation vector Hj . A higher weight value means that the feature has more influence on score prediction. This table suggests that each handcrafted feature contributes to some extent, whereas features with large weights vary across prompts.\nThese experimental results show that the proposed method effectively improves AES accuracy."
    }, {
      "heading" : "6 Conclusions",
      "text" : "We proposed a simple method that incorporates handcrafted essay-level features to DNN-AES models. Our method adds handcrafted features to a distributed essay representation vector obtained as an intermediate hidden representation of a DNN-AES model. Our method can be easily applied to various conventional DNN-AES models without increasing model complexity much, but significantly improving prediction performance.\nIn future studies, we will evaluate the effectiveness of the proposed method using more varied essay-\nlevel features. Although our method directly adds essay-level features to the DNN-based distributed essay representation vector, accuracy might be further improved by appending several layers after the feature input layer. Such model extensions are another topic for future study."
    }, {
      "heading" : "Acknowledgements",
      "text" : "This work was supported by xxxxx."
    } ],
    "references" : [ {
      "title" : "Automatic text scoring using neural networks",
      "author" : [ "Dimitrios Alikaniotis", "Helen Yannakoudakis", "Marek Rei." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics, pages 715–725.",
      "citeRegEx" : "Alikaniotis et al\\.,? 2016",
      "shortCiteRegEx" : "Alikaniotis et al\\.",
      "year" : 2016
    }, {
      "title" : "Automated essay scoring in the presence of biased ratings",
      "author" : [ "Evelin Amorim", "Márcia Cançado", "Adriano Veloso." ],
      "venue" : "Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 229–237.",
      "citeRegEx" : "Amorim et al\\.,? 2018",
      "shortCiteRegEx" : "Amorim et al\\.",
      "year" : 2018
    }, {
      "title" : "Automated essay scoring with e-rater v.2",
      "author" : [ "Yigal Attali", "Jill Burstein" ],
      "venue" : "The Journal of Technology, Learning and Assessment,",
      "citeRegEx" : "Attali and Burstein.,? \\Q2006\\E",
      "shortCiteRegEx" : "Attali and Burstein.",
      "year" : 2006
    }, {
      "title" : "Automated essay scoring by maximizing human-machine agreement",
      "author" : [ "Hongbo Chen", "Ben He." ],
      "venue" : "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1741–1752.",
      "citeRegEx" : "Chen and He.,? 2013",
      "shortCiteRegEx" : "Chen and He.",
      "year" : 2013
    }, {
      "title" : "A computer readability formula designed for machine scoring",
      "author" : [ "Meri Coleman", "Ta Lin Liau." ],
      "venue" : "Journal of Applied Psychology, 60(2):283.",
      "citeRegEx" : "Coleman and Liau.,? 1975",
      "shortCiteRegEx" : "Coleman and Liau.",
      "year" : 1975
    }, {
      "title" : "Readerbench learns dutch: Building a comprehensive automated essay scoring system for Dutch language",
      "author" : [ "Mihai Dascalu", "Wim Westera", "Stefan Ruseti", "Stefan Trausan-Matu", "Hub Kurvers." ],
      "venue" : "Proceedings of International Conference on Artificial Intelligence in Education, pages 52–63.",
      "citeRegEx" : "Dascalu et al\\.,? 2017",
      "shortCiteRegEx" : "Dascalu et al\\.",
      "year" : 2017
    }, {
      "title" : "Augmenting textual qualitative features in deep convolution recurrent neural network for automatic essay scoring",
      "author" : [ "Tirthankar Dasgupta", "Abir Naskar", "Lipika Dey", "Rupsa Saha." ],
      "venue" : "Proceedings of the 5th Workshop on Natural Language Processing Techniques for Educational Applications, pages 93–102. Association for Computational Linguistics.",
      "citeRegEx" : "Dasgupta et al\\.,? 2018",
      "shortCiteRegEx" : "Dasgupta et al\\.",
      "year" : 2018
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 4171–4186.",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Neural automated essay scoring and coherence modeling for adversarially crafted input",
      "author" : [ "Youmna Farag", "Helen Yannakoudakis", "Ted Briscoe." ],
      "venue" : "Proceedings of Conference of the North American Chapter of the Association for Computational Linguistics, pages 263–271.",
      "citeRegEx" : "Farag et al\\.,? 2018",
      "shortCiteRegEx" : "Farag et al\\.",
      "year" : 2018
    }, {
      "title" : "A readability assessment of online parkinson’s disease information",
      "author" : [ "Paul R Fitzsimmons", "BD Michael", "Joane L Hulley", "G Orville Scott." ],
      "venue" : "The journal of the Royal College of Physicians of Edinburgh, 40(4):292–296.",
      "citeRegEx" : "Fitzsimmons et al\\.,? 2010",
      "shortCiteRegEx" : "Fitzsimmons et al\\.",
      "year" : 2010
    }, {
      "title" : "Handbook of automated essay evaluation: Current applications and new directions",
      "author" : [ "Peter W. Foltz", "Lynn A. Streeter", "Karen E. Lochbaum." ],
      "venue" : "Implementation and Applications of the Intelligent Essay Assessor. Routledge.",
      "citeRegEx" : "Foltz et al\\.,? 2013",
      "shortCiteRegEx" : "Foltz et al\\.",
      "year" : 2013
    }, {
      "title" : "Automated language essay scoring systems: A literature review",
      "author" : [ "Mohamed Abdellatif Hussein", "Hesham A. Hassan", "Mohamed Nassef." ],
      "venue" : "PeerJ PrePrints, 7:e27715.",
      "citeRegEx" : "Hussein et al\\.,? 2019",
      "shortCiteRegEx" : "Hussein et al\\.",
      "year" : 2019
    }, {
      "title" : "TDNN: A two-stage deep neural network for prompt-independent automated essay scoring",
      "author" : [ "Cancan Jin", "Ben He", "Kai Hui", "Le Sun." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics, pages 1088–1097.",
      "citeRegEx" : "Jin et al\\.,? 2018",
      "shortCiteRegEx" : "Jin et al\\.",
      "year" : 2018
    }, {
      "title" : "Automated essay scoring: A survey of the state of the art",
      "author" : [ "Zixuan Ke", "Vincent Ng." ],
      "venue" : "Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, pages 6300–6308.",
      "citeRegEx" : "Ke and Ng.,? 2019",
      "shortCiteRegEx" : "Ke and Ng.",
      "year" : 2019
    }, {
      "title" : "Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel",
      "author" : [ "J Peter Kincaid", "Robert P Fishburne Jr", "Richard L Rogers", "Brad S Chissom." ],
      "venue" : "Institute for Simulation and Training, University of Central Florida.",
      "citeRegEx" : "Kincaid et al\\.,? 1975",
      "shortCiteRegEx" : "Kincaid et al\\.",
      "year" : 1975
    }, {
      "title" : "Adam: A method for stochastic optimization",
      "author" : [ "Diederik P Kingma", "Jimmy Ba." ],
      "venue" : "arXiv preprint arXiv:1412.6980.",
      "citeRegEx" : "Kingma and Ba.,? 2014",
      "shortCiteRegEx" : "Kingma and Ba.",
      "year" : 2014
    }, {
      "title" : "Word association profiles and their use for automated scoring of essays",
      "author" : [ "Beata Beigman Klebanov", "Michael Flor." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1148–1158.",
      "citeRegEx" : "Klebanov and Flor.,? 2013",
      "shortCiteRegEx" : "Klebanov and Flor.",
      "year" : 2013
    }, {
      "title" : "Automatic essay grading using text categorization techniques",
      "author" : [ "Leah S. Larkey." ],
      "venue" : "Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 90–95.",
      "citeRegEx" : "Larkey.,? 1998",
      "shortCiteRegEx" : "Larkey.",
      "year" : 1998
    }, {
      "title" : "Automatic short answer grading via multiway attention networks",
      "author" : [ "Tiaoqiao Liu", "Wenbiao Ding", "Zhiwei Wang", "Jiliang Tang", "Gale Yan Huang", "Zitao Liu." ],
      "venue" : "Proceedings of International Conference on Artificial Intelligence in Education, pages 169–173.",
      "citeRegEx" : "Liu et al\\.,? 2019",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2019
    }, {
      "title" : "Multiple data augmentation strategies for improving performance on automatic short answer scoring",
      "author" : [ "Jiaqi Lun", "Jia Zhu", "Yong Tang", "Min Yang." ],
      "venue" : "Proceedings of Association for the Advancement of Artificial Intelligence.",
      "citeRegEx" : "Lun et al\\.,? 2020",
      "shortCiteRegEx" : "Lun et al\\.",
      "year" : 2020
    }, {
      "title" : "Automated Essay Scoring: A Cross-disciplinary Perspective",
      "author" : [ "Jill C. Burstein Mark D. Shermis." ],
      "venue" : "Taylor & Francis.",
      "citeRegEx" : "Shermis.,? 2016",
      "shortCiteRegEx" : "Shermis.",
      "year" : 2016
    }, {
      "title" : "A neural local coherence model for text quality assessment",
      "author" : [ "Mohsen Mesgar", "Michael Strube." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 4328–4339.",
      "citeRegEx" : "Mesgar and Strube.,? 2018",
      "shortCiteRegEx" : "Mesgar and Strube.",
      "year" : 2018
    }, {
      "title" : "Unsupervised learning of discourse-aware text representation for essay scoring",
      "author" : [ "Farjana Sultana Mim", "Naoya Inoue", "Paul Reisert", "Hiroki Ouchi", "Kentaro Inui." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, pages 378–385.",
      "citeRegEx" : "Mim et al\\.,? 2019",
      "shortCiteRegEx" : "Mim et al\\.",
      "year" : 2019
    }, {
      "title" : "Automated essay scoring with discourse-aware neural models",
      "author" : [ "Farah Nadeem", "Huy Nguyen", "Yang Liu", "Mari Ostendorf." ],
      "venue" : "Proceedings of the Fourteenth Workshop on Innovative Use of NLP for Building Educational Applications, Association for Computational Linguistics, pages 484–493.",
      "citeRegEx" : "Nadeem et al\\.,? 2019",
      "shortCiteRegEx" : "Nadeem et al\\.",
      "year" : 2019
    }, {
      "title" : "Argument mining for improving the automated scoring of persuasive essays",
      "author" : [ "Huy V. Nguyen", "Diane J. Litman." ],
      "venue" : "Association for the Advancement of Artificial Intelligence, pages 5892–5899.",
      "citeRegEx" : "Nguyen and Litman.,? 2018",
      "shortCiteRegEx" : "Nguyen and Litman.",
      "year" : 2018
    }, {
      "title" : "Project essay grade: PEG",
      "author" : [ "E.B. Page." ],
      "venue" : "Automated essay scoring: A cross disciplinary perspective. Lawrence Erlbaum Associates.",
      "citeRegEx" : "Page.,? 2003",
      "shortCiteRegEx" : "Page.",
      "year" : 2003
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher Manning." ],
      "venue" : "Proceedings of the 2014 conference on empirical methods in natural language processing, pages 1532–1543.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Flexible domain adaptation for automated essay scoring using correlated linear regression",
      "author" : [ "Peter Phandi", "Kian Ming A. Chai", "Hwee Tou Ng." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 431–439.",
      "citeRegEx" : "Phandi et al\\.,? 2015",
      "shortCiteRegEx" : "Phandi et al\\.",
      "year" : 2015
    }, {
      "title" : "Investigating neural architectures for short answer scoring",
      "author" : [ "Brian Riordan", "Andrea Horbach", "Aoife Cahill", "Torsten Zesch", "Chong Min Lee." ],
      "venue" : "Proceedings of the 12th Workshop on Innovative Use of NLP for Building Educational Applications, pages 159–168. Association for Computational Linguistics.",
      "citeRegEx" : "Riordan et al\\.,? 2017",
      "shortCiteRegEx" : "Riordan et al\\.",
      "year" : 2017
    }, {
      "title" : "Language models and automated essay scoring",
      "author" : [ "Pedro Uria Rodriguez", "Amir Jafari", "Christopher M. Ormerod." ],
      "venue" : "arXiv, cs.CL.",
      "citeRegEx" : "Rodriguez et al\\.,? 2019",
      "shortCiteRegEx" : "Rodriguez et al\\.",
      "year" : 2019
    }, {
      "title" : "Automated essay scoring using bayes’ theorem",
      "author" : [ "Lawrence Rudner", "Tahung Liang." ],
      "venue" : "Journal of Technology, Learning, and Assessment, 1, 08.",
      "citeRegEx" : "Rudner and Liang.,? 2002",
      "shortCiteRegEx" : "Rudner and Liang.",
      "year" : 2002
    }, {
      "title" : "The intellimetric automated essay scoring engine: A review and an application to chinese essay scoring",
      "author" : [ "Matthew. T Schultz." ],
      "venue" : "Handbook of automated essay evaluation: Current applications and new directions. Routledge.",
      "citeRegEx" : "Schultz.,? 2013",
      "shortCiteRegEx" : "Schultz.",
      "year" : 2013
    }, {
      "title" : "Automated readability index",
      "author" : [ "Edgar A Smith", "R.J. Senter." ],
      "venue" : "Technical report, Cincinnati University, OH.",
      "citeRegEx" : "Smith and Senter.,? 1967",
      "shortCiteRegEx" : "Smith and Senter.",
      "year" : 1967
    }, {
      "title" : "Improving short answer grading using transformerbased pre-training",
      "author" : [ "Chul Sung", "Tejas Indulal Dhamecha", "Nirmal Mukhi." ],
      "venue" : "Proceedings of International Conference on Artificial Intelligence in Education, pages 469–481.",
      "citeRegEx" : "Sung et al\\.,? 2019",
      "shortCiteRegEx" : "Sung et al\\.",
      "year" : 2019
    }, {
      "title" : "A neural approach to automated essay scoring",
      "author" : [ "Kaveh Taghipour", "Hwee Tou Ng." ],
      "venue" : "Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1882–1891.",
      "citeRegEx" : "Taghipour and Ng.,? 2016",
      "shortCiteRegEx" : "Taghipour and Ng.",
      "year" : 2016
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N Gomez", "Lukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "Advances in Neural Information Processing Systems, pages 5998–6008. Curran Associates, Inc.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Automatic essay scoring incorporating rating schema via reinforcement learning",
      "author" : [ "Yucheng Wang", "Zhongyu Wei", "Yaqian Zhou", "Xuanjing Huang." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 791–797.",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "When judges scold lawyers",
      "author" : [ "Mary Whisner." ],
      "venue" : "Law Libr. J., 96:557.",
      "citeRegEx" : "Whisner.,? 2004",
      "shortCiteRegEx" : "Whisner.",
      "year" : 2004
    }, {
      "title" : "A new dataset and method for automatically grading ESOL texts",
      "author" : [ "Helen Yannakoudakis", "Ted Briscoe", "Ben Medlock." ],
      "venue" : "Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 180–189.",
      "citeRegEx" : "Yannakoudakis et al\\.,? 2011",
      "shortCiteRegEx" : "Yannakoudakis et al\\.",
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 11,
      "context" : "In various assessment fields, essay-writing tests have attracted much attention as a way to measure practical higher-order abilities such as logical thinking, critical reasoning, and creative-thinking skills (Hussein et al., 2019).",
      "startOffset" : 208,
      "endOffset" : 230
    }, {
      "referenceID" : 11,
      "context" : "However, because the scoring process takes much time and effort, it is hard to grade large numbers of essays (Hussein et al., 2019).",
      "startOffset" : 109,
      "endOffset" : 131
    }, {
      "referenceID" : 1,
      "context" : "Further, subjectivity in human scoring can reduce accuracy (Amorim et al., 2018).",
      "startOffset" : 59,
      "endOffset" : 80
    }, {
      "referenceID" : 11,
      "context" : "Many AES methods have been developed over the past decades, and can generally be categorized as feature-engineering and neural-network approaches (Hussein et al., 2019; Ke and Ng, 2019).",
      "startOffset" : 146,
      "endOffset" : 185
    }, {
      "referenceID" : 13,
      "context" : "Many AES methods have been developed over the past decades, and can generally be categorized as feature-engineering and neural-network approaches (Hussein et al., 2019; Ke and Ng, 2019).",
      "startOffset" : 146,
      "endOffset" : 185
    }, {
      "referenceID" : 0,
      "context" : "Many DNN-AES models have been proposed and have achieved high accuracy (Alikaniotis et al., 2016; Taghipour and Ng, 2016; Dasgupta et al., 2018; Farag et al., 2018; Jin et al., 2018; Mesgar and Strube, 2018; Wang et al., 2018; Mim et al., 2019; Nadeem et al., 2019).",
      "startOffset" : 71,
      "endOffset" : 265
    }, {
      "referenceID" : 34,
      "context" : "Many DNN-AES models have been proposed and have achieved high accuracy (Alikaniotis et al., 2016; Taghipour and Ng, 2016; Dasgupta et al., 2018; Farag et al., 2018; Jin et al., 2018; Mesgar and Strube, 2018; Wang et al., 2018; Mim et al., 2019; Nadeem et al., 2019).",
      "startOffset" : 71,
      "endOffset" : 265
    }, {
      "referenceID" : 6,
      "context" : "Many DNN-AES models have been proposed and have achieved high accuracy (Alikaniotis et al., 2016; Taghipour and Ng, 2016; Dasgupta et al., 2018; Farag et al., 2018; Jin et al., 2018; Mesgar and Strube, 2018; Wang et al., 2018; Mim et al., 2019; Nadeem et al., 2019).",
      "startOffset" : 71,
      "endOffset" : 265
    }, {
      "referenceID" : 8,
      "context" : "Many DNN-AES models have been proposed and have achieved high accuracy (Alikaniotis et al., 2016; Taghipour and Ng, 2016; Dasgupta et al., 2018; Farag et al., 2018; Jin et al., 2018; Mesgar and Strube, 2018; Wang et al., 2018; Mim et al., 2019; Nadeem et al., 2019).",
      "startOffset" : 71,
      "endOffset" : 265
    }, {
      "referenceID" : 12,
      "context" : "Many DNN-AES models have been proposed and have achieved high accuracy (Alikaniotis et al., 2016; Taghipour and Ng, 2016; Dasgupta et al., 2018; Farag et al., 2018; Jin et al., 2018; Mesgar and Strube, 2018; Wang et al., 2018; Mim et al., 2019; Nadeem et al., 2019).",
      "startOffset" : 71,
      "endOffset" : 265
    }, {
      "referenceID" : 21,
      "context" : "Many DNN-AES models have been proposed and have achieved high accuracy (Alikaniotis et al., 2016; Taghipour and Ng, 2016; Dasgupta et al., 2018; Farag et al., 2018; Jin et al., 2018; Mesgar and Strube, 2018; Wang et al., 2018; Mim et al., 2019; Nadeem et al., 2019).",
      "startOffset" : 71,
      "endOffset" : 265
    }, {
      "referenceID" : 36,
      "context" : "Many DNN-AES models have been proposed and have achieved high accuracy (Alikaniotis et al., 2016; Taghipour and Ng, 2016; Dasgupta et al., 2018; Farag et al., 2018; Jin et al., 2018; Mesgar and Strube, 2018; Wang et al., 2018; Mim et al., 2019; Nadeem et al., 2019).",
      "startOffset" : 71,
      "endOffset" : 265
    }, {
      "referenceID" : 22,
      "context" : "Many DNN-AES models have been proposed and have achieved high accuracy (Alikaniotis et al., 2016; Taghipour and Ng, 2016; Dasgupta et al., 2018; Farag et al., 2018; Jin et al., 2018; Mesgar and Strube, 2018; Wang et al., 2018; Mim et al., 2019; Nadeem et al., 2019).",
      "startOffset" : 71,
      "endOffset" : 265
    }, {
      "referenceID" : 23,
      "context" : "Many DNN-AES models have been proposed and have achieved high accuracy (Alikaniotis et al., 2016; Taghipour and Ng, 2016; Dasgupta et al., 2018; Farag et al., 2018; Jin et al., 2018; Mesgar and Strube, 2018; Wang et al., 2018; Mim et al., 2019; Nadeem et al., 2019).",
      "startOffset" : 71,
      "endOffset" : 265
    }, {
      "referenceID" : 25,
      "context" : "Following the first AES method, Project Essay Grade (PEG) (Page, 2003), many feature engineering– based AES methods have been developed, including Intelligent Essay Assessor (IEA) (Foltz et al.",
      "startOffset" : 58,
      "endOffset" : 70
    }, {
      "referenceID" : 10,
      "context" : "Following the first AES method, Project Essay Grade (PEG) (Page, 2003), many feature engineering– based AES methods have been developed, including Intelligent Essay Assessor (IEA) (Foltz et al., 2013), e-rater (Attali and Burstein, 2006), the Bayesian Essay Test Score sYstem (BETSY) (Rudner and Liang, 2002), and IntelliMetric (Schultz, 2013).",
      "startOffset" : 180,
      "endOffset" : 200
    }, {
      "referenceID" : 2,
      "context" : ", 2013), e-rater (Attali and Burstein, 2006), the Bayesian Essay Test Score sYstem (BETSY) (Rudner and Liang, 2002), and IntelliMetric (Schultz, 2013).",
      "startOffset" : 17,
      "endOffset" : 44
    }, {
      "referenceID" : 30,
      "context" : ", 2013), e-rater (Attali and Burstein, 2006), the Bayesian Essay Test Score sYstem (BETSY) (Rudner and Liang, 2002), and IntelliMetric (Schultz, 2013).",
      "startOffset" : 91,
      "endOffset" : 115
    }, {
      "referenceID" : 31,
      "context" : ", 2013), e-rater (Attali and Burstein, 2006), the Bayesian Essay Test Score sYstem (BETSY) (Rudner and Liang, 2002), and IntelliMetric (Schultz, 2013).",
      "startOffset" : 135,
      "endOffset" : 150
    }, {
      "referenceID" : 38,
      "context" : "Other recent works solve AES by using preference-ranking models (Yannakoudakis et al., 2011; Chen and He, 2013).",
      "startOffset" : 64,
      "endOffset" : 111
    }, {
      "referenceID" : 3,
      "context" : "Other recent works solve AES by using preference-ranking models (Yannakoudakis et al., 2011; Chen and He, 2013).",
      "startOffset" : 64,
      "endOffset" : 111
    }, {
      "referenceID" : 27,
      "context" : "Table 1 shows examples of representative features (Phandi et al., 2015; Ke and Ng, 2019).",
      "startOffset" : 50,
      "endOffset" : 88
    }, {
      "referenceID" : 13,
      "context" : "Table 1 shows examples of representative features (Phandi et al., 2015; Ke and Ng, 2019).",
      "startOffset" : 50,
      "endOffset" : 88
    }, {
      "referenceID" : 14,
      "context" : "Readability indices, such as Flesch–Kincaid reading ease (Kincaid et al., 1975), Gunning fog (Whisner, 2004), or SMOG index (Fitzsimmons et al.",
      "startOffset" : 57,
      "endOffset" : 79
    }, {
      "referenceID" : 37,
      "context" : ", 1975), Gunning fog (Whisner, 2004), or SMOG index (Fitzsimmons et al.",
      "startOffset" : 21,
      "endOffset" : 36
    }, {
      "referenceID" : 9,
      "context" : ", 1975), Gunning fog (Whisner, 2004), or SMOG index (Fitzsimmons et al., 2010).",
      "startOffset" : 52,
      "endOffset" : 78
    }, {
      "referenceID" : 10,
      "context" : "Semantic feature Semantic similarity based on latent semantic analysis (Foltz et al., 2013).",
      "startOffset" : 71,
      "endOffset" : 91
    }, {
      "referenceID" : 16,
      "context" : "Histogram-based features computed by pointwise mutual information (Klebanov and Flor, 2013).",
      "startOffset" : 66,
      "endOffset" : 91
    }, {
      "referenceID" : 24,
      "context" : "Argument tree depth as estimated using argument mining techniques (Nguyen and Litman, 2018).",
      "startOffset" : 66,
      "endOffset" : 91
    }, {
      "referenceID" : 0,
      "context" : "The LSTM-based model (Alikaniotis et al., 2016), which was the first DNN-AES model, predicts essay scores through the multi-layered neural networks shown in Fig.",
      "startOffset" : 21,
      "endOffset" : 47
    }, {
      "referenceID" : 35,
      "context" : "Specifically, bidirectional encoder representations from transformers (BERT), a pre-trained multilayer bidirectional transformer network (Vaswani et al., 2017) released by the Google AI Language team, have achieved state-of-the-art results in various NLP tasks, such as question answering, named entity recognition, natural language inference, and text classification (Devlin et al.",
      "startOffset" : 137,
      "endOffset" : 159
    }, {
      "referenceID" : 7,
      "context" : ", 2017) released by the Google AI Language team, have achieved state-of-the-art results in various NLP tasks, such as question answering, named entity recognition, natural language inference, and text classification (Devlin et al., 2019).",
      "startOffset" : 216,
      "endOffset" : 237
    }, {
      "referenceID" : 29,
      "context" : "BERT was also applied to AES (Rodriguez et al., 2019) and automated short-answer grading (Liu et al.",
      "startOffset" : 29,
      "endOffset" : 53
    }, {
      "referenceID" : 18,
      "context" : ", 2019) and automated short-answer grading (Liu et al., 2019; Sung et al., 2019) in 2019, and demonstrated good performance.",
      "startOffset" : 43,
      "endOffset" : 80
    }, {
      "referenceID" : 33,
      "context" : ", 2019) and automated short-answer grading (Liu et al., 2019; Sung et al., 2019) in 2019, and demonstrated good performance.",
      "startOffset" : 43,
      "endOffset" : 80
    }, {
      "referenceID" : 7,
      "context" : "BERT output corresponding to this token is used as a fixed-length distributed text representation (Devlin et al., 2019).",
      "startOffset" : 98,
      "endOffset" : 119
    }, {
      "referenceID" : 32,
      "context" : "Readability features Automated readability index (Smith and Senter, 1967), Coleman– Liau index (Coleman and Liau, 1975), Dale–Chall readability score, difficult word count, Flesch reading ease (Kincaid et al.",
      "startOffset" : 49,
      "endOffset" : 73
    }, {
      "referenceID" : 4,
      "context" : "Readability features Automated readability index (Smith and Senter, 1967), Coleman– Liau index (Coleman and Liau, 1975), Dale–Chall readability score, difficult word count, Flesch reading ease (Kincaid et al.",
      "startOffset" : 95,
      "endOffset" : 119
    }, {
      "referenceID" : 14,
      "context" : "Readability features Automated readability index (Smith and Senter, 1967), Coleman– Liau index (Coleman and Liau, 1975), Dale–Chall readability score, difficult word count, Flesch reading ease (Kincaid et al., 1975), Flesch–Kincaid grade (Kincaid et al.",
      "startOffset" : 193,
      "endOffset" : 215
    }, {
      "referenceID" : 14,
      "context" : ", 1975), Flesch–Kincaid grade (Kincaid et al., 1975), Gunning fog (Whisner, 2004), Linsear write formula, SMOG index (Fitzsimmons et al.",
      "startOffset" : 30,
      "endOffset" : 52
    }, {
      "referenceID" : 37,
      "context" : ", 1975), Gunning fog (Whisner, 2004), Linsear write formula, SMOG index (Fitzsimmons et al.",
      "startOffset" : 21,
      "endOffset" : 36
    }, {
      "referenceID" : 9,
      "context" : ", 1975), Gunning fog (Whisner, 2004), Linsear write formula, SMOG index (Fitzsimmons et al., 2010), syllable count.",
      "startOffset" : 72,
      "endOffset" : 98
    }, {
      "referenceID" : 26,
      "context" : "As the embedding matrix, we used Glove (Pennington et al., 2014) with 50 dimensions.",
      "startOffset" : 39,
      "endOffset" : 64
    }, {
      "referenceID" : 15,
      "context" : "We used the Adam optimization algorithm (Kingma and Ba, 2014) to minimize the mean squared error (MSE) loss function over the training data.",
      "startOffset" : 40,
      "endOffset" : 61
    }, {
      "referenceID" : 0,
      "context" : "has higher performance than models with last pooling, which is also consistent with previous studies (Alikaniotis et al., 2016; Riordan et al., 2017).",
      "startOffset" : 101,
      "endOffset" : 149
    }, {
      "referenceID" : 28,
      "context" : "has higher performance than models with last pooling, which is also consistent with previous studies (Alikaniotis et al., 2016; Riordan et al., 2017).",
      "startOffset" : 101,
      "endOffset" : 149
    }, {
      "referenceID" : 7,
      "context" : "BERT outperforms the LSTM-based models, as in other BERT applications including automated short-answer grading (Devlin et al., 2019; Liu et al., 2019; Lun et al., 2020; Sung et al., 2019).",
      "startOffset" : 111,
      "endOffset" : 187
    }, {
      "referenceID" : 18,
      "context" : "BERT outperforms the LSTM-based models, as in other BERT applications including automated short-answer grading (Devlin et al., 2019; Liu et al., 2019; Lun et al., 2020; Sung et al., 2019).",
      "startOffset" : 111,
      "endOffset" : 187
    }, {
      "referenceID" : 19,
      "context" : "BERT outperforms the LSTM-based models, as in other BERT applications including automated short-answer grading (Devlin et al., 2019; Liu et al., 2019; Lun et al., 2020; Sung et al., 2019).",
      "startOffset" : 111,
      "endOffset" : 187
    }, {
      "referenceID" : 33,
      "context" : "BERT outperforms the LSTM-based models, as in other BERT applications including automated short-answer grading (Devlin et al., 2019; Liu et al., 2019; Lun et al., 2020; Sung et al., 2019).",
      "startOffset" : 111,
      "endOffset" : 187
    } ],
    "year" : 2020,
    "abstractText" : "Automated essay scoring (AES) is the task of automatically assigning scores to essays as an alternative to grading by human raters. Conventional AES typically relies on handcrafted features, whereas recent studies have proposed AES models based on deep neural networks (DNN) to obviate the need for feature engineering. Furthermore, hybrid methods that integrate handcrafted features in a DNN-AES model have been recently developed and have achieved state-of-the-art accuracy. One of the most popular hybrid methods is formulated as a DNN-AES model with an additional recurrent neural network (RNN) that processes a sequence of handcrafted sentencelevel features. However, this method has the following problems: 1) It cannot incorporate effective essay-level features developed in previous AES research. 2) It greatly increases the numbers of model parameters and tuning parameters, increasing the difficulty of model training. 3) It has an additional RNN to process sentence-level features, enabling extension to various DNN-AES models complex. To resolve these problems, we propose a new hybrid method that integrates handcrafted essay-level features into a DNN-AES model. Specifically, our method concatenates handcrafted essay-level features to a distributed essay representation vector, which is obtained from an intermediate layer of a DNN-AES model. Our method is a simple DNN-AES extension, but significantly improves scoring accuracy.",
    "creator" : " TeX output 2020.04.06:1834"
  }
}