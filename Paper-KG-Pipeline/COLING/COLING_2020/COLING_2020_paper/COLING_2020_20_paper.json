{
  "name" : "COLING_2020_20_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Linguistic Perspective on Reference: Choosing a Feature Set for Generating Referring Expressions in Context",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Various theoretical and empirical works have addressed the question of which factors play a role in the choice of referring expressions. One of the main ideas in this tradition (henceforth; the linguistic tradition) is that there is a direct relationship between the “prominence” (in a broad sense) that a referent has at a given point in the discourse, and the form that is used to refer to the referent at that point. If a referent is highly prominent, a short anaphoric form (e.g. a pronoun) suffices; if it is less prominent, longer forms with more semantic content are used. Prominence has been argued to be influenced by various factors such as recency and frequency of mention (Ariel, 1990), grammatical function (Brennan, 1995), animacy (Fukumura and van Gompel, 2011), distance (McCoy and Strube, 1999) and competition between the referents (Arnold and Griffin, 2007). Reference production is also one of the most-studied topics in Natural Language Generation (Gatt and Krahmer, 2018), where it is known as Referring Expression Generation (Krahmer and van Deemter, 2019). A key part of the REG problem is deciding which form (e.g., proper name, definite description or pronoun) is employed to refer to a target referent at a given point in the discourse. Henceforth we call this task Selection of Referential Form (SRF). SRF models come in many shapes and forms, with feature-based machine learning models playing a dominant role. However, the feature sets employed by these models can differ considerably from one model to the next, and although “linguistic” features akin to the ones employed in the linguistic tradition are often used, other types of features, which are harder to interpret linguistically, are frequent as well.\nOur aim in this paper is to examine feature-based SRF models from a linguistic perspective: We will conduct a systematic evaluation of these models, asking what features make these models work best. Having done this, we propose a “consensus” feature set; we consider this to be useful because it will enable linguists to compare these algorithms to their own theories and insights, so that features may be enhanced or replaced by other features in the future. Finally, we compare the features in our consensus feature set against the factors considered to be important in the linguistic tradition.\nAn important question in any systematic evaluation is how the objects of study (in our case, SRF feature sets) are selected. We have proceeded as follows:\n• We selected all SRF algorithms submitted to GREC (Belz et al., 2010) and extracted the feature sets used by these algorithms. GREC was a Shared Task Evaluation task that still forms a natural starting point, because it attracted all the main SRF algorithms that existed at the time.\n• We additionally selected two other feature sets from the papers archived in the ACL Anthology. The selection method will be detailed in subsection 3.1.\n• We re-implemented all features that were obtained in this way, following the method detailed in section subsection 3.2.\nNote that our systematic evaluation does not include methods that are based on Deep Learning (e.g., Ferreira et al. (2018); Cao and Cheung (2019)) since, at the current state of the art, these do not yet offer much opportunity for linguistic interpretation. Our focus is on interpretable linguistic features. To perform our actual evaluation, two further choices need to be explained and motivated: we had to define an exact task (because the SRF task as such can be defined in different ways), and we had to specify a corpus. These two choices will be explained in section 3. The paper will conclude with a proposed consensus feature set and a discussion of the extent to which the features in it are linguistically interpretable (section 4)."
    }, {
      "heading" : "2 Related Work",
      "text" : "Data-driven models employ different features to make choices similar to what humans do. For instance, Greenbacker and McCoy (2009a) used linguistically informed features such as recency, subjecthood, parallelism and ambiguity to predict the form of expressions. Jamison (2008) trained a maximum entropy classifier on features pertaining to the competition between the referents, order of mentions in the text and the referential status of the expressions. In a comprehensive study, Kibrik et al. (2016) assumed that reference generation is a multifactorial process governed by various linguistically motivated features. Hendrickx et al. (2008), on the other hand, focused more on the existing patterns in the text and less on the use of linguistic categories. In a more recent study, Ferreira (2018) used features marking the syntactic position, recency and referential status (givenness) of the referents in a recurrent neural network model to model the referential choice variations.\nIn one of the few studies focusing on feature selection for the REG, Greenbacker and McCoy (2009b) surveyed the psycholinguistics literature to make up feature sets for their SRF study. They implemented several linguistically informed rules in their prototyping system, and “examined the incorrect classifications which resulted in an attempt to discover which other factors suggested by psycholinguistic research could explain the patterns they observed.” Additionally, they incorporated some of the features used in Hendrickx et al. (2008) and created an extensive set of features which they felt had an impact on the choice of referring expressions. They selected five different subsets of these features and trained C5.0 decision trees on them. The interesting result from their study is that the maximum number of features does not necessarily lead to best results. The problem with their study is that firstly, they do not propose any explanation on how they have selected different feature subsets. Secondly, their feature selection strategy is to subjective because it mostly concerns the features they find important and has less to do with the features of other models. Lastly, they have provided no linguistic explanation for their best performing system. Kibrik et al. (2016) also briefly talked about the feature selection in their study, stating that the distance-related features are the most important ones for the referential choice prediction. Their study is linguistically informed and includes various linguistic features. However, the annotation effort behind their study is very intense, as it requires complex layers of annotations. The question is whether they could achieve a nearly similar performance using a fewer set of features."
    }, {
      "heading" : "3 Corpus and feature sets considered",
      "text" : "As stated in section 1, we want to evaluate the importance of the features used in various SRF machine learning studies in a systematic way. The most important prerequisite for this evaluation is to select a collection of feature sets. subsection 3.1 describes the criteria for selecting the feature sets and provide an overview of the chosen sets. Afterwards, we explain how we applied the selected feature sets to the OntoNotes corpus (subsection 3.2)."
    }, {
      "heading" : "3.1 Feature sets",
      "text" : "This section outlines the procedure we followed for selecting feature sets from the available SRF papers. After setting out a concrete set of criteria for the feature set selection, we conducted an exhaustive review of literature which ended up in choosing seven feature sets for this study.\nThe criteria for selecting feature sets were as follows: we looked for studies that (1) had as their main objective SRF, (2) employed a machine learning method, (3) used an English dataset and (4) applied interpretable features.\nAs our starting point, we selected all the other feature sets used by the SRF algorithms in the GRECMSR’08, the GREC-MSR’09 and the GREC-NEG’09 challenges [henceforth the GREC feature sets]. Of these feature sets, we excluded the JUNLG set (Gupta and Bandopadhyay, 2009) because their study was rule-based, and the WLV feature set (Orăsan and Dornescu, 2009) because we were not able to interpret all their features.\nAs the GREC challenges were conducted several years ago, we decided to examine the more recent literature to see whether there are more recent SRF feature sets satisfying our criteria. We downloaded full Anthology as BibTex with abstracts from https://www.aclweb.org/anthology/ and used regular expressions to search manually the following expressions in the title and the abstracts of the articles: • [D|d]ata-driven˙[E|e]xpression • Generation.*[R|r]eferring [E|e]xpression.*discourse • [R|r]eferring [E|e]xpression.* [M|m]achine [L|l]earning • title =.*[R|r]eference [G|g]eneration and • title =.*[R|r]eferring [E|e]xpression.\nOf the selected results, we excluded various papers because they did not meet the criteria defined above (Zarrieß and Kuhn, 2013; Siddharthan et al., 2011; Stent, 2011; Nenkova, ; Ferreira and Paraboni, 2017). Based on the result of the manual search, we included feature sets from the papers by Castro Ferreira et al. (2016) and Kibrik et al. (2016), which, together with the GREC feature sets form the seven sets we use in our feature selection experiments. As a naming convention, we call the GREC feature sets by their names from Belz et al. (2010); the other two feature sets, namely ferreira and kibrik, are named after their first authors.\nIn what follows, each paragraph presents each individual feature set. The name in the parenthesis in front of each feature is how they are named in our experiments, and how we refer to them in the tables and figures. The features are separated from each other with a straight line.\nis-g (Bohnet, 2008): • grammatical role (gm) • distance to the last mention (dis pr nmrc) • count of the referring expressions (wch ment) • type of the previous mention (pr typ) • whether or not the current and the last mention are in the same sentence (diff sent)\nosu (Jamison and Mehay, 2008): • whether or not the current entity has a competitor in the whole text, the text preceding the mention, or between the current and the previous mention (consecutively: osu cmpet txt, osu prv cmpt, osu cmpet btwn) • *string similarity measures between the title and the current mention • discretized order of mentions (order fctr) • discretized distance in words to the previous mention (w dist fct) • discretized distance in sentence boundaries (d dist fct) • whether or not the expression is mentioned for the first time (old new) • grammatical role (gm) • semantic type (anim)\nudel (Greenbacker and McCoy, 2009a): • grammatical role of the current and the three most current mentions (gm prv, gm prv1, gm prv2, gm prv3) • whether or not the last mention was in the subject position (prv gm subj) • whether or not there are intervening referents between the current and the previous mention (interv ref) • *distance to the preceding non-referring occurrences of an entity name • whether or not the expression is immediately followed the words and, but,then, or if it appeared between a comma and the word and (flw and, flw but, flw then, btw comma and) •Whether or not the distance between the two mentions is more than two sentences (lng short dist) • whether or not there are interfering antecedents in the current sentence and the text since that last reference (interv ent sent) • distance between the mentions (dst prv) • entity and mention number (ent num, sent num) • sentence ID (sent num) and reference ID • whether or not the last mention is in subject position (prv gm subj), whether the mention is the subject of the current and the two previous sentences (subj curS, subj prevS, subj 2prvS)\ncnts (Hendrickx et al., 2008): • sentence number (sent num) • NP number (np num) • Whether or not the mention appears in the first sentence (first sent) • Grammatical role (gm) • semantic category (anim) • 3 words left and right of the entity (tri w before, bi w before, uni w before, tri w aft, bi w aft,\nuni w aft) • 3 POS tags left and right of the entity (tri pos before, bi pos before, uni pos before, tri pos aft, bi pos aft, uni pos aft) • Distance to the previous mention measured in sentences and in NPs (dist sent, dist np) • Trigram pattern of three previous mentions (three prv gm) • whether or not the previous sentence contains another referent (prevS anoth ent)\nicsi (Favre and Bohnet, 2009): • word unigram and bigram before and after the expression (bi w before, uni w before, bi w aft, uni w aft) • morphology of the previous and next words (morph before, morph after) • punctuation type before and after the referring expression (punct before, punct after) • grammatical role (gm) • *syntactic category • semantic category (anim) • whether or not the previous expression is about the same entity (same prv) • number of occurrence of the entity since the beginning of the text (ref in chain) • number of occurrence of the entity since the last change of entity (next in chain) • beginning of paragraph indicator (begin sent par)\nferreira (Ferreira et al., 2016): • grammatical role (gm) • whether or not the referent is new at the level of text, paragraph and sentence (new in text, new in par, new in sent) • number of words between the current and the previous mention (word distance)\nkibrik (Kibrik et al., 2016): • animacy (animacy) • gender (gender) • *person • number (plurality) • protagonism (protagonism1) • ordinal number of referent mention in the referential chain (ref in chain) • phrase type and grammatical role of the current and the previous mention(phrase ty, gm, prev phrase ty, prev gm) • referential form of the previous mention (prev ref ty) • length of the previous mention (prev ref len) • distance in words, markables, *EDU, *RhD, sentence and paragraphs to the previous mention (dist prev, dist markable, dist sent, dist par) • *number of markables in chain from the anaphor back to the nearest full NP antecedent\nIn this section, we explained the features of each feature set. We created an ontology of the features for SRF to get a feeling of the type of the information each feature set is trying to encode. Table 1 groups the features that were used in the models together into broader classes. The class Grammatical role contains information about the syntactic position of the current and the previous mentions. Inherent features of referents such as animacy, gender and plurality are grouped together in the class Inherent. Distance/Recency class includes information about the distance between a referring expression and its previous mention in different measures (e.g. in words, NP, sentences). Givenness/Referential status shows the referential status of the referring expressions, such as whether the referent is new in the paragraph. Information about the existence of other referents in the vicinity of the target expression are grouped together in the Competition. Tyhe class Antecedent form concerns the form and the length of the previous mention. Pattern contains features concerning the uni-trigram words and POS tags around the target expression. Information on the position of an expression such as in which sentence or in which paragraph it appears are available in the Position category. The last two classes, Chain and salience contain features pertaining to the length of a referential chain and the salience of a referent in the whole text."
    }, {
      "heading" : "3.2 Applying feature sets to the OntoNotes Corpus",
      "text" : "The GREC feature sets (isg, osu, udel, cnts and icsi) have been trained on one or both of the GREC corpora, GREC-20 and GREC-People. The SRF task in the GREC challenges concerned four referential choices, namely the choice between pronoun, proper name, descriptions or null forms. In their SRF study, (Ferreira et al., 2016) applied their feature set (ferreira) to the VaREG corpus to predict either of these forms: pronouns, descriptions, proper names, null forms and demonstratives. The last feature set, kibrik, has been applied to the RefRhet corpus in two SRF tasks, one for making a binary prediction, the other for making a three-way distinction (pronouns, proper names and descriptions). Excluding the binary distinction study, we take the intersection of the aforementioned referential choice distinctions. Hence, the prediction task in the current study is to predict the referential form being a pronoun, a proper name or a description.\nIn this study, we decided to use the English newswire data (from the Wall Street Journal) available in OntoNotes (Pradhan et al., 2013). One of the main reasons for using this subset of the data is that it is\nannotated with structural information (syntax and predicate argument structure) and shallow semantics. Also, in order to extract paragraph information, we incorporated the information from the underlying files of the PDTB parser (https://github.com/WING-NUS/pdtb-parser/tree/master/ external/aux_data/paragraphs). Having different levels of analysis made the application of most of the features to the corpus possible.\nThe total number of features attained after applying the feature sets to the OntoNotes corpus is 91. There are a few features that we did not apply to the corpus. Examples of such cases are: elementary discourse unit (EDU) and rhetorical distance (RhD) measurements, both from kibrik. These features are marked with an asterisk in subsection 3.1. It is noteworthy that applying the features was not always straightforward. Particular difficulty was posed for instance by distance measures: to find the distance in words between two mentions, two different approaches are possible: either to keep the punctuation in the counting or to ignore them. The distance measures in this study such as the distance in words, NPs and markables to the previous mention, take punctuation into the consideration. As another example, one of the features in the kibrik dataset is the distance in markables between two mentions. In the Ontonotes corpus, only those referring expressions which are mentioned more than once are marked. As a result, the count is solely based on the expressions which are marked. Another decision that we made was to solely use third person referents in the study, because first and second person referents majorly have one type of instantiating, being pronominal. After excluding these expressions, we ended up using 30500 referring expressions, divided into 70% training and 30% test sets.\nIn this section, we described the feature sets we will use in our feature selection studies and explained how we applied them to the OntoNotes corpus. In the next section, section 4, we will explain the feature selection experiments for the assessment of the feature sets."
    }, {
      "heading" : "4 Feature selection experiments for assessing the features of different feature sets",
      "text" : "We start by briefly explaining the classification algorithm and the feature selection methods we use in our experiments (subsection 4.1). Afterwards, we elaborate on the classification models trained on the OntoNotes data using the proposed feature sets (subsection 4.2). The section continues with two feature selection experiments with which we assess the importance of the features (subsection 4.3 and subsection 4.4). The next step we take is using different subsets of the features and re-run the classification algorithms. The purpose of this step is to see what would happen if the proposed feature sets were made smaller, and whether similar accuracy to the original models is possible using fewer features."
    }, {
      "heading" : "4.1 The classification algorithm and the feature selection methods explained",
      "text" : "We use the Random Forests algorithm as our classifier method in this study. Random Forests is an ensemble learning algorithm mostly used in the classification tasks. The classification is based on the\nresults achieved from the myriad of decision trees it generates while training (Nayak and Natarajan, 2016; Biau, 2012). Random Forests algorithm also computes the importance of the variables while training the classification models. We use this feature in our first feature selection experiment.\nAfter building the classification models, we want to assess how important the features in each model are. For assessing the importance of the features, we use two automatic feature selection methods: “Rank Features by Importance [henceforth RFI]” and “Forward Feature Selection [henceforth FFS]”.\nFor the RFI experiment, we make use of the outcome of the embedded built-in feature selection method of the Ranfom Forests algorithm. The second experiment concerns using the FFS method for assessing the importance of the features. FFS, as a wrapper method, computes the variable importance by trying out different subsets of the features. It starts with one attribute and incrementally adds other features up to the point that there is no more improvement in the performance."
    }, {
      "heading" : "4.2 Building the Random Forests models for predicting the referential choice",
      "text" : "To implement the Random Forests algorithm, we usedranger (Wright and Ziegler, 2015), which is a fast implementation of Random Forests in R. The variable importance measure was set to Permutation Importance (Mean Decrease in Accuracy). Table 2 presents the results of the Random Forests models with the original features of each feature set.\nAccording to Table 2, the model trained by the kibrik feature set has the highest accuracy, followed respectively by the cnts and osu models. In the next section, we will evaluate the features of each set to see which contributed the most to predictive success."
    }, {
      "heading" : "4.3 Experiment one: evaluating the importance of the features using RFI",
      "text" : "In this section, we will detail the results of the RFI experiment. We use the built-in RFI of the Random Forests algorithm. Figure 1 shows the importance of different variables in the seven models. In all the models using animacy, it either has the highest or the second highest importance. The common feature in all the feature sets is the grammatical role of the current mention. In all models (except kibrik), grammatical role is among the most important features. The next interesting observation is about the distance measures. There are different implementation of the distance measures in the feature sets, such as the distance in words, nps, markables, sentences and paragraph to the previous mention. Interestingly, all the models that employ the feature distance in number of sentences rank this feature more importance than the other distance measures. The other important feature is whether the current expression is the first mention of the referent in the current sentence, or whether it has been mentioned before. Based on the results of the isg and the ferreira models that employ this feature, it is ranked as the second most important in both models. Interestingly, other givenness measures such as the newness of the expression in the text (employed in the osu and the ferreira models) are not ranked as important. Features with less importance are from the position, chain and salience classes. Concerning the pattern features (e.g., the unigram words before and after the current mention), it seems only uni-gram patterns matters to some extent, and the bigram and trigram patterns do not play important roles."
    }, {
      "heading" : "4.4 Experiment two: evaluating the importance of the features using FFS",
      "text" : "The second method we use in this study is forward selection of the features. The algorithm starts with only one feature and adds up to the point that no further improvement happens. We used the R package mlr(Bischl et al., 2016) for the implementation of the FFS algorithm. The learner we used in this model\nis classif.randomForest and the resampling strategy is Holdout. Each box in the below image shows the important features of each model. In the next section, we will explain how we use the results of both RFI and FFS in assessing the importance of the features.\nisg gm prev type same sent\ncnts anim uni pos b4 dist np\nosu anim gm dist sent old new\nferreira gm same sent\nicsi anim same prv\nudel gm gm prev1 gm prev2 interv ref long short d\nkibrik anim plurality gm dist sent prev type dist par"
    }, {
      "heading" : "4.5 Experiment three: exploring different feature subsets based on their importance",
      "text" : "To discover what parts of the feature sets proposed in the computational linguistics literature are the most important, we experimented by applying the Random Forests algorithm of subsection 4.2 on various subsets of these feature sets, and combinations of these subsets.\n1. For each of the 7 models of Figure 1, instead of applying the Random Forests algorithm to all the features originally proposed for the model, we applied it to the one feature that was most impor-\ntant for that model (see Figure 1). For example, the isg 1 model was applied to the singleton set {pr typ}.\n2. Same procedure, but with the most important two features of the orginally proposed feature sets. For example, the isg 2 model was applied to the singleton set {pr typ, diff sent}.\n3. Same procedure, with the most important three features.\n4. Same procedure, with all features that are among the top 50% most important features.\n5. This time, we applied the Random Forests algorithm to the set of those features that were most important for one or more of the models. This is the set {gm, anim, pr typ} because many of the models have the same most important feature (gm or animacy).\n6. This time, we applied the Random Forests algorithm to the set of those features that were two most important features for one or more of the models.\n7. For each of the 7 models, we applied the Random Forests algorithm to the set of features listed under the FFS model in subsection 4.4. For example, the Random Forests algorithm was applied to the feature set {anim,gm,dist sent,old new}.\n8. For each of the 7 models, we applied the Random Forests algorithm to the set of all features mentioned in section 4.3 (this is the set union of the 7 sets in the previous item.)\n9. Finally, we applied the Random Forests algorithm to a new set of features, to be thoroughly explained in section 5. The idea here is to reach an optimal compromise between the number of features (which should be small) and performance (which should be high)."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this study, the aim was to systematically examine feature-based SRF models, trying to understand what features make the model work best. By evaluating different feature sets of the computational SRF studies from a linguistic perspective, we tried to make a bridge between using linguistically explainable features in computational models and the linguistic explanations behind the importance of those features.\nThe most obvious finding to emerge from this study is that by using an optimal (and smaller) set of features, the models can achieve a nearly identical performance. As shown in Table 3, the performance of the kibrik system using 18 features is 0.79. We can achieve a performance of .754 using only six features.\nBased on the results of the two feature selection experiments conducted on seven feature sets (91 features), we have composed a consensus set consisting of six features from 5 classes: • animacy and plurality [Inherent features of the referent] • grammatical role of the current mention • form of the previous mention • distance in sentence to the previous mention 1 [recency] •whether or not the mention is new in the sentence [givenness].\nComparing the consensus set we propose here with the previously proposed feature sets have interesting implications for the feature-based SRF research. As we saw in Table 1, except icsi, all the other systems encode the recency class one way or the other. For example the isg feature set encodes recency as the distance in words to the previous mention, osu implements two discretized recency measures (one in number of words, the other in number of sentences). Interestingly, as the result of the two experiment showed, the recency class measured in number of sentences plays a much important role compared to other recency measures. The same holds for the givenness class: the newness on the sentence level plays a much more important role than the other givenness measures. The important lesson from this observation for the feature-based studies is that the features we derive from decomposing single classes do not always contribute equally to a model; some makes a much bigger contributions. Examples are the two recency and givenness measures we just mentioned.\nIn addition to practical implications for the feature-based SRF studies, the present work also has major implications for the linguistic tradition. The six features selected as our consensus set are all from the major classes of factors claimed to impact the referential choice. In what follows, we go through them one by one and will detail the findings of the study:\n• Inherent features of the referent: In the two feature selection experiments, we showed that two inherent features of a referent, namely animacy and plurality, play major roles in predicting the referential choice. Given the linguistics literature, the importance of animacy is no great surprise (Fukumura and van Gompel, 2011). More of a surprise is the role of plurality for SRF which has attracted less attention in the linguistic tradition.\n• Grammatical role: Linguistic studies tend to emphasize the grammatical role of the antecedent as well the current mention (Brennan, 1995; Grosz et al., 1995). Our analysis suggests that the grammatical role of the current mention might be far more important than that of the antecedent.\n• Form of the previous mention: In this case, our findings match those in the linguistic tradition (Gundel and Hedberg, 2008).\n• Recency. Recency, in the linguistic tradition, has often been emphasized, but often without a clear definition. Our study suggests that recency is better defined in terms of the number of sentences that intervene between the antecedent and the current mention than in terms of the number of words or markables.\n• Givenness status. Givenness has always been one of the main factors discussed in the linguistic tradition (Gundel et al., 1993) We find plenty of support for this idea, but our findings suggest that the most important aspect of givenness from SRF perspective is whether or not a referent has been mentioned in the same sentence as the current mention (as opposed to the same discourse as a whole).\nLinguists can use the points mentioned here to consider implications of linguistic theories of reference production. In the linguistic tradition, the referential classes are usually discussed in a much broader sense (take for instance the recency class). How these classes are fragmented and broken into quantified features in the feature-based computational studies can provide new perspectives into these classes, and encourages the re-evaluation of these terms to propose more concrete definitions.\n1Between a numerical implementation of this feature and a discretized categorical implementation, the latter had a slightly better impact."
    } ],
    "references" : [ {
      "title" : "Accessing noun-phrase antecedents",
      "author" : [ "Mira Ariel" ],
      "venue" : null,
      "citeRegEx" : "Ariel.,? \\Q1990\\E",
      "shortCiteRegEx" : "Ariel.",
      "year" : 1990
    }, {
      "title" : "The effect of additional characters on choice of referring expression: Everyone counts",
      "author" : [ "Jennifer E Arnold", "Zenzi M Griffin." ],
      "venue" : "56(4):521–536.",
      "citeRegEx" : "Arnold and Griffin.,? 2007",
      "shortCiteRegEx" : "Arnold and Griffin.",
      "year" : 2007
    }, {
      "title" : "Generating referring expressions in context: The task evaluation challenges",
      "author" : [ "Anja Belz", "Eric Kow", "Jette Viethen", "Albert Gatt." ],
      "venue" : "Empirical methods in natural language generation, pages 294–327. Springer.",
      "citeRegEx" : "Belz et al\\.,? 2010",
      "shortCiteRegEx" : "Belz et al\\.",
      "year" : 2010
    }, {
      "title" : "Analysis of a random forests model",
      "author" : [ "Gérard Biau." ],
      "venue" : "The Journal of Machine Learning Research, 13(1):1063– 1095.",
      "citeRegEx" : "Biau.,? 2012",
      "shortCiteRegEx" : "Biau.",
      "year" : 2012
    }, {
      "title" : "mlr: Machine learning in r",
      "author" : [ "Bernd Bischl", "Michel Lang", "Lars Kotthoff", "Julia Schiffner", "Jakob Richter", "Erich Studerus", "Giuseppe Casalicchio", "Zachary M Jones." ],
      "venue" : "The Journal of Machine Learning Research, 17(1):5938–5942.",
      "citeRegEx" : "Bischl et al\\.,? 2016",
      "shortCiteRegEx" : "Bischl et al\\.",
      "year" : 2016
    }, {
      "title" : "Is-g: The comparison of different learning techniques for the selection of the main subject references",
      "author" : [ "Bernd Bohnet." ],
      "venue" : "Proceedings of the Fifth International Natural Language Generation Conference, pages 192–193. Association for Computational Linguistics.",
      "citeRegEx" : "Bohnet.,? 2008",
      "shortCiteRegEx" : "Bohnet.",
      "year" : 2008
    }, {
      "title" : "Centering attention in discourse",
      "author" : [ "Susan E Brennan." ],
      "venue" : "10(2):137–167.",
      "citeRegEx" : "Brennan.,? 1995",
      "shortCiteRegEx" : "Brennan.",
      "year" : 1995
    }, {
      "title" : "Referring expression generation using entity profiles",
      "author" : [ "Meng Cao", "Jackie Chi Kit Cheung." ],
      "venue" : "arXiv preprint arXiv:1909.01528.",
      "citeRegEx" : "Cao and Cheung.,? 2019",
      "shortCiteRegEx" : "Cao and Cheung.",
      "year" : 2019
    }, {
      "title" : "Towards more variation in text generation: Developing and evaluating variation models for choice of referential form",
      "author" : [ "Thiago Castro Ferreira", "Emiel Krahmer", "Sander Wubben." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 568–577, Berlin, Germany, August. Association for Computational Linguistics.",
      "citeRegEx" : "Ferreira et al\\.,? 2016",
      "shortCiteRegEx" : "Ferreira et al\\.",
      "year" : 2016
    }, {
      "title" : "Icsi-crf: the generation of references to the main subject and named entities using conditional random fields",
      "author" : [ "Benoit Favre", "Bernd Bohnet." ],
      "venue" : "Proceedings of the 2009 Workshop on Language Generation and Summarisation, pages 99–100. Association for Computational Linguistics.",
      "citeRegEx" : "Favre and Bohnet.,? 2009",
      "shortCiteRegEx" : "Favre and Bohnet.",
      "year" : 2009
    }, {
      "title" : "Improving the generation of personalised descriptions",
      "author" : [ "Thiago Castro Ferreira", "Ivandré Paraboni." ],
      "venue" : "Proceedings of the 10th International Conference on Natural Language Generation, pages 233–237.",
      "citeRegEx" : "Ferreira and Paraboni.,? 2017",
      "shortCiteRegEx" : "Ferreira and Paraboni.",
      "year" : 2017
    }, {
      "title" : "Individual variation in the choice of referential form",
      "author" : [ "Thiago Castro Ferreira", "Emiel Krahmer", "Sander Wubben." ],
      "venue" : "Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 423–427.",
      "citeRegEx" : "Ferreira et al\\.,? 2016",
      "shortCiteRegEx" : "Ferreira et al\\.",
      "year" : 2016
    }, {
      "title" : "Neuralreg: An end-to-end approach to referring expression generation",
      "author" : [ "Thiago Castro Ferreira", "Diego Moussallem", "Ákos Kádár", "Sander Wubben", "Emiel Krahmer" ],
      "venue" : null,
      "citeRegEx" : "Ferreira et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Ferreira et al\\.",
      "year" : 2018
    }, {
      "title" : "Advances in natural language generation: Generating varied outputs from semantic inputs",
      "author" : [ "Thiago Castro Ferreira" ],
      "venue" : null,
      "citeRegEx" : "Ferreira.,? \\Q2018\\E",
      "shortCiteRegEx" : "Ferreira.",
      "year" : 2018
    }, {
      "title" : "The effect of animacy on the choice of referring expression",
      "author" : [ "Kumiko Fukumura", "Roger PG van Gompel." ],
      "venue" : "26(10):1472–1504.",
      "citeRegEx" : "Fukumura and Gompel.,? 2011",
      "shortCiteRegEx" : "Fukumura and Gompel.",
      "year" : 2011
    }, {
      "title" : "Survey of the state of the art in natural language generation: Core tasks, applications and evaluation",
      "author" : [ "Albert Gatt", "Emiel Krahmer." ],
      "venue" : "Journal of Artificial Intelligence Research, 61:65–170.",
      "citeRegEx" : "Gatt and Krahmer.,? 2018",
      "shortCiteRegEx" : "Gatt and Krahmer.",
      "year" : 2018
    }, {
      "title" : "Udel: generating referring expressions guided by psycholinguistic findings",
      "author" : [ "Charles Greenbacker", "Kathleen McCoy." ],
      "venue" : "Proceedings of the 2009 Workshop on Language Generation and Summarisation, pages 101–102. Association for Computational Linguistics.",
      "citeRegEx" : "Greenbacker and McCoy.,? 2009a",
      "shortCiteRegEx" : "Greenbacker and McCoy.",
      "year" : 2009
    }, {
      "title" : "Feature selection for reference generation as informed by psycholinguistic research",
      "author" : [ "Charles F Greenbacker", "Kathleen F McCoy." ],
      "venue" : "Proceedings of the CogSci 2009 Workshop on Production of Referring Expressions (PRE-Cogsci 2009).",
      "citeRegEx" : "Greenbacker and McCoy.,? 2009b",
      "shortCiteRegEx" : "Greenbacker and McCoy.",
      "year" : 2009
    }, {
      "title" : "Centering: A framework for modeling the local coherence of discourse",
      "author" : [ "Barbara J Grosz", "Scott Weinstein", "Aravind K Joshi." ],
      "venue" : "21(2):203–225.",
      "citeRegEx" : "Grosz et al\\.,? 1995",
      "shortCiteRegEx" : "Grosz et al\\.",
      "year" : 1995
    }, {
      "title" : "Reference: interdisciplinary perspectives",
      "author" : [ "Jeanette K Gundel", "Nancy Hedberg." ],
      "venue" : "Oxford University Press.",
      "citeRegEx" : "Gundel and Hedberg.,? 2008",
      "shortCiteRegEx" : "Gundel and Hedberg.",
      "year" : 2008
    }, {
      "title" : "Cognitive status and the form of referring expressions in discourse",
      "author" : [ "Jeanette K Gundel", "Nancy Hedberg", "Ron Zacharski." ],
      "venue" : "pages 274–307.",
      "citeRegEx" : "Gundel et al\\.,? 1993",
      "shortCiteRegEx" : "Gundel et al\\.",
      "year" : 1993
    }, {
      "title" : "Junlg-msr: A machine learning approach of main subject reference selection with rule based improvement",
      "author" : [ "Samir Gupta", "Sivaji Bandopadhyay." ],
      "venue" : "Proceedings of the 2009 Workshop on Language Generation and Summarisation, pages 103–104. Association for Computational Linguistics.",
      "citeRegEx" : "Gupta and Bandopadhyay.,? 2009",
      "shortCiteRegEx" : "Gupta and Bandopadhyay.",
      "year" : 2009
    }, {
      "title" : "Cnts: Memorybased learning of generating repeated references",
      "author" : [ "Iris Hendrickx", "Walter Daelemans", "Kim Luyckx", "Roser Morante", "Vincent Van Asch." ],
      "venue" : "Proceedings of the Fifth International Natural Language Generation Conference, pages 194–195. Association for Computational Linguistics.",
      "citeRegEx" : "Hendrickx et al\\.,? 2008",
      "shortCiteRegEx" : "Hendrickx et al\\.",
      "year" : 2008
    }, {
      "title" : "Osu-2: Generating referring expressions with a maximum entropy classifier",
      "author" : [ "Emily Jamison", "Dennis Mehay." ],
      "venue" : "Proceedings of the Fifth International Natural Language Generation Conference, pages 196–197. Association for Computational Linguistics.",
      "citeRegEx" : "Jamison and Mehay.,? 2008",
      "shortCiteRegEx" : "Jamison and Mehay.",
      "year" : 2008
    }, {
      "title" : "Using discourse features for referring expression generation",
      "author" : [ "Emily Jamison" ],
      "venue" : null,
      "citeRegEx" : "Jamison.,? \\Q2008\\E",
      "shortCiteRegEx" : "Jamison.",
      "year" : 2008
    }, {
      "title" : "Referential choice: Predictability and its limits",
      "author" : [ "Andrej A Kibrik", "Mariya V Khudyakova", "Grigory B Dobrov", "Anastasia Linnik", "Dmitrij A Zalmanov." ],
      "venue" : "7:1429.",
      "citeRegEx" : "Kibrik et al\\.,? 2016",
      "shortCiteRegEx" : "Kibrik et al\\.",
      "year" : 2016
    }, {
      "title" : "Computational Generation of Referring Expressions: An",
      "author" : [ "Emiel Krahmer", "Kees van Deemter" ],
      "venue" : null,
      "citeRegEx" : "Krahmer and Deemter,? \\Q2019\\E",
      "shortCiteRegEx" : "Krahmer and Deemter",
      "year" : 2019
    }, {
      "title" : "Generating anaphoric expressions: pronoun or definite description",
      "author" : [ "Kathleen E McCoy", "Michael Strube" ],
      "venue" : null,
      "citeRegEx" : "McCoy and Strube.,? \\Q1999\\E",
      "shortCiteRegEx" : "McCoy and Strube.",
      "year" : 1999
    }, {
      "title" : "Comparative study of naive bayes, support vector machine and random forest classifiers in sentiment analysis of twitter feeds",
      "author" : [ "Anmol Nayak", "D Natarajan." ],
      "venue" : "Int. J. Adv. Stud. Comput. Sci. Eng, 5:14–17.",
      "citeRegEx" : "Nayak and Natarajan.,? 2016",
      "shortCiteRegEx" : "Nayak and Natarajan.",
      "year" : 2016
    }, {
      "title" : "WLV: A confidence-based machine learning method for the GREC-NEG’09 task",
      "author" : [ "Constantin Orăsan", "Iustin Dornescu." ],
      "venue" : "Proceedings of the 2009 Workshop on Language Generation and Summarisation (UCNLG+Sum 2009), pages 107–108, Suntec, Singapore, August. Association for Computational Linguistics.",
      "citeRegEx" : "Orăsan and Dornescu.,? 2009",
      "shortCiteRegEx" : "Orăsan and Dornescu.",
      "year" : 2009
    }, {
      "title" : "Towards robust linguistic analysis using ontonotes",
      "author" : [ "Sameer Pradhan", "Alessandro Moschitti", "Nianwen Xue", "Hwee Tou Ng", "Anders Björkelund", "Olga Uryupina", "Yuchen Zhang", "Zhi Zhong." ],
      "venue" : "Proceedings of the Seventeenth Conference on Computational Natural Language Learning, pages 143–152.",
      "citeRegEx" : "Pradhan et al\\.,? 2013",
      "shortCiteRegEx" : "Pradhan et al\\.",
      "year" : 2013
    }, {
      "title" : "Information status distinctions and referring expressions: An empirical study of references to people in news summaries",
      "author" : [ "Advaith Siddharthan", "Ani Nenkova", "Kathleen McKeown." ],
      "venue" : "Computational Linguistics, 37(4):811–842.",
      "citeRegEx" : "Siddharthan et al\\.,? 2011",
      "shortCiteRegEx" : "Siddharthan et al\\.",
      "year" : 2011
    }, {
      "title" : "Computational approaches to the production of referring expressions: Dialog changes (almost) everything",
      "author" : [ "Amanda J Stent." ],
      "venue" : "PRE-CogSci Workshop.",
      "citeRegEx" : "Stent.,? 2011",
      "shortCiteRegEx" : "Stent.",
      "year" : 2011
    }, {
      "title" : "ranger: A fast implementation of random forests for high dimensional data in c++ and r",
      "author" : [ "Marvin N Wright", "Andreas Ziegler." ],
      "venue" : "arXiv preprint arXiv:1508.04409.",
      "citeRegEx" : "Wright and Ziegler.,? 2015",
      "shortCiteRegEx" : "Wright and Ziegler.",
      "year" : 2015
    }, {
      "title" : "Combining referring expression generation and surface realization: A corpusbased investigation of architectures",
      "author" : [ "Sina Zarrieß", "Jonas Kuhn." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1547–1557.",
      "citeRegEx" : "Zarrieß and Kuhn.,? 2013",
      "shortCiteRegEx" : "Zarrieß and Kuhn.",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 0,
      "context" : "Prominence has been argued to be influenced by various factors such as recency and frequency of mention (Ariel, 1990), grammatical function (Brennan, 1995), animacy (Fukumura and van Gompel, 2011), distance (McCoy and Strube, 1999) and competition between the referents (Arnold and Griffin, 2007).",
      "startOffset" : 104,
      "endOffset" : 117
    }, {
      "referenceID" : 6,
      "context" : "Prominence has been argued to be influenced by various factors such as recency and frequency of mention (Ariel, 1990), grammatical function (Brennan, 1995), animacy (Fukumura and van Gompel, 2011), distance (McCoy and Strube, 1999) and competition between the referents (Arnold and Griffin, 2007).",
      "startOffset" : 140,
      "endOffset" : 155
    }, {
      "referenceID" : 27,
      "context" : "Prominence has been argued to be influenced by various factors such as recency and frequency of mention (Ariel, 1990), grammatical function (Brennan, 1995), animacy (Fukumura and van Gompel, 2011), distance (McCoy and Strube, 1999) and competition between the referents (Arnold and Griffin, 2007).",
      "startOffset" : 207,
      "endOffset" : 231
    }, {
      "referenceID" : 1,
      "context" : "Prominence has been argued to be influenced by various factors such as recency and frequency of mention (Ariel, 1990), grammatical function (Brennan, 1995), animacy (Fukumura and van Gompel, 2011), distance (McCoy and Strube, 1999) and competition between the referents (Arnold and Griffin, 2007).",
      "startOffset" : 270,
      "endOffset" : 296
    }, {
      "referenceID" : 15,
      "context" : "Reference production is also one of the most-studied topics in Natural Language Generation (Gatt and Krahmer, 2018), where it is known as Referring Expression Generation (Krahmer and van Deemter, 2019).",
      "startOffset" : 91,
      "endOffset" : 115
    }, {
      "referenceID" : 2,
      "context" : "• We selected all SRF algorithms submitted to GREC (Belz et al., 2010) and extracted the feature sets used by these algorithms.",
      "startOffset" : 51,
      "endOffset" : 70
    }, {
      "referenceID" : 21,
      "context" : "Of these feature sets, we excluded the JUNLG set (Gupta and Bandopadhyay, 2009) because their study was rule-based, and the WLV feature set (Orăsan and Dornescu, 2009) because we were not able to interpret all their features.",
      "startOffset" : 49,
      "endOffset" : 79
    }, {
      "referenceID" : 29,
      "context" : "Of these feature sets, we excluded the JUNLG set (Gupta and Bandopadhyay, 2009) because their study was rule-based, and the WLV feature set (Orăsan and Dornescu, 2009) because we were not able to interpret all their features.",
      "startOffset" : 140,
      "endOffset" : 167
    }, {
      "referenceID" : 34,
      "context" : "Of the selected results, we excluded various papers because they did not meet the criteria defined above (Zarrieß and Kuhn, 2013; Siddharthan et al., 2011; Stent, 2011; Nenkova, ; Ferreira and Paraboni, 2017).",
      "startOffset" : 105,
      "endOffset" : 208
    }, {
      "referenceID" : 31,
      "context" : "Of the selected results, we excluded various papers because they did not meet the criteria defined above (Zarrieß and Kuhn, 2013; Siddharthan et al., 2011; Stent, 2011; Nenkova, ; Ferreira and Paraboni, 2017).",
      "startOffset" : 105,
      "endOffset" : 208
    }, {
      "referenceID" : 32,
      "context" : "Of the selected results, we excluded various papers because they did not meet the criteria defined above (Zarrieß and Kuhn, 2013; Siddharthan et al., 2011; Stent, 2011; Nenkova, ; Ferreira and Paraboni, 2017).",
      "startOffset" : 105,
      "endOffset" : 208
    }, {
      "referenceID" : 10,
      "context" : "Of the selected results, we excluded various papers because they did not meet the criteria defined above (Zarrieß and Kuhn, 2013; Siddharthan et al., 2011; Stent, 2011; Nenkova, ; Ferreira and Paraboni, 2017).",
      "startOffset" : 105,
      "endOffset" : 208
    }, {
      "referenceID" : 5,
      "context" : "is-g (Bohnet, 2008): • grammatical role (gm) • distance to the last mention (dis pr nmrc) • count of the referring expressions (wch ment) • type of the previous mention (pr typ) • whether or not the current and the last mention are in the same sentence (diff sent)",
      "startOffset" : 5,
      "endOffset" : 19
    }, {
      "referenceID" : 23,
      "context" : "osu (Jamison and Mehay, 2008): • whether or not the current entity has a competitor in the whole text, the text preceding the mention, or between the current and the previous mention (consecutively: osu cmpet txt, osu prv cmpt, osu cmpet btwn) • *string similarity measures between the title and the current mention • discretized order of mentions (order fctr) • discretized distance in words to the previous mention (w dist fct) • discretized distance in sentence boundaries (d dist fct) • whether or not the expression is mentioned for the first time (old new) • grammatical role (gm) • semantic type (anim)",
      "startOffset" : 4,
      "endOffset" : 29
    }, {
      "referenceID" : 16,
      "context" : "udel (Greenbacker and McCoy, 2009a): • grammatical role of the current and the three most current mentions (gm prv, gm prv1, gm prv2, gm prv3) • whether or not the last mention was in the subject position (prv gm subj) • whether or not there are intervening referents between the current and the previous mention (interv ref) • *distance to the preceding non-referring occurrences of an entity name • whether or not the expression is immediately followed the words and, but,then, or if it appeared between a comma and the word and (flw and, flw but, flw then, btw comma and) •Whether or not the distance between the two mentions is more than two sentences (lng short dist) • whether or not there are interfering antecedents in the current sentence and the text since that last reference (interv ent sent) • distance between the mentions (dst prv) • entity and mention number (ent num, sent num) • sentence ID (sent num) and reference ID • whether or not the last mention is in subject position (prv gm subj), whether the mention is the subject of the current and the two previous sentences (subj curS, subj prevS, subj 2prvS)",
      "startOffset" : 5,
      "endOffset" : 35
    }, {
      "referenceID" : 22,
      "context" : "cnts (Hendrickx et al., 2008): • sentence number (sent num) • NP number (np num) • Whether or not the mention appears in the first sentence (first sent) • Grammatical role (gm) • semantic category (anim) • 3 words left and right of the entity (tri w before, bi w before, uni w before, tri w aft, bi w aft,",
      "startOffset" : 5,
      "endOffset" : 29
    }, {
      "referenceID" : 9,
      "context" : "icsi (Favre and Bohnet, 2009): • word unigram and bigram before and after the expression (bi w before, uni w before, bi w aft, uni w aft) • morphology of the previous and next words (morph before, morph after) • punctuation type before and after the referring expression (punct before, punct after) • grammatical role (gm) • *syntactic category • semantic category (anim) • whether or not the previous expression is about the same entity (same prv) • number of occurrence of the entity since the beginning of the text (ref in chain) • number of occurrence of the entity since the last change of entity (next in chain) • beginning of paragraph indicator (begin sent par)",
      "startOffset" : 5,
      "endOffset" : 29
    }, {
      "referenceID" : 8,
      "context" : "ferreira (Ferreira et al., 2016): • grammatical role (gm) • whether or not the referent is new at the level of text, paragraph and sentence (new in text, new in par, new in sent) • number of words between the current and the previous mention (word distance)",
      "startOffset" : 9,
      "endOffset" : 32
    }, {
      "referenceID" : 25,
      "context" : "kibrik (Kibrik et al., 2016): • animacy (animacy) • gender (gender) • *person • number (plurality) • protagonism (protagonism1) • ordinal number of referent mention in the referential chain (ref in chain) • phrase type and grammatical role of the current and the previous mention(phrase ty, gm, prev phrase ty, prev gm) • referential form of the previous mention (prev ref ty) • length of the previous mention (prev ref len) • distance in words, markables, *EDU, *RhD, sentence and paragraphs to the previous mention (dist prev, dist markable, dist sent, dist par) • *number of markables in chain from the anaphor back to the nearest full NP antecedent In this section, we explained the features of each feature set.",
      "startOffset" : 7,
      "endOffset" : 28
    }, {
      "referenceID" : 8,
      "context" : "In their SRF study, (Ferreira et al., 2016) applied their feature set (ferreira) to the VaREG corpus to predict either of these forms: pronouns, descriptions, proper names, null forms and demonstratives.",
      "startOffset" : 20,
      "endOffset" : 43
    }, {
      "referenceID" : 30,
      "context" : "In this study, we decided to use the English newswire data (from the Wall Street Journal) available in OntoNotes (Pradhan et al., 2013).",
      "startOffset" : 113,
      "endOffset" : 135
    }, {
      "referenceID" : 28,
      "context" : "results achieved from the myriad of decision trees it generates while training (Nayak and Natarajan, 2016; Biau, 2012).",
      "startOffset" : 79,
      "endOffset" : 118
    }, {
      "referenceID" : 3,
      "context" : "results achieved from the myriad of decision trees it generates while training (Nayak and Natarajan, 2016; Biau, 2012).",
      "startOffset" : 79,
      "endOffset" : 118
    }, {
      "referenceID" : 33,
      "context" : "To implement the Random Forests algorithm, we usedranger (Wright and Ziegler, 2015), which is a fast implementation of Random Forests in R.",
      "startOffset" : 57,
      "endOffset" : 83
    }, {
      "referenceID" : 4,
      "context" : "We used the R package mlr(Bischl et al., 2016) for the implementation of the FFS algorithm.",
      "startOffset" : 25,
      "endOffset" : 46
    }, {
      "referenceID" : 6,
      "context" : "• Grammatical role: Linguistic studies tend to emphasize the grammatical role of the antecedent as well the current mention (Brennan, 1995; Grosz et al., 1995).",
      "startOffset" : 124,
      "endOffset" : 159
    }, {
      "referenceID" : 18,
      "context" : "• Grammatical role: Linguistic studies tend to emphasize the grammatical role of the antecedent as well the current mention (Brennan, 1995; Grosz et al., 1995).",
      "startOffset" : 124,
      "endOffset" : 159
    }, {
      "referenceID" : 19,
      "context" : "• Form of the previous mention: In this case, our findings match those in the linguistic tradition (Gundel and Hedberg, 2008).",
      "startOffset" : 99,
      "endOffset" : 125
    }, {
      "referenceID" : 20,
      "context" : "Givenness has always been one of the main factors discussed in the linguistic tradition (Gundel et al., 1993) We find plenty of support for this idea, but our findings suggest that the most important aspect of givenness from SRF perspective is whether or not a referent has been mentioned in the same sentence as the current mention (as opposed to the same discourse as a whole).",
      "startOffset" : 88,
      "endOffset" : 109
    } ],
    "year" : 2020,
    "abstractText" : "This paper reports on a structured evaluation of feature-based machine learning algorithms for selecting the form of a referring expression in discourse context. Based on this evaluation and a number of follow-up studies (e.g. using ablation), we propose a “consensus” feature set which we compare with insights in the linguistic literature.",
    "creator" : "LaTeX with hyperref"
  }
}