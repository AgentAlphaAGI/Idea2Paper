{
  "name" : "COLING_2020_29_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Lexical Semantic Analysis of Meaning Representation",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Several symbolic meaning representations (MRs) support human annotation of text with broad coverage (Abend and Rappoport, 2017; Oepen et al., 2019). To date, it is still not completely clear what semantic content they all encode, and how it compares to the content represented by the others. It therefore behooves us to develop a firm linguistic understanding of MRs. In particular: are they merely a coarsening and rearranging of syntactic information, such as encoded in Universal Dependencies (Nivre et al., 2016, UD)? To what extent do they take lexical semantic properties into account? And what does this suggest about the potential for exploiting simpler or better-resourced linguistic representations for improved MR parsing? Intuitively, we ask whether the following equation holds:\nsentence-level meaning representation ?= syntax + lexical semantics\nTo address this question, we examine UCCA, a document-level MR often used for sentence-level semantics (see §2.1). Hershcovich et al. (2019a) began to examine the relation of UCCA to syntax, contributing a corpus with gold standard UD and UCCA parses, heuristically aligning them, and quantifying the correlations between syntactic and semantic labels. Conversely, Hershcovich et al. (2018) provided some initial evidence that other MRs can be brought to bear on the UCCA parsing task via multitask learning, but left the details of the relationship between representations to latent (and opaque) parameters of neural models.\nIn this paper, we aim to close the gap between the two previous investigations by (1) building an interpretable rule-based system to convert from shallower representations (syntax and lexical semantic units/tags) into UCCA, forcing us to be linguistically precise about what UCCA captures and how it “decomposes”; and (2) training top-performing supervised parsers in a delexicalized setting with only syntactic and lexical semantics features, as a data-driven mapping corroborating the rule-based approach.\nWe perform our analysis on the Reviews section of the English Web Treebank (Bies et al., 2012), which has been manually annotated with UD and UCCA; and STREUSLE for lexical semantics (§2). Although at present we only have the necessary evaluation data for English, the linguistic representations we use have (like UCCA) been applied to multiple languages (§2). Our approach can thus be applied cross-linguistically with minimal adaptation. Our specific contributions are:\n• Developing rule-based and supervised UCCA parsers based only on syntax and lexical semantics.\n• Finding similarities and differences between the frameworks by a linguistically motivated analysis.\nOur conversion, parsing and analysis code will be publicly available upon publication."
    }, {
      "heading" : "2 Representations",
      "text" : "The increasing interest in semantic representation and parsing, and the partial overlap in content between the different frameworks (Oepen et al., 2019), is a main motivation for our inquiry as to content differences between UD and STREUSLE, and UCCA. We expect our inquiry to be relevant to other schemes, in developing a general methodology, as well as in the insights gathered. For example, UD also serves as the backbone of the DeComp scheme (White et al., 2016), and so information as to its semantic content is important there as well. Argument structural phenomena are at the heart of many MRs, which provide further motivation for empirical studies to the extent lexical semantics and syntax can encode them."
    }, {
      "heading" : "2.1 Universal Conceptual Cognitive Annotation",
      "text" : "Universal Conceptual Cognitive Annotation (Abend and Rappoport, 2013) targets a level of semantic granularity that abstracts away from syntactic paraphrases in a typologically-motivated, cross-linguistic fashion (Sulem et al., 2015), building on Basic Linguistic Theory (Dixon, 2010 2012), an influential framework for linguistic description. The scheme does not rely on language-specific resources, and sets a low threshold for annotator training. Beyond syntactic paraphrases, UCCA further encodes coarsegrained lexical semantic properties such as the aspectual distinction between states and processes (depending on whether an event evolves in time or not).\nUCCA has been applied to text simplification (Sulem et al., 2018b), and text-to-text generation evaluation (Birch et al., 2016; Choshen and Abend, 2018; Sulem et al., 2018a). UCCA corpora are available for English, French and German, and pilot studies were conducted on a few more languages. UCCA parsing has been targeted in two shared tasks (Hershcovich et al., 2019b; Oepen et al., 2019). Here we summarize the organizing principles and main semantic distinctions in UCCA, but see the extensive annotation manual for further details.1\nIn UCCA, an analysis of a text passage is a DAG (directed acyclic graph) over semantic elements called units. A unit corresponds to (is anchored by) one or more tokens, labeled with one or more semantic categories in relation to a parent unit.2 The principal kind of unit is a scene denoting a situation mentioned in the sentence, typically involving a scene-evoking predicate, participants, and (perhaps) modifiers. Each predicate is labeled with the category State (S) or Process (P). Figure 1 contains three scenes: one anchored by the Process took; one anchored by the Process a repair; and one anchored by the possessive pronoun our, which indicates a stative possession relation. A Participant (A) of a scene is typically an entity or location involved. Adverbials (D) modify scenes with respect to properties like negation, modality, causativity, direction, manner, etc., which do not constitute an independent situation or entity. Temporal modifiers are labeled Time (T).\nScenes in UCCA can relate to one another in one of three ways. A Scene can serve as a Participant within a larger scene; a Scene can serve to elaborate on a Participant within a Scene (typically relative clauses); other relations between scenes are called parallel linkage: a unit consists of Parallel Scenes (H) and possibly Linkers (L) describing how they are related. This is seen at the top level of figure 1, where the taking and repair scenes are parallel and the purposive for is a linker.\n1https://github.com/UniversalConceptualCognitiveAnnotation/docs/blob/master/guidelines.pdf 2UCCA also supports implicit units which do not correspond to any tokens (Cui and Hershcovich, 2020), but these are\nexcluded from parsing evaluation and we ignore them for purposes of this paper.\n2\nWe took our vehicle in for a repair to the air conditioning .\nUCCA abbreviations: H = parallel scene, L = scene linker, P = process (dynamic event), S = state, A = scene participant, D = scene adverbial, E = non-scene elaborator, C = center (non-scene head), R = relator, F = functional element. The STREUSLE and UD part is adapted from Liu et al. (2020).\nOther categories only apply to units with no predicate: a semantic head—the Center (C); modifiers of Quantity (Q); and other modifiers, called Elaborators (E). An Elaborator may itself be a scene, as in our vehicle, where the scene of possession elaborates on the vehicle entity. Similarly, blue vehicles would be analyzed with a stative scene of blueness that elaborates on the vehicles in question.\nApart from the main semantic content of scenes and participants, UCCA provides the categories: Relator (R) for grammatical markers expressing how a unit relates to its parent unit—in English, these are mainly prepositions and the possessive ’s; Function (F) for other grammatical markers with minimal semantic content, such as tense auxiliaries, light verbs, and articles. Other categories are used for expressing coordination and for expressions expressing speaker perspective outside the propositional structure of the sentence. Semantically opaque multi-word expressions (e.g., air conditioning in figure 1) are called unanalyzable units, and are not analyzed internally.\nUCCA distinguishes primary edges that always form a tree, and remote edges that together form a DAG, and are used to express reentrancies (multiple parents), such as the dotted edge from the possession scene unit to vehicle."
    }, {
      "heading" : "2.2 Universal Dependencies",
      "text" : "UD is a syntactic dependency scheme used in many languages, aiming for cross-linguistically consistent and coarse-grained treebank annotation. Formally, UD uses bi-lexical trees, with edge labels representing syntactic relations. An example UD tree appears at the bottom of figure 1, below fine-grained POS tags."
    }, {
      "heading" : "2.3 STREUSLE",
      "text" : "STREUSLE (Supersense-Tagged Repository of English with a Unified Semantics for Lexical Expressions) is a corpus annotated comprehensively for several forms of lexical semantics (Schneider and Smith, 2015; Schneider et al., 2018): all kinds of multi-word expressions (MWEs) are annotated, giving each sentence a lexical semantic segmentation.3 Syntactic and semantic tags are then applied to individual units (single- and multi-word). The semantic tags are supersenses for noun, verb, and prepositional/possessive units. Preposition supersenses include two tiers of annotation: scene role labels represent the semantic role of the prepositional phrase marked by the preposition, and functional role labels represent the lexical contribution of the preposition in itself.\nThe lexcat annotations (syntactic category of lexical unit) is a slight extension to the Universal POS tagset, adding categories for certain MWE subtypes, such as light verb constructions, following Walsh\n3STREUSLE distinguishes strong MWEs, which are opaque (noncompositional) or idiosyncratic in meaning, and weak MWEs, which represent looser collocations, that are nevertheless semantically compositional, like “highly recommended”.\net al. (2018) and idiomatic PPs; it also distinguishes possessive pronouns, the possessive clitic ’s, and discourse expressions.4 The MWE, lexcat, and supersense layers are illustrated in figure 1.\nSTREUSLE itself is limited to English, but many of its component annotations have been applied to other languages: verbal multi-word expressions (Ramisch et al., 2018), noun and verb supersenses (Picca et al., 2008; Qiu et al., 2011; Schneider et al., 2013; Martínez Alonso et al., 2015; Hellwig, 2017), and preposition supersenses (Hwang et al., 2017; Zhu et al., 2019).\nRecently, Liu et al. (2020) presented a comprehensive lexical semantic tagger for STREUSLE, which accurately predicts the comprehensive lexical semantic analysis from text, and is freely available.\nPrange et al. (2019) proposed several procedures for integrating STREUSLE supersenses directly into UCCA, refining its coarse-grained categories with preposition supersenses. They also showed that enriching a supervised UCCA parser with preposition supersense features from STREUSLE—and, even more so, training a parser to predict supersenses jointly with UCCA—improves parsing performance, showing that the two frameworks are overlapping but complementary."
    }, {
      "heading" : "2.4 Related Representations",
      "text" : "The above annotation schemes define finite inventories of coarse-grained categories to avoid depending on language-specific lexical resources, and thus can in principle be applied to any language. This fact distinguishes UCCA and STREUSLE from finer-grained sentence-structural representations like FrameNet (Baker et al., 1998) and the Abstract Meaning Representation (Banarescu et al., 2013), which relies on PropBank (Palmer et al., 2005). The Prague Dependency Treebank tectogrammatical layer (Böhmová et al., 2003) uses few lexicon-free roles, but its semantics is determined by a valency lexicon.\nParallel Meaning Bank (Abzianidze et al., 2017) uses lexicon-free5 VerbNet (Schuler, 2005) semantic roles. The STREUSLE tagset for preposition supersenses generalizes VerbNet’s role set, to cover noncore arguments/adjuncts of verbs, as well as prepositional complements of nouns and adjectives.\nUniversal Decompositional Semantics (DeComp) takes a different approach, defining semantic roles as bundles of lexicon-free features. Cross-linguistic applicability in this case is delegated to the parser, which parses sentences in other languages to their corresponding English semantics (Zhang et al., 2018)."
    }, {
      "heading" : "3 Rule-based UCCA Parsing from Lexical Semantics",
      "text" : "In this section, we describe a system to produce UCCA analyses for text given UD syntactic graphs and STREUSLE lexical semantic annotation. The UD-to-UCCA converter of Hershcovich et al. (2019a) was used for assimilating UD and UCCA graphs, to allow comparing their content. It attached nodes according to preorder traversal of the original dependency graph, keeping the UD dependency relations. The remaining differences are cases that could not be disambiguated based on UD alone.\nWe extend the converter to account for these differences, integrating lexical semantics into the process, and additionally assigning UCCA categories to edges. We normalize deterministic differences between the structures to abstract away from formal differences, as we are interested in a comparison in terms of content and semantic distinctions. An analysis of the converter’s successes and failures (§6) will, in turn, reveal the similarities and differences between the schemes.6\nSTREUSLE multi-word expressions and UCCA unanalyzable units. Based on the MWE annotation from STREUSLE, we group together text tokens to single unanalyzable semantic units when they are annotated as MWEs of certain types.7 For example, in the sentence\nThis is one of the worst places I have stayed, we cut out[sic] stay short and went to the Mulberry. (reviews-023620-0001),\n4STREUSLE tagset documentation: https://github.com/nert-nlp/streusle/blob/master/CONLLULEX.md 5While the lexical items comprising a linguistic utterance are naturally essential to its meaning, and therefore influence its semantic representation, by lexicon-free we mean the ontology and label set of the representation are not tied to a lexicon or a particular language.\n6A detailed description of the rules is found in appendix A. 7We do not use weak MWEs, as UCCA does not encode them.\ncut. . . short is an unanalyzable unit according to the gold UCCA annotation, but the syntactic relation between cut and short, namely xcomp, does not indicate that; only a small proportion of xcomps, in general, correspond to UCCA unanalyzable units (Hershcovich et al., 2019a). In STREUSLE, however, cut. . . short is annotated as a strong MWE, whose lexcat is V.VID (idiomatic verb). Our rules create an unanalyzable unit covering this phrase, which matches the gold UCCA annotation in this case. The same is true for Blue cross8 in figure 2.\nSTREUSLE supersenses and UCCA scene-evoking phrases. We identify main relations (sceneevoking phrases) using rules based on a combination of syntactic and lexical semantic features. These provide a more fine-grained distinction between otherwise semantically underspecified syntactic relations. For example, the noun reversal in figure 2 is marked as a main relation (and eventually annotated as a P), since its supersense of N.EVENT informs us that this is a scene-evoking noun.\nSTREUSLE lexical categories and UCCA edge categories. We assign categories to edges based on the marked main relations: the relations themselves are labeled P or S depending on lexical categories and supersenses. Functional modifiers, discourse modifiers, and other modifiers are labeled E or D depending on whether they modify a non-scene or scene unit, respectively. Verbal arguments and modifiers of scene-evoking non-verbal phrases are labeled A.\nSecondary verbs constructions. This construction is treated differently in UD/STREUSLE and in UCCA: for example, in the phrase “members who won’t stop talking”, according to UD the verb “stop” is the head and “talking” is a dependent. However, in UCCA “stop” is D and “talking” is the main relation, labeled P. To normalize the treatment of secondary verb constructions, they are marked and eventually restructured such that the main verb is labeled D and the secondary verb as the main relation.\nCoordination. According to the marking of scene-evoking phrases, coordination between scene units is labeled L (Linker), and coordination between non-scene units is labeled N (Connector).\nLexical heads. Scene units are labeled H, and heads of non-scene units are labeled C."
    }, {
      "heading" : "4 Delexicalized Supervised UCCA Parsing with Lexical Semantic Features",
      "text" : "Previous work tackled the UCCA parsing task using supervised learning. In order to complement and validate the analysis based on the rule-based converter, we compare its findings to a delexicalized supervised parser, that can be seen as inducing a converter from data. By removing all word and lemma\n8Short for Blue Cross Blue Shield, a well-known health insurance organization in the United States.\nfeatures from these parsers, and adding features based on UD and STREUSLE instead, we obtain supervised “converters”, which can be used for data-driven analysis and complement the manual rules."
    }, {
      "heading" : "4.1 TUPA",
      "text" : "TUPA (Hershcovich et al., 2017), the first UCCA parser presented, is based on a transition-based algorithm with a neural network transition classifier, using a BiLSTM for encoding input representation, with word, lemma, and syntactic features embedded as real-valued features.\nWe add the supersense and lexcat from STREUSLE as embedding inputs to the TUPA BiLSTM (concatenated with existing inputs). For prepositions, we add both the scene role and functional role (see §2)."
    }, {
      "heading" : "4.2 HIT-SCIR Parser",
      "text" : "The HIT-SCIR (Che et al., 2019) parser is a transition-based parser for several MR frameworks, including UCCA. It achieved the highest average score in the CoNLL 2019 shared task (Oepen et al., 2019). It uses stack LSTMs (Dyer et al., 2015) to represent the stack, the buffer, and the sequence of actions. These representations are updated after every transition.\nWhile Che et al. (2019) fine-tuned BERT (Devlin et al., 2019) for contextualized word representation, our delexicalized version replaces BERT with embeddings for UD and STREUSLE features, taken from the BIO-like encoding included in the STREUSLE dataset: POS tag, dependency relation, supersenses (scene role and functional role; see §2), the lexical category of the word or the MWE that the word is part of, and the BIO tag. These six embeddings are concatenated to form one representation of each word.\n5 Experiments\n5.1 Experimental Setup\nData. We use the Reviews section from UD 2.6 English_EWT (Zeman et al., 2019), with lexical semantic annotations from STREUSLE 4.4 (Schneider et al., 2017),9 and with UCCA graphs from UCCA_EnglishEWT v1.0.1 (Hershcovich et al., 2019a).10 We use the\nstandard train/development split for this dataset, and do not use the test split to avoid over-analyzing it, although all datasets contain annotations for it too. The data statistics are listed in table 1.\nRule-based converters. We evaluate the rule-based converter (§3), as well as the basic converter from Hershcovich et al. (2019a), using majority-based UD-to-UCCA category mapping (based on the most common category in the training set). That converter is oblivious to lexical semantics, using syntax only.\nParsers. We train TUPA v1.3 and the HIT-SCIR CoNLL 2019 parser using gold-standard features from UD and STREUSLE, for equal conditions with the rule-based converters. Default hyperparameters are used. For both parsers, categorical features are added as 20-dimensional randomly initialized embeddings, and scores are averaged across 3 models trained with different random initializations.\nEvaluation. We use standard UCCA evaluation, matching edges by the terminal yields of their endpoint units.11 Labeled precision, recall and F1-score consider the edge categories when matching edges. Where an edge has multiple categories, each of them is considered separately."
    }, {
      "heading" : "5.2 Results",
      "text" : "Table 2 shows the scores for the different parsing approaches. All scores are evaluated on the EWT Reviews development set. For comparison with parsers that have access to full word and lemma features, we also show the TUPA development set results from Hershcovich et al. (2019a), who used syntactic\n9https://github.com/nert-nlp/streusle 10https://github.com/UniversalConceptualCognitiveAnnotation/UCCA_English-EWT 11The terminal yield of a unit is defined based on the graph’s primary edges only, as standard in UCCA evaluation.\nfeatures from the gold UD annotation and GloVe (Pennington et al., 2014) word embeddings;12 and the HIT-SCIR parser trained in the original setting, with BERT embeddings (and no syntactic features).\nWhen gold standard UD and STREUSLE are available, rules based on lexical semantics fully close the gap between the syntax-based converter and the supervised approach with word information, reaching the primary labeled F1 of 71.7%, which is the same as TUPA with word features. However, many errors remain in both approaches, which we can analyze to investigate the frameworks.\nTable 3 presents the confusion matrix of categories between the rule-based converter’s output and gold-standard UCCA, in the EWT Reviews development set. The delexicalized parsers’ confusion matrix (included in appendix C) is similar. For multiple UCCA units with the same terminal yield (i.e., units with a single nonremote child), we take the top category only, to avoid double-counting.\nWhile the development set confusion matrix is shown here, we consulted the training set iteratively while developing the rules, so many of the recurring issues that would show up as prominent confusions have already been addressed.13"
    }, {
      "heading" : "6 Analysis",
      "text" : "We proceed with an extensive error analysis of the rule-based converter, to point out its strong points and delineate the divergences that still remain, which we stipulate constitute content differences between UCCA and the combination of syntax and lexical semantics from UD and STREUSLE. Gold standard annotation in each frameworks, as well as the rule-based converter’s predictions, are exemplified in figure 3."
    }, {
      "heading" : "6.1 High Match—Converging Analyses",
      "text" : "Participants. As are recovered with high precision and recall. This is generally expected as most syntactic subjects and objects, as well as some obliques and even clauses signify scene participants. Where syntax and semantics diverge, STREUSLE supersenses can rule out unlikely candidates. The most common sources of missed As are structural errors, i.e., incorrect scene structures, overly flat units containing more than the referential words, or misinterpreted noun compounds (see §6.3 below).\nFunction words. As evident in table 3, Function words (F) are accurately predicted. The distinction between words that contribute to the semantic meaning and those that do not is preserved between STREUSLE and UCCA, except for some cases—mainly infinitive “to”.\nLinkers. Linkers (L) are also relatively easy for the converter: they are prototypically instantiated by syntactic co- and subordinators. To the extent that these are considered adpositional by STREUSLE, their supersense helps disambiguate between inter-scene linkage and Connectors (N) of non-scenes."
    }, {
      "heading" : "6.2 Partial Match—Inferrable by Combining Syntax and Lexical Semantics",
      "text" : "Time (T) and Quantifier (Q) expressions frequently coincide with certain syntactic categories such as adverbs and prepositions, and can typically be identified from corresponding supersenses, if available.\n12Parsing from gold features is by no means a realistic scenario, but we give the scores as a reference for the converters. 13Full reports of development set outputs are included in the supplementary material.\nThe converter tends to err on the conservative side, falling back to Adverbials (D) and Elaborators (E) when it cannot find sufficient explicit semantic evidence."
    }, {
      "heading" : "6.3 Low Match—Divergences or Insufficient Information",
      "text" : "Noun compound interpretation. Lexical composition in noun compounds evokes various forms of event structures, which are underspecified by the meaning of the constituent words (Shwartz and Dagan, 2019). While often compounding is used for Elaboration, as in [E tap] [C water], it may be the other way around, as in [C moving] [E experience] (referring to the act of relocating, which entails placing “moving” as the C). The modifier may also be a Participant in the scene evoked by the head, as in [A road] [P construction]. This is partially encoded in STREUSLE, as the fact that “construction” has the N.EVENT supersense indicates that it is scene-evoking, but it still does not reveal the relation to “road”. Indeed, “experience” is also N.EVENT, but its relation to “moving” is different.\nAdverbs and linkage. While many syntactic adverbs are semantically Linkers (“well”, “though”), neither UD nor STREUSLE distinguish them from Adverbials (“really”, “possibly”) and other uses. Some adverbs, like “so”, can serve either roles (see figure 3), a distinction that is only made in UCCA.\nCenters. Centers (C) are often unaligned due to the different notions of multi-word expressions in STREUSLE and UCCA. For example, “tap water” is considered a strong MWE in STREUSLE, but is internally analyzed (with “water” being the Center) in UCCA (see figure 3), leading to an unmatched C."
    }, {
      "heading" : "6.3.1 Scene-evokers",
      "text" : "While the concept of scenes is central to UCCA, correctly identifying scene-evoking words is one of the more difficult tasks for our converter. “Scene-ness” clearly goes beyond syntax (not all verbs evoke scenes and scenes can be evoked by a wide range of POS) and STREUSLE supersenses in isolation are often too coarse to resolve the question whether a given word evokes a scene and, if so, whether it is a Process (P) or a State (S). The former decision is generally somewhat easier for the converter (Recall of scene-evokers: 71.3%) than distinguishing between P (Recall: 69.1%) and S (64.0%). Below we examine a few recurring phenomena involving scenes.\nScene-evoking nouns. STREUSLE underspecifies whether nouns evoke scenes. For example, “menu” and “question” both have the N.COMMUNICATION supersense in STREUSLE, but “menu” does not evoke a scene, while “question” does.\nRelational nouns. A special case of scene-evoking nouns are relational nouns (Newell and Cheung, 2018; Meyers et al., 2004), which both refer to an entity and evoke a scene in which the entity generally or habitually participates.14 These units have two categories in UCCA, either A|P or A|S. The converter relies here on a combination of N.PERSON or N.GROUP supersenses and lexical lists. However, their scene-ness is often not recognized and they are confused with regular Participants or Centers.\nScene-evoking adjectives. Inspecting the high-frequency confusions, adjectives stand out as persistent error inducers. Different classes of adjectives are handled differently in UCCA: e.g., while most adjectives are scene-evoking, pertainyms (academic), inherent-composition modifiers (sugary), and quantity modifiers (many) are not. Some adjectives are ambiguous: a legal practice may refer to a behavior that is legal as opposed to illegal, in which case it should be scene-evoking, or to a law office, in which case it should not. Enriching STREUSLE with supersenses for adjectives (Tsvetkov et al., 2014) might be fruitful for such distinctions. Even with lexical disambiguation, the scene attachment of the adjective may be ambiguous: e.g. a good chef probably means a chef who cooks well, so good should be an Adverbial in the scene evoked by chef—in contrast with a tall chef, where tall is not part of the cooking scene and instead should evoke a State. Predicative adjectives, and adjective modifiers in predicative NPs, are another source of difficulty, especially when they occur in fragments: sometimes the adjective is annotated as evoking the main scene, and sometimes not. Determining this requires making various semantic distinctions, which are not fully represented in STREUSLE."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We presented an extensive analysis of the similarities and differences between STREUSLE and UCCA on the EWT Reviews corpus, assisted by two complementary methods: manual rule-based conversion, and delexicalized parsing. Both approaches reached similar results, showing that the conversion between the frameworks can be accurate, while also revealing important divergences, namely distinctions made in UCCA but not in STREUSLE: semantic relation between nouns in compounds, adverbial and linkage usage of adverbs, and the scene-evoking status of nouns, possessives and adjectives, among others.\nEnriching supervised parsers with features from lexical semantics improves parsing performance when using gold input features. While this paper focuses on analysis, future work will investigate using predicted features with a UD parser and STREUSLE tagger (Liu et al., 2020), and possibly also with features based on the rule-based converter’s output. This approach is expected to improve parsing performance and robustness, demonstrating the utility of linguistically-informed approaches in complementing general supervised semantic parsers.\n14E.g., a teacher is a person who teaches, and a friend is a person who stands in a friendship relation with another person."
    }, {
      "heading" : "A Details of Rule-based Converter",
      "text" : "The following is a detailed description of the rules used in the rule-based parser (§3). This gives a stepby-step overview of the algorithm for constructing an UCCA semantic graph using STREUSLE/UD annotations. It is not a full specification and omits many details of the criteria and operations, but should be helpful for understanding the full code, available in anonymized. A running example is given at each step for the sentence:\nThere’s plenty of parking, and I’ve never had an issue with audience members who won’t stop talking or answering their cellphones.\nIt has the following gold annotation:\n[H [F There] [F ’s] [D plenty] [P [R of] [C parking] ] ] [U ,] [L and] [H [A I] [F ’ve] [D|T never] [F had] [P [F an] [C issue] ] [A [R with] [C [A audience] [P members] ] [E [R who] [H [A* members] [F wo] [D n’t] [D stop] [P talking] ] [L or] [H [A* members] [P answering] [A [E [S|A their] [A* cellphones] ] [C cellphones] [U .] ] ] ] ] ]\nStep 0.1: Transform the UD dependency parse\nSplit the final preposition off from V.IAV MWEs like take care of, as it is usually not treated as part of the verbal unit in UCCA. If the remaining part is still an MWE, it is labeled V.LVC.full or V.VPC.full depending on its syntax.\nStep 0.2: Initialize lexical units under the UCCA root\n• Each strong lexical expression (single-word or MWE) in STREUSLE is treated as an UCCA unit with the following exceptions:\n– An MWE with lexcat V.LVC.cause is broken into two units: D for the light verb modifies the main predicate in a + unit.\n– An MWE with lexcat V.LVC.full is broken into two units: F for the light verb modifies the main predciate in a + unit.\n– An MWE annotation is discarded if it would lead to a cycle in the dependencies such that the highest token of the MWE is dependent on a token outside of the MWE, which is dependent on another token of the MWE.\n• MWE-internal dependency edges are discarded so they will not be processed later.\n• Punctuation is marked U.\n• Mappings between units and dependency nodes are maintained.\nStep 0.3: Identify which lexical units are main relations (scene-evoking)\nIn a top-down traversal of the dependency parse, visit each word’s lexical unit and decide whether it evokes a state (S), process (P), undetermined between state or process (+), or does not evoke a scene (-):\n• If already labeled D, F, or +, do nothing.\n• If an adjective not from a small list of quantity adjectives, label S.\n• If existential there, label S. If a be verb in an existential construction, label - and swap the positions of be and there in the dependency parse so there is the head.\n• If an adverb not attached as discourse and it has a copula, label S.\n• thanks and thank you are P.\n• In most cases, predicative prepositions are S.\n• A copula introducing a predicate nominal (non-PP) is labeled S and promoted to the head of the dependency parse, unless the nominal is scene-evoking. (The top-down traversal order ensures the nominal is reached first.)\n• If a common noun, mark as\n– S if supersense-tagged as ATTRIBUTE, FEELING, or STATE – P if ACT, PHENOMENON, PROCESS, or EVENT (with the exception of nouns denoting a\npart of the day) – a relational noun if PERSON or GROUP and matching kinship/occupation lists or suffixes – - otherwise\n• If a verb or copula not handled above, label +\n• Else label -"
    }, {
      "heading" : "In the notation, “UNA” means “lexical” (it originally meant “unanalyzable”).",
      "text" : "[DUMMYROOT [S [UNA There] ] [- [UNA ’s] ] [- [UNA plenty] ] [- [UNA of] ] [S [UNA parking] ] [U ,] [- [UNA and] ] [- [UNA I] ] [- [UNA ’ve] ] [- [UNA never] ] [+ [F had] . . . [UNA issue] ] [- [UNA an] ] . . . [- [UNA with] ] [- [UNA audience] ] [- [UNA|A|P [UNA members] ] ] [- [UNA who] ] [- [UNA wo] ] [- [UNA n’t] ] [+ [UNA stop] ] [+ [UNA talking] ] [- [UNA or] ] [+ [UNA answering] ] [- [UNA their] ] [- [UNA cellphones] ] [U .] ]\nStep 1: Attach functional and discourse modifier words Determiners, auxiliaries, copulas are generally F; vocatives and interjections, G. Exceptions include modal auxiliaries (D), demonstrative determiners modifying a non-scene unit (E), quantifier determiners modifying a non-scene unit (Q).\nOmitting the root:\n[S [UNA There] [F [UNA ’s] ] ] [- [UNA plenty] ] [- [UNA of] ] [S [UNA parking] ] [U ,] [- [UNA and] ] [- [UNA I] ] [+ [F [UNA ’ve] ] . . . [F had] [F [UNA an] ] [UNA issue] ] [- [UNA never] ] . . . [- [UNA with] ] [- [UNA audience] ] [- [UNA|A|P [UNA members] ] ] [- [UNA who] ] [+ [F [UNA wo] ] . . . [UNA stop] ] [- [UNA n’t] ] . . . [+ [UNA talking] ] [- [UNA or] ] [+ [UNA answering] ] [- [UNA their] ] [- [UNA cellphones] ] [U .]\nStep 2: Attach other modifiers: adverbial, adjectival, numeric, compound, possessive, predicative-PP, adnominal-PP; as well as possessive clitic and preposition (as R, unless possessive clitic marks canonical possession in which case it is S)\n[S [UNA There] [F [UNA ’s] ] ] [- [UNA plenty] [E [S [R [UNA of] ] [UNA parking] ] ] ] [U ,] [- [UNA and] ] [- [UNA I] ] [+ [F [UNA ’ve] ] [T [UNA never] ] [F had] [F [UNA an] ] [UNA issue] [A [R [UNA with] ] [E [UNA audience] ] [UNA|A|P [UNA members] ] . . . [E [+ [A* members] [F [UNA wo] ] [D [UNA n’t] ] [UNA stop] ] ] ] ] [- [UNA who] ] . . . [+ [UNA talking] ] [- [UNA or] ] [+ [UNA answering] ] [- [E [A|S [UNA their] ] [A* cellphones] ] [UNA cellphones] ] [U .]\nStep 3: Process verbal argument structure relations: subjects, objects, obliques, clausal complements; flag secondary (non-auxiliary) verb constructions\n[S [UNA There] [F [UNA ’s] ] [A [UNA plenty] [E [S [R [UNA of] ] [UNA parking] ] ] ] ] [U ,] [- [UNA and] ] [+ [A [UNA I] ] [F [UNA ’ve] ] [T [UNA never] ] [F had] [F [UNA an] ] [UNA issue] [A [R [UNA with] ] [E [UNA audience] ] [UNA|A|P [UNA members] ] [E [+ [A* members] [R [UNA who] ] [F [UNA wo] ] [D [UNA n’t] ] [UNA stop] [ˆ [+ [UNA talking] ] ] ] ] ] ] [- [UNA or] ] [+ [UNA answering] [A [E [A|S [UNA their] ] [A* cellphones] ] [UNA cellphones] ] ] [U .]\nStep 4: Coordination\nTraversing the graph top-down: for each coordinate construction with conjuncts’ units’ categories X and Y, create a ternary-branching structure [X(COORD) X L Y] if X is scene-evoking (+, P, or S) and [X(COORD) X N Y] otherwise.\nThere’s plenty. . . and I’ve never had an issue with. . .\n[S(COORD) [S [UNA There] [F [UNA ’s] ] [A [UNA plenty] [E [S [R [UNA of] ] [UNA parking] ] ] ] ] . . . [L [UNA and] ] [+ [A [UNA I] ] [F [UNA ’ve] ] [T [UNA never] ] [F had] [F [UNA an] ] [UNA issue] [A [R [UNA with] ] [E [UNA audience] ] [UNA|A|P [UNA members] ] [E [+ [A* members] [R [UNA who] ] [F [UNA wo] ] [D [UNA n’t] ] [UNA stop] [ˆ [+ [UNA talking] ] ] ] ] ] ] ] [U ,] . . . [- [UNA or] ] [+ [UNA answering] [A [E [A|S [UNA their] ] [A* cellphones] ] [UNA cellphones] ] ] [U .]\n. . . won’t stop talking or answering. . .\n[S(COORD) [S [UNA There] [F [UNA ’s] ] [A [UNA plenty] [E [S [R [UNA of] ] [UNA parking] ] ] ] ] . . . [L [UNA and] ] [P [A [UNA I] ] [F [UNA ’ve] ] [T [UNA never] ] [F had] [F [UNA an] ] [UNA issue] [A [R [UNA with] ] [E [UNA audience] ] [UNA|A|P [UNA members] ] [E [P [A* members] [R [UNA who] ] [F [UNA wo] ] [D [UNA n’t] ] [UNA stop] [ˆ [+(COORD) [P [UNA talking] ] [L [UNA or] ] [P [UNA answering] [A [E [A|S [UNA their] ] [A* cellphones] ] [UNA cellphones] ] ] ] ]] ] ] ] ] [U ,] . . . [U .]\nStep 5: Decide S or P for remaining + scenes\nCopula be and stative have are S; other verbs, as well as nouns tagged as ACT, PHENOMENON, PROCESS, or EVENT, are P.\n[S(COORD) [S [UNA There] [F [UNA ’s] ] [A [UNA plenty] [E [S [R [UNA of] ] [UNA parking] ] ] ] ] . . . [L [UNA and] ] [P [A [UNA I] ] [F [UNA ’ve] ] [T [UNA never] ] [F had] [F [UNA an] ] [UNA issue] [A [R [UNA with] ] [E [UNA audience] ] [UNA|A|P [UNA members] ] [E [P [A* members] [R [UNA who] ] [F [UNA wo] ] [D [UNA n’t] ] [UNA stop] [ˆ [+(COORD) [P [UNA talking] ] [L [UNA or] ] [P [UNA answering] [A [E [A|S [UNA their] ] [A* cellphones] ] [UNA cellphones] ] ] ] ]] ] ] ] ] [U ,] . . . [U .]\nStep 6.1: Restructure for secondary verbs\n[S(COORD) [S [UNA There] [F [UNA ’s] ] [A [UNA plenty] [E [S [R [UNA of] ] [UNA parking] ] ] ] ] . . . [L [UNA and] ] [P [A [UNA I] ] [F [UNA ’ve] ] [T [UNA never] ] [F had] [F [UNA an] ] [UNA issue] [A [R [UNA with] ] [E [UNA audience] ] [UNA|A|P [UNA members] ] [E [P [A* members] [R [UNA who] ] [F [UNA wo] ] [D [UNA n’t] ] [D [UNA stop] ] [+(COORD) [P [UNA talking] ] [L [UNA or] ] [P [UNA answering] [A [E [A|S [UNA their] ] [A* cellphones] ] [UNA cellphones] ] ] ]] ] ] ] ] [U ,] . . . [U .]\nStep 6.2: Articulation—marking lexical heads of units as C, P, or S, and renaming scene units as H where necessary; determination of C involves “X of Y” constructions involving quantities/Species\n[S(COORD) [H(S) [S [UNA There] ] [F [UNA ’s] ] [A [Q [UNA plenty] ] [E [H(S) [R [UNA of] ] [S [UNA parking] ] ] ] ] ] . . . [L [UNA and] ] [H(P) [A [UNA I] ] [F [UNA ’ve] ] [T [UNA never] ] [F had] [F [UNA an] ] [P [UNA issue] ] [A [R [UNA with] ] [E [UNA audience] ] [H(A|P)|A|P [A|P [UNA members] ] ] [E [H [A* members] [R [UNA who] ] [F [UNA wo] ] [D [UNA n’t] ] [D [UNA stop] ] [+(COORD) [H(P) [P [UNA talking] ] ] [L [UNA or] ] [H(P) [P [UNA answering] ] [A [E [H(A|S)|S [A|S [UNA their] ] ] [A* cellphones] ] [C [UNA cellphones] ] ] ] ] ] ] ] ] ] [U ,] . . . [U .]\nSteps 7+: Cleanup\nRemove temporary decorations on H units from articulation; move U units for punctuation to more convenient attachment points; convert remaining - and + labels; wrap stray P and S units with H scenes; remove UNA and other temporary designations in the graph\n[S(COORD) [H [S [UNA There] ] [F [UNA ’s] ] [A [Q [UNA plenty] ] [E [H [R [UNA of] ] [S [UNA parking] ] ] ] ] ] . . . [L [UNA and] ] [H [A [UNA I] ] [F [UNA ’ve] ] [T [UNA never] ] [F had] [F [UNA an] ] [P [UNA issue] ] [A [R [UNA with] ] [E [UNA audience] ] [C [A|P [UNA members] ] ] [E [H [A* members] [R [UNA who] ] [F [UNA wo] ] [D [UNA n’t] ] [D [UNA stop] ] [+(COORD) [H [P [UNA talking] ] ] [L [UNA or] ] [H [P [UNA answering] ] [A [E [C [A|S [UNA their] ] ] [A* cellphones] ] [C [UNA cellphones] ] ] ] ] ] ] ] ] ] [U ,] . . . [U .]\n[S(COORD) [H [S [UNA There] ] [F [UNA ’s] ] [A [Q [UNA plenty] ] [E [H [R [UNA of] ] [S [UNA parking] ] ] ] ] ] [U ,] [L [UNA and] ] [H [A [UNA I] ] [F [UNA ’ve] ] [T [UNA never] ] [F had] [F [UNA an] ] [P [UNA issue] ] [A [R [UNA with] ] [E [UNA audience] ] [C [A|P [UNA members] ] ] [E [H [A* members] [R [UNA who] ] [F [UNA wo] ] [D [UNA n’t] ] [D [UNA stop] ] [+(COORD) [H [P [UNA talking] ] ] [L [UNA or] ] [H [P [UNA answering] ] [A [E [C [A|S [UNA their] ] ] [A* cellphones] ] [C [UNA cellphones] ] ] ] ] ] ] ] ] [U .] ]\n[H [H [S [UNA There] ] [F [UNA ’s] ] [A [Q [UNA plenty] ] [E [H [R [UNA of] ] [S [UNA parking] ] ] ] ] ] [U ,] [L [UNA and] ] [H [A [UNA I] ] [F [UNA ’ve] ] [T [UNA never] ] [F had] [F [UNA an] ] [P [UNA issue] ] [A [R [UNA with] ] [E [UNA audience] ] [C [A|P [UNA members] ] ] [E [H [A* members] [R [UNA who] ] [F [UNA wo] ] [D [UNA n’t] ] [D [UNA stop] ] [H [H [P [UNA talking] ] ] [L [UNA or] ] [H [P [UNA answering] ] [A [E [C [A|S [UNA their] ] ] [A* cellphones] ] [C [UNA cellphones] ] ] ] ] ] ] ] ] [U .] ]\n[H [H [S There] [F ’s] [A [Q plenty] [E [R of] [S parking] ] ] ] [U ,] [L and] [H [A I] [F ’ve] [T never] [F had] [F an] [P issue] [A [R with] [E audience] [C [A|P members] ] [E [A* members] [R who] [F wo] [D n’t] [D stop] [H [H [P talking] ] [L or] [H [P answering] [A [E [C [A|S their] ] [A* cellphones] ] [C cellphones] ] ] ] ] ] ] [U .] ]"
    }, {
      "heading" : "B An Alternative Converter",
      "text" : "B.1 Dependency Transformations\nHershcovich et al. (2019a) apply several pre-conversion dependency transformation, to match UCCA’s flat linkage structure: cc dependents and mark dependents of advcl are promoted to be siblings of their heads, as in UCCA they are often L between scenes. advcl, appos, conj and parataxis are also promoted.15\nB.2 Label Mapping\nWe assign UCCA categories to graph edges, translating each UD relation to the most commonly cooccurring UCCA category in the training set.\nWe augment this simple majority-based UD-to-UCCA category mapping with rules based on lexical semantics, whose synopsis follows. The rules are based on the concept of scene-evoking words and phrases, which is not directly encoded in either UD or STREUSLE. However, by defining a set of heuristics on the lexical semantic categories, we obtain a good approximation of the UCCA scene/nonscene distinction. These rules first apply heuristics based on STREUSLE noun and verb supersenses— determined by examining the training data—and then take into account POS tags and word lists for the more complex cases.\n15We implement the same transformations using DepEdit: https://corpling.uis.georgetown.edu/depedit\nScene-evoking or not? If a noun has one of the supersenses N.ACT, N.EVENT, N.PHENOMENON, N.PROCESS, N.STATE, N.ATTRIBUTE, or N.FEELING, it is identified as scene-evoking. Proper nouns (UPOS=PROPN) are classified as non-scene-evoking. Other nouns with the supersense N.PERSON are first matched against a hand-crafted list of relational suffixes16 and then against a list of relational nouns based on AMR heuristic lists and WordNet synsets.17 Copulas with UPOS=AUX and supersense V.STATIVE are classified as non–scene-evoking. V.CHANGE verbs are matched against a hand-crafted list of aspectual verbs,18 which are non–scene-evoking (D) in UCCA. Nouns and verbs that do not satisfy any of these criteria are canonically classified as non–scene-evoking and scene-evoking, respectively.\nCategories. Scene-evoking verbs and nouns are labeled P instead of C by default (and their modifiers D instead of E). However, they are S under the following conditions: nouns with the supersenses N.STATE, N.ATTRIBUTE, and N.FEELING, and adjectives modifying non-scene-evoking nouns. Predicative nouns with no subject are labeled as A, and their modifiers as S (e.g. “Great food!”). Possessives with P.SOCIALREL or P.ORGROLE supersenses are E scenes with the possessive labeled both S and A, and their head as a A in the scene they evoke (see example in Figure 1).\nSpecial cases of verbs. Verbs with the V.STATIVE supersense are labeled F if they have scene-evoking objects (e.g., “they have great customer service”), as S if their lemma is “be”/“have”, and as P otherwise. Verbs in full light verb constructions or verb idiomatic expressions (V.LVC.full, V.VID ) are labeled F (e.g., “pay attention”).\nFurther lexical decisions. Expressions with the N.TIME supersense are labeled T. Locative proadverbs from a pre-defined lexicon (“here”, “there”, etc.) are labeled as A. Expressions with the NUM lexcat are labeled Q. If they are not labeled as R or D by the majority-based mapping, words from a pre-defined lexicon or having the DISC lexcat or the P.PURPOSE supersense are labeled L. Adverbs with the P.APPROXIMATOR supersense are E instead of D (e.g. “about 30%”).\nFurther structural decisions. While conj (conjunct, e.g., in coordination) most often correspond to H, if the head is a non-scene then the dependent is labeled as C instead, as its corresponding unit is likely non-scene too. Compound or possessive modifiers of scene nouns are labeled as A. vocative dependents are labeled as both A and G.\nB.3 UCCA Postprocessing\nUCCA enforces a number of well-formedness restrictions, in terms of which categories may be siblings or children of which. These are sometimes violated by applying the rules described so far. We apply the category replacements listed in Table 4 to enforce meeting them. Additionally, H or L inside a scene are promoted to be a sibling of the scene, and remote H, N, L are removed.\n16-er, -ess, -or, -ant, -ent, -ee, -ian, -ist 17From http://amr.isi.edu/download.html we obtained have-org-role-91-roles-v1.06, which lists 39 types of government officials; and have-rel-role-91-roles-v1.06, which includes 85 kinship terms and a handful of person-to-person relations like boss, client, and roommate (the ‘MAYBE’ entries in these lists, which contain ambiguous words, are disregarded). The WordNet list consists of 1,487 occupations given by the single-word lemmas in the synsets leader.n.01, professional.n.01, worker.n.01, and their hyponyms, minus the words man and woman. The heuristics assign the State category to kinship terms like ‘father’ and Process to occupation nouns.\n18start, stop, begin, end, finish, complete, continue, resume, get, become, quit, keep\nB.4 Comparison with the Primary Converter In the following head-to-head comparison, we refer to the primary system presented in the main part of the paper as “system A” and the secondary version presented here as “system B”.\nEasy for both:\n• both systems perform well on As\n• both systems are good at recalling Fs (system A: 84.9, system B: 89.9), but system A (in contrast to system B) has almost perfect precision (98.6 vs 82.5)\nDifficult for both:\n• both systems perform okay on Cs; system B tends to confuse Cs for As and Ps more than system A, which tends to fail at predicting units matching gold Cs entirely\n• Ds are difficult for both systems; system A underpredicts Ds more than system B, but it is also more precise\n• Es are difficult for both systems; Es often get confused (by both systems and in both directions) with Ds, As and Ss\n• relational nouns (A|S, A|P) are very difficult for both systems; system B doesn’t predict them at all, and system A predicts a few A|Ss which are mostly correct, but still misses 3/4 of them (and all A|Ps)\n• Gs are very difficult for both systems; system B doesn’t predict them at all, and system A predicts a few but with low precision and recall\nDifferences:\n• system A is better at recalling Qs\n• system A is better at recall (64.0 vs 53.6) and precision (61.2 vs 48.4) on Ss, but also confuses some gold Fs for Ss\n• system A is better at recalling Ts; both systems tend to confuse Ts for Ds, but system B does it more than half of the time whereas system A only a quarter\n• system A is more eager to predict Ls, thus has higher recall (83.7 vs 61.0) but lower precision (74.7 vs 87.5) here than system B; system A confuses some gold Fs and Rs for Ls, system B confuses some gold Ls for Cs, Ns and Rs\n• system B is more eager to predict Ns, thus has higher recall (76.6 vs 66.0) but lower precision (37.1 vs 66.0) here than system A; system B confuses some gold Ls for Ns\n• system B is more eager to predict Ps, thus has higher recall (78.6 vs 69.1) but lower precision (56.3 vs 73.1) here than system A; system B confuses some gold Cs, Ds and Fs for Ps, system A confuses some gold Ps for Hs\n• system B is more eager to predict Rs, thus has higher recall (88.8 vs 74.0) but lower precision (65.5 vs 84.1) here than system A; system B confuses some gold Fs and Ls for Rs, system A confuses some gold Rs for Ls\nGiven the small differences between the converters in terms of performance, we decided to use system A for the main analysis in the paper, as it is more modular and interpretable."
    }, {
      "heading" : "C Delexicalized Parser Confusion Matrix",
      "text" : "Table 5 shows the confusion matrix for the delexicalized HIT-SCIR parser on the EWT reviews development set."
    } ],
    "references" : [ {
      "title" : "Universal Conceptual Cognitive Annotation (UCCA)",
      "author" : [ "Omri Abend", "Ari Rappoport." ],
      "venue" : "Proc. of ACL, pages 228–238, August.",
      "citeRegEx" : "Abend and Rappoport.,? 2013",
      "shortCiteRegEx" : "Abend and Rappoport.",
      "year" : 2013
    }, {
      "title" : "The state of the art in semantic representation",
      "author" : [ "Omri Abend", "Ari Rappoport." ],
      "venue" : "Proc. of ACL, pages 77–89.",
      "citeRegEx" : "Abend and Rappoport.,? 2017",
      "shortCiteRegEx" : "Abend and Rappoport.",
      "year" : 2017
    }, {
      "title" : "The parallel meaning bank: Towards a multilingual corpus of translations annotated with compositional meaning representations",
      "author" : [ "Lasha Abzianidze", "Johannes Bjerva", "Kilian Evang", "Hessel Haagsma", "Rik van Noord", "Pierre Ludmann", "Duc-Duy Nguyen", "Johan Bos." ],
      "venue" : "Proc. of EACL, volume 2, pages 242–247.",
      "citeRegEx" : "Abzianidze et al\\.,? 2017",
      "shortCiteRegEx" : "Abzianidze et al\\.",
      "year" : 2017
    }, {
      "title" : "The Berkeley FrameNet project",
      "author" : [ "Collin F. Baker", "Charles J. Fillmore", "John B. Lowe." ],
      "venue" : "ACL-COLING ’98.",
      "citeRegEx" : "Baker et al\\.,? 1998",
      "shortCiteRegEx" : "Baker et al\\.",
      "year" : 1998
    }, {
      "title" : "Abstract Meaning Representation for sembanking",
      "author" : [ "Laura Banarescu", "Claire Bonial", "Shu Cai", "Madalina Georgescu", "Kira Griffitt", "Ulf Hermjakob", "Kevin Knight", "Martha Palmer", "Nathan Schneider." ],
      "venue" : "Proc. of the Linguistic Annotation Workshop.",
      "citeRegEx" : "Banarescu et al\\.,? 2013",
      "shortCiteRegEx" : "Banarescu et al\\.",
      "year" : 2013
    }, {
      "title" : "English web treebank",
      "author" : [ "Ann Bies", "Justin Mott", "Colin Warner", "Seth Kulick." ],
      "venue" : "Linguistic Data Consortium, Philadelphia, PA.",
      "citeRegEx" : "Bies et al\\.,? 2012",
      "shortCiteRegEx" : "Bies et al\\.",
      "year" : 2012
    }, {
      "title" : "HUME: Human UCCA-based evaluation of machine translation",
      "author" : [ "Alexandra Birch", "Omri Abend", "Ondřej Bojar", "Barry Haddow." ],
      "venue" : "Proc. of EMNLP, pages 1264–1274, November.",
      "citeRegEx" : "Birch et al\\.,? 2016",
      "shortCiteRegEx" : "Birch et al\\.",
      "year" : 2016
    }, {
      "title" : "The Prague dependency treebank",
      "author" : [ "Alena Böhmová", "Jan Hajič", "Eva Hajičová", "Barbora Hladká." ],
      "venue" : "Treebanks, pages 103–127. Springer.",
      "citeRegEx" : "Böhmová et al\\.,? 2003",
      "shortCiteRegEx" : "Böhmová et al\\.",
      "year" : 2003
    }, {
      "title" : "HIT-SCIR at MRP 2019: A unified pipeline for meaning representation parsing via efficient training and effective encoding",
      "author" : [ "Wanxiang Che", "Longxu Dou", "Yang Xu", "Yuxuan Wang", "Yijia Liu", "Ting Liu." ],
      "venue" : "Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning, pages 76–85, Hong Kong, November. Association for Computational Linguistics.",
      "citeRegEx" : "Che et al\\.,? 2019",
      "shortCiteRegEx" : "Che et al\\.",
      "year" : 2019
    }, {
      "title" : "Reference-less measure of faithfulness for grammatical error correction",
      "author" : [ "Leshem Choshen", "Omri Abend." ],
      "venue" : "Proc. of NAACL-HLT.",
      "citeRegEx" : "Choshen and Abend.,? 2018",
      "shortCiteRegEx" : "Choshen and Abend.",
      "year" : 2018
    }, {
      "title" : "Refining implicit argument annotation for ucca",
      "author" : [ "Ruixiang Cui", "Daniel Hershcovich." ],
      "venue" : "arXiv preprint arXiv:2005.12889.",
      "citeRegEx" : "Cui and Hershcovich.,? 2020",
      "shortCiteRegEx" : "Cui and Hershcovich.",
      "year" : 2020
    }, {
      "title" : "BERT: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171–4186, Minneapolis, Minnesota, June. Association for Computational Linguistics.",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Transition-based dependency parsing with stack long short-term memory",
      "author" : [ "Chris Dyer", "Miguel Ballesteros", "Wang Ling", "Austin Matthews", "Noah A. Smith." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 334–343, Beijing, China, July. Association for Computational Linguistics.",
      "citeRegEx" : "Dyer et al\\.,? 2015",
      "shortCiteRegEx" : "Dyer et al\\.",
      "year" : 2015
    }, {
      "title" : "Coarse semantic classification of rare nouns using cross-lingual data and recurrent neural networks",
      "author" : [ "Oliver Hellwig." ],
      "venue" : "Proc. of IWCS, Montpellier, France.",
      "citeRegEx" : "Hellwig.,? 2017",
      "shortCiteRegEx" : "Hellwig.",
      "year" : 2017
    }, {
      "title" : "A transition-based directed acyclic graph parser for UCCA",
      "author" : [ "Daniel Hershcovich", "Omri Abend", "Ari Rappoport." ],
      "venue" : "Proc. of ACL, pages 1127–1138.",
      "citeRegEx" : "Hershcovich et al\\.,? 2017",
      "shortCiteRegEx" : "Hershcovich et al\\.",
      "year" : 2017
    }, {
      "title" : "Multitask parsing across semantic representations",
      "author" : [ "Daniel Hershcovich", "Omri Abend", "Ari Rappoport." ],
      "venue" : "Proc. of ACL, pages 373–385.",
      "citeRegEx" : "Hershcovich et al\\.,? 2018",
      "shortCiteRegEx" : "Hershcovich et al\\.",
      "year" : 2018
    }, {
      "title" : "Content differences in syntactic and semantic representation",
      "author" : [ "Daniel Hershcovich", "Omri Abend", "Ari Rappoport." ],
      "venue" : "Proc. of NAACL-HLT, pages 478–488, Minneapolis, Minnesota, June. Association for Computational Linguistics.",
      "citeRegEx" : "Hershcovich et al\\.,? 2019a",
      "shortCiteRegEx" : "Hershcovich et al\\.",
      "year" : 2019
    }, {
      "title" : "SemEval 2019 task 1: Cross-lingual semantic parsing with UCCA",
      "author" : [ "Daniel Hershcovich", "Leshem Choshen", "Elior Sulem", "Zohar Aizenbud", "Ari Rappoport", "Omri Abend." ],
      "venue" : "Proc. of SemEval.",
      "citeRegEx" : "Hershcovich et al\\.,? 2019b",
      "shortCiteRegEx" : "Hershcovich et al\\.",
      "year" : 2019
    }, {
      "title" : "Double trouble: the problem of construal in semantic annotation of adpositions",
      "author" : [ "Jena D. Hwang", "Archna Bhatia", "Na-Rae Han", "Tim O’Gorman", "Vivek Srikumar", "Nathan Schneider" ],
      "venue" : "In Proc. of *SEM,",
      "citeRegEx" : "Hwang et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Hwang et al\\.",
      "year" : 2017
    }, {
      "title" : "Supersense tagging for Danish",
      "author" : [ "Héctor Martínez Alonso", "Anders Johannsen", "Sussi Olsen", "Sanni Nimb", "Nicolai Hartvig Sørensen", "Anna Braasch", "Anders Søgaard", "Bolette Sandford Pedersen." ],
      "venue" : "Beáta Megyesi, editor, Proc. of NODALIDA, pages 21–29, Vilnius, Lithuania.",
      "citeRegEx" : "Alonso et al\\.,? 2015",
      "shortCiteRegEx" : "Alonso et al\\.",
      "year" : 2015
    }, {
      "title" : "The NomBank project: an interim report",
      "author" : [ "Adam Meyers", "Ruth Reeves", "Catherine Macleod", "Rachel Szekely", "Veronika Zielinska", "Brian Young", "Ralph Grishman." ],
      "venue" : "Adam Meyers, editor, Proc. of the Frontiers in Corpus Annotation Workshop, pages 24–31, Boston, Massachusetts, USA, May.",
      "citeRegEx" : "Meyers et al\\.,? 2004",
      "shortCiteRegEx" : "Meyers et al\\.",
      "year" : 2004
    }, {
      "title" : "Constructing a lexicon of relational nouns",
      "author" : [ "Edward Newell", "Jackie Chi Kit Cheung." ],
      "venue" : "Nicoletta Calzolari, Khalid Choukri, Christopher Cieri, Thierry Declerck, Sara Goggi, Koiti Hasida, Hitoshi Isahara, Bente Maegaard, Joseph Mariani, Hélène Mazo, Asuncion Moreno, Jan Odijk, Stelios Piperidis, and Takenobu Tokunaga, editors, Proc. of LREC, pages 3405–3410, Miyazaki, Japan, May.",
      "citeRegEx" : "Newell and Cheung.,? 2018",
      "shortCiteRegEx" : "Newell and Cheung.",
      "year" : 2018
    }, {
      "title" : "Universal dependencies v1: A multilingual treebank collection",
      "author" : [ "Joakim Nivre", "Marie-Catherine de Marneffe", "Filip Ginter", "Yoav Goldberg", "Jan Hajic", "Christopher D. Manning", "Ryan McDonald", "Slav Petrov", "Sampo Pyysalo", "Natalia Silveira", "Reut Tsarfaty", "Daniel Zeman." ],
      "venue" : "Proc. of LREC, may.",
      "citeRegEx" : "Nivre et al\\.,? 2016",
      "shortCiteRegEx" : "Nivre et al\\.",
      "year" : 2016
    }, {
      "title" : "MRP 2019: Cross-framework Meaning Representation Parsing",
      "author" : [ "Stephan Oepen", "Omri Abend", "Jan Hajič", "Daniel Hershcovich", "Marco Kuhlmann", "Tim O’Gorman", "Nianwen Xue", "Jayeol Chun", "Milan Straka", "Zdeňka Urešová" ],
      "venue" : "In Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning,",
      "citeRegEx" : "Oepen et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Oepen et al\\.",
      "year" : 2019
    }, {
      "title" : "The proposition bank: An annotated corpus of semantic roles",
      "author" : [ "Martha Palmer", "Daniel Gildea", "Paul Kingsbury." ],
      "venue" : "Computational Linguistics, 31(1).",
      "citeRegEx" : "Palmer et al\\.,? 2005",
      "shortCiteRegEx" : "Palmer et al\\.",
      "year" : 2005
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher D Manning." ],
      "venue" : "Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1532–1543.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Supersense Tagger for Italian",
      "author" : [ "Davide Picca", "Alfio Massimiliano Gliozzo", "Massimiliano Ciaramita." ],
      "venue" : "Nicoletta Calzolari, Khalid Choukri, Bente Maegaard, Joseph Mariani, Jan Odjik, Stelios Piperidis, and Daniel Tapias, editors, Proc. of LREC, pages 2386–2390, Marrakech, Morocco.",
      "citeRegEx" : "Picca et al\\.,? 2008",
      "shortCiteRegEx" : "Picca et al\\.",
      "year" : 2008
    }, {
      "title" : "Made for each other: Broad-coverage semantic structures meet preposition supersenses",
      "author" : [ "Jakob Prange", "Nathan Schneider", "Omri Abend." ],
      "venue" : "Proc. of CoNLL.",
      "citeRegEx" : "Prange et al\\.,? 2019",
      "shortCiteRegEx" : "Prange et al\\.",
      "year" : 2019
    }, {
      "title" : "Combining contextual and structural information for supersense tagging of Chinese unknown words",
      "author" : [ "Likun Qiu", "Yunfang Wu", "Yanqiu Shao", "Alexander Gelbukh." ],
      "venue" : "Computational Linguistics and Intelligent Text Processing: Proceedings of the 12th International Conference (CICLing’11), volume 6608 of Lecture Notes in Computer Science, pages 15–28. Springer, Berlin.",
      "citeRegEx" : "Qiu et al\\.,? 2011",
      "shortCiteRegEx" : "Qiu et al\\.",
      "year" : 2011
    }, {
      "title" : "A corpus and model integrating multiword expressions and supersenses",
      "author" : [ "Nathan Schneider", "Noah A. Smith." ],
      "venue" : "Proc. of NAACL-HLT, pages 1537–1547, Denver, Colorado, June.",
      "citeRegEx" : "Schneider and Smith.,? 2015",
      "shortCiteRegEx" : "Schneider and Smith.",
      "year" : 2015
    }, {
      "title" : "Supersense tagging for Arabic: the MT-in-the-middle attack",
      "author" : [ "Nathan Schneider", "Behrang Mohit", "Chris Dyer", "Kemal Oflazer", "Noah A. Smith." ],
      "venue" : "Proc. of NAACL-HLT, pages 661–667, Atlanta, Georgia, USA.",
      "citeRegEx" : "Schneider et al\\.,? 2013",
      "shortCiteRegEx" : "Schneider et al\\.",
      "year" : 2013
    }, {
      "title" : "Adposition and case supersenses v2: Guidelines for english",
      "author" : [ "Nathan Schneider", "Jena D Hwang", "Archna Bhatia", "Na-Rae Han", "Vivek Srikumar", "Tim O’Gorman", "Sarah R Moeller", "Omri Abend", "Austin Blodgett", "Jakob Prange" ],
      "venue" : "arXiv preprint arXiv:1704.02134",
      "citeRegEx" : "Schneider et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Schneider et al\\.",
      "year" : 2017
    }, {
      "title" : "Comprehensive supersense disambiguation of English prepositions and possessives",
      "author" : [ "Nathan Schneider", "Jena D. Hwang", "Vivek Srikumar", "Jakob Prange", "Austin Blodgett", "Sarah R. Moeller", "Aviram Stern", "Adi Bitan", "Omri Abend." ],
      "venue" : "Proc. of ACL, pages 185–196, Melbourne, Australia, July.",
      "citeRegEx" : "Schneider et al\\.,? 2018",
      "shortCiteRegEx" : "Schneider et al\\.",
      "year" : 2018
    }, {
      "title" : "VerbNet: A broad-coverage, comprehensive verb lexicon",
      "author" : [ "Karin Kipper Schuler." ],
      "venue" : "Ph.D. thesis, University of Pennsylvania.",
      "citeRegEx" : "Schuler.,? 2005",
      "shortCiteRegEx" : "Schuler.",
      "year" : 2005
    }, {
      "title" : "Still a pain in the neck: Evaluating text representations on lexical composition",
      "author" : [ "Vered Shwartz", "Ido Dagan." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 7:403–419.",
      "citeRegEx" : "Shwartz and Dagan.,? 2019",
      "shortCiteRegEx" : "Shwartz and Dagan.",
      "year" : 2019
    }, {
      "title" : "Conceptual annotations preserve structure across translations: A French-English case study",
      "author" : [ "Elior Sulem", "Omri Abend", "Ari Rappoport." ],
      "venue" : "Proc. of S2MT, pages 11–22.",
      "citeRegEx" : "Sulem et al\\.,? 2015",
      "shortCiteRegEx" : "Sulem et al\\.",
      "year" : 2015
    }, {
      "title" : "Semantic structural annotation for text simplification",
      "author" : [ "Elior Sulem", "Omri Abend", "Ari Rappoport." ],
      "venue" : "Proc. of NAACL.",
      "citeRegEx" : "Sulem et al\\.,? 2018a",
      "shortCiteRegEx" : "Sulem et al\\.",
      "year" : 2018
    }, {
      "title" : "Simple and effective text simplification using semantic and neural methods",
      "author" : [ "Elior Sulem", "Omri Abend", "Ari Rappoport." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Sulem et al\\.,? 2018b",
      "shortCiteRegEx" : "Sulem et al\\.",
      "year" : 2018
    }, {
      "title" : "Augmenting English adjective senses with supersenses",
      "author" : [ "Yulia Tsvetkov", "Nathan Schneider", "Dirk Hovy", "Archna Bhatia", "Manaal Faruqui", "Chris Dyer." ],
      "venue" : "Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proc. of LREC, pages 4359–4365, Reykjavík, Iceland.",
      "citeRegEx" : "Tsvetkov et al\\.,? 2014",
      "shortCiteRegEx" : "Tsvetkov et al\\.",
      "year" : 2014
    }, {
      "title" : "Constructing an annotated corpus of verbal MWEs for English",
      "author" : [ "Abigail Walsh", "Claire Bonial", "Kristina Geeraert", "John P. McCrae", "Nathan Schneider", "Clarissa Somers." ],
      "venue" : "Proc. of LAW-MWE-CxG-2018, pages 193– 200, Santa Fe, New Mexico, USA.",
      "citeRegEx" : "Walsh et al\\.,? 2018",
      "shortCiteRegEx" : "Walsh et al\\.",
      "year" : 2018
    }, {
      "title" : "Universal decompositional semantics on Universal Dependencies",
      "author" : [ "Aaron Steven White", "Drew Reisinger", "Keisuke Sakaguchi", "Tim Vieira", "Sheng Zhang", "Rachel Rudinger", "Kyle Rawlins", "Benjamin Van Durme." ],
      "venue" : "Proc. of EMNLP, pages 1713–1723.",
      "citeRegEx" : "White et al\\.,? 2016",
      "shortCiteRegEx" : "White et al\\.",
      "year" : 2016
    }, {
      "title" : "Universal dependencies 2.5. LINDAT/CLARIN digital library at the Institute of Formal and Applied Linguistics (ÚFAL), Faculty of Mathematics and Physics, Charles University",
      "author" : [ "Washington", "Maximilan Wendt", "Seyi Williams", "Mats Wirén", "Christian Wittern", "Tsegay Woldemariam", "Tak-sum Wong", "Alina Wróblewska", "Mary Yako", "Naoki Yamazaki", "Chunxiao Yan", "Koichi Yasuoka", "Marat M. Yavrumyan", "Zhuoran Yu", "Zdeněk Žabokrtský", "Amir Zeldes", "Manying Zhang", "Hanzhi Zhu" ],
      "venue" : null,
      "citeRegEx" : "Washington et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Washington et al\\.",
      "year" : 2019
    }, {
      "title" : "Cross-lingual decompositional semantic parsing",
      "author" : [ "Sheng Zhang", "Xutai Ma", "Rachel Rudinger", "Kevin Duh", "Benjamin Van Durme." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1664–1675.",
      "citeRegEx" : "Zhang et al\\.,? 2018",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2018
    }, {
      "title" : "Adpositional Supersenses for Mandarin Chinese",
      "author" : [ "Yilun Zhu", "Yang Liu", "Siyao Peng", "Austin Blodgett", "Yushi Zhao", "Nathan Schneider." ],
      "venue" : "Proc. of SCiL, volume 2, pages 334–337, New York, NY, USA, January.",
      "citeRegEx" : "Zhu et al\\.,? 2019",
      "shortCiteRegEx" : "Zhu et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 1,
      "context" : "Several symbolic meaning representations (MRs) support human annotation of text with broad coverage (Abend and Rappoport, 2017; Oepen et al., 2019).",
      "startOffset" : 100,
      "endOffset" : 147
    }, {
      "referenceID" : 23,
      "context" : "Several symbolic meaning representations (MRs) support human annotation of text with broad coverage (Abend and Rappoport, 2017; Oepen et al., 2019).",
      "startOffset" : 100,
      "endOffset" : 147
    }, {
      "referenceID" : 5,
      "context" : "We perform our analysis on the Reviews section of the English Web Treebank (Bies et al., 2012), which has been manually annotated with UD and UCCA; and STREUSLE for lexical semantics (§2).",
      "startOffset" : 75,
      "endOffset" : 94
    }, {
      "referenceID" : 23,
      "context" : "The increasing interest in semantic representation and parsing, and the partial overlap in content between the different frameworks (Oepen et al., 2019), is a main motivation for our inquiry as to content differences between UD and STREUSLE, and UCCA.",
      "startOffset" : 132,
      "endOffset" : 152
    }, {
      "referenceID" : 40,
      "context" : "For example, UD also serves as the backbone of the DeComp scheme (White et al., 2016), and so information as to its semantic content is important there as well.",
      "startOffset" : 65,
      "endOffset" : 85
    }, {
      "referenceID" : 0,
      "context" : "1 Universal Conceptual Cognitive Annotation Universal Conceptual Cognitive Annotation (Abend and Rappoport, 2013) targets a level of semantic granularity that abstracts away from syntactic paraphrases in a typologically-motivated, cross-linguistic fashion (Sulem et al.",
      "startOffset" : 86,
      "endOffset" : 113
    }, {
      "referenceID" : 35,
      "context" : "1 Universal Conceptual Cognitive Annotation Universal Conceptual Cognitive Annotation (Abend and Rappoport, 2013) targets a level of semantic granularity that abstracts away from syntactic paraphrases in a typologically-motivated, cross-linguistic fashion (Sulem et al., 2015), building on Basic Linguistic Theory (Dixon, 2010 2012), an influential framework for linguistic description.",
      "startOffset" : 256,
      "endOffset" : 276
    }, {
      "referenceID" : 37,
      "context" : "UCCA has been applied to text simplification (Sulem et al., 2018b), and text-to-text generation evaluation (Birch et al.",
      "startOffset" : 45,
      "endOffset" : 66
    }, {
      "referenceID" : 6,
      "context" : ", 2018b), and text-to-text generation evaluation (Birch et al., 2016; Choshen and Abend, 2018; Sulem et al., 2018a).",
      "startOffset" : 49,
      "endOffset" : 115
    }, {
      "referenceID" : 9,
      "context" : ", 2018b), and text-to-text generation evaluation (Birch et al., 2016; Choshen and Abend, 2018; Sulem et al., 2018a).",
      "startOffset" : 49,
      "endOffset" : 115
    }, {
      "referenceID" : 36,
      "context" : ", 2018b), and text-to-text generation evaluation (Birch et al., 2016; Choshen and Abend, 2018; Sulem et al., 2018a).",
      "startOffset" : 49,
      "endOffset" : 115
    }, {
      "referenceID" : 17,
      "context" : "UCCA parsing has been targeted in two shared tasks (Hershcovich et al., 2019b; Oepen et al., 2019).",
      "startOffset" : 51,
      "endOffset" : 98
    }, {
      "referenceID" : 23,
      "context" : "UCCA parsing has been targeted in two shared tasks (Hershcovich et al., 2019b; Oepen et al., 2019).",
      "startOffset" : 51,
      "endOffset" : 98
    }, {
      "referenceID" : 10,
      "context" : "pdf (2)UCCA also supports implicit units which do not correspond to any tokens (Cui and Hershcovich, 2020), but these are excluded from parsing evaluation and we ignore them for purposes of this paper.",
      "startOffset" : 79,
      "endOffset" : 106
    }, {
      "referenceID" : 29,
      "context" : "3 STREUSLE STREUSLE (Supersense-Tagged Repository of English with a Unified Semantics for Lexical Expressions) is a corpus annotated comprehensively for several forms of lexical semantics (Schneider and Smith, 2015; Schneider et al., 2018): all kinds of multi-word expressions (MWEs) are annotated, giving each sentence a lexical semantic segmentation.",
      "startOffset" : 188,
      "endOffset" : 239
    }, {
      "referenceID" : 32,
      "context" : "3 STREUSLE STREUSLE (Supersense-Tagged Repository of English with a Unified Semantics for Lexical Expressions) is a corpus annotated comprehensively for several forms of lexical semantics (Schneider and Smith, 2015; Schneider et al., 2018): all kinds of multi-word expressions (MWEs) are annotated, giving each sentence a lexical semantic segmentation.",
      "startOffset" : 188,
      "endOffset" : 239
    }, {
      "referenceID" : 26,
      "context" : ", 2018), noun and verb supersenses (Picca et al., 2008; Qiu et al., 2011; Schneider et al., 2013; Martínez Alonso et al., 2015; Hellwig, 2017), and preposition supersenses (Hwang et al.",
      "startOffset" : 35,
      "endOffset" : 142
    }, {
      "referenceID" : 28,
      "context" : ", 2018), noun and verb supersenses (Picca et al., 2008; Qiu et al., 2011; Schneider et al., 2013; Martínez Alonso et al., 2015; Hellwig, 2017), and preposition supersenses (Hwang et al.",
      "startOffset" : 35,
      "endOffset" : 142
    }, {
      "referenceID" : 30,
      "context" : ", 2018), noun and verb supersenses (Picca et al., 2008; Qiu et al., 2011; Schneider et al., 2013; Martínez Alonso et al., 2015; Hellwig, 2017), and preposition supersenses (Hwang et al.",
      "startOffset" : 35,
      "endOffset" : 142
    }, {
      "referenceID" : 13,
      "context" : ", 2018), noun and verb supersenses (Picca et al., 2008; Qiu et al., 2011; Schneider et al., 2013; Martínez Alonso et al., 2015; Hellwig, 2017), and preposition supersenses (Hwang et al.",
      "startOffset" : 35,
      "endOffset" : 142
    }, {
      "referenceID" : 18,
      "context" : ", 2015; Hellwig, 2017), and preposition supersenses (Hwang et al., 2017; Zhu et al., 2019).",
      "startOffset" : 52,
      "endOffset" : 90
    }, {
      "referenceID" : 43,
      "context" : ", 2015; Hellwig, 2017), and preposition supersenses (Hwang et al., 2017; Zhu et al., 2019).",
      "startOffset" : 52,
      "endOffset" : 90
    }, {
      "referenceID" : 3,
      "context" : "This fact distinguishes UCCA and STREUSLE from finer-grained sentence-structural representations like FrameNet (Baker et al., 1998) and the Abstract Meaning Representation (Banarescu et al.",
      "startOffset" : 111,
      "endOffset" : 131
    }, {
      "referenceID" : 4,
      "context" : ", 1998) and the Abstract Meaning Representation (Banarescu et al., 2013), which relies on PropBank (Palmer et al.",
      "startOffset" : 48,
      "endOffset" : 72
    }, {
      "referenceID" : 24,
      "context" : ", 2013), which relies on PropBank (Palmer et al., 2005).",
      "startOffset" : 34,
      "endOffset" : 55
    }, {
      "referenceID" : 7,
      "context" : "The Prague Dependency Treebank tectogrammatical layer (Böhmová et al., 2003) uses few lexicon-free roles, but its semantics is determined by a valency lexicon.",
      "startOffset" : 54,
      "endOffset" : 76
    }, {
      "referenceID" : 2,
      "context" : "Parallel Meaning Bank (Abzianidze et al., 2017) uses lexicon-free5 VerbNet (Schuler, 2005) semantic roles.",
      "startOffset" : 22,
      "endOffset" : 47
    }, {
      "referenceID" : 33,
      "context" : ", 2017) uses lexicon-free5 VerbNet (Schuler, 2005) semantic roles.",
      "startOffset" : 35,
      "endOffset" : 50
    }, {
      "referenceID" : 42,
      "context" : "Cross-linguistic applicability in this case is delegated to the parser, which parses sentences in other languages to their corresponding English semantics (Zhang et al., 2018).",
      "startOffset" : 155,
      "endOffset" : 175
    }, {
      "referenceID" : 16,
      "context" : "short is an unanalyzable unit according to the gold UCCA annotation, but the syntactic relation between cut and short, namely xcomp, does not indicate that; only a small proportion of xcomps, in general, correspond to UCCA unanalyzable units (Hershcovich et al., 2019a).",
      "startOffset" : 242,
      "endOffset" : 269
    }, {
      "referenceID" : 14,
      "context" : "1 TUPA TUPA (Hershcovich et al., 2017), the first UCCA parser presented, is based on a transition-based algorithm with a neural network transition classifier, using a BiLSTM for encoding input representation, with word, lemma, and syntactic features embedded as real-valued features.",
      "startOffset" : 12,
      "endOffset" : 38
    }, {
      "referenceID" : 8,
      "context" : "2 HIT-SCIR Parser The HIT-SCIR (Che et al., 2019) parser is a transition-based parser for several MR frameworks, including UCCA.",
      "startOffset" : 31,
      "endOffset" : 49
    }, {
      "referenceID" : 23,
      "context" : "It achieved the highest average score in the CoNLL 2019 shared task (Oepen et al., 2019).",
      "startOffset" : 68,
      "endOffset" : 88
    }, {
      "referenceID" : 12,
      "context" : "It uses stack LSTMs (Dyer et al., 2015) to represent the stack, the buffer, and the sequence of actions.",
      "startOffset" : 20,
      "endOffset" : 39
    }, {
      "referenceID" : 11,
      "context" : "(2019) fine-tuned BERT (Devlin et al., 2019) for contextualized word representation, our delexicalized version replaces BERT with embeddings for UD and STREUSLE features, taken from the BIO-like encoding included in the STREUSLE dataset: POS tag, dependency relation, supersenses (scene role and functional role; see §2), the lexical category of the word or the MWE that the word is part of, and the BIO tag.",
      "startOffset" : 23,
      "endOffset" : 44
    }, {
      "referenceID" : 31,
      "context" : "4 (Schneider et al., 2017),9 and with UCCA graphs from UCCA_EnglishEWT v1.",
      "startOffset" : 2,
      "endOffset" : 26
    }, {
      "referenceID" : 25,
      "context" : "features from the gold UD annotation and GloVe (Pennington et al., 2014) word embeddings;12 and the HIT-SCIR parser trained in the original setting, with BERT embeddings (and no syntactic features).",
      "startOffset" : 47,
      "endOffset" : 72
    }, {
      "referenceID" : 34,
      "context" : "Lexical composition in noun compounds evokes various forms of event structures, which are underspecified by the meaning of the constituent words (Shwartz and Dagan, 2019).",
      "startOffset" : 145,
      "endOffset" : 170
    }, {
      "referenceID" : 21,
      "context" : "A special case of scene-evoking nouns are relational nouns (Newell and Cheung, 2018; Meyers et al., 2004), which both refer to an entity and evoke a scene in which the entity generally or habitually participates.",
      "startOffset" : 59,
      "endOffset" : 105
    }, {
      "referenceID" : 20,
      "context" : "A special case of scene-evoking nouns are relational nouns (Newell and Cheung, 2018; Meyers et al., 2004), which both refer to an entity and evoke a scene in which the entity generally or habitually participates.",
      "startOffset" : 59,
      "endOffset" : 105
    }, {
      "referenceID" : 38,
      "context" : "Enriching STREUSLE with supersenses for adjectives (Tsvetkov et al., 2014) might be fruitful for such distinctions.",
      "startOffset" : 51,
      "endOffset" : 74
    } ],
    "year" : 2020,
    "abstractText" : "Many frameworks exist for representing various aspects of linguistic meaning. Building robust natural language understanding systems will require a clear characterization of whether and how these representations complement each other. To perform a systematic comparative analysis, we evaluate the mapping between meaning representations from different frameworks using two complementary methods: a linguistically motivated and carefully designed rule-based converter, and a data-driven supervised delexicalized parser, which parses to one framework using only information from the other as features. We apply these methods to convert STREUSLE to UCCA. While STREUSLE provides comprehensive lexical semantic analysis on top of Universal Dependencies, UCCA is a sentence-level (or even document-level) meaning representation. Surprisingly, we find that both methods yield accurate target representations, close to fully supervised UCCA parser outputs in quality. A construction-level analysis of the results reveals the distinctions each method is sensitive to, as well as the similarities and divergences between the semantic frameworks. Our results show that UCCA, as a sentence-level meaning representation, cannot simply be reduced to syntax and lexical semantics, and that manually annotated training data for it is still a valuable resource for semantic parsers.",
    "creator" : "TeX"
  }
}