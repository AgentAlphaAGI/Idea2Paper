{
  "name" : "COLING_2020_73_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Aspect-Category based Sentiment Analysis with Hierarchical Graph Convolutional Network",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "As an important fine-grained subtask in the field of sentiment analysis, Aspect-Based Sentiment Classification (ABSC) (Pang et al., 2008; Liu, 2012) aims to detect the sentiment polarities of aspect terms mentioned in review text. For example, in Fig.1, given the aspect term food, it is expected to identify its corresponding sentiment polarity as positive. The main limitation of ABSC lies in that aspect terms need to be annotated before aspect sentiment classification, which is not applicable to real applications. To address this problem, many studies have been proposed to explore Aspect Term-based Sentiment Analysis (ATSA), which performs aspect term extraction and aspect sentiment classification jointly (Mitchell et al., 2013; Zhang et al., 2015; Li et al., 2019; Luo et al., 2019; Hu et al., 2019).\nHowever, ATSA still suffers from a major obstacle that it only considers explicit aspects but completely ignore implicit aspects in text. Take the review in Fig.1 as an example. Although the second clause does not mention any aspect term, it clearly expresses user’s negative sentiment towards the service. More importantly, we observe that existing benchmark datasets contain a large amount of such reviews. For instance, Table 2 shows the proportion of reviews with implicit aspects in the Restaurant dataset from SemEval 2015, and it is clear that nearly 25% of the examples contain implicit aspects. Since these examples also convey valuable information, we should no longer ignore them, as the previous ATSA methods do.\nMotivated by this, we focus on Aspect-Category based Sentiment Analysis (ACSA) in this paper, aiming to perform joint aspect category detection and category-oriented sentiment classification. Compared with ATSA, ACSA has the following two advantages: On the one hand, for each aspect mentioned in a piece of text, even if it does not have the corresponding aspect term, there must be a corresponding aspect category so that we can identify user’s sentiment over it. On the other hand, from the perspective of application in real scenarios, aspect category detection and category-oriented sentiment classification can meet the demand of opinion summary from multiple aspect level granularity.\nNumber Total Percentage Train 375 1654 22.67% Test 248 845 29.35%\nFigure 2: Percentage of implicit aspect in Restaurant-15 dataset of SemEval 2015.\nHowever, research in this area is relatively rare, and only a few preliminary studies have been carried out. (Schmitt et al., 2018) proposed a joint model by extending sentiment labels with one more dimension to indicate the occurrence of each aspect category, which is shown to outperform traditional pipeline methods. Another feasible solution is to perform Cartesian product for aspect categories and sentiment labels, which essentially performs multi-label sentiment classification for each aspect category. Nevertheless, most of these methods fail to explicitly model the hierarchical relationship between aspect category detection and category-oriented sentiment classification. In particular, when there are many aspect categories, it is difficult for these methods to learn the inner-relations among multiple categories and the inter-relations between categories and sentiments.\nIn this paper, we re-formalize the task as a category-sentiment hierarchy prediction problem, which contains a two-layer hierarchy output structure. The lower layer is to detect aspect categories, which can be modelled as a multi-label classification problem (i.e., one review may contain more than one category). The higher layer is to perform category-oriented sentiment classification, which can be modelled as a multi-class classification problem for each detected category.\nUnder the hierarchy output structure, our model contains three modules: the bottom module leverages BERT to obtain hidden representations of the two sub-tasks respectively. In the middle module, we propose a Hierarchical Graph Convolutional Network (Hier-GCN), where the lower-level GCN is to model the inner-relations among multiple categories, and the higher-level GCN is to capture the interrelations between categories and category-oriented sentiments. Based on the interactive representations generated from Hier-GCN, the top module performs category-sentiment hierarchy prediction to generate the final output.\nWe conduct experiments on four benchmark product review datasets from SemEval 2015 and SemEval 2016. Our observations are as follows. First, the hierarchy output structure shows better performance than other existing structures. On this basis, the proposed Hier-GCN architecture can bring additional performance gains, and consistently achieves the best results across the four datasets. Moreover, further analysis shows that Hier-GCN is also superior over existing methods on implicit aspect-based sentiment analysis."
    }, {
      "heading" : "2 Problem Formalization",
      "text" : "Given an input sentence with n words S={w1, . . . , wn}, Aspect Category-based Sentiment Analysis (ACSA) aims to detect all the mentioned aspect categories, and identify the sentiment for each detected category. Formally, let C = {c1, . . . , cm} be a set of m predefined aspect categories, and P = {positive, negative, neutral} be the label set of sentiment polarities. Accordingly, for each input S, the goal of ACSA is to generate a set of category-sentiment pairs, denoted as {. . . , yci -y p i , . . .}, where yci is the i-th aspect category mentioned in S, and ypi is its corresponding sentiment. As shown in Fig.3.a, one possible solution to this task is to consider all the combinations of categorysentiment pairs, denoted by Cartesian Product. Specifically, for each aspect category cj , we can model its sentiment prediction as a multi-label classification task to generate the output pj ∈ {0, 1}3, which indicates the occurrence of the positive, negative, and neutral sentiment, respectively. Note that if pj = [0, 0, 0], it indicates the absence of the category cj .\nSince Cartesian Product suffers from the risk of generating multiple sentiments for each category, an alternative solution is to add one label to the sentiment label space to predict the presence or absence of each category (Schmitt et al., 2018). In this case, the occurrence and the sentiment prediction of each category is unified as a simple multi-class classification problem.\nHowever, both approaches simply unify aspect category detection and category-oriented sentiment classification as one task, while ignoring the internal relationship between the two sub-tasks. Intuitively, if an aspect category is not detected, it is unnecessary to perform sentiment classification for it, and if multiple categories are detected, their sentiment output should be highly correlated. Motivated by this, we re-formalize the ACSA task as a category-sentiment hierarchy prediction problem with a hierarchy output structure, where the first layer is modeled as a multi-label classification problem for aspect category detection, and the second layer is modeled as a multi-class classification problem to perform sentiment classification for each detected category."
    }, {
      "heading" : "3 The Proposed Approach",
      "text" : ""
    }, {
      "heading" : "3.1 Overall Architecture",
      "text" : "The overall architecture of the proposed framework is illustrated in Fig.4. We use BERT as the basic encoder of our model to encode the contextual information of a sentence and generate context-aware category representations and sentiment representations, respectively (Section 3.2); Next, we use two hierarchical graph convolution network to capture the inner-relation between multiple categories and the inter-relation between categories and sentiment polarities, respectively (Section 3.3); Finally, a hierarchical output and integration module is designed to construct the final prediction from category prediction and sentiment prediction (Section 3.4)."
    }, {
      "heading" : "3.2 Feature Extraction with BERT",
      "text" : "We adopt Bidirectional Encoder Representations from Transformers (BERT) as our sentence encoder, which is a pre-trained on a huge amount of text with masked language model and has been shown to achieve state-of-the-art results on a broad set of NLP tasks. Let H ∈ Rd×(n+2) denote the final hidden states generated from BERT, where we insert two special tokens (i.e., [CLS] and [SEP]) at the beginning and the end of each input S. For space limitation, we omit a detailed description of BERT and refer readers to (Devlin et al., 2018).\nFor category representations, we further usem separate self-attention sub-layers on top of H to get the representations of m categories, denoted by C ∈ Rd×m. Besides, following the practice in (Devlin et al., 2018), we employ the last hidden state of the first token [CLS] as the shared sentiment representation for each category, denoted by S ∈ Rd."
    }, {
      "heading" : "3.3 Hierarchical Graph Convolutional Network (Hier-GCN)",
      "text" : ""
    }, {
      "heading" : "3.3.1 Motivation",
      "text" : "As introduced before, we model the task of ACSA as a hierarchy prediction problem with two sub-tasks: Aspect Category Detection (ACD) and Category-oriented Sentiment Classification (CSC). For ACD, since some aspect categories tend to frequently co-occur with each other, it is necessary to model the inner-relations between categories (e.g., in Fig.1, if food is mentioned in a user review, the service of the restaurant is likely to be mentioned as well). Similarly, for CSC, since the sentiment prediction is highly dependent on the prediction of aspect category, it is crucial to model the inter-relations between\ncategories and sentiment (e.g., in Fig.1, we only need to predict sentiment for Food and Service categories but not the others).\nSince graph convolutional network (GCN) can better capture the two kinds of relations by incorporating category-category and category-sentiment co-occurrence as prior knowledge, we employ it to model the inner-realtions and the inter-relations simultaneously. Specifically, we propose a hierarchical GCN model with two sub-layers, where the lower GCN sub-layer is to learn the inner interactions between categories, and the higher GCN sub-layer is to learn the inter interactions between categories and sentiments. The two sub-layers are coupled together as a Hier-GCN layer, and we further stack multiple such Hier-GCN layers to better learn the two kinds of relations. Next, we will detail the lower category GCN sub-layer, and the higher category-sentiment GCN sub-layer in the following two subsections."
    }, {
      "heading" : "3.3.2 Category GCN Sub-Layer",
      "text" : "To adapt GCN to model the inner-relations between multiple categories, we construct a directed graph by treating each category as a node, and obtain the adjacent matrix M c ∈ Rm×m by calculating the co-occurrence between every category pair over the entire training corpus. Formally, we use M ci,j to denote the transition probability of having the j-th category given the i-th category, and M c ∈ Rm×m can be computed as follows:\nM ci,j =\n{ count(ci,cj) count(ci)+1\n, i 6= j 1, i = j , (1)\nwhere count(ci) refers to the number of samples with the i-th category, and count(ci, cj) denotes the number of samples with both the i-th and the j-th category. Note that in most cases, M ci,j is not equal to M cj,i, which indicates that for a co-occurred category pair (ci, cj), the category with high frequency will have a high effect on the category with low frequency but not vice versa. This implies that modeling the inner-relations between categories may help detect more categories with low frequency, which is more significant for large-scale multi-label classification with many low frequency categories.\nWith the adjacent matrix M c, we perform the standard graph convolution on the node representations as follows:\nX l+1 = f(W lX lM c + bl), (2)\nwhere C is the initial state of X , i.e., X0, l refers to the l-th category GCN sub-layer, W l ∈ Rd×d and bl ∈ Rd are the linear transformation weight and bias, and f(·) is a nonlinear activation function, i.e.,\nGELU. After obtaining the output of the l+1-th sub-layer X l+1, we not only feed it to the next category GCN sub-layer as the input category representation, but also combine it with sentiment representations as the initial state of the l + 1-th category-sentiment GCN sub-layer. Note that in the final Hier-GCN layer, it is used to perform multi-label classification for aspect category detection."
    }, {
      "heading" : "3.3.3 Category-sentiment GCN Sub-Layer",
      "text" : "Similarly, to employ GCN to model the inter-relations betweenm categories andm∗3 category-oriented sentiments, we construct another directed graph by treating the m categories and m ∗ 3 sentiments as graph nodes. Since our final goal is to predict sentiment for each detected category, we propose to obtain an adjacent matrix for the positive, negative, and neutral sentiment, respectively. Take the positive sentiment as an example. We use M c−posi,j to denote the transition probability that the sentiment of the j-th category is positive given the i-th category:\nM c−posi,j =\n{ count(ci,c pos j )\ncount(ci)+1 , i 6= j\n1, i = j , (3)\nwhere cposj denotes the sentiment towards the i-th category is positive. Similarly, we can obtain all the three adjacent matrices, denoted by M c−k, k ∈ {pos, neg, neu}.\nNext, we first obtain the sentiment-sensitive category representation for each input node to derive\nĈS l ∈ Rm×d as follows:\nĈS l = Tanh(W lc,sX l+1 ⊕ Sl + blc,s), (4)\nwhere ⊕ denotes the concatenation operation, and W lc,s ∈ Rd×2d and blc,s ∈ Rd refer to the weight and bias.\nWith the node representation and the three adjacent matrices, the standard graph convolution is then\nperformed on the input nodes to obtain ĈS l ∈ Rm×d:\nC̃S l\nk = f(W l kĈS\nl M c−k), (5)\nwhere W lk ∈ Rd×d and bias are learnable parameters. Finally, we can obtain the category-oriented sentiment representation Sl+1 as follows:\nSl+1 = max pooling\n(dense(C̃S l pos); dense(C̃S l neg); dense(C̃S l neu)), (6)\nwhere dense(·) is a parameter sharing feed-forward network with tanh as the activation function."
    }, {
      "heading" : "3.4 Hierarchical Prediction Integration",
      "text" : "Based on the final category representation XLi and sentiment representation S L i generated from the Llayer Hier-GCN, we can obtain the probability of having the i-th category ŷci ∈ R1 and its corresponding sentiment probability distribution ŷpi ∈ R3 as follows:\nŷci = sigmoid(W c i X L i + b c i ), (7) ŷpi = softmax(W pSLi + b p), (8)\nwhere the parameters W p and bp are used for sentiment classification, which is shared for all categories. Then, Hierarchical Prediction Module is used to get the final prediction of the i-th category sentiment ŷc,pi ∈ R3: ŷc,pi = I(ŷci > σ) ŷ p i , (9)\nwhere I(·) is indicator function, σ is the threshold of category detection, is Logical AND operation between category and its corresponding sentiment polarity prediction.\nThe loss of ACSA has two parts. Since category detection task is modeled as a multi-label classification problem, the loss function is defined as:\nlossc = − m∑ i=1 yci logŷ c i + (1− yci )log(1− ŷci ), (10)\nwhere yci is the ground truth of the i-th category. The sentiment classification task is treated as multi-class classification problem, and the loss function is defined as:\nlossp = − m∑ i=1 3∑ j=1 I(ypi,j)logŷ p i,j , (11)\nwhere yp is the ground truth of sentiment polarity. Our final objective function is a simple combination of the two parts as follows:\nlossall = lossc + lossp (12)"
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Datasets and Evaluation Metrics",
      "text" : "We evaluate our model on the benchmark SemEval 2015 and 2016 datasets (Pontiki et al., 2015; Pontiki et al., 2016), which contain customer reviews from laptop and restaurant domains.To ensure that aspect category can accurately describe an opinion expression object, a category is predefined as specific entity type E and its attribute label A in SemEval 2015 and 2016 datasets. The E#A pair defines an aspect category. The details of the data sets are summarized in Table 1. We compute the Precision, Recall of the predicted (category, sentiment) pairs respectively, and use Micro-F1 score as the final evaluation metric."
    }, {
      "heading" : "4.2 Experimental Settings",
      "text" : "We randomly split the training set into the ratio of 9:1 as training, validation set. The reported results are averaged scores of 10 runs to obtain statistically stable results. We use BERT-base as basic encoder, and refer readers to (Devlin et al., 2018) for the detailed BERT-base model setting. We adopt the same AdamW optimizer in BERT. The learning rate and batch size are set to 5e-5 and 8, respectively. We set the maximum sentence length to 128 for SemEval 2015 and 100 for SemEval 2016, and run 20 epochs for every fold, a dropout rate of 0.1 is used, and the hidden size of Transformer is 768, the threshold σ is set to 0.5 for category detection."
    }, {
      "heading" : "4.3 Compared Systems",
      "text" : "In Section 2, we have summarized several problem formalization methods including Cartesian, Add one dimension. We use them as baseline systems for comparison. We furthermore implement a pipeline method of category detection and sentiment classification. All compared systems are as follows:\n• Cartesian-BERT: The Cartesian method with BERT as the sentence encoder.\n• Pipeline-BERT: Pipeline of individual aspect category detection and category sentiment classification, both with BERT as the review encoder. This method can better model each sub-task, but ignores the associations between two sub-tasks. • AddOneDim-LSTM: The Add one dimension method with LSTM as the sentence encoder. This\nrepresents the state-of-the-art work by (Schmitt et al., 2018). • AddOneDim-BERT: The Add one dimension method with BERT as the sentence encoder. • Hier-BERT: The hierarchy method with BERT as the sentence encoder. • Hier-Transformer-BERT: As a strong baseline, we use Transformer to model the inner-relations\nbetween category and inter-relations between category and sentiment based on Hier-BERT. • Hier-GCN-BERT: Our proposed hierarchy prediction model with Hier-GCN as the relation learn-\ning module based on Hier-BERT.\nIt should be noted that except AddOneDim-LSTM, all the other systems are proposed in this work."
    }, {
      "heading" : "4.4 Main Results",
      "text" : "Table 2 shows the results of different systems on two datasets. It can be observed that AddOneDimLSTM seems difficult to achieve good performance when the number of categories is large. For example, in the Laptop dataset, the training algorithm fails to converge. In comparison, AddOneDim-BERT can perform much better. Cartesian-BERT is less effective probably due to the class-parse problem especially when the number of categories is large (e.g., Recall on Laptop is very low). The precision of the pipeline method is low although its recall is high, because it ignores the relations among sub-tasks and leads to too many sentiment predictions without taking category-sentiment restriction into consideration. This also indicates that our proposed category-sentiment hierarchy structure is more suitable for joint aspect category detection and category-oriented sentiment classification.\nWe can see that among all systems, our hierarchical methods (Hier, Hier-Transfomer-BERT, HierGCN-BERT) achieves significantly better F1 performance than the other baseline systems, among which, Hier-GCN-BERT gets the best performance on three datasets. This indicates that the modeling of hierarchical relationship can better describe the original problem on the basis of hierarchical label prediction."
    }, {
      "heading" : "4.5 Discussions on Hier-GCN",
      "text" : ""
    }, {
      "heading" : "4.5.1 GCN vs Transformer",
      "text" : "In Table 2, we further present the result of Hier-Transformer-BERT where we replace GCN with Transformer to learn the relations among categories and sentiments. The layers of Transformer is kept the same as that in Hier-GCN-BERT. The first Transformer layer is used to model the inner-relation between categories, and the second layer is used to capture the inter-relation between category and sentiment. It can be found that Hier-Transformer-BERT is quite efficient but still lower than Hier-GCN-BERT on three datasets, only slightly better on Restaurant 2015. The improvement of GCN upon Transformer is more significant when the number of categories is larger (e.g., the Laptop dataset), due to the GCN’s ability in learning the inner-relations between categories and inter-relations between category and sentiment."
    }, {
      "heading" : "4.5.2 Ablation Study",
      "text" : "In Table 3, we present the ablation study results by testing the effectiveness of each component in HierGCN-BERT.\nRestaurant-16 Laptop-16 Restaurant-15 Laptop-15 1 layer 71.80 47.02 60.69 49.27 2 layers 74.55 54.15 64.23 62.13 3 layers 72.75 54.01 63.18 60.21\nTable 4: Impact of the number of layers in HierGCN-BERT.\n• C-GCN-BERT: only category GCN without category-sentiment GCN; • CS-GCN-BERT: only category-sentiment GCN without category GCN.\nIt can be seen that both C-GCN-BERT and CS-GCN-BERT have incremental effects compared with the basic hierarchy prediction model Hier-BERT. Among two sub-GCNs, category GCN plays a more important role than category-sentiment GCN, because it captures the inner-relations among multiple categories and lays the basis of the following category-sentiment inter-relation learning."
    }, {
      "heading" : "4.5.3 Impact of the Number of Hier-GCN Layers",
      "text" : "We further investigate the impact of the number of Hier-GCN layers L. Considering the over-smoothing problem caused by high co-occurrence nodes, we vary L from 1 to 3, and reports the results in Table 4. The best performance is obtained when L = 2. Layers more than 3 in GCN may incorporate too much node co-occurrence information and result in non-discriminative representations."
    }, {
      "heading" : "4.6 Results on Implicit Aspects",
      "text" : "As we have mentioned in Table 2, there are nearly 25% of aspect terms are not annotated in the Restaurant 2015 dataset. We refer to them as implicit aspects. To test our approach’s ability to capture the implicit aspects, we split the Restaurant 2015 test set into two parts: Explicit Aspects (containing 212 samples) and Implicit Aspects (containing 360 samples), and report the performance of category-sentiment hierarchy prediction in Table 6. We find that although the performance of our approaches on the Implicit Aspects part is lower than the Explicit Aspects part, it can still accurately identify a considerable amount of category and sentiment pairs, and outperform all the compared systems in implicit aspects.\nCase study: In order to verify the advantages of Hier-GCN-BERT in detecting categories and predicting category sentiment polarity intuitively. We further study cases of approaches AddOneDim-BERT, Hier-BERT and Hier-GCN-BERT on implicit aspects of Restaurant 2015. As shown in Table 6, review Once you try it for a special occasion beware.. you can’t stop! implies positive sentiment towards category miscellaneous of restaurant, only AddOneDim-BERT cannot detect the corresponding category. Review I have never ever had such an unpleasant experience. implies general negative sentiment towards category restaurant, AddOneDim-BERT cannot detect the mentioned category, while Hier-BERT detects the mentioned category correctly, but predicts the sentiment polarity as positive. Only Hier-GCN-BERT predicts the category-sentiment pairs correctly. Besides, in a complex context with both implicit and explicit aspects, Hier-GCN-BERT can still perform better. Review Highly impressed from the decor to the food to the hospitality to the great night I had! has two explicit aspects and two implicit aspects, all approaches can predict the explicit aspects, while only Hier-GCN-BERT finds one more implicit category-sentiment pair."
    }, {
      "heading" : "5 Related Work",
      "text" : "Aspect-Based Sentiment Analysis: We have witnessed recent extensive studies of the Aspect-Based Sentiment Analysis task. Most existing approaches can be categorized into two branches, namely Aspect Term-based Sentiment Analysis (ATSA) and Aspect Category-based Sentiment Analysis (ACSA).\nATSA aims to detect the aspect term and identify their corresponding sentiment polarities given a piece of text. (Mitchell et al., 2013) first explored the end-to-end task by applying traditional approaches with shallow features to extract aspect terms and their sentiments jointly. Later, (Zhang et al., 2015) extended the above approach by designing several neural models, and achieved better performance. Based on this, (Li et al., 2019) proposed a unified neural architecture with multi-task learning for the task. (Luo et al., 2019) proposed a joint model to solve the problem. Moreover, (Hu et al., 2019) designed a span extraction-based neural framework and addressed the problem in an extract-then-classify manner.\nDifferent from ATSA, ACSA targets at identifying the aspect category as well as its corresponding sentiment. Most existing studies on ACSA focused on its sub-tasks, namely, the aspect category detection (ACD) and category-oriented sentiment classification (CSC). For the task of ACD, (Zhou et al., 2015; Schouten et al., 2017) proposed algorithms to predict categories. More recently, (Movahedi et al., 2019) proposed an attention-based neural network method to identify different aspect categories based on different topics. For the task of CSC, (Ruder et al., 2016; Wang et al., 2016; Xue and Li, 2018; Tay et al., 2018) proposed neural networks to make the most of context and aspect category information. Apart from the researches on the two subtasks, there are a few studies focusing on the end-to-end ACSA task. For example, (Schmitt et al., 2018) proposed a joint model and transform the task into a multi-class classification problem. However, most of these studies fail to explore the relations between ACD and CSC. Therefore, we propose a hierarchical graph convolutional network to achieve this goal.\nHierarchical Classification & GCN: The hierarchical classification problem has been studied in some previous work. (Silla and Freitas, 2011) defined the task of hierarchical classification and presented a new perspective about hierarchical classification approaches, (Aly et al., 2019) investigated simple shallow capsule networks for hierarchical multi-label text classification. GCN can be used for non-Euclidean Structure data, (Bruna et al., 2013) proposed spectral graph convolutional neural networks, and (Kipf and Welling, 2016) designed a convolutional architecture via a localized first-order approximation of spectral graph convolutions. Inspired by these work, we propose a BERT-based Hier-GCN model, which decomposes the inner-relations between aspect categories and the inter-relations between sentiment polarities into two hierarchically related sub-graphs and get the final predictions in hierarchy manner."
    }, {
      "heading" : "6 Conclusion",
      "text" : "In this paper, we first examined the limitations of existing approaches for the task of Aspect Categorybased Sentiment Analysis, and proposed a hierarchy output structure to first detect the aspect categories, and then perform sentiment classification for each detected category. Given the output structure, we further proposed a Hierarchical Graph Convolutional Network to capture the inner-relations between multiple categories as well as the inter-relations between categories and sentiments. Experimental results on four benchmark datasets show that our hierarchy output structure performs significantly better than any existing output structure, and Hier-GCN can outperform a number of highly competive approaches including a strong hierarchical Transformer model proposed by us."
    } ],
    "references" : [ {
      "title" : "Hierarchical multi-label classification of text with capsule networks",
      "author" : [ "Rami Aly", "Steffen Remus", "Chris Biemann." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop, pages 323–330.",
      "citeRegEx" : "Aly et al\\.,? 2019",
      "shortCiteRegEx" : "Aly et al\\.",
      "year" : 2019
    }, {
      "title" : "Spectral networks and locally connected networks on graphs",
      "author" : [ "Joan Bruna", "Wojciech Zaremba", "Arthur Szlam", "Yann LeCun." ],
      "venue" : "arXiv preprint arXiv:1312.6203.",
      "citeRegEx" : "Bruna et al\\.,? 2013",
      "shortCiteRegEx" : "Bruna et al\\.",
      "year" : 2013
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "Open-domain targeted sentiment analysis via span-based extraction and classification",
      "author" : [ "Minghao Hu", "Yuxing Peng", "Zhen Huang", "Dongsheng Li", "Yiwei Lv." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 537–546.",
      "citeRegEx" : "Hu et al\\.,? 2019",
      "shortCiteRegEx" : "Hu et al\\.",
      "year" : 2019
    }, {
      "title" : "Semi-supervised classification with graph convolutional networks",
      "author" : [ "Thomas N Kipf", "Max Welling." ],
      "venue" : "arXiv preprint arXiv:1609.02907.",
      "citeRegEx" : "Kipf and Welling.,? 2016",
      "shortCiteRegEx" : "Kipf and Welling.",
      "year" : 2016
    }, {
      "title" : "A unified model for opinion target extraction and target sentiment prediction",
      "author" : [ "Xin Li", "Lidong Bing", "Piji Li", "Wai Lam." ],
      "venue" : "Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 6714–6721.",
      "citeRegEx" : "Li et al\\.,? 2019",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2019
    }, {
      "title" : "Sentiment analysis and opinion mining",
      "author" : [ "Bing Liu." ],
      "venue" : "Synthesis lectures on human language technologies, 5(1):1–167.",
      "citeRegEx" : "Liu.,? 2012",
      "shortCiteRegEx" : "Liu.",
      "year" : 2012
    }, {
      "title" : "Doer: Dual cross-shared rnn for aspect term-polarity co-extraction",
      "author" : [ "Huaishao Luo", "Tianrui Li", "Bing Liu", "Junbo Zhang." ],
      "venue" : "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 591–601.",
      "citeRegEx" : "Luo et al\\.,? 2019",
      "shortCiteRegEx" : "Luo et al\\.",
      "year" : 2019
    }, {
      "title" : "Open domain targeted sentiment",
      "author" : [ "Margaret Mitchell", "Jacqui Aguilar", "Theresa Wilson", "Benjamin Van Durme." ],
      "venue" : "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1643–1654.",
      "citeRegEx" : "Mitchell et al\\.,? 2013",
      "shortCiteRegEx" : "Mitchell et al\\.",
      "year" : 2013
    }, {
      "title" : "Aspect category detection via topicattention network",
      "author" : [ "Sajad Movahedi", "Erfan Ghadery", "Heshaam Faili", "Azadeh Shakery." ],
      "venue" : "arXiv preprint arXiv:1901.01183.",
      "citeRegEx" : "Movahedi et al\\.,? 2019",
      "shortCiteRegEx" : "Movahedi et al\\.",
      "year" : 2019
    }, {
      "title" : "Opinion mining and sentiment analysis",
      "author" : [ "Bo Pang", "Lillian Lee" ],
      "venue" : "Foundations and Trends R",
      "citeRegEx" : "Pang and Lee,? \\Q2008\\E",
      "shortCiteRegEx" : "Pang and Lee",
      "year" : 2008
    }, {
      "title" : "Semeval-2015 task 12: Aspect based sentiment analysis",
      "author" : [ "Maria Pontiki", "Dimitrios Galanis", "Harris Papageorgiou", "Suresh Manandhar", "Ion Androutsopoulos." ],
      "venue" : "Proceedings of the 9th international workshop on semantic evaluation (SemEval 2015), pages 486–495.",
      "citeRegEx" : "Pontiki et al\\.,? 2015",
      "shortCiteRegEx" : "Pontiki et al\\.",
      "year" : 2015
    }, {
      "title" : "Semeval-2016 task 5: Aspect based sentiment analysis",
      "author" : [ "Maria Pontiki", "Dimitrios Galanis", "Haris Papageorgiou", "Ion Androutsopoulos", "Suresh Manandhar", "Mohammad AlSmadi", "Mahmoud Al-Ayyoub", "Yanyan Zhao", "Bing Qin", "Orphée De Clercq" ],
      "venue" : "In 10th International Workshop on Semantic Evaluation (SemEval",
      "citeRegEx" : "Pontiki et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Pontiki et al\\.",
      "year" : 2016
    }, {
      "title" : "A hierarchical model of reviews for aspect-based sentiment analysis",
      "author" : [ "Sebastian Ruder", "Parsa Ghaffari", "John G Breslin." ],
      "venue" : "Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 999–1005.",
      "citeRegEx" : "Ruder et al\\.,? 2016",
      "shortCiteRegEx" : "Ruder et al\\.",
      "year" : 2016
    }, {
      "title" : "Joint aspect and polarity classification for aspect-based sentiment analysis with end-to-end neural networks",
      "author" : [ "Martin Schmitt", "Simon Steinheber", "Konrad Schreiber", "Benjamin Roth." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1109–1114.",
      "citeRegEx" : "Schmitt et al\\.,? 2018",
      "shortCiteRegEx" : "Schmitt et al\\.",
      "year" : 2018
    }, {
      "title" : "Supervised and unsupervised aspect category detection for sentiment analysis with co-occurrence data",
      "author" : [ "Kim Schouten", "Onne Van Der Weijde", "Flavius Frasincar", "Rommert Dekker." ],
      "venue" : "IEEE transactions on cybernetics, 48(4):1263–1275.",
      "citeRegEx" : "Schouten et al\\.,? 2017",
      "shortCiteRegEx" : "Schouten et al\\.",
      "year" : 2017
    }, {
      "title" : "A survey of hierarchical classification across different application domains",
      "author" : [ "Carlos N Silla", "Alex A Freitas." ],
      "venue" : "Data Mining and Knowledge Discovery, 22(1-2):31–72.",
      "citeRegEx" : "Silla and Freitas.,? 2011",
      "shortCiteRegEx" : "Silla and Freitas.",
      "year" : 2011
    }, {
      "title" : "Learning to attend via word-aspect associative fusion for aspect-based sentiment analysis",
      "author" : [ "Yi Tay", "Luu Anh Tuan", "Siu Cheung Hui." ],
      "venue" : "Thirty-Second AAAI Conference on Artificial Intelligence.",
      "citeRegEx" : "Tay et al\\.,? 2018",
      "shortCiteRegEx" : "Tay et al\\.",
      "year" : 2018
    }, {
      "title" : "Attention-based lstm for aspect-level sentiment classification",
      "author" : [ "Yequan Wang", "Minlie Huang", "Xiaoyan Zhu", "Li Zhao." ],
      "venue" : "Proceedings of the 2016 conference on empirical methods in natural language processing, pages 606–615.",
      "citeRegEx" : "Wang et al\\.,? 2016",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2016
    }, {
      "title" : "Aspect based sentiment analysis with gated convolutional networks",
      "author" : [ "Wei Xue", "Tao Li." ],
      "venue" : "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2514–2523.",
      "citeRegEx" : "Xue and Li.,? 2018",
      "shortCiteRegEx" : "Xue and Li.",
      "year" : 2018
    }, {
      "title" : "Neural networks for open domain targeted sentiment",
      "author" : [ "Meishan Zhang", "Yue Zhang", "Duy-Tin Vo." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 612–621.",
      "citeRegEx" : "Zhang et al\\.,? 2015",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2015
    }, {
      "title" : "Representation learning for aspect category detection in online reviews",
      "author" : [ "Xinjie Zhou", "Xiaojun Wan", "Jianguo Xiao." ],
      "venue" : "Twenty-Ninth AAAI Conference on Artificial Intelligence.",
      "citeRegEx" : "Zhou et al\\.,? 2015",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2015
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "As an important fine-grained subtask in the field of sentiment analysis, Aspect-Based Sentiment Classification (ABSC) (Pang et al., 2008; Liu, 2012) aims to detect the sentiment polarities of aspect terms mentioned in review text.",
      "startOffset" : 118,
      "endOffset" : 148
    }, {
      "referenceID" : 8,
      "context" : "To address this problem, many studies have been proposed to explore Aspect Term-based Sentiment Analysis (ATSA), which performs aspect term extraction and aspect sentiment classification jointly (Mitchell et al., 2013; Zhang et al., 2015; Li et al., 2019; Luo et al., 2019; Hu et al., 2019).",
      "startOffset" : 195,
      "endOffset" : 290
    }, {
      "referenceID" : 20,
      "context" : "To address this problem, many studies have been proposed to explore Aspect Term-based Sentiment Analysis (ATSA), which performs aspect term extraction and aspect sentiment classification jointly (Mitchell et al., 2013; Zhang et al., 2015; Li et al., 2019; Luo et al., 2019; Hu et al., 2019).",
      "startOffset" : 195,
      "endOffset" : 290
    }, {
      "referenceID" : 5,
      "context" : "To address this problem, many studies have been proposed to explore Aspect Term-based Sentiment Analysis (ATSA), which performs aspect term extraction and aspect sentiment classification jointly (Mitchell et al., 2013; Zhang et al., 2015; Li et al., 2019; Luo et al., 2019; Hu et al., 2019).",
      "startOffset" : 195,
      "endOffset" : 290
    }, {
      "referenceID" : 7,
      "context" : "To address this problem, many studies have been proposed to explore Aspect Term-based Sentiment Analysis (ATSA), which performs aspect term extraction and aspect sentiment classification jointly (Mitchell et al., 2013; Zhang et al., 2015; Li et al., 2019; Luo et al., 2019; Hu et al., 2019).",
      "startOffset" : 195,
      "endOffset" : 290
    }, {
      "referenceID" : 3,
      "context" : "To address this problem, many studies have been proposed to explore Aspect Term-based Sentiment Analysis (ATSA), which performs aspect term extraction and aspect sentiment classification jointly (Mitchell et al., 2013; Zhang et al., 2015; Li et al., 2019; Luo et al., 2019; Hu et al., 2019).",
      "startOffset" : 195,
      "endOffset" : 290
    }, {
      "referenceID" : 14,
      "context" : "(Schmitt et al., 2018) proposed a joint model by extending sentiment labels with one more dimension to indicate the occurrence of each aspect category, which is shown to outperform traditional pipeline methods.",
      "startOffset" : 0,
      "endOffset" : 22
    }, {
      "referenceID" : 14,
      "context" : "Since Cartesian Product suffers from the risk of generating multiple sentiments for each category, an alternative solution is to add one label to the sentiment label space to predict the presence or absence of each category (Schmitt et al., 2018).",
      "startOffset" : 224,
      "endOffset" : 246
    }, {
      "referenceID" : 2,
      "context" : "For space limitation, we omit a detailed description of BERT and refer readers to (Devlin et al., 2018).",
      "startOffset" : 82,
      "endOffset" : 103
    }, {
      "referenceID" : 2,
      "context" : "Besides, following the practice in (Devlin et al., 2018), we employ the last hidden state of the first token [CLS] as the shared sentiment representation for each category, denoted by S ∈ Rd.",
      "startOffset" : 35,
      "endOffset" : 56
    }, {
      "referenceID" : 11,
      "context" : "1 Datasets and Evaluation Metrics We evaluate our model on the benchmark SemEval 2015 and 2016 datasets (Pontiki et al., 2015; Pontiki et al., 2016), which contain customer reviews from laptop and restaurant domains.",
      "startOffset" : 104,
      "endOffset" : 148
    }, {
      "referenceID" : 12,
      "context" : "1 Datasets and Evaluation Metrics We evaluate our model on the benchmark SemEval 2015 and 2016 datasets (Pontiki et al., 2015; Pontiki et al., 2016), which contain customer reviews from laptop and restaurant domains.",
      "startOffset" : 104,
      "endOffset" : 148
    }, {
      "referenceID" : 2,
      "context" : "We use BERT-base as basic encoder, and refer readers to (Devlin et al., 2018) for the detailed BERT-base model setting.",
      "startOffset" : 56,
      "endOffset" : 77
    }, {
      "referenceID" : 14,
      "context" : "This represents the state-of-the-art work by (Schmitt et al., 2018).",
      "startOffset" : 45,
      "endOffset" : 67
    }, {
      "referenceID" : 8,
      "context" : "(Mitchell et al., 2013) first explored the end-to-end task by applying traditional approaches with shallow features to extract aspect terms and their sentiments jointly.",
      "startOffset" : 0,
      "endOffset" : 23
    }, {
      "referenceID" : 20,
      "context" : "Later, (Zhang et al., 2015) extended the above approach by designing several neural models, and achieved better performance.",
      "startOffset" : 7,
      "endOffset" : 27
    }, {
      "referenceID" : 5,
      "context" : "Based on this, (Li et al., 2019) proposed a unified neural architecture with multi-task learning for the task.",
      "startOffset" : 15,
      "endOffset" : 32
    }, {
      "referenceID" : 7,
      "context" : "(Luo et al., 2019) proposed a joint model to solve the problem.",
      "startOffset" : 0,
      "endOffset" : 18
    }, {
      "referenceID" : 3,
      "context" : "Moreover, (Hu et al., 2019) designed a span extraction-based neural framework and addressed the problem in an extract-then-classify manner.",
      "startOffset" : 10,
      "endOffset" : 27
    }, {
      "referenceID" : 21,
      "context" : "For the task of ACD, (Zhou et al., 2015; Schouten et al., 2017) proposed algorithms to predict categories.",
      "startOffset" : 21,
      "endOffset" : 63
    }, {
      "referenceID" : 15,
      "context" : "For the task of ACD, (Zhou et al., 2015; Schouten et al., 2017) proposed algorithms to predict categories.",
      "startOffset" : 21,
      "endOffset" : 63
    }, {
      "referenceID" : 9,
      "context" : "More recently, (Movahedi et al., 2019) proposed an attention-based neural network method to identify different aspect categories based on different topics.",
      "startOffset" : 15,
      "endOffset" : 38
    }, {
      "referenceID" : 13,
      "context" : "For the task of CSC, (Ruder et al., 2016; Wang et al., 2016; Xue and Li, 2018; Tay et al., 2018) proposed neural networks to make the most of context and aspect category information.",
      "startOffset" : 21,
      "endOffset" : 96
    }, {
      "referenceID" : 18,
      "context" : "For the task of CSC, (Ruder et al., 2016; Wang et al., 2016; Xue and Li, 2018; Tay et al., 2018) proposed neural networks to make the most of context and aspect category information.",
      "startOffset" : 21,
      "endOffset" : 96
    }, {
      "referenceID" : 19,
      "context" : "For the task of CSC, (Ruder et al., 2016; Wang et al., 2016; Xue and Li, 2018; Tay et al., 2018) proposed neural networks to make the most of context and aspect category information.",
      "startOffset" : 21,
      "endOffset" : 96
    }, {
      "referenceID" : 17,
      "context" : "For the task of CSC, (Ruder et al., 2016; Wang et al., 2016; Xue and Li, 2018; Tay et al., 2018) proposed neural networks to make the most of context and aspect category information.",
      "startOffset" : 21,
      "endOffset" : 96
    }, {
      "referenceID" : 14,
      "context" : "For example, (Schmitt et al., 2018) proposed a joint model and transform the task into a multi-class classification problem.",
      "startOffset" : 13,
      "endOffset" : 35
    }, {
      "referenceID" : 16,
      "context" : "(Silla and Freitas, 2011) defined the task of hierarchical classification and presented a new perspective about hierarchical classification approaches, (Aly et al.",
      "startOffset" : 0,
      "endOffset" : 25
    }, {
      "referenceID" : 0,
      "context" : "(Silla and Freitas, 2011) defined the task of hierarchical classification and presented a new perspective about hierarchical classification approaches, (Aly et al., 2019) investigated simple shallow capsule networks for hierarchical multi-label text classification.",
      "startOffset" : 152,
      "endOffset" : 170
    }, {
      "referenceID" : 1,
      "context" : "GCN can be used for non-Euclidean Structure data, (Bruna et al., 2013) proposed spectral graph convolutional neural networks, and (Kipf and Welling, 2016) designed a convolutional architecture via a localized first-order approximation of spectral graph convolutions.",
      "startOffset" : 50,
      "endOffset" : 70
    }, {
      "referenceID" : 4,
      "context" : ", 2013) proposed spectral graph convolutional neural networks, and (Kipf and Welling, 2016) designed a convolutional architecture via a localized first-order approximation of spectral graph convolutions.",
      "startOffset" : 67,
      "endOffset" : 91
    } ],
    "year" : 2020,
    "abstractText" : "Most of the aspect based sentiment analysis research aims at identifying the sentiment polarities toward some explicit aspect terms while ignores implicit aspects in text. To capture both explicit and implicit aspects, we focus on aspect-category based sentiment analysis, which involves joint aspect category detection and category-oriented sentiment classification. However, currently only a few simple studies have focused on this problem. The shortcomings in the way they defined the task make their approaches difficult to effectively learn the inner-relations between categories and the inter-relations between categories and sentiments. In this work, we re-formalize the task as a category-sentiment hierarchy prediction problem, which contains a hierarchy output structure to first identify multiple aspect categories in a piece of text, and then predict the sentiment for each of the identified categories. Specifically, we propose a Hierarchical Graph Convolutional Network (Hier-GCN), where a lower-level GCN is to model the inner-relations among multiple categories, and the higher-level GCN is to capture the inter-relations between aspect categories and sentiments. Extensive evaluations demonstrate that our hierarchy output structure is superior over existing ones, and the Hier-GCN model can consistently achieve the best results on four benchmarks.",
    "creator" : "TeX"
  }
}