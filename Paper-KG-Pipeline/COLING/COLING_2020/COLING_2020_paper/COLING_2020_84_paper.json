{
  "name" : "COLING_2020_84_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Automatic Distractor Generation for Multiple Choice Questions in Standard Tests",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Standard test, such as TOFEL and SAT, is an efficient and essential tool to assess knowledge proficiency of a learner (Ch and Saha, 2018). According to testing results, teachers or ITS (Intelligent Tutoring System) services can develop personalized study plans for different students. When organizing a standard test, a vital issue is to select a suitable question form. Among various question forms, multiple choice question (MCQ) is widely adopted in many notable tests, such as GRE, TOFEL and SAT. MCQs have many advantages including less testing time, more objective and easy on the grader (Ch and Saha, 2018). A typical MCQ consists of a stem and several candidate answers, among which one is correct, the rest are distractors. As shown in Figure 1, in addition to a stem, some tests also include a long reading passage to provide the context of this MCQ.\nThe quality of an MCQ depends heavily on the quality of the distractors. If the distractors can not confuse students, the correct answer could be concluded easily. As a result, the discrimination of the question will degrade, and the test will also lose the ability of the assessment.\nHowever, it is a challenging job to design useful and qualified distractors. Rather than being a trivial wrong answer, the distractor should have the plausibility which confuses learners who did not master the knowledge (Liang et al., 2018). A good distractor should be grammatically correct given the question and semantically consistent with the passage context of the question (Gao et al., 2018). Meanwhile, the question composers need to enhance the plausibility of the distractor without hurting its inherent incorrectness. Otherwise, the distractor easily becomes a definitely wrong answer, further making the question to be sloppy. Hence, the manual preparation of distractors is time-consuming and costly (Ha and Yaneva, 2018). It is an urgent issue to automatically generate useful distractors, which can help to alleviate question composers’ workload and relax the restrictions on experience. It could also be helpful to prepare a large train set to boost the machine reading comprehension (MRC) systems (Yang et al., 2017). In this paper, we focus on automatically generating semantic-rich distractors for MCQs in realworld standard tests, such as RACE (Lai et al., 2017) which is collected from the English exams for Chinese students from grades 7 to 12.\nManuscript submitted to ACM\nExisting works conduct some attempts on generating short distractors (Stasaski and Hearst, 2017; Guo et al., 2016). These approaches formulate distractor generation as a similar word selection task. They leverage the pre-defined ontology or word embeddings to find similar words/entities of the correct answer as the generated distractors. These word-level or entity-level methods can only generate short distractors and do not apply to semantic-rich and long distractors for RACE-like MCQs. Recently, generating longer distractors has been explored in a few studies (Zhou et al., 2019; Gao et al., 2018). For example, Gao et al. (2018) proposes a sequence-to-sequence based model, which leverages the attention mechanism to automatically generate distractors from the reading passages. However, these methods mainly focus on the relation between the distractor and the passage and fail to comprehensively model the interactions among the passage, question and correct answer which helps to ensure the incorrectness of the generated distractors.\nTo better generate useful distractors, we propose a novel quEstion and answer guided Distractor GEneration (EDGE) framework. More specifically, given the passage, the question and the correct answer, we first leverage a contextual encoder to generate the semantic representations for all text materials. Then we use the attention mechanism to enrich the context of the question and the correct answer. Next, we break down the distractor’s usefulness into two aspects: the incorrectness and plausibility. Incorrectness is the inherent attribute of the distractor, while plausibility refers to the ability to confuse the students. We introduce two modules by leveraging the gate layer to guarantee the incorrectness: Reforming Question Module and Reforming Passage Module. We further leverage an attention-based distractor generator, plus the previous two reforming modules, to guarantee the plausibility. Finally, in the generation stage, we use the beam search to generate several diverse distractors by controlling their distances. We conduct experiments on a large-scale public distractor generation dataset prepared from RACE. The experimental results demonstrate the effectiveness of our proposed framework. Moreover, our method achieves a new state-of-the-art result in the distractor generation task."
    }, {
      "heading" : "2 Related work",
      "text" : "In recent years, some research efforts have devoted to distractor generation. Generally, the related work can be classified into the following three categories.\nFeature-based methods. Considerable research efforts (Liang et al., 2018; Sakaguchi et al., 2013; Araki et al., 2016) have been devoted to using manual design features, such as POS features and statistic features, to generate the distractors. However, designing effective features is also labor intensive and hard to scale to various domains. Differently, our work is an end-to-end framework without manual design features.\nSimilar word/entity-based methods. Some works (Stasaski and Hearst, 2017; Guo et al., 2016; Kumar et al., 2015; Afzal and Mitkov, 2014) focused on finding answer-relevant ontologies or words as the distractors with the help of WordNet and Word2Vec. For example, Stasaski and Hearst (2017) leveraged an educational Biology ontology to conduct the distractor generation. However, some of these works depend heavily on the well-designed ontology and they can only generate short distractors, which usually only contain one single word or phrase.\nNN-based methods. Recently, neural network based and data-driven solutions emerge. Gao et al.\n(2018) proposed an end-to-end solution focusing on distractor generation for MCQs in standard English tests. They employed the hierarchical encoder-decoder network as the base model and used the dynamic attention mechanism to generate the long distractors. Zhou et al. (2019) further strengthened the interaction between the question and the passage based on the model of (Gao et al., 2018)."
    }, {
      "heading" : "3 Framework Description",
      "text" : ""
    }, {
      "heading" : "3.1 Problem Definition",
      "text" : "In this paper, we focus on the automatic distractor generation for MCQs (see Figure 1). Let P = {wpt } t=Lp t=1 denote the reading passage, which consists of Lp words. Let Q = {w q t } t=Lq t=1 and A = {wat } t=La t=1 denote the question and its correct answer, respectively. Lq and La denote the lengths of the question and the answer, respectively. Note that the answer may not be a span of the passage P .\nProblem Definition. Formally, given the reading passage P , the question Q and its correct answer A as inputs, an EDGE modelM aims to generate a distractor D = {wdt } t=Ld t=1 about the question, which is defined as finding the best distractor D that maximizes the conditional likelihood given P , Q, and A:\nD = argmax D\nlog Pr(D|P,Q,A)"
    }, {
      "heading" : "3.2 Framework Overview",
      "text" : "Inspired by existing question generation works (Duan et al., 2017; Du and Cardie, 2017; Zhou et al., 2017; Kim et al., 2018), we employ a sequence-to-sequence based network to generate the distractors. As shown in Figure 2, our overall framework contains five components. First, we employ the encoding module to extract the contextual semantic representations for all materials. Then, we use the attention mechanism to enrich the semantic representations of the question and its answer. Finally, we design three key components to generate useful distractors.\nAs mentioned above, the quality of the generated distractor are guaranteed from two aspects:\n• Incorrectness: Both the passage and the question contain some parts strongly relevant to the answer, which may disorder the decoder to output the words contained by the answer and further hurt the inherent incorrectness of generated distractors. To guarantee the incorrectness, in our proposed framework, we reform the passage and question by erasing their answer-relevant information before they are fed into the decoder. Based on the gate mechanism, the two reforming modules highlight the distractor-relevant words and constrain the answer-relevant words by measuring the distances between the words and the correct answer.\n• Plausibility: To look reasonable, the distractor first should be grammatically and semantically consistent with the question. Otherwise, after reading the question, the students can trivially exclude it. Furthermore, to hinder students from excluding the distractor only by reading the passage, it should also be semantically relevant to the passage. To guarantee the plausibility, in our proposed framework, the distractor generator uses the semantic representation of the reformed question to initialize the generation process and leverages the attention mechanism to obtain the context representation from the reformed passage to guide the output.\nWe will address each component in detail in the following subsections."
    }, {
      "heading" : "3.3 Encoding and Enriching Module",
      "text" : "In the encoding module, given a passage P = {wpt } t=Lp t=1 , a question Q = {w q t } t=Lq t=1 and its answer A = {wat } t=La t=1 , we first convert every word w to its d-dimensional vector e via an embedding matrix E ∈ R|V |×d, where V is the vocabulary and d is the dimension of word embedding. Then we use the encoder to extract the contextual representation for each word. The outputs of the contextual encoder are three matrices: P ∈ RLp×d, Q ∈ RLq×d, and A ∈ RLa×d.\nNext, we introduce the attention layer and the fusion layer to enrich the semantic representations of the question and its answer by fusing the passage information. In the enriching module, we adopt the\nscaled dot product attention mechanism and the fusion kernel used in recent works (Chen et al., 2017; Mou et al., 2016) for better semantic understanding.\nMq = Attn(Q,P) = softmax( QP>√\nd )\nQ̃ = Fuse(Q,Q) = tanh([Q;Q;Q−Q;Q ◦Q]Wf + bf ) where Q = MqP\nwhere Wf ∈ R4d×d and bf ∈ Rd are the parameters to learn. [; ] denotes the column-wise concatenation. ◦ and − denote the element-wise multiplication and subtraction between two matrices, respectively. Mq ∈ RLq×Lp denotes the attention weight matrix.\nFor the answer A, we can also obtain the enriched representation Ã via the same attention and fusion process."
    }, {
      "heading" : "3.4 Reforming Question Module",
      "text" : "As mentioned above, to retain the inherent incorrectness of the distractors, we need to reform the question by constraining the answer-relevant parts. In this module, we first evaluate the semantic distance between the answer and each word of the question. Then, the distances are used as the weights to differentiate the useful words from the words strongly relevant to the correct answer. The reforming process is conducted in the following two steps.\nSelf-Attend Layer. Firstly, we use this layer to obtain the sentence-level representation ṽa ∈ R1×d of the answer.\nṽa = SelfAlign(Ã) = r>Ã where r = softmax(ÃWa)\nwhere Wa ∈ Rd×1 is a trainable parameter. r ∈ RLa×1 denotes the weight vector. Gate Layer. In this layer, we first use a bilinear layer to measure the distance between each word and the answer. Then, the distance information is used as gate values to reform each word and gain the reformed question Q̇.\nQ̇i = δiQ̃i, i ∈ [1, Lq] where δi = Gate(Q̃i, ṽa) = Q̃iWqgṽa> + bqg\nwhere Wqg is a trainable bilinear projection matrix and b q g ∈ R is also a parameter to learn. δi ∈ R is the semantic distance between the correct answer and the i-th word of the question. Q̃i and Q̇i denote the original representation and reformed representation of the i-th word in the question, respectively."
    }, {
      "heading" : "3.5 Reforming Passage Module",
      "text" : "Likewise, the passage also needs to be reformed to erase the impact of the answer. However, there still are some differences between the two reforming modules’ architectures:\n• Some parts of the passage may belong to other questions but have some common words with the answer. These common words may obtain low gate values which further reduce their contributions to the generation. Hence, before passage reforming, we first attend the question information to the answer to constrain it only to affect the words related to its question.\n• To further strengthen the relationship between the generated distractor and the question, we integrate the question information into the reformed passage to further highlight the question-relevant sentences.\nThe reformation process consists of the following four steps. A-Q Attention Layer. We use the Attn(·, ·) and Fuse(·, ·) to fuse the question information into the answer. Note that we use the original question but not the reformed question because the former contains complete answer-relevant information."
    }, {
      "heading" : "Â = Fuse(Ã,A) where A = Attn(Ã, Q̃)Q̃",
      "text" : "Self-Attend & Gate Layer. As the reforming question module, we first use the SelfAlign(·) to obtain the answer’s sentence-level representation v̂a = SelfAlign(Â) ∈ R1×d. We then use another gate layer to obtain the reformed passage Ṗ.\nṖi = Gate(Pi, v̂ a)Pi, i ∈ [1, Lp]\nwhere Pi and Ṗi denote the original and reformed representations of the i-th passage word, respectively. P-Q Attention Layer. This layer uses the attention mechanism to fuse the question information as mentioned above. P̃ = Fuse(Ṗ,P) where P = Attn(Ṗ, Q̇)Q̇\nRe-encoding Layer. We re-extract the contextual representation by another Bi-LSTM for the reformed passage P̃. The final semantic representation of the passage is denoted as P̂ ∈ RLp×d."
    }, {
      "heading" : "3.6 Question Initializer",
      "text" : "As mentioned above, the generated distractor should be grammatically and semantically consistent with the question. Inspired by (Gao et al., 2018), we use the question information to initialize the decoding process to enhance the semantic relevance between the distractor and question. Specifically, we first use a Bi-LSTM (Hochreiter and Schmidhuber, 1997) to re-encode the reformed question Q̇.\n−→ hqi = −−−→ LSTM(Q̇i, −−→ hqi−1)\nwhere −→ hqi is the hidden state of the forward LSTM at time i. We then concatenate the last hidden states of two directions as hq ∈ Rd, which then is projected to get the initial state of the decoder h0.\nh0 = h qWp + bp where hq = [ −−→ hqLq ; ←−− hqLq ]\nwhere Wp ∈ Rd×d and bp ∈ Rd are learnable parameters."
    }, {
      "heading" : "3.7 Distractor Generator",
      "text" : "At the decoder side, we adopt an attention-based LSTM layer. Specifically, at the first step, we use the output of the reforming question module h0 as the initial state and use the mean pooling vector of the reformed passage P̂ as the context vector c0 ∈ Rd. The first word is set to the special token [EOS].\nc0 = MeanPooling(P̂), e0 = E([EOS])\nNext, for each decoding step t, we use the attention mechanism to attend the most relevant words in the reading passage to form the context vector.\nht = LSTM([et−1; ct−1],ht−1), ct = Attn(htWh, P̂)P̂ (1)\nwhere Wh ∈ Rd×d, projecting the hidden state to the passage context, is the parameter to learn. et−1 denotes the embedding of the word at the t− 1-th step.\nMoreover, at each step, we concatenate ht and ct together and use an MLP layer to predict the word probability distribution. HV = softmax(tanh([ht; ct]Ws)Wv + bv) (2) where Ws ∈ R2d×d, Wv ∈ Rd×|V | and bv ∈ R|V | are learnable parameters. HV denotes the probabilities of all words in the vocabulary in which the word with the maximum probability is the predicted word at step t."
    }, {
      "heading" : "3.8 Training and Inference",
      "text" : "We train the model by minimizing regular cross-entropy loss:\nL(θM) = − ∑\nD\n∑\nt\nlog Pr(wdt |P,A,Q,wd<t; θM)\nwhereD is the training corpus in which each data sample contains a distractorD, a passage P , a question Q and an answer A. wdt is the t-th position of the distractor D. Pr(w d t |P,A,Q,wd<t; θ) is the predicted probability of the wdt and can be calculated by the Eq.(2). θM denotes all trainable parameters in EDGE. During the inference phase, we use a beam search of width n and receive n candidate distractors with decreasing likelihood because an MCQ has several diverse distractors. Following Gao et al. (2018), we use the Jaccard distance to generate the final multiple diverse distractors from the beam search results. Specifically, we first select the first candidate distractor with the maximum likelihood from the search results as Dg1 . The second one D g 2 should have a Jaccard distance, larger than 0.5, to D g 1 . Likewise, we select the third one Dg3 which has a restricted distance to both D g 1 and D g 2 ."
    }, {
      "heading" : "4 Experiments",
      "text" : ""
    }, {
      "heading" : "4.1 Experiment Setup",
      "text" : ""
    }, {
      "heading" : "4.1.1 Dataset",
      "text" : "For a fair comparison, we use the distractor generation dataset1 released by Gao et al. (2018) as our benchmark. This dataset is constructed based on RACE (Lai et al., 2017), which is a popular multiple choice question dataset for MRC. More details about the dataset construction process can be found in (Gao et al., 2018). The train/validation/test set contain 96,501/12,089/12,284 examples, respectively.\n2 zp10211059\nManuscript submitted to ACM\nThe left sub-figure of Figure 3 shows the count statistics on this dataset. We can see that most passages are related to more than two questions. A question is usually associated with multiple distractors, which proves necessary to conduct the beam search in the testing phase. The right sub-figure shows the distributions of the lengths of the passages, questions, answers, and distractors. The distractors and the answers have similar lengths and the questions are slightly longer than them. Meanwhile, we can see that the median of the distractor lengths is larger than 8. This suggests the similar word/entity-based methods do not apply to this dataset."
    }, {
      "heading" : "4.1.2 Model Details",
      "text" : "We use the GloVe.840B.300d (Pennington et al., 2014) as the pre-trained word embeddings (i.e., d = 300), and the word representations are shared across different components of EDGE. In the encoding module, we choose the Bi-LSTM as the contextual encoder, the size of the hidden unit is set to 300 (150 for each direction). Please note that the Bi-LSTM encoder is a plug-in module that can be easily replaced\n1https://github.com/Evan-Gao/Distractor-Generation-RACE\nby Transformer (Vaswani et al., 2017), BERT (Devlin et al., 2019) or XLNet (Yang et al., 2019). The parameters of the Bi-LSTM are shared among the encoding module and two reforming modules.\nAccording to the 95th percentile values shown in Figure 3, we set the maximum lengths of passages, questions, answers, and distractors to be 500, 17, 15, and 15, respectively.\nThe model is trained with a mini-batch size of 64. We use Nesterov Accelerated Gradient (NAG) optimizer (Nesterov, 1983) with a learning rate of 0.005. The dropout rate is set to 0.1 to reduce overfitting. The beam size n is set to 50."
    }, {
      "heading" : "4.2 Baseline Approaches and Metrics",
      "text" : "The following models are selected as baselines:\nBasic models: the basic sequence-to-sequence framework and its variants including (1) SS (Seq2Seq): the basic model that generates a distractor from the passage; (2) SEQ (SS+Enriching Module+Question Initializer): the sequence-to-sequence with the enriching module and the question-initialized decoder in which the initial state is set to the output of the question initializer; and (3) SEQA (SEQ+Attention): the sequence-to-sequence with a decoder same as the distractor generator of the EDGE.\nHRED (HieRarchical Encoder-Decoder): the basic framework of (Gao et al., 2018), which also contains the question initializer and attention mechanism.\nHSA (HRED+static attention) (Gao et al., 2018): which uses the HRED as the basic architecture and leverages two attention strategies to combine the information of the passage, question, and answer.\nCHN (Zhou et al., 2019): which extends HSA with a co-attention mechanism to further strengthen the interaction between the passage and the question. This model achieved state-of-the-art performance previously on this task.\nFollowing the distractor generation work (Gao et al., 2018) and some question generation works (Kim et al., 2018; Chen et al., 2019), we use BLEU (Papineni et al., 2001) and ROUGE (Lin, 2004) scores as our evaluation metrics.\nAll hyper-parameters of EDGE and other baselines are selected on the validation set based on the lowest perplexity and the results are reported on the test set."
    }, {
      "heading" : "4.3 Performance Comparison",
      "text" : "The experimental results of all models are summarized in Table 1. Since the dataset in (Gao et al., 2018) is slightly different from the public dataset in Github, we not only report the HSA’s results from its original paper (Gao et al., 2018) but also include the reimplementation results of (Gao et al., 2018) from (Zhou et al., 2019) on the public dataset. There are several observations: Firstly, the proposed model, EDGE, outperforms all baselines significantly in all metrics and achieves the new state-of-the-art scores on this distractor generation dataset; Secondly, SEQ and SEQA outperform the basic Seq2Seq which indicates both the question information and the passage information are vital to the distractor generation; Thirdly, SEQA outperforms HRED which indicates that the co-attention between the question and the passage in the enriching module can help to generate better distractors. The observation that CHN outperforms HSA also proves the effectiveness of the co-attention mechanism; Finally, the basic Seq2Seq performs far worse than other models, which indicates that the distractor generation is a challenging task and hard to solve only with simple models."
    }, {
      "heading" : "4.4 Ablation Analysis",
      "text" : "Table 2 shows the experimental results of the ablation study. We can see that removing the Reforming Passage Module or the Reforming Question Module leads to the suboptimal results. This validates the effectiveness of two reforming mechanisms. Moreover, we find the former module is more important for the overall distractor generation model. This is probably due to that the reformed passage has a higher impact on the decoding process. Particularly, in each decoding step, the context information from the passage can provide more clues to generate proper distractors than the context information from the question.\nWe can also observe that the question initializer brings performance gain. This verifies the hypothesis in Section 3.6 that the initial decoder state encoded from the question helps to generate distractors gram-\nmatically and semantically consistent with the question. Removing the encoding or enriching module will also result in a performance drop. This indicates that extracting contextual representations is important for the generation task. Moreover, the enriching module can further improve the performance by fusing the passage information into the contextual representation of the question."
    }, {
      "heading" : "4.5 Human Evaluation",
      "text" : "We conduct a human evaluation to evaluate the quality of the generated distractors of different models. We use three metrics designed by Zhou et al. (2019) to conduct the evaluation: (1) Fluency, which evaluates whether the distractor follows regular English grammar and conforms with human logic and common sense; (2) Coherence, which measures whether the key phrases in the distractors are relevant to the passage and the question; (3) Distracting Ability, which evaluates how likely a generated distractor will be used by the question composers in real examinations. We choose the first 100 samples of the test set and the corresponding distractors generated by three models as the input. We employ five annotators with good English background (at least holding a bachelor’s degree) to scores these distractors with three gears by three metrics, the scores are then projected to 0 - 10.\nThe results of all models, averaged over all generated distractors, are shown in Table 3. We can find that our model performs best in three metrics. This suggests our model is able to generate plausible and useful distractors. This conclusion also aligns with the experimental results of automatic metrics in Section 4.3."
    }, {
      "heading" : "4.6 Case Study",
      "text" : "The design of two reforming modules and the generator enables convenient interpretation of the generated distractors. Take the MCQ in Figure 4 for example, the blue highlighted sentence in the paragraph includes the clue to infer the correct answer. EDGE managed to block this clue by assigning a lower attention weight with the help of the gate layer. In this manner, the clue of the correct answer is prohibited from generating the distractor. Meanwhile, all the sentences related to three distractors (colored red and orange) obtain higher gate values, which further help to achieve higher attention weights (highlighted pink in the left part). Especially, when generating the first distractor, the red sentence has the highest attention score, indicating it make the most contributions to the generation. In summary, the visualization results demonstrate that EDGE provides a good way for the interpretation of the key information of a generated distractor."
    }, {
      "heading" : "5 Conclusion and Future Work",
      "text" : "In this paper, we propose a novel quEstion and answer guided Distractor GEneration(EDGE) framework to automatically generate distractors for multiple choice questions in standard English tests. In EDGE, we design two modules based on attention and gate strategies to reform the passage and question, which then are combined to decode the distractor. Experimental results on a large-scale public dataset demonstrate the state-of-the-art performance of EDGE and the effectiveness of two reforming modules.\nIn future work, we will explore two potential directions. First, since the beam search ignores the generation diversity, we will explore how to incorporate the prior generated distractor information to guide the generation of successor distractors. Second, we will work on how to generate the distractors requiring multi-sentence/hop reasoning, which can further improve the plausibility."
    } ],
    "references" : [ {
      "title" : "Automatic generation of multiple choice questions using dependencybased semantic relations",
      "author" : [ "Naveed Afzal", "Ruslan Mitkov." ],
      "venue" : "Soft Computing, 18:1269–1281.",
      "citeRegEx" : "Afzal and Mitkov.,? 2014",
      "shortCiteRegEx" : "Afzal and Mitkov.",
      "year" : 2014
    }, {
      "title" : "Generating questions and multiple-choice answers using semantic analysis of texts",
      "author" : [ "Jun Araki", "Dheeraj Rajagopal", "Sreecharan Sankaranarayanan", "Susan Holm", "Yukari Yamakawa", "Teruko Mitamura." ],
      "venue" : "COLING.",
      "citeRegEx" : "Araki et al\\.,? 2016",
      "shortCiteRegEx" : "Araki et al\\.",
      "year" : 2016
    }, {
      "title" : "Automatic multiple choice question generation from text : A survey",
      "author" : [ "Dhawaleswar Rao Ch", "Sujan Kumar Saha" ],
      "venue" : null,
      "citeRegEx" : "Ch and Saha.,? \\Q2018\\E",
      "shortCiteRegEx" : "Ch and Saha.",
      "year" : 2018
    }, {
      "title" : "Neural natural language inference models enhanced with external knowledge",
      "author" : [ "Qian Chen", "Xiaodan Zhu", "Zhen-Hua Ling", "Diana Inkpen", "Si Wei." ],
      "venue" : "arXiv preprint arXiv:1711.04289.",
      "citeRegEx" : "Chen et al\\.,? 2017",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2017
    }, {
      "title" : "Reinforcement learning based graph-to-sequence model for natural question generation",
      "author" : [ "Yu Chen", "Lingfei Wu", "Mohammed J. Zaki." ],
      "venue" : "ArXiv, abs/1908.04942.",
      "citeRegEx" : "Chen et al\\.,? 2019",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2019
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "NAACL-HLT.",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Identifying where to focus in reading comprehension for neural question generation",
      "author" : [ "Xinya Du", "Claire Cardie." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Du and Cardie.,? 2017",
      "shortCiteRegEx" : "Du and Cardie.",
      "year" : 2017
    }, {
      "title" : "Question generation for question answering",
      "author" : [ "Nan Duan", "Duyu Tang", "Peng Chen", "Ming Zhou." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Duan et al\\.,? 2017",
      "shortCiteRegEx" : "Duan et al\\.",
      "year" : 2017
    }, {
      "title" : "Generating distractors for reading comprehension questions from real examinations",
      "author" : [ "Yifan Gao", "Lidong Bing", "Piji Li", "Irwin King", "Michael R. Lyu." ],
      "venue" : "AAAI.",
      "citeRegEx" : "Gao et al\\.,? 2018",
      "shortCiteRegEx" : "Gao et al\\.",
      "year" : 2018
    }, {
      "title" : "Questimator: Generating knowledge assessments for arbitrary topics",
      "author" : [ "Qi Guo", "Chinmay Kulkarni", "Aniket Kittur", "Jeffrey P. Bigham", "Emma Brunskill." ],
      "venue" : "IJCAI.",
      "citeRegEx" : "Guo et al\\.,? 2016",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2016
    }, {
      "title" : "Automatic distractor suggestion for multiple-choice tests using concept embeddings and information retrieval",
      "author" : [ "Le An Ha", "Victoria Yaneva." ],
      "venue" : "BEA@NAACL-HLT.",
      "citeRegEx" : "Ha and Yaneva.,? 2018",
      "shortCiteRegEx" : "Ha and Yaneva.",
      "year" : 2018
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber." ],
      "venue" : "Neural computation, 9(8):1735–1780.",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? 1997",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Improving neural question generation using answer separation",
      "author" : [ "Yanghoon Kim", "Hwanhee Lee", "Joongbo Shin", "Kyomin Jung." ],
      "venue" : "AAAI.",
      "citeRegEx" : "Kim et al\\.,? 2018",
      "shortCiteRegEx" : "Kim et al\\.",
      "year" : 2018
    }, {
      "title" : "Automatic fill-the-blank question generator for student self-assessment",
      "author" : [ "Girish Kumar", "Rafael E Banchs", "Luis Fernando D’Haro" ],
      "venue" : "In 2015 IEEE Frontiers in Education Conference (FIE),",
      "citeRegEx" : "Kumar et al\\.,? \\Q2015\\E",
      "shortCiteRegEx" : "Kumar et al\\.",
      "year" : 2015
    }, {
      "title" : "Race: Large-scale reading comprehension dataset from examinations",
      "author" : [ "Guokun Lai", "Qizhe Xie", "Hanxiao Liu", "Yiming Yang", "Eduard H. Hovy." ],
      "venue" : "EMNLP.",
      "citeRegEx" : "Lai et al\\.,? 2017",
      "shortCiteRegEx" : "Lai et al\\.",
      "year" : 2017
    }, {
      "title" : "Distractor generation for multiple choice questions using learning to rank",
      "author" : [ "Chen Liang", "Xiao Yang", "Neisarg Dave", "Drew Wham", "Bart Pursel", "C. Lee Giles." ],
      "venue" : "BEA@NAACL-HLT.",
      "citeRegEx" : "Liang et al\\.,? 2018",
      "shortCiteRegEx" : "Liang et al\\.",
      "year" : 2018
    }, {
      "title" : "Rouge: A package for automatic evaluation of summaries",
      "author" : [ "Chin-Yew Lin." ],
      "venue" : "ACL 2004.",
      "citeRegEx" : "Lin.,? 2004",
      "shortCiteRegEx" : "Lin.",
      "year" : 2004
    }, {
      "title" : "Natural language inference by treebased convolution and heuristic matching",
      "author" : [ "Lili Mou", "Rui Men", "Ge Li", "Yan Xu", "Lu Zhang", "Rui Yan", "Zhi Jin." ],
      "venue" : "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), volume 2, pages 130–136.",
      "citeRegEx" : "Mou et al\\.,? 2016",
      "shortCiteRegEx" : "Mou et al\\.",
      "year" : 2016
    }, {
      "title" : "A method for unconstrained convex minimization problem with the rate of convergence o(1/k2)",
      "author" : [ "Y. Nesterov" ],
      "venue" : null,
      "citeRegEx" : "Nesterov.,? \\Q1983\\E",
      "shortCiteRegEx" : "Nesterov.",
      "year" : 1983
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "Wei-Jing Zhu." ],
      "venue" : "ACL.",
      "citeRegEx" : "Papineni et al\\.,? 2001",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2001
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher D. Manning." ],
      "venue" : "Empirical Methods in Natural Language Processing (EMNLP), pages 1532–1543.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Discriminative approach to fill-in-the-blank quiz generation for language learners",
      "author" : [ "Keisuke Sakaguchi", "Yuki Arase", "Mamoru Komachi." ],
      "venue" : "ACL.",
      "citeRegEx" : "Sakaguchi et al\\.,? 2013",
      "shortCiteRegEx" : "Sakaguchi et al\\.",
      "year" : 2013
    }, {
      "title" : "Multiple choice question generation utilizing an ontology",
      "author" : [ "Katherine Stasaski", "Marti A. Hearst." ],
      "venue" : "BEA@EMNLP.",
      "citeRegEx" : "Stasaski and Hearst.,? 2017",
      "shortCiteRegEx" : "Stasaski and Hearst.",
      "year" : 2017
    }, {
      "title" : "Attention is all you need",
      "author" : [ "Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin." ],
      "venue" : "NIPS.",
      "citeRegEx" : "Vaswani et al\\.,? 2017",
      "shortCiteRegEx" : "Vaswani et al\\.",
      "year" : 2017
    }, {
      "title" : "Semi-supervised qa with generative domain-adaptive nets",
      "author" : [ "Zhilin Yang", "Junjie Hu", "Ruslan Salakhutdinov", "William W. Cohen." ],
      "venue" : "ACL.",
      "citeRegEx" : "Yang et al\\.,? 2017",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2017
    }, {
      "title" : "Xlnet: Generalized autoregressive pretraining for language understanding",
      "author" : [ "Zhilin Yang", "Zihang Dai", "Yiming Yang", "Jaime G. Carbonell", "Ruslan Salakhutdinov", "Quoc V. Le." ],
      "venue" : "ArXiv, abs/1906.08237.",
      "citeRegEx" : "Yang et al\\.,? 2019",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "Neural question generation from text: A preliminary study",
      "author" : [ "Qingyu Zhou", "Nan Yang", "Furu Wei", "Chuanqi Tan", "Hangbo Bao", "Ming Zhou." ],
      "venue" : "NLPCC.",
      "citeRegEx" : "Zhou et al\\.,? 2017",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2017
    }, {
      "title" : "Co-attention hierarchical network: Generating coherent long distractors for reading comprehension",
      "author" : [ "Xiaorui Zhou", "Senlin Luo", "Yunfang Wu" ],
      "venue" : null,
      "citeRegEx" : "Zhou et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2019
    } ],
    "referenceMentions" : [ {
      "referenceID" : 2,
      "context" : "Standard test, such as TOFEL and SAT, is an efficient and essential tool to assess knowledge proficiency of a learner (Ch and Saha, 2018).",
      "startOffset" : 118,
      "endOffset" : 137
    }, {
      "referenceID" : 2,
      "context" : "MCQs have many advantages including less testing time, more objective and easy on the grader (Ch and Saha, 2018).",
      "startOffset" : 93,
      "endOffset" : 112
    }, {
      "referenceID" : 15,
      "context" : "Rather than being a trivial wrong answer, the distractor should have the plausibility which confuses learners who did not master the knowledge (Liang et al., 2018).",
      "startOffset" : 143,
      "endOffset" : 163
    }, {
      "referenceID" : 8,
      "context" : "A good distractor should be grammatically correct given the question and semantically consistent with the passage context of the question (Gao et al., 2018).",
      "startOffset" : 138,
      "endOffset" : 156
    }, {
      "referenceID" : 10,
      "context" : "Hence, the manual preparation of distractors is time-consuming and costly (Ha and Yaneva, 2018).",
      "startOffset" : 74,
      "endOffset" : 95
    }, {
      "referenceID" : 24,
      "context" : "It could also be helpful to prepare a large train set to boost the machine reading comprehension (MRC) systems (Yang et al., 2017).",
      "startOffset" : 111,
      "endOffset" : 130
    }, {
      "referenceID" : 14,
      "context" : "In this paper, we focus on automatically generating semantic-rich distractors for MCQs in realworld standard tests, such as RACE (Lai et al., 2017) which is collected from the English exams for Chinese students from grades 7 to 12.",
      "startOffset" : 129,
      "endOffset" : 147
    }, {
      "referenceID" : 22,
      "context" : "Existing works conduct some attempts on generating short distractors (Stasaski and Hearst, 2017; Guo et al., 2016).",
      "startOffset" : 69,
      "endOffset" : 114
    }, {
      "referenceID" : 9,
      "context" : "Existing works conduct some attempts on generating short distractors (Stasaski and Hearst, 2017; Guo et al., 2016).",
      "startOffset" : 69,
      "endOffset" : 114
    }, {
      "referenceID" : 27,
      "context" : "Recently, generating longer distractors has been explored in a few studies (Zhou et al., 2019; Gao et al., 2018).",
      "startOffset" : 75,
      "endOffset" : 112
    }, {
      "referenceID" : 8,
      "context" : "Recently, generating longer distractors has been explored in a few studies (Zhou et al., 2019; Gao et al., 2018).",
      "startOffset" : 75,
      "endOffset" : 112
    }, {
      "referenceID" : 15,
      "context" : "Considerable research efforts (Liang et al., 2018; Sakaguchi et al., 2013; Araki et al., 2016) have been devoted to using manual design features, such as POS features and statistic features, to generate the distractors.",
      "startOffset" : 30,
      "endOffset" : 94
    }, {
      "referenceID" : 21,
      "context" : "Considerable research efforts (Liang et al., 2018; Sakaguchi et al., 2013; Araki et al., 2016) have been devoted to using manual design features, such as POS features and statistic features, to generate the distractors.",
      "startOffset" : 30,
      "endOffset" : 94
    }, {
      "referenceID" : 1,
      "context" : "Considerable research efforts (Liang et al., 2018; Sakaguchi et al., 2013; Araki et al., 2016) have been devoted to using manual design features, such as POS features and statistic features, to generate the distractors.",
      "startOffset" : 30,
      "endOffset" : 94
    }, {
      "referenceID" : 22,
      "context" : "Some works (Stasaski and Hearst, 2017; Guo et al., 2016; Kumar et al., 2015; Afzal and Mitkov, 2014) focused on finding answer-relevant ontologies or words as the distractors with the help of WordNet and Word2Vec.",
      "startOffset" : 11,
      "endOffset" : 100
    }, {
      "referenceID" : 9,
      "context" : "Some works (Stasaski and Hearst, 2017; Guo et al., 2016; Kumar et al., 2015; Afzal and Mitkov, 2014) focused on finding answer-relevant ontologies or words as the distractors with the help of WordNet and Word2Vec.",
      "startOffset" : 11,
      "endOffset" : 100
    }, {
      "referenceID" : 13,
      "context" : "Some works (Stasaski and Hearst, 2017; Guo et al., 2016; Kumar et al., 2015; Afzal and Mitkov, 2014) focused on finding answer-relevant ontologies or words as the distractors with the help of WordNet and Word2Vec.",
      "startOffset" : 11,
      "endOffset" : 100
    }, {
      "referenceID" : 0,
      "context" : "Some works (Stasaski and Hearst, 2017; Guo et al., 2016; Kumar et al., 2015; Afzal and Mitkov, 2014) focused on finding answer-relevant ontologies or words as the distractors with the help of WordNet and Word2Vec.",
      "startOffset" : 11,
      "endOffset" : 100
    }, {
      "referenceID" : 8,
      "context" : "(2019) further strengthened the interaction between the question and the passage based on the model of (Gao et al., 2018).",
      "startOffset" : 103,
      "endOffset" : 121
    }, {
      "referenceID" : 7,
      "context" : "2 Framework Overview Inspired by existing question generation works (Duan et al., 2017; Du and Cardie, 2017; Zhou et al., 2017; Kim et al., 2018), we employ a sequence-to-sequence based network to generate the distractors.",
      "startOffset" : 68,
      "endOffset" : 145
    }, {
      "referenceID" : 6,
      "context" : "2 Framework Overview Inspired by existing question generation works (Duan et al., 2017; Du and Cardie, 2017; Zhou et al., 2017; Kim et al., 2018), we employ a sequence-to-sequence based network to generate the distractors.",
      "startOffset" : 68,
      "endOffset" : 145
    }, {
      "referenceID" : 26,
      "context" : "2 Framework Overview Inspired by existing question generation works (Duan et al., 2017; Du and Cardie, 2017; Zhou et al., 2017; Kim et al., 2018), we employ a sequence-to-sequence based network to generate the distractors.",
      "startOffset" : 68,
      "endOffset" : 145
    }, {
      "referenceID" : 12,
      "context" : "2 Framework Overview Inspired by existing question generation works (Duan et al., 2017; Du and Cardie, 2017; Zhou et al., 2017; Kim et al., 2018), we employ a sequence-to-sequence based network to generate the distractors.",
      "startOffset" : 68,
      "endOffset" : 145
    }, {
      "referenceID" : 3,
      "context" : "scaled dot product attention mechanism and the fusion kernel used in recent works (Chen et al., 2017; Mou et al., 2016) for better semantic understanding.",
      "startOffset" : 82,
      "endOffset" : 119
    }, {
      "referenceID" : 17,
      "context" : "scaled dot product attention mechanism and the fusion kernel used in recent works (Chen et al., 2017; Mou et al., 2016) for better semantic understanding.",
      "startOffset" : 82,
      "endOffset" : 119
    }, {
      "referenceID" : 8,
      "context" : "Inspired by (Gao et al., 2018), we use the question information to initialize the decoding process to enhance the semantic relevance between the distractor and question.",
      "startOffset" : 12,
      "endOffset" : 30
    }, {
      "referenceID" : 11,
      "context" : "Specifically, we first use a Bi-LSTM (Hochreiter and Schmidhuber, 1997) to re-encode the reformed question Q̇.",
      "startOffset" : 37,
      "endOffset" : 71
    }, {
      "referenceID" : 14,
      "context" : "This dataset is constructed based on RACE (Lai et al., 2017), which is a popular multiple choice question dataset for MRC.",
      "startOffset" : 42,
      "endOffset" : 60
    }, {
      "referenceID" : 8,
      "context" : "More details about the dataset construction process can be found in (Gao et al., 2018).",
      "startOffset" : 68,
      "endOffset" : 86
    }, {
      "referenceID" : 20,
      "context" : "300d (Pennington et al., 2014) as the pre-trained word embeddings (i.",
      "startOffset" : 5,
      "endOffset" : 30
    }, {
      "referenceID" : 23,
      "context" : "by Transformer (Vaswani et al., 2017), BERT (Devlin et al.",
      "startOffset" : 15,
      "endOffset" : 37
    }, {
      "referenceID" : 5,
      "context" : ", 2017), BERT (Devlin et al., 2019) or XLNet (Yang et al.",
      "startOffset" : 14,
      "endOffset" : 35
    }, {
      "referenceID" : 18,
      "context" : "We use Nesterov Accelerated Gradient (NAG) optimizer (Nesterov, 1983) with a learning rate of 0.",
      "startOffset" : 53,
      "endOffset" : 69
    }, {
      "referenceID" : 8,
      "context" : "HRED (HieRarchical Encoder-Decoder): the basic framework of (Gao et al., 2018), which also contains the question initializer and attention mechanism.",
      "startOffset" : 60,
      "endOffset" : 78
    }, {
      "referenceID" : 8,
      "context" : "HSA (HRED+static attention) (Gao et al., 2018): which uses the HRED as the basic architecture and leverages two attention strategies to combine the information of the passage, question, and answer.",
      "startOffset" : 28,
      "endOffset" : 46
    }, {
      "referenceID" : 27,
      "context" : "CHN (Zhou et al., 2019): which extends HSA with a co-attention mechanism to further strengthen the interaction between the passage and the question.",
      "startOffset" : 4,
      "endOffset" : 23
    }, {
      "referenceID" : 8,
      "context" : "Following the distractor generation work (Gao et al., 2018) and some question generation works (Kim et al.",
      "startOffset" : 41,
      "endOffset" : 59
    }, {
      "referenceID" : 12,
      "context" : ", 2018) and some question generation works (Kim et al., 2018; Chen et al., 2019), we use BLEU (Papineni et al.",
      "startOffset" : 43,
      "endOffset" : 80
    }, {
      "referenceID" : 4,
      "context" : ", 2018) and some question generation works (Kim et al., 2018; Chen et al., 2019), we use BLEU (Papineni et al.",
      "startOffset" : 43,
      "endOffset" : 80
    }, {
      "referenceID" : 19,
      "context" : ", 2019), we use BLEU (Papineni et al., 2001) and ROUGE (Lin, 2004) scores as our evaluation metrics.",
      "startOffset" : 21,
      "endOffset" : 44
    }, {
      "referenceID" : 16,
      "context" : ", 2001) and ROUGE (Lin, 2004) scores as our evaluation metrics.",
      "startOffset" : 18,
      "endOffset" : 29
    }, {
      "referenceID" : 8,
      "context" : "Since the dataset in (Gao et al., 2018) is slightly different from the public dataset in Github, we not only report the HSA’s results from its original paper (Gao et al.",
      "startOffset" : 21,
      "endOffset" : 39
    }, {
      "referenceID" : 8,
      "context" : ", 2018) is slightly different from the public dataset in Github, we not only report the HSA’s results from its original paper (Gao et al., 2018) but also include the reimplementation results of (Gao et al.",
      "startOffset" : 126,
      "endOffset" : 144
    }, {
      "referenceID" : 8,
      "context" : ", 2018) but also include the reimplementation results of (Gao et al., 2018) from (Zhou et al.",
      "startOffset" : 57,
      "endOffset" : 75
    }, {
      "referenceID" : 27,
      "context" : ", 2018) from (Zhou et al., 2019) on the public dataset.",
      "startOffset" : 13,
      "endOffset" : 32
    }, {
      "referenceID" : 8,
      "context" : "HSA* denotes the result reported in (Gao et al., 2018) and HSA denotes the result reported in (Zhou et al.",
      "startOffset" : 36,
      "endOffset" : 54
    }, {
      "referenceID" : 27,
      "context" : ", 2018) and HSA denotes the result reported in (Zhou et al., 2019).",
      "startOffset" : 47,
      "endOffset" : 66
    } ],
    "year" : 2020,
    "abstractText" : "To assess the knowledge proficiency of a learner, multiple choice question is an efficient and widespread form in standard tests. However, the composition of the multiple choice question, especially the construction of distractors is quite challenging. The distractors are required to both incorrect and plausible enough to confuse the learners who did not master the knowledge. Currently, the distractors are generated by domain experts which are both expensive and timeconsuming. This urges the emergence of automatic distractor generation, which can benefit various standard tests in a wide range of domains. In this paper, we propose a quEstion and answer guided Distractor GEneration (EDGE) framework to automate distractor generation. EDGE consists of three major modules: (1) the Reforming Question Module and the Reforming Passage Module apply gate layers to guarantee the inherent incorrectness of the generated distractors; (2) the Distractor Generator Module applies attention mechanism to control the level of plausibility. Experimental results on a large-scale public dataset demonstrate that our model significantly outperforms existing models and achieves a new state-of-the-art.",
    "creator" : "TeX"
  }
}