{
  "name" : "COLING_2020_45_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Definition Frames: Using Definitions for Hybrid Concept Representations",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Ontologies have been widely used in lexical semantics to organize and represent knowledge. Carefully built by experts, they contain semantically meaningful information in the form of relations between concepts. However, being manually constructed, they struggle to assimilate new information.\nCompared to ontologies, distributed representations are fully automated and can be fine-tuned for new tasks. Despite their exceptional performance, most distributional methods do not have an explicit semantic interpretation. The resulting representations encode a tremendous amount of information, but afford no way to interpret what this information is and how it relates to the concept. Thus, one cannot choose which type of information is useful for a specific task, unless one has a lot of data and resources to fine-tune. Although a few approaches have tried to bridge the gap between semantics and distributed representations (Faruqui et al., 2015; Mrkšić et al., 2017), (1) they only encode information from ontologies, which are not extensible, and (2) the final representations are still not semantically meaningful.\nMotivated by these problems, we introduce a novel hybrid representation called Definition Frames (DF), which encode semantic information extracted from definitions. DFs are matrix representations, where each row corresponds to a particular relation. The set of the relations used is based on the Qualia structure suggested in (Boguraev and Pustejovsky, 1990), and they are extracted automatically from definitions via a domain-adaptation approach. To the best of our knowledge, DF is the first hybrid representation, combining an explicit structure through semantically meaningful rows, while still being decomposed into distributional vectors."
    }, {
      "heading" : "2 Prior Work",
      "text" : "Prior research on lexical semantics has established a set of relations that are sufficient to uniquely define a concept. Such work includes the Qualia structure (Boguraev and Pustejovsky, 1990) and the generative lexicon theory (Pustejovsky, 1991). Other related work includes ontological approaches (Baker et al., 1998; Miller, 1995; Lenat, 1995; Speer and Havasi, 2012) and more fine-grained definition-based frames like Semagrams (Moerdijk and others, 2008).\nIn distributional semantics, approaches including GloVe (Pennington et al., 2014), word2vec (Mikolov et al., 2013), and fastText (Bojanowski et al., 2017) obtain generic word embeddings by pre-training on large corpora. Recent work focused on context-sensitive embeddings like ELMo (Peters et al., 2018) and BERT (Devlin et al., 2018), which achieve significant improvements in downstream NLP tasks.\n1Code release for Definition Frames upon acceptance.\nEarlier work on definitions extracted the type of a concept (Genus) and the relations distinguishing it from other members of the same type (Differentia) via syntax and string matching heuristics (Binot and Jensen, 1993; Calzolari, 1984; Chodorow et al., 1985). Recent approaches directly encoded definitions to distributed representations. Tissier (2017) obtained embeddings via a skip-gram model trained on definitions, while Bosc (2018) used an auto-encoder. Other work includes definition generation (Noraset et al., 2017), binary classification of sentences on whether they are definitional (Anke and Schockaert, 2018), reverse dictionary look-up (Hill et al., 2016; Zock and Bilac, 2004), and extraction of hypernymy relations from definitions using syntactic patterns (Boella and Di Caro, 2013)."
    }, {
      "heading" : "3 Approach",
      "text" : "Our framework consists of two parts: the Relation Retriever and the Definition Frame (DF) Encoder. The WordNet definition for any given term is used by the Relation Retriever model to extract the Qualia structure relations. The set of extracted terms pertaining to these relations form the Definition Frame. The DF Encoder encodes this output to a distributed matrix representation, which can be used in downstream NLP tasks.\nQualia Structure Besides domain-specific relations, most Relation Extraction tasks (Gábor et al., 2018; Hendrickx et al., 2009) contain relations describing the type (isA), structure (madeOf, partOf, hasA), function (usedFor), or provenance (createdBy) of a concept. This set of relation categories corresponds to the Qualia structure (formal, constitutive, telic, and origin), which is defined as the complete modes of explanation associated with an entity (Boguraev and Pustejovsky, 1990; Pustejovsky, 1991). These relations usually suffice to uniquely define a concept and completely (more details in Appendix A).\nTo automatically extract the Qualia structure of a term, we use dictionary definitions, as they uniquely describe a term. We confirm the prevalence of those relations in definitions by annotating 300 Wikipedia and 150 WordNet definitions, chosen at random from nominal terms in WordNet (Appendix A).\nTraining Data Since there are no definitions annotated with Qualia structure, we deploy a domain adaptation technique. We use ConceptNet to pre-train the Relation Retriever model (section 3) and then fine-tune it on and apply it to WordNet definitions. We fine-tune on a set of 150 manual annotations, since WordNet definitions tend to have more complex sentences than the ones in ConceptNet.\nConceptNet (Speer and Havasi, 2012) is a general purpose ontology that contains relations between pairs of concepts, accompanied by a small source-sentence. Figure 1 shows that the Concept-query Sun is linked to two sentences (Sun is a star and Sun is in our solar system) from ConceptNet with the corresponding relations isA and partOf. The training data for the Relation Retriever is composed of all ConceptNet source-sentences that contain one of the Qualia structure relations.\nExtracting Definition Frames The Relation Retriever uses the WordNet definition of a term to extract words that are related to that term via a Qualia-type relation. The set of extracted relations with their corresponding related words form the Definition Frame (DF). More specifically, we define a Definition Frame for a term t as Ft = {r1 : S1, r2 : S2,.., rk : Sk}, where ri 2 { isA, usedFor, partOf, hasA, madeOf, createdBy } and Si is the set of words related to t via the relation ri. For example, to extract the DF for moon (Figure 1), we use the WordNet definition of moon as input. The Relation Retriever extracts the terms that are related to moon via a Qualia-structure relation (i.e. satellite, astronomical body and\nsolar system). These terms with their corresponding relations constitute the Definition Frame Fmoon. More examples of Definition Frames are shown in Appendix B.\nThe Relation Retriever uses a BiLSTM model to extract the relations from each sentence. The task is formulated as a sequence tagging problem where we identify both the relation type and the related entities, and optimizes the cross-entropy loss. For model selection, we perform experiments with strong baseline architectures for RE tasks (BiLSTM, BERT-BiLSTM, BiLSTM-CNN). The Relation Retriever obtains F1 = 0.97 on ConceptNet test data (Appendix C).\nThe Definition Frame is encoded via the DF Encoder into a matrix where each row wi corresponds to one of the Qualia relations. The DF Encoder uses an embedding space (Basis) to construct each row vector wi. Note that Basis can be any distributional embedding model. Given a DF Ft, we define wi as the average of word embeddings from the set of related terms Si through relation ri:\nwi = 1 |Si| X\ns2Si Basis(s)\nwhere Basis(s) is the embedding for word s. We include an additional row for the Basis vector of the term itself. This encoding of DF maintains a semantically meaningful structure as each row always corresponds to the same relation. If no terms are extracted for a relation, we use the zero vector of appropriate size. An example of the encoded DFmoon is shown in Figure 1, where each dimension corresponds to a unique relation like isA and partOf."
    }, {
      "heading" : "4 Experiments",
      "text" : "Word-Similarity Task We perform experiments on benchmark word-similarity datasets provided by Faruqui (2014): SimLex999 (Hill et al., 2015), MC30 (Miller and Charles, 1991), RG65 (Rubenstein and Goodenough, 1965), WS353 (Finkelstein et al., 2002) and MEN (Bruni et al., 2012). Following Agirre (2009), we split them into word-similarity (WS-Sim, SimLex999, MC30, RG65) and word-relatedness (WS-Rel, MEN) datasets, as they evaluate different semantic affinities. We only consider nominal terms that exist in WordNet and report Spearman’s correlation ⇢. We perform experiments with three types of embeddings used as Basis: GloVe (Pennington et al., 2014), dict2vec trained on Wikipedia (Tissier et al., 2017), and retrofit embeddings (Faruqui et al., 2015) based on GloVe. Since the task comprises of pairs of words without any context, we do not compare against context-based representations.\nAblation Study We perform an ablation study by varying the set of relations used in DF. In this study, both Basis and DF are encoded with dict2vec, as it achieves the best performance (Table 1). The goal of this study is to measure how each extracted relation affects the performance of DF in word similarity tasks. The results (details in Appendix B) show that, for similarity tasks, pruning relations sometimes improves performance over both the original DF (with all relations) and the Basis embeddings. However, we observe that DFs consistently have worse performance than Basis in relatedness tasks, particularly in the MEN dataset. As we further discuss in detail in Section 4, although DFs capture relatedness, this is not reflected when using the cosine similarity metric directly, since it cannot compare information across different dimensions. For example, consider the pair (car, wheel). If we compare row-vectors of DFwheel and DFcar for each relation separately, the representations are very different. Each Qualia structure relation defining car and wheel is different for the two terms. However, the Structure dimension of DFcar would contain the information that wheel is part (meronym) of car, thus it should be compared to the Basis dimension of DFwheel.\nResults To account for the cross-dimension problem described in the previous section, we design a slightly modified version of the previous experiments. We apply a linear transformation with the weights varying according to which type of word similarity (relatedness or similarity) we are measuring. This allows us to: (1) give more weight to more important relations and (2) compare the representations across different Qualia structure relations.\nUsing a linear transformation allows us to recover the initial DF representation from its transformed counterpart, which is important in order to maintain the semantic interpretability of DF (i.e. which\nwords are related to t and how). Thus, given DFt for a term t, we get DF ⇤t = W ⇥DFt + b, which we use in our experiments. The parameters W , b are learnt separately for similarity and relatedness tasks, since different relations and cross-relation comparisons have varying importance for the two tasks. The training objective for the linear transformation is the minimization of the mean squared error between the cosine similarity of the transformed representations and the normalized ground truth similarity score. For fair comparison, we also apply a linear transformation to the baseline Basis by learning parameters Wbasis, bbasis as described above for DF . In our experiments on similarity and relatedness datasets we use 10-Fold cross-validation and report the average performance, while on MEN we use the provided split into training and test data (it is the only dataset with a train/test split).\nOur results show that Definition Frames achieve the best performance, compared to any of the baselines. In Table 1 we compare the performance of the Basis embeddings before and after the linear transformation (Basis and Basis⇤), with the Definition Frames (DF and DF ⇤). DF ⇤ benefits much more of the dimension weighting and achieves better results compared to Basis⇤, particularly with GloVe embeddings. Furthermore, we observe that Relatedness datasets (including MEN) gain the greatest advantage from the linear weighting. This lines up with our previous hypothesis, since the relatedness task requires more cross-relation comparisons (DFcar vs DFwheel).\nQualitative Analysis One of the distinguishing features of DFs is that they are semantically interpretable. Beyond determining whether two terms are related, we find that DFs can be used to infer how they are related. We perform a qualitative analysis on 100 randomly selected terms from the MEN dataset that have high relatedness score (higher than 35 out of 50). The goal of this study is to assess whether we can use the explicit structure of DFs to predict the type of the relation between two terms.\nWe conduct a Mechanical Turk study, where we present (1) the pair of related words, (2) their corresponding definitions and (3) a Qualia structure relation, in the form of question. We phrase the annotation task as a binary question such as “Is an aquarium created by a fish?”. We include all possible Qualia structure relations for each of the 100 pairs of related words. We ask three annotators to annotate each sample (1200 questions, each annotated three times, for a total of 3600 annotations).\nTo identify the most probable relation between two terms t1 and t2 using the encoded DF, we conduct a set of row-to-row comparisons. We measure the cosine similarity of each row of DFt1 with Basis(t2) and vice-versa DFt2 with Basis(t1). The relation corresponding to the row with highest cosine similarity is taken to be the most probable relation. We test if the relation predicted by the DFs is correct according to humans. By taking the majority vote of the annotations, we find that 77% of the extracted relations are considered valid by the workers. Furthermore, 54% of the relations were considered accurate by all three annotators and the inter annotator percent agreement is 60% over the 1200 relations (more details in Appendix E)."
    }, {
      "heading" : "5 Conclusion",
      "text" : "We propose Definition Frames, a hybrid semantically interpretable representation that is grounded in both lexical semantics and distributed representations. By disentangling the Qualia structure relations, DFs can capture different types of similarity (relatedness and similarity) and achieve improved performance on word similarity tasks. Finally, we demonstrate the explainability of Definition Frames via a human study showing that they provide valid insights on how terms are related."
    } ],
    "references" : [ {
      "title" : "A study on similarity and relatedness using distributional and wordnet-based approaches",
      "author" : [ "Eneko Agirre", "Enrique Alfonseca", "Keith Hall", "Jana Kravalova", "Marius Paşca", "Aitor Soroa." ],
      "venue" : "Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 19–27. Association for Computational Linguistics.",
      "citeRegEx" : "Agirre et al\\.,? 2009",
      "shortCiteRegEx" : "Agirre et al\\.",
      "year" : 2009
    }, {
      "title" : "Syntactically aware neural architectures for definition extraction",
      "author" : [ "Luis Espinosa Anke", "Steven Schockaert." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 378–385.",
      "citeRegEx" : "Anke and Schockaert.,? 2018",
      "shortCiteRegEx" : "Anke and Schockaert.",
      "year" : 2018
    }, {
      "title" : "The berkeley framenet project",
      "author" : [ "Collin F Baker", "Charles J Fillmore", "John B Lowe." ],
      "venue" : "Proceedings of the 17th international conference on Computational linguistics-Volume 1, pages 86–90. Association for Computational Linguistics.",
      "citeRegEx" : "Baker et al\\.,? 1998",
      "shortCiteRegEx" : "Baker et al\\.",
      "year" : 1998
    }, {
      "title" : "A semantic expert using an online standard dictionary",
      "author" : [ "Jean-Louis Binot", "Karen Jensen." ],
      "venue" : "Natural Language Processing: The PLNLP Approach, pages 135–147. Springer.",
      "citeRegEx" : "Binot and Jensen.,? 1993",
      "shortCiteRegEx" : "Binot and Jensen.",
      "year" : 1993
    }, {
      "title" : "Extracting definitions and hypernym relations relying on syntactic dependencies and support vector machines",
      "author" : [ "Guido Boella", "Luigi Di Caro." ],
      "venue" : "51st Annual Meeting of the Association for Computational Linguistics, ACL 2013, volume 2, pages 532–537. Association for Computational Linguistics (ACL).",
      "citeRegEx" : "Boella and Caro.,? 2013",
      "shortCiteRegEx" : "Boella and Caro.",
      "year" : 2013
    }, {
      "title" : "Lexical ambiguity and the role of knowledge representation in lexicon design",
      "author" : [ "Branimir Boguraev", "James Pustejovsky." ],
      "venue" : "Proceedings of the 13th conference on Computational linguistics-Volume 2, pages 36–41. Association for Computational Linguistics.",
      "citeRegEx" : "Boguraev and Pustejovsky.,? 1990",
      "shortCiteRegEx" : "Boguraev and Pustejovsky.",
      "year" : 1990
    }, {
      "title" : "Enriching word vectors with subword information",
      "author" : [ "Piotr Bojanowski", "Edouard Grave", "Armand Joulin", "Tomas Mikolov." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 5:135–146.",
      "citeRegEx" : "Bojanowski et al\\.,? 2017",
      "shortCiteRegEx" : "Bojanowski et al\\.",
      "year" : 2017
    }, {
      "title" : "Auto-encoding dictionary definitions into consistent word embeddings",
      "author" : [ "Tom Bosc", "Pascal Vincent." ],
      "venue" : "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 1522–1532.",
      "citeRegEx" : "Bosc and Vincent.,? 2018",
      "shortCiteRegEx" : "Bosc and Vincent.",
      "year" : 2018
    }, {
      "title" : "Distributional semantics in technicolor",
      "author" : [ "Elia Bruni", "Gemma Boleda", "Marco Baroni", "Nam-Khanh Tran." ],
      "venue" : "Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long PapersVolume 1, pages 136–145. Association for Computational Linguistics.",
      "citeRegEx" : "Bruni et al\\.,? 2012",
      "shortCiteRegEx" : "Bruni et al\\.",
      "year" : 2012
    }, {
      "title" : "Detecting patterns in a lexical data base",
      "author" : [ "Nicoletta Calzolari." ],
      "venue" : "10th International Conference on Computational Linguistics and 22nd Annual Meeting of the Association for Computational Linguistics.",
      "citeRegEx" : "Calzolari.,? 1984",
      "shortCiteRegEx" : "Calzolari.",
      "year" : 1984
    }, {
      "title" : "Extracting semantic hierarchies from a large on-line dictionary",
      "author" : [ "Martin S Chodorow", "Roy J Byrd", "George E Heidorn." ],
      "venue" : "Proceedings of the 23rd annual meeting on Association for Computational Linguistics, pages 299–304. Association for Computational Linguistics.",
      "citeRegEx" : "Chodorow et al\\.,? 1985",
      "shortCiteRegEx" : "Chodorow et al\\.",
      "year" : 1985
    }, {
      "title" : "Bert: Pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "arXiv preprint arXiv:1810.04805.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "Community evaluation and exchange of word vectors at wordvectors.org",
      "author" : [ "Manaal Faruqui", "Chris Dyer" ],
      "venue" : "In Proceedings of ACL: System Demonstrations",
      "citeRegEx" : "Faruqui and Dyer.,? \\Q2014\\E",
      "shortCiteRegEx" : "Faruqui and Dyer.",
      "year" : 2014
    }, {
      "title" : "Retrofitting word vectors to semantic lexicons",
      "author" : [ "Manaal Faruqui", "Jesse Dodge", "Sujay Kumar Jauhar", "Chris Dyer", "Eduard Hovy", "Noah A Smith." ],
      "venue" : "Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1606–1615.",
      "citeRegEx" : "Faruqui et al\\.,? 2015",
      "shortCiteRegEx" : "Faruqui et al\\.",
      "year" : 2015
    }, {
      "title" : "Placing search in context: The concept revisited",
      "author" : [ "Lev Finkelstein", "Evgeniy Gabrilovich", "Yossi Matias", "Ehud Rivlin", "Zach Solan", "Gadi Wolfman", "Eytan Ruppin." ],
      "venue" : "ACM Transactions on information systems, 20(1):116– 131.",
      "citeRegEx" : "Finkelstein et al\\.,? 2002",
      "shortCiteRegEx" : "Finkelstein et al\\.",
      "year" : 2002
    }, {
      "title" : "Semeval-2018 task 7: Semantic relation extraction and classification in scientific papers",
      "author" : [ "Kata Gábor", "Davide Buscaldi", "Anne-Kathrin Schumann", "Behrang QasemiZadeh", "Haifa Zargayouna", "Thierry Charnois." ],
      "venue" : "Proceedings of The 12th International Workshop on Semantic Evaluation, pages 679–688.",
      "citeRegEx" : "Gábor et al\\.,? 2018",
      "shortCiteRegEx" : "Gábor et al\\.",
      "year" : 2018
    }, {
      "title" : "Semeval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals",
      "author" : [ "Iris Hendrickx", "Su Nam Kim", "Zornitsa Kozareva", "Preslav Nakov", "Diarmuid Ó Séaghdha", "Sebastian Padó", "Marco Pennacchiotti", "Lorenza Romano", "Stan Szpakowicz." ],
      "venue" : "Proceedings of the Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 94–99. Association for Computational Linguistics.",
      "citeRegEx" : "Hendrickx et al\\.,? 2009",
      "shortCiteRegEx" : "Hendrickx et al\\.",
      "year" : 2009
    }, {
      "title" : "Simlex-999: Evaluating semantic models with (genuine) similarity estimation",
      "author" : [ "Felix Hill", "Roi Reichart", "Anna Korhonen." ],
      "venue" : "Computational Linguistics, 41(4):665–695.",
      "citeRegEx" : "Hill et al\\.,? 2015",
      "shortCiteRegEx" : "Hill et al\\.",
      "year" : 2015
    }, {
      "title" : "Learning to understand phrases by embedding the dictionary",
      "author" : [ "Felix Hill", "Kyunghyun Cho", "Anna Korhonen", "Yoshua Bengio." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 4:17–30.",
      "citeRegEx" : "Hill et al\\.,? 2016",
      "shortCiteRegEx" : "Hill et al\\.",
      "year" : 2016
    }, {
      "title" : "Cyc: A large-scale investment in knowledge infrastructure",
      "author" : [ "Douglas B. Lenat." ],
      "venue" : "Commun. ACM, 38(11):33– 38, November.",
      "citeRegEx" : "Lenat.,? 1995",
      "shortCiteRegEx" : "Lenat.",
      "year" : 1995
    }, {
      "title" : "Distributed representations of words and phrases and their compositionality",
      "author" : [ "Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg S Corrado", "Jeff Dean." ],
      "venue" : "Advances in neural information processing systems, pages 3111–3119.",
      "citeRegEx" : "Mikolov et al\\.,? 2013",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2013
    }, {
      "title" : "Contextual correlates of semantic similarity",
      "author" : [ "George A Miller", "Walter G Charles." ],
      "venue" : "Language and cognitive processes, 6(1):1–28.",
      "citeRegEx" : "Miller and Charles.,? 1991",
      "shortCiteRegEx" : "Miller and Charles.",
      "year" : 1991
    }, {
      "title" : "Wordnet: a lexical database for english",
      "author" : [ "George A Miller." ],
      "venue" : "Communications of the ACM, 38(11):39–41.",
      "citeRegEx" : "Miller.,? 1995",
      "shortCiteRegEx" : "Miller.",
      "year" : 1995
    }, {
      "title" : "Frames and semagrams",
      "author" : [ "Fons Moerdijk" ],
      "venue" : "meaning description in the general dutch dictionary. In Proceedings of the Thirteenth Euralex International Congress, EURALEX 2008.",
      "citeRegEx" : "Moerdijk,? 2008",
      "shortCiteRegEx" : "Moerdijk",
      "year" : 2008
    }, {
      "title" : "Semantic specialization of distributional word vector spaces using monolingual and crosslingual constraints",
      "author" : [ "Nikola Mrkšić", "Ivan Vulić", "Diarmuid Ó Séaghdha", "Ira Leviant", "Roi Reichart", "Milica Gašić", "Anna Korhonen", "Steve Young." ],
      "venue" : "Transactions of the Association for Computational Linguistics, 5:309–324.",
      "citeRegEx" : "Mrkšić et al\\.,? 2017",
      "shortCiteRegEx" : "Mrkšić et al\\.",
      "year" : 2017
    }, {
      "title" : "Definition modeling: Learning to define word embeddings in natural language",
      "author" : [ "Thanapon Noraset", "Chen Liang", "Larry Birnbaum", "Doug Downey." ],
      "venue" : "Thirty-First AAAI Conference on Artificial Intelligence.",
      "citeRegEx" : "Noraset et al\\.,? 2017",
      "shortCiteRegEx" : "Noraset et al\\.",
      "year" : 2017
    }, {
      "title" : "Glove: Global vectors for word representation",
      "author" : [ "Jeffrey Pennington", "Richard Socher", "Christopher Manning." ],
      "venue" : "Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1532–1543.",
      "citeRegEx" : "Pennington et al\\.,? 2014",
      "shortCiteRegEx" : "Pennington et al\\.",
      "year" : 2014
    }, {
      "title" : "Deep contextualized word representations",
      "author" : [ "Matthew Peters", "Mark Neumann", "Mohit Iyyer", "Matt Gardner", "Christopher Clark", "Kenton Lee", "Luke Zettlemoyer." ],
      "venue" : "Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 2227–2237.",
      "citeRegEx" : "Peters et al\\.,? 2018",
      "shortCiteRegEx" : "Peters et al\\.",
      "year" : 2018
    }, {
      "title" : "The generative lexicon",
      "author" : [ "James Pustejovsky." ],
      "venue" : "Computational linguistics, 17(4):409–441.",
      "citeRegEx" : "Pustejovsky.,? 1991",
      "shortCiteRegEx" : "Pustejovsky.",
      "year" : 1991
    }, {
      "title" : "Contextual correlates of synonymy",
      "author" : [ "Herbert Rubenstein", "John B Goodenough." ],
      "venue" : "Communications of the ACM, 8(10):627–633.",
      "citeRegEx" : "Rubenstein and Goodenough.,? 1965",
      "shortCiteRegEx" : "Rubenstein and Goodenough.",
      "year" : 1965
    }, {
      "title" : "Representing general relational knowledge in conceptnet 5",
      "author" : [ "Robert Speer", "Catherine Havasi." ],
      "venue" : "LREC, pages 3679–3686.",
      "citeRegEx" : "Speer and Havasi.,? 2012",
      "shortCiteRegEx" : "Speer and Havasi.",
      "year" : 2012
    }, {
      "title" : "Dict2vec: Learning word embeddings using lexical dictionaries",
      "author" : [ "Julien Tissier", "Christophe Gravier", "Amaury Habrard." ],
      "venue" : "Conference on Empirical Methods in Natural Language Processing (EMNLP 2017), pages 254–263.",
      "citeRegEx" : "Tissier et al\\.,? 2017",
      "shortCiteRegEx" : "Tissier et al\\.",
      "year" : 2017
    }, {
      "title" : "Word lookup on the basis of associations: From an idea to a roadmap",
      "author" : [ "Michael Zock", "Slaven Bilac." ],
      "venue" : "Proceedings of the Workshop on Enhancing and Using Electronic Dictionaries, ElectricDict ’04, pages 29–35, Stroudsburg, PA, USA. Association for Computational Linguistics.",
      "citeRegEx" : "Zock and Bilac.,? 2004",
      "shortCiteRegEx" : "Zock and Bilac.",
      "year" : 2004
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "DF dimensions correspond to the Qualia structure relations (Boguraev and Pustejovsky, 1990): a set of relations that uniquely define a term.",
      "startOffset" : 59,
      "endOffset" : 91
    }, {
      "referenceID" : 13,
      "context" : "Although a few approaches have tried to bridge the gap between semantics and distributed representations (Faruqui et al., 2015; Mrkšić et al., 2017), (1) they only encode information from ontologies, which are not extensible, and (2) the final representations are still not semantically meaningful.",
      "startOffset" : 105,
      "endOffset" : 148
    }, {
      "referenceID" : 24,
      "context" : "Although a few approaches have tried to bridge the gap between semantics and distributed representations (Faruqui et al., 2015; Mrkšić et al., 2017), (1) they only encode information from ontologies, which are not extensible, and (2) the final representations are still not semantically meaningful.",
      "startOffset" : 105,
      "endOffset" : 148
    }, {
      "referenceID" : 5,
      "context" : "The set of the relations used is based on the Qualia structure suggested in (Boguraev and Pustejovsky, 1990), and they are extracted automatically from definitions via a domain-adaptation approach.",
      "startOffset" : 76,
      "endOffset" : 108
    }, {
      "referenceID" : 5,
      "context" : "Such work includes the Qualia structure (Boguraev and Pustejovsky, 1990) and the generative lexicon theory (Pustejovsky, 1991).",
      "startOffset" : 40,
      "endOffset" : 72
    }, {
      "referenceID" : 28,
      "context" : "Such work includes the Qualia structure (Boguraev and Pustejovsky, 1990) and the generative lexicon theory (Pustejovsky, 1991).",
      "startOffset" : 107,
      "endOffset" : 126
    }, {
      "referenceID" : 2,
      "context" : "Other related work includes ontological approaches (Baker et al., 1998; Miller, 1995; Lenat, 1995; Speer and Havasi, 2012) and more fine-grained definition-based frames like Semagrams (Moerdijk and others, 2008).",
      "startOffset" : 51,
      "endOffset" : 122
    }, {
      "referenceID" : 22,
      "context" : "Other related work includes ontological approaches (Baker et al., 1998; Miller, 1995; Lenat, 1995; Speer and Havasi, 2012) and more fine-grained definition-based frames like Semagrams (Moerdijk and others, 2008).",
      "startOffset" : 51,
      "endOffset" : 122
    }, {
      "referenceID" : 19,
      "context" : "Other related work includes ontological approaches (Baker et al., 1998; Miller, 1995; Lenat, 1995; Speer and Havasi, 2012) and more fine-grained definition-based frames like Semagrams (Moerdijk and others, 2008).",
      "startOffset" : 51,
      "endOffset" : 122
    }, {
      "referenceID" : 30,
      "context" : "Other related work includes ontological approaches (Baker et al., 1998; Miller, 1995; Lenat, 1995; Speer and Havasi, 2012) and more fine-grained definition-based frames like Semagrams (Moerdijk and others, 2008).",
      "startOffset" : 51,
      "endOffset" : 122
    }, {
      "referenceID" : 26,
      "context" : "In distributional semantics, approaches including GloVe (Pennington et al., 2014), word2vec (Mikolov et al.",
      "startOffset" : 56,
      "endOffset" : 81
    }, {
      "referenceID" : 20,
      "context" : ", 2014), word2vec (Mikolov et al., 2013), and fastText (Bojanowski et al.",
      "startOffset" : 18,
      "endOffset" : 40
    }, {
      "referenceID" : 6,
      "context" : ", 2013), and fastText (Bojanowski et al., 2017) obtain generic word embeddings by pre-training on large corpora.",
      "startOffset" : 22,
      "endOffset" : 47
    }, {
      "referenceID" : 27,
      "context" : "Recent work focused on context-sensitive embeddings like ELMo (Peters et al., 2018) and BERT (Devlin et al.",
      "startOffset" : 62,
      "endOffset" : 83
    }, {
      "referenceID" : 11,
      "context" : ", 2018) and BERT (Devlin et al., 2018), which achieve significant improvements in downstream NLP tasks.",
      "startOffset" : 17,
      "endOffset" : 38
    }, {
      "referenceID" : 3,
      "context" : "Earlier work on definitions extracted the type of a concept (Genus) and the relations distinguishing it from other members of the same type (Differentia) via syntax and string matching heuristics (Binot and Jensen, 1993; Calzolari, 1984; Chodorow et al., 1985).",
      "startOffset" : 196,
      "endOffset" : 260
    }, {
      "referenceID" : 9,
      "context" : "Earlier work on definitions extracted the type of a concept (Genus) and the relations distinguishing it from other members of the same type (Differentia) via syntax and string matching heuristics (Binot and Jensen, 1993; Calzolari, 1984; Chodorow et al., 1985).",
      "startOffset" : 196,
      "endOffset" : 260
    }, {
      "referenceID" : 10,
      "context" : "Earlier work on definitions extracted the type of a concept (Genus) and the relations distinguishing it from other members of the same type (Differentia) via syntax and string matching heuristics (Binot and Jensen, 1993; Calzolari, 1984; Chodorow et al., 1985).",
      "startOffset" : 196,
      "endOffset" : 260
    }, {
      "referenceID" : 25,
      "context" : "Other work includes definition generation (Noraset et al., 2017), binary classification of sentences on whether they are definitional (Anke and Schockaert, 2018), reverse dictionary look-up (Hill et al.",
      "startOffset" : 42,
      "endOffset" : 64
    }, {
      "referenceID" : 1,
      "context" : ", 2017), binary classification of sentences on whether they are definitional (Anke and Schockaert, 2018), reverse dictionary look-up (Hill et al.",
      "startOffset" : 77,
      "endOffset" : 104
    }, {
      "referenceID" : 18,
      "context" : ", 2017), binary classification of sentences on whether they are definitional (Anke and Schockaert, 2018), reverse dictionary look-up (Hill et al., 2016; Zock and Bilac, 2004), and extraction of hypernymy relations from definitions using syntactic patterns (Boella and Di Caro, 2013).",
      "startOffset" : 133,
      "endOffset" : 174
    }, {
      "referenceID" : 32,
      "context" : ", 2017), binary classification of sentences on whether they are definitional (Anke and Schockaert, 2018), reverse dictionary look-up (Hill et al., 2016; Zock and Bilac, 2004), and extraction of hypernymy relations from definitions using syntactic patterns (Boella and Di Caro, 2013).",
      "startOffset" : 133,
      "endOffset" : 174
    }, {
      "referenceID" : 15,
      "context" : "Qualia Structure Besides domain-specific relations, most Relation Extraction tasks (Gábor et al., 2018; Hendrickx et al., 2009) contain relations describing the type (isA), structure (madeOf, partOf, hasA), function (usedFor), or provenance (createdBy) of a concept.",
      "startOffset" : 83,
      "endOffset" : 127
    }, {
      "referenceID" : 16,
      "context" : "Qualia Structure Besides domain-specific relations, most Relation Extraction tasks (Gábor et al., 2018; Hendrickx et al., 2009) contain relations describing the type (isA), structure (madeOf, partOf, hasA), function (usedFor), or provenance (createdBy) of a concept.",
      "startOffset" : 83,
      "endOffset" : 127
    }, {
      "referenceID" : 5,
      "context" : "This set of relation categories corresponds to the Qualia structure (formal, constitutive, telic, and origin), which is defined as the complete modes of explanation associated with an entity (Boguraev and Pustejovsky, 1990; Pustejovsky, 1991).",
      "startOffset" : 191,
      "endOffset" : 242
    }, {
      "referenceID" : 28,
      "context" : "This set of relation categories corresponds to the Qualia structure (formal, constitutive, telic, and origin), which is defined as the complete modes of explanation associated with an entity (Boguraev and Pustejovsky, 1990; Pustejovsky, 1991).",
      "startOffset" : 191,
      "endOffset" : 242
    }, {
      "referenceID" : 30,
      "context" : "ConceptNet (Speer and Havasi, 2012) is a general purpose ontology that contains relations between pairs of concepts, accompanied by a small source-sentence.",
      "startOffset" : 11,
      "endOffset" : 35
    }, {
      "referenceID" : 17,
      "context" : "Word-Similarity Task We perform experiments on benchmark word-similarity datasets provided by Faruqui (2014): SimLex999 (Hill et al., 2015), MC30 (Miller and Charles, 1991), RG65 (Rubenstein and Goodenough, 1965), WS353 (Finkelstein et al.",
      "startOffset" : 120,
      "endOffset" : 139
    }, {
      "referenceID" : 21,
      "context" : ", 2015), MC30 (Miller and Charles, 1991), RG65 (Rubenstein and Goodenough, 1965), WS353 (Finkelstein et al.",
      "startOffset" : 14,
      "endOffset" : 40
    }, {
      "referenceID" : 29,
      "context" : ", 2015), MC30 (Miller and Charles, 1991), RG65 (Rubenstein and Goodenough, 1965), WS353 (Finkelstein et al.",
      "startOffset" : 47,
      "endOffset" : 80
    }, {
      "referenceID" : 14,
      "context" : ", 2015), MC30 (Miller and Charles, 1991), RG65 (Rubenstein and Goodenough, 1965), WS353 (Finkelstein et al., 2002) and MEN (Bruni et al.",
      "startOffset" : 88,
      "endOffset" : 114
    }, {
      "referenceID" : 26,
      "context" : "We perform experiments with three types of embeddings used as Basis: GloVe (Pennington et al., 2014), dict2vec trained on Wikipedia (Tissier et al.",
      "startOffset" : 75,
      "endOffset" : 100
    }, {
      "referenceID" : 31,
      "context" : ", 2014), dict2vec trained on Wikipedia (Tissier et al., 2017), and retrofit embeddings (Faruqui et al.",
      "startOffset" : 39,
      "endOffset" : 61
    }, {
      "referenceID" : 13,
      "context" : ", 2017), and retrofit embeddings (Faruqui et al., 2015) based on GloVe.",
      "startOffset" : 33,
      "endOffset" : 55
    } ],
    "year" : 2020,
    "abstractText" : "Advances in word representations have shown tremendous improvements in downstream NLP tasks, but lack semantic interpretability. In this paper1, we introduce Definition Frames (DF), a matrix distributed representation extracted from definitions, where each dimension is semantically interpretable. DF dimensions correspond to the Qualia structure relations (Boguraev and Pustejovsky, 1990): a set of relations that uniquely define a term. Our results show that DFs have competitive performance with other distributional semantic approaches on word similarity tasks.",
    "creator" : "LaTeX with hyperref"
  }
}