{
  "name" : "COLING_2020_76_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Variation in Coreference Strategies across Genres and Production Media",
    "authors" : [ ],
    "emails" : [ "email@domain", "email@domain" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Research on strategies for producing referring expressions has often investigated the differences (if any) between spoken and written language, but as we will show in Section 2, results have been inconclusive. Sometimes, claims are simply contradictory, but the more important problem is that usually, the exact ways of measuring the properties of coreference chains are not being made transparent. In addition, the data that has been used can vary considerably, and it is not always clear how studies can be compared.\nOur primary goal here is to shed light on coreference with respect to the spoken/written distinction, by undertaking a careful comparative corpus analysis and explicitly stating our methods of measurement.\nThe secondary goal is to explore how the medium microblog, specifically Twitter, relates to the spokenwritten spectrum for coreference strategies. While Twitter has been applied widely for NLP tasks such as sentiment analysis or information extraction, it has received very little attention on the side of coreference so far. To illustrate, we used an out-of-the-box contemporary coreference resolver (Lee et al., 2018), set to coarse-to-fine inference, and obtained an F1 score of 72.6% on the standard OntoNotes test data (Pradhan et al., 2013), and in contrast a score of only 45.2% on the corpus of Twitter conversations.\nIn an earlier study, Aktaş et al. (2018) outlined peculiar anaphoric cases in Twitter conversations, such as exophoric references to non-linguistic content in pictures attached to the messages, or mixed personal pronominal references to the same entity due to the nature of multi-user conversations. Our paper goes a step further and situates coreference strategies found in Twitter conversations in a comparative empirical study of coreference in spoken versus written texts. For the latter, we build on (Aktaş et al., 2019), who presented a quantitative study on different genre sections of the OntoNotes corpus. We extend their study by broadening the data base in two directions: We augment the rather small proportion of spoken data in Ontonotes with the Switchboard corpus (Godfrey et al., 1992), and we add the comparison with Twitter texts, thus achieving both broader coverage of speech and a wider range of production media. Although Switchboard and OntoNotes have previously both been used for investigating coreference, to our knowledge they have not yet been systematically compared. Accordingly, an important part of our work is in harmonizing the data sets and the underlying annotation schemes, to enable a sensible analysis.\nWe will show genre-specific distributional patterns of nominal referring expressions in terms of frequency of syntactic categories, heaviness of NP structures, and relative distance between anaphors and antecedents in the text. Most of our analyses lead to a common ranking of the genres, as discussed in\nSection 5. In addition to the theoretical value, we believe that the observed patterns can provide a basis for data-driven design of automated coreference resolution tools that perform better on spoken or Twitter language than the current ”out of the box” systems do.\nThe following section presents related work. Section 3 introduces data sources and corpus alignment strategies we applied to harmonize the data. Section 4 presents the measures we used for the comparison, and the results of the analyses, which are further discussed in Section 5, concentrating on the comparison of the genres and production media. Section 6 summarizes and shows directions for future work."
    }, {
      "heading" : "2 Related Work",
      "text" : "Coreference across genres and media. Various linguistic coreference phenomena have been compared by researchers in different domains such as across languages (Lapshinova-Koltunski, 2015; Kunz and Lapshinova-Koltunski, 2015; Engell, 2016; Kunz et al., 2016), regional language varieties (Neumann and Fest, 2016), production media (spoken, written, web) (Fox, 1987; Biber, 1992; Amoia et al., 2012) and across genres in these domains. Among the features, frequency-based statistics and distance measurements are most prominent. For distance between referring expressions and their antecedents (the closest previous mention of the same referent), different metrics have been used in the studies, and the results sometimes point into different directions. For example, Biber et al. (1999) and Kunz et al. (2016) measured the distance in terms of number of tokens. Both teams found that the average distance is longer in spoken texts than in written texts. Fox (1987) measured the distance in terms of number of clauses, and arrived at the same observation. In contrast, Amoia et al. (2012) measured the distance in terms of sentences and concluded that the average distance is longer in written texts than in spoken texts. The same claim was made by Biber (1992), who computed distance as the number of interfering mentions. — These partly-incompatible outcomes indicate that textual distance metrics are not easily comparable; for instance, the distance in terms of tokens may not always correspond to distance in terms of clauses or sentences. This is one of the aspects we will address in this paper.\nOther phenomena that have been studied include the distribution of referring expressions in terms of their syntactic categories, i.e., pronouns vs. noun phrases (NPs). Fox (1987) argued that referential NPs are generally more frequent in written texts than in spoken conversations (47% in written texts vs. 22% in conversations), whereas Biber et al. (1999) and Amoia et al. (2012) found different characteristics: On the one hand, they confirm Fox’s finding that NPs are more frequently used than pronouns in the written medium than in the spoken medium. But in written text, according to Amoia et al. (2012)), NPs are more frequent than pronouns as well (63% NPs vs. 29% pronouns), which is not in line with (Fox, 1987). For length, they found that the avg. number of tokens of referring expression in their written data is 3.42, compared to 2.58 for spoken data. Another interesting finding on the distribution of syntactic categories is that narrative genres (fiction) show spoken-like characteristics in terms of pronoun usage (Biber, 1992; Biber et al., 1999; Amoia et al., 2012; Neumann and Fest, 2016; Lapshinova-Koltunski, 2015).\nFurther quantitative metrics of coreference phenomena used in the literature are the number of referring expressions (Biber, 1992; Schnedecker, 2018), number of referents (Biber, 1992; Kunz et al., 2016), and chain length (Biber, 1992; Amoia et al., 2012; Kunz et al., 2016; Schnedecker, 2018). We did not examine these features because in OntoNotes, documents can be artificially split in smaller parts, and because singletons are not annotated (see Sct. 3); therefore, these metrics may create misleading results.\nAlthough it is heavily used for coreference research, OntoNotes has to our knowledge not been extensively examined for quantitative comparison of reference features across genres. Exceptions are Hardmeier et al. (2018), who investigated how organisational entities are being referred to, and found a correlation between preferred reference type and genre (e.g., pronouns are more common in telephone conversations than newswire and broadcast news). Zeldes (2018) used OntoNotes for predicting ’notional anaphora’1 and found it to be more common in broadcast conversations than in newswire. Zeldes used 20 linguistic features, and genre emerged as the third-most important one, which indicates that observed differences between genres can have a strong impact on automatic classification.\n1This denotes pronouns disagreeing with their antecedents’ grammatical categories for notional reasons, e.g., “the government ... they.”\nAutomatic coreference resolution for “non-standard” language. Only few studies have addressed performance differences of coreference systems across the genres of Ontonotes. Pradhan et al. (2013) reported that their system of choice showed better performance on telephone conversations (64%) than on news texts (56%) and broadcast news (59%). The authors evaluated which sections turned out to be the “easiest” but did not assess the possible reasons. Another study that looks in detail at performance differences in OntoNotes (and also in two other corpora) is that of Uryupina and Poesio (2012), who compared the performance of domain-specific and generic models, for both knowledge-poor statistical systems and for implementations using hand-crafted linguistic features.\nSimilarly, coreference resolution specifically for spoken data has not received much attention. Beside work on the rather domain-specific data of the TRAINS corpus by Byron (2002), Eckert and Strube (2000) worked with the Switchboard corpus and gave results for an algorithm resolving personal and demonstrative pronouns. They found that pronoun usage differs considerably from that in written text, because of a high frequency of both non-nominal antecedents and pronouns with no antecedent at all. Strube and Müller (2003) refined the algorithm, and we are not aware of more recent work in this vein.\nWhile Twitter has been tackled for standard preprocessing tasks like POS tagging or NER, to our knowledge there is no research on coreference resolution yet, except for the study by Aktaş et al. (2018) who tested an out-of-the-box resolver on Twitter data and found a similar result as we did in our experiment mentioned in Section 1."
    }, {
      "heading" : "3 Corpora",
      "text" : "We use three English-language data sources for our empirical study. See Table 1 for a summary, whose numbers are computed after harmonizing the corpora with respect to the criteria described in Sct. 3.4."
    }, {
      "heading" : "3.1 TwitterThreads",
      "text" : "The conversational Twitter corpus (tw) was built by (Aktaş et al., 2018). After constructing the conversational full tree structures for randomly chosen tweets that generated replies, they kept only the longest thread (a path from the root to a leaf node) from each tree and discarded all other branches, so there is no tweet overlap in the data. The corpus holds 43K tokens distributed across 1756 tweets arranged in 185 threads. The sentence segments in tweets are identified using the SoMaJo sentence splitter (Proisl and Uhrig, 2016). Boundary errors in complicated cases (e.g., when sentences in the same tweet start with a lowercase letter or a hashtag, or users omit punctuation) were manually corrected. As shown in Table 1, 1525 coreference chains are annotated in the corpus. Of these, 1055 contain intertweet references (i.e. at least one of the mentions in the chain is located in a different tweet than the rest). Further investigation of the links for each anaphora-antecedent pair showed that 50% of the coreferential links are established across tweets. Hence, for coreference resolution it is indeed important to consider the conversation context."
    }, {
      "heading" : "3.2 OntoNotes",
      "text" : "The OntoNotes corpus (ont) consists of multi-language data from a range of different sources, including translations, and offers gold annotations at different linguistic layers such as part of speech tags, syntactic constituent parses and coreference chains. In our study, we used only the original English data, in order to avoid effects from potential translation divergences. The resulting data portion consists of both spoken and written language. Spoken data includes telephone conversations (tc), and broadcast TV conversations (bc), whereas written data is composed of newswire texts (nw) and web blogs (wb). Finally there are broadcast news (bn), which are produced in the spoken medium but mostly contain prepared speeches (i.e., edited language).\nWe used the CoNLL-formatted OntoNotes data (Pradhan et al., 2013). As shown in Table 1, the corpus contains 903K tokens distributed across 2040 documents2. The distribution of the various genres is also presented in the table."
    }, {
      "heading" : "3.3 Switchboard",
      "text" : "Switchboard (swbd) is a long-standing corpus of conversational speech (Godfrey et al., 1992). The original dataset is composed of approximately 2,400 spontaneous telephone conversations between unacquainted speakers of American English. The data is collected in an experimental setup where two strangers were given a topic from a predefined list and expected to have a conversation on it. Calhoun et al. (2010) brought together the various annotations made on the corpus and delivered a combined resource in NITE XML (NXT) format. 147 of the dialogs in NXT-Switchboard, all in separate documents, are annotated for coreference. In Switchboard, coreference links are marked as anaphorantecedent pairs. We constructed complete chains from these pairs. The corpus contains 248K tokens in 147 documents, where 23K mentions are annotated in 6.8K coreference chains (see Table 1)."
    }, {
      "heading" : "3.4 Corpus Homogenity",
      "text" : "Transcription The spoken texts can differ in terms of the transcription procedures applied. For instance, in Switchboard, silence moments and spots of grammatical ellipsis are inserted as separate tokens into the transcribed texts, whereas in Ontonotes, only the surface linguistic forms and punctuations are considered as tokens. In addition to this, unlike OntoNotes, repairs and false starts (i.e. reparanda) are also included in Switchboard transcriptions. We do not take these additional tokens in Switchboard into consideration in this study. Tokens marked by a META tag in OntoNotes which are referring to the metadata of the texts, such as the ”Reporter” of broadcast news, are not considered in this analysis either.\nTokenization All the investigated corpora follow PTB tokenization conventions3 with various adaptations based on the specific string types included in the texts. For instance, smileys, emojis, hashtags (#TIMESUP) and links (https://t.co/Bgyj3U71HK) are considered as single tokens in Twitter texts, which would be handled in a different way in standard PTB tokenization scheme. The usernames of the conversation participants in tw thread structure, introduced by the @ sign, are automatically added to the content of the reply message in Twitter. Since these are not inserted to the post intentionally by the user, we consider such usernames (4.9K in total) as part of the metadata of the tweet and do not count them as tokens in the text.\nLinguistic Annotation OntoNotes and Switchboard have gold part-of-speech (PoS) and syntax (i.e. constituency parse trees) annotation layers compatible with Penn TreeBank conventions (Taylor et al., 2003). TwitterThreads do not come with gold annotations for these layers. We thus use the Stanford parser (Manning et al., 2014) to automatically create the PoS and syntax annotations for Twitter texts, which are also compatible with PTB conventions. However, the predicted parses are not reliably accurate for tweet texts, and therefore we manually checked and corrected the structures computed through these parses in our analysis. The applied procedures are described below.\n2In OntoNotes terminology, documents are the units of independent annotation. 3ftp://ftp.cis.upenn.edu/pub/treebank/public_html/tokenization.html\nThe other annotation layer of interest is the coreference annotations. All three corpora contain gold annotations for coreference, but with various differences in the definition of markables. For instance, in OntoNotes and Switchboard, singletons, copula constructions, headless relative clauses and appositions are not annotated (Pradhan et al., 2007; Calhoun et al., 2010). Hence, for compatibility, we ignore these type of mentions in the tw corpus.\nAs specified in OntoNotes guidelines (BBN Technologies, 2007), verbs are annotated as mentions in the OntoNotes corpus when they refer to the same entity as a nominal mention. An example chain containing a verbal entity is “chain meeting=[met, the meeting, the APEC meeting, it]”. Since we want to focus on nominal coreference (which is also in line with the majority of work in coreference resolution), we excluded these non-nominal mentions in OntoNotes in our analyses.\nAnother difference in the coreference annotation schemes is encountered in Switchboard, where only markables with information status ”old” are annotated for coreference (Calhoun et al., 2010). However, not all candidates of referential expressions compatible with the markable definition are annotated for information status. This indicates that annotated coreference chains do not cover the complete set of nonsingleton entities in the texts in Switchboard. Therefore, we chose not to include the cumulative metrics of referential expressions (number of coreference chains, number of mentions) in our comparative analysis. Table 1 shows the summary statistics for annotations, but they are not fully comparable due to this design preference in Switchboard. Although the selection criteria for markables are not clearly described in the Switchboard documentation, we assume that the annotated chains are internally complete (i.e., all mentions for an annotated entity are marked), and therefore, can serve our purposes in terms of the chain internal features we investigated (i.e. distance-based comparison in Section 4.4)."
    }, {
      "heading" : "4 Data Analysis",
      "text" : "We use frequency-, heaviness- and distance-metrics in the quantitative comparison of the (sub-)corpora surveyed in Table 1."
    }, {
      "heading" : "4.1 Delimiting NPs",
      "text" : "For computing the frequency and heaviness measures we need to identify the boundaries of NPs in the texts. As mentioned in Section 3, OntoNotes and Switchboard have gold part-of-speech (PoS) and syntax annotations compatible to PTB conventions. These annotation layers are used to detect the NP structures in swbd and ont. However, Noun phrases can be embedded in each other, and hence the boundaries can differ according to the detection procedure applied. For instance, the string ”an invasion of the privacy” can be recognized as one single large span NP, two short span NPs (”an invasion” and ”the privacy”) or three NPs (”an invasion of the privacy”, ”an invasion” and ”the privacy”).\nWe compute NP-based metrics both considering the large and the short NP spans. To detect the large NP spans, we traverse the sentence parse trees in a top down breadth-first manner and extract the first encountered NP nodes in each branch (e.g. ”an invasion of the privacy”). For short NP spans, we traverse the tree in a top down depth-first manner but extracting the last encountered NP nodes this time in each branch (e.g. ”an invasion” and ”the privacy”).\nAs TwitterThreads do not have gold PoS and syntax annotations, we apply a semi-automated procedure for identifying the NP boundaries in tw texts. After creating the constituency trees with the Stanford parser and detecting NP boundaries in the trees, we correct all the detected NP spans manually. This step is necessary, because we observe that 75% of the short span NPs are identified correctly by the predicted parses, in contrast to only 40% of the large span NPs.\nRegarding the non-standard tokens in Twitter, we consider emojis, smileys and links as NPs only if they have a syntactic role of an NP in a sentence as shown in brackets in examples 1 and 2 below. There are 4 cases among 553 emojis and 4 cases among 340 links in tw corpus, where emojis and links are considered as NPs.\n(1)\n(2) If crashing, please refer to this: [https://t.co/NCvwPFGeaM]\nThe automatically-inserted usernames at the beginning of reply tweets are not considered as NPs (ex. 3). However, we see names that are integrated in sentence syntax or at the end of a tweet as purposefully added and thus count them as NPs (ex. 4). This holds for 179 of the 5K usernames in the tw corpus.\n(3) @brycetache @TeresaMac2009 @BarackObama Thank you Obama!\n(4) [@JoeNBC] just said twice [the @washingtonpost] deleted his unnamed quotes.\nThere are 205 instances of hashtags in tw, which we all consider as NPs. However, handling differs according to the syntactic function of the hashtag: We regard those with a syntactic role of an NP in sentence structure as separate NPs (e.g. #SecretaryofState in ex. 5). Hashtags that are not syntactically integrated, and placed at the beginning or end of a tweet are also considered as NPs; but in case of more than 1 consecutive hashtag (also in ex. 5), they form a single NP. The content of a hashtag may contain several words (e.g. #SecretaryofState), but we do not do any segmentation. Hence, regardless of actual content, hashtags are always considered as single token in all our computations presented below.\n(5) The only Russia collusion occurred when @HillaryClinton conspired to seel US Uranium to a Russian oligarch while she was [#SecretaryofState]. [#RussiaCollusion #UraniumOne]\nAfter detecting the NP structures, we differentiated the personal pronouns (PRPs) by the PoS categories in ont and swbd, and by pronoun types in gold coreference annotation in the tw corpus. We classify their ”person” feature (i.e. 1st, 2nd, 3rd) by string matching. Pronoun variants stemming from transcription (e.g.,”yo-”,”em”) or speaker’s choices such as contracted forms of nominal pronouns in tw (e.g.,”im”,”hes”,”youve”) are also considered as valid pronoun forms."
    }, {
      "heading" : "4.2 Frequency-based Features",
      "text" : "As frequency-based metrics for the genre/medium comparison, we computed the relative distribution of nominal expressions according to their syntactic categories (i.e. PRPs vs. NPs) and distribution of PRPs according to the grammatical person feature (i.e. 1st, 2nd and 3rd person PRPs).\nResults Table 2 gives descriptive statistics for NP and PRP instances, and Figure 1 shows the distribution of large span NPs and PRPs, where the differences between genres are confirmed to be statistically significant (p-value<0.05). The representative chart for the pronoun distribution in terms of grammatical person is shown in Figure 2. All the differences between genres except the swbd-tc pair are statistically significant (p-value<0.05)."
    }, {
      "heading" : "4.3 Heaviness-based Features",
      "text" : "A variety of definitions for the heaviness of noun phrases has been proposed in the literature. Wasow (1997) classifies these definitions into two groups. The first group contains the categorical definitions relying on, for instance, the type of nodes dominated, or the givenness of the constituents involved. The other group is composed of graded measures such as number of words included, or nodes/phrasal nodes\n4Personal pronouns are not included in this count.\ndominated. Wasow compares these measures in the context of constituency ordering and concludes that graded measures are more descriptive in that context and they all work well according to the corpusbased evidence presented. As Wasow’s analysis indicates that number of words in NPs is sufficiently robust to evaluate the heaviness, we use a slightly modified version of this metric and count the number of tokens in noun phrases (i.e. NP-Length) as the measure of heaviness of NPs. In addition to the length, we also considered the number of nodes in NP parse trees (i.e. NP-Height) as a second measure. It is computed with the constituency parses in ont and swbd, while for tw, we run the Stanford parser on gold NP spans and use the automatically created parse trees for calculating NP-Height. We do not apply manual verification of the parse trees for this measure. We compute the heaviness metrics for both large and short span NPs, and we exclude personal pronouns in heaviness-based comparison of NPs.\nResults The average NP-Length and NP-Height values across genres are shown in Table 3. The differences in average NP-Length are statistically significant for all the pairs except tw-tc for large span NPs and bn-wb pair for short span NPs (p-value<0.05). The differences in average NP-Height are statistically significant for all the pairs except tw-tc for large span NPs, and swbd-tc and bn-wb pairs for short span NPs (p-value<0.05)."
    }, {
      "heading" : "4.4 Distance-based Features",
      "text" : "We measured the linear distance between anaphoric 3rd person pronouns and their antecedents in terms of tokens, clauses and noun phrases. We excluded non-anaphoric intensifier self-forms of 3rd person pronouns (e.g. ”The prisoner himself can come to the points”) in distance-based computations.\nA qualitative investigation of long distance anaphor-antecedent links in Switchboard indicates that long anaphoric distances can arise from the missed antecedents or wrong matching of pairs for that corpus (e.g. in example 6 there are 1699 tokens between two instances of ”they”, but an additional mention for that entity -channel thirteen- was mistakenly not annotated). To get rid of the potential side effects of the misleading annotations, we did not take into consideration anaphoric distances that are longer than 500 tokens, 100 clauses or 150 NPs in Switchboard.\n(6) [they] mention sulfur and carbon dioxide a lot [..] and channel thirteen [they]’re really um emphasizing the problem with acid rain.\nToken-based Distance We count the number of tokens between the initial tokens of two mentions to calculate the linear token-based distance (TBD) between them. As mentioned in Section 3.4, the hashtags and usernames that are not automatically inserted by the UI, as well as emojis, links, and smileys are considered as single tokens in the tw corpus. Other tokens in all genres are compatible with PTB conventions. Discourse markers such as the fillers ”um”, ”uhm”, ”well” are frequent in spoken genres (for statistics, see Table 1). To see the impact of these tokens on TBD, we additionally measured the distance without considering discourse markers (TBD′).\nClause-based Distance The first step in measuring the clause-based distance (CBD) between two mentions is determining the clause boundaries in the texts. We use the constituency parse trees to detect the clause boundaries in the same way as done by (Aktaş et al., 2019). We manually correct the identified clause boundaries for tw corpus due to low accuracy of automatically created parse trees. Automatically inserted @-usernames are not considered as part of the clauses in tw. Common expressions in tw texts such as “LOL”, “haha” and emojis, hashtags are themselves not clauses, but they can be a part if they are used at the end of a clause as in “he said that lol” or they are part of the syntactic structure as in ”this doesn’t pass the #smelltest”. We marked the first token of each identified clause and counted the number of marked tokens between two mentions to calculate the CBD. As shown in Table 1, parenthetical clauses (PRNs) are frequent in spoken genres. To see their impact on CBD, we additionally measured the distance without considering parentheticals (CBD′).\nNP-Based Distance We count the number of (short span) nominal expressions between two mentions to calculate the linear NP-based distance (NBD) between them. All the nominal expressions including PRPs are considered in the calculation of NBD. We also compute the NBD without considering NPs in parentheticals (NBD′).\nResults Table 4 shows the average values for distance metrics. The statistical significance tests indicate that the differences among genres in terms of TBD values (for both settings) can be due to chance. The statistical significance tests for CBD indicate that differences between tw and spoken genres (tw-tc for CBD, tw-tc and tw-swbd for CBD′) and between two written genres (nw-wb) can be due to chance. Apart from those, all the differences in CBD are statistically significant (p-value<0.05) for both settings. For NBD, except from the bn-wb, nw-wb pairs, all the differences are statistically significant. However, when nominals in parentheticals are excluded (i.e. for NBD′), the differences in bc-nw and tw-swbd pairs become not significant."
    }, {
      "heading" : "5 Discussion",
      "text" : "”Spoken” and ”written” are in one sense trivial, but from a linguistic perspective fairly problematic concepts. Following the notion of ”conceptual orality” by Koch and Oesterreicher (1985), we do not assume a binary distinction but a continuum from ”close” to ”distant” language, which only loosely corresponds to the two media. In OntoNotes, for example, the ”broadcast news” genre contains edited speech that differs in many ways from the spontaneous speech of ”telephone conversations”.\nOur analyses in the previous sections lead to rankings of the genres, which collectively suggest a general pattern. We observe that two spontaneous spoken genres swbd/tc and two written genres nw/wb are always located closely (if not adjacent) in the ranking of genres in terms of the average values of the features investigated, and they are situated at the opposite ends.\nOur frequency-based analysis shows that the relative frequencies of pronouns and NPs in the swbd/tc pair are close to each other, whereas NPs are much more dominant in nw/wb. The comparison of distance-based features indicates that the textual distance between anaphoric pronouns and their antecedents are longer in swbd/tc than nw/wb. And lastly, nw/wb genres contain heavier NPs than swbd/tc do. These inter-medium differences are statistically significant for all the measures except TBD, whereas for a number of cases, as demonstrated in Sct. 4, intra-medium differences were not confirmed statistically. The significance levels can differ when parentheticals and discourse markers are excluded in the computation of features, but these differences do not affect the statistical significance levels between the swbd/tc and nw/wb pairs. The placement of the bc and tw genres in our genre ranking differs according to the measure. For instance, tw is located close to the swbd/tc pair w.r.t. NP-Length, but to nw/wb pair w.r.t. NBD.\nIn addition to rankings derived from average-value orderings, we also used hierarchical clustering for grouping the genres based on the quantitative features. We first normalized the data size, and then applied the hclust method in R with default settings. Similar to the observations mentioned above, the swbd/tc and nw/wb pairs are always grouped together for all the metrics except NBD for swbd/tc and NP-Height (Short Span) for nw/wb. Again, for bc and tw the grouping differs from feature to feature. For instance, in Figure 3, bc is clustered in the same branch with nw/wb, whereas in Figure 4, it is grouped together with the swbd/tc pair.\nThe ranking-based and cluster-based groupings do not always overlap (as in the NBD case), but the proximity of the swbd/tc and nw/wb pairs is observed as a common pattern in both cases. A few exceptional cases of this pattern require more attention. The groups of bc and tw depend on features: bn genre is usually grouped with the nw/wb pair as it is expected due to the edited content of the genre. The only exception is in hierarchical clustering with respect to the frequencies of personal pronouns, where bn is clustered together with swbd/tc. We consider these findings (i.e. existence of more rigid clusters as well as the floating genres between the groups) as evidence for perceiving spoken/written media as a continuum rather than discrete concepts, and it turns out that Twitter has a medium position that differs somewhat between the features."
    }, {
      "heading" : "6 Conclusions and Future work",
      "text" : "We presented an in-depth study of coreference strategies across genres that involve different production media (spoken, written). As a prerequisite, we harmonized the annotations (for syntax and coreference) of three corpora, and to our knowledge, this is the first systematic comparison of its kind. Our findings and interpretation for the spoken–written dichotomy and the placement of Twitter have been given in the previous section. In addition, we see our results as potentially fruitful for automatic pronoun resolution, viz. its adaptation to genres and media, in the light of small amounts of training data, where knowledge about the differences in strategies could be utilized. Such experiments are a part of our future work, as is a psycholinguistic study (text production experiment) designed to validate the results on the spokenwritten contrast from a perspective that is complementary to corpus analysis.\nThe analyzed data and the scripts necessary for computing the measures will be made available if the paper is accepted."
    } ],
    "references" : [ {
      "title" : "Anaphora resolution for twitter conversations: An exploratory study",
      "author" : [ "Berfin Aktaş", "Tatjana Scheffler", "Manfred Stede" ],
      "venue" : "In Proceedings of the First Workshop on Computational Models of Reference, Anaphora and Coreference,",
      "citeRegEx" : "Aktaş et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Aktaş et al\\.",
      "year" : 2018
    }, {
      "title" : "Coreference in english ontonotes: Properties and genre differences",
      "author" : [ "Berfin Aktaş", "Tatjana Scheffler", "Manfred Stede" ],
      "venue" : "In Kamil Ekštein,",
      "citeRegEx" : "Aktaş et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Aktaş et al\\.",
      "year" : 2019
    }, {
      "title" : "Coreference in spoken vs. written texts: a corpus-based analysis",
      "author" : [ "Marilisa Amoia", "Kerstin Kunz", "Ekaterina Lapshinova-Koltunski" ],
      "venue" : "In Nicoletta Calzolari (Conference Chair),",
      "citeRegEx" : "Amoia et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Amoia et al\\.",
      "year" : 2012
    }, {
      "title" : "Using computer-based text corpora to analyze the referential strategies of spoken and written texts",
      "author" : [ "Douglas Biber" ],
      "venue" : "In Jan Svartvik, editor, Directions in Corpus Linguistics: Proceedings of Nobel Symposium 82, Stockholm,",
      "citeRegEx" : "Biber.,? \\Q1992\\E",
      "shortCiteRegEx" : "Biber.",
      "year" : 1992
    }, {
      "title" : "Resolving pronominal reference to abstract entities",
      "author" : [ "Donna K. Byron" ],
      "venue" : "In Proceedings of the ACL Conference,",
      "citeRegEx" : "Byron.,? \\Q2002\\E",
      "shortCiteRegEx" : "Byron.",
      "year" : 2002
    }, {
      "title" : "The nxt-format switchboard corpus: A rich resource for investigating the syntax, semantics, pragmatics and prosody of dialogue",
      "author" : [ "Sasha Calhoun", "Jean Carletta", "Jason M. Brenier", "Neil Mayo", "Dan Jurafsky", "Mark Steedman", "David Beaver" ],
      "venue" : "Language Resources and Evaluation,",
      "citeRegEx" : "Calhoun et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Calhoun et al\\.",
      "year" : 2010
    }, {
      "title" : "Dialogue Acts, Synchronizing Units, and Anaphora Resolution",
      "author" : [ "Miriam Eckert", "Michael Strube" ],
      "venue" : "Journal of Semantics,",
      "citeRegEx" : "Eckert and Strube.,? \\Q2000\\E",
      "shortCiteRegEx" : "Eckert and Strube.",
      "year" : 2000
    }, {
      "title" : "Coreference in English and German: A Theoretical Framework and Its Application in a Study of Court Decisions",
      "author" : [ "S. Engell" ],
      "venue" : "Logos Verlag Berlin",
      "citeRegEx" : "Engell.,? \\Q2016\\E",
      "shortCiteRegEx" : "Engell.",
      "year" : 2016
    }, {
      "title" : "Discourse structure and anaphora : written and conversational English / Barbara A",
      "author" : [ "Barbara A. Fox" ],
      "venue" : null,
      "citeRegEx" : "Fox.,? \\Q1987\\E",
      "shortCiteRegEx" : "Fox.",
      "year" : 1987
    }, {
      "title" : "Switchboard: telephone speech corpus for research and development",
      "author" : [ "J. Godfrey", "E. Holliman", "J. McDaniel" ],
      "venue" : "IEEE International Conference on Speech, and Signal Processing, ICASSP-92,",
      "citeRegEx" : "Godfrey et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "Godfrey et al\\.",
      "year" : 1992
    }, {
      "title" : "Forms of anaphoric reference to organisational named entities: Hoping to widen appeal, they diversified",
      "author" : [ "Christian Hardmeier", "Luca Bevacqua", "Sharid Loáiciga", "Hannah Rohde" ],
      "venue" : "In Proceedings of the Seventh Named Entities Workshop,",
      "citeRegEx" : "Hardmeier et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Hardmeier et al\\.",
      "year" : 2018
    }, {
      "title" : "Sprache der Nähe - Sprache der Distanz. Müdlichkeit und Schriftlichkeit im Spannungsfeld von Sprachtheorie und Sprachgeschichte",
      "author" : [ "Peter Koch", "Wulf Oesterreicher" ],
      "venue" : "Romanistisches Jahrbuch,",
      "citeRegEx" : "Koch and Oesterreicher.,? \\Q1985\\E",
      "shortCiteRegEx" : "Koch and Oesterreicher.",
      "year" : 1985
    }, {
      "title" : "Cross-linguistic analysis of discourse variation across registers. Cross-linguistic Studies at the Interface between Lexis and Grammar",
      "author" : [ "Kerstin Kunz", "Ekaterina Lapshinova-Koltunski" ],
      "venue" : "Nordic Journal of English Studies.,",
      "citeRegEx" : "Kunz and Lapshinova.Koltunski.,? \\Q2015\\E",
      "shortCiteRegEx" : "Kunz and Lapshinova.Koltunski.",
      "year" : 2015
    }, {
      "title" : "Beyond identity coreference: Contrasting indicators of textual coherence in english and german",
      "author" : [ "Kerstin Kunz", "Ekaterina Lapshinova-Koltunski", "José Manuel Martı́nez" ],
      "venue" : "In Proceedings of the Workshop on Coreference Resolution Beyond OntoNotes (CORBON",
      "citeRegEx" : "Kunz et al\\.,? \\Q2016\\E",
      "shortCiteRegEx" : "Kunz et al\\.",
      "year" : 2016
    }, {
      "title" : "Exploration of inter- and intralingual variation of discourse phenomena",
      "author" : [ "Ekaterina Lapshinova-Koltunski" ],
      "venue" : "In Proceedings of the Second Workshop on Discourse in Machine Translation,",
      "citeRegEx" : "Lapshinova.Koltunski.,? \\Q2015\\E",
      "shortCiteRegEx" : "Lapshinova.Koltunski.",
      "year" : 2015
    }, {
      "title" : "Higher-order coreference resolution with coarse-to-fine inference. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)",
      "author" : [ "Kenton Lee", "Luheng He", "Luke Zettlemoyer" ],
      "venue" : null,
      "citeRegEx" : "Lee et al\\.,? \\Q2018\\E",
      "shortCiteRegEx" : "Lee et al\\.",
      "year" : 2018
    }, {
      "title" : "The Stanford CoreNLP natural language processing toolkit",
      "author" : [ "Christopher D. Manning", "Mihai Surdeanu", "John Bauer", "Jenny Finkel", "Steven J. Bethard", "David McClosky" ],
      "venue" : "In Association for Computational Linguistics (ACL) System Demonstrations,",
      "citeRegEx" : "Manning et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Manning et al\\.",
      "year" : 2014
    }, {
      "title" : "Cohesive devices across registers and varieties: The role of medium in English. In Variational text linguistics : revisiting register in English / edited by Christoph Schubert, Christina Sanchez-Stockhammer, volume 90 of Topics in English Linguistics, pages 195–220",
      "author" : [ "Stella Neumann", "Jennifer Fest" ],
      "venue" : null,
      "citeRegEx" : "Neumann and Fest.,? \\Q2016\\E",
      "shortCiteRegEx" : "Neumann and Fest.",
      "year" : 2016
    }, {
      "title" : "Unrestricted Coreference: Identifying Entities and Events in OntoNotes",
      "author" : [ "Sameer Pradhan", "Lance Ramshaw", "Ralph Weischedel", "Jessica Macbride", "Linnea Micciulla" ],
      "venue" : "International Conference on Semantic Computing,",
      "citeRegEx" : "Pradhan et al\\.,? \\Q2007\\E",
      "shortCiteRegEx" : "Pradhan et al\\.",
      "year" : 2007
    }, {
      "title" : "Towards robust linguistic analysis using ontonotes",
      "author" : [ "Sameer Pradhan", "Alessandro Moschitti", "Nianwen Xue", "Hwee Tou Ng", "Anders Björkelund", "Olga Uryupina", "Yuchen Zhang", "Zhi Zhong" ],
      "venue" : "In Proceedings of the Seventeenth Conference on Computational Natural Language Learning,",
      "citeRegEx" : "Pradhan et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Pradhan et al\\.",
      "year" : 2013
    }, {
      "title" : "SoMaJo: State-of-the-art tokenization for German web and social media texts",
      "author" : [ "Thomas Proisl", "Peter Uhrig" ],
      "venue" : "In Proceedings of the 10th Web as Corpus Workshop (WAC-X) and the EmpiriST Shared Task,",
      "citeRegEx" : "Proisl and Uhrig.,? \\Q2016\\E",
      "shortCiteRegEx" : "Proisl and Uhrig.",
      "year" : 2016
    }, {
      "title" : "Reference chains and genre identification: From discrete to non-discrete units",
      "author" : [ "Catherine Schnedecker" ],
      "venue" : "The Grammar of Genres and Styles,",
      "citeRegEx" : "Schnedecker.,? \\Q2018\\E",
      "shortCiteRegEx" : "Schnedecker.",
      "year" : 2018
    }, {
      "title" : "A machine learning approach to pronoun resolution in spoken dialogue",
      "author" : [ "Michael Strube", "Christoph Müller" ],
      "venue" : "In Proceedings of the ACL Conference,",
      "citeRegEx" : "Strube and Müller.,? \\Q2003\\E",
      "shortCiteRegEx" : "Strube and Müller.",
      "year" : 2003
    }, {
      "title" : "The Penn Treebank: An Overview",
      "author" : [ "Ann Taylor", "Mitchell Marcus", "Beatrice Santorini" ],
      "venue" : null,
      "citeRegEx" : "Taylor et al\\.,? \\Q2003\\E",
      "shortCiteRegEx" : "Taylor et al\\.",
      "year" : 2003
    }, {
      "title" : "Domain-specific vs. uniform modeling for coreference resolution",
      "author" : [ "Olga Uryupina", "Massimo Poesio" ],
      "venue" : "In Proceedings of the Eighth International Conference on Language Resources and Evaluation",
      "citeRegEx" : "Uryupina and Poesio.,? \\Q2012\\E",
      "shortCiteRegEx" : "Uryupina and Poesio.",
      "year" : 2012
    }, {
      "title" : "A predictive model for notional anaphora in english",
      "author" : [ "Amir Zeldes" ],
      "venue" : "In Proceedings of the First Workshop on Computational Models of Reference, Anaphora and Coreference,",
      "citeRegEx" : "Zeldes.,? \\Q2018\\E",
      "shortCiteRegEx" : "Zeldes.",
      "year" : 2018
    } ],
    "referenceMentions" : [ {
      "referenceID" : 15,
      "context" : "To illustrate, we used an out-of-the-box contemporary coreference resolver (Lee et al., 2018), set to coarse-to-fine inference, and obtained an F1 score of 72.",
      "startOffset" : 75,
      "endOffset" : 93
    }, {
      "referenceID" : 19,
      "context" : "6% on the standard OntoNotes test data (Pradhan et al., 2013), and in contrast a score of only 45.",
      "startOffset" : 39,
      "endOffset" : 61
    }, {
      "referenceID" : 1,
      "context" : "For the latter, we build on (Aktaş et al., 2019), who presented a quantitative study on different genre sections of the OntoNotes corpus.",
      "startOffset" : 28,
      "endOffset" : 48
    }, {
      "referenceID" : 9,
      "context" : "We extend their study by broadening the data base in two directions: We augment the rather small proportion of spoken data in Ontonotes with the Switchboard corpus (Godfrey et al., 1992), and we add the comparison with Twitter texts, thus achieving both broader coverage of speech and a wider range of production media.",
      "startOffset" : 164,
      "endOffset" : 186
    }, {
      "referenceID" : 14,
      "context" : "Various linguistic coreference phenomena have been compared by researchers in different domains such as across languages (Lapshinova-Koltunski, 2015; Kunz and Lapshinova-Koltunski, 2015; Engell, 2016; Kunz et al., 2016), regional language varieties (Neumann and Fest, 2016), production media (spoken, written, web) (Fox, 1987; Biber, 1992; Amoia et al.",
      "startOffset" : 121,
      "endOffset" : 219
    }, {
      "referenceID" : 12,
      "context" : "Various linguistic coreference phenomena have been compared by researchers in different domains such as across languages (Lapshinova-Koltunski, 2015; Kunz and Lapshinova-Koltunski, 2015; Engell, 2016; Kunz et al., 2016), regional language varieties (Neumann and Fest, 2016), production media (spoken, written, web) (Fox, 1987; Biber, 1992; Amoia et al.",
      "startOffset" : 121,
      "endOffset" : 219
    }, {
      "referenceID" : 7,
      "context" : "Various linguistic coreference phenomena have been compared by researchers in different domains such as across languages (Lapshinova-Koltunski, 2015; Kunz and Lapshinova-Koltunski, 2015; Engell, 2016; Kunz et al., 2016), regional language varieties (Neumann and Fest, 2016), production media (spoken, written, web) (Fox, 1987; Biber, 1992; Amoia et al.",
      "startOffset" : 121,
      "endOffset" : 219
    }, {
      "referenceID" : 13,
      "context" : "Various linguistic coreference phenomena have been compared by researchers in different domains such as across languages (Lapshinova-Koltunski, 2015; Kunz and Lapshinova-Koltunski, 2015; Engell, 2016; Kunz et al., 2016), regional language varieties (Neumann and Fest, 2016), production media (spoken, written, web) (Fox, 1987; Biber, 1992; Amoia et al.",
      "startOffset" : 121,
      "endOffset" : 219
    }, {
      "referenceID" : 17,
      "context" : ", 2016), regional language varieties (Neumann and Fest, 2016), production media (spoken, written, web) (Fox, 1987; Biber, 1992; Amoia et al.",
      "startOffset" : 37,
      "endOffset" : 61
    }, {
      "referenceID" : 8,
      "context" : ", 2016), regional language varieties (Neumann and Fest, 2016), production media (spoken, written, web) (Fox, 1987; Biber, 1992; Amoia et al., 2012) and across genres in these domains.",
      "startOffset" : 103,
      "endOffset" : 147
    }, {
      "referenceID" : 3,
      "context" : ", 2016), regional language varieties (Neumann and Fest, 2016), production media (spoken, written, web) (Fox, 1987; Biber, 1992; Amoia et al., 2012) and across genres in these domains.",
      "startOffset" : 103,
      "endOffset" : 147
    }, {
      "referenceID" : 2,
      "context" : ", 2016), regional language varieties (Neumann and Fest, 2016), production media (spoken, written, web) (Fox, 1987; Biber, 1992; Amoia et al., 2012) and across genres in these domains.",
      "startOffset" : 103,
      "endOffset" : 147
    }, {
      "referenceID" : 8,
      "context" : "29% pronouns), which is not in line with (Fox, 1987).",
      "startOffset" : 41,
      "endOffset" : 52
    }, {
      "referenceID" : 3,
      "context" : "Another interesting finding on the distribution of syntactic categories is that narrative genres (fiction) show spoken-like characteristics in terms of pronoun usage (Biber, 1992; Biber et al., 1999; Amoia et al., 2012; Neumann and Fest, 2016; Lapshinova-Koltunski, 2015).",
      "startOffset" : 166,
      "endOffset" : 271
    }, {
      "referenceID" : 2,
      "context" : "Another interesting finding on the distribution of syntactic categories is that narrative genres (fiction) show spoken-like characteristics in terms of pronoun usage (Biber, 1992; Biber et al., 1999; Amoia et al., 2012; Neumann and Fest, 2016; Lapshinova-Koltunski, 2015).",
      "startOffset" : 166,
      "endOffset" : 271
    }, {
      "referenceID" : 17,
      "context" : "Another interesting finding on the distribution of syntactic categories is that narrative genres (fiction) show spoken-like characteristics in terms of pronoun usage (Biber, 1992; Biber et al., 1999; Amoia et al., 2012; Neumann and Fest, 2016; Lapshinova-Koltunski, 2015).",
      "startOffset" : 166,
      "endOffset" : 271
    }, {
      "referenceID" : 14,
      "context" : "Another interesting finding on the distribution of syntactic categories is that narrative genres (fiction) show spoken-like characteristics in terms of pronoun usage (Biber, 1992; Biber et al., 1999; Amoia et al., 2012; Neumann and Fest, 2016; Lapshinova-Koltunski, 2015).",
      "startOffset" : 166,
      "endOffset" : 271
    }, {
      "referenceID" : 3,
      "context" : "Further quantitative metrics of coreference phenomena used in the literature are the number of referring expressions (Biber, 1992; Schnedecker, 2018), number of referents (Biber, 1992; Kunz et al.",
      "startOffset" : 117,
      "endOffset" : 149
    }, {
      "referenceID" : 21,
      "context" : "Further quantitative metrics of coreference phenomena used in the literature are the number of referring expressions (Biber, 1992; Schnedecker, 2018), number of referents (Biber, 1992; Kunz et al.",
      "startOffset" : 117,
      "endOffset" : 149
    }, {
      "referenceID" : 3,
      "context" : "Further quantitative metrics of coreference phenomena used in the literature are the number of referring expressions (Biber, 1992; Schnedecker, 2018), number of referents (Biber, 1992; Kunz et al., 2016), and chain length (Biber, 1992; Amoia et al.",
      "startOffset" : 171,
      "endOffset" : 203
    }, {
      "referenceID" : 13,
      "context" : "Further quantitative metrics of coreference phenomena used in the literature are the number of referring expressions (Biber, 1992; Schnedecker, 2018), number of referents (Biber, 1992; Kunz et al., 2016), and chain length (Biber, 1992; Amoia et al.",
      "startOffset" : 171,
      "endOffset" : 203
    }, {
      "referenceID" : 0,
      "context" : "The conversational Twitter corpus (tw) was built by (Aktaş et al., 2018).",
      "startOffset" : 52,
      "endOffset" : 72
    }, {
      "referenceID" : 20,
      "context" : "The sentence segments in tweets are identified using the SoMaJo sentence splitter (Proisl and Uhrig, 2016).",
      "startOffset" : 82,
      "endOffset" : 106
    }, {
      "referenceID" : 19,
      "context" : "We used the CoNLL-formatted OntoNotes data (Pradhan et al., 2013).",
      "startOffset" : 43,
      "endOffset" : 65
    }, {
      "referenceID" : 9,
      "context" : "Switchboard (swbd) is a long-standing corpus of conversational speech (Godfrey et al., 1992).",
      "startOffset" : 70,
      "endOffset" : 92
    }, {
      "referenceID" : 23,
      "context" : "constituency parse trees) annotation layers compatible with Penn TreeBank conventions (Taylor et al., 2003).",
      "startOffset" : 86,
      "endOffset" : 107
    }, {
      "referenceID" : 16,
      "context" : "We thus use the Stanford parser (Manning et al., 2014) to automatically create the PoS and syntax annotations for Twitter texts, which are also compatible with PTB conventions.",
      "startOffset" : 32,
      "endOffset" : 54
    }, {
      "referenceID" : 18,
      "context" : "For instance, in OntoNotes and Switchboard, singletons, copula constructions, headless relative clauses and appositions are not annotated (Pradhan et al., 2007; Calhoun et al., 2010).",
      "startOffset" : 138,
      "endOffset" : 182
    }, {
      "referenceID" : 5,
      "context" : "For instance, in OntoNotes and Switchboard, singletons, copula constructions, headless relative clauses and appositions are not annotated (Pradhan et al., 2007; Calhoun et al., 2010).",
      "startOffset" : 138,
      "endOffset" : 182
    }, {
      "referenceID" : 5,
      "context" : "Another difference in the coreference annotation schemes is encountered in Switchboard, where only markables with information status ”old” are annotated for coreference (Calhoun et al., 2010).",
      "startOffset" : 169,
      "endOffset" : 191
    }, {
      "referenceID" : 1,
      "context" : "We use the constituency parse trees to detect the clause boundaries in the same way as done by (Aktaş et al., 2019).",
      "startOffset" : 95,
      "endOffset" : 115
    } ],
    "year" : 2020,
    "abstractText" : "In response to (i) inconclusive results in the literature as to the properties of coreference chains in written versus spoken language, and (ii) a general lack of work on automatic coreference resolution on both spoken language and social media, we undertake a corpus study involving the various genre sections of Ontonotes, the Switchboard corpus, and a corpus of Twitter conversations. Using a set of measures that previously have been applied individually to different data sets, we find fairly clear patterns of ”behavior” for the different genres/media. Besides their role for psycholinguistic investigation (why do we employ different coreference strategies when we write or speak) and for the placement of Twitter in the spoken–written continuum, we see our results as a contribution to approaching genre-/media-specific coreference resolution.",
    "creator" : "TeX"
  }
}