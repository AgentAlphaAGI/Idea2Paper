{
  "name" : "COLING_2020_18_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Normalizing Compositional Structures Across Graphbanks",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Graph-based representations of sentence meaning offer an expressive and flexible means of modeling natural language semantics. In recent years, a number of different graphbanks have annotated large corpora with graph-based semantic representations of various types (Oepen and Lønning, 2006; Ivanova et al., 2012; Banarescu et al., 2013; Abend and Rappoport, 2013). Because of differences in graphbank design principles, individual graphs can differ greatly and often in fundamental strategies (Oepen et al., 2019). Fig. 1 illustrates distinct graphs from the three graphbanks of the SemEval 2015 Shared Task on Semantic Dependency Parsing, which we take as our focus in this paper. The graphs visibly differ with respect to edge labels, edge directions, the treatment of a periphrastic verb construction, and coordination.\nIn this paper, we develop a methodology to (i) understand the nature of the differences across graphbanks and (ii) normalize annotations from different graphbanks at the level of their compositional structures. This approach allows us to identify which design differences between graphbanks are linguistically meaningful and important for the design of future corpora; as well as to identify more unified approaches to certain structures to potentially facilitate multi-task learning (MTL). In Section 2 we build upon Lindemann et al. (2019), who used AM dependency trees to represent the compositional structure of graph-based meaning representations (MRs) based on the AM algebra (Groschwitz et al., 2018). We detail a new methodology for identifying and quantifying mismatches between the compositional structures assigned to the same sentence by different graphbanks; we then present our extended AM+ algebra, with which we can systematically reshape these compositional structures to align them across graphbanks (Section 3). Finally, we provide key examples of how our methodology normalizes specific linguistic phenomena that pose challenges to MR design and differ in representation across graphbanks (Section 4).\nUsing our methods, we increase the match between the AM dependency trees (compositional structure) of the different graphbanks to 76.3 (DM-PAS), 78.8 (DM-PSD), and 82.0 (PAS-PSD) directed unlabeled F-score, compared to 63.5, 55.7, and 57.0 for Lindemann et al.’s AM dependency trees (Section 5). This is a drastic improvement over the unlabeled F-scores of 64.2, 26.1, and 29.6 for the original graphs (Oepen et al., 2015). We additionally demonstrate that when training a graph parser on a tiny graphbank combined with larger graphbanks using multi-task learning (MTL), our methods improve parsing accuracy by up to 2.6 points F-score over MTL without normalized AM dependency trees. Our work serves as a proof of\nconcept that linguistically-informed methods to normalize compositional structure across graphbanks is successful and can be applied at broad-scale and potentially to more complex graphbanks (Section 6)."
    }, {
      "heading" : "2 Background",
      "text" : ""
    }, {
      "heading" : "2.1 The Graphbanks",
      "text" : "We focus on the three graphbanks of the SemEval 2015 Shared Task on Semantic Dependency Parsing (SDP): (i) DELPH-IN MRS-Derived Semantic Dependencies (DM), (ii) Enju Predicate–Argument Structures (PAS), and (iii) Prague Semantic Dependencies (PSD) (Oepen et al., 2015). All graphbanks have parallel semantic annotations over the same English texts: the Wall Street Journal (WSJ) and Brown segments of the Penn Treebank (PTB; Marcus et al. (1993)). The graphbanks are bilexical, node-ordered, labeled, directed graphs, representing core semantic information like predicate-argument relations.\nThe SDP graphbanks make different choices about which linguistic information to represent and how to represent it (first columns of Table 2) (Oepen et al., 2016). Representative graphs of the three graphbanks containing linguistic phenomena of interest (modification, coordination, copula, prepositional phrase) are shown in Fig. 1. While in all three graphs each token of the sentence corresponds to at most one node, there may also be tokens which are not part of the graph. These ‘ignored’ tokens differ across graphbanks; for instance, in DM coordinators (“and”) and temporal auxiliaries (“are”) are not nodes in the graph, while PSD ignores temporal auxiliaries, prepositions, and determiners. The edges are also different; for instance, edges that point from adjectives to nouns in DM and PAS go the other way in PSD.\nThe fundamental question we address in this paper is to what extent these variations are superficial and artifacts of graph design choice, and to what extent they are deeper and structurally rooted in complex linguistic phenomena. To this end, we make the standard assumption from theoretical semantics that MRs are derived compositionally by systematically computing MRs for each part of the sentence from its immediate subparts. We say that a difference between two graphs is ‘superficial’ if it can be derived using the same compositional structure. To give an example, Fig. 4(a, b) show the compositional structure which Lindemann et al. (2019) assign to the DM and PSD graphs in Fig. 1. We explain the technical details in Section 2.2; for now, observe that certain differences between DM and PSD have been normalized (e.g. both dependency trees analyze the noun as the head and the adjective as the modifier), while others are still present (e.g. ignored tokens)."
    }, {
      "heading" : "2.2 Compositional Semantic Parsing with the AM Algebra",
      "text" : "The Apply-Modify (AM) Algebra was initially presented in Groschwitz et al. (2018) for compositional AMR parsing. It provides the latent compositional structures we aim to normalize, in the form of AM dependency trees (explained below). Lindemann et al. (2019) (hereafter referred to as L19) extended the AM algebra to parsing four additional graph-based MRs (DM, PAS, PSD, and EDS); Donatelli et al. (2019) extended this work to UCCA. L19 achieved state of the art results for all formalisms in question\nwith pretrained BERT embeddings and manual heuristics tailored to each graphbank. We adapt these heuristics to find uniform structures that generalize across graphbanks.\nTo illustrate the algebra, consider the example AM dependency tree in Fig. 3e, which constructs the PAS graph in Fig. 3b. The edges correspond to AM algebra operations, and each word is assigned a graph constant, specifically an as-graph, written below the word (as a visual help, Fig. 2 (bottom) shows the PAS graph of Fig. 3b in a style more compatible with the graph constants). As-graphs possess two kinds of markers: (i) an obligatory root source on the root node (indicated with bold outline); and (ii) optional sources (marked in red, e.g. S and O) on other nodes, which allow as-graphs to be combined. Every node can bear at most one source, and each source can occur at most once in an as-graph. Moving forward, we will write Gthe for the graph constant at “the”, Gcat for “cat”, and so on.\nThe two kinds of edge labels in the AM dependency tree reflect the two operations of the AM algebra. First, the Apply operation APPO on the edge from the head “is” to the argument “lazy” fills the O-source of Gis with the root of Glazy; in other words, it plugs the root of the argument into the specified source of the head.1 The result is shown in Fig. 2 (top left). Nodes in both graphs with the same source (here S) are merged. The type annotation [S] at the O-source of Gis requests the argument to have an S-source (which Glazy does). This way, type annotations lead to reentrancies in the graph (like the triangle structure here).\nSecond, the Modify operation allows an as-graph to modify a head. For example, the MODDET operation encoded by the edge from “cat” to “the” yields the as-graph shown in Fig. 2 (top right). Here, Gcat is the head and Gthe the modifier; Gthe attaches with its DET-source at Gcat and loses its own root source. We combine these two intermediate results with APPS. The final graph is the result of the MODM operation between “not” and “is”. Note that AM dependency trees do not always cover all words in a sentence: in the AM dependency tree for this sentence’s DM graph (Fig. 3d), “is” is not covered, reflecting the fact that it has no incident edges in the DM graph (Fig. 3a). If a token is not covered by the AM dependency tree, we assign it no graph constant and write ‘?’ instead."
    }, {
      "heading" : "3 Quantifying and Normalizing Compositional Mismatches",
      "text" : "The AM dependency trees of L19 (henceforth, L19 AM trees) naturally normalize some of the differences of the original MRs we consider in this paper (Fig. 3). Here, we go further and ask: how far can this normalization be pushed? Given our corpus, if we can find a single compositional structure for each sentence that corresponds to all three MR graphs, this suggests that the designs and annotators of the three graphbanks tacitly agree on compositional structure; surface differences between the graphs can then be explained by low-level representations of individual words. In this work, we take a first step towards this goal, devising linguistically motivated changes to the compositional structures that we can apply automatically to all sentences in the corpus to normalize them.\nFig. 3(g, h, i) shows a successful normalization by our method: the edges of the AM trees are the same across all three MRs; all differences are delegated to the graph constants. Take for example the determiner “the”, which is originally ignored in PSD but not in DM or PAS. In the normalized PSD AM tree (Fig. 3i), it has a constant that consists of an unlabeled root marked with a DET-source, and has an incoming MODDET edge from “cat”. When this semantically empty graph modifies the graph for “cat” Gcat (the MODDET operation), it does not in fact change that graph Gcat but just merges with its root without leaving a trace. This way, the normalized AM tree in Fig. 3i still evaluates to the original graph in Fig. 3c but with the added MODDET edge to match DM and PAS. The trees also normalize the copula and negation, which requires more subtle methods detailed in Section 4.\n1Note: “lazy” is represented in Fig. 3e with an S-source for ease of understanding here; L19 analyze it as a M-source. We use S-sources for adjectives in PAS in the presentation of all examples."
    }, {
      "heading" : "3.1 The AM+ Algebra",
      "text" : "The graph constant we introduced for “the” poses a technical challenge: technically, it is invalid because its root node is marked with another source (DET). This is necessary to make the constant semantically vacuous, but the AM algebra does not allow root nodes to also have another source besides the root source. We therefore extend the AM algebra to the AM+ algebra, which is defined exactly like the AM algebra but allows root nodes to contain additional sources. The concept of an AM dependency tree thus generalizes naturally to the AM+ algebra. Fig. 3(g-i) become valid AM dependency trees of the AM+ algebra and evaluate to the original graphs in Fig. 3(a-c).\nThe seemingly innocent step from the AM algebra to the AM+ algebra has both formal and practical consequences. On a technical level, the AM algebra is grounded in the HR graph algebra (Courcelle and Engelfriet, 2012). In this translation, root nodes in the AM algebra are mapped to sources with a special\nw ?\n(a) EMPTY w\nMODx\n(b) MOD w⇤\nMODx\n(c) CMOD w v\nAPPx APPy\n(d) APP1 u w v\nAPPx APPy APPz\n(e) APP2 u w⇤ v\nAPPx APPy APPz\n(f) CAPP2 w\nAPPx\n(g) BASIC w v\nMODx\nAPPy\n(h) CONN\nFigure 5: The set of local patterns for w we distinguish based on their structures in L19 AM trees.\nname (“root”) in the HR algebra, and a node in a graph of the HR algebra may not be marked with more than one source at once. Formally, we thus base the AM+ algebra on the extension of the HR algebra presented in van Harmelen and Groschwitz (2020) that allows multiple sources at one node. The AM+ algebra also makes it possible to create loops and multiple edges between two nodes, from constants that do not have them (detailed in Appendix A). This is undesirable here since SDP graphs only contain single non-loop edges; we find in Section 5 that while loops and multiple edges can be created accidentally during parsing, this occurs only rarely. From a modeling perspective, the extra flexibility of the AM+ algebra means that the same graph can be described with more terms of the AM+ algebra than with terms of the AM algebra. This can be useful – in fact, we rely on this flexibility here – but it also means that the choice of compositional structure must be made with care and, ideally, in a linguistically informed manner. We therefore first classify and quantify the compositional mismatches."
    }, {
      "heading" : "3.2 Classifying compositional mismatches with local patterns",
      "text" : "To normalize the compositional discrepancies across the large graphbanks, it is imperative that we can apply our changes automatically to each sentence. At the same time, we want to ensure that the changes we make are linguistically reasonable to keep the flexibility of the AM+ algebra in check. We therefore develop a set of ‘local’ patterns in the L19 AM trees trees that correspond to individual tokens. We then compare these local patterns across the L19 AM trees for the three graphbanks to uncover a pattern signature, with which we can identify and normalize differences across the graphbanks.\nThe patterns we use are based on incoming and outgoing AM dependency edges of a token, and on a property of the graph constant; Fig. 5 lists all patterns. For example, the pattern EMPTY matches tokens that are ignored in the AM dependency tree, the pattern MOD matches tokens with an incoming MOD edge (e.g. adjectives), and APP1 matches heads with one argument (e.g. intransitive verbs). Patterns where w has an incoming APPx edge also apply when w is the root of the AM tree. The patterns do not take outgoing MOD edges of w (i.e. modifiers of w) into account. The star at w in the ‘complex’ CMOD and CAPP2 patterns indicates that the graph constant of w causes a reentrancy, like the [S] annotation of Gis in Fig. 3e causing the reentrancy “is”–“lazy”–“cat” in Fig. 3b as seen in 2.2. This is an example of CAPP2; an example of CMOD is “are” in Fig. 4c. The distinctions MOD/CMOD and APP2/CAPP2 do not reflect differences in the AM dependency edges and do not require normalization, but they are useful in distinguishing linguistic phenomena. Tokens matching none of the patterns are classified as OTHER.\nPattern signatures inform us how tokens are represented across the graphbanks. As an example, consider the determiner “the” in Fig. 3. In the L19 AM trees (d–f): the DM (d) and PAS (e) trees combine the determiner with a MOD relation, while the PSD tree (f) leaves it absent (?). That is, we have the patterns MOD for DM and PAS, and EMPTY for PSD. This creates a pattern signature with the triple [DM / PAS / PSD]: [MOD / MOD / EMPTY]. We use this order for all pattern signatures."
    }, {
      "heading" : "4 Normalizing Key Compositional Structures Across Graphbanks",
      "text" : "Examining the pattern signatures of distinct tokens, we make a key finding: about half of the nodes exhibit the same pattern in all three graphbanks. These aligned patterns are typically in the form of open-class words and predicate-argument structure, core components of MR design. For example, adjectives often display the signature [MOD / MOD / MOD], and nouns [BASIC / BASIC / BASIC]. Uniform pattern signatures represent a priori shared compositional structure across graphbanks that we do not need to normalize.\nFor unaligned pattern signatures, i.e. ones that display a pattern mismatch across graphbanks, our goal is to align the pattern signature so the patterns for each graphbank are equivalent. This normalization process follows a three-step process: (i) identify the pattern signatures with distinct local patterns for the three MRs; (ii) match these patterns to meaningful linguistic phenomena; and (iii) manipulate the compositional\nstructures to align the pattern signature across graphbanks, using the AM+ algebra. Table 1 shows the pattern signatures we have investigated in detail and normalized; we chose them as a combination of the most frequent unaligned pattern signatures, and signatures that correspond to interesting and challenging linguistic phenomena. A full list of signatures we detect is in Appendix B. As with aligned pattern signatures, these unaligned signatures map quite precisely to linguistic phenomena—specifically, phenomena involving closed-class functional words, elements often peripheral in MR design.\nA close investigation of the unaligned pattern signatures reveals three main disparities between the graphbanks that we can now address with the AM+ algebra: (i) ‘ignored’ elements; (ii) disagreement in headedness of constructions; and (iii) relational constructions. Here we detail representative examples for each case; Appendix C has additional examples. For all normalizations, we apply transformations using the AM+ algebra directly to the AM dependency trees of L19. The transformations are carefully designed not to change the graph the AM dependency trees evaluate to. We do this for all AM dependency trees by iterating over the sentences in the graphbanks and applying a transformation whenever its corresponding pattern signature matches. The transformations are always applied in the same order (Table 2)."
    }, {
      "heading" : "4.1 Copula and “Ignored” Elements",
      "text" : "A common difference between graphbanks is the ‘ignoring’ of tokens, when certain tokens do not contribute any edges or nodes to the final graph. Among the SDP graphs, PSD consistently ‘ignores’ the most token types; PAS includes nearly all tokens in the graph; and DM falls somewhere in the middle. Importantly, in the corresponding L19 AM trees, ignored tokens are not part of the dependency tree.\nSection 3.2 already discussed how we normalize determiners like “the” in Fig. 1. Copula constructions with adjectival predicates are another prime example of this category, exhibiting the [EMPTY / CAPP2 / APP2] pattern. This is seen for the sentence “The cat is not lazy” in Fig. 3(a-c)). DM treats this construction like an adnominal adjectival construction (“cute dogs” in Fig. 1a); as such, the copula does not contribute directly to the graph (EMPTY pattern). PSD and PAS choose an alternative strategy: the copula verb functions as a transitive verb. PAS includes an edge from the adjective to the subject, resulting in a reentrancy in the graph (Section 2.2) and the CAPP2 pattern in the AM tree. PSD expresses the relation between the adjective and the subject only via the copula. This results in the APP2 pattern in the AM tree. Though APP2 pattern (PSD) differs from CAPP2 pattern (PAS), both result in same AM dependency tree: the verb is the root with outgoing APPS and APPO edges to the subject and the predicate respectively (Fig. 3(e, f)). Thus, only DM exhibits a different compositional structure.\nTo address this discrepancy between DM on one hand and PAS/PSD on the other, we use the AM+ algebra to create vacuous lexical as-graphs that do not change the graph when combined. Specifically, we align the AM dependency tree of DM to that of PSD and PAS by adding a vacuous graph constant for the DM copula verb. This new constant consists of one root node with an O-source, requiring an S-source in its argument (see “is” in Fig. 3g). To evaluate this new AM tree, the adjective (“lazy”) is first plugged\ninto the O-source of the copula (“is”), resulting in an as-graph identical to the lexical as-graph of the adjective. The S-source is then filled, plugging the subject into the correct slot of the adjective. As an added perk, this solution allows us to use the same DM adjective as-graph for adnominal and predicative uses. We restrict our copula fix to instances which have a node with the lemma “be” in PSD plus exactly two outgoing edges APPS and APPO where the target node of the latter has an adjectival POS tag.\nIn addition to determiner and copula constructions, we use the above methods to normalize punctuation, particles, and temporal and aspectual auxiliary verbs (see Appendix C). Together these cases account for roughly 30% of the tokens that exhibit a pattern difference."
    }, {
      "heading" : "4.2 Verbal Negation and Graph Headedness Challenges",
      "text" : "A second discrepancy between graphbanks arises from disagreement about which token is the head of a given construction. One such construction is verbal negation (roughly 2% of tokens that exhibit a pattern difference). Verbal negation follows the [APP1 / MOD / MOD] pattern: while PSD and PAS treat the negation as modifier, DM usually considers the negation to be the head (Fig. 3(a-f)).\nWe address this challenge by switching the headedness between graphbanks, making the negation the head in the AM dependency trees for PAS and PSD graphs. This transformation resembles type raising in lambda calculus where functor and argument are exchanged. An example is shown for the PSD dependency tree in Fig. 3f and its transformation in Fig. 3i (the process is the same for PAS). The AM+ algebra allows us to change the graph constant for “not” by moving the root source to the node with the NEG-source. As a result, the dependency relation between the former head (“is” in Fig. 3f) and the negation is flipped and the label changed from MOD to APP. We restrict our negation fix to instances which have a node with the lemma “#Neg” or “never” in PSD. This covers 35% of the pattern; other phenomena adhering to this pattern include some discourse connectors and adverbs.\nBesides conceptual differences in headedness like negation, some phrases simply do not have an obvious head, such as a date like “Nov. 29”. In such cases, the MRs also often disagree on whether “Nov.” or “29” is the head. We leave the automatic detection and transformation of such cases to future work."
    }, {
      "heading" : "4.3 Binary Coordination and Relational Elements",
      "text" : "As a third category, the SDP graphbanks differ in how they mark certain linguistic relations such as in coordination or prepositional phrases. We observe two strategies: (i) the relation is marked using only an edge between the two more ‘contentful’ elements, ignoring the functional word; or (ii) the relation is marked using a node for the functional word with outgoing edges to the two elements. These decisions permeate through to the AM dependency trees. We address one of the most common phenomena of this category here, coordination, which along with prepositions (Appendix C) accounts for about 20% of the divergences. In both cases, we normalize the AM dependency trees towards strategy (ii).\nTaking coordination as an example, to connect two conjuncts DM uses an edge (strategy (i)) while PAS and PSD2 make the conjunction “and” the head of the phrase with outgoing edges to the conjuncts (strategy (ii)). This can be seen in Fig. 1 for the coordinate phrase “cats and cute dogs”, where the edge in DM is ‘ and c’. PAS and PSD exhibit the same APP2 pattern in the L19 AM trees (Fig. 4(b, c)), while DM exhibits the EMPTY pattern. If both conjuncts share an argument, PAS and PSD exhibit the OTHER pattern due to the additional APP child for this argument (for an example, see Appendix C.2). Binary coordination can thus have either the [EMPTY / APP2 / APP2] or [EMPTY / OTHER / OTHER] signature.\nBinary coordination makes up approximately 86% of all coordinations. We leave automatic normalization of coordination of three or more conjuncts to future work. We restrict our fix to nodes with CC POS tag and exactly two outgoing ‘*.member’ edges in PSD. This covers 89% of the two patterns. Our fix consists of adding a lexical as-graph for the conjunction token (e.g. “and”) in DM containing the dedicated conjunction edge that was previously part of one of the conjuncts graph constants (compare Fig. 4a and 4d). The incident nodes use OP1- and OP2-sources to indicate the open positions for the conjuncts, and we connect the conjuncts as APPOP1 and APPOP2 children accordingly. One of the conjuncts was previously the head of the coordination in DM (here “cats”), we shift its incoming edge (here APPS) to\n2As preprocessed by L19.\nthe conjunction instead. The root of the conjunction’s lexical as-graph is placed at the OP1-source where “cats” will be placed, such that all outside graph edges attach correctly. For coordination with a common argument, source annotations at OP1- and OP2-sources are added for this argument (see Appendix C.2)."
    }, {
      "heading" : "5 Evaluation",
      "text" : "We evaluate the quality of the normalized AM dependency trees by measuring cross-formalism similarity and suitability for parsing on the SDP corpora of the 2015 shared task (Oepen et al., 2015). We apply L19’s preprocessing of coordination for PSD. Due to the similarities of the graphbanks, it is appealing to use multi-task learning (MTL), which shares a subset of the model weights across graphbanks to allow training data for one graphbank influence the prediction on another. We expect this to help particularly in scenarios where there is limited data for one graphbank but large amounts for others."
    }, {
      "heading" : "5.1 Structural Similarity",
      "text" : "Table 2 summarizes the structural comparison of the graphs and AM dependency trees, respectively. We also calculate the percentage of lexical as-graphs that change by graphbank as a result of our normalization: 13.53% (DM), .35% (PAS), and 33.22% (PSD).\nThere is a consistent increase in similarity by at least 12.3 points F-score of the normalized AM dependency trees in comparison to the L19 AM trees over all metrics. The A/M F-score is the upper bound on how much similarity can be achieved by systematically making the source names more uniform as well. Comparing the similarities of the normalized AM dependency trees to the similarities of the graphs, there is an even larger gain in the unlabeled, directed F-score of up to 52.7 points. Importantly, we only compute F-scores on the edges of the AM dependency trees, not on the as-graph constants. The higher similarity in the tree structure is achieved primarily by moving discrepancies to the lexicon, particularly for edge directions and edge labels."
    }, {
      "heading" : "5.2 Suitability for Parsing",
      "text" : "An important question to ask is if the normalization of the AM dependency trees has an impact on how accurate parsing is. In particular, we expect the high similarity to be beneficial for projecting from a large corpus to a smaller one. Therefore, we conduct parsing experiments in the usual high-resource scenario and also in a simulated low-resource scenario, for which we sampled 3 subsets of the training data with 100 instances each and used those subsets throughout all low-resource experiments.\nWe use the parser of L19 but, in contrast, we use only those training instances for which we have AM dependency trees in all formalisms, resulting in 29,182 training instances. Moreover, we do not use embeddings for lemmas because of data sparsity in the low-resource condition. We follow L19 in how we perform MTL, that is, we share an LSTM over all tasks in addition to using task-specific ones. Scores for edges and lexical as-graphs are produced from single-layer feedforward networks that take the concatenation of the output of the shared and task-specific LSTM as input. MTL experiments use the full training data of the non-target formalism and the specified amount for the target task; no data beyond the SDP corpora was used for the MTL experiments. For full details of hyperparameters, see Appendix D.\nTable 3 summarizes the results. MTL in the low-resource scenario is hugely beneficial and works better with the normalized AM dependency trees. The slight to moderate decrease in accuracy of the normalized trees in the full data condition likely comes from the noise we introduce, as not all phenomena are detected perfectly and our fixes are sometimes restricted to specific instances. As noted in Section 3.1, the AM+ algebra can produce multiple edges between pairs of nodes and self-loops. This is rare in practice except for PSD in the low-resource condition without MTL, where up to 1.7% of predicted edges are affected."
    }, {
      "heading" : "6 Discussion",
      "text" : "The methodology we detail in Sections 3 and 4 allows us to normalize roughly 60% of differences across compositional structures of the SDP graphbanks. Our work establishes that a small set of linguisticallygrounded transformations are quite powerful towards creating uniform compositional structure; in fact, we find that all of the divergent patterns across graphbanks that we detect are ‘superficial’ in the sense that, given proper attention and methodology, we can normalize them.\nThe individual phenomena that create inconsistencies across graph representations and their corresponding L19 AM trees predictably adhere to a Zipfian distribution (Appendix B). To manually develop automatic normalizations for 100% of the unaligned patterns may be infeasible. These observations seem to indicate that the remaining differences between our normalized AM trees are due to practical, implementation concerns rather than conceptual ones. A possible approach to solving the practical issues would be a fully automated method with statistical rather than human guidance. In a low resource scenario, manual annotations could also be a feasible solution. It is to note though that the AM+ algebra is not all-powerful; the L19 preprocessing step for coordination in PSD remains necessary.\nDespite the fact that all phenomena we examine can be normalized, how they are normalized provides insights into the differences among the underlying MRs. While structural differences like those seen in negation and coordination essentially reduce to mildly different graph constants, ignored words or underspecified attachment that may create ambiguity are a different story. Namely, they make explicit the different kinds of information that some MRs include and others do not, forcing us to choose the most informative compositional structure (such as including determiners for PSD). Curiously, our parser does not seem to care much about this added, more-explicit information, but we believe future work in cross-framework parsing with more distinct graphbanks may provide more meaningful insight on this fact."
    }, {
      "heading" : "7 Conclusion",
      "text" : "We have shown how annotations from different graphbanks (specifically, DM, PAS, and PSD) can be normalized at the level of their compositional structure using principled linguistic reasoning. We achieve this by updating the AM algebra to the AM+ algebra, which allows more flexibility in adapting compositional structures across MRs. By working at the compositional level of the graphs using AM dependency trees, we are able to quantify mismatches between different graphbanks, systematically reshape these mismatches to make them more uniform across graphbanks, and thereby increase the match between the compositional structures for the three graphbanks. Such work serves as a proof of concept that normalization is possible and contributes to a broader effort to increase parallel MR parsing accuracy."
    } ],
    "references" : [ {
      "title" : "Universal conceptual cognitive annotation (UCCA)",
      "author" : [ "Omri Abend", "Ari Rappoport." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 228–238, Sofia, Bulgaria, August. Association for Computational Linguistics.",
      "citeRegEx" : "Abend and Rappoport.,? 2013",
      "shortCiteRegEx" : "Abend and Rappoport.",
      "year" : 2013
    }, {
      "title" : "Abstract meaning representation for sembanking",
      "author" : [ "Laura Banarescu", "Claire Bonial", "Shu Cai", "Madalina Georgescu", "Kira Griffitt", "Ulf Hermjakob", "Kevin Knight", "Philipp Koehn", "Martha Palmer", "Nathan Schneider." ],
      "venue" : "Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse, pages 178–186, Sofia, Bulgaria, August. Association for Computational Linguistics.",
      "citeRegEx" : "Banarescu et al\\.,? 2013",
      "shortCiteRegEx" : "Banarescu et al\\.",
      "year" : 2013
    }, {
      "title" : "Graph Structure and Monadic Second-Order Logic, a Language Theoretic Approach",
      "author" : [ "Bruno Courcelle", "Joost Engelfriet." ],
      "venue" : "Cambridge University Press.",
      "citeRegEx" : "Courcelle and Engelfriet.,? 2012",
      "shortCiteRegEx" : "Courcelle and Engelfriet.",
      "year" : 2012
    }, {
      "title" : "Saarland at MRP 2019: Compositional parsing across all graphbanks",
      "author" : [ "Lucia Donatelli", "Meaghan Fowlie", "Jonas Groschwitz", "Alexander Koller", "Matthias Lindemann", "Mario Mina", "Pia Weißenhorn." ],
      "venue" : "Proceedings",
      "citeRegEx" : "Donatelli et al\\.,? 2019",
      "shortCiteRegEx" : "Donatelli et al\\.",
      "year" : 2019
    }, {
      "title" : "AMR dependency parsing with a typed semantic algebra",
      "author" : [ "Jonas Groschwitz", "Matthias Lindemann", "Meaghan Fowlie", "Mark Johnson", "Alexander Koller." ],
      "venue" : "Proceedings of ACL.",
      "citeRegEx" : "Groschwitz et al\\.,? 2018",
      "shortCiteRegEx" : "Groschwitz et al\\.",
      "year" : 2018
    }, {
      "title" : "Methods for taking semantic graphs apart and putting them back together again",
      "author" : [ "Jonas Groschwitz." ],
      "venue" : "Ph.D. thesis, Macquarie University and Saarland University.",
      "citeRegEx" : "Groschwitz.,? 2019",
      "shortCiteRegEx" : "Groschwitz.",
      "year" : 2019
    }, {
      "title" : "Who did what to whom? a contrastive study of syntacto-semantic dependencies",
      "author" : [ "Angelina Ivanova", "Stephan Oepen", "Lilja Øvrelid", "Dan Flickinger." ],
      "venue" : "Proceedings of the Sixth Linguistic Annotation Workshop, pages 2–11, Jeju, Republic of Korea, July. Association for Computational Linguistics.",
      "citeRegEx" : "Ivanova et al\\.,? 2012",
      "shortCiteRegEx" : "Ivanova et al\\.",
      "year" : 2012
    }, {
      "title" : "Compositional semantic parsing across graphbanks",
      "author" : [ "Matthias Lindemann", "Jonas Groschwitz", "Alexander Koller." ],
      "venue" : "Proceedings of ACL.",
      "citeRegEx" : "Lindemann et al\\.,? 2019",
      "shortCiteRegEx" : "Lindemann et al\\.",
      "year" : 2019
    }, {
      "title" : "Building a large annotated corpus of English: The Penn Treebank",
      "author" : [ "Mitchell P. Marcus", "Beatrice Santorini", "Mary Ann Marcinkiewicz." ],
      "venue" : "Computational Linguistics, 19(2):313–330.",
      "citeRegEx" : "Marcus et al\\.,? 1993",
      "shortCiteRegEx" : "Marcus et al\\.",
      "year" : 1993
    }, {
      "title" : "Discriminant-based MRS banking",
      "author" : [ "Stephan Oepen", "Jan Tore Lønning." ],
      "venue" : "Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC’06), Genoa, Italy, May. European Language Resources Association (ELRA).",
      "citeRegEx" : "Oepen and Lønning.,? 2006",
      "shortCiteRegEx" : "Oepen and Lønning.",
      "year" : 2006
    }, {
      "title" : "SemEval 2015 task 18: Broad-coverage semantic dependency parsing",
      "author" : [ "Stephan Oepen", "Marco Kuhlmann", "Yusuke Miyao", "Daniel Zeman", "Silvie Cinková", "Dan Flickinger", "Jan Hajič", "Zdeňka Urešová." ],
      "venue" : "Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 915–926, Denver, Colorado, June. Association for Computational Linguistics.",
      "citeRegEx" : "Oepen et al\\.,? 2015",
      "shortCiteRegEx" : "Oepen et al\\.",
      "year" : 2015
    }, {
      "title" : "Towards comparability of linguistic graph banks for semantic parsing",
      "author" : [ "Stephan Oepen", "Marco Kuhlmann", "Yusuke Miyao", "Daniel Zeman", "Silvie Cinková", "Dan Flickinger", "Jan Hajic", "Angelina Ivanova", "Zdenka Uresova." ],
      "venue" : "Proceedings of the Tenth International Conference on Language Resources and Evaluation (LREC’16), pages 3991–3995.",
      "citeRegEx" : "Oepen et al\\.,? 2016",
      "shortCiteRegEx" : "Oepen et al\\.",
      "year" : 2016
    }, {
      "title" : "MRP 2019: Cross-framework meaning representation parsing",
      "author" : [ "Stephan Oepen", "Omri Abend", "Jan Hajic", "Daniel Hershcovich", "Marco Kuhlmann", "Tim O’Gorman", "Nianwen Xue", "Jayeol Chun", "Milan Straka", "Zdenka Uresova" ],
      "venue" : "In Proceedings of the Shared Task on Cross-Framework Meaning Representation Parsing at the 2019 Conference on Natural Language Learning,",
      "citeRegEx" : "Oepen et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Oepen et al\\.",
      "year" : 2019
    }, {
      "title" : "Comprehensive supersense disambiguation of English prepositions and possessives",
      "author" : [ "Nathan Schneider", "Jena D. Hwang", "Vivek Srikumar", "Jakob Prange", "Austin Blodgett", "Sarah R. Moeller", "Aviram Stern", "Adi Bitan", "Omri Abend." ],
      "venue" : "Proceedings of ACL, pages 185–196, Melbourne, Australia, July.",
      "citeRegEx" : "Schneider et al\\.,? 2018",
      "shortCiteRegEx" : "Schneider et al\\.",
      "year" : 2018
    }, {
      "title" : "Graphs with Multiple Sources per Vertex",
      "author" : [ "Martin van Harmelen", "Jonas Groschwitz." ],
      "venue" : "arXiv e-prints. https://arxiv.org/abs/2006.11159.",
      "citeRegEx" : "Harmelen and Groschwitz.,? 2020",
      "shortCiteRegEx" : "Harmelen and Groschwitz.",
      "year" : 2020
    } ],
    "referenceMentions" : [ {
      "referenceID" : 7,
      "context" : "We present a methodology for normalizing discrepancies between MRs at the compositional level (Lindemann et al., 2019), finding that we can normalize the majority of divergent phenomena using linguistically-grounded rules.",
      "startOffset" : 94,
      "endOffset" : 118
    }, {
      "referenceID" : 9,
      "context" : "In recent years, a number of different graphbanks have annotated large corpora with graph-based semantic representations of various types (Oepen and Lønning, 2006; Ivanova et al., 2012; Banarescu et al., 2013; Abend and Rappoport, 2013).",
      "startOffset" : 138,
      "endOffset" : 236
    }, {
      "referenceID" : 6,
      "context" : "In recent years, a number of different graphbanks have annotated large corpora with graph-based semantic representations of various types (Oepen and Lønning, 2006; Ivanova et al., 2012; Banarescu et al., 2013; Abend and Rappoport, 2013).",
      "startOffset" : 138,
      "endOffset" : 236
    }, {
      "referenceID" : 1,
      "context" : "In recent years, a number of different graphbanks have annotated large corpora with graph-based semantic representations of various types (Oepen and Lønning, 2006; Ivanova et al., 2012; Banarescu et al., 2013; Abend and Rappoport, 2013).",
      "startOffset" : 138,
      "endOffset" : 236
    }, {
      "referenceID" : 0,
      "context" : "In recent years, a number of different graphbanks have annotated large corpora with graph-based semantic representations of various types (Oepen and Lønning, 2006; Ivanova et al., 2012; Banarescu et al., 2013; Abend and Rappoport, 2013).",
      "startOffset" : 138,
      "endOffset" : 236
    }, {
      "referenceID" : 12,
      "context" : "Because of differences in graphbank design principles, individual graphs can differ greatly and often in fundamental strategies (Oepen et al., 2019).",
      "startOffset" : 128,
      "endOffset" : 148
    }, {
      "referenceID" : 4,
      "context" : "(2019), who used AM dependency trees to represent the compositional structure of graph-based meaning representations (MRs) based on the AM algebra (Groschwitz et al., 2018).",
      "startOffset" : 147,
      "endOffset" : 172
    }, {
      "referenceID" : 10,
      "context" : "1 The Graphbanks We focus on the three graphbanks of the SemEval 2015 Shared Task on Semantic Dependency Parsing (SDP): (i) DELPH-IN MRS-Derived Semantic Dependencies (DM), (ii) Enju Predicate–Argument Structures (PAS), and (iii) Prague Semantic Dependencies (PSD) (Oepen et al., 2015).",
      "startOffset" : 265,
      "endOffset" : 285
    }, {
      "referenceID" : 11,
      "context" : "The SDP graphbanks make different choices about which linguistic information to represent and how to represent it (first columns of Table 2) (Oepen et al., 2016).",
      "startOffset" : 141,
      "endOffset" : 161
    }, {
      "referenceID" : 2,
      "context" : "On a technical level, the AM algebra is grounded in the HR graph algebra (Courcelle and Engelfriet, 2012).",
      "startOffset" : 73,
      "endOffset" : 105
    }, {
      "referenceID" : 10,
      "context" : "O15 are F-scores on SDP graphs (Oepen et al., 2015); else F-scores on AM dependency trees at different stages of normalization.",
      "startOffset" : 31,
      "endOffset" : 51
    }, {
      "referenceID" : 10,
      "context" : "5 Evaluation We evaluate the quality of the normalized AM dependency trees by measuring cross-formalism similarity and suitability for parsing on the SDP corpora of the 2015 shared task (Oepen et al., 2015).",
      "startOffset" : 186,
      "endOffset" : 206
    } ],
    "year" : 2020,
    "abstractText" : "The emergence of a variety of graph-based meaning representations (MRs) has sparked an important conversation about how to adequately represent semantic structure. MRs exhibit structural differences that reflect different theoretical and design considerations, presenting challenges to uniform linguistic analysis and cross-framework semantic parsing. Here, we ask the question of which design differences between MRs are meaningful and semantically-rooted, and which are superficial. We present a methodology for normalizing discrepancies between MRs at the compositional level (Lindemann et al., 2019), finding that we can normalize the majority of divergent phenomena using linguistically-grounded rules. Our work significantly increases the match in compositional structure between MRs and improves multi-task learning (MTL) in a low-resource setting, serving as a proof of concept for future broad-scale cross-MR normalization.",
    "creator" : "LaTeX with hyperref"
  }
}