{
  "name" : "COLING_2020_39_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "A Systematic Analysis of Text Mining Features: Towards a Holistic Taxonomy",
    "authors" : [ ],
    "emails" : [ "email@domain", "email@domain" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Text mining is receiving continued attention from both researchers and practitioners. In the last years, several application areas have become popular, such as spam detection (Wood, 2016), sport performance prediction (Gruettner et al., 2020), web mining to predict pandemic outbreaks (Jahanbin and Rahmanian, 2020), predictive policing (Meijer and Wessels, 2019), or procedural knowledge extraction (Wambsganss and Fromm, 2019). Fueled with big data, artifical neural networks (ANN) and transfer learning algorithms such as BERT (Devlin et al., 2018) have been very successful in processing large amounts of data and predicting outcomes precisely (Alom et al., 2019). For certain use cases, however, traditional machine learning models are often the more promising modelling approach, since only little labelled data is available, and transparency as well as explainability play a major role for the practical success of the application of those algorithms. Exemplary use cases can be found in human-centered decision support systems (Stoica et al., 2017; Alom et al., 2019), e.g., writing support systems for educational feedback (Wambsganss et al., 2020b) or auditing for predictive policing (Scanlan, 2019).\nThe main challenge of text mining is to preprocess written text and extract valuable features to enable information extraction (IE), data analytics (DA), or machine learning (ML) algorithms to reach their maximum performance (Rajman and Vesely, 2004; Johnson et al., 2015; Allahyari et al., 2017). However, a large amount of text mining applications simply rely on basic feature generation techniques such as bags of words (BOW) (Khadjeh Nassirtoussi et al., 2014) in which information such as the order and co-occurrence of words is not taken into account. This may lead to an overall underperformance, since copious training data is often not available (Pustejovsky and Stubbs, 2013). As a result, different teams of authors have indicated that enhancing text mining algorithms with the appropriate design, implementation, and evaluation of text features - a process commonly referred to as feature engineering - bears high chances of improving text mining outcomes significantly (Bird et al., 2009; Khadjeh Nassirtoussi et al., 2014; Johnson et al., 2015).\nHowever, feature engineering comes with a number of challenges. First and foremost, feature engineering still depends largely on human intuition and experience, since it requires deep domain knowledge\nto identify and operationalize relevant features. Second, as Talib et al. (2016) point out, text mining has been influenced by different disciplines like computer science, statistics, computational linguistics, and library and information sciences. Accordingly, text mining features that evolved in one particular discipline are often unknown or rarely used in other disciplines. Third, systematic feature frameworks that might help researchers and practitioners to select from, compare, and evaluate new or existing features across different disciplines or areas of application are rather rare. In this regard, existing literature focuses more on the comparison of particular domain-specific features and their learning algorithms but lacks a holistic text mining feature classification framework.\nHence, our goal is to develop a comprehensive multidisciplinary taxonomy of text features to provide guidance by revealing the complex relationships of text features and by illustrating the application of certain feature groups based on a similarity analysis. To achieve our goal, we 1) illustrate the diversity of text feature engineering through a systematic literature review in which we found 133 distinct text mining features in different applications domains, 2) we outline a classification framework through a taxonomy with five dimensions and multiple characteristics, 3) we identify patterns and ”white spots” in the application of text feature groups to provide further assistance for a) the development and design of new text mining solutions and b) the assessment and comparison of existing applications. For practical guidance, we therefore present our taxonomy as a text mining feature canvas, in which a single text feature can be categorized and compared along five dimensions. Moreover, we illustrate all 133 identified text features on a web platform and encourage researchers to add missing features accordingly. Our ultimate goal is to present an eclectic collection of text features and a corresponding classification framework towards a shared understanding across application domains.\nTherefore, we contribute to both scientific literature by empirically analyzing the manifold use of features in text mining and to practice by proposing a menu of features and categories that might be of value in text mining projects. The resulting taxonomy should simplify the comparability of text features between different studies, domains, or applications and reduce the costly effort of feature engineering for practitioners and scientists when traditional machine learning methods are applied. We present five dimensions of features diverse enough to demonstrate their commonalities and differences and comprehensive enough to encompass every feature we found in our systematic literature review. We believe that such a menu of features will stimulate researchers and practitioners to enhance their knowledge about feature generation and to use the most appropriate features for their research."
    }, {
      "heading" : "2 Feature Engineering of Text Mining Algorithms",
      "text" : "Text mining uses techniques from different areas: Natural Language Processing (NLP), Information Extraction (IE), Data Analytics (DA), and Machine Learning (ML). Hereby, the main challenge is to extract and reduce relevant features in a feature vector to reach a maximum performance by different DA or ML algorithms (e.g., classification, clustering, or trend analysis, etc.) as depicted in Figure 1 (Rajman and Vesely, 2004). Features are understood as certain text characteristics or distinct attributes of a text that might bear valuable information for the ML or DA algorithms. Thus, we use NLP and text features as synonyms.\nFueled with large amounts of data, artificial neural networks (ANNs) or transfer learning models such as BERT (Devlin et al., 2018) have been very successful in processing large amounts of data and achieving high-quality predictions (Alom et al., 2019; Wambsganss et al., 2020a). These models are\nsaid to learn features automatically in their top layers and adjust to the patterns of the data in their lower layers. However, big amounts of data are usually necessary for those algorithms to be trained to detect and predict theses data patterns. Moreover, deep ANNs ”do not reveal their features”. This means that the user receives no indication why the network has delivered a particular result. The lack of interpretability often hinders the practical application of ANNs. In fact, explainablility has played a major role for the practical success of ML algorithms, as they are often embedded in human-centered decision support systems (Stoica et al., 2017; Alom et al., 2019). On the other hand, traditional ML approaches often show better performance for small amounts of input data (e.g., less than 1,000 labelled data points) (Alom et al., 2019). Traditional ML models together with text feature engineering are therefore still mainly used as the default modelling approach for text mining, since often only small data sets are available that are labelled, e.g., for human-centered writing support systems (Wambsganss et al., 2020b) or auditing for predictive policing (Scanlan, 2019).\nBird et al., (2009, p. 224) state that “selecting relevant features and deciding how to encode them for a learning method can have an enormous impact on the learning method’s ability to extract a good model”. Thus, most work in building a text classifier with traditional text mining methods is creating relevant features and deciding how to represent them. Bird et al., (2009, p. 224) mention that it is possible to receive a decent performance “by using a fairly simple and obvious set of features . . . ”, however, “there are usually significant gains to be had by using carefully constructed features based on a thorough understanding of the task at hand”. Nevertheless, most features are created through a process of trial and error and not by rigorous feature engineering supported by a framework or a taxonomy. In fact, we did not find a comprehensive and concise taxonomy for text mining features in the literature. What can be found are classifications of text mining features along single dimensions, which are often more a simple categorization of attributes than a set of comprehensive and robust dimensions (e.g., Johnson et al. (2015; Missen et al. (2013)). Mostly, feature engineering is done by intuition about what information might be relevant to the problem. As Bird et al., (2009, p. 224) wrote, “it’s common to start with a “kitchen sink” approach, including all the features that you can think of, and then checking to see which features actually are helpful.”\nAs a consequence, the different application areas of text analysis and text mining have created a variety of features. Education and literary sciences have brought up a number of readability indices, which are used to judge the readability level of books and texts. The one most widely applied is the Flesch readability index, which is calculated from the number of sentences, words, and syllables of a text (Flesch, 1943; Kincaid et al., 1975). Sentiment analysis and opinion mining are concerned with the polarity of texts. Polarity is a feature describing the emotion or sentiment present in a text. It can be observed on the word, the sentence, or the document level (Pang and Lee, 2008). Applications for authorship attribution and verification analyze the syntactic depth and complexity of texts and have come up with features like the vocabulary richness or the use of hapax legomena (e.g., NagaPrasad et al. (2015)). Procedure or instruction mining tries to find answers for “how to” questions in the vastness of the internet (Wambsganss and Fromm, 2019). This can range from instructions on how to repair an automobile to recipes on how to prepare a meal. Typical features used in this domain are the occurrence of enumerations, imperatives, or certain verb-noun combinations.\nAll these application areas and disciplines are confronted with different challenges and therefore have developed their own features and their own modes of speaking. A holistic feature classification framework might help by illustrating the features’ commonalities and differences. However, current feature frameworks fall mostly short of depicting the nature of text features across the different disciplines. Hence, we aim to address this gap with our stated research questions."
    }, {
      "heading" : "3 Towards a Taxonomy of Text Mining Features",
      "text" : "To provide framing for the wide variety of NLP features and to explain their propositions and nature, we carried out three research steps to achieve our goal (Figure 2). 1) We conducted a systematic literature review based on Webster and Watson (2002) and vom Brocke et al. (2015) to capture the diversity of text features used for feature engineering across different disciplines. 2) We structured the identified diversity\nof text features by deriving appropriate dimensions and characteristics in a novel taxonomy following the method presented by Nickerson et al. (2013). 3) We identify patterns by performing a cluster analysis to display the complex relationships between text features in a heat map and to identify the application of certain feature groups that used similar features (Kaufman and Rousseeuw, 2005). We believe that these results will guide and inspire researchers in their text mining studies and encourage them to use one or the other feature in their own research."
    }, {
      "heading" : "3.1 Step 1: Analysis of Text Feature Diversity",
      "text" : "In total, we found 133 distinct text mining features in 211 papers that discussed feature engineering for text mining and described at least one textual feature. We chose the papers based on a systematic literature analysis with search strings in the most common literature databases (such as ACM Digital Library, IEEE Xplore Digital Library or Science Direct). We basically found three groups of papers: 1) papers that described features but did not give them a designation (= a class name); 2) Papers that used such designations for features, which we considered as the starting point of a classification; and 3) a group of papers that presented lists of features and classified them along a single dimension and, in very rare cases, along two dimensions (e.g., Abbasi et al. (2008a)). In total, we found 20 papers containing a feature list or table and 191 papers which simply present their distinct features without further illustration or categorization (see Figure 3 on the right). Very common is a classification into lexical and syntactic, sometimes into lexical, syntactic, and semantic features. Only few authors proposed a further differentiation into word, sentence, or document level. We did not find a classification into more than two dimensions. We found out that a lot of designations were synonymous or overlapping. Easier cases were simple synonymy: some authors called features content-based, which other authors called semantic. However, often, designations were specific to a certain application area, e.g., authorship features or stylistic features. In these cases, we discarded the application-specific names and selected designations as class names that were most commonly used and applicable across application areas. Even if certain characteristics were mentioned in the literature, e.g., two of the following groups: lexical, syntactic, semantic, character level, word level, sentence level, and document level, no collective name was given to these groups. Therefore, we had to select designations that we believed describe best the intentions of the authors who used these characteristics. These designations became the names of our dimensions. In the first case, we called the characteristics “linguistic analysis level”, in the second case ”granularity level”. A test to see if both dimensions are necessary for the characterization of features was done simply by using word polarity and sentence polarity, two well-known features for sentiment analysis and opinion mining. Both are semantic features, but they are applied on different granularity levels: the first one on the word level, the second one on the sentence level. In the course of developing our taxonomy, we did different checks to validate our choice of dimensions and characteristics. We constantly checked if the taxonomy can classify all the features that we found in the literature. This is a requirement that Nickerson et al. (2013) described as the comprehensiveness or completeness of a taxonomy.\nThe majority of papers that we analyzed applied feature engineering to a specific NLP domain. 75 of the 191 papers had a theoretical focus without addressing a particular application area. The remaining\n136 papers, however, could well be assigned to a particular application area. Figure 3 shows their distribution on the left. In total, we found more than 20 application areas in our sample of text mining papers. Most of the publications were applying feature engineering to sentiment analysis (20 percent) and social media sense making (10 percent). The rest of the sample applied text mining feature engineering to various other topics, such as authorship attribution, deception detection (e.g., fake news detection), text summarization, question answering, readability analysis, or argumentation mining."
    }, {
      "heading" : "3.2 Step 2: Structuration of Text Features",
      "text" : "Our objective was to structure the identified diversity of text mining features into one comprehensive classification framework with which a single text mining feature can be categorized. In order to do so, we derived and iterated a taxonomy according to Nickerson et al. (2013). We iterated five versions of our taxonomy in multiple workshops until we finalized a robust, concise but comprehensive feature framework that is holistic enough to classify every feature we found but extensible to classify new features that might appear in future studies. We suggest the following five dimensions to classify a text feature: linguistic analysis level, granularity level, information source, dimensionality, and representation (see Figure 4)."
    }, {
      "heading" : "3.2.1 Linguistic Analysis Level",
      "text" : "The dimensions most widely mentioned in literature are the linguistic perspectives (Johnson et al., 2015), or in other words, the hierarchy of stages in NLP: morphological analysis, lexical analysis, syntactical analysis, and semantic analysis (Johnson et al., 2015; Bird et al., 2009). Lexical analysis converts a textual input stream into words (also called terms or tokens) that build the vocabulary of the text. Morphological analysis looks at the internal structure of the words in more detail (e.g., syllables). Syntactic analysis determines the structure of a sentence and the role that each word has within the sentence. Semantic analysis is concerned with the meaning of a word, a sentence, or a whole text. Many authors classify text mining features along these linguistic perspectives. Lexical, syntactic, and semantic features are described by Kambhatla (2004) for relation detection, by Abbasi et al. (2008a) for sentiment analysis, by Loni et al. (2011) for question classification, and by Alzahrani et al. (2012) for plagiarism detection. Hancke et al. (2012) use morphological, lexical, and semantic features for readability classification. NagaPrasad et al. (2015) distinguish lexical, semantic, and structural features for authorship attribution. Van Den Bosch (2017) describe lexical and syntactic features for language variety identification. The problem that linguistic analysis levels create when developing a feature taxonomy is that there is not necessarily a one-to-one relationship between a feature and an analysis level. Sentiment analysis works basically with the meaning of words (with positive or negative sentiments) and thus requires a lexical and semantic but not necessarily syntactic analysis (Hatzivassiloglou and Wiebe, 2000). The study of meanings of words is called lexical semantics (Johnson, 2007). In our analysis, we always assign a feature to the highest linguistic analysis level. However, there are also features that are not presented through a linguistic category, such as the number of replies to a post (Abbasi et al., 2008a). Examples are also stylistic features (Cossu et al., 2015; Mahajan and Zaveri, 2017), contextual/ non-contextual features (Negi and Buitelaar, 2014), and frequency-related and intensity-related features (Mahajan and Zaveri, 2017). We addressed those features with a category called nonlinguistic features."
    }, {
      "heading" : "3.2.2 Granularity Level",
      "text" : "A much less observed characteristic of textual features is their granularity level (called in Missen et al. (2013) and Suh (2016)). A hierarchy can be described that decomposes a text (a document, a review, a post, a tweet) into sentences, which are decomposed into words, which are decomposed into characters. Even if the granularity levels seem to be similar to the linguistic analysis levels, they are not the same. This becomes vividly illustrated by looking at unigrams and POS unigrams (Brett and Pinna, 2015; Reyes and Rosso, 2012). A text “the highest peak in the country” (Brett and Pinna, 2015) is composed of the single words (= unigrams) “the”, “highest”, “peak”, “in”, “the”, “country” – which have the syntactic roles (= part-of-speech tags, POS tags) “AT0”, “AJS”, ”NN1”, ”PRP”, ”AT0”, ”NN1”. Occurrences of both unigrams and POS unigrams can be counted and thus be used as features. It is clear that unigrams require lexical analysis and POS unigrams require syntactic analysis (“part-of-speech tagging”). So, unigrams and POS unigrams are on different linguistic analysis levels, but they have the same granularity; they are both on the word level. Thus, the granularity level “word” does not necessarily coincide with the linguistic analysis level “lexical”. Another example is the semantic feature “polarity” (semantic orientation). Polarity can be analyzed on the word level, on the sentence level, or on the document level (Missen et al., 2013), which again shows how important the granularity level is for differentiation. On top of that, we realized that several authors used features that go beyond the level of the single document, e.g., the similarity of titles between multiple documents (John et al., 2017). Here, lexical components are compared between different data points (documents). Moreover, there exist plenty of nonlinguistic features that go beyond pure text analysis. Examples are the number of links pointing to a web page (Fürnkranz, 1999), the number of clicks on a question and answer pair (Jeon et al., 2006), or the number of tweets marked as favorites (Cossu et al., 2015). This type of feature depicts a characteristic that is above the single document level, mostly looking at a collection of several documents. This can be hypertexts, discussion threads on web forums, or question and answer threads. We address the granularity level of those features with a characteristic called ”beyond document”."
    }, {
      "heading" : "3.2.3 Information Source",
      "text" : "Semantic features often rely on externally available lexicons that describe the semantic orientation or polarity (positive or negative) and subjectivity (subjective or objective) of individual words or phrases (Taboada et al., 2011). SentiWordNet is such a lexical resource used for opinion mining (Baccianella et al., 2010). Since semantic features can also be corpus-based (Liao and Grishman, 2010), a dimension describing the use of external sources is appropriate. Therefore, we included a dimension called “information source” with the characteristics corpus-based and lexicon-based to provide differentiation."
    }, {
      "heading" : "3.2.4 Dimensionality of Features",
      "text" : "As already stated above, several classifications of text mining features along single dimensions can be found in literature. A dimension that has rarely been brought up in research papers is the dimensionality of a feature – probably because it is too obvious for most of the authors. There are essentially two cases: features that are expressed in a single number, like the number of occurrences of a specific word in a document, the percentage of nouns in a text, or the Flesch readability index (e.g., (Feng et al., 2010; Kincaid et al., 1975; Flesch, 1943)), and features represented as a vector, like bags of words, bags of n grams, word embeddings, or sentence embeddings (e.g., (Brett and Pinna, 2015; Wambsganss et al., 2020a; Levy and Goldberg, 2014)). The dimensionalities of the latter correspond with the size of the individual vocabulary or embedding dimensions. Therefore, it is sufficient to distinguish the two characteristics as one-dimensional (scalar) and multi-dimensional features (vector)."
    }, {
      "heading" : "3.2.5 Representation of Features",
      "text" : "All features that we found in the literature were expressed in numbers. They can be distinguished according to their representation (Khadjeh Nassirtoussi et al., 2014) in binary numbers (0, 1), integer numbers (e.g., counts, frequencies), and real numbers (e.g., percentages, values within an interval). Bags of words appear in four different representations: presence of a word in a document (binary), number of occurrences of a word in a document (TF = term frequency), TFIDF representation of a word in a document\n(TFIDF = term frequency-inverse document frequency), and a real number representing the relative importance of a word in a document within a given corpus. Since TFIDF has a paramount role in text mining, we keep TFIDF as a separate class within the dimension “representation”. Literature often does not distinguish clearly between the name of a feature and its representation. Some authors call an individual word a feature, some say that the presence or the number of occurrences of a certain word is a feature. Günal et al. (2006) talk about 140 features for spam detection, and they present a list of 140 words (Günal et al., 2006). With the representation dimension, things should become clear. We want to provide a deeper understanding of the five dimension and their characteristics. Therefore, we allocated different feature examples in the derived dimensions illustrated in Table 1."
    }, {
      "heading" : "4 Step 3: Pattern Identification",
      "text" : "To address our third research goal, we aim to identify patterns of text features by illustrating the frequency of text features according to the dimensions and characteristics we found in our sample of studies (see Figure 5). Moreover, we unveil complex relationships between text features by performing a hierarchical cluster analysis on the studies and by visualizing the results in a heat map (see Figure 6). In Figure 5, we illustrate the frequency distribution of text mining features we found in our subset of text mining studies. With respect to the linguistic analysis level, 74 percent of all features are on the lexical level. Moreover, 73 percent of studies used features on the word granularity level, and around 27 percent used external information such as dictionaries for feature engineering. The analysis shows that researchers solely use features above the word or lexical level. Also, our objective was to identify patterns and white spots in\norder to better interpret the application of certain text feature groups which used similar features. We do not aim to derive a finite set of clusters with defined propositions. In fact, our objective is to contribute to literature and practice by deepening the understanding of the used features and describing the distribution of text mining features of our sample of studies. In Figure 5, we display our binary NxM data matrix after rearranging the columns based on Ward’s algorithm (Ward, 1963). The rows represent the N text mining features (N=133), and the columns encompass all M studies from our sample collected in the systematic literature review (M=211). A black dot indicates that a feature is used by the corresponding study. On the left side, we illustrated the resulting tree in a dendrogram, the leaves of which define a similarity sequence. In the heat map, we can clearly see filaments in the data, which indicate a certain feature and a group of studies that use it. Most prominent is the lexical feature BOW based on the word level. More than 90 percent of the analyzed papers were using BOW, which explains the long black vertical line in the heat map. In fact, a large group of studies solely used this feature (50 percent) in which the order and co-occurrence of words are not taken into account. Either the authors were not aware of higher-level features or they were satisfied with the performance of their analysis based on BOW. Moreover, this phenomenon is particularly surprising for this sample of text mining studies, as our analysis was focused on finding papers which particularly talk about text feature engineering themselves. Nevertheless, we see a high percentage of studies that use BOW in combination with other features. These features are indicated by two more filaments: One feature group is POS grams, which 32 percent of the analyzed papers used. Another band reflects the occurrence of negative or positive words, which 22 percent of the studies in our sample used. On the other side, we have a small percentage of papers (about 10 percent)\nthat do not use BOW as a feature at all. Instead, those authors used a combination of different feature levels in their domains. Looking at our feature characteristics, one phenomenon is quite surprising: only a minority of papers used features above the word level. In fact, only 18 percent of our annotated studies about feature engineering in text mining used features on a sentence, document or beyond-document level. This clearly depicts a lack of application of those feature levels, since these feature characteristics showed promising values in various other studies (e.g., Fürnkranz (1999))."
    }, {
      "heading" : "5 Conclusion",
      "text" : "In this study, we developed a taxonomy of NLP features based on Nickerson et al. (2013)’s methodological approach and provide guidance by identifying groups and propositions based on a cluster heat map analysis. Our NLP feature taxonomy is supposed to help researchers and practitioners to develop, refine, compare, and evaluate their text mining studies. We 1) illustrated the diversity of text feature engineering through a systematic literature review in which we found 133 distinct text mining features in different application domains, 2) we outlined a classification framework through a taxonomy with five dimensions and multiple characteristics, 3) we identified patterns and white spots in the application of text feature groups. For practical guidance, we present our taxonomy as a text mining feature canvas, in which a single text feature can be categorized and compared using five dimensions. Moreover, we freely present all 133 found text features on a web platform and encourage researchers to add features not listed accordingly (published upon acceptance). Our ultimate goal is to present an eclectic collection of text features and a corresponding classification framework towards a shared understanding across application domains. However, our research is limited to a certain extent. In the preliminary screening, we only selected research papers that talked explicitly about text feature engineering. By intention, we excluded the vast amount of general papers on text mining applications, which are counted in thousands. Our goal was to get diversity, not volume. The selected literature provided us with enough diversity to develop the taxonomy and to reveal first relationships. We aim to address this diversity in the future by encouraging fellow researchers to add missing features to our found feature list through our freely accessible platform."
    } ],
    "references" : [ {
      "title" : "Sentiment analysis in multiple languages",
      "author" : [ "Ahmed Abbasi", "Hsinchun Chen", "Arab Salem." ],
      "venue" : "ACM Transactions on Information Systems, 26(3):1–34.",
      "citeRegEx" : "Abbasi et al\\.,? 2008a",
      "shortCiteRegEx" : "Abbasi et al\\.",
      "year" : 2008
    }, {
      "title" : "Sentiment analysis in multiple languages: Feature selection for opinion classification in Web forums",
      "author" : [ "Ahmed Abbasi", "Hsinchun Chen", "Arab Salem." ],
      "venue" : "ACM Transactions on Information Systems, 26(3):1–34, 6.",
      "citeRegEx" : "Abbasi et al\\.,? 2008b",
      "shortCiteRegEx" : "Abbasi et al\\.",
      "year" : 2008
    }, {
      "title" : "Prominent Feature Extraction for Sentiment Analysis",
      "author" : [ "Basant Agarwal", "Namita Mittal." ],
      "venue" : "Prominent Feature Extraction for Sentiment Analysis, pages 21–45.",
      "citeRegEx" : "Agarwal and Mittal.,? 2016",
      "shortCiteRegEx" : "Agarwal and Mittal.",
      "year" : 2016
    }, {
      "title" : "A Brief Survey of Text Mining : Classification",
      "author" : [ "Mehdi Allahyari", "Elizabeth D Trippe", "Juan B Gutierrez" ],
      "venue" : "Clustering and Extraction Techniques",
      "citeRegEx" : "Allahyari et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Allahyari et al\\.",
      "year" : 2017
    }, {
      "title" : "A State-of-the-Art Survey on Deep Learning Theory and Architectures",
      "author" : [ "Md Zahangir Alom", "Tarek M. Taha", "Chris Yakopcic", "Stefan Westberg", "Paheding Sidike", "Mst Shamima Nasrin", "Mahmudul Hasan", "Brian C. Van Essen", "Abdul A.S. Awwal", "Vijayan K. Asari", "Md Zahangir Alom", "Tarek M. Taha", "Chris Yakopcic", "Stefan Westberg", "Paheding Sidike", "Mst Shamima Nasrin", "Mahmudul Hasan", "Brian C. Van Essen", "Abdul A.S. Awwal", "Vijayan K. Asari." ],
      "venue" : "Electronics, 8(3):292, 3.",
      "citeRegEx" : "Alom et al\\.,? 2019",
      "shortCiteRegEx" : "Alom et al\\.",
      "year" : 2019
    }, {
      "title" : "Understanding Plagiarism Linguistic Patterns, Textual Features, and Detection Methods",
      "author" : [ "Salha M Alzahrani", "Naomie Salim", "Ajith Abraham", "Senior Member." ],
      "venue" : "IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS, volume 42, page 133.",
      "citeRegEx" : "Alzahrani et al\\.,? 2012",
      "shortCiteRegEx" : "Alzahrani et al\\.",
      "year" : 2012
    }, {
      "title" : "SentiWordNet 3.0: An Enhanced Lexical Resource for Sentiment Analysis and Opinion Mining",
      "author" : [ "Stefano Baccianella", "Andrea Esuli", "Fabrizio Sebastiani" ],
      "venue" : null,
      "citeRegEx" : "Baccianella et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "Baccianella et al\\.",
      "year" : 2010
    }, {
      "title" : "Patterns, Fixedness and Variability: Using PoS-grams to Find Phraseologies in the Language of Travel Journalism",
      "author" : [ "David Brett", "Antonio Pinna." ],
      "venue" : "Procedia - Social and Behavioral Sciences, 198(Cilc):52–57.",
      "citeRegEx" : "Brett and Pinna.,? 2015",
      "shortCiteRegEx" : "Brett and Pinna.",
      "year" : 2015
    }, {
      "title" : "Detecting Real-World Influence through Twitter",
      "author" : [ "Jean Valere Cossu", "Nicolas Dugue", "Vincent Labatut." ],
      "venue" : "Proceedings - 2nd European Network Intelligence Conference, ENIC 2015, pages 83–90.",
      "citeRegEx" : "Cossu et al\\.,? 2015",
      "shortCiteRegEx" : "Cossu et al\\.",
      "year" : 2015
    }, {
      "title" : "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "10.",
      "citeRegEx" : "Devlin et al\\.,? 2018",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2018
    }, {
      "title" : "A Comparison of Features for Automatic Readability Assessment",
      "author" : [ "Lijun Feng", "Martin Jansche", "Matt Huenerfauth", "Noémie Elhadad." ],
      "venue" : "pages 276–284.",
      "citeRegEx" : "Feng et al\\.,? 2010",
      "shortCiteRegEx" : "Feng et al\\.",
      "year" : 2010
    }, {
      "title" : "Marks of readable style; a study in adult education",
      "author" : [ "R Flesch." ],
      "venue" : "Teachers College Contributions to Education, 897.",
      "citeRegEx" : "Flesch.,? 1943",
      "shortCiteRegEx" : "Flesch.",
      "year" : 1943
    }, {
      "title" : "Exploiting Structural Information for Text Classification on the WWW",
      "author" : [ "Johannes Fürnkranz." ],
      "venue" : "pages 487– 497.",
      "citeRegEx" : "Fürnkranz.,? 1999",
      "shortCiteRegEx" : "Fürnkranz.",
      "year" : 1999
    }, {
      "title" : "The New Window to Athletes’ Soul-What Social Media Tells Us About Athletes’ Performances",
      "author" : [ "Arne Gruettner", "Min Vitisvorakarn", "Thiemo Wambsganss", "Roman Rietsche", "Andrea Back." ],
      "venue" : "Hawaii International Conference on System Sciences (HICSS).",
      "citeRegEx" : "Gruettner et al\\.,? 2020",
      "shortCiteRegEx" : "Gruettner et al\\.",
      "year" : 2020
    }, {
      "title" : "On feature extraction for spam e-mail detection",
      "author" : [ "Serkan Günal", "Semih Ergin", "M. Bilginer Gülmezoǧlu", "Ö Nezih Gerek." ],
      "venue" : "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), volume 4105 LNCS, pages 635–642. Springer Verlag.",
      "citeRegEx" : "Günal et al\\.,? 2006",
      "shortCiteRegEx" : "Günal et al\\.",
      "year" : 2006
    }, {
      "title" : "Readability Classification for German using Lexical, Syntactic, and Morphological Features",
      "author" : [ "Julia Hancke", "Sowmya V.", "Detmar Meurers." ],
      "venue" : "24th International Conference on Computational Linguistics - Proceedings of COLING 2012: Technical Papers, pages 1063–1080.",
      "citeRegEx" : "Hancke et al\\.,? 2012",
      "shortCiteRegEx" : "Hancke et al\\.",
      "year" : 2012
    }, {
      "title" : "Effects of adjective orientation and gradability on sentence subjectivity",
      "author" : [ "Vasileios Hatzivassiloglou", "Janyce M. Wiebe." ],
      "venue" : "pages 299–305.",
      "citeRegEx" : "Hatzivassiloglou and Wiebe.,? 2000",
      "shortCiteRegEx" : "Hatzivassiloglou and Wiebe.",
      "year" : 2000
    }, {
      "title" : "Using twitter and web news mining to predict COVID-19 outbreak",
      "author" : [ "Kia Jahanbin", "Vahid Rahmanian." ],
      "venue" : "Asian Pacific Journal of Tropical Medicine, (March):26–28.",
      "citeRegEx" : "Jahanbin and Rahmanian.,? 2020",
      "shortCiteRegEx" : "Jahanbin and Rahmanian.",
      "year" : 2020
    }, {
      "title" : "A Framework to Predict the Quality of Answers with Non-Textual Features",
      "author" : [ "Jiwoon Jeon", "W Bruce Croft", "Joon Ho Lee", "Soyeon Park." ],
      "venue" : "Technical report.",
      "citeRegEx" : "Jeon et al\\.,? 2006",
      "shortCiteRegEx" : "Jeon et al\\.",
      "year" : 2006
    }, {
      "title" : "Extractive multi-document summarization using populationbased multicriteria optimization",
      "author" : [ "Ansamma John", "P.S. Premjith", "M. Wilscy." ],
      "venue" : "Expert Systems with Applications, 86:385–397, 11.",
      "citeRegEx" : "John et al\\.,? 2017",
      "shortCiteRegEx" : "John et al\\.",
      "year" : 2017
    }, {
      "title" : "The emergence of online community Leadership",
      "author" : [ "Steven L. Johnson", "Hani Safadi", "Samer Faraj." ],
      "venue" : "Information and Organization, (July):35–68.",
      "citeRegEx" : "Johnson et al\\.,? 2015",
      "shortCiteRegEx" : "Johnson et al\\.",
      "year" : 2015
    }, {
      "title" : "An Overview of Lexical Semantics",
      "author" : [ "Kent Johnson." ],
      "venue" : "Philosophy Compass, 3(1):119–134, 11.",
      "citeRegEx" : "Johnson.,? 2007",
      "shortCiteRegEx" : "Johnson.",
      "year" : 2007
    }, {
      "title" : "Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations",
      "author" : [ "Nanda Kambhatla." ],
      "venue" : "Proceedings of the ACL 2004 on Interactive poster and demonstration sessions -, pages 22–es, Morristown, NJ, USA. Association for Computational Linguistics.",
      "citeRegEx" : "Kambhatla.,? 2004",
      "shortCiteRegEx" : "Kambhatla.",
      "year" : 2004
    }, {
      "title" : "Finding groups in data : an introduction to cluster analysis",
      "author" : [ "Leonard. Kaufman", "Peter J. Rousseeuw." ],
      "venue" : "Wiley.",
      "citeRegEx" : "Kaufman and Rousseeuw.,? 2005",
      "shortCiteRegEx" : "Kaufman and Rousseeuw.",
      "year" : 2005
    }, {
      "title" : "Text mining for market prediction: A systematic review",
      "author" : [ "Arman Khadjeh Nassirtoussi", "Saeed Aghabozorgi", "Teh Ying Wah", "David Chek Ling Ngo." ],
      "venue" : "Expert Systems with Applications, 41(16):7653–7670.",
      "citeRegEx" : "Nassirtoussi et al\\.,? 2014",
      "shortCiteRegEx" : "Nassirtoussi et al\\.",
      "year" : 2014
    }, {
      "title" : "Derivation Of New Readability Formulas (Automated Readability Index, Fog Count And Flesch Reading Ease Formula) For Navy Enlisted Personnel",
      "author" : [ "J. Kincaid", "Robert Fishburne", "Richard Rogers", "Brad Chissom." ],
      "venue" : "Institute for Simulation and Training, 1.",
      "citeRegEx" : "Kincaid et al\\.,? 1975",
      "shortCiteRegEx" : "Kincaid et al\\.",
      "year" : 1975
    }, {
      "title" : "Dependency-based word embeddings",
      "author" : [ "Omer Levy", "Yoav Goldberg." ],
      "venue" : "Technical report.",
      "citeRegEx" : "Levy and Goldberg.,? 2014",
      "shortCiteRegEx" : "Levy and Goldberg.",
      "year" : 2014
    }, {
      "title" : "Large Corpus-based Semantic Feature Extraction for Pronoun Coreference",
      "author" : [ "Shasha Liao", "Ralph Grishman." ],
      "venue" : "Technical report.",
      "citeRegEx" : "Liao and Grishman.,? 2010",
      "shortCiteRegEx" : "Liao and Grishman.",
      "year" : 2010
    }, {
      "title" : "Identifying featured articles in Wikipedia: Writing style matters",
      "author" : [ "Nedim Lipka", "Benno Stein." ],
      "venue" : "Proceedings of the 19th International Conference on World Wide Web, WWW ’10, pages 1147–1148, New York, New York, USA. ACM Press.",
      "citeRegEx" : "Lipka and Stein.,? 2010",
      "shortCiteRegEx" : "Lipka and Stein.",
      "year" : 2010
    }, {
      "title" : "Question classification by weighted combination of lexical, syntactic and semantic features",
      "author" : [ "Babak Loni", "Gijs Van Tulder", "Pascal Wiggers", "David M.J. Tax", "Marco Loog." ],
      "venue" : "Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), volume 6836 LNAI, pages 243–250. Springer, Berlin, Heidelberg.",
      "citeRegEx" : "Loni et al\\.,? 2011",
      "shortCiteRegEx" : "Loni et al\\.",
      "year" : 2011
    }, {
      "title" : "SVNIT @ SemEval 2017 Task-6: Learning a Sense of Humor Using Supervised Approach",
      "author" : [ "Rutal Mahajan", "Mukesh Zaveri." ],
      "venue" : "pages 411–415.",
      "citeRegEx" : "Mahajan and Zaveri.,? 2017",
      "shortCiteRegEx" : "Mahajan and Zaveri.",
      "year" : 2017
    }, {
      "title" : "Predictive Policing: Review of Benefits and Drawbacks",
      "author" : [ "Albert Meijer", "Martijn Wessels." ],
      "venue" : "International Journal of Public Administration, 42(12):1031–1039, 9.",
      "citeRegEx" : "Meijer and Wessels.,? 2019",
      "shortCiteRegEx" : "Meijer and Wessels.",
      "year" : 2019
    }, {
      "title" : "Opinion mining: reviewed from word to document level",
      "author" : [ "Malik Muhammad Saad Missen", "Mohand Boughanem", "Guillaume Cabanac." ],
      "venue" : "Social Network Analysis and Mining, 3(1):107–125.",
      "citeRegEx" : "Missen et al\\.,? 2013",
      "shortCiteRegEx" : "Missen et al\\.",
      "year" : 2013
    }, {
      "title" : "Sentiment Analysis in Twitter with Lightweight Discourse Analysis",
      "author" : [ "Subhabrata Mukherjee", "Pushpak Bhattacharyya." ],
      "venue" : "COLING.",
      "citeRegEx" : "Mukherjee and Bhattacharyya.,? 2012",
      "shortCiteRegEx" : "Mukherjee and Bhattacharyya.",
      "year" : 2012
    }, {
      "title" : "Influence of lexical, syntactic and structural features and their combination on Authorship Attribution for Telugu Tex",
      "author" : [ "S. NagaPrasad", "V.B. Narsimha", "P. Vijayapal Reddy", "A. Vinaya Babu." ],
      "venue" : "Procedia Computer Science, volume 48, pages 58–64. Elsevier B.V., 1.",
      "citeRegEx" : "NagaPrasad et al\\.,? 2015",
      "shortCiteRegEx" : "NagaPrasad et al\\.",
      "year" : 2015
    }, {
      "title" : "INSIGHT Galway: Syntactic and Lexical Features for Aspect Based Sentiment Analysis",
      "author" : [ "Sapna Negi", "Paul Buitelaar." ],
      "venue" : "pages 346–350.",
      "citeRegEx" : "Negi and Buitelaar.,? 2014",
      "shortCiteRegEx" : "Negi and Buitelaar.",
      "year" : 2014
    }, {
      "title" : "A method for taxonomy development and its application in information systems",
      "author" : [ "Robert C Nickerson", "Upkar Varshney", "Jan Muntermann." ],
      "venue" : "European Journal of Information Systems, 22(3):336–359, 5.",
      "citeRegEx" : "Nickerson et al\\.,? 2013",
      "shortCiteRegEx" : "Nickerson et al\\.",
      "year" : 2013
    }, {
      "title" : "Opinion mining and sentiment analysis",
      "author" : [ "Bo Pang", "Lillian Lee." ],
      "venue" : "Foundations and Trends in Information Retrieval, 2(12):1–135.",
      "citeRegEx" : "Pang and Lee.,? 2008",
      "shortCiteRegEx" : "Pang and Lee.",
      "year" : 2008
    }, {
      "title" : "Natural Language Annotation",
      "author" : [ "James Pustejovsky", "Amber Stubbs." ],
      "venue" : "O’Reilly.",
      "citeRegEx" : "Pustejovsky and Stubbs.,? 2013",
      "shortCiteRegEx" : "Pustejovsky and Stubbs.",
      "year" : 2013
    }, {
      "title" : "From Text to Knowledge: Document Processing and Visualization: a Text Mining Approach",
      "author" : [ "Martin Rajman", "Martin Vesely." ],
      "venue" : "pages 7–24. Springer, Berlin, Heidelberg.",
      "citeRegEx" : "Rajman and Vesely.,? 2004",
      "shortCiteRegEx" : "Rajman and Vesely.",
      "year" : 2004
    }, {
      "title" : "Making objective decisions from subjective data: Detecting irony in customer reviews",
      "author" : [ "Antonio Reyes", "Paolo Rosso." ],
      "venue" : "Decision Support Systems, volume 53, pages 754–760. North-Holland, 11.",
      "citeRegEx" : "Reyes and Rosso.,? 2012",
      "shortCiteRegEx" : "Reyes and Rosso.",
      "year" : 2012
    }, {
      "title" : "Auditing Predictive Policing",
      "author" : [ "Jeremiah Scanlan." ],
      "venue" : "Brigham Young University Prelaw Review, 33.",
      "citeRegEx" : "Scanlan.,? 2019",
      "shortCiteRegEx" : "Scanlan.",
      "year" : 2019
    }, {
      "title" : "A Berkeley View of Systems Challenges for AI",
      "author" : [ "Ion Stoica", "Dawn Song", "Raluca Ada Popa", "David Patterson", "Michael W Mahoney", "Randy Katz", "Anthony D Joseph", "Michael Jordan", "Joseph M Hellerstein", "Joseph E. Gonzalez", "Ken Goldberg", "Ali Ghodsi", "David Culler", "Pieter Abbeel" ],
      "venue" : null,
      "citeRegEx" : "Stoica et al\\.,? \\Q2017\\E",
      "shortCiteRegEx" : "Stoica et al\\.",
      "year" : 2017
    }, {
      "title" : "Comparing writing style feature-based classification methods for estimating user reputations in social media",
      "author" : [ "Jong Hwan Suh" ],
      "venue" : null,
      "citeRegEx" : "Suh.,? \\Q2016\\E",
      "shortCiteRegEx" : "Suh.",
      "year" : 2016
    }, {
      "title" : "Lexicon-basedmethods for sentiment analysis",
      "author" : [ "Maite Taboada", "Julian Brooke", "Milan Tofiloski", "Kimberly Voll", "Manfred Stede." ],
      "venue" : "Computational Linguistics, 37(2):267–307, 6.",
      "citeRegEx" : "Taboada et al\\.,? 2011",
      "shortCiteRegEx" : "Taboada et al\\.",
      "year" : 2011
    }, {
      "title" : "Text Mining : Techniques , Applications and Issues",
      "author" : [ "Ramzan Talib", "Muhammad Kashif Hanif", "Shaeela Ayesha", "Fakeeha Fatima." ],
      "venue" : "7(11):414–418.",
      "citeRegEx" : "Talib et al\\.,? 2016",
      "shortCiteRegEx" : "Talib et al\\.",
      "year" : 2016
    }, {
      "title" : "Automatic feature generation and selection in predictive analytics solutions",
      "author" : [ "Suzanne Van Den Bosch." ],
      "venue" : "page 40.",
      "citeRegEx" : "Bosch.,? 2017",
      "shortCiteRegEx" : "Bosch.",
      "year" : 2017
    }, {
      "title" : "Standing on the Shoulders of Giants: Challenges and Recommendations of Literature Search in Information Systems Research",
      "author" : [ "Jan vom Brocke", "Alexander Simons", "Kai Riemer", "Björn Niehaves", "Ralf Plattfaut", "Anne Cleven." ],
      "venue" : "Communications of the Association for Information Systems, 37(1), 8.",
      "citeRegEx" : "Brocke et al\\.,? 2015",
      "shortCiteRegEx" : "Brocke et al\\.",
      "year" : 2015
    }, {
      "title" : "Mining User-Generated Repair Instructions from Automotive Web Communities",
      "author" : [ "Thiemo Wambsganss", "Hansjörg Fromm." ],
      "venue" : "Proceedings of the 52nd Hawaii International Conference on System Sciences, volume 6, pages 1184–1193, Hawaii.",
      "citeRegEx" : "Wambsganss and Fromm.,? 2019",
      "shortCiteRegEx" : "Wambsganss and Fromm.",
      "year" : 2019
    }, {
      "title" : "Unlocking Transfer Learning in Argumentation Mining : A Domain-Independent Modelling Approach",
      "author" : [ "Thiemo Wambsganss", "Nikolaos Molyndris", "Matthias Söllner." ],
      "venue" : "15th International Conference on Wirtschaftsinformatik,, number Ml, Potsdam, Germany.",
      "citeRegEx" : "Wambsganss et al\\.,? 2020a",
      "shortCiteRegEx" : "Wambsganss et al\\.",
      "year" : 2020
    }, {
      "title" : "AL : An Adaptive Learning Support System for Argumentation Skills",
      "author" : [ "Thiemo Wambsganss", "Christina Niklaus", "Matthias Cetto", "Matthias Söllner", "Jan Marco Leimeister", "Siegfried Handschuh." ],
      "venue" : "ACM CHI Conference on Human Factors in Computing Systems, pages 1–14.",
      "citeRegEx" : "Wambsganss et al\\.,? 2020b",
      "shortCiteRegEx" : "Wambsganss et al\\.",
      "year" : 2020
    }, {
      "title" : "Hierarchical Grouping to Optimize an Objective Function",
      "author" : [ "Joe H. Ward." ],
      "venue" : "Journal of the American Statistical Association, 58(301):236, 3.",
      "citeRegEx" : "Ward.,? 1963",
      "shortCiteRegEx" : "Ward.",
      "year" : 1963
    }, {
      "title" : "Analyzing the past to prepare for the future : Writing a literature review Reproduced with permission of the copyright owner",
      "author" : [ "Jane Webster", "Richard T Watson." ],
      "venue" : "Further reproduction prohibited without permission . MIS Quarterly, 26(2):xiii–xxiii.",
      "citeRegEx" : "Webster and Watson.,? 2002",
      "shortCiteRegEx" : "Webster and Watson.",
      "year" : 2002
    }, {
      "title" : "ificial Intelligence (Ai) Market By Technology (Machine Learning, Natural Language Processing (Nlp), Image Processing, And Speech Recognition), Application &amp; Geography - Global Forecast To 2020",
      "author" : [ "Laura Wood." ],
      "venue" : "Technical report.",
      "citeRegEx" : "Wood.,? 2016",
      "shortCiteRegEx" : "Wood.",
      "year" : 2016
    }, {
      "title" : "A framework for authorship identification of online messages: Writing-style features and classification techniques",
      "author" : [ "Rong Zheng", "Jiexun Li", "Hsinchun Chen", "Zan Huang." ],
      "venue" : "Journal of the American Society for Information Science and Technology, 57(3):378–393, 2.",
      "citeRegEx" : "Zheng et al\\.,? 2006",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 53,
      "context" : "In the last years, several application areas have become popular, such as spam detection (Wood, 2016), sport performance prediction (Gruettner et al.",
      "startOffset" : 89,
      "endOffset" : 101
    }, {
      "referenceID" : 13,
      "context" : "In the last years, several application areas have become popular, such as spam detection (Wood, 2016), sport performance prediction (Gruettner et al., 2020), web mining to predict pandemic outbreaks (Jahanbin and Rahmanian, 2020), predictive policing (Meijer and Wessels, 2019), or procedural knowledge extraction (Wambsganss and Fromm, 2019).",
      "startOffset" : 132,
      "endOffset" : 156
    }, {
      "referenceID" : 17,
      "context" : ", 2020), web mining to predict pandemic outbreaks (Jahanbin and Rahmanian, 2020), predictive policing (Meijer and Wessels, 2019), or procedural knowledge extraction (Wambsganss and Fromm, 2019).",
      "startOffset" : 50,
      "endOffset" : 80
    }, {
      "referenceID" : 31,
      "context" : ", 2020), web mining to predict pandemic outbreaks (Jahanbin and Rahmanian, 2020), predictive policing (Meijer and Wessels, 2019), or procedural knowledge extraction (Wambsganss and Fromm, 2019).",
      "startOffset" : 102,
      "endOffset" : 128
    }, {
      "referenceID" : 48,
      "context" : ", 2020), web mining to predict pandemic outbreaks (Jahanbin and Rahmanian, 2020), predictive policing (Meijer and Wessels, 2019), or procedural knowledge extraction (Wambsganss and Fromm, 2019).",
      "startOffset" : 165,
      "endOffset" : 193
    }, {
      "referenceID" : 9,
      "context" : "Fueled with big data, artifical neural networks (ANN) and transfer learning algorithms such as BERT (Devlin et al., 2018) have been very successful in processing large amounts of data and predicting outcomes precisely (Alom et al.",
      "startOffset" : 100,
      "endOffset" : 121
    }, {
      "referenceID" : 4,
      "context" : ", 2018) have been very successful in processing large amounts of data and predicting outcomes precisely (Alom et al., 2019).",
      "startOffset" : 104,
      "endOffset" : 123
    }, {
      "referenceID" : 42,
      "context" : "Exemplary use cases can be found in human-centered decision support systems (Stoica et al., 2017; Alom et al., 2019), e.",
      "startOffset" : 76,
      "endOffset" : 116
    }, {
      "referenceID" : 4,
      "context" : "Exemplary use cases can be found in human-centered decision support systems (Stoica et al., 2017; Alom et al., 2019), e.",
      "startOffset" : 76,
      "endOffset" : 116
    }, {
      "referenceID" : 50,
      "context" : ", writing support systems for educational feedback (Wambsganss et al., 2020b) or auditing for predictive policing (Scanlan, 2019).",
      "startOffset" : 51,
      "endOffset" : 77
    }, {
      "referenceID" : 41,
      "context" : ", 2020b) or auditing for predictive policing (Scanlan, 2019).",
      "startOffset" : 45,
      "endOffset" : 60
    }, {
      "referenceID" : 39,
      "context" : "The main challenge of text mining is to preprocess written text and extract valuable features to enable information extraction (IE), data analytics (DA), or machine learning (ML) algorithms to reach their maximum performance (Rajman and Vesely, 2004; Johnson et al., 2015; Allahyari et al., 2017).",
      "startOffset" : 225,
      "endOffset" : 296
    }, {
      "referenceID" : 20,
      "context" : "The main challenge of text mining is to preprocess written text and extract valuable features to enable information extraction (IE), data analytics (DA), or machine learning (ML) algorithms to reach their maximum performance (Rajman and Vesely, 2004; Johnson et al., 2015; Allahyari et al., 2017).",
      "startOffset" : 225,
      "endOffset" : 296
    }, {
      "referenceID" : 3,
      "context" : "The main challenge of text mining is to preprocess written text and extract valuable features to enable information extraction (IE), data analytics (DA), or machine learning (ML) algorithms to reach their maximum performance (Rajman and Vesely, 2004; Johnson et al., 2015; Allahyari et al., 2017).",
      "startOffset" : 225,
      "endOffset" : 296
    }, {
      "referenceID" : 38,
      "context" : "This may lead to an overall underperformance, since copious training data is often not available (Pustejovsky and Stubbs, 2013).",
      "startOffset" : 97,
      "endOffset" : 127
    }, {
      "referenceID" : 20,
      "context" : "As a result, different teams of authors have indicated that enhancing text mining algorithms with the appropriate design, implementation, and evaluation of text features - a process commonly referred to as feature engineering - bears high chances of improving text mining outcomes significantly (Bird et al., 2009; Khadjeh Nassirtoussi et al., 2014; Johnson et al., 2015).",
      "startOffset" : 295,
      "endOffset" : 371
    }, {
      "referenceID" : 9,
      "context" : "Fueled with large amounts of data, artificial neural networks (ANNs) or transfer learning models such as BERT (Devlin et al., 2018) have been very successful in processing large amounts of data and achieving high-quality predictions (Alom et al.",
      "startOffset" : 110,
      "endOffset" : 131
    }, {
      "referenceID" : 4,
      "context" : ", 2018) have been very successful in processing large amounts of data and achieving high-quality predictions (Alom et al., 2019; Wambsganss et al., 2020a).",
      "startOffset" : 109,
      "endOffset" : 154
    }, {
      "referenceID" : 49,
      "context" : ", 2018) have been very successful in processing large amounts of data and achieving high-quality predictions (Alom et al., 2019; Wambsganss et al., 2020a).",
      "startOffset" : 109,
      "endOffset" : 154
    }, {
      "referenceID" : 42,
      "context" : "In fact, explainablility has played a major role for the practical success of ML algorithms, as they are often embedded in human-centered decision support systems (Stoica et al., 2017; Alom et al., 2019).",
      "startOffset" : 163,
      "endOffset" : 203
    }, {
      "referenceID" : 4,
      "context" : "In fact, explainablility has played a major role for the practical success of ML algorithms, as they are often embedded in human-centered decision support systems (Stoica et al., 2017; Alom et al., 2019).",
      "startOffset" : 163,
      "endOffset" : 203
    }, {
      "referenceID" : 4,
      "context" : ", less than 1,000 labelled data points) (Alom et al., 2019).",
      "startOffset" : 40,
      "endOffset" : 59
    }, {
      "referenceID" : 50,
      "context" : ", for human-centered writing support systems (Wambsganss et al., 2020b) or auditing for predictive policing (Scanlan, 2019).",
      "startOffset" : 45,
      "endOffset" : 71
    }, {
      "referenceID" : 41,
      "context" : ", 2020b) or auditing for predictive policing (Scanlan, 2019).",
      "startOffset" : 45,
      "endOffset" : 60
    }, {
      "referenceID" : 11,
      "context" : "The one most widely applied is the Flesch readability index, which is calculated from the number of sentences, words, and syllables of a text (Flesch, 1943; Kincaid et al., 1975).",
      "startOffset" : 142,
      "endOffset" : 178
    }, {
      "referenceID" : 25,
      "context" : "The one most widely applied is the Flesch readability index, which is calculated from the number of sentences, words, and syllables of a text (Flesch, 1943; Kincaid et al., 1975).",
      "startOffset" : 142,
      "endOffset" : 178
    }, {
      "referenceID" : 37,
      "context" : "It can be observed on the word, the sentence, or the document level (Pang and Lee, 2008).",
      "startOffset" : 68,
      "endOffset" : 88
    }, {
      "referenceID" : 48,
      "context" : "Procedure or instruction mining tries to find answers for “how to” questions in the vastness of the internet (Wambsganss and Fromm, 2019).",
      "startOffset" : 109,
      "endOffset" : 137
    }, {
      "referenceID" : 23,
      "context" : "3) We identify patterns by performing a cluster analysis to display the complex relationships between text features in a heat map and to identify the application of certain feature groups that used similar features (Kaufman and Rousseeuw, 2005).",
      "startOffset" : 215,
      "endOffset" : 244
    }, {
      "referenceID" : 20,
      "context" : "The dimensions most widely mentioned in literature are the linguistic perspectives (Johnson et al., 2015), or in other words, the hierarchy of stages in NLP: morphological analysis, lexical analysis, syntactical analysis, and semantic analysis (Johnson et al.",
      "startOffset" : 83,
      "endOffset" : 105
    }, {
      "referenceID" : 20,
      "context" : ", 2015), or in other words, the hierarchy of stages in NLP: morphological analysis, lexical analysis, syntactical analysis, and semantic analysis (Johnson et al., 2015; Bird et al., 2009).",
      "startOffset" : 146,
      "endOffset" : 187
    }, {
      "referenceID" : 16,
      "context" : "Sentiment analysis works basically with the meaning of words (with positive or negative sentiments) and thus requires a lexical and semantic but not necessarily syntactic analysis (Hatzivassiloglou and Wiebe, 2000).",
      "startOffset" : 180,
      "endOffset" : 214
    }, {
      "referenceID" : 21,
      "context" : "The study of meanings of words is called lexical semantics (Johnson, 2007).",
      "startOffset" : 59,
      "endOffset" : 74
    }, {
      "referenceID" : 0,
      "context" : "However, there are also features that are not presented through a linguistic category, such as the number of replies to a post (Abbasi et al., 2008a).",
      "startOffset" : 127,
      "endOffset" : 149
    }, {
      "referenceID" : 8,
      "context" : "Examples are also stylistic features (Cossu et al., 2015; Mahajan and Zaveri, 2017), contextual/ non-contextual features (Negi and Buitelaar, 2014), and frequency-related and intensity-related features (Mahajan and Zaveri, 2017).",
      "startOffset" : 37,
      "endOffset" : 83
    }, {
      "referenceID" : 30,
      "context" : "Examples are also stylistic features (Cossu et al., 2015; Mahajan and Zaveri, 2017), contextual/ non-contextual features (Negi and Buitelaar, 2014), and frequency-related and intensity-related features (Mahajan and Zaveri, 2017).",
      "startOffset" : 37,
      "endOffset" : 83
    }, {
      "referenceID" : 35,
      "context" : ", 2015; Mahajan and Zaveri, 2017), contextual/ non-contextual features (Negi and Buitelaar, 2014), and frequency-related and intensity-related features (Mahajan and Zaveri, 2017).",
      "startOffset" : 71,
      "endOffset" : 97
    }, {
      "referenceID" : 30,
      "context" : ", 2015; Mahajan and Zaveri, 2017), contextual/ non-contextual features (Negi and Buitelaar, 2014), and frequency-related and intensity-related features (Mahajan and Zaveri, 2017).",
      "startOffset" : 152,
      "endOffset" : 178
    }, {
      "referenceID" : 54,
      "context" : "Frequency of character ”@” (Zheng et al., 2006) lexical character no scalar integer (count)",
      "startOffset" : 27,
      "endOffset" : 47
    }, {
      "referenceID" : 10,
      "context" : "Average number of syllables per word (Feng et al., 2010) morphol.",
      "startOffset" : 37,
      "endOffset" : 56
    }, {
      "referenceID" : 43,
      "context" : "Average sentence length in words (Suh, 2016) lexical word no scalar real number",
      "startOffset" : 33,
      "endOffset" : 44
    }, {
      "referenceID" : 7,
      "context" : "POS-n-gram vectors (Brett and Pinna, 2015) syntactical word no vector integer (count)",
      "startOffset" : 19,
      "endOffset" : 42
    }, {
      "referenceID" : 26,
      "context" : "Word embeddings (Levy and Goldberg, 2014) lexical word yes vector real number",
      "startOffset" : 16,
      "endOffset" : 41
    }, {
      "referenceID" : 28,
      "context" : "Binary character trigram vectors (Lipka and Stein, 2010) lexical character no vector binary (presence)",
      "startOffset" : 33,
      "endOffset" : 56
    }, {
      "referenceID" : 11,
      "context" : ") (Flesch, 1943) lexical document no scalar real number",
      "startOffset" : 2,
      "endOffset" : 16
    }, {
      "referenceID" : 2,
      "context" : "Word polarity (Agarwal and Mittal, 2016) semantic word yes vector real number (-1;+1)",
      "startOffset" : 14,
      "endOffset" : 40
    }, {
      "referenceID" : 32,
      "context" : "Sentence polarity (Missen et al., 2013) semantic sentence yes scalar real number (-1;+1)",
      "startOffset" : 18,
      "endOffset" : 39
    }, {
      "referenceID" : 33,
      "context" : "Document polarity (Review polarity) (Mukherjee and Bhattacharyya, 2012) semantic document yes vector real number (-1;+1)",
      "startOffset" : 36,
      "endOffset" : 71
    }, {
      "referenceID" : 1,
      "context" : "Time stamp of a message (Abbasi et al., 2008b) nonlinguistic document no scalar real number",
      "startOffset" : 24,
      "endOffset" : 46
    }, {
      "referenceID" : 19,
      "context" : "Title similarity across documents (John et al., 2017) lexical beyond document no vector real number (TF/IDF) Number of links pointing to a web page (Fürnkranz, 1999) nonlinguistic beyond document no scalar real number",
      "startOffset" : 34,
      "endOffset" : 53
    }, {
      "referenceID" : 12,
      "context" : ", 2017) lexical beyond document no vector real number (TF/IDF) Number of links pointing to a web page (Fürnkranz, 1999) nonlinguistic beyond document no scalar real number",
      "startOffset" : 102,
      "endOffset" : 119
    }, {
      "referenceID" : 7,
      "context" : "This becomes vividly illustrated by looking at unigrams and POS unigrams (Brett and Pinna, 2015; Reyes and Rosso, 2012).",
      "startOffset" : 73,
      "endOffset" : 119
    }, {
      "referenceID" : 40,
      "context" : "This becomes vividly illustrated by looking at unigrams and POS unigrams (Brett and Pinna, 2015; Reyes and Rosso, 2012).",
      "startOffset" : 73,
      "endOffset" : 119
    }, {
      "referenceID" : 7,
      "context" : "A text “the highest peak in the country” (Brett and Pinna, 2015) is composed of the single words (= unigrams) “the”, “highest”, “peak”, “in”, “the”, “country” – which have the syntactic roles (= part-of-speech tags, POS tags) “AT0”, “AJS”, ”NN1”, ”PRP”, ”AT0”, ”NN1”.",
      "startOffset" : 41,
      "endOffset" : 64
    }, {
      "referenceID" : 32,
      "context" : "Polarity can be analyzed on the word level, on the sentence level, or on the document level (Missen et al., 2013), which again shows how important the granularity level is for differentiation.",
      "startOffset" : 92,
      "endOffset" : 113
    }, {
      "referenceID" : 19,
      "context" : ", the similarity of titles between multiple documents (John et al., 2017).",
      "startOffset" : 54,
      "endOffset" : 73
    }, {
      "referenceID" : 12,
      "context" : "Examples are the number of links pointing to a web page (Fürnkranz, 1999), the number of clicks on a question and answer pair (Jeon et al.",
      "startOffset" : 56,
      "endOffset" : 73
    }, {
      "referenceID" : 18,
      "context" : "Examples are the number of links pointing to a web page (Fürnkranz, 1999), the number of clicks on a question and answer pair (Jeon et al., 2006), or the number of tweets marked as favorites (Cossu et al.",
      "startOffset" : 126,
      "endOffset" : 145
    }, {
      "referenceID" : 8,
      "context" : ", 2006), or the number of tweets marked as favorites (Cossu et al., 2015).",
      "startOffset" : 53,
      "endOffset" : 73
    }, {
      "referenceID" : 44,
      "context" : "Semantic features often rely on externally available lexicons that describe the semantic orientation or polarity (positive or negative) and subjectivity (subjective or objective) of individual words or phrases (Taboada et al., 2011).",
      "startOffset" : 210,
      "endOffset" : 232
    }, {
      "referenceID" : 6,
      "context" : "SentiWordNet is such a lexical resource used for opinion mining (Baccianella et al., 2010).",
      "startOffset" : 64,
      "endOffset" : 90
    }, {
      "referenceID" : 27,
      "context" : "Since semantic features can also be corpus-based (Liao and Grishman, 2010), a dimension describing the use of external sources is appropriate.",
      "startOffset" : 49,
      "endOffset" : 74
    }, {
      "referenceID" : 10,
      "context" : ", (Feng et al., 2010; Kincaid et al., 1975; Flesch, 1943)), and features represented as a vector, like bags of words, bags of n grams, word embeddings, or sentence embeddings (e.",
      "startOffset" : 2,
      "endOffset" : 57
    }, {
      "referenceID" : 25,
      "context" : ", (Feng et al., 2010; Kincaid et al., 1975; Flesch, 1943)), and features represented as a vector, like bags of words, bags of n grams, word embeddings, or sentence embeddings (e.",
      "startOffset" : 2,
      "endOffset" : 57
    }, {
      "referenceID" : 11,
      "context" : ", (Feng et al., 2010; Kincaid et al., 1975; Flesch, 1943)), and features represented as a vector, like bags of words, bags of n grams, word embeddings, or sentence embeddings (e.",
      "startOffset" : 2,
      "endOffset" : 57
    }, {
      "referenceID" : 14,
      "context" : "(2006) talk about 140 features for spam detection, and they present a list of 140 words (Günal et al., 2006).",
      "startOffset" : 88,
      "endOffset" : 108
    }, {
      "referenceID" : 51,
      "context" : "In Figure 5, we display our binary NxM data matrix after rearranging the columns based on Ward’s algorithm (Ward, 1963).",
      "startOffset" : 107,
      "endOffset" : 119
    } ],
    "year" : 2020,
    "abstractText" : "The extraction of features from texts plays a major role in the performance of text-mining applications. However, text features that evolved in one particular domain are often unknown in the other domain and scientific text feature frameworks that facilitate costly human feature engineering are rarely available. Therefore, we developed a novel text feature taxonomy that aims to assist researchers and practitioners to classify, compare, and evaluate their text mining studies. Based on a systematic literature review, we found 133 unique features in studies about text feature engineering and iteratively derived five dimensions with multiple corresponding characteristics. Using our framework, a researcher can classify and compare a text feature according to its linguistic analysis level, granularity level, information source, dimensionality, and its representation. Moreover, we identified several application patterns and white spots in a cluster heat mapping analysis and present our found features and categorization on a web platform to encourage fellow researchers to get inspiration, compare, or add missing features.",
    "creator" : "TeX"
  }
}