{
  "name" : "COLING_2020_64_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Text generation with deep learning models is data hungry. For example, in Figure 1, to make a model learn how to verbalize knowledge graphs, researchers need to collect a large number of human-annotated text and graph pairs. However, good annotation is both expensive and difficult to get – annotators need to have a thorough understanding of hundreds of edge types in the knowledge graphs, as well as proper verbalization of the text, so that the written text can conform to the distribution of the desired text style. Moreover, for dataset curators, checking the quality of annotation is also non-trivial. For example, the WebNLG dataset goes through five updates to fix errors in the annotation over the past 3 years.1\nThese difficulties in dataset collection makes parallel data-to-text datasets small-sized, and even nonexistent for low-resource domains. To make problems worse, data-to-text models are, in many cases, infeasible to transfer from one domain to another. For example, a text generation model that can produce Wikipedia biography-like descriptions cannot be used to generate introductions of plants. This can happen even between domains with similar content but different text styles. For example, given the knowledge graph triple “(Obama, birthYear, 1961),” one domain verbalizes it as “Obama was born in 1961,” whereas another domain prefers “Obama (1961 – ) ...”. A model trained in the first domain can only generate the entities correctly but fail on all other words in the second domain.\nTo overcome the lack of labelled data and difficulty in domain adaptation, unsupervised data-to-text generation has emerged as an active research field recently (Freitag and Roy, 2018; Schmitt and Schütze, 2019; Guo et al., 2020). However, the progress of this line of research is slowed down due to the lack of large-scale unsupervised datasets. Notably, the curation of graph-to-text unsupervised datasets are nontrivial, as it requires (1) same content distribution between graphs and text, (2) text with high-accuracy entity annotation, (3) a much larger scale than the supervised datasets, and (4) a human-annotated test set. Unfortunately, lacking such an unsupervised dataset, most unsupervised works have to artificially remove the pairing information between text and structured data, to force parallel datasets to be nonparallel. Obviously, splitting parallel datasets, such as the WebNLG dataset (13K), and E2E dataset (50K), into non-parallel ones remains the originally small data size. Consequenty, the research on unsupervised models is limited, as these existing unsupervised models cannot even have a deep architecture. In contrast, a relatively faster field, unsupervised machine translation, has dataset sizes on the order of billions, such as 1.6B German and 2.1B English text used in (Artetxe et al., 2019).\n1https://gitlab.com/shimorina/webnlg-dataset\nTherefore, we propose a large dataset, GenWiki, which contains 1.3 million non-parallel text and graphs with shared content, and meet all four requirements mentioned before. To better facilitate research in unsupervised graph-to-text generation, we provide two versions of our dataset: the full dataset GenWikiFULL (1.3M), and a fine version, GenWikiFINE (750K), which adds constraints on the text and graphs to force them to contain highly overlapped entity sets. The overview of our two datasets are shown in Figure 1. The GenWikiFULL on the bottom left contains graphs on the same topic (Dota 2) as the text, and GenWikiFINE imposes a stronger constraint that entities in the graph can largely overlap with entities in text. Both datasets are collected in a scalable, automatic way. The comparison of our dataset and previous data-to-text datasets is illustrated in Table 2.\nAn additional contribution is our human-annotated test set with of 1,000 graph and text pairs. Based on our large-scale training dataset and the human-annotated test set, we analyze the performance of several baselines and existing models."
    }, {
      "heading" : "2 Existing Data-to-Text Models and Datasets",
      "text" : "Research in NLP can be viewed as a close interplay between models and datasets. Traditionally, most methods hand-craft linguistic features to build rule-based systems, so datasets containing hundreds or thousands of samples are adequate. For example, in data-to-text generation, the traditional approach is to hand-craft templates (Kukich, 1983; Holmes-Higgin, 1994; McRoy et al., 2000). There are also works that abstract the templates and use probabilistic models to learn the rules (Angeli et al., 2010; Howald\n2The unfiltered dataset contained 728K, but only 500K are non-empty samples.\net al., 2013). Popular datasets for these methods are, for example, the 0.7K RoboCup dataset (Chen and Mooney, 2008).\nWith the advance of deep learning, models have a large number of parameters, so they have to be fueled by large datasets. For data-to-text generation, many supervised methods use large neural networks. To match with these data-hungry models, researchers devote many efforts to curate supervised datasets. Most supervised data-to-text datasets have tens of thousands of data.3 For instance, WebNLG dataset (Gardent et al., 2017) has 13K valid data-text pairs, WeatherGov (Liang et al., 2009) has 22K weather forecasts, and E2E (Novikova et al., 2017) has 50K restaurant and hotel descriptions, as shown in Table 2.\nRecently, there is a rising trend of unsupervised approaches (Freitag and Roy, 2018; Schmitt and Schütze, 2019; Guo et al., 2020). Unsupervised data-to-text models (Konstas and Lapata, 2012) are proposed in response to the lack of data-text pairs in many domains, similar to the emergence of unsupervised machine translation that addresses lack of data low-resource language pairs. However, to match with the active research on unsupervised data-to-text generation, no suitable dataset has been curated. As a result, most previous works have to artificially force parallel datasets to be non-parallel, by separately shuffling the data part and text part of the original dataset, or directly deleting the text part. However, such formulation will make the unsupervised datasets inherent the small size of the supervised datasets, which are limited to only tens of thousands samples.\nThere are several caveats of using small datasets for unsupervised models. (1) Limiting the model potential: Unsupervised models can be data-hungry. For example, 1.6B German and 2.1B English tokens are fed to unsupervised machine translation models (Artetxe et al., 2019); 3.3 billion words are used to pretrain the language model BERT (Devlin et al., 2019). With abundant data, the potential of unsupervised models is unleashed – impressive performance, based on an enormous number parameters, such as 12 layers of transformers. So far, no large data-to-text corpus can be used to unveil the potential of unsupervised data-to-text. (2) Lack of diversity: As many unsupervised models need to impose strong priors such as grammar and dependency tree (Konstas and Lapata, 2012), if a proposed model works well on a specific type of text generation, we cannot validate whether such a model generalizes well. (3) Negligence of model efficiency: The goal of unsupervised models is to learn from as many unsupervised data as possible and thus achieve high accuracy. However, the current design of many unsupervised does not take efficiency into consideration because of the small datasets they use does not expose the problem of efficiency.\nHence, to foster research in unsupervised data-to-text learning, we construct a new, large-scale dataset, GenWiki, which can satisfy all constraints imposed by existing unsupervised models. The dataset will be introduced in Section 3 and 4."
    }, {
      "heading" : "3 Desiderata",
      "text" : "Although it is easy to collect unsupervised datasets for tasks such as machine translation, it is a different story for data-to-text generation. To match with the design of unsupervised data-to-text models, some strict constraints are required. A common constraint is that the text and knowledge graphs should have the same content distribution. Some more specific constraints require, for example, the text corpus to have entity annotations. The reason is that recent unsupervised learning models (Guo et al., 2020; Schmitt and Schütze, 2019) use cycle training of two tasks: graph-to-text, and text-to-graph, which is simplified to relation extraction given entities. This simplification requires the unsupervised text corpus to have entity annotations in text. Additionally, it is also reasonable to make the relation types in the knowledge graphs a closed set of, for example, 300 relations as in WebNLG (Gardent et al., 2017). In this way, the relation extraction model can avoid collapsing on unseen relations in the test set, and it is also an easier job for human annotators as they only need to consider a limited-sized, well-defined set of relations.\nWe summarize the requirements of the dataset collection as follows: • Basic Requirements\n1. Text and graphs should have similar contents, such as a Wikipedia article and a knowledge graph of the same article.\n3https://aclweb.org/aclwiki/Data_sets_for_NLG\n2. To fit for recent unsupervised models (Guo et al., 2020; Schmitt and Schütze, 2019), the text corpus should contain entity annotations.\n3. The knowledge graphs should have a closed set of relations. • Preferred Properties\n4. Large scale (over 500K). 5. Diversity, not limited to one specialized domain. 6. Human-annotated test set, as opposed to distant supervision test sets (Mintz et al., 2009; Riedel\net al., 2010), because noisy test sets can misguide the comparison of unsupervised models."
    }, {
      "heading" : "4 GenWiki Dataset",
      "text" : "Based on the desiderata outlined in Section 3, we will first introduce the construction process of our training set in Section 4.1, and test set in Section 4.2. We will then analyze the characteristics of the resulting dataset in Section 4.3."
    }, {
      "heading" : "4.1 Training Set Construction",
      "text" : "An ideal unsupervised graph-to-text dataset allows text sequences consisting of multiple sentences, and graphs of several triples. In the collection process of GenWiki, we allow each text sequence to have 1 to 10 sentences and at most 50 words, and graphs to have 1 to 10 triples. Our dataset aims to satisfy all the requirements mentioned in Section 3, namely (1) same content distribution between text and graph, (2) entity annotation in text, (3) a closed set of relations, (4) a large size, (5) diversity, and (6) a human-annotated test set. Specifically, our construction process is as follows.\nStep 1. Data Collection Our dataset, GenWiki, is collected from general Wikipedia. Different from other data that are limited to specific categories of Wikipedia (Gardent et al., 2017; Lebret et al., 2016; Wang et al., 2018), we aim at general-domain data-to-text generation. To this end, we collect text from the HTML webpages of all Wikipedia articles by April 2020, and use the titles of these articles to query their corresponding knowledge graphs from DBPedia.4 Note that we identify all hyperlinked terms in the HTML files as entities. We tokenize the text corpus using the NLTK package.5\nThe output of this step is Wikipedia articles with hyperlinked entities, and each article’s corresponding knowledge graph.\nStep 2. Filtering For all the articles retrieved from Wikipedia, we filter out empty pages, and pages containing placeholder contents such as “See the error message at the bottom of this page for more information.” To control the quality, we also look at the top 10 frequent sentences, and filter out highfrequency but unrelated sentences such as “Media related to ... at Wikimedia Commons.”\nFor the noisy graphs collected from Step 1, we only keep relations (namely edge types) that can be grounded to DBPedia relation ontology. We then filter out meta-relations such as “wikiPageRedirect,” and relations that are unlikely to be described in text such as “latitude” and “longitude.” After this filtering, due to the close-set relation constraint, we only keep the top 300 frequent relations, similar to the practice of (Gardent et al., 2017).\nAfter Step 2, the resulting dataset include 14,734,778 articles, and 3,009,112 graphs, with 19.45 triples per graph on average.\nStep 3. Entity Annotation To fit for the recent advances of unsupervised models based on cycle training, we take a challenging step to annotate the entities in text. From Step 1, terms with hyperlinks are annotated as entities. However, such annotation is very sparse, one per 14.50 words. The reason is that Wikipedia hyperlinks are manually added by human contributors, and not all occurrences of entities are linked. For example, there is no hyperlink in the sentence “In October 1871, Claude Monet returned to France.” despite the existence of three entities, “October 1871,” “Claude Monet,” and “France.”\n4http://dbpedia.org/isparql/ 5We use the NLTK package (http://nltk.org/) only for experimentation.\nTo increase the entity annotation in text, we develop a hybrid of methods based on the following intuitions:\n1. All entities in the graph should be annotated if they also occur in the corresponding article.\n2. The surface forms of graph entities (e.g., “President Obama” is a surface form of “Barack Obama”) should also be annotated if they appear in the corresponding article.\n3. Named entities, including dates, locations, organizations, and numbers, should be annotated.\n4. Personal pronouns (e.g., “he”, “she”) should also be annotated.\nTherefore, we first prepare a set of candidate entities for each sentence, including (1) entities in the knowledge graph corresponding to the Wikipedia article, (2) all surface forms of graph entities, (3) named entities annotated by the stanza package,6 and (4) personal pronouns except the versatile “it.” We annotate these entities whenever their occurrence in the text is detected. Note that there might be overlapping entities (e.g., “Obama” is a substring of “Barack Obama,” but both are entities), so we start from entities with the most number of words to entities with the fewest number of words.\nThe resulting density of annotated entities in text is one per 4.28 words.\nStep 4. Text-Graph Alignment Remember the first hard requirement (that text and graphs should have similar contents). We introduce an alignment step to ensure that this constraint can be approximated. This step is inspired by the assumption introduced in distant supervision for relation extraction (Mintz et al., 2009; Riedel et al., 2010): if the entity sets of a text sequence and a relation overlap, it is highly likely that the sentence express that relation.\nIn Step 4, for each article and its corresponding graph, we enumerate all text sequences (1-10 subsequent sentences with at most 50 words) and all small graphs (1-10 triples). For each text sequence, we only add it to the text corpus if its entity set can overlap with the entity set. Similarly, for each small graph, we add it to the graph dataset only if its entity set overlaps with the entity set of at lease one text sequence. In this way, we collect the text sequences and graphs with shared content, and form GenWikiFULL.\nIt is also good to curate a finer version of our dataset by imposing a higher threshold of entity overlap rate. Specifically, we construct GenWikiFINE which consists of text sequences that have an F1 score of over 40% and entity overlap of at least 2 with at least one graph, and graphs in the same way."
    }, {
      "heading" : "4.2 Test Set Annotation",
      "text" : "Apart from the unsupervised training set, we also collect a human-annotated test set of 1,000 text-graph pairs. To ensure the quality, we recruit annotators who have experience in data-to-text research. The annotators are introduced the background of the task, format of the data, and goals of annotation.\nAs the test set annotation is intensive and challenging, we design a workflow to minimize the annotators’ effort. Based on a randomly selected sample set from the training set, we automatically construct distantly aligned graph-text pairs, to serve as a reference for human annotators. Each distantly aligned pair are the text and graph which have a higher entity F1 with each other than with any other text or graph of the same Wikipedia article. The whole workflow is as follows:\n1. We construct distantly aligned pairs, and, as supplementary information, we show the annotator the entire knowledge graph (up to a hundred triples) of the source Wikipedia article of each pair. 2. We format each example in a reader-friendly way, by underlining all entities in text, and bold-facing overlapped entities between text and graphs. We also provide the corresponding Wikipedia article title, so that the annotator can look up the article if the annotation requires background knowledge. 3. Annotators first check if there is an easy way to edit the text and graph so that they express the same content.\n• If yes, then make minimal edits to align the text and graph\n6https://stanfordnlp.github.io/stanza/\n• If no, then split one sample into two cases, where the first case keeps the text as original and edits the graph to align with the text, and the second case keeps the graph as original and modifies the text.\n4. We use programs to check whether in each annotated sample, the text entities perfectly match with the graph entities. If not, we reject the sample, and return it to the annotators to redo Step 3."
    }, {
      "heading" : "4.3 Analysis",
      "text" : "Reflection on the Desiderata We compare our dataset with the two most similar previous datasets, WikiBio (Lebret et al., 2016) and WebNLG (Gardent et al., 2017). The properties evaluated in Table 2 correspond to the desiderata we outlined previously in Section 3. Unlisted properties imply that all three datasets have satisfied them. The diversity property is evaluated by both the domain and text type.\nAmong the three datasets, WikiBio, despite a large size, does not have entity annotations or a gold test set, so it cannot be used by many unsupervised models. On the other hand, WebNLG is a humanannotated supervised dataset, so it has high-quality entity annotation, and covers relatively diverse topics, 13 wiki categories sincluding athletes, buildings, and universities. However, due to the manual annotation, WebNLG cannot scale to higher orders of magnitudes such as millions of data that our dataset has.\nOur dataset, GenWiki, satisfies all criteria. Its text corpus has entity annotation, and GenWiki has a gold test. Due to the automatic collection process, it has a large number of data, and can easily scale to other domains in the future. It is also diverse in terms of categories of Wikipedia articles that every data sample is extracted from. The diversity can also be reflected through the text type, as crowdsourced sentences tend to be simpler and have less variations than the well-edited Wikipedia text. We will quantify characteristics of our dataset compared to WebNLG more in detail later in this section.\nDataset Overview For our two versions of datasets, GenWikiFINE and GenWikiFULL, we summarize the overall statistics of our GenWiki dataset in Table 3. We compare it with WebNLG, which also meets all three basic requirements, and has been used for previous unsupervised models (Guo et al., 2020; Schmitt and Schütze, 2019).\nWe can see from Table 3 that our dataset has significantly more data than the human-annotated WebNLG, and can be a better dataset for unsupervised learning. Our GenWikiFINE contains 757K examples with about 20M tokens, and GenWikiFULL contains 1.3M samples with about 30M tokens. The number of examples of our GenWikiFINE is 58 times the size of WebNLG, and GenWikiFULL is 102 times the size of WebNLG. Similar to the overall size, the number of entities, triples, tokens, and vocabulary size of our dataset are also several orders of magnitudes higher than that of WebNLG. On average, each graph of GenWikiFINE has 2.64 triples and each text 26.05 words; GenWikiFULL has 1.94 triples per graph, and 21.46 words per text sequence. The smaller average size of GenWikiFULL than GenWikiFINE\nmight be due to the lower entity overlap threshold when collecting data for GenWikiFULL, which allows for more small graphs, and short text sequences.\nDiversity of Topics We plot the most frequent topics and their counts in Figure 2a, and show some examples of three representative categories in Figure 2b. To make Figure 2a more illustrative, we omit the top-1 frequent category, biography, which has 339K Wikipedia articles, and plot the next 20 categories which are more on the same scale.\nFigure 2a shows that the dataset includes a variety of topic categories such as sports and games (77K), politics and government (30K), and arts and entertainment (29K). It also include many places, ranging from United States (50K), to India (40K), and France (34K). It also has nature-related articles, such as the order of insects Lepidoptera (46K), insects (28K), and geography (27K). Interestingly, there is a considerable number of articles related to women (39K).\nFigure 2b shows some typical examples in three categories, sports and games, United States, and women. Bold terms in the text box are automatically annotated entities. Note that in the dataset, each topic has some related graphs and text. Although not strictly aligned, the graphs and text have an overall similar content distribution.\nDistribution of Relation Types Relation types is an important feature as it indicates the diversity of knowledge graphs, and correlates with the diversity of text generation. As we can see from Figure 3, there are a variety of relations, from the biography-related ones such as birthPlace, birthYear, and deathPlace, to general relations such as country, family, activeYearsStart, populationTotal, isPartOf, and so on. The distribution of relations are long-tailed, as some least frequent relations, although not plotted, have only 10 to 20 occurrences.\nRichness of Text and Graphs We evaluate the lexical richness and graph characteristics in Table 4. We first show the lexical diversity by type-token ratio (TTR), on which WebNLG scores 0.007, compared to 0.016 and 0.017 of the two GenWiki datasets. As TTR is sensitive to sample size, we also show the mean segmental type-token ratio (MSTTR) (Johnson, 1944). MSTTR is the average TTR for successive segments of text or transcript that contain a standard number of tokens. We calculate the MSTTR for successive every 50 words in the text corpus of each dataset. WebNLG’s MSTTR is lower than that of GenWik by a large margin. We also evaluate the entity density (the number entity words divided by the number of all words), where we can see that all three datasets have a similar entity density of around 23% or 27%. Complementary to the entity density, we also define the concept of information density, which refers to the number of words divided by the number of triples, because text and graphs share the same\ncontent. Apart from characteristics of text richness, we also look into the graph richness, and calculate the percentage of graphs with more than two triples in Table 4."
    }, {
      "heading" : "5 Evaluating Unsupervised Data-to-Text Models",
      "text" : ""
    }, {
      "heading" : "5.1 Models",
      "text" : "Based on our datasets, we evaluate the following unsupervised baselines.\nRule-Based As a baseline proposed by (Schmitt and Schütze, 2019), Rule-Based linearizes the graph into a sequence of triples. Each triple is described by turning the camel-cased relation type to a normal phrase. For example, the triple “(New York City, populationTotal, 8 million)” will be verbalized as “New York City population total 8 million.” The descriptions of multiple triples are joined by “and.”\nDirectTransfer DirectTransfer is another intuitive baseline, where we use a model trained on the supervised WebNLG dataset, and test it on the GenWiki test set. For a fair comparison, we use a graph transformer generation model proposed by (Koncel-Kedziorski et al., 2019) for all graph-to-text models.\nNoisySupervised We also propose another baseline, NoisySupervised, which attempts to absorb the weak supervision signals in the training set, and convert the difficult unsupervised learning problem into supervised learning. Specifically, NoisySupervised first constructs distantly aligned pairs on the whole training data, using the same matching method that we adopted to create our preliminary test set before human annotation. It then takes these pairs with noises as supervision signals, and learn from them using the graph transformer (Koncel-Kedziorski et al., 2019).\nCycleGTBase (Guo et al., 2020) proposes two models, the first of which uses a basic setting, iterative back translation with no pretraining. The CycleGT model jointly learns from two losses, a graph-to-text generation loss, and text-to-graph relation classification loss. Such a cycle training setting, despite its simplicity, was proved comparable performance with supervised models on the WebNLG dataset.\nCycleGTWarm The second setting proposed in (Guo et al., 2020) uses a warm up strategy before the cycle training process. Specifically, as entities are given by the dataset and serve as shared information between text and graphs, the CycleGT model warms up by learning entity-to-text generation and entityto-graph relation classification. This warm up strategy is used to make the unsupervised training more stable."
    }, {
      "heading" : "5.2 Evaluation Metrics",
      "text" : "We evaluate the text generation quality by four commonly used metrics: BLEU (Papineni et al., 2002), Meteor (Banerjee and Lavie, 2005), ROUGEL (Lin, 2004) and CIDEr (Vedantam et al., 2015), to measure the closeness of the reconstructed paragraph (model output) to the input paragraph.7"
    }, {
      "heading" : "5.3 Implementation Details",
      "text" : "For CycleGTBase. and CycleGTWarm, we use the same code provided by (Guo et al., 2020). For DirectTransfer and NoisySupervised, we use the graph transformer model (Koncel-Kedziorski et al., 2019) reimplemented by (Guo et al., 2020) using the Deep Graph Library (DGL) (Wang et al., 2019). For a fair comparison, we use the same hyperparameters for the overlapped components of NoisySupervised, CycleGTBase, and CycleGTWarm.\n6 Results\nThe main experiment results are listed in Table 6. From the text generation quality of the five models, we can see that the Rule-Based baseline (Schmitt and Schütze, 2019) performs poorly on our GenWiki dataset. The DirectTransfer also has a similar performance as Rule-Based, which implies that even WebNLG and GenWiki are similar wiki-based datasets, it is difficult to make a model trained on one corpus to do well on the other slightly different one. The NoisySupervised model performs relatively well, scoring 30.30 BLEU points. As it relies on the quality of distant supervision on our non-parallel training set, the good performance of the NoisySupervised model validates that the GenWiki dataset has a good alignment of text and graphs. The two models proposed by (Guo et al., 2020), CycleGTBase and CycleGTWarm is the strongest out of all unsupervised models, outperforming NoisySupervised by 10 BLEU points. The two models achieve similar performance with each other, with CycleGTWarm slightly better on BLEU, and CycleGTBase higher on the other three metrics."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this paper, we constructed a large-scale, general-domain text generation dataset, GenWiki. This work is designed for the emerging research on unsupervised models for text generation. Our dataset is several magnitudes larger than previous text generation datasets, covers a diverse range of topics, and contains more complicated linguistic structures. It relieves the unsupervised models of the limited sizes of previous datasets, and lays the foundation for more future research on unsupervised text generation models."
    } ],
    "references" : [ {
      "title" : "A simple domain-independent probabilistic approach to generation",
      "author" : [ "Gabor Angeli", "Percy Liang", "Dan Klein." ],
      "venue" : "Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP 2010, 9-11 October 2010, MIT Stata Center, Massachusetts, USA, A meeting of SIGDAT, a Special Interest Group of the ACL, pages 502–512. ACL.",
      "citeRegEx" : "Angeli et al\\.,? 2010",
      "shortCiteRegEx" : "Angeli et al\\.",
      "year" : 2010
    }, {
      "title" : "An effective approach to unsupervised machine translation",
      "author" : [ "Mikel Artetxe", "Gorka Labaka", "Eneko Agirre." ],
      "venue" : "Anna Korhonen, David R. Traum, and Lluı́s Màrquez, editors, Proceedings of the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers, pages 194–203. Association for Computational Linguistics. 7We calculate all metrics using the pycocoevalcap tool (https://github.com/salaniz/pycocoevalcap).",
      "citeRegEx" : "Artetxe et al\\.,? 2019",
      "shortCiteRegEx" : "Artetxe et al\\.",
      "year" : 2019
    }, {
      "title" : "METEOR: an automatic metric for MT evaluation with improved correlation with human judgments",
      "author" : [ "Satanjeev Banerjee", "Alon Lavie." ],
      "venue" : "Jade Goldstein, Alon Lavie, Chin-Yew Lin, and Clare R. Voss, editors, Proceedings of the Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization@ACL 2005, Ann Arbor, Michigan, USA, June 29, 2005, pages 65–72. Association for Computational Linguistics.",
      "citeRegEx" : "Banerjee and Lavie.,? 2005",
      "shortCiteRegEx" : "Banerjee and Lavie.",
      "year" : 2005
    }, {
      "title" : "The kbgen challenge",
      "author" : [ "Eva Banik", "Claire Gardent", "Eric Kow." ],
      "venue" : "Albert Gatt and Horacio Saggion, editors, ENLG 2013 - Proceedings of the 14th European Workshop on Natural Language Generation, August 8-9, 2013, Sofia, Bulgaria, pages 94–97. The Association for Computer Linguistics.",
      "citeRegEx" : "Banik et al\\.,? 2013",
      "shortCiteRegEx" : "Banik et al\\.",
      "year" : 2013
    }, {
      "title" : "Learning to sportscast: a test of grounded language acquisition",
      "author" : [ "David L. Chen", "Raymond J. Mooney." ],
      "venue" : "William W. Cohen, Andrew McCallum, and Sam T. Roweis, editors, Machine Learning, Proceedings of the Twenty-Fifth International Conference (ICML 2008), Helsinki, Finland, June 5-9, 2008, volume 307 of ACM International Conference Proceeding Series, pages 128–135. ACM.",
      "citeRegEx" : "Chen and Mooney.,? 2008",
      "shortCiteRegEx" : "Chen and Mooney.",
      "year" : 2008
    }, {
      "title" : "BERT: pre-training of deep bidirectional transformers for language understanding",
      "author" : [ "Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova." ],
      "venue" : "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 4171–4186.",
      "citeRegEx" : "Devlin et al\\.,? 2019",
      "shortCiteRegEx" : "Devlin et al\\.",
      "year" : 2019
    }, {
      "title" : "Unsupervised natural language generation with denoising autoencoders",
      "author" : [ "Markus Freitag", "Scott Roy." ],
      "venue" : "Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun’ichi Tsujii, editors, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, Brussels, Belgium, October 31 - November 4, 2018, pages 3922–3929. Association for Computational Linguistics.",
      "citeRegEx" : "Freitag and Roy.,? 2018",
      "shortCiteRegEx" : "Freitag and Roy.",
      "year" : 2018
    }, {
      "title" : "The webnlg challenge: Generating text from RDF data",
      "author" : [ "Claire Gardent", "Anastasia Shimorina", "Shashi Narayan", "Laura Perez-Beltrachini." ],
      "venue" : "José M. Alonso, Alberto Bugarı́n, and Ehud Reiter, editors, Proceedings of the 10th International Conference on Natural Language Generation, INLG 2017, Santiago de Compostela, Spain, September 4-7, 2017, pages 124–133. Association for Computational Linguistics.",
      "citeRegEx" : "Gardent et al\\.,? 2017",
      "shortCiteRegEx" : "Gardent et al\\.",
      "year" : 2017
    }, {
      "title" : "Cyclegt: Unsupervised graph-to-text and text-to-graph generation via cycle training",
      "author" : [ "Qipeng Guo", "Zhijing Jin", "Xipeng Qiu", "Weinan Zhang", "David Wipf", "Zheng Zhang." ],
      "venue" : "CoRR, abs/2006.04702.",
      "citeRegEx" : "Guo et al\\.,? 2020",
      "shortCiteRegEx" : "Guo et al\\.",
      "year" : 2020
    }, {
      "title" : "Text generation - using discourse strategies and focus constraints to generate natural language text by kathleen r",
      "author" : [ "Paul Holmes-Higgin." ],
      "venue" : "mckeown, cambridge university press, 1992, pp 246, £13.95, ISBN 0-521-43802-0. Knowledge Eng. Review, 9(4):421–422.",
      "citeRegEx" : "Holmes.Higgin.,? 1994",
      "shortCiteRegEx" : "Holmes.Higgin.",
      "year" : 1994
    }, {
      "title" : "Domain adaptable semantic clustering in statistical NLG",
      "author" : [ "Blake Howald", "Ravikumar Kondadadi", "Frank Schilder." ],
      "venue" : "Katrin Erk and Alexander Koller, editors, Proceedings of the 10th International Conference on Computational Semantics, IWCS 2013, March 19-22, 2013, University of Potsdam, Potsdam, Germany, pages 143–154. The Association for Computer Linguistics.",
      "citeRegEx" : "Howald et al\\.,? 2013",
      "shortCiteRegEx" : "Howald et al\\.",
      "year" : 2013
    }, {
      "title" : "Studies in language behavior: A program of research",
      "author" : [ "Wendell Johnson." ],
      "venue" : "Psychological Monographs, 56(2):1–15.",
      "citeRegEx" : "Johnson.,? 1944",
      "shortCiteRegEx" : "Johnson.",
      "year" : 1944
    }, {
      "title" : "Text generation from knowledge graphs with graph transformers",
      "author" : [ "Rik Koncel-Kedziorski", "Dhanush Bekal", "Yi Luan", "Mirella Lapata", "Hannaneh Hajishirzi." ],
      "venue" : "Jill Burstein, Christy Doran, and Thamar Solorio, editors, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), pages 2284–2293. Association for Computational Linguistics.",
      "citeRegEx" : "Koncel.Kedziorski et al\\.,? 2019",
      "shortCiteRegEx" : "Koncel.Kedziorski et al\\.",
      "year" : 2019
    }, {
      "title" : "Unsupervised concept-to-text generation with hypergraphs",
      "author" : [ "Ioannis Konstas", "Mirella Lapata." ],
      "venue" : "Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings, June 3-8, 2012, Montréal, Canada, pages 752–761. The Association for Computational Linguistics.",
      "citeRegEx" : "Konstas and Lapata.,? 2012",
      "shortCiteRegEx" : "Konstas and Lapata.",
      "year" : 2012
    }, {
      "title" : "Design of a knowledge-based report generator",
      "author" : [ "Karen Kukich." ],
      "venue" : "Mitchell P. Marcus, editor, 21st Annual Meeting of the Association for Computational Linguistics, Massachusetts Institute of Technology, Cambridge, Massachusetts, USA, June 15-17, 1983, pages 145–150. ACL.",
      "citeRegEx" : "Kukich.,? 1983",
      "shortCiteRegEx" : "Kukich.",
      "year" : 1983
    }, {
      "title" : "Neural text generation from structured data with application to the biography domain",
      "author" : [ "Rémi Lebret", "David Grangier", "Michael Auli." ],
      "venue" : "Jian Su, Xavier Carreras, and Kevin Duh, editors, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, EMNLP 2016, Austin, Texas, USA, November 1-4, 2016, pages 1203–1213. The Association for Computational Linguistics.",
      "citeRegEx" : "Lebret et al\\.,? 2016",
      "shortCiteRegEx" : "Lebret et al\\.",
      "year" : 2016
    }, {
      "title" : "Learning semantic correspondences with less supervision",
      "author" : [ "Percy Liang", "Michael I. Jordan", "Dan Klein." ],
      "venue" : "Keh-Yih Su, Jian Su, and Janyce Wiebe, editors, ACL 2009, Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the AFNLP, 2-7 August 2009, Singapore, pages 91–99. The Association for Computer Linguistics.",
      "citeRegEx" : "Liang et al\\.,? 2009",
      "shortCiteRegEx" : "Liang et al\\.",
      "year" : 2009
    }, {
      "title" : "ROUGE: A package for automatic evaluation of summaries",
      "author" : [ "Chin-Yew Lin." ],
      "venue" : "Text Summarization Branches Out, pages 74–81, Barcelona, Spain, July. Association for Computational Linguistics.",
      "citeRegEx" : "Lin.,? 2004",
      "shortCiteRegEx" : "Lin.",
      "year" : 2004
    }, {
      "title" : "Yag: A template-based generator for real-time systems",
      "author" : [ "Susan W McRoy", "Songsak Channarukul", "Syed S Ali." ],
      "venue" : "INLG’2000 Proceedings of the First International Conference on Natural Language Generation, pages 264–267.",
      "citeRegEx" : "McRoy et al\\.,? 2000",
      "shortCiteRegEx" : "McRoy et al\\.",
      "year" : 2000
    }, {
      "title" : "Distant supervision for relation extraction without labeled data",
      "author" : [ "Mike Mintz", "Steven Bills", "Rion Snow", "Daniel Jurafsky." ],
      "venue" : "Keh-Yih Su, Jian Su, and Janyce Wiebe, editors, ACL 2009, Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the AFNLP, 2-7 August 2009, Singapore, pages 1003–1011. The Association for Computer Linguistics.",
      "citeRegEx" : "Mintz et al\\.,? 2009",
      "shortCiteRegEx" : "Mintz et al\\.",
      "year" : 2009
    }, {
      "title" : "The E2E dataset: New challenges for end-to-end generation",
      "author" : [ "Jekaterina Novikova", "Ondrej Dusek", "Verena Rieser." ],
      "venue" : "Kristiina Jokinen, Manfred Stede, David DeVault, and Annie Louis, editors, Proceedings of the 18th Annual SIGdial Meeting on Discourse and Dialogue, Saarbrücken, Germany, August 15-17, 2017, pages 201–206. Association for Computational Linguistics.",
      "citeRegEx" : "Novikova et al\\.,? 2017",
      "shortCiteRegEx" : "Novikova et al\\.",
      "year" : 2017
    }, {
      "title" : "Bleu: a method for automatic evaluation of machine translation",
      "author" : [ "Kishore Papineni", "Salim Roukos", "Todd Ward", "Wei-Jing Zhu." ],
      "venue" : "Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, July 6-12, 2002, Philadelphia, PA, USA, pages 311–318. ACL.",
      "citeRegEx" : "Papineni et al\\.,? 2002",
      "shortCiteRegEx" : "Papineni et al\\.",
      "year" : 2002
    }, {
      "title" : "Totto: A controlled table-to-text generation dataset",
      "author" : [ "Ankur P. Parikh", "Xuezhi Wang", "Sebastian Gehrmann", "Manaal Faruqui", "Bhuwan Dhingra", "Diyi Yang", "Dipanjan Das." ],
      "venue" : "CoRR, abs/2004.14373.",
      "citeRegEx" : "Parikh et al\\.,? 2020",
      "shortCiteRegEx" : "Parikh et al\\.",
      "year" : 2020
    }, {
      "title" : "Generation of company descriptions using concept-to-text and text-to-text deep models: dataset collection and systems evaluation",
      "author" : [ "Raheel Qader", "Khoder Jneid", "François Portet", "Cyril Labbé." ],
      "venue" : "Proceedings of the 11th International Conference on Natural Language Generation, pages 254–263. Association for Computational Linguistics.",
      "citeRegEx" : "Qader et al\\.,? 2018",
      "shortCiteRegEx" : "Qader et al\\.",
      "year" : 2018
    }, {
      "title" : "Modeling relations and their mentions without labeled text",
      "author" : [ "Sebastian Riedel", "Limin Yao", "Andrew McCallum." ],
      "venue" : "José L. Balcázar, Francesco Bonchi, Aristides Gionis, and Michèle Sebag, editors, Machine Learning and Knowledge Discovery in Databases, European Conference, ECML PKDD 2010, Barcelona, Spain, September 20-24, 2010, Proceedings, Part III, volume 6323 of Lecture Notes in Computer Science, pages 148–163. Springer.",
      "citeRegEx" : "Riedel et al\\.,? 2010",
      "shortCiteRegEx" : "Riedel et al\\.",
      "year" : 2010
    }, {
      "title" : "Unsupervised text generation from structured data",
      "author" : [ "Martin Schmitt", "Hinrich Schütze." ],
      "venue" : "CoRR, abs/1904.09447.",
      "citeRegEx" : "Schmitt and Schütze.,? 2019",
      "shortCiteRegEx" : "Schmitt and Schütze.",
      "year" : 2019
    }, {
      "title" : "Cider: Consensus-based image description evaluation",
      "author" : [ "Ramakrishna Vedantam", "C. Lawrence Zitnick", "Devi Parikh." ],
      "venue" : "IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, Boston, MA, USA, June 7-12, 2015, pages 4566–4575. IEEE Computer Society.",
      "citeRegEx" : "Vedantam et al\\.,? 2015",
      "shortCiteRegEx" : "Vedantam et al\\.",
      "year" : 2015
    }, {
      "title" : "Describing a knowledge base",
      "author" : [ "Qingyun Wang", "Xiaoman Pan", "Lifu Huang", "Boliang Zhang", "Zhiying Jiang", "Heng Ji", "Kevin Knight." ],
      "venue" : "Emiel Krahmer, Albert Gatt, and Martijn Goudbeek, editors, Proceedings of the 11th International Conference on Natural Language Generation, Tilburg University, The Netherlands, November 5-8, 2018, pages 10–21. Association for Computational Linguistics.",
      "citeRegEx" : "Wang et al\\.,? 2018",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2018
    }, {
      "title" : "Deep graph library: Towards efficient and scalable deep learning on graphs",
      "author" : [ "Minjie Wang", "Lingfan Yu", "Da Zheng", "Quan Gan", "Yu Gai", "Zihao Ye", "Mufei Li", "Jinjing Zhou", "Qi Huang", "Chao Ma", "Ziyue Huang", "Qipeng Guo", "Hao Zhang", "Haibin Lin", "Junbo Zhao", "Jinyang Li", "Alexander J. Smola", "Zheng Zhang." ],
      "venue" : "CoRR, abs/1909.01315.",
      "citeRegEx" : "Wang et al\\.,? 2019",
      "shortCiteRegEx" : "Wang et al\\.",
      "year" : 2019
    }, {
      "title" : "Semantically conditioned lstm-based natural language generation for spoken dialogue systems",
      "author" : [ "Tsung-Hsien Wen", "Milica Gasic", "Nikola Mrksic", "Pei-hao Su", "David Vandyke", "Steve J. Young." ],
      "venue" : "Lluı́s Màrquez, Chris Callison-Burch, Jian Su, Daniele Pighin, and Yuval Marton, editors, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, EMNLP 2015, Lisbon, Portugal, September 17-21, 2015, pages 1711–1721. The Association for Computational Linguistics.",
      "citeRegEx" : "Wen et al\\.,? 2015",
      "shortCiteRegEx" : "Wen et al\\.",
      "year" : 2015
    }, {
      "title" : "Challenges in data-to-document generation",
      "author" : [ "Sam Wiseman", "Stuart M. Shieber", "Alexander M. Rush." ],
      "venue" : "Martha Palmer, Rebecca Hwa, and Sebastian Riedel, editors, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017, pages 2253–2263. Association for Computational Linguistics.",
      "citeRegEx" : "Wiseman et al\\.,? 2017",
      "shortCiteRegEx" : "Wiseman et al\\.",
      "year" : 2017
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "To overcome the lack of labelled data and difficulty in domain adaptation, unsupervised data-to-text generation has emerged as an active research field recently (Freitag and Roy, 2018; Schmitt and Schütze, 2019; Guo et al., 2020).",
      "startOffset" : 161,
      "endOffset" : 229
    }, {
      "referenceID" : 25,
      "context" : "To overcome the lack of labelled data and difficulty in domain adaptation, unsupervised data-to-text generation has emerged as an active research field recently (Freitag and Roy, 2018; Schmitt and Schütze, 2019; Guo et al., 2020).",
      "startOffset" : 161,
      "endOffset" : 229
    }, {
      "referenceID" : 8,
      "context" : "To overcome the lack of labelled data and difficulty in domain adaptation, unsupervised data-to-text generation has emerged as an active research field recently (Freitag and Roy, 2018; Schmitt and Schütze, 2019; Guo et al., 2020).",
      "startOffset" : 161,
      "endOffset" : 229
    }, {
      "referenceID" : 3,
      "context" : "Dataset Size Purpose Collection Domain KBGen (Banik et al., 2013) 0.",
      "startOffset" : 45,
      "endOffset" : 65
    }, {
      "referenceID" : 4,
      "context" : "2K Supervised Human Descriptions of biology knowledge bases RoboCup (Chen and Mooney, 2008) 0.",
      "startOffset" : 68,
      "endOffset" : 91
    }, {
      "referenceID" : 30,
      "context" : "7K Supervised Human Sportscast RotoWire (Wiseman et al., 2017) 5K Supervised Human Baseketball game summaries SF Hotels/Restaurants (Wen et al.",
      "startOffset" : 40,
      "endOffset" : 62
    }, {
      "referenceID" : 29,
      "context" : ", 2017) 5K Supervised Human Baseketball game summaries SF Hotels/Restaurants (Wen et al., 2015) 10K Supervised Human Dialogues about restaurants and hotels WebNLG (Gardent et al.",
      "startOffset" : 77,
      "endOffset" : 95
    }, {
      "referenceID" : 7,
      "context" : ", 2015) 10K Supervised Human Dialogues about restaurants and hotels WebNLG (Gardent et al., 2017) 13K Supervised Human 13 categories (building, person) WeatherGov (Liang et al.",
      "startOffset" : 75,
      "endOffset" : 97
    }, {
      "referenceID" : 16,
      "context" : ", 2017) 13K Supervised Human 13 categories (building, person) WeatherGov (Liang et al., 2009) 22K Supervised Human Weather forecasts E2E (Novikova et al.",
      "startOffset" : 73,
      "endOffset" : 93
    }, {
      "referenceID" : 20,
      "context" : ", 2009) 22K Supervised Human Weather forecasts E2E (Novikova et al., 2017) 50K Supervised Human Restaurant and hotel descriptions WikiCompany (Qader et al.",
      "startOffset" : 51,
      "endOffset" : 74
    }, {
      "referenceID" : 23,
      "context" : ", 2017) 50K Supervised Human Restaurant and hotel descriptions WikiCompany (Qader et al., 2018) 51K Supervised Human Company descriptions ToTTO (Parikh et al.",
      "startOffset" : 75,
      "endOffset" : 95
    }, {
      "referenceID" : 22,
      "context" : ", 2018) 51K Supervised Human Company descriptions ToTTO (Parikh et al., 2020) 100K Supervised Human Description of Wikipedia tables WikiBio (Lebret et al.",
      "startOffset" : 56,
      "endOffset" : 77
    }, {
      "referenceID" : 15,
      "context" : ", 2020) 100K Supervised Human Description of Wikipedia tables WikiBio (Lebret et al., 2016) 500K(2) Supervised Auto First sentence of Wikipedia biographies GenWikiFINE 750K Unsupervised Auto&distant align General domain (all wiki topics) GenWikiFULL 1.",
      "startOffset" : 70,
      "endOffset" : 91
    }, {
      "referenceID" : 14,
      "context" : "For example, in data-to-text generation, the traditional approach is to hand-craft templates (Kukich, 1983; Holmes-Higgin, 1994; McRoy et al., 2000).",
      "startOffset" : 93,
      "endOffset" : 148
    }, {
      "referenceID" : 9,
      "context" : "For example, in data-to-text generation, the traditional approach is to hand-craft templates (Kukich, 1983; Holmes-Higgin, 1994; McRoy et al., 2000).",
      "startOffset" : 93,
      "endOffset" : 148
    }, {
      "referenceID" : 18,
      "context" : "For example, in data-to-text generation, the traditional approach is to hand-craft templates (Kukich, 1983; Holmes-Higgin, 1994; McRoy et al., 2000).",
      "startOffset" : 93,
      "endOffset" : 148
    }, {
      "referenceID" : 7,
      "context" : "3 For instance, WebNLG dataset (Gardent et al., 2017) has 13K valid data-text pairs, WeatherGov (Liang et al.",
      "startOffset" : 31,
      "endOffset" : 53
    }, {
      "referenceID" : 16,
      "context" : ", 2017) has 13K valid data-text pairs, WeatherGov (Liang et al., 2009) has 22K weather forecasts, and E2E (Novikova et al.",
      "startOffset" : 50,
      "endOffset" : 70
    }, {
      "referenceID" : 20,
      "context" : ", 2009) has 22K weather forecasts, and E2E (Novikova et al., 2017) has 50K restaurant and hotel descriptions, as shown in Table 2.",
      "startOffset" : 43,
      "endOffset" : 66
    }, {
      "referenceID" : 6,
      "context" : "Recently, there is a rising trend of unsupervised approaches (Freitag and Roy, 2018; Schmitt and Schütze, 2019; Guo et al., 2020).",
      "startOffset" : 61,
      "endOffset" : 129
    }, {
      "referenceID" : 25,
      "context" : "Recently, there is a rising trend of unsupervised approaches (Freitag and Roy, 2018; Schmitt and Schütze, 2019; Guo et al., 2020).",
      "startOffset" : 61,
      "endOffset" : 129
    }, {
      "referenceID" : 8,
      "context" : "Recently, there is a rising trend of unsupervised approaches (Freitag and Roy, 2018; Schmitt and Schütze, 2019; Guo et al., 2020).",
      "startOffset" : 61,
      "endOffset" : 129
    }, {
      "referenceID" : 13,
      "context" : "Unsupervised data-to-text models (Konstas and Lapata, 2012) are proposed in response to the lack of data-text pairs in many domains, similar to the emergence of unsupervised machine translation that addresses lack of data low-resource language pairs.",
      "startOffset" : 33,
      "endOffset" : 59
    }, {
      "referenceID" : 1,
      "context" : "1B English tokens are fed to unsupervised machine translation models (Artetxe et al., 2019); 3.",
      "startOffset" : 69,
      "endOffset" : 91
    }, {
      "referenceID" : 5,
      "context" : "3 billion words are used to pretrain the language model BERT (Devlin et al., 2019).",
      "startOffset" : 61,
      "endOffset" : 82
    }, {
      "referenceID" : 13,
      "context" : "(2) Lack of diversity: As many unsupervised models need to impose strong priors such as grammar and dependency tree (Konstas and Lapata, 2012), if a proposed model works well on a specific type of text generation, we cannot validate whether such a model generalizes well.",
      "startOffset" : 116,
      "endOffset" : 142
    }, {
      "referenceID" : 8,
      "context" : "The reason is that recent unsupervised learning models (Guo et al., 2020; Schmitt and Schütze, 2019) use cycle training of two tasks: graph-to-text, and text-to-graph, which is simplified to relation extraction given entities.",
      "startOffset" : 55,
      "endOffset" : 100
    }, {
      "referenceID" : 25,
      "context" : "The reason is that recent unsupervised learning models (Guo et al., 2020; Schmitt and Schütze, 2019) use cycle training of two tasks: graph-to-text, and text-to-graph, which is simplified to relation extraction given entities.",
      "startOffset" : 55,
      "endOffset" : 100
    }, {
      "referenceID" : 7,
      "context" : "Additionally, it is also reasonable to make the relation types in the knowledge graphs a closed set of, for example, 300 relations as in WebNLG (Gardent et al., 2017).",
      "startOffset" : 144,
      "endOffset" : 166
    }, {
      "referenceID" : 8,
      "context" : "To fit for recent unsupervised models (Guo et al., 2020; Schmitt and Schütze, 2019), the text corpus should contain entity annotations.",
      "startOffset" : 38,
      "endOffset" : 83
    }, {
      "referenceID" : 25,
      "context" : "To fit for recent unsupervised models (Guo et al., 2020; Schmitt and Schütze, 2019), the text corpus should contain entity annotations.",
      "startOffset" : 38,
      "endOffset" : 83
    }, {
      "referenceID" : 19,
      "context" : "Human-annotated test set, as opposed to distant supervision test sets (Mintz et al., 2009; Riedel et al., 2010), because noisy test sets can misguide the comparison of unsupervised models.",
      "startOffset" : 70,
      "endOffset" : 111
    }, {
      "referenceID" : 24,
      "context" : "Human-annotated test set, as opposed to distant supervision test sets (Mintz et al., 2009; Riedel et al., 2010), because noisy test sets can misguide the comparison of unsupervised models.",
      "startOffset" : 70,
      "endOffset" : 111
    }, {
      "referenceID" : 7,
      "context" : "Different from other data that are limited to specific categories of Wikipedia (Gardent et al., 2017; Lebret et al., 2016; Wang et al., 2018), we aim at general-domain data-to-text generation.",
      "startOffset" : 79,
      "endOffset" : 141
    }, {
      "referenceID" : 15,
      "context" : "Different from other data that are limited to specific categories of Wikipedia (Gardent et al., 2017; Lebret et al., 2016; Wang et al., 2018), we aim at general-domain data-to-text generation.",
      "startOffset" : 79,
      "endOffset" : 141
    }, {
      "referenceID" : 27,
      "context" : "Different from other data that are limited to specific categories of Wikipedia (Gardent et al., 2017; Lebret et al., 2016; Wang et al., 2018), we aim at general-domain data-to-text generation.",
      "startOffset" : 79,
      "endOffset" : 141
    }, {
      "referenceID" : 7,
      "context" : "” After this filtering, due to the close-set relation constraint, we only keep the top 300 frequent relations, similar to the practice of (Gardent et al., 2017).",
      "startOffset" : 138,
      "endOffset" : 160
    }, {
      "referenceID" : 19,
      "context" : "This step is inspired by the assumption introduced in distant supervision for relation extraction (Mintz et al., 2009; Riedel et al., 2010): if the entity sets of a text sequence and a relation overlap, it is highly likely that the sentence express that relation.",
      "startOffset" : 98,
      "endOffset" : 139
    }, {
      "referenceID" : 24,
      "context" : "This step is inspired by the assumption introduced in distant supervision for relation extraction (Mintz et al., 2009; Riedel et al., 2010): if the entity sets of a text sequence and a relation overlap, it is highly likely that the sentence express that relation.",
      "startOffset" : 98,
      "endOffset" : 139
    }, {
      "referenceID" : 15,
      "context" : "3 Analysis Reflection on the Desiderata We compare our dataset with the two most similar previous datasets, WikiBio (Lebret et al., 2016) and WebNLG (Gardent et al.",
      "startOffset" : 116,
      "endOffset" : 137
    }, {
      "referenceID" : 8,
      "context" : "We compare it with WebNLG, which also meets all three basic requirements, and has been used for previous unsupervised models (Guo et al., 2020; Schmitt and Schütze, 2019).",
      "startOffset" : 125,
      "endOffset" : 170
    }, {
      "referenceID" : 25,
      "context" : "We compare it with WebNLG, which also meets all three basic requirements, and has been used for previous unsupervised models (Guo et al., 2020; Schmitt and Schütze, 2019).",
      "startOffset" : 125,
      "endOffset" : 170
    }, {
      "referenceID" : 11,
      "context" : "As TTR is sensitive to sample size, we also show the mean segmental type-token ratio (MSTTR) (Johnson, 1944).",
      "startOffset" : 93,
      "endOffset" : 108
    }, {
      "referenceID" : 25,
      "context" : "Rule-Based As a baseline proposed by (Schmitt and Schütze, 2019), Rule-Based linearizes the graph into a sequence of triples.",
      "startOffset" : 37,
      "endOffset" : 64
    }, {
      "referenceID" : 12,
      "context" : "For a fair comparison, we use a graph transformer generation model proposed by (Koncel-Kedziorski et al., 2019) for all graph-to-text models.",
      "startOffset" : 79,
      "endOffset" : 111
    }, {
      "referenceID" : 12,
      "context" : "It then takes these pairs with noises as supervision signals, and learn from them using the graph transformer (Koncel-Kedziorski et al., 2019).",
      "startOffset" : 110,
      "endOffset" : 142
    }, {
      "referenceID" : 8,
      "context" : "CycleGTBase (Guo et al., 2020) proposes two models, the first of which uses a basic setting, iterative back translation with no pretraining.",
      "startOffset" : 12,
      "endOffset" : 30
    }, {
      "referenceID" : 8,
      "context" : "CycleGTWarm The second setting proposed in (Guo et al., 2020) uses a warm up strategy before the cycle training process.",
      "startOffset" : 43,
      "endOffset" : 61
    }, {
      "referenceID" : 21,
      "context" : "2 Evaluation Metrics We evaluate the text generation quality by four commonly used metrics: BLEU (Papineni et al., 2002), Meteor (Banerjee and Lavie, 2005), ROUGEL (Lin, 2004) and CIDEr (Vedantam et al.",
      "startOffset" : 97,
      "endOffset" : 120
    }, {
      "referenceID" : 2,
      "context" : ", 2002), Meteor (Banerjee and Lavie, 2005), ROUGEL (Lin, 2004) and CIDEr (Vedantam et al.",
      "startOffset" : 16,
      "endOffset" : 42
    }, {
      "referenceID" : 17,
      "context" : ", 2002), Meteor (Banerjee and Lavie, 2005), ROUGEL (Lin, 2004) and CIDEr (Vedantam et al.",
      "startOffset" : 51,
      "endOffset" : 62
    }, {
      "referenceID" : 26,
      "context" : ", 2002), Meteor (Banerjee and Lavie, 2005), ROUGEL (Lin, 2004) and CIDEr (Vedantam et al., 2015), to measure the closeness of the reconstructed paragraph (model output) to the input paragraph.",
      "startOffset" : 73,
      "endOffset" : 96
    }, {
      "referenceID" : 8,
      "context" : "and CycleGTWarm, we use the same code provided by (Guo et al., 2020).",
      "startOffset" : 50,
      "endOffset" : 68
    }, {
      "referenceID" : 12,
      "context" : "For DirectTransfer and NoisySupervised, we use the graph transformer model (Koncel-Kedziorski et al., 2019) reimplemented by (Guo et al.",
      "startOffset" : 75,
      "endOffset" : 107
    }, {
      "referenceID" : 8,
      "context" : ", 2019) reimplemented by (Guo et al., 2020) using the Deep Graph Library (DGL) (Wang et al.",
      "startOffset" : 25,
      "endOffset" : 43
    }, {
      "referenceID" : 28,
      "context" : ", 2020) using the Deep Graph Library (DGL) (Wang et al., 2019).",
      "startOffset" : 43,
      "endOffset" : 62
    }, {
      "referenceID" : 25,
      "context" : "From the text generation quality of the five models, we can see that the Rule-Based baseline (Schmitt and Schütze, 2019) performs poorly on our GenWiki dataset.",
      "startOffset" : 93,
      "endOffset" : 120
    }, {
      "referenceID" : 8,
      "context" : "The two models proposed by (Guo et al., 2020), CycleGTBase and CycleGTWarm is the strongest out of all unsupervised models, outperforming NoisySupervised by 10 BLEU points.",
      "startOffset" : 27,
      "endOffset" : 45
    } ],
    "year" : 2020,
    "abstractText" : "Data collection for the knowledge graph-to-text generation is expensive. As a result, research on unsupervised models has emerged as an active field recently. However, most unsupervised models have to use non-parallel versions of existing small supervised datasets, which largely constrain their potential. In this paper, we propose a large-scale, general-domain dataset, GenWiki. Our unsupervised dataset has 1.3M text and graph examples, respectively. With a human-annotated test set, we provide this new benchmark dataset for future research on unsupervised text generation from knowledge graphs.",
    "creator" : "TeX"
  }
}