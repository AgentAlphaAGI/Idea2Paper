{
  "name" : "COLING_2020_79_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Multi-grained Chinese Word Segmentation with Weakly Labeled Data",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "As a preliminary but critical processing step for Chinese language processing, word segmentation (WS) has been extensively studied for decades and made great progress (Zheng et al., 2013; Pei et al., 2014; Zhang et al., 2016; Yang et al., 2019; He et al., 2020). However, most of previous works adopt the single-grained word segmentation (SWS) formulation, where a sentence corresponds to a single word sequence according to some pre-defined annotation guidelines. As shown in Figure 1 (left), the SWS annotations of the sentence are different according to the guidelines of Penn Chinese Treebank (CTB) (Xue et al., 2005), the People Daily Corpus of the Peking University (PPD) (Yu et al., 2003), and the Microsoft Research WS Corpus (MSR) (Huang et al., 2006). This is largely due to the fact that as a polysynthetic language, Chinese has plenty of compound words with morphemes (mostly characters as basic units). The boundary between compounds and morphemes is usually subtle and vague (Jernudd and Shapiro, 1989). Sproat et al. (1987) show that the consensus ratio over word boundaries is only 76% even among Chinese native speakers without training on any guideline.\nIn order to guarantee the annotation consistency, people turn to detailed annotation guidelines according to specific tasks or applications. For example, CTB usually prefers fine-grained words over coarse-grained words to facilitate further annotation of syntax and semantics, while PPD accommodates more coarse-grained words with information extraction and retrieval tasks in mind. This poses a strong challenge in Chinese WS since words of different granularities are necessary for a variety of tasks and applications at the same time. Zhu and Li (2008) and Hou et al. (2010) adopt heuristic rules based on lexicon dictionaries to accommodate the necessity. Similar functions are provided by publicly available Chinese WS tools such as jieba and PullWord. However, the effectiveness of such tools are far below satisfactory without tackling segmentation ambiguity problem.\nIt is worth emphasizing that even for the same task or application, MWS can be useful due to its potential complementarity: fine-grained words reduce data sparseness, whereas coarse-grained words\nreserve more semantics. This facilitates researchers to employ multiple SWS outputs at the same time in information retrieval (IR) (Liu et al., 2008) and machine translation (MT) (Su et al., 2017).\nMotivated by above perspectives, Gong et al. (2017) propose an MWS formulation with a hierarchical tree structure to accommodate all words of different granularities. Figure 1 (right) presents an example, where “W” means the spanning characters compose a word. To solve the issue of lacking labeled MWS data, they construct a large-scale pseudo MWS data for model training and tuning. They propose several MWS approaches and justify the superiority of treating MWS as constituent parsing. However, their approaches only learn from pseudo MWS data and do not fully exploit word boundary information from other available sources which are helpful and easy to obtain.\nThis paper advances the state-of-the-art MWS model with weakly labeled data. Particularly, we propose to accommodate two types of weakly labeled data, i.e., SWS and naturally annotated dictionary example (DictEx) sentences, as extra training data, by employing a simple but competitive graph-based parsing model with local span-wise loss. Besides, we develop a unified annotation guideline for MWS and manually annotate a large-scale high-quality MWS dataset containing over 9,000 sentences from both canonical newswire texts (NEWS) and non-canonical web texts (BAIKE) for better evaluation. Detailed evaluation shows that our proposed model with weakly labeled data significantly improves the state-of-the-art MWS model by 1.12 on NEWS and by 5.97 on BAIKE in F1. We will release all the newly annotated data and the codes at https://github.com with a demo at https://url."
    }, {
      "heading" : "2 Graph-based Model with Local Loss",
      "text" : "Given an input sentence, the task of MWS is to retrieve all words of different granularities, which can be naturally organized as a hierarchical tree structure as shown in Figure 1 (right).\nGong et al. (2017) propose several MWS approaches and show that treating MWS as constituent parsing leads to the best performance. They adopt the transition-based parser of Cross and Huang (2016), which greedily searches an optimal shift-reduce action sequence to build a tree. In this work, instead of adopting the transition-based parser as Gong et al. (2017), we employ the graph-based parser of Stern et al. (2017) and replace the original global max-margin loss with local span-wise loss (Joshi et al., 2018; Teng and Zhang, 2018) as our basic MWS model due to two considerations: 1) the graph-based parser with local loss gains more efficiency without hurting the performance compared with the transitionbased parser and the graph-based parser with global loss, which will be discussed in Section 5.3; 2) more importantly, this work aims to conduct in-depth study on a simple, efficient, and effective way to incorporate weakly labeled data for MWS. The graph-based parser with local loss trains the model directly on individual labeled spans, and thus can accommodate weakly labeled data naturally."
    }, {
      "heading" : "2.1 Model Architecture",
      "text" : "As illustrated in Figure 2, our model architecture consists of following four components. The input layer builds a dense vector representation for each character position x0x1...xn, given the input sentence c0c1...cn, where ci denotes the i-th character and c0 is a pseudo character for sentence\nstart. Following previous work on Chinese word segmentation (Pei et al., 2014), we use the concatenation of single character embeddings embci and bigram character embeddings embci−1ci as the input.\nxi = emb ci ⊕ embci−1ci (1)\nThe encoding layer uses two layers of BiLSTM to encode the sentence and produce contextualized representations. We use fi and bi to denote the hidden vector of the top-layer forward and backward LSTMs for the i-th position.\nThe span representation layer constructs a dense representation vector for each possible span ci...cj−1 denoted as (i, j):\nri,j = (fj − fi)⊕ (bi − bj) (2) which is also known as the LSTM-minus features (Wang and Chang, 2016; Cross and Huang, 2016).\nThe classification layer uses an MLP to compute the labeling scores of each span.\noi,j = W2ReLU(W1ri,j + b1) + b2 (3)\nwhere W1, W2, b1, and b2 are parameters. In our task, the dimension of oi,j is 2, w.r.t “W” and “NW” respectively (oi,j [0] is the score of labeling span (i, j) as a word, and oi,j [1] as a non-word)."
    }, {
      "heading" : "2.2 Training with Local Span-wise Loss",
      "text" : "During training, we compute a local cross-entropy loss value for each span, and accumulate all loss values of all possible spans in the input sentence.\nL = − ∑\n0≤i<j≤n log\neoi,j [y ∗ i,j ]\neoi,j [0] + eoi,j [1] (4)\nwhere y∗i,j ∈ {0, 1} is the gold-standard label for span (i, j). For the weakly labeled data introduced in Section 3, the loss function only accumulates the values of the spans with ground-truth labels and overlooks others."
    }, {
      "heading" : "2.3 Inference with Chart Decoding",
      "text" : "During test, after obtaining the scores of different labels for each span, we follow Stern et al. (2017) and adopt chart decoding to find a global optimal MWS tree T ∗ with the highest score from all the possible trees. The score of an MWS tree T is the sum of label scores of all spans.\nscore(T ) = ∑\n(i,j,y)∈T\noi,j [y] (5)\nwhere (i, j, y) means span (i, j) is labeled as y, y ∈ {0, 1}."
    }, {
      "heading" : "3 MWS with Weakly Labeled Data",
      "text" : "Due to the lack of manually labeled high-quality data, Gong et al. (2017) construct a large-scale pseudo labeled MWS data by automatically converting existing heterogeneous SWS data in a pairwise way. They train their model with the pseudo labeled data and obtain promising performance on a small scale manually labeled MWS data. However, they observe that the pseudo labeled data inevitably has a lot of noise due to the pairwise conversion model and severly suffer from the under-representation phenomena of multi-grained words. In order to alleviate above issues, we propose to accommodate two types of weakly labeled data (i.e., SWS data and DictEx data) as extra data for MWS training, inspired by previous work on utilizing naturally annotated data for SWS (Jiang et al., 2013; Zhao et al., 2018)."
    }, {
      "heading" : "3.1 SWS Data as Weakly Labeled Data",
      "text" : "Although Gong et al. (2017) already adopt three heterogeneous SWS data to construct pseudo MWS data, there exist many other high-quality SWS datasets to explore with, and new ones are constantly annotated by research institutes and commercial companies.\nInstead of converting such new SWS data into noisy MWS data as Gong et al. (2017) did, we propose to treat SWS data as weakly labeled MWS data with a minor extension on the training loss. The key idea is that when accumulating training loss, we only consider spans whose gold-standard labels can be directly determined according to the SWS annotation and overlook others, as illustrated in Figure 3, where spans labeled with “W” correspond to the words in the SWS sentence, those labeled with “NW” are definitely non-words since they overlap with existing gold-standard words, and all blank spans without labels are overlooked with no loss."
    }, {
      "heading" : "3.2 DictEx Data as Weakly Labeled Data",
      "text" : "The use of naturally annotated data has been extensively studied for SWS (Jiang et al., 2013; Liu et al., 2014; Zhao et al., 2018). The basic idea is to derive word boundaries from implicit information encoded in web texts, such as anchor texts and punctuation marks, and use them as partially labeled training data in sequence labeling models.\nIn this work, we propose to obtain naturally annotated data with complete word information from the example sentences in dictionary (rather than only boundaries), which are manually constructed by linguistic experts, e.g., Entry: 最佳 (the best)\nExample sentence: 1: 找到最佳途径 2: 这是最佳选择 (find the best way) ( this is the best choice)\nwhere two DictEx sentences are carefully chosen to explain the usage of the word “最佳 (the best)”. Obviously, we can safely assume the two characters “最佳 (the best)” compose an explicit word. In this way, we can obtain many naturally annotated sentences, each labeled with one explicit word from a dictionary entry. Similar to the SWS data case, we can adjust the training loss to utilize such naturally\nannotated DictEx sentences by only accumulating the loss of the spans whose gold-standard labels can be directly determined, as shown in Figure 4."
    }, {
      "heading" : "4 High-quality Evaluation Data Annotation",
      "text" : "Gong et al. (2017) construct pseudo MWS data as the training and development datasets and manually annotate 1,500 sentences with the MWS tree structure as the test data. They present pseudo MWS results to annotators for correction without defining a strict MWS annotation guideline. Their inter-annotator consensus ratio is very high (98.1%). The main reason is that the annotators usually only detect very obvious segmentation errors and accept others as correct by default. Our early investigation shows that their data contains at least 5% annotation errors according to our newly compiled guideline.\nIn order to produce more high-quality data for better evaluation, we adopt a more scientific and robust annotation procedure and methodology. Our annotation work differs from Gong et al. (2017) from following aspects: 1) We compile a systematic and detailed MWS annotation guideline for annotators’ reference; 2) We abandon the annotation-via-correction method and present raw texts to annotators without pseudo MWS results or any other word information; 3) We adopt double annotation for all sentences with inconsistency handling by experts, to guarantee high quality.\nAs a result, we achieves the first large-scale high-quality MWS evaluation data covering two sources, i.e., 3,000 NEWS and 6,320 BAIKE sentences."
    }, {
      "heading" : "4.1 Annotation Process",
      "text" : "Annotation guideline. After a few months’ in-depth study, we integrate the three well-known SWS guidelines (i.e., CTB, PPD and MSR) and compile a systematic and detailed MWS annotation guideline. We also gradually improve the guideline according to the feedback from the annotators. The latest version is attached as supplementary material.\nQuality control. We employ 24 undergraduate students as annotators and train them for 4-8 hours before formal annotation. We apply strict double annotation to guarantee high quality. We build a browser-based annotation platform to support the annotation workflow, with the annotation interface and examples shown in the supplementary material.\nData selection. To better understand the capability of the state-of-the-art MWS model in dealing with real-world data, we select data from two sources for annotation, i.e., canonical newswire (NEWS) and non-canonical web texts .\nFor the canonical newswire texts, we re-annotate the 1,500 sentences of Gong et al. (2017), which are randomly sampled from CTB, PPD and MSR, according to our guideline. We further annotate 1,500 sentences from the year 2000 PPD SWS data, leading to 3,000 sentences with MWS full annotations, which are used as the development and test data in this work.\nFor non-canonical web texts, we collect 12 million sentences with anchor texts from the Baidu Baike website1 (similar to Wikipedia) after data cleaning. Inspired by the idea of naturally annotated WS data (Jiang et al., 2013), we use anchor texts as word boundaries to select sentences difficult for models. First, we use our basic MWS model trained on pseudo MWS data to predict an MWS tree for each sentence. Then, we randomly select 6,320 sentences where the automatic MWS tree contains at least one word that violates with a boundary, indicating the model makes at least one mistake. To save cost, we adopt partial annotation for the Baike web texts, and annotate only words related with the anchor texts. We use the annotated Baike web texts as a cross-domain test data."
    }, {
      "heading" : "4.2 Statistics and Analysis",
      "text" : "Table 1 shows the data statistics. Our re-annotated NEWS data contains 1.4% more multi-grained words compared with the NEWS data annotated by Gong et al. (2017), indicating that their annotation procedure may under-annotate multi-granularity structures. It is obvious that BAIKE contains much more multi-grained words than NEWS, because for BAIKE we only partially annotated words related with anchor texts, among which a large proportion are named entities and tend to be multi-grained.\n1https://baike.baidu.com/\n#Sents #Words Grain Distribution (%) Single Two Three+\nNEWS? 1,500 45,279 71.6 26.8 1.6 NEWS 3,000 94,585 70.2 26.9 2.9 BAIKE 6,320 14,445 51.5 39.2 9.3\nTable 1: Statistics of our manually annotated data. NEWS? represents the NEWS data annotated by Gong et al. (2017) Please note that BAIKE data is partially annotated.\nType #Sent #Word Train Pseudo MWS 138,628 4,127,461\nSWS (additional) 100,000 2,490,589 DictEx (additional) 145,037 146,934\nDev Manual NEWS 1,000 31,477 Test Manual NEWS 2,000 63,108\nManual BAIKE 6,320 14,445\nTable 2: Data settings in our experiments.\nInter-annotator consensus ratio. The word-wise inter-annotator consensus ratio is defined as #WordannoA∩annoB #WordannoA∪annoB\n, where the denominator is the number of words after merging the submission of all annotator pairs, and the numerator is the consensus word number. The overall word-wise consensus ratio is only 82.5%. This indicates the difficulty of the annotation task and the necessity of performing strict double annotation to guarantee data quality."
    }, {
      "heading" : "5 Experiments",
      "text" : "We conduct various experiments to show the effectiveness of our proposed MWS approaches. Data. Data statistics are shown in Table 2. For the training data, we directly adopt the pseudo MWS training data of Gong et al. (2017), consisting of about 140K sentences from CTB, PPD, and MSR via automatic pairwise conversion as the baseline. For the dev data, different from previous work which uses the pseudo MWS data, we randomly sample 1,000 sentences from the manually labeled NEWS data. We use two types of test data, the manually annotated 2,000 sentences of NEWS and 6,320 sentences of BAIKE. For the SWS data, we use 100K sentences from the year 2000 PPD, while we collect 140K naturally annotated DictEx sentences from the Dictionary of Modern Chinese Grammar Information of Peking University (Yu and Zhu, 2017) and the Xinhua dictionary2.\nEvaluation metrics. Precision (#Wordgold∩pred#Wordpred ), recall ( #Wordgold∩pred #Wordgold ) and F1 ( 2PRP+R ) score are used to measure the MWS performance. We adopt Dan Bikel’s randomized parsing evaluation comparator for significance test (Noreen, 1989).\nModel setting. We preserve most of the hyperparameter settings in Stern et al. (2017), and our preliminary experiments show that the performance of our approach is quite stable. Each model is trained for at most 1000 iterations, and early stopping is triggered when the peak performance does not increase in 50 consecutive iterations."
    }, {
      "heading" : "5.1 Benchmark Methods",
      "text" : "We adopt following four benchmark methods for comparison. Beside the transition-based parser and the graph-based parser with global max-margin loss, we also re-implement another two benchmark methods in Gong et al. (2017) and report their results on the new evaluation data for more insights. All the models adopt the similar architecture based on a multi-layer BiLSTM encoder.\n1. SWS aggregation. We train three SWS models separately on PPD, MSR and CTB datasets, and merge their outputs as MWS results.\n2. Sequence labeling. It considers MWS as sequence labeling problem. Each character corresponds to an MWS label to denote the positions of the character in all the multi-grained words containing it.\n3. Transition-based parser. We adopt the same transition-based parser of Cross and Huang (2016). 4. Graph-based parser (global). We use the same graph-based constituent parser of Stern et al.\n(2017) with global max-margin loss."
    }, {
      "heading" : "5.2 Main results",
      "text" : "Table 3 compares different approaches on the manually annotated development, NEWS-test and BAIKEtest. Please kindly note that the results look very low on BAIKE-test, because only the most difficult parts\n2http://xh.5156edu.com/\n(anchor texts) are partially annotated for BAIKE sentences, as discussed in Section 4.1. Our graph-based parser with local loss outperforms the SWS aggregation and sequence labeling methods with large margins (p < 0.001) on both dev and tests. We observe that although the SWS aggregation method achieves the best recall compared with other benchmark methods, the precision is very low due to the ignorance of the connections among different heterogeneous SWS data. The recall of the sequence labeling approach is poor, because the sequence labeling model produces less words and multi-grained words than other models and thus fails to produce words more than three granularity levels. These indicate that casting MWS as a constituent parsing problem is more proper.\nOur graph-based model with local loss performs slightly better on NEWS-test in F1 and achieves nearly the same performance on BAIKE-test compared with the transition-based parser. Besides, the results of the graph-based parser with local loss and global loss are comparable.\nMoreover, the precision values are much higher than the recall values for transition/graph-based parser on both types of test data. This large gap means that the MWS models tend to generate single-grained words rather than multi-grained ones. The main reason is that multi-granularity phenomena are underrepresented in the noisy pseudo MWS data due to the mistakes and bias imposed by the automatic conversion models.\nUsing additional SWS data for training brings large F1 improvement over the basic parser trained on only pseudo MWS data. For NEWS, although precision decreases by 0.82/0.61 on dev/test, recall increases by much larger margin of 2.38/2.50, leading to overall F1 increase of 0.83 and 0.99 on dev and test (p < 0.001). We believe the reason is that the SWS data can alleviate the under-representation of multi-granularity phenomena in the noisy pseudo MWS training data. For further investigation, we calculate the word proportion (defined as #SpanW#SpanW+#SpanNW , where #SpanW and #SpanNW represent the number of spans labeled “W” and “NW” respectively), which accounts for 3.5% for SWS data and only 2.0% for pseudo MWS data. In other words, there are more positive examples for the “W” label in the SWS data than in the pseudo MWS data, thus encouraging the model to produce more multi-grained words and achieve higher recall to some extend. For BAIKE-test, the model with additional SWS data outperforms the basic parser by 5.74 (from 43.14 to 48.88) in F1 (p < 0.001). The improvement is mostly contributed by the large increase of recall, which is consistent with NEWS.\nUsing the DictEx data as extra training data consistently improves F1 score by 0.21/0.26 on NEWS/BAIKE test compared with the basic parser trained on only pseudo MWS data. The improvement seems small yet both significant (p < 0.001). Looking into the precision/recall changes, though precision decreases a little bit, recall increases a lot. This can be explained similarly by the proportion of positive “W” examples, which is 11.2% for DictEx and it is much higher than pseudo MWS data.\nAbove results show that the DictEx data is a very reliable knowledge source, and the small yet steady improvement is mainly due to its weak supervision, considering that only a very small portion of spans have loss in each sentence.\nUsing both SWS and DictEx data achieves the highest F1 scores on both dev and test, outperforming\nthe basic parser by 1.13 on dev, 1.12/5.91 on NEWS/BAIKE test (p < 0.001). Compared with the “+ SWS” model, the extra DictEx data increases both precision and recall on dev and NEWS/BAIKE test.\nOverall, above results show that the SWS data can effectively reach a balance with the pseudo MWS by alleviating under-representation problem of multi-granularity, while the DictEX data can provide complementary and consistent contribution."
    }, {
      "heading" : "5.3 Efficiency",
      "text" : "We report the averaged one-epoch training time on the pseudo MWS data (consuming 15,000 training instances) as follows:\nTransition-based parser 38min Graph-based parser (global) 35min Our graph-based basic parser (local) 23min\nWe choose the transition-based parser and the graph-based parser with global loss for comparison, as they outperform other benchmark methods by large margins. We find that our graph-based parser with local loss is about 1.5 times faster than these two compared models."
    }, {
      "heading" : "5.4 Analysis",
      "text" : "We conduct detailed analysis to gain more insights on our proposed approaches. For space limitation, we only present the analysis results on NEWS-test.\nInfluence of the amount of data. Figure 5 illustrates the influence of the amount of both the pseudo MWS data and the weakly labeled data. In each curve, we fix the size of the pseudo MWS data and incrementally add a random subset of the weakly labeled data. For the three curves, we use all, 50%, and 25% of the pseudo MWS data by random sampling. We observe that using more weakly labeled data leads to consistently higher performance for all three curves. While the first 25% data produces largest improvement, the gain becomes less substantial afterwards. From another aspect, performance steadily goes up by large margin when raising the size of the pseudo MWS data, demonstrating that the pseudo MWS data is fundamentally important for training the MWS model, although containing inevitable noises.\nPerformance of different granularities. To understand the performance of our approaches on words of different granularities, we divide the gold-standard words into three subsets according to their guanularities and compute the recall of each approach on the three subsets. We compare our models with the transition-based parser and the graph-based parser with global loss, which have better performance than other benchmark methods. The results are shown in Figure 6. The percentages in parenthesis at the X-axis denote the word proportions of corresponding granularities on NEWS-test. Figure 6 shows that the words with more granularities have lower recall for all models. This indicates that multi-grained words are difficult to predict. Compared with the transition-based parser and the graph-based parser\nwith global loss, our basic parser using only the pseudo data performs better in two of the three types of granularities. After utilizing weakly labeled data, our MWS model achieves consistent improvements on all the three types of granularities."
    }, {
      "heading" : "6 Related Work",
      "text" : "MWS approaches. The industrial community has long been interested in retrieving words of different granularities with the help of lexicon dictionaries and heuristic rules (Zhu and Li, 2008; Hou et al., 2010). We also find that publicly available WS tools such as jieba3 and PullWord4 provide the interface for retrieving words of different granularities. However, all those tools judge the probability of each substring being a word independently, without resolving any segmentation ambiguity. Therefore, the output words may overlap with each other.\nGong et al. (2017) first formally address the MWS task and build a pseudo MWS dataset for model training. They also propose and compare three benchmark MWS approach, i.e., constituent parsing, sequence labeling, and SWS aggregation, showing that treating MWS as constituent parsing is most effective. We follow their work and advance the state-of-the-art MWS research progress from the perspectives of both data and approach.\nUtilizing MWS results. Due to its critical importance, MWS results have been explored in various NLP applications. Liu et al. (2008) propose a ranking based WS approach to produce words of different granularities to help IR. Su et al. (2017) propose a lattice-based RNN encoder for neural MT by representing MWS outputs in word lattices, leading to improved translation performance. Due to the lack of MWS model, they obtain MWS outputs from several SWS models independently trained on heterogeneous SWS datasets.\nUtilizing weakly labeled data. The use of weakly labeled data has been an interesting research direction in NLP for a long time. On the one hand, it is usually much easier and cheaper to perform partial annotation than complete annotation, especially for complex tasks such as parsing (Hwa, 1999; Sassano and Kurohashi, 2010; Li et al., 2016b; Joshi et al., 2018). On the other hand, it is sometimes feasible to automatically extract naturally annotated data. Several works utilize naturally annotated data with word boundaries for training SWS models, by making use of markup information such as anchor texts in web pages (Jiang et al., 2013; Liu et al., 2014; Zhao et al., 2018).\nIn this work, we propose two types of weakly labeled data for MWS, i.e., SWS data and naturally annotated data from DictEx sentences, which are shown to be complementary and able to alleviate the under-representation problem of multi-grained phenomena in the noisy pseudo MWS training data.\nSWS with heterogeneous data. In recent years, there has been a surge of interest in improving SWS with heterogeneous SWS data. The basic idea is improving SWS by utilizing multiple manually labeled SWS data for training at the same time. Representative works include Li et al. (2016a), Chen et al. (2016), He et al. (2018), Chen et al. (2017) and Yang et al. (2017). Although MWS results can be obtained by merging multiple SWS outputs, but many overlapped words may generated due to the lack of proper constraints, leading to low precision. In this work, we alleviate this issue by considering MWS as a constituent tree parsing problem."
    }, {
      "heading" : "7 Conclusions",
      "text" : "This work advances the state-of-the-art MWS research from three perspectives. First, we manually annotate over 9,000 sentences for better evaluation, consisting of both canonical NEWS and non-canonical BAIKE texts. Second, we employ a simple graph-based parsing model with local loss to facilitate the use of weakly labeled data. Finally, we propose to accomodate two types of weakly labeled data as extra training data, i.e., the SWS data and the DictEx data. Detailed analysis show that 1) the simple graph-based parsing model with local loss achieves highly competitive performance; 2) both types of weakly labeled data can provide consistent and substantial gains; 3) our proposed approach outperforms the state-of-the-art MWS model by 1.12 on NEWS and by 5.97 on BAIKE in F1.\n3https://github.com/fxsjy/jieba 4http://pullword.com"
    } ],
    "references" : [ {
      "title" : "Neural network for heterogeneous annotations",
      "author" : [ "Hongshen Chen", "Yue Zhang", "Qun Liu." ],
      "venue" : "Proceedings of EMNLP, pages 731–741.",
      "citeRegEx" : "Chen et al\\.,? 2016",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2016
    }, {
      "title" : "Adversarial multi-criteria learning for Chinese word segmentation",
      "author" : [ "Xinchi Chen", "Zhan Shi", "Xipeng Qiu", "Xuanjing Huang." ],
      "venue" : "Proceedings of ACL, pages 1193–1203.",
      "citeRegEx" : "Chen et al\\.,? 2017",
      "shortCiteRegEx" : "Chen et al\\.",
      "year" : 2017
    }, {
      "title" : "Span-based constituency parsing with a structure-label system and provably optimal dynamic oracles",
      "author" : [ "James Cross", "Liang Huang." ],
      "venue" : "Proceedings of EMNLP, pages 1–11, Austin, Texas.",
      "citeRegEx" : "Cross and Huang.,? 2016",
      "shortCiteRegEx" : "Cross and Huang.",
      "year" : 2016
    }, {
      "title" : "Multi-grained Chinese word segmentation",
      "author" : [ "Chen Gong", "Zhenghua Li", "Min Zhang", "Xinzhou Jiang." ],
      "venue" : "Proceedings of EMNLP, pages 703–714, Copenhagen, Denmark.",
      "citeRegEx" : "Gong et al\\.,? 2017",
      "shortCiteRegEx" : "Gong et al\\.",
      "year" : 2017
    }, {
      "title" : "Effective neural solution for multi-criteria word segmentation",
      "author" : [ "Han He", "Lei Wu", "Hua Yan", "Zhimin Gao", "Yi Feng", "George Townsend." ],
      "venue" : "arXiv preprint arXiv:1712.02856.",
      "citeRegEx" : "He et al\\.,? 2018",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2018
    }, {
      "title" : "Dynamic programming encoding for subword segmentation in neural machine translation",
      "author" : [ "Xuanli He", "Gholamreza Haffari", "Mohammad Norouzi." ],
      "venue" : "Proceedings of ACL, pages 3042–3051.",
      "citeRegEx" : "He et al\\.,? 2020",
      "shortCiteRegEx" : "He et al\\.",
      "year" : 2020
    }, {
      "title" : "Method and device for providing multi-granularity word segmentation result",
      "author" : [ "Lei Hou", "Min Chu", "Jingming Tang", "Jian Sun", "Xiaoling Liao", "Rengang Peng", "Yang Yang", "Bingjing Xu." ],
      "venue" : "Chinese Patent (CN102479191A).",
      "citeRegEx" : "Hou et al\\.,? 2010",
      "shortCiteRegEx" : "Hou et al\\.",
      "year" : 2010
    }, {
      "title" : "Tokenization guidelines of Chinese text(v5.0, in Chinese)",
      "author" : [ "Chang-Ning Huang", "Yumei Li", "Xiaodan Zhu" ],
      "venue" : "Journal of Logic and Computation",
      "citeRegEx" : "Huang et al\\.,? \\Q2006\\E",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2006
    }, {
      "title" : "Supervised grammar induction using training data with limited constituent information",
      "author" : [ "Rebecca Hwa." ],
      "venue" : "Proceedings of ACL, pages 73–79.",
      "citeRegEx" : "Hwa.,? 1999",
      "shortCiteRegEx" : "Hwa.",
      "year" : 1999
    }, {
      "title" : "The Politics of Language Purism",
      "author" : [ "Björn H. Jernudd", "Michael J. Shapiro" ],
      "venue" : null,
      "citeRegEx" : "Jernudd and Shapiro.,? \\Q1989\\E",
      "shortCiteRegEx" : "Jernudd and Shapiro.",
      "year" : 1989
    }, {
      "title" : "Discriminative learning with natural annotations: Word segmentation as a case study",
      "author" : [ "Wenbin Jiang", "Meng Sun", "Yajuan Lü", "Yating Yang", "Qun Liu." ],
      "venue" : "Proceedings of ACL, pages 761–769, Sofia, Bulgari.",
      "citeRegEx" : "Jiang et al\\.,? 2013",
      "shortCiteRegEx" : "Jiang et al\\.",
      "year" : 2013
    }, {
      "title" : "Extending a parser to distant domains using a few dozen partially annotated examples",
      "author" : [ "Vidur Joshi", "Matthew Peters", "Mark Hopkins." ],
      "venue" : "Proceedings of ACL, pages 1190–1199, Melbourne, Australia.",
      "citeRegEx" : "Joshi et al\\.,? 2018",
      "shortCiteRegEx" : "Joshi et al\\.",
      "year" : 2018
    }, {
      "title" : "Fast coupled sequence labeling on heterogeneous annotations via context-aware pruning",
      "author" : [ "Zhenghua Li", "Jiayuan Chao", "Min Zhang", "Jiwen Yang." ],
      "venue" : "Proceedings of EMNLP, pages 753–762.",
      "citeRegEx" : "Li et al\\.,? 2016a",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Active learning for dependency parsing with partial annotation",
      "author" : [ "Zhenghua Li", "Min Zhang", "Yue Zhang", "Zhanyi Liu", "Wenliang Chen", "Hua Wu", "Haifeng Wang." ],
      "venue" : "Proceedings of ACL, pages 344–357, Berlin, Germany.",
      "citeRegEx" : "Li et al\\.,? 2016b",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Information retrieval oriented word segmentation based on character association strength ranking",
      "author" : [ "Yixuan Liu", "Bin Wang", "Fan Ding", "Sheng Xu." ],
      "venue" : "Proceedings of EMNLP, pages 495–504.",
      "citeRegEx" : "Liu et al\\.,? 2008",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2008
    }, {
      "title" : "Domain adaptation for crf-based Chinese word segmentation using free annotations",
      "author" : [ "Yijia Liu", "Yue Zhang", "Wanxiang Che", "Ting Liu", "Fan Wu." ],
      "venue" : "Proceedings of EMNLP, pages 864–874, Doha, Qatar.",
      "citeRegEx" : "Liu et al\\.,? 2014",
      "shortCiteRegEx" : "Liu et al\\.",
      "year" : 2014
    }, {
      "title" : "Computer-intensive methods for testing hypotheses: An introduction",
      "author" : [ "Eric W. Noreen." ],
      "venue" : "John Wiley & Sons, Inc., New York.",
      "citeRegEx" : "Noreen.,? 1989",
      "shortCiteRegEx" : "Noreen.",
      "year" : 1989
    }, {
      "title" : "Max-margin tensor neural network for Chinese word segmentation",
      "author" : [ "Wenzhe Pei", "Tao Ge", "Baobao Chang." ],
      "venue" : "Proceedings of ACL, pages 293–303, Baltimore, Maryland.",
      "citeRegEx" : "Pei et al\\.,? 2014",
      "shortCiteRegEx" : "Pei et al\\.",
      "year" : 2014
    }, {
      "title" : "Using smaller constituents rather than sentences in active learning for japanese dependency parsing",
      "author" : [ "Manabu Sassano", "Sadao Kurohashi." ],
      "venue" : "Proceedings of ACL, pages 356–365, Uppsala, Sweden.",
      "citeRegEx" : "Sassano and Kurohashi.,? 2010",
      "shortCiteRegEx" : "Sassano and Kurohashi.",
      "year" : 2010
    }, {
      "title" : "A stochastic finite-state word-segmentation algorithm for Chinese",
      "author" : [ "Richard Sproat", "William Gales", "Chilin Shih", "Nancy Chang." ],
      "venue" : "Computational Linguistics, 22:377–404.",
      "citeRegEx" : "Sproat et al\\.,? 1987",
      "shortCiteRegEx" : "Sproat et al\\.",
      "year" : 1987
    }, {
      "title" : "A minimal span-based neural constituency parser",
      "author" : [ "Mitchell Stern", "Jacob Andreas", "Dan Klein." ],
      "venue" : "Proceedings of ACL, pages 818–827, Vancouver, Canada.",
      "citeRegEx" : "Stern et al\\.,? 2017",
      "shortCiteRegEx" : "Stern et al\\.",
      "year" : 2017
    }, {
      "title" : "Lattice-based recurrent neurla network encoders for neural machine translation",
      "author" : [ "Jinsong Su", "Zhixing Tan", "Deyi Xiong", "Rongrong Ji", "Xiaodong Shi", "Yang Liu." ],
      "venue" : "Proceedings of AAAI, pages 3302–3308, San Francisco, USA.",
      "citeRegEx" : "Su et al\\.,? 2017",
      "shortCiteRegEx" : "Su et al\\.",
      "year" : 2017
    }, {
      "title" : "Two local models for neural constituent parsing",
      "author" : [ "Zhiyang Teng", "Yue Zhang." ],
      "venue" : "Proceedings of COLING, pages 119–132.",
      "citeRegEx" : "Teng and Zhang.,? 2018",
      "shortCiteRegEx" : "Teng and Zhang.",
      "year" : 2018
    }, {
      "title" : "Graph-based dependency parsing with bidirectional lstm",
      "author" : [ "Wenhui Wang", "Baobao Chang." ],
      "venue" : "Proceedings of ACL, pages 2306–2315, Berlin, Germany.",
      "citeRegEx" : "Wang and Chang.,? 2016",
      "shortCiteRegEx" : "Wang and Chang.",
      "year" : 2016
    }, {
      "title" : "The penn Chinese treebank: Phrase structure annotation of a large corpus",
      "author" : [ "Nianwen Xue", "Fei Xia", "Fu-Dong Chiou", "Martha Palmer." ],
      "venue" : "Natural Language Engineering, 11(2):207–238.",
      "citeRegEx" : "Xue et al\\.,? 2005",
      "shortCiteRegEx" : "Xue et al\\.",
      "year" : 2005
    }, {
      "title" : "Neural word segmentation with rich pretraining",
      "author" : [ "Jie Yang", "Yue Zhang", "Fei Dong." ],
      "venue" : "Proceedings of ACL, pages 839–849.",
      "citeRegEx" : "Yang et al\\.,? 2017",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2017
    }, {
      "title" : "Subword encoding in lattice LSTM for Chinese word segmentation",
      "author" : [ "Jie Yang", "Yue Zhang", "Shuailong Liang." ],
      "venue" : "Proceedings of NAACL, pages 2720–2725.",
      "citeRegEx" : "Yang et al\\.,? 2019",
      "shortCiteRegEx" : "Yang et al\\.",
      "year" : 2019
    }, {
      "title" : "A dictionary of modern Chinese grammar information",
      "author" : [ "Shiwen Yu", "Xuefeng Zhu." ],
      "venue" : "http://dx.doi.org/10. 18170/DVN/EDQWIL.",
      "citeRegEx" : "Yu and Zhu.,? 2017",
      "shortCiteRegEx" : "Yu and Zhu.",
      "year" : 2017
    }, {
      "title" : "Specification for corpus processing at peking university: Word segmentation, pos tagging and phonetic notation (in Chinese)",
      "author" : [ "Shiwen Yu", "Huiming Duan", "Xuefeng Zhu", "Bin Swen", "Baobao Chang." ],
      "venue" : "Journal of Chinese Language and Computing, 13(2):121–158.",
      "citeRegEx" : "Yu et al\\.,? 2003",
      "shortCiteRegEx" : "Yu et al\\.",
      "year" : 2003
    }, {
      "title" : "Transition-based neural word segmentation",
      "author" : [ "Meishan Zhang", "Yue Zhang", "Guohong Fu." ],
      "venue" : "Proceedings of ACL, pages 421–431, Berlin, Germany.",
      "citeRegEx" : "Zhang et al\\.,? 2016",
      "shortCiteRegEx" : "Zhang et al\\.",
      "year" : 2016
    }, {
      "title" : "Neural networks incorporating unlabeled and partiallylabeled data for cross-domain Chinese word segmentation",
      "author" : [ "Lujun Zhao", "Qi Zhang", "Peng Wang", "Xiaoyu Liu." ],
      "venue" : "Proceedings of IJCAI, pages 4602–4608, Stockholm, Sweden.",
      "citeRegEx" : "Zhao et al\\.,? 2018",
      "shortCiteRegEx" : "Zhao et al\\.",
      "year" : 2018
    }, {
      "title" : "Deep learning for Chinese word segmentation and POS tagging",
      "author" : [ "Xiaoqing Zheng", "Hanyang Chen", "Tianyu Xu." ],
      "venue" : "Proceedings of EMNLP, pages 647–657, Washington, USA.",
      "citeRegEx" : "Zheng et al\\.,? 2013",
      "shortCiteRegEx" : "Zheng et al\\.",
      "year" : 2013
    }, {
      "title" : "Method and device for large- and small-grained segmentation of Chinese text",
      "author" : [ "Jian Zhu", "Shan Li." ],
      "venue" : "Chinese Patent (CN101246472A).",
      "citeRegEx" : "Zhu and Li.,? 2008",
      "shortCiteRegEx" : "Zhu and Li.",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 31,
      "context" : "As a preliminary but critical processing step for Chinese language processing, word segmentation (WS) has been extensively studied for decades and made great progress (Zheng et al., 2013; Pei et al., 2014; Zhang et al., 2016; Yang et al., 2019; He et al., 2020).",
      "startOffset" : 167,
      "endOffset" : 261
    }, {
      "referenceID" : 17,
      "context" : "As a preliminary but critical processing step for Chinese language processing, word segmentation (WS) has been extensively studied for decades and made great progress (Zheng et al., 2013; Pei et al., 2014; Zhang et al., 2016; Yang et al., 2019; He et al., 2020).",
      "startOffset" : 167,
      "endOffset" : 261
    }, {
      "referenceID" : 29,
      "context" : "As a preliminary but critical processing step for Chinese language processing, word segmentation (WS) has been extensively studied for decades and made great progress (Zheng et al., 2013; Pei et al., 2014; Zhang et al., 2016; Yang et al., 2019; He et al., 2020).",
      "startOffset" : 167,
      "endOffset" : 261
    }, {
      "referenceID" : 26,
      "context" : "As a preliminary but critical processing step for Chinese language processing, word segmentation (WS) has been extensively studied for decades and made great progress (Zheng et al., 2013; Pei et al., 2014; Zhang et al., 2016; Yang et al., 2019; He et al., 2020).",
      "startOffset" : 167,
      "endOffset" : 261
    }, {
      "referenceID" : 5,
      "context" : "As a preliminary but critical processing step for Chinese language processing, word segmentation (WS) has been extensively studied for decades and made great progress (Zheng et al., 2013; Pei et al., 2014; Zhang et al., 2016; Yang et al., 2019; He et al., 2020).",
      "startOffset" : 167,
      "endOffset" : 261
    }, {
      "referenceID" : 24,
      "context" : "As shown in Figure 1 (left), the SWS annotations of the sentence are different according to the guidelines of Penn Chinese Treebank (CTB) (Xue et al., 2005), the People Daily Corpus of the Peking University (PPD) (Yu et al.",
      "startOffset" : 138,
      "endOffset" : 156
    }, {
      "referenceID" : 28,
      "context" : ", 2005), the People Daily Corpus of the Peking University (PPD) (Yu et al., 2003), and the Microsoft Research WS Corpus (MSR) (Huang et al.",
      "startOffset" : 64,
      "endOffset" : 81
    }, {
      "referenceID" : 7,
      "context" : ", 2003), and the Microsoft Research WS Corpus (MSR) (Huang et al., 2006).",
      "startOffset" : 52,
      "endOffset" : 72
    }, {
      "referenceID" : 9,
      "context" : "The boundary between compounds and morphemes is usually subtle and vague (Jernudd and Shapiro, 1989).",
      "startOffset" : 73,
      "endOffset" : 100
    }, {
      "referenceID" : 14,
      "context" : "This facilitates researchers to employ multiple SWS outputs at the same time in information retrieval (IR) (Liu et al., 2008) and machine translation (MT) (Su et al.",
      "startOffset" : 107,
      "endOffset" : 125
    }, {
      "referenceID" : 21,
      "context" : ", 2008) and machine translation (MT) (Su et al., 2017).",
      "startOffset" : 37,
      "endOffset" : 54
    }, {
      "referenceID" : 11,
      "context" : "(2017) and replace the original global max-margin loss with local span-wise loss (Joshi et al., 2018; Teng and Zhang, 2018) as our basic MWS model due to two considerations: 1) the graph-based parser with local loss gains more efficiency without hurting the performance compared with the transitionbased parser and the graph-based parser with global loss, which will be discussed in Section 5.",
      "startOffset" : 81,
      "endOffset" : 123
    }, {
      "referenceID" : 22,
      "context" : "(2017) and replace the original global max-margin loss with local span-wise loss (Joshi et al., 2018; Teng and Zhang, 2018) as our basic MWS model due to two considerations: 1) the graph-based parser with local loss gains more efficiency without hurting the performance compared with the transitionbased parser and the graph-based parser with global loss, which will be discussed in Section 5.",
      "startOffset" : 81,
      "endOffset" : 123
    }, {
      "referenceID" : 17,
      "context" : "Following previous work on Chinese word segmentation (Pei et al., 2014), we use the concatenation of single character embeddings embi and bigram character embeddings embi−1i as the input.",
      "startOffset" : 53,
      "endOffset" : 71
    }, {
      "referenceID" : 23,
      "context" : "ri,j = (fj − fi)⊕ (bi − bj) (2) which is also known as the LSTM-minus features (Wang and Chang, 2016; Cross and Huang, 2016).",
      "startOffset" : 79,
      "endOffset" : 124
    }, {
      "referenceID" : 2,
      "context" : "ri,j = (fj − fi)⊕ (bi − bj) (2) which is also known as the LSTM-minus features (Wang and Chang, 2016; Cross and Huang, 2016).",
      "startOffset" : 79,
      "endOffset" : 124
    }, {
      "referenceID" : 10,
      "context" : ", SWS data and DictEx data) as extra data for MWS training, inspired by previous work on utilizing naturally annotated data for SWS (Jiang et al., 2013; Zhao et al., 2018).",
      "startOffset" : 132,
      "endOffset" : 171
    }, {
      "referenceID" : 30,
      "context" : ", SWS data and DictEx data) as extra data for MWS training, inspired by previous work on utilizing naturally annotated data for SWS (Jiang et al., 2013; Zhao et al., 2018).",
      "startOffset" : 132,
      "endOffset" : 171
    }, {
      "referenceID" : 10,
      "context" : "2 DictEx Data as Weakly Labeled Data The use of naturally annotated data has been extensively studied for SWS (Jiang et al., 2013; Liu et al., 2014; Zhao et al., 2018).",
      "startOffset" : 110,
      "endOffset" : 167
    }, {
      "referenceID" : 15,
      "context" : "2 DictEx Data as Weakly Labeled Data The use of naturally annotated data has been extensively studied for SWS (Jiang et al., 2013; Liu et al., 2014; Zhao et al., 2018).",
      "startOffset" : 110,
      "endOffset" : 167
    }, {
      "referenceID" : 30,
      "context" : "2 DictEx Data as Weakly Labeled Data The use of naturally annotated data has been extensively studied for SWS (Jiang et al., 2013; Liu et al., 2014; Zhao et al., 2018).",
      "startOffset" : 110,
      "endOffset" : 167
    }, {
      "referenceID" : 10,
      "context" : "Inspired by the idea of naturally annotated WS data (Jiang et al., 2013), we use anchor texts as word boundaries to select sentences difficult for models.",
      "startOffset" : 52,
      "endOffset" : 72
    }, {
      "referenceID" : 27,
      "context" : "For the SWS data, we use 100K sentences from the year 2000 PPD, while we collect 140K naturally annotated DictEx sentences from the Dictionary of Modern Chinese Grammar Information of Peking University (Yu and Zhu, 2017) and the Xinhua dictionary2.",
      "startOffset" : 202,
      "endOffset" : 220
    }, {
      "referenceID" : 16,
      "context" : "We adopt Dan Bikel’s randomized parsing evaluation comparator for significance test (Noreen, 1989).",
      "startOffset" : 84,
      "endOffset" : 98
    }, {
      "referenceID" : 32,
      "context" : "The industrial community has long been interested in retrieving words of different granularities with the help of lexicon dictionaries and heuristic rules (Zhu and Li, 2008; Hou et al., 2010).",
      "startOffset" : 155,
      "endOffset" : 191
    }, {
      "referenceID" : 6,
      "context" : "The industrial community has long been interested in retrieving words of different granularities with the help of lexicon dictionaries and heuristic rules (Zhu and Li, 2008; Hou et al., 2010).",
      "startOffset" : 155,
      "endOffset" : 191
    }, {
      "referenceID" : 8,
      "context" : "On the one hand, it is usually much easier and cheaper to perform partial annotation than complete annotation, especially for complex tasks such as parsing (Hwa, 1999; Sassano and Kurohashi, 2010; Li et al., 2016b; Joshi et al., 2018).",
      "startOffset" : 156,
      "endOffset" : 234
    }, {
      "referenceID" : 18,
      "context" : "On the one hand, it is usually much easier and cheaper to perform partial annotation than complete annotation, especially for complex tasks such as parsing (Hwa, 1999; Sassano and Kurohashi, 2010; Li et al., 2016b; Joshi et al., 2018).",
      "startOffset" : 156,
      "endOffset" : 234
    }, {
      "referenceID" : 13,
      "context" : "On the one hand, it is usually much easier and cheaper to perform partial annotation than complete annotation, especially for complex tasks such as parsing (Hwa, 1999; Sassano and Kurohashi, 2010; Li et al., 2016b; Joshi et al., 2018).",
      "startOffset" : 156,
      "endOffset" : 234
    }, {
      "referenceID" : 11,
      "context" : "On the one hand, it is usually much easier and cheaper to perform partial annotation than complete annotation, especially for complex tasks such as parsing (Hwa, 1999; Sassano and Kurohashi, 2010; Li et al., 2016b; Joshi et al., 2018).",
      "startOffset" : 156,
      "endOffset" : 234
    }, {
      "referenceID" : 10,
      "context" : "Several works utilize naturally annotated data with word boundaries for training SWS models, by making use of markup information such as anchor texts in web pages (Jiang et al., 2013; Liu et al., 2014; Zhao et al., 2018).",
      "startOffset" : 163,
      "endOffset" : 220
    }, {
      "referenceID" : 15,
      "context" : "Several works utilize naturally annotated data with word boundaries for training SWS models, by making use of markup information such as anchor texts in web pages (Jiang et al., 2013; Liu et al., 2014; Zhao et al., 2018).",
      "startOffset" : 163,
      "endOffset" : 220
    }, {
      "referenceID" : 30,
      "context" : "Several works utilize naturally annotated data with word boundaries for training SWS models, by making use of markup information such as anchor texts in web pages (Jiang et al., 2013; Liu et al., 2014; Zhao et al., 2018).",
      "startOffset" : 163,
      "endOffset" : 220
    } ],
    "year" : 2020,
    "abstractText" : "Previous work train and tune multi-grained Chinese word segmentation (MWS) models only on automatically generated pseudo MWS data due to the lack of manually annotated MWS data. In this work, we further take advantage of the rich word boundary information in existing single-grained word segmentation (SWS) data and naturally annotated data from dictionary example (DictEx) sentences, to advance the state-of-the-art MWS model based on the idea of weak supervision. Particularly, we propose to accommodate two types of weakly labeled data for MWS, i.e., SWS data and DictEx data by employing a simple yet competitive graph-based parser with local loss. Besides, we manually annotate a high-quality MWS dataset according to our newly compiled annotation guideline, consisting of over 9,000 sentences from two types of texts, i.e., canonical newswire (NEWS) and non-canonical web (BAIKE) data for better evaluation. Detailed evaluation shows that our proposed model with weakly labeled data significantly outperforms the state-of-the-art MWS model by 1.12 and 5.97 on NEWS and BAIKE data in F1, coupled with several interesting findings due to the availability of our manually annotated high-quality MWS evaluation data.",
    "creator" : "LaTeX with hyperref"
  }
}