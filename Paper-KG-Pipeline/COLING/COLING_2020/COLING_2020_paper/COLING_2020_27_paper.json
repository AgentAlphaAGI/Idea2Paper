{
  "name" : "COLING_2020_27_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "The Indigenous Languages Technology project: An empowerment-oriented approach to developing language software",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "This paper surveys the first, three-year phase of a project that is developing software to assist Indigenous communities in Canada in their efforts to preserve their languages and extend their use. The project aimed to work within the empowerment paradigm, where collaboration with communities and fulfillment of their goals is central. Since many of the technologies we developed were in response to community needs, the project ended up as a collection of diverse subprojects, including the creation of a sophisticated framework for building verb conjugators for highly inflectional polysynthetic languages (such as Kanyen’kéha, in the Iroquoian language family), release of what is probably the largest available corpus of sentences in a polysynthetic language (Inuktut) aligned with English sentences and experiments with machine translation (MT) systems trained on this corpus, free online services based on automatic speech recognition (ASR) for easing the transcription bottleneck for recordings of speech in Indigenous languages (and other languages), software for implementing text prediction and read-along audiobooks for Indigenous languages, and several other subprojects."
    }, {
      "heading" : "1 Introduction",
      "text" : "This paper surveys Phase I of a project whose primary goal is to serve Indigenous communities in Canada by producing software that would enhance their efforts to preserve and revitalize their languages. This phase of the project began inMarch 2017, ended inMarch 2020, and had funding of $6million; it involved a collaboration by several research organizations. Phase II is ongoing. Different communities have very different linguistic needs, so our project was made up of a diverse set of subprojects. Because there is relatively little textual or speech data for Indigenous languages in Canada (with the partial exception of Inuktut), most of the technologies developed within the project described here have been rule-based, rather than relying on data-driven machine learning. Different approaches have been taken to linguistic research involving Indigenous languages (Cameron et al., 1992; Czaykowska-Higgins, 2009). Most of the work carried out within this project fits into the “empowerment” approach, in which research is carried out collaboratively, with equal emphasis on the agenda of the linguist and of the community. Themost ambitious subproject described here was suggested to us by an Indigenous educator: the creation of a verb conjugator for Kanyen’kéha (Mohawk). Similarly, the “readalong” subproject for automating word–speech alignment for audio books was in response to strong interest from several communities. The project was guided by an Advisory Committee made up of Indigenous people with expertise in language revitalization. Their counsel has been invaluable; they are listed at [self-identifying URL]. At no stage did the project claim ownership of Indigenous language data collected with the project’s funding. We were determined to break with the unfortunate history of academics and government departments refusing to return linguistic data to the Indigenous communities from which it was collected (see (Pool, 2016), (Keegan, 2019), and (Brinklow et al., forthcoming))."
    }, {
      "heading" : "2 Sociolinguistic Background",
      "text" : "There are about 70 Indigenous languages from 10 distinct language families currently spoken in Canada (Rice, 2008). Most of these languages have complexmorphology; they are polysynthetic or agglutinative. Commonly, a single word carries the meaning of an entire clause in Indo-European languages. All Indigenous languages in Canada were targeted by government policies that sought to eradicate them. These policies were implemented through legislation, such as the Indian Act,1 which discouraged, and often made illegal, gathering for cultural practices and speaking ancestral languages. Many Indigenous children were forcibly removed from their communities and placed in compulsory boarding schools (known as Residential Schools) or adopted by non-Indigenous families (known as the Sixties Scoop (Fachinger, 2019)). According to the Truth and Reconciliation Commission of Canada, the residential school system was “created for the purpose of separating Aboriginal children from their families, in order to minimize and weaken family ties and cultural linkages” (Government of Canada, 2015, preface). The resilience of Indigenous communities can be seen in the many ways that they have resisted assimilation and continued to teach, learn, and speak their languages (Pine and Turin, 2017). The benefits associated with the use of these languages are wide-ranging (Whalen et al., 2016; Reyhner, 2010; Oster et al., 2014; Marmion et al., 2014). For instance, there is a correlation between Indigenous language use and a decrease in youth suicide rates on reserves in British Columbia (Chandler and Lalonde, 1998; Hallett et al., 2007). However, many communities face decreasing numbers of first language (mother tongue) speakers, due to declining language transmission rates (Norris, 2018). Much Indigenous language revitalization work in Canada focuses on preservation of language through recording the speech of Elders: recordings and transcriptions are a vital resource for language learning by younger generations.\nFigure 1 (obtained from the Statistics Canada website) shows the number of speakers per language in 2016 (Statistics Canada, 2017). The languages underlined in red are those with which the ILT project has interacted in some way. These census numbers are controversial. This figure is included to give the\n1See https://www.thecanadianencyclopedia.ca/en/article/indian-act, https://indigenousfoundations.arts.ubc.ca/the_indian_ act/.\nnon-expert reader a general idea of the number of speakers of each language; for detailed demographic information, one should consult experts on each individual language."
    }, {
      "heading" : "3 Text-based subprojects",
      "text" : "This section includes work on polysynthetic verb conjugation, on tools for the Inuktut language, and on text prediction for mobile devices."
    }, {
      "heading" : "3.1 Polysynthetic Verb Conjugation",
      "text" : ""
    }, {
      "heading" : "3.1.1 Background",
      "text" : "Early in the project, the director of a community-based adult immersion school asked whether our project would be able to create a software-based verb conjugator for the language, Kanyen’kéha, taught at the school. This school, located in an Indigenous territory in Ontario, takes students through 2000 hours of Kanyen’kéha immersion over two years. Kanyen’kéha is an Iroquoian language, commonly known as “Mohawk”, spoken in territory that spans present-day Ontario, Quebec, and New York State. Iroquoian languages are highly polysynthetic. Learning and teaching verbs in Kanyen’kéha is a formidable task. There are millions of conjugations for even the most common verbs. It is therefore only possible to create a verb conjugator with reasonable coverage in software, not on paper. Verb roots in Kanyen’kéha are bound morphemes: they do not, on their own, constitute words. A pronominal prefix, a verb root and an aspectual ending are always present (for commands the aspectual ending is null). A verb can contain pre- and post-pronominal prefixes and pre-aspectual suffixes. Kanyen’kéha has 14 stand-alone or ‘free’ pronouns, and 72 bound pronouns, meaning the combinatorial inflectional possibilities are much larger than in English, French, or other European languages. This complexity adds to the difficulty of teaching the language: even learning how to properly conjugate a modest number of verbs requires a significant amount of work. For detailed information on Kanyen’kéha syntax, see (Kanatawakhon, 2002). In 2017, we began building the verb conjugator for Kanyen’kéha described below. We are now building a verb conjugator for Michif, an unrelated polysynthetic language. For each language, we have been working with members of the relevant community to develop a conjugator that does not replace learners’ experience of studying verbal morphology at schools in the community, but that complements it. These conjugators rely on finite-state transducers (FSTs) which are rule-based. Rulebased approaches may seem outdated in contrast to statistical or neural methods. However, with most Indigenous languages, existing corpora are not large enough to produce accurate statistical models."
    }, {
      "heading" : "3.1.2 VerbMaker",
      "text" : "Since many Indigenous languages have rich inflectional morphology, we planned to carry out the educator’s request by building a software tool that could be extended beyond Kanyen’kéha to other languages. The structure of the VerbMaker2 ecosystem consists of two main parts: a front-end interface (VerbMaker UI) implemented in Angular, and a back-end database and API implemented in Python (Fastapi & CouchDB). Initially, VerbMaker was tightly coupled to the instance’s language model, specifically Foma (Hulden, 2009). However, all data is now stored in a database. This architecture allows verb conjugators to be made without requiring knowledge about FSTs."
    }, {
      "heading" : "3.1.3 VerbMaker Instances",
      "text" : "The first instance of VerbMaker, called Kanyen’kéhaVerbs,3 models the Western dialect of Kanyen’kéha that is taught at the school. Kanyen’kéhaVerbs means “It Makes Words” in the language. We have since also created an instance for the Eastern dialect, spoken in the Kahnawà:ke community in Quebec. Additional sample instances have been made for other languages (e.g., French). To design the rules encoded in the first Kanyen’kéhaVerbs FST, we relied on a textbook that describes the Western dialect (Self Citation, 2017), along with writings on other Kanyen’kéha dialects and the 2Name modified for this anonymous submission. 3Name modified for this anonymous submission.\nclosely related language Oneida. We benefited from a close relationship with the staff of the immersion school, who added hundreds of new verbs to the system through a collaborative development process whereby new verb stems are entered in a spreadsheet and are then compiled into an FST lexicon formalism (lexc). Quality control for this Western version of Kanyen’kéhaVerbs was done by teachers at the school and bymembers of the research team. Teammembersmade several in-person visits to the school to participate in multi-day collaborative sessions to design, evaluate, and improve the user interface (UI). Creation of the Eastern (Kahnawà:ke) version relied heavily on the expertise of a single gifted individual who is familiar with that dialect. The current Western version of Kanyen’kéhaVerbs contains over 250 verb stems while the Eastern version has approximately 600. Both versions contain all bound pronouns and 12 tense/aspect combinations (command, habitual forms, perfective forms and punctual forms including the definite past, conditional and future forms) and are capable of generating over 100,000 conjugated forms."
    }, {
      "heading" : "3.1.4 VerbMaker UI",
      "text" : "The UI is of prime importance, if Kanyen’kéhaVerbs is to be useful to students. The process for prototyping, designing, and evaluating the VerbMaker UI involved multiple in-person visits for defining the requirements, hiring in-community designers, and extensive user interface and user experience (UI/UX) review. The resulting UI is interactive, highly theme-able, translated into English, French and Kanyen’kéha, available on the web and mobile as a progressive web application, and available offline. There are two main views within the application, the ‘Wordmaker’ and the ‘Tableviewer’. The ‘Wordmaker’ is the simplest view and guides the user linearly through three questions to create a single conjugation, what the action is, who is doing it, and when it’s happening. This reflects three basic categories in VerbMaker. It is assumed that each conjugation will minimally require a root and some sort of pronominal inflection. The third category is the most open and could be used for other ‘options’ beyond the temporal options suggested by the demonstration version of VerbMaker. The ‘Tableviewer’ is the more advanced view. It allows users to create paradigm tables of conjugations instead of single output forms. Here users can select multiple options from the three categories to create a query for many conjugated forms. The user can then either interact with the conjugations in a tabular grid format (see Figure 2, left) or in a ‘tree’ format (see Figure 2, right). Users can also download the conjugations as a Microsoft Word Document, CSV file, or a formatted LATEX file. This functionality allows users to create and print out tables for making their own flashcards or study tools."
    }, {
      "heading" : "3.1.5 Work on Michif",
      "text" : "The work on a verb conjugator for Michif began after our team was asked by a language revitalization activist whether we could implement a system like Kanyen’kéhaVerbs for Michif. Michif is a mixed, highly polysynthetic language which arose during the 19th century from the intermarriage between French fur traders and Cree and Ojibwe women (Rosen and Souter, 2009). Their descendants are the Métis people, whose official language is Michif. Michif takes most of its nominal patterns from French, and its verbal patterns from Cree. There is a high degree of regional variation (Sammons, 2019). As is the case for many Indigenous languages, there is a shortage of data and formal documentation for the language. In collaboration with a Michif language activist, our team has been building Li Verb kaa-Ooshitahk di Michif, a finite-state transducer (FST) which models the verbal morphology of Michif according to the lexc formalism stated in Beesley and Karttunen (2003). The current implementation allows for the conjugation of 22 verb stems, which generates 6791 possible verb forms. Though Li Verb kaa-Ooshitahk di Michif relies on FSTs, just as Kanyen’kéhaVerbs does, it is not yet integrated into the VerbMaker code base; we have started working on this integration. The Li Verb kaa-Ooshitahk di Michif FST serves as the back-end to an app that will allow users to conjugate verbs in Michif without having any previous training relating to FSTs or linguistics. The app contains a simple interface that walks a user through building a verb conjugation in Michif. This interface will be available for both Android and iOS, and as a web application. The application will be available for use offline (after initial download) and deliberately avoids the use of over-technical linguistic terminology, to make it easier for learners to ask about the language directly from speakers in informal Métis community settings."
    }, {
      "heading" : "3.2 Tools for Inuktut (including machine translation)",
      "text" : "Inuit languages, which are polysynthetic, are spoken across Arctic Canada. The Government of Nunavut uses the term Inuktut to represent all of the Inuit language varieties spoken in Nunavut. We created and released the sentence-aligned Inuktut–English “Nunavut Hansard” corpus based on the proceedings of the Legislative Assembly of Nunavut from April 1999 to June 2017. We believe this to be the largest parallel corpus for an Indigenous language of the Americas or a polysynthetic language released to date (1.3 million aligned sentence pairs). The corpus is available online under the CC-BY-4.0 license; creation of the corpus and preliminary machine translation experiments are described in (Self citation removed for blind review, 2020a).4 The existence of the Nunavut Hansard has made possible a shared task for the Inuktut–English language pair in the 2020 Workshop for Machine Translation.5\nSeveral years ago, Canadian researchers built a search engine for English-to-Inuktut translators, WeBInuk (Désilets et al., 2008). Given an English word or phrase, it would return matching Inuktut–English sentence pairs from a parallel corpus (the portion of the Nunavut Hansard that was available at the time). Unfortunately, this online service lapsed for several years. One of the goals of our project was to create a similar tool, but to make it bidirectional—i.e., to allow users to enter Inuktut search terms as well as English ones. We also aimed at providing other tools for Inuktut: a dictionary, a gister (i.e. a service that provides rough English renderings of the component morphemes of an Inuktut word), a spell checker, etc. Inuktut words resemble short phrases in English. They are composed by stringing together: a root (about 2000 possibilities) and a fairly long sequence of morphemes (typically 4-5 morphemes, but potentially up to 9) taken from a set of roughly 450 affixes (verbs, adjectives, etc.), 1300 verb endings, and 320 noun endings. Unlike Kanyen’kéha, where the surface forms of morphemes are usually invariant, many Inuktut morphemes have surface forms that change in different contexts. The same surface form may correspond to different morphemes. Many, perhaps most, Inuktut words in a given text will not have occurred before. Thus, building a word-based dictionary with good coverage is unrealistic. However, one can decompose the Inuktut word\n4A pre-release version of the same corpus was used for machine translation experiments during a 2019 JSALT workshop (Schwartz et al., 2020)\n5http://www.statmt.org/wmt20/\ninto a sequence of morphemes, then look up the meanings of the morphemes. Similarly, one could easily build a version of WeBInuk that would allow users to look up whole Inuktut words, but it would not have high coverage; users would often enter words for which exact matches cannot be found in the parallel corpus. It would be more helpful to supply them with Inuktut words in the corpus that share the root and a few other morphemes with the word they are interested in. Nevertheless, by building on a morphological analyzer created earlier, we were able to create five prototype apps: 1. a “morpheme example search” app that, given a morpheme, shows examples of its use; 2. a gister that, given Inuktut text, returns not only the meanings of the morphemes in the words composing it, but also sentence pairs that may have related meanings; 3. a search tool for Inuktut– English sentence pairs similar to WeBInuk (but bidirectional); 4. an Inuktut spell checker that, if it can’t find a word, returns the most similar words which are known to be correctly spelled and the longest correctly spelled head and tail in the word; and 5. amorphological search engine that, given an Inuktut word, searches for its five most frequent morphological variants. All will soon be released."
    }, {
      "heading" : "3.3 Predictive Text",
      "text" : "Writers in majority languages have benefited from predictive text suggestions on their smartphone keyboards. Predictive text requires data—typically mined from large text corpora—to generate an n-gram language model (van Esch et al., 2019); however, many Indigenous language communities either do not have extensive text corpora, or the data are too culturally sensitive to share outside of their community. We have collaborated with an open-source keyboard creation platform, to add a predictive text platform to their suite of smartphone keyboards and their keyboard development tool. We have “decentralized” the creation of predictive text models, by making it possible for language activists, using a spreadsheet of words in their language, to provide predictive text suggestions for their community. Thus, the language activists are in charge of their own data, and can choose how they share their predictive text keyboard. This contrasts with Gboard (van Esch et al., 2019) where a centralized entity mines text corpora and creates a language-specific model. Since we expect data to be sparse, the language models our software generates are word-level unigrams. We have implemented predictive text for one language so far, SENĆOŦEN. Members of that community report that it makes typing in their language, which has an unusual orthography, dramatically easier. We are working to make the software easier to use, so that communities can implement predictive text for their own languages."
    }, {
      "heading" : "4 Speech-based subprojects",
      "text" : "Traditionally, Indigenous languages in Canada were spoken,6 not written. Thus, several subprojects focused on applications of speech technology."
    }, {
      "heading" : "4.1 Work on Audio Segmentation and Speech Recognition",
      "text" : "Transcription and further annotation of speech recordings are the biggest part of the workload in most language documentation and conservation projects. The pace at which speech is being recorded in Indigenous languages in Canada and indeed, in minority languages across the world, greatly outstrips the pace at which field linguists and Indigenous language activists can transcribe these recordings. This is the “transcription bottleneck” (Cox et al., 2019). One of the biggest subprojects involved developing tools based on automatic speech recognition (ASR) to relieve both this bottleneck, and a related one that could be termed the “indexation bottleneck”. Some communities have thousands of hours of recordings of speech in their languages made years earlier, with no means of searching through them for relevant words or phrases. Though it may be impractical to transcribe all that speech now, ASR-based audio indexation might make search possible. This subproject faced two main challenges. First, very little data for training ASR systems for Indigenous languages in Canada was available. Second, ASR research has focused on languages that are in the low to medium range of morphological complexity. Most Indigenous languages in Canada are in the high range. Inuktut is known to be particularly morphologically complex, as measured by mean distance\n6Or signed, though our current work does not touch on Indigenous sign languages of Canada.\nto novel type (Schwartz et al., 2020). To address these issues, this subproject had three themes: data collection and transcription, creation of tools to facilitate transcription, and ASR experiments."
    }, {
      "heading" : "4.1.1 Data Collection and Transcription",
      "text" : "Four transcription activities were carried out as core parts of this project, as shown in Table 1."
    }, {
      "heading" : "4.1.2 Audio Segmentation",
      "text" : "This theme yielded a set of tools to make the early stages of processing recorded speech easier, prior to transcription. These were packaged as Web services and are available for researchers and communities directly on their platform or through an ELAN extension.7\nThey are starting to be deployed in the field, and we have received anecdotal reports of significant productivity improvements due to their use in speech preprocessing. The services include: DNN-VAD: deep neural net (DNN) voice activity detection, which extracts segments containing speech (versus silence, noise, etc.); Diarization: identifies who spoke when in a recording; Language Retrieval: finds segments which are spoken in a particular language (among 32 languages); Speaker Retrieval: finds segments spoken by a particular speaker, given a short sample of the speaker’s voice; Multichannel Voice Activity Detection: detects segments containing speech separately for each track in a multichannel recording with multiple microphones; Language Independent Text-to-Audio Alignment: works with any grapheme-to-IPA phoneme table."
    }, {
      "heading" : "4.1.3 Automatic Speech Recognition (ASR)",
      "text" : "ASR experiments so far have focused on Inuktut and East Cree. They have highlighted major differences between these two polysynthetic languages. Inuktut is highly polysynthetic, causing a word-based language model (LM) to be ineffective. Even with a dictionary containing 300,000 words (from 6 million words of the Nunavut Hansard), 60% of the words in an unseen story text were out of vocabulary (OOV). So the experimenters tried syllables and morphemes as sub-word units and found that syllables gave the lowest word error rate (WER). The WER for the reconstituted words obtained from different sub-word units is shown in Table 2 (for acoustic models trained on 40 hours of transcribed Inuktut speech). B_ and _E markers are used to show boundaries for morphemes and syllables; experiments with boundaries chosen by deep neural nets (DNNs) were also carried out. The LM predicts the start or end of the words through these markers so that syllable or morpheme sequences can be converted back to word sequences. When training data is increased from 40 hours to 80 hours, the speaker independent (SI) WER decreases from 74.3% to 72.3%. For East Cree, a word-based LM with a 30,000 word dictionary obtains a much lower OOV rate. Training a word-based LM for Cree frommuch less text data than for Inuktut (260,000 words of text from reports from Cree organisations and scriptures text) still yields only 25% OOV rate on video stories and 9% OOV rate on scriptures. Video stories are very different from the LM text, and so they have a higher OOV rate than the scriptures development text. Decoding Cree speech using this LM yields a 69.0% WER on video stories (speaker independent = SI WER) and 24.6% on scriptures (speaker dependent = SDWER). Note that SI WER is lower for Cree than for Inuktut, even when Inuktut benefits from twice as\n7A widely-used annotation tool available at https://archive.mpi.nl/tla/elan/; see (Wittenburg et al., 2006) for an overview.\nmuch acoustic training data (80 hours instead of 40 hours) and far more LM training data: 69.0% WER for Cree versus 72.3% for Inuktut. The speaker-dependent (SD) ASR result for East Cree above is good news: with a few hours of transcribed audio from a single speaker, the WER on new data from the same speaker was 24.6%. Phoneme error rate (PER) in this SD condition was 8.7%. This is well below the 30% PER considered good enough to significantly speed up themanual transcription process (if transcription is done by a non-native speaker, as is often the case in field linguistics) (Adams et al., 2018). It took only 3 hours of transcribed audio to achieve this result. A similar SD experiment was run with Inuktut, with 3 hours of training from one speaker, and the same syllable LM as for the SI case. This resulted in 67.3% WER and 18.4% PER. So even for the SD case, Inuktut has higher WER and PER than East Cree. Experiments on other Indigenous polysynthetic languages are needed to see where they fall along the East Cree to Inuktut spectrum, in terms of SI and SD ASR difficulty. Field linguists often record many hours of speech from each of a very small number of fluent speakers: the Elders of an Indigenous community. If it turns out that good SDASR is possible for several Indigenous languages, one could imagine a common mode of work in which an SD system is trained on the first few hours of speech from an Elder, then used to produce a first-draft transcription of the remaining hours."
    }, {
      "heading" : "4.2 Read-along audiobooks",
      "text" : "A subproject on software that supports “read-along/sing-along” activities was inspired by the East Cree online activities pioneered by Carleton University (see eastcree.org). Interactive read-along/sing-along audiobooks that highlight words as they are spoken and allow students to click on words to hear them aloud are well liked by both students and teachers, but their creation is labour intensive, and requires expertise with specialized software like ELAN or Audacity. We seek to make the creation of such activities quick and easy, without requiring the creator to manually align each word. Fortunately, text/audio alignment (also called “forced alignment”) is feasible to perform in a “zeroshot” scenario (that is, where there is no data available in the language in question). One constructs an approximate mapping between target language phonemes and phonemes in a high-resource “donor” language (in our case, English), converts the target document into phones in the donor language, and trains an acoustic model on the donor language to recognize when each word is spoken. This is the assumed default when working with a new language in the Festival toolkit (Black et al., 1998). Based on this concept, our Read-Along Tool8 allows a user to easily create a text/speech alignment system for a new language without being a specialist in speech technology. Read-Along Tool currently supports 22 languages; among Indigenous languages spoken in Canada it supports Anishinaabemowin (Ojibway), Atikamekw, Dakelh, East Cree, Gitxsan, Heiltsuk, Inuktut, Kanyen’kéha, Kwak’wala, SENĆOŦEN, Seneca, Tagish, Tŝilhqot’in, and Tsuut’ina (the other eight are not spoken in Canada). Adding a new language is the work of only a few hours, depending on the complexity of the language’s orthography. Read-Along Tool can already create high-quality interactive webpages (see Figure 3), MP4 movies, and EPUB documents, and can export in ELAN, TextGrid (PRAAT), and subtitle formats. A user-friendly interface is currently in development.\n8Name modified for this anonymous submission."
    }, {
      "heading" : "5 Other Subprojects",
      "text" : "Space is lacking to describe several other subprojects of this project (for these see the full technical report (Self citation removed for blind review, 2020b)). They include work on text-to-speech (TTS) for Kanyen’kéha, and subprojects carried out by external organizations (mostly Indigenous-run). The latter include enhancement of online language courses for East Cree and Innu, development of online courses for Plains Cree, Kwak’wala, Michif, and Naskapi, improvements to a role-playing game with Swampy Cree content, two subprojects for training Indigenous language activists in data collection methodologies, and data collection efforts for Plains Cree, Kanyen’kéha, Kwak’wala, Michif, Nsyilxcn, Tŝilhqot’in, and Tsuut’ina."
    }, {
      "heading" : "6 Future Work",
      "text" : "In accordance with the empowerment goal of the project, our focus in Phase II will be on making the technologies described above easier for Indigenous communities to deploy themselves without outside expertise. We have alreadymademajor progress on developing a framework for building verb conjugators that will greatly reduce the need for specialized knowledge."
    } ],
    "references" : [ {
      "title" : "Evaluating Phonemic Transcription of Low-Resource Tonal Languages for Language Documentation",
      "author" : [ "Oliver Adams", "Trevor Cohn", "Graham Neubig", "Steven Bird", "Alexis Michaud." ],
      "venue" : "Proc. LREC, pages 3356– 3365.",
      "citeRegEx" : "Adams et al\\.,? 2018",
      "shortCiteRegEx" : "Adams et al\\.",
      "year" : 2018
    }, {
      "title" : "Finite State Morphology",
      "author" : [ "Kenneth R. Beesley", "Lauri Karttunen." ],
      "venue" : "CSLI Publications.",
      "citeRegEx" : "Beesley and Karttunen.,? 2003",
      "shortCiteRegEx" : "Beesley and Karttunen.",
      "year" : 2003
    }, {
      "title" : "The Festival speech synthesis system",
      "author" : [ "Alan W. Black", "Paul Taylor", "Richard Caley." ],
      "venue" : "http://www.festvox.org/festival.",
      "citeRegEx" : "Black et al\\.,? 1998",
      "shortCiteRegEx" : "Black et al\\.",
      "year" : 1998
    }, {
      "title" : "Rampton, andKayRichardson",
      "author" : [ "DeborahCameron", "Elizabeth Frazer", "PenelopeHarvey", "M.B.H" ],
      "venue" : null,
      "citeRegEx" : "DeborahCameron et al\\.,? \\Q1992\\E",
      "shortCiteRegEx" : "DeborahCameron et al\\.",
      "year" : 1992
    }, {
      "title" : "Cultural continuity as a hedge against suicide in Canada’s First Nations",
      "author" : [ "Michael J. Chandler", "Christopher Lalonde." ],
      "venue" : "Transcultural Psychiatry, 35(4):191–219.",
      "citeRegEx" : "Chandler and Lalonde.,? 1998",
      "shortCiteRegEx" : "Chandler and Lalonde.",
      "year" : 1998
    }, {
      "title" : "Taking aim at the “transcription bottleneck”: Integrating speech technology into language documentation and conservation",
      "author" : [ "Christopher Cox", "Gilles Boulianne", "Jahangir Alam." ],
      "venue" : "http://hdl.handle.net/10125/44841. Presentation at the 6th International Conference on Language Documentation and Conservation (ICLDC), University of Hawai’i at Mānoa, Honolulu, HI.",
      "citeRegEx" : "Cox et al\\.,? 2019",
      "shortCiteRegEx" : "Cox et al\\.",
      "year" : 2019
    }, {
      "title" : "Researchmodels, community engagement, and linguistic fieldwork: Reflections on working within Canadian Indigenous communities",
      "author" : [ "Ewa Czaykowska-Higgins." ],
      "venue" : "Language documentation & conservation, 3(1):182–215.",
      "citeRegEx" : "Czaykowska.Higgins.,? 2009",
      "shortCiteRegEx" : "Czaykowska.Higgins.",
      "year" : 2009
    }, {
      "title" : "WeBiText: Building large heterogeneous translationmemories from parallel web content",
      "author" : [ "Alain Désilets", "Benoît Farley", "Geneviève Patenaude", "Marta Stojanovic." ],
      "venue" : "InProceedings of Translating and the Computer, volume 30. International Association for Advancement in Language Technology.",
      "citeRegEx" : "Désilets et al\\.,? 2008",
      "shortCiteRegEx" : "Désilets et al\\.",
      "year" : 2008
    }, {
      "title" : "Colonial violence in sixties scoop narratives: from In Search of April Raintree to A Matter of Conscience",
      "author" : [ "Petra Fachinger." ],
      "venue" : "Studies in American Indian Literatures, 31(1-2):115.",
      "citeRegEx" : "Fachinger.,? 2019",
      "shortCiteRegEx" : "Fachinger.",
      "year" : 2019
    }, {
      "title" : "Final report of the truth and reconciliation commission",
      "author" : [ "Government of Canada." ],
      "venue" : "http://nctr.ca/reports.php.",
      "citeRegEx" : "Canada.,? 2015",
      "shortCiteRegEx" : "Canada.",
      "year" : 2015
    }, {
      "title" : "Aboriginal language knowledge and youth suicide",
      "author" : [ "Darcy Hallett", "Michael J. Chandler", "Christopher E. Lalonde." ],
      "venue" : "Cognitive Development, 22(3):392–399.",
      "citeRegEx" : "Hallett et al\\.,? 2007",
      "shortCiteRegEx" : "Hallett et al\\.",
      "year" : 2007
    }, {
      "title" : "Foma: a finite-state compiler and library",
      "author" : [ "Mans Hulden." ],
      "venue" : "Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics, pages 29–32. Association for Computational Linguistics.",
      "citeRegEx" : "Hulden.,? 2009",
      "shortCiteRegEx" : "Hulden.",
      "year" : 2009
    }, {
      "title" : "Yonteweyenhstahkwa Kanyen’kéha: a Mohawk Teaching Dictionary",
      "author" : [ "David Kanatawakhon." ],
      "venue" : "Centre for Research and Teaching of Canadian Native Languages, University of Western Ontario.",
      "citeRegEx" : "Kanatawakhon.,? 2002",
      "shortCiteRegEx" : "Kanatawakhon.",
      "year" : 2002
    }, {
      "title" : "Issues with māori sovereignty over māori language data",
      "author" : [ "Te Taka Keegan." ],
      "venue" : "url: http://video.web.gov.bc.ca/ public/fpcc/letlanguageslive.html.",
      "citeRegEx" : "Keegan.,? 2019",
      "shortCiteRegEx" : "Keegan.",
      "year" : 2019
    }, {
      "title" : "Community, identity, wellbeing: the report of the Second National Indigenous Languages Survey",
      "author" : [ "Doug Marmion", "Kazuko Obata", "Jakelin Troy." ],
      "venue" : "Australian Institute of Aboriginal and Torres Strait Islander Studies Canberra.",
      "citeRegEx" : "Marmion et al\\.,? 2014",
      "shortCiteRegEx" : "Marmion et al\\.",
      "year" : 2014
    }, {
      "title" : "The state of Indigenous languages in Canada: Trends and prospects in language retention, revitalization and revival",
      "author" : [ "Mary Jane Norris." ],
      "venue" : "Canadian Diversity, 15(1):22–31.",
      "citeRegEx" : "Norris.,? 2018",
      "shortCiteRegEx" : "Norris.",
      "year" : 2018
    }, {
      "title" : "Cultural continuity, traditional Indigenous language, and diabetes in Alberta First Nations: A mixed methods study",
      "author" : [ "Richard T. Oster", "Angela Grier", "Rick Lightning", "Maria J. Mayan", "Ellen L. Toth." ],
      "venue" : "International journal for equity in health, 13(1):92.",
      "citeRegEx" : "Oster et al\\.,? 2014",
      "shortCiteRegEx" : "Oster et al\\.",
      "year" : 2014
    }, {
      "title" : "Language revitalization",
      "author" : [ "Aidan Pine", "Mark Turin." ],
      "venue" : "Oxford Research Encyclopedia of Linguistics. Oxford University Press.",
      "citeRegEx" : "Pine and Turin.,? 2017",
      "shortCiteRegEx" : "Pine and Turin.",
      "year" : 2017
    }, {
      "title" : "Colonialism’s and postcolonialism’s fellow traveller: the collection, use and misuse of data on indigenous people",
      "author" : [ "Ian Pool." ],
      "venue" : "Indigenous Data Sovereignty, pages 57–76.",
      "citeRegEx" : "Pool.,? 2016",
      "shortCiteRegEx" : "Pool.",
      "year" : 2016
    }, {
      "title" : "Indigenous language immersion schools for strong Indigenous identities",
      "author" : [ "Jon Reyhner." ],
      "venue" : "Heritage Language Journal, 7(2):138–152.",
      "citeRegEx" : "Reyhner.,? 2010",
      "shortCiteRegEx" : "Reyhner.",
      "year" : 2010
    }, {
      "title" : "Indigenous languages in Canada",
      "author" : [ "Keren Rice." ],
      "venue" : "The Canadian Encyclopedia. Historica Canada. https: //www.thecanadianencyclopedia.ca/en/article/aboriginal-people-languages (Accessed on May 6, 2020.).",
      "citeRegEx" : "Rice.,? 2008",
      "shortCiteRegEx" : "Rice.",
      "year" : 2008
    }, {
      "title" : "Language revitalization in a multilingual community: The case of Michif",
      "author" : [ "Nicole Rosen", "Heather Souter." ],
      "venue" : "1st International Conference on Language Documentation and Conservation (ICLDC), Honolulu.",
      "citeRegEx" : "Rosen and Souter.,? 2009",
      "shortCiteRegEx" : "Rosen and Souter.",
      "year" : 2009
    }, {
      "title" : "Nominal classification in Michif",
      "author" : [ "Olivia N. Sammons." ],
      "venue" : "Ph.D. thesis, University of Alberta, DOI: 10.7939/r3b8sq-xz05.",
      "citeRegEx" : "Sammons.,? 2019",
      "shortCiteRegEx" : "Sammons.",
      "year" : 2019
    }, {
      "title" : "Neural polysynthetic language modelling. https://arxiv.org/abs/2005.05477",
      "author" : [ "Lane Schwartz", "Francis Tyers", "Lori Levin", "Christo Kirov", "Patrick Littell", "Chi-kiu Lo", "Emily Prud’hommeaux", "Hyunji Hayley Park", "Kenneth Steimel", "Rebecca Knowles", "Jeffrey Micher", "Lonny Strunk", "Han Liu", "Coleman Haley", "Katherine J. Zhang", "Robbie Jimmerson", "Vasilisa Andriyanets", "Aldrian Obaja Muis", "Naoki Otani", "Jong Hyuk Park", "Zhisong Zhang" ],
      "venue" : null,
      "citeRegEx" : "Schwartz et al\\.,? \\Q2020\\E",
      "shortCiteRegEx" : "Schwartz et al\\.",
      "year" : 2020
    }, {
      "title" : "Proportion of mother tongue responses for various regions in Canada, 2016 census",
      "author" : [ "Statistics Canada." ],
      "venue" : "https://www12.statcan.gc.ca/census-recensement/2016/dp-pd/dv-vd/lang/index-eng.cfm.",
      "citeRegEx" : "Canada.,? 2017",
      "shortCiteRegEx" : "Canada.",
      "year" : 2017
    }, {
      "title" : "Writing across the world’s languages: Deep internationalization for Gboard, the Google keyboard. https://arxiv.org/abs/1912.01218",
      "author" : [ "Daan van Esch", "Elnaz Sarbar", "Tamar Lucassen", "Jeremy O’Brien", "Theresa Breiner", "Manasa Prasad", "Evan Crew", "Chieu Nguyen", "Françoise Beaufays" ],
      "venue" : null,
      "citeRegEx" : "Esch et al\\.,? \\Q2019\\E",
      "shortCiteRegEx" : "Esch et al\\.",
      "year" : 2019
    }, {
      "title" : "Healing through language: Positive physical health effects of indigenous language use",
      "author" : [ "Douglas H. Whalen", "Margaret Moss", "Daryl Baldwin." ],
      "venue" : "F1000Research, 5.",
      "citeRegEx" : "Whalen et al\\.,? 2016",
      "shortCiteRegEx" : "Whalen et al\\.",
      "year" : 2016
    }, {
      "title" : "ELAN: A professional framework for multimodality research",
      "author" : [ "Peter Wittenburg", "Hennie Brugman", "Albert Russel", "Alex Klassmann", "Han Sloetjes." ],
      "venue" : "LREC. European Language Resources Association (ELRA).",
      "citeRegEx" : "Wittenburg et al\\.,? 2006",
      "shortCiteRegEx" : "Wittenburg et al\\.",
      "year" : 2006
    } ],
    "referenceMentions" : [ {
      "referenceID" : 6,
      "context" : "Different approaches have been taken to linguistic research involving Indigenous languages (Cameron et al., 1992; Czaykowska-Higgins, 2009).",
      "startOffset" : 91,
      "endOffset" : 139
    }, {
      "referenceID" : 18,
      "context" : "We were determined to break with the unfortunate history of academics and government departments refusing to return linguistic data to the Indigenous communities from which it was collected (see (Pool, 2016), (Keegan, 2019), and (Brinklow et al.",
      "startOffset" : 195,
      "endOffset" : 207
    }, {
      "referenceID" : 13,
      "context" : "We were determined to break with the unfortunate history of academics and government departments refusing to return linguistic data to the Indigenous communities from which it was collected (see (Pool, 2016), (Keegan, 2019), and (Brinklow et al.",
      "startOffset" : 209,
      "endOffset" : 223
    }, {
      "referenceID" : 20,
      "context" : "There are about 70 Indigenous languages from 10 distinct language families currently spoken in Canada (Rice, 2008).",
      "startOffset" : 102,
      "endOffset" : 114
    }, {
      "referenceID" : 8,
      "context" : "Many Indigenous children were forcibly removed from their communities and placed in compulsory boarding schools (known as Residential Schools) or adopted by non-Indigenous families (known as the Sixties Scoop (Fachinger, 2019)).",
      "startOffset" : 209,
      "endOffset" : 226
    }, {
      "referenceID" : 17,
      "context" : "The resilience of Indigenous communities can be seen in the many ways that they have resisted assimilation and continued to teach, learn, and speak their languages (Pine and Turin, 2017).",
      "startOffset" : 164,
      "endOffset" : 186
    }, {
      "referenceID" : 26,
      "context" : "The benefits associated with the use of these languages are wide-ranging (Whalen et al., 2016; Reyhner, 2010; Oster et al., 2014; Marmion et al., 2014).",
      "startOffset" : 73,
      "endOffset" : 151
    }, {
      "referenceID" : 19,
      "context" : "The benefits associated with the use of these languages are wide-ranging (Whalen et al., 2016; Reyhner, 2010; Oster et al., 2014; Marmion et al., 2014).",
      "startOffset" : 73,
      "endOffset" : 151
    }, {
      "referenceID" : 16,
      "context" : "The benefits associated with the use of these languages are wide-ranging (Whalen et al., 2016; Reyhner, 2010; Oster et al., 2014; Marmion et al., 2014).",
      "startOffset" : 73,
      "endOffset" : 151
    }, {
      "referenceID" : 14,
      "context" : "The benefits associated with the use of these languages are wide-ranging (Whalen et al., 2016; Reyhner, 2010; Oster et al., 2014; Marmion et al., 2014).",
      "startOffset" : 73,
      "endOffset" : 151
    }, {
      "referenceID" : 4,
      "context" : "For instance, there is a correlation between Indigenous language use and a decrease in youth suicide rates on reserves in British Columbia (Chandler and Lalonde, 1998; Hallett et al., 2007).",
      "startOffset" : 139,
      "endOffset" : 189
    }, {
      "referenceID" : 10,
      "context" : "For instance, there is a correlation between Indigenous language use and a decrease in youth suicide rates on reserves in British Columbia (Chandler and Lalonde, 1998; Hallett et al., 2007).",
      "startOffset" : 139,
      "endOffset" : 189
    }, {
      "referenceID" : 15,
      "context" : "However, many communities face decreasing numbers of first language (mother tongue) speakers, due to declining language transmission rates (Norris, 2018).",
      "startOffset" : 139,
      "endOffset" : 153
    }, {
      "referenceID" : 12,
      "context" : "For detailed information on Kanyen’kéha syntax, see (Kanatawakhon, 2002).",
      "startOffset" : 52,
      "endOffset" : 72
    }, {
      "referenceID" : 11,
      "context" : "Initially, VerbMaker was tightly coupled to the instance’s language model, specifically Foma (Hulden, 2009).",
      "startOffset" : 93,
      "endOffset" : 107
    }, {
      "referenceID" : 21,
      "context" : "Michif is a mixed, highly polysynthetic language which arose during the 19th century from the intermarriage between French fur traders and Cree and Ojibwe women (Rosen and Souter, 2009).",
      "startOffset" : 161,
      "endOffset" : 185
    }, {
      "referenceID" : 22,
      "context" : "There is a high degree of regional variation (Sammons, 2019).",
      "startOffset" : 45,
      "endOffset" : 60
    }, {
      "referenceID" : 7,
      "context" : "5 Several years ago, Canadian researchers built a search engine for English-to-Inuktut translators, WeBInuk (Désilets et al., 2008).",
      "startOffset" : 108,
      "endOffset" : 131
    }, {
      "referenceID" : 23,
      "context" : "4A pre-release version of the same corpus was used for machine translation experiments during a 2019 JSALT workshop (Schwartz et al., 2020) 5http://www.",
      "startOffset" : 116,
      "endOffset" : 139
    }, {
      "referenceID" : 5,
      "context" : "This is the “transcription bottleneck” (Cox et al., 2019).",
      "startOffset" : 39,
      "endOffset" : 57
    }, {
      "referenceID" : 27,
      "context" : "nl/tla/elan/; see (Wittenburg et al., 2006) for an overview.",
      "startOffset" : 18,
      "endOffset" : 43
    }, {
      "referenceID" : 0,
      "context" : "This is well below the 30% PER considered good enough to significantly speed up themanual transcription process (if transcription is done by a non-native speaker, as is often the case in field linguistics) (Adams et al., 2018).",
      "startOffset" : 206,
      "endOffset" : 226
    }, {
      "referenceID" : 2,
      "context" : "This is the assumed default when working with a new language in the Festival toolkit (Black et al., 1998).",
      "startOffset" : 85,
      "endOffset" : 105
    } ],
    "year" : 2020,
    "abstractText" : "This paper surveys the first, three-year phase of a project that is developing software to assist Indigenous communities in Canada in their efforts to preserve their languages and extend their use. The project aimed to work within the empowerment paradigm, where collaboration with communities and fulfillment of their goals is central. Since many of the technologies we developed were in response to community needs, the project ended up as a collection of diverse subprojects, including the creation of a sophisticated framework for building verb conjugators for highly inflectional polysynthetic languages (such as Kanyen’kéha, in the Iroquoian language family), release of what is probably the largest available corpus of sentences in a polysynthetic language (Inuktut) aligned with English sentences and experiments with machine translation (MT) systems trained on this corpus, free online services based on automatic speech recognition (ASR) for easing the transcription bottleneck for recordings of speech in Indigenous languages (and other languages), software for implementing text prediction and read-along audiobooks for Indigenous languages, and several other subprojects.",
    "creator" : "LaTeX with hyperref"
  }
}