[{"rid": "0", "reviewer": null, "report": {"main": "The paper presents an annotated dataset for identify and categorize language that is patronizing or condescending (PCL) towards vulnerable communities. The annotation task is twofold: (a) from a given set of paragraphs, identify a subset that potentially contains PCL (b) from this subset of paragraphs, identify the spans containing. PCL is categorized into 10 predefined labels and various multilabel classifiers are tested to show that PCL identification is indeed a difficult NLP task.  Strength: Problem definition and motivation is verbosely presented. Section 3 provides a great background on PCL (though I recommend the authors to add a few more examples while explaining what PCL is and what is not). The overall outcome of the work is a challenging NLP dataset which, if released publicly, could be a very valuable resource.  Weaknesses: Since this is a dataset paper, the technical limitations are not judged. However, a discussion on what modification could be applied to the vanilla classifiers to obtain performance improvement is necessary. Perhaps, it is worth proposing an incremental version of BERT based model that is tailormade for the task.  A note on how to trivially and non-trivially extend the dataset to other domains and languages should be provided.  Minor: Report kappa scores for Step-2 as well (in section 4.2.2) and provide some examples of such spans. "}, "scores": {"overall": "3", "Originality": "3", "Readability_clarity": "3", "Relevance": "5", "Reproducibility": "3", "Substance": "4"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "4", "sentences": {"main": [[0, 152], [152, 335], [335, 490], [490, 491], [491, 559], [559, 710], [710, 835], [835, 836], [836, 921], [921, 1056], [1056, 1163], [1163, 1164], [1164, 1279], [1279, 1280], [1280, 1386]]}}}]