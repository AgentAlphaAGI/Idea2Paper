[{"rid": "0", "reviewer": null, "report": {"main": "The paper describes a method for learning interpretable embeddings for words and their contexts that is based on weakly supervised word sense disambiguation. The embeddings achieve solid performance on word sense disambiguation; they substantially lag behind BERT, but surpass it in interpretability and are much more compact. The presented solution is also currently limited in a number of ways, so there is room for further improvement.\nThe method is based on training classifiers for noun supersenses. Each word can then be represented as a collection of scores from these supersenses, and such representation would be interpretable. The classifiers are trained on pseudo-annotated corpora, where some seed monosemous nouns corresponding to each supersense are automatically marked. The scores for each context are combined into the word embedding with a parabolic function, so as to downweigh the non-informative scores.\nStrengths: - interesting idea; - going against the mainstream approaches to contextualized meaning representations; - the choices are well-motivated; - convincing error analysis; - well-motivated, solid background in lexical semantics; Limitations: The method is currently limited to nouns, and the constructed representations are 6-dimensional (for coarse supersenses). That clearly does not have enough expressive power for lexical semantics of all nouns, and is confirmed by the fact that MLP was able to make better use of more training data with FlauBERT. There is definitely room for improvement if the SLICE embeddings were more fine-grained, but the authors should discuss where the data for such improvements would come from. The choice of coarse senses was already motivated by data availability.\n- focus on monosemous words is necessary for pseudo-annotation, but arguably the classifiers were never taught to deal with polysemous words, and then tasked with WSD; - The description for Table 2 could be made more clearer; it is not obvious what the letters in the columns R, L, and C stand for; - Table 2: while the overall pattern for the linear model and MLP are the same, MLP reaches relatively high accuracy in all configurations. What does that say about the configurations themselves?\n- It would be great to include a section outlining how this could possibly be extended to other parts of speach. A big problem for interpretable representations is scoring words on inapplicable categories (e.g. \"animacy\" for prepositions); what's the plan for that? "}, "scores": {"overall": "4", "Originality": "4", "Readability_clarity": "5", "Relevance": "5", "Reproducibility": "4", "Substance": "4"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "4", "sentences": {"main": [[0, 158], [158, 327], [327, 439], [439, 505], [505, 637], [637, 786], [786, 925], [925, 936], [936, 956], [956, 1041], [1041, 1075], [1075, 1104], [1104, 1161], [1161, 1174], [1174, 1296], [1296, 1486], [1486, 1660], [1660, 1732], [1732, 1900], [1900, 2031], [2031, 2171], [2171, 2227], [2227, 2340], [2340, 2493]]}}}, {"rid": "1", "reviewer": null, "report": {"main": "This paper proposes a hybrid model for the representation of contextual embeddings (BERT) that aims to disambiguate French nouns at supersense level. The model's performance does not improve the BERT state of the art performance on the same corpus (FlauBERT). However, it has the advantage of making embeddings interpretable, helping in the error analysis. In the error analysis section, the main finding is that errors are due to the polysemous nature of nouns: it is not surprising since polysemy is the primary source of errors for all the WSD systems. The paper does not propose how to improve on that aspect - just using a different corpus is mentioned as a possibility, but not changes in the methodology are tried or suggested -. In other words, even if the methodology is interesting and it is true that makes the embeddings less opaque, at the moment it is not able to guarantee improvements in the results because, from error analysis, it is not possible to get insights on how to improve the hybrid embedding representations of polysemous words. "}, "scores": {"overall": "3", "Originality": "4", "Readability_clarity": "4", "Relevance": "5", "Reproducibility": "3", "Substance": "2"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "3", "sentences": {"main": [[0, 150], [150, 260], [260, 357], [357, 556], [556, 737], [737, 1057]]}}}]