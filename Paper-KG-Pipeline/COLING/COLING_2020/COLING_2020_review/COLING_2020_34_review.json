[{"rid": "0", "reviewer": null, "report": {"main": "This paper describes a morphological disambiguation task for Kinyarwanda, a Bantu language. Particularly, it describes the problem of multiple morphological analyses and the problem of finding a single correct answer given several possible stem realizations. The challenge is an interesting one, and one barely sees languages from this family represented at CL conferences, so this investigation is very welcome. The paper focuses on verb segmentation, and utilizes several resources including a morphological analyser and a manually stemmed (crowdsourced) dataset. The possible segmentations are then classified (ranked) based on a set of features. \nWhile the paper is overall well-written, its structure could be improved much more. The 'Experimental setup' section for instance does not explain exactly how the annotated dataset is being used for the experiments. If the dataset was crowdsourced, then how did the authors know which annotator was the best trained, and had better understanding of morphology ? Going further, what was the motivation behind crowdsourcing the data if the task does seem to require specialized linguistic knowledge? \nThe experimental section also describes the creation of 'invalid' segmentations which are provided as input to the classifier. Does the morphological analyser (section 3.2) play a role here? Or are the ranked segmentations then directly used to choose the best output from the analyser? This part is not clear to me. Section 3.2 could have better clarification on what exactly is its relation to the experiments being carried out. The section on 'Features' needs much more clarity and some examples. Perhaps the proposed features could be split into two sections- this section was a bit frustrating to read.\nTable 4 and Table 5 require some more explanation, particularly the active learning part- as this is not how the dataset was described earlier. Some more explanation of how fine-tuning the model was carried out would be useful as well.  Overall, I think this paper describes a good effort but structure and clarity need much more improvement. "}, "scores": {"overall": "4", "Originality": "4", "Readability_clarity": "4", "Relevance": "4", "Reproducibility": "3", "Substance": "4"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "3", "sentences": {"main": [[0, 92], [92, 259], [259, 413], [413, 566], [566, 650], [650, 735], [735, 867], [867, 1013], [1013, 1149], [1149, 1277], [1277, 1341], [1341, 1437], [1437, 1467], [1467, 1581], [1581, 1650], [1650, 1758], [1758, 1902], [1902, 1994], [1994, 1995], [1995, 2101]]}}}, {"rid": "1", "reviewer": null, "report": {"main": "The paper proposes to disambiguate finite state morphological analysis for Kinyarwanda by training a classifier (feed forward network) on a data set collected through an app. Various features are given as input to the classifier, including pre-trained word embeddings.  Strengths: Exploring new methods to improve Kinyarwandais NLP is highly desirable and relevant work that can lead to a more general contribution. The current version of the paper presents some potentially good ideas and a new data set. The characteristics of Kinyarwandaâ€™s morphology and the problems highlighted by this work, e.g., several sources of ambiguity, could be helpful for other languages that are facing similar conditions.\nWeaknesses:  There is considerable lack of clarity and meaningful comparison with the related work. The problem addressed by the paper needs to be defined more precisely. For this, the authors might want to refer to some pre-2000 work on morphological analysis, including popular textbooks. A much clearer description of the classifier input, output, training and test instances (with examples) is necessary in order to understand the procedure and to properly assess the novelty of the presented work. Crucial details are also missing in the description of the procedure for selecting the features of interest (Section 4.2).  Smaller issues: Not all tables (results)  specify that they are showing accuracy as the performance metric. \nProofread is strongly recommended. "}, "scores": {"overall": "2", "Originality": "2", "Readability_clarity": "2", "Relevance": "5", "Reproducibility": "2", "Substance": "2"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "4", "sentences": {"main": [[0, 175], [175, 269], [269, 270], [270, 416], [416, 506], [506, 706], [706, 806], [806, 877], [877, 997], [997, 1209], [1209, 1332], [1332, 1333], [1333, 1441], [1441, 1477]]}}}]