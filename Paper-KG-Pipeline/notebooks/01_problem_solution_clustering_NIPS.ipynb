{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79b34db",
   "metadata": {},
   "source": [
    "# 论文套路抽取: Reusable Research Patterns\n",
    "\n",
    "\n",
    "这个 notebook 目标是：\n",
    "NIPS paper and review → 结构化 problem/solution 抽取 → problem/solution 级 embedding → 套路聚类 → RAG/KG-ready artifacts\n",
    "\n",
    "Structure：\n",
    "\n",
    "0. Environment Setup\n",
    "1. Load Dataset\n",
    "2. Paper Text Assembly\n",
    "3. LLM-based Structured Extraction\n",
    "4. Flatten and prepare text for clustering\n",
    "5. Embedding & Vectorization\n",
    "6. Hyperparameter for UMAP and HDBSCAN \n",
    "7. Pattern Clustering (UMAP and HDBSCAN)\n",
    "8. Create pattern library for RAG / Downstream Use \n",
    "9. Cluster Interpretation & Naming (LLM)\n",
    "10. Finalize: Link cluster_id to papers and problems (for building knowledge graph)\n",
    "\n",
    "\n",
    "\n",
    "dataset by Alina: https://huggingface.co/datasets/Alina0796/neurips-2025-reviews/tree/main/data/full\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ca662f",
   "metadata": {},
   "source": [
    " ## 0. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9068ef2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Any, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import hdbscan\n",
    "\n",
    "# Optional LLM (OpenAI example)\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15118e9",
   "metadata": {},
   "source": [
    "## 1. Load NIPS 2025 paper\n",
    "\n",
    "download datasets: https://huggingface.co/datasets/Alina0796/neurips-2025-reviews/tree/main/data/full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0289c3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level folders: ['NIPS_2025_meta', 'NIPS_2025_review', 'NIPS_2025_paper']\n",
      "Loaded paper jsons: 5183\n",
      "Example keys: dict_keys(['forum_id', 'metadata'])\n",
      "Example metadata keys: dict_keys(['source', 'year', 'title', 'abstractText', 'sections', 'references'])\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"../review2_new/NIPS/NIPS_2025/\")\n",
    "\n",
    "print(\"Top-level folders:\", [p.name for p in DATA_DIR.iterdir() if p.is_dir()])\n",
    "\n",
    "# load paper\n",
    "def load_jsons_from_dir(dir_path: Path) -> List[Dict[str, Any]]:\n",
    "    items = []\n",
    "    for fp in sorted(dir_path.rglob(\"*.json\")):\n",
    "        try:\n",
    "            items.append(json.loads(fp.read_text(encoding=\"utf-8\")))\n",
    "        except Exception as e:\n",
    "            print(\"Failed:\", fp, e)\n",
    "    return items\n",
    "\n",
    "# 自动猜 paper 目录：名字里包含 \"paper\"\n",
    "paper_dir = None\n",
    "for p in DATA_DIR.iterdir():\n",
    "    if p.is_dir() and \"paper\" in p.name.lower():\n",
    "        paper_dir = p\n",
    "        break\n",
    "\n",
    "assert paper_dir is not None, \"Could not find paper folder automatically.\"\n",
    "papers = load_jsons_from_dir(paper_dir)\n",
    "print(\"Loaded paper jsons:\", len(papers))\n",
    "print(\"Example keys:\", papers[0].keys())\n",
    "print(\"Example metadata keys:\", papers[0].get(\"metadata\", {}).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edc90ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forum_id</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004uTlSufe</td>\n",
       "      <td>{'source': 'NeurIPS', 'year': 2025, 'title': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00Bwl1woOJ</td>\n",
       "      <td>{'source': 'NeurIPS', 'year': 2025, 'title': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00oRAPDWsX</td>\n",
       "      <td>{'source': 'NeurIPS', 'year': 2025, 'title': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01hPO0uJhS</td>\n",
       "      <td>{'source': 'NeurIPS', 'year': 2025, 'title': '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>021PIPyOU1</td>\n",
       "      <td>{'source': 'NeurIPS', 'year': 2025, 'title': '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     forum_id                                           metadata\n",
       "0  004uTlSufe  {'source': 'NeurIPS', 'year': 2025, 'title': '...\n",
       "1  00Bwl1woOJ  {'source': 'NeurIPS', 'year': 2025, 'title': '...\n",
       "2  00oRAPDWsX  {'source': 'NeurIPS', 'year': 2025, 'title': '...\n",
       "3  01hPO0uJhS  {'source': 'NeurIPS', 'year': 2025, 'title': '...\n",
       "4  021PIPyOU1  {'source': 'NeurIPS', 'year': 2025, 'title': '..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "papers_df = pd.DataFrame(papers)\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b40e9ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json print metadata of the first paper\n",
    "#print(json.dumps(papers[0].get(\"metadata\", {}), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8345fece",
   "metadata": {},
   "source": [
    "## 2. Build Paper Text（从 sections 拼接）\n",
    "\n",
    "选择哪些 section（推荐：Intro/Related/Method/Experiment/Conclusion）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39f1d8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example paper_text length: 4763\n",
      "Title: How Well Can Differential Privacy Be Audited in One Run?\n",
      "\n",
      "## 1 Introduction\n",
      "Differential privacy (DP) is increasingly deployed to protect the privacy of training data, including in large-scale industry machine learning settings. As DP provides a theoretical guarantee about the worst-case behavior of a machine learning algorithm, any DP algorithm should be accompanied by a proof of an upper bound on its privacy parameters. However, such upper bounds can be quite loose. Worse, analyses and deployments of differential privacy can contain bugs that render those privacy upper bounds incorrect. As a result, there is growing interest in *privacy auditing* methods that can provide empirical lower bounds on an algorithm's privacy parameters. Such lower bounds can help detect whether the uppe\n"
     ]
    }
   ],
   "source": [
    "# Build Paper Text（从 sections 拼接）\n",
    "# 选择哪些 section（推荐：Intro/Related/Method/Experiment/Conclusion）\n",
    "# DEFAULT_INCLUDE = [\n",
    "#    \"abstract\", \"introduction\", \"background\", \"related\",\n",
    "#    \"method\", \"approach\", \"model\", \"training\",\n",
    "#    \"experiment\", \"evaluation\", \"results\",\n",
    "#    \"discussion\", \"conclusion\", \"limitations\"\n",
    "#]\n",
    "\n",
    "DEFAULT_INCLUDE = [\n",
    "    \"abstract\", \"introduction\"\n",
    "]\n",
    "\n",
    "def normalize_heading(h: str) -> str:\n",
    "    return (h or \"\").strip().lower()\n",
    "\n",
    "def should_include_section(heading: str, include_keywords: List[str]) -> bool:\n",
    "    h = normalize_heading(heading)\n",
    "    return any(k in h for k in include_keywords)\n",
    "\n",
    "def build_paper_text(paper: Dict[str, Any], include_keywords: List[str] = DEFAULT_INCLUDE,\n",
    "                     max_chars: int = 18000) -> str:\n",
    "    md = paper.get(\"metadata\", {}) or {}\n",
    "    title = md.get(\"title\", \"\") or \"\"\n",
    "    sections = md.get(\"sections\", []) or []\n",
    "\n",
    "    chunks = []\n",
    "    if title:\n",
    "        chunks.append(f\"Title: {title}\")\n",
    "\n",
    "    for sec in sections:\n",
    "        heading = sec.get(\"heading\", \"\") or \"\"\n",
    "        text = sec.get(\"text\", \"\") or \"\"\n",
    "        if not text.strip():\n",
    "            continue\n",
    "        if should_include_section(heading, include_keywords):\n",
    "            chunks.append(f\"\\n## {heading}\\n{text}\")\n",
    "\n",
    "    full = \"\\n\".join(chunks).strip()\n",
    "    # 截断，防止超出 LLM 上下文\n",
    "    if len(full) > max_chars:\n",
    "        full = full[:max_chars] + \"\\n\\n[TRUNCATED]\"\n",
    "    return full\n",
    "\n",
    "paper_texts = [build_paper_text(p) for p in papers]\n",
    "print(\"Example paper_text length:\", len(paper_texts[0]))\n",
    "print(paper_texts[0][:800])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d6e8e7",
   "metadata": {},
   "source": [
    "Map Paper ID（把 paper/review/rebuttal 对齐的关键）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f1054b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004uTlSufe</td>\n",
       "      <td>2025</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>How Well Can Differential Privacy Be Audited i...</td>\n",
       "      <td>Title: How Well Can Differential Privacy Be Au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00Bwl1woOJ</td>\n",
       "      <td>2025</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>Uncertainty-Sensitive Privileged Learning</td>\n",
       "      <td>Title: Uncertainty-Sensitive Privileged Learni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00oRAPDWsX</td>\n",
       "      <td>2025</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>KL Penalty Control via Perturbation for Direct...</td>\n",
       "      <td>Title: KL Penalty Control via Perturbation for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01hPO0uJhS</td>\n",
       "      <td>2025</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>Who You Are Matters: Bridging Topics and Socia...</td>\n",
       "      <td>Title: Who You Are Matters: Bridging Topics an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>021PIPyOU1</td>\n",
       "      <td>2025</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>ALTER: &lt;u&gt;All-in-One Layer Pruning and Tempora...</td>\n",
       "      <td>Title: ALTER: &lt;u&gt;All-in-One Layer Pruning and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id  year   source  \\\n",
       "0  004uTlSufe  2025  NeurIPS   \n",
       "1  00Bwl1woOJ  2025  NeurIPS   \n",
       "2  00oRAPDWsX  2025  NeurIPS   \n",
       "3  01hPO0uJhS  2025  NeurIPS   \n",
       "4  021PIPyOU1  2025  NeurIPS   \n",
       "\n",
       "                                               title  \\\n",
       "0  How Well Can Differential Privacy Be Audited i...   \n",
       "1          Uncertainty-Sensitive Privileged Learning   \n",
       "2  KL Penalty Control via Perturbation for Direct...   \n",
       "3  Who You Are Matters: Bridging Topics and Socia...   \n",
       "4  ALTER: <u>All-in-One Layer Pruning and Tempora...   \n",
       "\n",
       "                                          paper_text  \n",
       "0  Title: How Well Can Differential Privacy Be Au...  \n",
       "1  Title: Uncertainty-Sensitive Privileged Learni...  \n",
       "2  Title: KL Penalty Control via Perturbation for...  \n",
       "3  Title: Who You Are Matters: Bridging Topics an...  \n",
       "4  Title: ALTER: <u>All-in-One Layer Pruning and ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "paper_rows = []\n",
    "for p in papers:\n",
    "    \n",
    "    pid = p.get(\"forum_id\", \"\")\n",
    "    md = p.get(\"metadata\", {}) or {}\n",
    "    paper_rows.append({\n",
    "        \"paper_id\": pid, \n",
    "         \"year\": md.get(\"year\", \"\"),\n",
    "         \"source\": md.get(\"source\", \"\"),\n",
    "        \"title\": md.get(\"title\", \"\"),\n",
    "        \"paper_text\": build_paper_text(p)\n",
    "    })\n",
    "\n",
    "paper_df = pd.DataFrame(paper_rows).drop_duplicates(\"paper_id\")\n",
    "paper_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a6618896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample paper count: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>year</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iUjGNJzrF1</td>\n",
       "      <td>2025</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>Debate or Vote: Which Yields Better Decisions ...</td>\n",
       "      <td>Title: Debate or Vote: Which Yields Better Dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>isATAFP71B</td>\n",
       "      <td>2025</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>SE-Agent: Self-Evolution Trajectory Optimizati...</td>\n",
       "      <td>Title: SE-Agent: Self-Evolution Trajectory Opt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id  year   source  \\\n",
       "0  iUjGNJzrF1  2025  NeurIPS   \n",
       "1  isATAFP71B  2025  NeurIPS   \n",
       "\n",
       "                                               title  \\\n",
       "0  Debate or Vote: Which Yields Better Decisions ...   \n",
       "1  SE-Agent: Self-Evolution Trajectory Optimizati...   \n",
       "\n",
       "                                          paper_text  \n",
       "0  Title: Debate or Vote: Which Yields Better Dec...  \n",
       "1  Title: SE-Agent: Self-Evolution Trajectory Opt...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter out papers with text less than 50 words   \n",
    "#paper_df = paper_df[paper_df[\"paper_text\"].str.split().str.len() >= 50].reset_index(drop=True)\n",
    "#print(\"Filtered paper count:\", len(paper_df))\n",
    "\n",
    "# pick a small set of papers for testing\n",
    "#\n",
    "#paper title contains \"Multi-Agent Debate for LLM Judges with Adaptive Stability Detection\"\n",
    "#sample_df = paper_df[paper_df[\"title\"].str.contains(\"Debate for LLM Judges\", case=False)].reset_index(drop=True)\n",
    "# paper text contains \"evolution\"\n",
    "mad_df = paper_df[paper_df[\"title\"].str.contains(\"Debate or Vote\", case=False)].reset_index(drop=True)\n",
    "mad_df.head()\n",
    "\n",
    "# paper title comains \"A-Mem: Agentic Memory for LLM Agents\n",
    "#se_df = paper_df[paper_df[\"title\"].str.contains(\"A-Mem\", case=False)].reset_index(drop=True)\n",
    "se_df = paper_df[paper_df[\"title\"].str.contains(\"Self-Evolution Trajectory\", case=False)].reset_index(drop=True)\n",
    "se_df.head()\n",
    "\n",
    "sample_df = pd.concat([mad_df, se_df]).reset_index(drop=True)\n",
    "print(\"Sample paper count:\", len(sample_df))\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85c2950f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "source\n",
       "NeurIPS    5183\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# value_counts of years\n",
    "paper_df[\"source\"].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aae6f1c",
   "metadata": {},
   "source": [
    "(Optional) Load Reviews / Rebuttals 并拼进去"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fd46db",
   "metadata": {},
   "source": [
    "## 3. LLM Extraction（你的字段：core idea / problem / gap / domains / methods / tricks）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "578f81b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [3:12:57<00:00, 23.16s/it]   \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>core_idea</th>\n",
       "      <th>problem_solution_pairs</th>\n",
       "      <th>gap_analysis</th>\n",
       "      <th>domains</th>\n",
       "      <th>proposed_methods</th>\n",
       "      <th>tricks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uG8kRtNGEI</td>\n",
       "      <td>Fix False Transparency by Noise Guided Splatting</td>\n",
       "      <td>The paper introduces Noise Guided Splatting (N...</td>\n",
       "      <td>[{'problem': '3D Gaussian Splatting (3DGS) oft...</td>\n",
       "      <td>{'prior_work_limitation': 'Previous methods fo...</td>\n",
       "      <td>[3D neural rendering, computer vision, graphic...</td>\n",
       "      <td>[{'method_name': 'Noise Guided Splatting (NGS)...</td>\n",
       "      <td>[{'trick_description': 'Injecting high-opacity...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HdY8CCHife</td>\n",
       "      <td>**A Unified Stability Analysis of SAM vs SGD: ...</td>\n",
       "      <td>This paper presents a unified stability analys...</td>\n",
       "      <td>[{'problem': 'Existing analyses of SAM and SGD...</td>\n",
       "      <td>{'prior_work_limitation': 'Prior work has focu...</td>\n",
       "      <td>[optimization, machine learning theory, deep l...</td>\n",
       "      <td>[{'method_name': 'Unified Stability Analysis F...</td>\n",
       "      <td>[{'trick_description': 'Empirically validate t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4ULtNYHc5T</td>\n",
       "      <td>Exploring Tradeoffs through Mode Connectivity ...</td>\n",
       "      <td>This paper proposes a novel approach to multi-...</td>\n",
       "      <td>[{'problem': 'Optimization-based MTL methods s...</td>\n",
       "      <td>{'prior_work_limitation': 'Prior optimization-...</td>\n",
       "      <td>[multi-task learning, deep learning optimizati...</td>\n",
       "      <td>[{'method_name': 'Curve-based mode connectivit...</td>\n",
       "      <td>[{'trick_description': 'Use NURBS instead of B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>klOr9y9nMU</td>\n",
       "      <td>CORE: Reducing UI Exposure in Mobile Agents vi...</td>\n",
       "      <td>CORE introduces a collaborative framework that...</td>\n",
       "      <td>[{'problem': 'Mobile agents for task automatio...</td>\n",
       "      <td>{'prior_work_limitation': 'Previous mobile age...</td>\n",
       "      <td>[mobile automation, privacy-preserving AI, hum...</td>\n",
       "      <td>[{'method_name': 'CORE collaborative framework...</td>\n",
       "      <td>[{'trick_description': 'Partition UI pages int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yjLew3Nd7z</td>\n",
       "      <td>Part-Level Visual Understanding</td>\n",
       "      <td>The paper introduces Explanatory Part Segmenta...</td>\n",
       "      <td>[{'problem': 'Current LMMs lack strong abiliti...</td>\n",
       "      <td>{'prior_work_limitation': 'Prior LMMs perform ...</td>\n",
       "      <td>[computer vision, multimodal learning, object ...</td>\n",
       "      <td>[{'method_name': 'Explanatory Part Segmentatio...</td>\n",
       "      <td>[{'trick_description': 'Avoid using special se...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     paper_id                                              title  \\\n",
       "0  uG8kRtNGEI   Fix False Transparency by Noise Guided Splatting   \n",
       "1  HdY8CCHife  **A Unified Stability Analysis of SAM vs SGD: ...   \n",
       "2  4ULtNYHc5T  Exploring Tradeoffs through Mode Connectivity ...   \n",
       "3  klOr9y9nMU  CORE: Reducing UI Exposure in Mobile Agents vi...   \n",
       "4  yjLew3Nd7z                    Part-Level Visual Understanding   \n",
       "\n",
       "                                           core_idea  \\\n",
       "0  The paper introduces Noise Guided Splatting (N...   \n",
       "1  This paper presents a unified stability analys...   \n",
       "2  This paper proposes a novel approach to multi-...   \n",
       "3  CORE introduces a collaborative framework that...   \n",
       "4  The paper introduces Explanatory Part Segmenta...   \n",
       "\n",
       "                              problem_solution_pairs  \\\n",
       "0  [{'problem': '3D Gaussian Splatting (3DGS) oft...   \n",
       "1  [{'problem': 'Existing analyses of SAM and SGD...   \n",
       "2  [{'problem': 'Optimization-based MTL methods s...   \n",
       "3  [{'problem': 'Mobile agents for task automatio...   \n",
       "4  [{'problem': 'Current LMMs lack strong abiliti...   \n",
       "\n",
       "                                        gap_analysis  \\\n",
       "0  {'prior_work_limitation': 'Previous methods fo...   \n",
       "1  {'prior_work_limitation': 'Prior work has focu...   \n",
       "2  {'prior_work_limitation': 'Prior optimization-...   \n",
       "3  {'prior_work_limitation': 'Previous mobile age...   \n",
       "4  {'prior_work_limitation': 'Prior LMMs perform ...   \n",
       "\n",
       "                                             domains  \\\n",
       "0  [3D neural rendering, computer vision, graphic...   \n",
       "1  [optimization, machine learning theory, deep l...   \n",
       "2  [multi-task learning, deep learning optimizati...   \n",
       "3  [mobile automation, privacy-preserving AI, hum...   \n",
       "4  [computer vision, multimodal learning, object ...   \n",
       "\n",
       "                                    proposed_methods  \\\n",
       "0  [{'method_name': 'Noise Guided Splatting (NGS)...   \n",
       "1  [{'method_name': 'Unified Stability Analysis F...   \n",
       "2  [{'method_name': 'Curve-based mode connectivit...   \n",
       "3  [{'method_name': 'CORE collaborative framework...   \n",
       "4  [{'method_name': 'Explanatory Part Segmentatio...   \n",
       "\n",
       "                                              tricks  \n",
       "0  [{'trick_description': 'Injecting high-opacity...  \n",
       "1  [{'trick_description': 'Empirically validate t...  \n",
       "2  [{'trick_description': 'Use NURBS instead of B...  \n",
       "3  [{'trick_description': 'Partition UI pages int...  \n",
       "4  [{'trick_description': 'Avoid using special se...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an expert research scientist and conference reviewer.\n",
    "Extract structured research insights from the paper content (and optionally reviews/rebuttals).\n",
    "Be concise, faithful, and separate core ideas vs implementation tricks.\n",
    "Return valid JSON only.\n",
    "\"\"\".strip()\n",
    "\n",
    "USER_PROMPT = \"\"\"\n",
    "Extract the following fields as JSON:\n",
    "\n",
    "- core_idea: 1-3 sentences\n",
    "- problem_solution_pairs: list of {{ problem, solution, key_insight, setting }} where:\n",
    "  - problem: 1-2 sentences\n",
    "  - solution: 1-2 sentences\n",
    "  - key_insight: 1 sentence\n",
    "  - setting: short phrase (e.g., \"DP auditing / one-run setting\", \"LLM reasoning / multi-agent\", etc.)\n",
    "- gap_analysis: {{\n",
    "    prior_work_limitation,\n",
    "    why_unresolved\n",
    "  }}\n",
    "- domains: list of strings\n",
    "- proposed_methods: list of {{ method_name, method_type }} where method_type is one of:\n",
    "  [architecture, loss, data, inference, training, evaluation, theory, system]\n",
    "- tricks: list of {{ trick_description, trick_type, novelty_level }} where trick_type in:\n",
    "  [engineering, optimization, heuristic, data-centric, evaluation]\n",
    "  and novelty_level in [low, medium, high]\n",
    "\n",
    "Rules:\n",
    "- Output MUST be valid JSON only (no markdown, no commentary).\n",
    "- core_idea should not repeat the problem_solution_pairs verbatim.\n",
    "- problem_solution_pairs: 1-5 items; each pair must be distinct (no paraphrase duplicates).\n",
    "- Prefer reusable phrasing in solutions (e.g., \"Reduce X by doing Y under condition Z\").\n",
    "- If uncertain, still fill fields with best-effort text; avoid null. Use empty list [] only when truly none.\n",
    "\n",
    "Text:\n",
    "{paper_text}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "\n",
    "def extract_insights_llm(text: str, model: str = \"gpt-4.1\") -> Dict[str, Any]:\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": USER_PROMPT.format(paper_text=text)}\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    return json.loads(resp.choices[0].message.content)\n",
    "\n",
    "# 先抽样跑 500 篇做 sanity check\n",
    "sample_df = paper_df.sample(n=min(500, len(paper_df)), random_state=42).copy()\n",
    "#sample_df = paper_df.head(1)\n",
    "\n",
    "results = []\n",
    "for _, r in tqdm(sample_df.iterrows(), total=len(sample_df)):\n",
    "    try:\n",
    "        out = extract_insights_llm(r[\"paper_text\"])\n",
    "        results.append({**{\"paper_id\": r[\"paper_id\"], \"title\": r[\"title\"]}, **out})\n",
    "    except Exception as e:\n",
    "        results.append({\"paper_id\": r[\"paper_id\"], \"title\": r[\"title\"], \"error\": str(e)})\n",
    "\n",
    "ex_df = pd.DataFrame(results)\n",
    "ex_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32c1ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print json of the first row\n",
    "#print(json.dumps(ex_df.iloc[0].to_dict(), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "25b961ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved extraction results to: ../review2_new/NIPS/NIPS_2025/NIPS_2025_extraction_raw.jsonl\n"
     ]
    }
   ],
   "source": [
    "# save ex_df to jsonl\n",
    "output_fp = DATA_DIR / \"NIPS_2025_extraction_raw.jsonl\"\n",
    "with output_fp.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    for _, r in ex_df.iterrows():\n",
    "        f.write(json.dumps(r.to_dict()) + \"\\n\")\n",
    "print(\"Saved extraction results to:\", output_fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6730eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(json.dumps(ex_df.iloc[0].to_dict(), indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9f40ac",
   "metadata": {},
   "source": [
    "## 4. Flatten：为 PS 聚类准备语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf6f20cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK. Output dir: ../review2_new/NIPS/NIPS_2025/output_nb\n"
     ]
    }
   ],
   "source": [
    "# load the extracted inights\n",
    "import os, json\n",
    "from typing import Any, Dict, List, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# ====== paths (edit these) ======\n",
    "JSONL_PATH = DATA_DIR / \"NIPS_2025_extraction_raw.jsonl\" # <-- 改成你的 jsonl\n",
    "OUT_DIR = DATA_DIR / \"output_nb\"\n",
    "CORPUS_DIR = os.path.join(OUT_DIR, \"corpus\")\n",
    "EMB_DIR = os.path.join(OUT_DIR, \"embeddings\")\n",
    "CLUSTER_DIR = os.path.join(OUT_DIR, \"clusters\")\n",
    "\n",
    "for d in [OUT_DIR, CORPUS_DIR, EMB_DIR, CLUSTER_DIR]:\n",
    "    os.makedirs(d, exist_ok=True)\n",
    "\n",
    "print(\"OK. Output dir:\", OUT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26cd59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper\n",
    "def safe_get(d: Dict[str, Any], keys: List[str], default=None):\n",
    "    for k in keys:\n",
    "        if k in d and d[k] not in (None, \"\"):\n",
    "            return d[k]\n",
    "    return default\n",
    "\n",
    "def build_ps_cluster_text(ps: Dict[str, Any]) -> str:\n",
    "    setting = (ps.get(\"setting\") or \"\").strip()\n",
    "    problem = (ps.get(\"problem\") or \"\").strip()\n",
    "    solution = (ps.get(\"solution\") or \"\").strip()\n",
    "    insight = (ps.get(\"key_insight\") or \"\").strip()\n",
    "\n",
    "    return (\n",
    "        f\"[SETTING] {setting}\\n\"\n",
    "        f\"[PROBLEM] {problem}\\n\"\n",
    "        f\"[SOLUTION] {solution}\\n\"\n",
    "        f\"[INSIGHT] {insight}\"\n",
    "    ).strip()\n",
    "\n",
    "def looks_valid_pair(problem: str, solution: str) -> bool:\n",
    "    return (problem is not None and solution is not None \n",
    "            and len(problem.strip()) >= 10 and len(solution.strip()) >= 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6485be29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88e602dcf8d4a1791b930671e44f24e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Reading JSONL: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1683"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten the extraction results\n",
    "rows = []\n",
    "\n",
    "with open(JSONL_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in tqdm(f, desc=\"Reading JSONL\"):\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        obj = json.loads(line)\n",
    "\n",
    "        paper_id = safe_get(obj, [\"paper_id\", \"forum_id\", \"id\"], default=\"\")\n",
    "        title = safe_get(obj, [\"title\"], default=\"\")\n",
    "        year = safe_get(obj, [\"year\"], default='2025')\n",
    "\n",
    "        ps_list = obj.get(\"problem_solution_pairs\") or []\n",
    "        if not isinstance(ps_list, list):\n",
    "            continue\n",
    "\n",
    "        for i, ps in enumerate(ps_list):\n",
    "            if not isinstance(ps, dict):\n",
    "                continue\n",
    "\n",
    "            problem = (ps.get(\"problem\") or \"\").strip()\n",
    "            solution = (ps.get(\"solution\") or \"\").strip()\n",
    "            key_insight = (ps.get(\"key_insight\") or \"\").strip()\n",
    "            setting = (ps.get(\"setting\") or \"\").strip()\n",
    "\n",
    "            if not looks_valid_pair(problem, solution):\n",
    "                continue\n",
    "\n",
    "            uid = f\"{paper_id}#ps#{i}\" if paper_id else f\"unknown#ps#{i}\"\n",
    "\n",
    "            rows.append({\n",
    "                \"uid\": uid,\n",
    "                \"paper_id\": paper_id,\n",
    "                \"title\": title,\n",
    "                \"year\": year,\n",
    "                \"setting\": setting,\n",
    "                \"problem\": problem,\n",
    "                \"solution\": solution,\n",
    "                \"key_insight\": key_insight,\n",
    "                \"cluster_text\": build_ps_cluster_text(ps),\n",
    "            })\n",
    "\n",
    "df_ps = pd.DataFrame(rows)\n",
    "len(df_ps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64166259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>paper_id</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>setting</th>\n",
       "      <th>problem</th>\n",
       "      <th>solution</th>\n",
       "      <th>key_insight</th>\n",
       "      <th>cluster_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>uG8kRtNGEI#ps#0</td>\n",
       "      <td>uG8kRtNGEI</td>\n",
       "      <td>Fix False Transparency by Noise Guided Splatting</td>\n",
       "      <td>2025</td>\n",
       "      <td>3D neural rendering / object-centric 3DGS</td>\n",
       "      <td>3D Gaussian Splatting (3DGS) often produces fa...</td>\n",
       "      <td>Inject high-opacity, randomly colored noise Ga...</td>\n",
       "      <td>Persistent internal noise structures act as an...</td>\n",
       "      <td>[SETTING] 3D neural rendering / object-centric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uG8kRtNGEI#ps#1</td>\n",
       "      <td>uG8kRtNGEI</td>\n",
       "      <td>Fix False Transparency by Noise Guided Splatting</td>\n",
       "      <td>2025</td>\n",
       "      <td>3DGS training / ambiguous opacity regions</td>\n",
       "      <td>Standard 2D photometric losses in 3DGS supervi...</td>\n",
       "      <td>Guide the optimization by filling the object's...</td>\n",
       "      <td>Explicitly modeling the object's interior with...</td>\n",
       "      <td>[SETTING] 3DGS training / ambiguous opacity re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uG8kRtNGEI#ps#2</td>\n",
       "      <td>uG8kRtNGEI</td>\n",
       "      <td>Fix False Transparency by Noise Guided Splatting</td>\n",
       "      <td>2025</td>\n",
       "      <td>Evaluation / transparency diagnostics</td>\n",
       "      <td>Evaluating the severity of false transparency ...</td>\n",
       "      <td>Use the recolored noise infill as a diagnostic...</td>\n",
       "      <td>Recoloring and visualizing internal noise Gaus...</td>\n",
       "      <td>[SETTING] Evaluation / transparency diagnostic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HdY8CCHife#ps#0</td>\n",
       "      <td>HdY8CCHife</td>\n",
       "      <td>**A Unified Stability Analysis of SAM vs SGD: ...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Optimization algorithm analysis / generalization</td>\n",
       "      <td>Existing analyses of SAM and SGD do not fully ...</td>\n",
       "      <td>Develop a unified stability framework that qua...</td>\n",
       "      <td>Data coherence modulates the stability and sim...</td>\n",
       "      <td>[SETTING] Optimization algorithm analysis / ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HdY8CCHife#ps#1</td>\n",
       "      <td>HdY8CCHife</td>\n",
       "      <td>**A Unified Stability Analysis of SAM vs SGD: ...</td>\n",
       "      <td>2025</td>\n",
       "      <td>Implicit bias / data-dependent analysis</td>\n",
       "      <td>The role of data coherence in shaping the impl...</td>\n",
       "      <td>Theoretically and empirically analyze how data...</td>\n",
       "      <td>High data coherence amplifies the simplicity b...</td>\n",
       "      <td>[SETTING] Implicit bias / data-dependent analy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               uid    paper_id  \\\n",
       "0  uG8kRtNGEI#ps#0  uG8kRtNGEI   \n",
       "1  uG8kRtNGEI#ps#1  uG8kRtNGEI   \n",
       "2  uG8kRtNGEI#ps#2  uG8kRtNGEI   \n",
       "3  HdY8CCHife#ps#0  HdY8CCHife   \n",
       "4  HdY8CCHife#ps#1  HdY8CCHife   \n",
       "\n",
       "                                               title  year  \\\n",
       "0   Fix False Transparency by Noise Guided Splatting  2025   \n",
       "1   Fix False Transparency by Noise Guided Splatting  2025   \n",
       "2   Fix False Transparency by Noise Guided Splatting  2025   \n",
       "3  **A Unified Stability Analysis of SAM vs SGD: ...  2025   \n",
       "4  **A Unified Stability Analysis of SAM vs SGD: ...  2025   \n",
       "\n",
       "                                            setting  \\\n",
       "0         3D neural rendering / object-centric 3DGS   \n",
       "1         3DGS training / ambiguous opacity regions   \n",
       "2             Evaluation / transparency diagnostics   \n",
       "3  Optimization algorithm analysis / generalization   \n",
       "4           Implicit bias / data-dependent analysis   \n",
       "\n",
       "                                             problem  \\\n",
       "0  3D Gaussian Splatting (3DGS) often produces fa...   \n",
       "1  Standard 2D photometric losses in 3DGS supervi...   \n",
       "2  Evaluating the severity of false transparency ...   \n",
       "3  Existing analyses of SAM and SGD do not fully ...   \n",
       "4  The role of data coherence in shaping the impl...   \n",
       "\n",
       "                                            solution  \\\n",
       "0  Inject high-opacity, randomly colored noise Ga...   \n",
       "1  Guide the optimization by filling the object's...   \n",
       "2  Use the recolored noise infill as a diagnostic...   \n",
       "3  Develop a unified stability framework that qua...   \n",
       "4  Theoretically and empirically analyze how data...   \n",
       "\n",
       "                                         key_insight  \\\n",
       "0  Persistent internal noise structures act as an...   \n",
       "1  Explicitly modeling the object's interior with...   \n",
       "2  Recoloring and visualizing internal noise Gaus...   \n",
       "3  Data coherence modulates the stability and sim...   \n",
       "4  High data coherence amplifies the simplicity b...   \n",
       "\n",
       "                                        cluster_text  \n",
       "0  [SETTING] 3D neural rendering / object-centric...  \n",
       "1  [SETTING] 3DGS training / ambiguous opacity re...  \n",
       "2  [SETTING] Evaluation / transparency diagnostic...  \n",
       "3  [SETTING] Optimization algorithm analysis / ge...  \n",
       "4  [SETTING] Implicit bias / data-dependent analy...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "51042738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved problem-solution pairs to: ../review2_new/NIPS/NIPS_2025/output_nb/NIPS_2025_problem_solutions.jsonl\n"
     ]
    }
   ],
   "source": [
    "# save the problems to jsonl\n",
    "PS_JSONL = OUT_DIR/\"NIPS_2025_problem_solutions.jsonl\"\n",
    "sim_ps = df_ps[[ \"paper_id\", \"title\", \"year\", \"setting\", \"problem\", \"solution\", \"key_insight\"]]\n",
    "with open(PS_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, r in sim_ps.iterrows():\n",
    "        f.write(json.dumps(r.to_dict(), ensure_ascii=False) + \"\\n\")\n",
    "print(\"Saved problem-solution pairs to:\", PS_JSONL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0148c33b",
   "metadata": {},
   "source": [
    "## 5. Embedding & Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac6557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding\n",
    "texts = df_ps[\"cluster_text\"].tolist()\n",
    "# Embedding\n",
    "embedder = SentenceTransformer(\"all-mpnet-base-v2\")\n",
    "emb = embedder.encode(df_ps[\"cluster_text\"].tolist(), normalize_embeddings=True, show_progress_bar=True)\n",
    "#emb = embedder.encode(trick_df[\"canonical_trick\"].tolist(), normalize_embeddings=True, show_progress_bar=True)\n",
    "emb = np.asarray(emb)\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4394f0af",
   "metadata": {},
   "source": [
    "## 6: 超参 UMAP(15D) + HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "957418ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liling/projects/Bridging-AI-and-Science/.venv/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1683, 15)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fallback to UMAP\n",
    "import umap\n",
    "\n",
    "umap15 = umap.UMAP(\n",
    "    n_components=15,\n",
    "    n_neighbors=30,\n",
    "    min_dist=0.0,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "T_15 = umap15.fit_transform(emb)\n",
    "T_15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bbeddeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcs 3 | problem-solution clusters 135 noise 0.286\n",
      "mcs 5 | problem-solution clusters 96 noise 0.307\n",
      "mcs 8 | problem-solution clusters 41 noise 0.169\n",
      "mcs 10 | problem-solution clusters 38 noise 0.176\n",
      "mcs 15 | problem-solution clusters 31 noise 0.208\n"
     ]
    }
   ],
   "source": [
    "import hdbscan\n",
    "import numpy as np\n",
    "\n",
    "def n_clusters(labels):\n",
    "    return len(set(labels)) - (1 if -1 in labels else 0)\n",
    "\n",
    "def run_hdb(X, mcs, ms=None):\n",
    "    #cl = hdbscan.HDBSCAN(min_cluster_size=mcs, min_samples=ms, metric=\"euclidean\", cluster_selection_method=\"leaf\")\n",
    "    cl = hdbscan.HDBSCAN(min_cluster_size=mcs, min_samples=ms, metric=\"euclidean\") # \"leaf\" selection\n",
    "    labels = cl.fit_predict(X)\n",
    "    return labels, n_clusters(labels), (labels==-1).mean()\n",
    "\n",
    "for mcs in [3,5,8,10,15]:\n",
    "    p_lables, np_c, np_noise = run_hdb(T_15, mcs, ms=3)\n",
    "    print(\"mcs\", mcs, \"| problem-solution clusters\", np_c, \"noise\", round(np_noise,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4af31e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trick clusters 41 noise 0.169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cluster\n",
       " 6     344\n",
       "-1     284\n",
       " 18    176\n",
       " 20     71\n",
       " 15     71\n",
       " 12     68\n",
       " 10     37\n",
       " 32     34\n",
       " 9      32\n",
       " 33     31\n",
       " 30     28\n",
       " 23     28\n",
       " 39     26\n",
       " 4      26\n",
       " 11     25\n",
       " 1      24\n",
       " 8      24\n",
       " 31     24\n",
       " 35     23\n",
       " 36     22\n",
       " 21     21\n",
       " 40     19\n",
       " 27     19\n",
       " 3      19\n",
       " 24     17\n",
       " 2      17\n",
       " 13     15\n",
       " 29     13\n",
       " 34     13\n",
       " 17     13\n",
       " 16     13\n",
       " 22     12\n",
       " 5      11\n",
       " 38     11\n",
       " 19     11\n",
       " 0      10\n",
       " 37     10\n",
       " 14      9\n",
       " 26      8\n",
       " 28      8\n",
       " 7       8\n",
       " 25      8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# locked mcs=8, ms=3\n",
    "p_lables, np_c, np_noise = run_hdb(T_15, 8, ms=3)\n",
    "print(\"Trick clusters\", np_c, \"noise\", round(np_noise,3))\n",
    "df_ps[\"cluster\"] = p_lables\n",
    "\n",
    "df_ps[\"cluster\"].value_counts().head(58)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed2a003",
   "metadata": {},
   "source": [
    "## 7. Put together： UMAP + HDBSCAN 聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3b4312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liling/projects/Bridging-AI-and-Science/.venv/lib/python3.11/site-packages/umap/umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters: 43 noise: 0.165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "cluster\n",
       " 9     352\n",
       "-1     278\n",
       " 27     84\n",
       " 37     78\n",
       " 28     72\n",
       " 20     67\n",
       " 18     65\n",
       " 11     37\n",
       " 0      36\n",
       " 42     33\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import umap\n",
    "import hdbscan\n",
    "\n",
    "assert len(df_ps) == emb.shape[0], \"df_ps rows must match emb rows\"\n",
    "\n",
    "# --- UMAP reduce ---\n",
    "um = umap.UMAP(\n",
    "    n_neighbors=15,\n",
    "    n_components=30,     # 常用 10~30\n",
    "    metric=\"cosine\",\n",
    "    random_state=42\n",
    ")\n",
    "emb_low = um.fit_transform(emb)\n",
    "\n",
    "# --- HDBSCAN cluster (locked mcs=8) ---\n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=8,\n",
    "    min_samples=3,                 # 稳一点；你可试 2~5\n",
    "    metric=\"euclidean\",\n",
    "    #cluster_selection_method=\"leaf\"\n",
    ")\n",
    "labels = clusterer.fit_predict(emb_low)\n",
    "\n",
    "df_ps = df_ps.copy()\n",
    "df_ps[\"cluster\"] = labels\n",
    "\n",
    "noise_rate = (df_ps[\"cluster\"] == -1).mean() # 聚合后噪声率\n",
    "n_clusters = (df_ps[\"cluster\"].nunique() - (1 if -1 in df_ps[\"cluster\"].unique() else 0))\n",
    "\n",
    "print(\"clusters:\", n_clusters, \"noise:\", round(noise_rate, 3))\n",
    "df_ps[\"cluster\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d50bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"uid\": \"uG8kRtNGEI#ps#0\",\n",
      "  \"paper_id\": \"uG8kRtNGEI\",\n",
      "  \"title\": \"Fix False Transparency by Noise Guided Splatting\",\n",
      "  \"year\": \"2025\",\n",
      "  \"setting\": \"3D neural rendering / object-centric 3DGS\",\n",
      "  \"problem\": \"3D Gaussian Splatting (3DGS) often produces false transparency, where opaque surfaces appear semi-transparent due to unconstrained optimization and ambiguous alpha blending.\",\n",
      "  \"solution\": \"Inject high-opacity, randomly colored noise Gaussians inside the object's volume during training to enforce correct surface opacity.\",\n",
      "  \"key_insight\": \"Persistent internal noise structures act as an occlusion barrier, preventing the optimization from blending back surfaces into the front-facing rendering.\",\n",
      "  \"cluster_text\": \"[SETTING] 3D neural rendering / object-centric 3DGS\\n[PROBLEM] 3D Gaussian Splatting (3DGS) often produces false transparency, where opaque surfaces appear semi-transparent due to unconstrained optimization and ambiguous alpha blending.\\n[SOLUTION] Inject high-opacity, randomly colored noise Gaussians inside the object's volume during training to enforce correct surface opacity.\\n[INSIGHT] Persistent internal noise structures act as an occlusion barrier, preventing the optimization from blending back surfaces into the front-facing rendering.\",\n",
      "  \"cluster\": 9\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# json print of the first row\n",
    "print(json.dumps(df_ps.iloc[0].to_dict(), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40affc70",
   "metadata": {},
   "source": [
    "## 8 RAG-ready pattern library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8323bac",
   "metadata": {},
   "source": [
    "生成 RAG-ready 的 pattern 文档（每个 cluster 一个 doc）\n",
    "\n",
    "这里我给你一个“够用又通用”的 schema（后面很适合丢进向量库）：\n",
    "\n",
    "pattern_id\n",
    "\n",
    "pattern_name（稍后由 LLM 生成）\n",
    "\n",
    "pattern_description\n",
    "\n",
    "examples（trick_text 样本）\n",
    "\n",
    "supporting_items（可选：paper_id/title 等证据字段，如果你有）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b4a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pattern_id': 9,\n",
       "  'pattern_name': None,\n",
       "  'pattern_description': None,\n",
       "  'cluster_size': 352,\n",
       "  'examples': ['[SETTING] Explainable VAD / multi-granularity reasoning\\n[PROBLEM] Existing methods struggle to comprehensively understand and reason about anomalies at multiple temporal granularities, especially for complex, long-duration events.\\n[SOLUTION] Construct a hierarchical granularity-aware tree to represent videos at multiple temporal scales, supporting multi-granularity anomaly reasoning and score fusion.\\n[INSIGHT] Hierarchical representations allow flexible aggregation of evidence from both coarse and fine temporal segments, improving detection of both short and long anomalies.',\n",
       "   \"[SETTING] Benchmark construction / multi-modal, multi-video QA\\n[PROBLEM] Current benchmarks only associate each question with a single short video clip, failing to assess models' ability to synthesize information across multiple sources.\\n[SOLUTION] Curate AVHaystacks, a dataset of 3100 QA pairs requiring multi-video linkage and reasoning, with a robust filtering pipeline to ensure questions demand both audio and visual understanding.\\n[INSIGHT] Careful data curation and filtering are essential to create tasks that genuinely require multi-modal, multi-source reasoning.\",\n",
       "   \"[SETTING] VLM benchmarking / failure analysis\\n[PROBLEM] State-of-the-art VLMs hallucinate and fail to reason about counterintuitive phenomena in synthetic videos, indicating limited physical reasoning.\\n[SOLUTION] Benchmark VLMs on the VideoHallu dataset and analyze their failure modes to identify reliance on linguistic priors over visual evidence.\\n[INSIGHT] Systematic benchmarking on counterfactual scenarios exposes the models' shallow reasoning and guides targeted improvements.\",\n",
       "   '[SETTING] Personalized deepfake detection / identity-aware setting\\n[PROBLEM] Existing deepfake detectors are general-purpose and do not leverage knowledge of whose identity is being targeted, limiting their effectiveness and explainability in real-world scenarios where the target identity is known.\\n[SOLUTION] Reformulate deepfake detection as an identity-aware, fine-grained face recognition problem that explicitly incorporates both global and detailed facial priors of the target individual.\\n[INSIGHT] Personalized detection can be improved by aligning suspect images with known authentic identity features and attributes.',\n",
       "   '[SETTING] RIS / complex linguistic scenarios\\n[PROBLEM] RIS models struggle with object-distracting and category-implicit expressions, where misleading context or lack of explicit object categories hinders accurate segmentation.\\n[SOLUTION] Use the Saccade operation for rapid global scanning to establish initial correspondence, followed by the Fixation operation for region-wise inspection with reiterated textual cues.\\n[INSIGHT] Region-wise inspection guided by repeated textual context allows the model to disambiguate complex or implicit references.',\n",
       "   '[SETTING] Event-based video frame interpolation / feature alignment\\n[PROBLEM] There exists a distribution gap between semantic-perceptual features extracted from keyframes and ground truth data, which can hinder effective frame interpolation.\\n[SOLUTION] Align feature distributions using a Bidirectional Event-Guided Alignment (BEGA) module that leverages inter-frame temporal cues from event data in a hierarchical manner.\\n[INSIGHT] Event data provides fine-grained temporal information that can guide more precise feature alignment for frame interpolation.',\n",
       "   '[SETTING] Semantic segmentation / 2D-3D integration\\n[PROBLEM] Decoupled learning of 2D priors and 3D representations leads to limited modeling of appearance and motion, preventing coherent predictions.\\n[SOLUTION] Jointly refine 2D semantic priors and 3D attributes through iterative semantic refinement and alignment between rendered 3D masks and 2D predictions.\\n[INSIGHT] Iterative alignment and joint refinement of 2D and 3D information improve semantic and motion coherence.',\n",
       "   '[SETTING] Text-conditioned image super-resolution / inference-time guidance\\n[PROBLEM] Prompt extraction methods may fail to provide guidance for all image regions, leaving some areas ungrounded and susceptible to irrelevant text influence.\\n[SOLUTION] Introduce Spatially Targeted Classifier-Free Guidance (STCFG) to selectively disable text conditioning in ungrounded regions during inference.\\n[INSIGHT] Suppressing text guidance in ungrounded regions avoids undesired semantic artifacts where no reliable prompt is available.',\n",
       "   '[SETTING] Large-scale 3D scene reconstruction / explicit representation\\n[PROBLEM] Divide-and-conquer 3DGS methods require complex, scene-specific parameter tuning for block partitioning and image assignment, leading to inefficiency and manual intervention.\\n[SOLUTION] Treat the entire scene as a holistic optimization problem, eliminating the need for manual block partitioning and threshold adjustments.\\n[INSIGHT] Global optimization over the whole scene removes the dependency on hand-tuned partitioning parameters.',\n",
       "   '[SETTING] Depth estimation / synthetic 3D scene perturbations\\n[PROBLEM] Existing robustness evaluations for depth estimation primarily address 2D image corruptions and neglect 3D scene and camera variations relevant to real-world applications.\\n[SOLUTION] Introduce a suite of 3D scene perturbations—including camera movement, object articulation, and material changes—using a photorealistic procedural generator to test model robustness.\\n[INSIGHT] Evaluating with 3D scene perturbations uncovers vulnerabilities in depth models that are missed by 2D corruption tests.'],\n",
       "  'supporting_items': [{'paper_id': 'uG8kRtNGEI',\n",
       "    'title': 'Fix False Transparency by Noise Guided Splatting'},\n",
       "   {'paper_id': 'yjLew3Nd7z', 'title': 'Part-Level Visual Understanding'},\n",
       "   {'paper_id': 'fVgnP5WHXX',\n",
       "    'title': 'VADTree: Explainable Training-Free Video Anomaly Detection via Hierarchical Granularity-Aware Tree'},\n",
       "   {'paper_id': 'bA02DmQN5d',\n",
       "    'title': \"Vision Transformers Don't Need *Trained* Registers\"},\n",
       "   {'paper_id': 'KUHrL5NYHe',\n",
       "    'title': 'SEGA: Shaping Semantic Geometry for Robust Hashing under Noisy Supervision'},\n",
       "   {'paper_id': 'igtjRQfght',\n",
       "    'title': 'ENERVERSE: Envisioning Embodied Future Space for Robotics Manipulation'},\n",
       "   {'paper_id': 'BG0Hbee5si',\n",
       "    'title': 'Beyond the Seen: Bounded Distribution Estimation for Open-Vocabulary Learning'},\n",
       "   {'paper_id': 'v6kyF3S7dM',\n",
       "    'title': 'FLEX-Judge: Text-Only Reasoning Unleashes Zero-Shot Multimodal Evaluators'},\n",
       "   {'paper_id': 'OF7OLxvY0t',\n",
       "    'title': 'Training-Free Test-Time Adaptation via Shape and Style Guidance for Vision-Language Models'},\n",
       "   {'paper_id': 'qUnjCEcN6S',\n",
       "    'title': 'Incomplete Multi-view Deep Clustering with Data Imputation and Alignment'},\n",
       "   {'paper_id': 'oQYq9L1NVT',\n",
       "    'title': 'Deep Video Discovery : Agentic Search with Tool Use for Long-form Video Understanding'},\n",
       "   {'paper_id': 'vDV912fa3t',\n",
       "    'title': 'TrackingWorld: World-centric Monocular 3D Tracking of Almost All Pixels'},\n",
       "   {'paper_id': 'ILr4UNiZcQ',\n",
       "    'title': 'Vision as a Dialect: Unifying Visual Understanding and Generation via Text-Aligned Representations'},\n",
       "   {'paper_id': 'Kq08RIeXxI',\n",
       "    'title': 'Panoptic Captioning: An Equivalence Bridge for Image and Text'},\n",
       "   {'paper_id': 'XewZ4rJYKZ',\n",
       "    'title': 'ReservoirTTA: Prolonged Test-time Adaptation for Evolving and Recurring Domains'},\n",
       "   {'paper_id': '7nTWoceJGK', 'title': 'Abstract'},\n",
       "   {'paper_id': 'TrHeq0yFhv',\n",
       "    'title': 'SensorLM: Learning the Language of Wearable Sensors'},\n",
       "   {'paper_id': 'CwXyUdqFqW',\n",
       "    'title': 'MAGNET: A Multi-agent Framework for Finding Audio-Visual Needles by Reasoning over Multi-Video Haystacks'},\n",
       "   {'paper_id': 'F9SSJLg55j',\n",
       "    'title': 'Unleashing the Potential of Multimodal LLMs for Zero-Shot Spatio-Temporal Video Grounding'},\n",
       "   {'paper_id': '0g9gVoA7sn',\n",
       "    'title': 'Dual-Space Semantic Synergy Distillation for Continual Learning of Unlabeled Streams'},\n",
       "   {'paper_id': 'sFyTsO2qO3',\n",
       "    'title': 'Disentangled Cross-Modal Representation Learning with Enhanced Mutual Supervision'},\n",
       "   {'paper_id': 'M6l3pyvUfr',\n",
       "    'title': 'TRIDENT: Tri-Modal Molecular Representation Learning with Taxonomic Annotations and Local Correspondence'},\n",
       "   {'paper_id': 'SBPWnXhwjq',\n",
       "    'title': '**Emergent Temporal Correspondences from Video Diffusion Transformers**'},\n",
       "   {'paper_id': 'q39uZC6RSo',\n",
       "    'title': 'Foresight: Adaptive Layer Reuse for Accelerated and High-Quality Text-to-Video Generation'},\n",
       "   {'paper_id': 'fmCnNQjZrr',\n",
       "    'title': 'STAR: Spatial-Temporal Tracklet Matching for Multi-Object Tracking'},\n",
       "   {'paper_id': '0rVD66dXqT',\n",
       "    'title': '*Gaze-VLM:* Bridging Gaze and VLMs via Attention Regularization for Egocentric Understanding'},\n",
       "   {'paper_id': '1iSnpztjbD',\n",
       "    'title': 'Compositional Discrete Latent Code for High Fidelity, Productive Diffusion Models'},\n",
       "   {'paper_id': 'a2JTVVvcEl',\n",
       "    'title': 'Video-R1: Reinforcing Video Reasoning in MLLMs'},\n",
       "   {'paper_id': 'oIBwHvF930',\n",
       "    'title': 'MEGADance: Mixture-of-Experts Architecture for Genre-Aware 3D Dance Generation'},\n",
       "   {'paper_id': 'kcSbYJRQub',\n",
       "    'title': 'AR-RAG: Autoregressive Retrieval Augmentation for Image Generation'}]},\n",
       " {'pattern_id': 27,\n",
       "  'pattern_name': None,\n",
       "  'pattern_description': None,\n",
       "  'cluster_size': 84,\n",
       "  'examples': ['[SETTING] RNN expressivity / formal language analysis\\n[PROBLEM] Existing literature on RNN expressivity lacks a unified, principled framework, making it difficult to compare results due to differing assumptions and finite-precision models.\\n[SOLUTION] Introduce Metric Automata Theory (MAT) as a general framework that formalizes and unifies the analysis of RNNs and their expressivity under various settings.\\n[INSIGHT] A common theoretical foundation enables direct comparison and transfer of results across different RNN architectures and finite-precision assumptions.',\n",
       "   '[SETTING] Symbolic reasoning / transformer architecture\\n[PROBLEM] It is unknown whether simple transformer architectures can perform OCR and what architectural factors affect this ability.\\n[SOLUTION] Demonstrate empirically that a one-layer single-head attention-only transformer with separate output and value matrices can perform OCR, while a reparameterized model with combined output-value weights cannot.\\n[INSIGHT] The separation of output and value matrices in the transformer is critical for enabling OCR.',\n",
       "   '[SETTING] Sequence generation / discrete diffusion\\n[PROBLEM] Autoregressive language models generate sequences token by token, making it difficult to enforce global sequence-level constraints, which can lead to unreliable or unsafe outputs.\\n[SOLUTION] Replace autoregressive generation with discrete diffusion models that denoise entire sequences iteratively, allowing for global constraint enforcement at each step.\\n[INSIGHT] Discrete diffusion models provide a global view of the sequence at each step, enabling natural integration of constraint enforcement mechanisms.',\n",
       "   '[SETTING] Model parallelism / transformer architectures\\n[PROBLEM] Existing communication-efficient techniques for distributed data parallelism (DDP) cannot be directly applied to model parallelism because activations, unlike weight gradients, do not exhibit redundancy and are sensitive to approximation errors.\\n[SOLUTION] Design a compression algorithm specifically for MP that leverages the recursive structure of transformers to enable lossless reconstruction of activations after compression.\\n[INSIGHT] The recursive structure of transformer networks allows for a principled decomposition of activations, facilitating effective compression.',\n",
       "   '[SETTING] Transformer attention with bias / GPU acceleration\\n[PROBLEM] Existing attention acceleration methods focus on masks, exploiting their sparsity, but do not address the dense and continuous nature of attention bias matrices, leading to high memory IO costs.\\n[SOLUTION] Reduce IO overload by representing attention bias matrices in low-rank form, enabling efficient computation via matrix multiplications instead of element-wise operations.\\n[INSIGHT] Most commonly used attention biases are inherently low-rank, allowing for significant IO reduction through low-rank factorization.',\n",
       "   '[SETTING] Model explanation / safety-sensitive interpretability\\n[PROBLEM] Approximate methods like Attention Rollout reduce computation but distort information propagation by ignoring global flow constraints, leading to potentially misleading explanations.\\n[SOLUTION] Preserve global flow properties by designing pruning operations that maintain the critical structure required for faithful max-flow computation.\\n[INSIGHT] Maintaining flow conservation and capacity constraints is essential for accurate interpretability in safety-critical applications.',\n",
       "   '[SETTING] mLSTM kernel implementation / language modeling\\n[PROBLEM] Efficient kernels for mLSTM leveraging chunkwise-parallel formulation were missing, limiting scalability and speed compared to other architectures.\\n[SOLUTION] Implement TFLA-based kernels for mLSTM, achieving faster runtimes than highly optimized Attention, Linear Attention, and Mamba kernels.\\n[INSIGHT] Applying TFLA to mLSTM enables both high efficiency and scalability for large-scale language modeling.',\n",
       "   '[SETTING] Layered graph optimization / Transformer architecture\\n[PROBLEM] The strictly layered structure of attention graphs leads to redundancy, as not all layers contribute equally to the minimum cut.\\n[SOLUTION] Compress the graph by removing layers with fewer minimum cut edges and reconnecting adjacent layers to preserve connectivity.\\n[INSIGHT] Layer-wise localization of minimum cut edges enables targeted compression without loss of critical flow paths.',\n",
       "   '[SETTING] RNN/sequence modeling / memory access\\n[PROBLEM] RNN-based models suffer from an information bottleneck, lacking random access to contextual information, which impairs performance on tasks requiring long-term memory.\\n[SOLUTION] Enable random access and long-term memory by augmenting RNNs with a hierarchical sparse attention mechanism that learns chunk-aware token-to-chunk relevance.\\n[INSIGHT] Chunk-aware learning allows the model to maintain random access flexibility without sacrificing efficiency.',\n",
       "   '[SETTING] Positional encoding / empirical analysis\\n[PROBLEM] Existing positional embedding methods (e.g., RoPE, ALiBi, NoPE) have unclear trade-offs regarding their impact on long context performance and overall model quality.\\n[SOLUTION] Systematically analyze and benchmark different positional encoding strategies and their combinations within the hybrid model.\\n[INSIGHT] Empirical analysis of attention patterns reveals which positional information and biases are most beneficial for long context tasks.'],\n",
       "  'supporting_items': [{'paper_id': 'lE2cD7C9fk',\n",
       "    'title': 'On Inductive Biases That Enable Generalization of Diffusion Transformers'},\n",
       "   {'paper_id': 'b6H64u6TqI',\n",
       "    'title': 'Tiled Flash Linear Attention: More Efficient Linear RNN and xLSTM Kernels'},\n",
       "   {'paper_id': 'lwIQC4MVJZ',\n",
       "    'title': 'Efficient Large Language Model Inference with Neural Block Linearization'},\n",
       "   {'paper_id': 'Tp6ds3Dfqo',\n",
       "    'title': 'Rope to Nope and Back Again: A New Hybrid Attention Strategy'},\n",
       "   {'paper_id': 'LZrRvYBqsJ',\n",
       "    'title': '**Δ Attention: Fast and Accurate Sparse Attention Inference by Delta Correction**'},\n",
       "   {'paper_id': 'v6vBK4t8vB',\n",
       "    'title': 'Bilevel ZOFO: Efficient LLM Fine-Tuning and Meta-Training'},\n",
       "   {'paper_id': 'bk1IlSAwxR',\n",
       "    'title': 'RAT : Bridging RNN Efficiency and Attention Accuracy via Chunk-based Sequence Modeling'},\n",
       "   {'paper_id': 'q39uZC6RSo',\n",
       "    'title': 'Foresight: Adaptive Layer Reuse for Accelerated and High-Quality Text-to-Video Generation'},\n",
       "   {'paper_id': 'ZYHzcZFEGD',\n",
       "    'title': 'Direct3D-S2: Gigascale 3D Generation Made Easy with Spatial Sparse Attention'},\n",
       "   {'paper_id': '1v0ULVJOZ9',\n",
       "    'title': 'RHYTHM: Reasoning with Hierarchical Temporal Tokenization for Human Mobility'},\n",
       "   {'paper_id': 'dH8mKmvADv',\n",
       "    'title': 'Learning in Compact Spaces with Approximately Normalized Transformer'},\n",
       "   {'paper_id': '7L4NvUtZY3',\n",
       "    'title': 'FlashBias: Fast Computation of Attention with Bias'},\n",
       "   {'paper_id': 'dIHSZTx9Lu',\n",
       "    'title': 'Hardware-aligned Hierarchical Sparse Attention for Efficient Long-term Memory Access'},\n",
       "   {'paper_id': 'M6zQNbCaLl',\n",
       "    'title': 'FlowCut: Rethinking Redundancy via Information Flow for Efficient Vision-Language Models'},\n",
       "   {'paper_id': 'YeZnsJzjii',\n",
       "    'title': 'Metric Automata Theory: A Unifying Theory of RNNs'},\n",
       "   {'paper_id': 'W0DDiJeZo6',\n",
       "    'title': 'Vocabulary In-Context Learning in Transformers: Benefits of Positional Encoding'},\n",
       "   {'paper_id': 'vqaWAmuzRt',\n",
       "    'title': 'EMLoC: Emulator-based Memory-efficient Fine-tuning with LoRA Correction'},\n",
       "   {'paper_id': 'IFQBrEAuQ6', 'title': 'Rethinking PCA Through Duality'},\n",
       "   {'paper_id': 'iZk78dZ1Ap',\n",
       "    'title': 'Gemstones: A Model Suite for Multi-Faceted Scaling Laws'},\n",
       "   {'paper_id': 'pOLpyGGOq8',\n",
       "    'title': 'Kinaema: A recurrent sequence model for memory and pose in motion'},\n",
       "   {'paper_id': 'ZkGHzGIaMB',\n",
       "    'title': 'Generalization or Hallucination? Understanding Out-of-Context Reasoning in Transformers'},\n",
       "   {'paper_id': 'Y4ZMHNhrPT',\n",
       "    'title': 'SaFiRe: Saccade-Fixation Reiteration with Mamba for Referring Image Segmentation'},\n",
       "   {'paper_id': 'Es4s9dtCjR', 'title': 'Constrained Discrete Diffusion'},\n",
       "   {'paper_id': 'zJzu9evD5K',\n",
       "    'title': 'LittleBit: Ultra Low-Bit Quantization via Latent Factorization'},\n",
       "   {'paper_id': 'fyeSq3m8CY',\n",
       "    'title': 'A Mathematical Description of MLP and Attention Using Partial Channel–Reduce'},\n",
       "   {'paper_id': 'XxR70zr9Sf',\n",
       "    'title': 'Linear Transformers Implicitly Discover Unified Numerical Algorithms'},\n",
       "   {'paper_id': 'kke9TwtKi0',\n",
       "    'title': 'Subspace Networks: Scaling Decentralized Training with Communication-Efficient Model Parallelism'},\n",
       "   {'paper_id': 'e2WesV6Voe',\n",
       "    'title': '**Sequence Modeling with Spectral Mean Flows**'},\n",
       "   {'paper_id': '3SUkvb8PRo',\n",
       "    'title': 'FlowPrune: Accelerating Attention Flow Calculation by Pruning Flow Network'},\n",
       "   {'paper_id': 'paiyYD81Wr',\n",
       "    'title': 'L Zero-Shot Performance Prediction for Bilingual Translation (Train-Test Split as in the Main Paper)'}]}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# 先生成基础 pattern doc（不含 LLM 命名）\n",
    "pattern_docs = []\n",
    "for cid, sub in df_ps[df_ps[\"cluster\"] != -1].groupby(\"cluster\"):\n",
    "    # examples：放 10 条最典型/随机\n",
    "    ex = sub[\"cluster_text\"].sample(n=min(10, len(sub)), random_state=0).tolist()\n",
    "\n",
    "    doc = {\n",
    "        \"pattern_id\": int(cid),\n",
    "        \"pattern_name\": None,            # Step 2 填\n",
    "        \"pattern_description\": None,     # Step 2 填\n",
    "        \"cluster_size\": int(len(sub)),\n",
    "        \"examples\": ex,\n",
    "    }\n",
    "\n",
    "    # 如果你有 paper_id/title，可以一起带上（可选）\n",
    "    if \"paper_id\" in sub.columns or \"title\" in sub.columns:\n",
    "        keep_cols = [c for c in [\"paper_id\", \"title\"] if c in sub.columns]\n",
    "        if keep_cols:\n",
    "            doc[\"supporting_items\"] = sub[keep_cols].drop_duplicates().head(30).to_dict(\"records\")\n",
    "\n",
    "    pattern_docs.append(doc)\n",
    "\n",
    "pattern_docs = sorted(pattern_docs, key=lambda x: x[\"cluster_size\"], reverse=True)\n",
    "pattern_docs[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e925ac3c",
   "metadata": {},
   "source": [
    "## 9. Cluster Naming（LLM 自动生成套路名）: 给 cluster 做 LLM 命名 + coherence score\n",
    "\n",
    "coherence score：建议 1–5 分\n",
    "并让它输出 “why” 的一句话理由（方便你写论文分析）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ba83384a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "CLUSTER_SYS = \"\"\"\n",
    "You are a research methods analyst. You name reusable research patterns and evaluate cluster coherence.\n",
    "Be specific and avoid generic phrases.\n",
    "Return valid JSON only.\n",
    "\"\"\".strip()\n",
    "\n",
    "CLUSTER_USER = \"\"\"\n",
    "Given the following research settings, problems and solutions pair (all from the same cluster), do:\n",
    "\n",
    "1) Provide a short, specific pattern_name (<= 8 words).\n",
    "2) Provide a 1-2 sentence pattern_description describing the shared reusable technique.\n",
    "3) Provide a setting that this pattern applies to.\n",
    "4) Provide a base problem that this pattern addresses.\n",
    "5) Provide a base solution that this pattern implements.\n",
    "6) Rate coherence_score from 1 to 5:\n",
    "   - 5: highly coherent, same reusable pattern\n",
    "   - 3: somewhat coherent, related but mixed\n",
    "   - 1: incoherent, unrelated items\n",
    "7) Provide one-sentence rationale.\n",
    "\n",
    "Return JSON:\n",
    "{{\n",
    "  \"pattern_name\": \"...\",\n",
    "  \"pattern_description\": \"...\",\n",
    "  \"setting\": \"...\",\n",
    "  \"base_problem\": \"...\",\n",
    "  \"base_solution\": \"...\",\n",
    "  \"coherence_score\": <int 1-5>,\n",
    "  \"rationale\": \"...\"\n",
    "}}\n",
    "\n",
    "problem-solution pairs:\n",
    "{texts}\n",
    "\"\"\".strip()\n",
    "\n",
    "def name_and_score_cluster(df, model=\"gpt-4.1\"):\n",
    "    joined = \"\\n\\n---\\n\\n\".join(df[:12])  # 8~12 条足够\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": CLUSTER_SYS},\n",
    "            {\"role\": \"user\", \"content\": CLUSTER_USER.format(texts=joined)},\n",
    "        ],\n",
    "        temperature=0,\n",
    "        # 如果你模型支持强制 JSON，可以开这个：\n",
    "        # response_format={\"type\":\"json_object\"},\n",
    "        timeout=90,\n",
    "    )\n",
    "    return json.loads(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8416c94",
   "metadata": {},
   "source": [
    "对所有 pattern_docs 批量命名 + 打分（带 checkpoint）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9659ce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] cluster=9 size=352 score=3 name=Granularity-Aware Reasoning\n",
      "[OK] cluster=27 size=84 score=5 name=Architecture-Aware Compression & Constraint\n",
      "[OK] cluster=37 size=78 score=5 name=Adaptive Reasoning Optimization\n",
      "[OK] cluster=28 size=72 score=5 name=Adaptive Parameterization and Routing\n",
      "[OK] cluster=20 size=67 score=5 name=Diffusion Model Optimization Patterns\n",
      "[OK] cluster=18 size=65 score=5 name=Structure-Aware Graph Uncertainty Modeling\n",
      "[OK] cluster=11 size=37 score=5 name=Symmetry-Constrained Generative Modeling\n",
      "[OK] cluster=0 size=36 score=5 name=Assumption-Driven Causal Identification\n",
      "[OK] cluster=42 size=33 score=5 name=Loss Decomposition and Policy Unification\n",
      "[OK] cluster=8 size=29 score=5 name=Interaction-Aware Attribution\n",
      "[OK] cluster=25 size=29 score=5 name=Context-Aware Cache and Decoding Optimization\n",
      "[OK] cluster=30 size=29 score=5 name=Geometry-Aware Optimization Extensions\n",
      "[OK] cluster=38 size=28 score=5 name=Systematic Safety Stress Testing\n",
      "[OK] cluster=5 size=26 score=5 name=Fairness-Aware Data Synthesis\n",
      "[OK] cluster=29 size=25 score=5 name=Theory-Empirics Generalization Bridge\n",
      "[OK] cluster=41 size=25 score=5 name=Context-Aware Reward Decomposition\n",
      "[OK] cluster=3 size=23 score=5 name=Physics-Informed Temporal Modeling\n",
      "[OK] cluster=32 size=22 score=5 name=Sample Complexity Tightening\n",
      "[OK] cluster=39 size=22 score=4 name=Context-Aware LLM Enhancement\n",
      "[OK] cluster=34 size=21 score=5 name=Constraint-Aware Algorithmic Design\n",
      "[OK] cluster=6 size=20 score=5 name=DP-Aware Aggregation for LoRA\n",
      "[OK] cluster=10 size=20 score=5 name=Physics-Informed Spectral Structuring\n",
      "[OK] cluster=15 size=20 score=5 name=Physics-Guided Unsupervised Regularization\n",
      "[OK] cluster=22 size=19 score=5 name=Automated Feedback and Search Steering\n",
      "[OK] cluster=13 size=18 score=4 name=Relaxed Approximation and Reduction\n",
      "[OK] cluster=35 size=18 score=5 name=Collaborative Multi-Agent Reasoning\n",
      "[OK] cluster=26 size=17 score=5 name=Internal Self-Distillation for SNNs\n",
      "[OK] cluster=14 size=15 score=5 name=Hybrid Flow Matching Fine-Tuning\n",
      "[OK] cluster=24 size=13 score=5 name=Cross-Participant Generalization\n",
      "[OK] cluster=31 size=13 score=5 name=Bilevel Distribution Adjustment\n",
      "[OK] cluster=40 size=13 score=5 name=Structure-Aware Robustness and Estimation\n",
      "[OK] cluster=4 size=12 score=5 name=Spectral-Spatial Decomposition\n",
      "[OK] cluster=12 size=12 score=5 name=Structure-Aware Alignment and Feature Fusion\n",
      "[OK] cluster=1 size=11 score=5 name=Quantum Resource-Aware Algorithm Design\n",
      "[OK] cluster=21 size=11 score=5 name=Structure-Aware Langevin Preconditioning\n",
      "[OK] cluster=19 size=10 score=5 name=Decoupled Hebbian Projection\n",
      "[OK] cluster=36 size=10 score=5 name=Multi-Label Human Judgment Elicitation\n",
      "[OK] cluster=16 size=9 score=5 name=Foundation Model-Driven SBI\n",
      "[OK] cluster=23 size=9 score=5 name=Disentangled Bottleneck Learning\n",
      "[OK] cluster=2 size=8 score=5 name=SOS Certification & Threshold Bounding\n",
      "[OK] cluster=7 size=8 score=5 name=Advanced Quantization Optimization\n",
      "[OK] cluster=17 size=8 score=5 name=Structured High-Order Variational Inference\n",
      "[OK] cluster=33 size=8 score=3 name=Adversarial Robustness via Factor Optimization\n"
     ]
    }
   ],
   "source": [
    "import os, time\n",
    "\n",
    "OUT_JSONL = OUT_DIR/\"pattern_library_mcs8.jsonl\"\n",
    "\n",
    "def append_jsonl(path, obj):\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "def load_done_ids(path):\n",
    "    done = set()\n",
    "    if not os.path.exists(path):\n",
    "        return done\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                done.add(json.loads(line)[\"pattern_id\"])\n",
    "            except:\n",
    "                pass\n",
    "    return done\n",
    "\n",
    "done = load_done_ids(OUT_JSONL)\n",
    "\n",
    "for doc in pattern_docs:\n",
    "    pid = doc[\"pattern_id\"]\n",
    "    if pid in done:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        info = name_and_score_cluster(doc[\"examples\"])\n",
    "        doc2 = {**doc, **info}\n",
    "        append_jsonl(OUT_JSONL, doc2)\n",
    "        print(f\"[OK] cluster={pid} size={doc['cluster_size']} score={doc2['coherence_score']} name={doc2['pattern_name']}\")\n",
    "        time.sleep(0.2)  # 温和一点，避免限速\n",
    "    except Exception as e:\n",
    "        append_jsonl(OUT_JSONL, {\"pattern_id\": pid, \"error\": str(e), \"cluster_size\": doc[\"cluster_size\"]})\n",
    "        print(f\"[FAIL] cluster={pid} err={e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51ab54b",
   "metadata": {},
   "source": [
    "汇总成 DataFrame（便于筛选“高质量套路”）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "68c36e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "with open(OUT_JSONL, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        rows.append(json.loads(line))\n",
    "\n",
    "pattern_df = pd.DataFrame(rows)\n",
    "pattern_df = pattern_df[pattern_df.get(\"error\").isna() if \"error\" in pattern_df.columns else slice(None)]\n",
    "#pattern_df.sort_values([\"coherence_score\", \"cluster_size\"], ascending=[False, False]).head(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9ca5d3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern_id</th>\n",
       "      <th>pattern_name</th>\n",
       "      <th>pattern_description</th>\n",
       "      <th>cluster_size</th>\n",
       "      <th>examples</th>\n",
       "      <th>supporting_items</th>\n",
       "      <th>setting</th>\n",
       "      <th>base_problem</th>\n",
       "      <th>base_solution</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>rationale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>Granularity-Aware Reasoning</td>\n",
       "      <td>This pattern constructs hierarchical or multi-...</td>\n",
       "      <td>352</td>\n",
       "      <td>[[SETTING] Explainable VAD / multi-granularity...</td>\n",
       "      <td>[{'paper_id': 'uG8kRtNGEI', 'title': 'Fix Fals...</td>\n",
       "      <td>Explainable VAD / multi-granularity reasoning</td>\n",
       "      <td>Existing methods struggle to comprehensively u...</td>\n",
       "      <td>Construct a hierarchical granularity-aware tre...</td>\n",
       "      <td>3</td>\n",
       "      <td>While several pairs use hierarchical or multi-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>Architecture-Aware Compression &amp; Constraint</td>\n",
       "      <td>This pattern leverages the structural properti...</td>\n",
       "      <td>84</td>\n",
       "      <td>[[SETTING] RNN expressivity / formal language ...</td>\n",
       "      <td>[{'paper_id': 'lE2cD7C9fk', 'title': 'On Induc...</td>\n",
       "      <td>Transformer and RNN architectures for sequence...</td>\n",
       "      <td>Standard methods for model analysis, compressi...</td>\n",
       "      <td>Develop architecture-aware algorithms that exp...</td>\n",
       "      <td>5</td>\n",
       "      <td>All pairs employ a reusable strategy of exploi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Adaptive Reasoning Optimization</td>\n",
       "      <td>This pattern involves adaptively structuring, ...</td>\n",
       "      <td>78</td>\n",
       "      <td>[[SETTING] LLM training / multi-format reasoni...</td>\n",
       "      <td>[{'paper_id': 'D8nHwexHNv', 'title': 'Unveilin...</td>\n",
       "      <td>LLM training and reasoning optimization across...</td>\n",
       "      <td>Standard training or optimization methods for ...</td>\n",
       "      <td>Introduce adaptive mechanisms—such as step-wis...</td>\n",
       "      <td>5</td>\n",
       "      <td>All pairs share the core technique of adaptive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Adaptive Parameterization and Routing</td>\n",
       "      <td>This pattern involves adaptively learning or r...</td>\n",
       "      <td>72</td>\n",
       "      <td>[[SETTING] Scientific ML / large operator mode...</td>\n",
       "      <td>[{'paper_id': '4ULtNYHc5T', 'title': 'Explorin...</td>\n",
       "      <td>LLM training, scientific ML adaptation, solver...</td>\n",
       "      <td>Static or naive parameter choices, knowledge t...</td>\n",
       "      <td>Dynamically learn, route, or adjust parameters...</td>\n",
       "      <td>5</td>\n",
       "      <td>All pairs share the core technique of adaptive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>Diffusion Model Optimization Patterns</td>\n",
       "      <td>These research problems and solutions share th...</td>\n",
       "      <td>67</td>\n",
       "      <td>[[SETTING] RL value estimation / continuous co...</td>\n",
       "      <td>[{'paper_id': 'YB9VGCClv9', 'title': 'Diffusio...</td>\n",
       "      <td>Diffusion model inference and training across ...</td>\n",
       "      <td>Standard diffusion model methods suffer from i...</td>\n",
       "      <td>Introduce novel optimization methods, unified ...</td>\n",
       "      <td>5</td>\n",
       "      <td>All pairs focus on advancing diffusion model m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pattern_id                                 pattern_name  \\\n",
       "0           9                  Granularity-Aware Reasoning   \n",
       "1          27  Architecture-Aware Compression & Constraint   \n",
       "2          37              Adaptive Reasoning Optimization   \n",
       "3          28        Adaptive Parameterization and Routing   \n",
       "4          20        Diffusion Model Optimization Patterns   \n",
       "\n",
       "                                 pattern_description  cluster_size  \\\n",
       "0  This pattern constructs hierarchical or multi-...           352   \n",
       "1  This pattern leverages the structural properti...            84   \n",
       "2  This pattern involves adaptively structuring, ...            78   \n",
       "3  This pattern involves adaptively learning or r...            72   \n",
       "4  These research problems and solutions share th...            67   \n",
       "\n",
       "                                            examples  \\\n",
       "0  [[SETTING] Explainable VAD / multi-granularity...   \n",
       "1  [[SETTING] RNN expressivity / formal language ...   \n",
       "2  [[SETTING] LLM training / multi-format reasoni...   \n",
       "3  [[SETTING] Scientific ML / large operator mode...   \n",
       "4  [[SETTING] RL value estimation / continuous co...   \n",
       "\n",
       "                                    supporting_items  \\\n",
       "0  [{'paper_id': 'uG8kRtNGEI', 'title': 'Fix Fals...   \n",
       "1  [{'paper_id': 'lE2cD7C9fk', 'title': 'On Induc...   \n",
       "2  [{'paper_id': 'D8nHwexHNv', 'title': 'Unveilin...   \n",
       "3  [{'paper_id': '4ULtNYHc5T', 'title': 'Explorin...   \n",
       "4  [{'paper_id': 'YB9VGCClv9', 'title': 'Diffusio...   \n",
       "\n",
       "                                             setting  \\\n",
       "0      Explainable VAD / multi-granularity reasoning   \n",
       "1  Transformer and RNN architectures for sequence...   \n",
       "2  LLM training and reasoning optimization across...   \n",
       "3  LLM training, scientific ML adaptation, solver...   \n",
       "4  Diffusion model inference and training across ...   \n",
       "\n",
       "                                        base_problem  \\\n",
       "0  Existing methods struggle to comprehensively u...   \n",
       "1  Standard methods for model analysis, compressi...   \n",
       "2  Standard training or optimization methods for ...   \n",
       "3  Static or naive parameter choices, knowledge t...   \n",
       "4  Standard diffusion model methods suffer from i...   \n",
       "\n",
       "                                       base_solution  coherence_score  \\\n",
       "0  Construct a hierarchical granularity-aware tre...                3   \n",
       "1  Develop architecture-aware algorithms that exp...                5   \n",
       "2  Introduce adaptive mechanisms—such as step-wis...                5   \n",
       "3  Dynamically learn, route, or adjust parameters...                5   \n",
       "4  Introduce novel optimization methods, unified ...                5   \n",
       "\n",
       "                                           rationale  \n",
       "0  While several pairs use hierarchical or multi-...  \n",
       "1  All pairs employ a reusable strategy of exploi...  \n",
       "2  All pairs share the core technique of adaptive...  \n",
       "3  All pairs share the core technique of adaptive...  \n",
       "4  All pairs focus on advancing diffusion model m...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d222d4e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pattern_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m out = \u001b[43mpattern_df\u001b[49m[[\u001b[33m\"\u001b[39m\u001b[33mpattern_id\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpattern_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpattern_description\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcluster_size\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msetting\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mbase_problem\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mbase_solution\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33msupporting_items\u001b[39m\u001b[33m\"\u001b[39m]]\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#out = extract_insights_llm(paper_df.iloc[0][\"paper_text\"])\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#print(json.dumps(out.to_dict(orient=\"records\"), indent=2, ensure_ascii=False))\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'pattern_df' is not defined"
     ]
    }
   ],
   "source": [
    "out = pattern_df[[\"pattern_id\", \"pattern_name\", \"pattern_description\", \"cluster_size\", \"setting\",\"base_problem\",\"base_solution\",\"supporting_items\"]]\n",
    "#out = extract_insights_llm(paper_df.iloc[0][\"paper_text\"])\n",
    "#print(json.dumps(out.to_dict(orient=\"records\"), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "04795fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to jsonl\n",
    "SIM_OUT_JSONL = OUT_DIR/\"NIPS_pattern_library.jsonl\"\n",
    "with open(SIM_OUT_JSONL, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, r in out.iterrows():\n",
    "        f.write(json.dumps(r.to_dict(), ensure_ascii=False) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40508718",
   "metadata": {},
   "source": [
    "## 10. TODO: Finalize paper insights for Knowledge graph\n",
    "* back link cluster_id\n",
    "* correlate with reviews"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
