[{"rid": 0, "reviewer": null, "report": {"main": "- Strengths: This is the first neural network-based approach to argumentation mining. The proposed method used a Pointer Network (PN) model with multi-task learning and outperformed previous methods in the experiments on two datasets.\n- Weaknesses: This is basically an application of PN to argumentation mining. Although the combination of PN and multi-task learning for this task is novel, its novelty is not enough for ACL long publication. The lack of qualitative analysis and error analysis is also a major concern.\n- General Discussion: Besides the weaknesses mentioned above, the use of PN is not well-motivated. Although three characteristics of PN were described in l.138-143, these are not a strong motivation against the use of bi-directional LSTMs and the attention mechanism. The authors should describe what problems are solved by PN and discuss in the experiments how much these problems are solved.\nFigures 2 and 3 are difficult to understand. What are the self link to D1 and the links from D2 to E1 and D3/D4 to E2? These are just the outputs from the decoder and not links. The decoder LSTM does not have an input from e_j in these figures, but it does in Equation (3). Also, in Figure 3, the abbreviation \"FC\" is not defined.\nEquation (8) is strange. To calculate the probability of each component type, the probability of E_i is calculated.\nIn the experiments, I did not understand why only \"PN\", which is not a joint model, was performed for the microtext corpus.\nIt is not clear whether the BLSTM model is trained with the joint-task objective.\nThere are some studies on discourse parsing using the attention mechanism. The authors should describe the differences from these studies.\nMinor issues: l.128: should related -> should be related l.215: (2015) is floating l.706: it able -> it is able I raised my recommendation score after reading the convincing author responses. \nI strongly recommend that the authors should discuss improved examples by PN as well as the details of feature ablation. "}, "scores": {"overall": "3", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "PRESENTATION_FORMAT": "Poster", "SOUNDNESS_CORRECTNESS": "5"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "5", "sentences": {"main": [[0, 13], [13, 86], [86, 235], [235, 249], [249, 313], [313, 444], [444, 521], [521, 543], [543, 620], [620, 789], [789, 915], [915, 960], [960, 1034], [1034, 1093], [1093, 1189], [1189, 1246], [1246, 1271], [1271, 1362], [1362, 1486], [1486, 1568], [1568, 1643], [1643, 1707], [1707, 1721], [1721, 1764], [1764, 1790], [1790, 1819], [1819, 1899], [1899, 2021]]}}}, {"rid": 1, "reviewer": null, "report": {"main": "The paper presents an application of Pointer Networks, a recurrent neural network model original used for solving algorithmic tasks, to two subtasks of Argumentation Mining: determining the types of Argument Components, and finding the links between them. The model achieves state-of-the-art results.\nStrengths: - Thorough review of prior art in the specific formulation of argument mining handled in this paper.\n- Simple and effective modification of an existing model to make it suitable for the task. The model is mostly explained clearly.\n- Strong results as compared to prior art in this task.\nWeaknesses: - 071: This formulation of argumentation mining is just one of several proposed subtask divisions, and this should be mentioned. For example, in [1], claims are detected and classified before any supporting evidence is detected. \nFurthermore, [2] applied neural networks to this task, so it is inaccurate to say (as is claimed in the abstract of this paper) that this work is the first NN-based approach to argumentation mining.\n- Two things must be improved in the presentation of the model: (1) What is the pooling method used for embedding features (line 397)? and (2) Equation (7) in line 472 is not clear enough: is E_i the random variable representing the *type* of AC i, or its *identity*? Both are supposedly modeled (the latter by feature representation), and need to be defined. Furthermore, it seems like the LHS of equation (7) should be a conditional probability.\n- There are several unclear things about Table 2: first, why are the three first baselines evaluated only by macro f1 and the individual f1 scores are missing? \nThis is not explained in the text. Second, why is only the \"PN\" model presented? Is this the same PN as in Table 1, or actually the Joint Model? What about the other three?\n- It is not mentioned which dataset the experiment described in Table 4 was performed on.\nGeneral Discussion: - 132: There has to be a lengthier introduction to pointer networks, mentioning recurrent neural networks in general, for the benefit of readers unfamiliar with \"sequence-to-sequence models\". Also, the citation of Sutskever et al. (2014) in line 145 should be at the first mention of the term, and the difference with respect to recursive neural networks should be explained before the paragraph starting in line 233 (tree structure etc.).\n- 348: The elu activation requires an explanation and citation (still not enough well-known).\n- 501: \"MC\", \"Cl\" and \"Pr\" should be explained in the label.\n- 577: A sentence about how these hyperparameters were obtained would be appropriate.\n- 590: The decision to do early stopping only by link prediction accuracy should be explained (i.e. why not average with type accuracy, for example?).\n- 594: Inference at test time is briefly explained, but would benefit from more details.\n- 617: Specify what the length of an AC is measured in (words?).\n- 644: The referent of \"these\" in \"Neither of these\" is unclear.\n- 684: \"Minimum\" should be \"Maximum\".\n- 694: The performance w.r.t. the amount of training data is indeed surprising, but other models have also achieved almost the same results - this is especially surprising because NNs usually need more data. It would be good to say this.\n- 745: This could alternatively show that structural cues are less important for this task.\n- Some minor typos should be corrected (e.g. \"which is show\", line 161).\n[1] Rinott, Ruty, et al. \"Show Me Your Evidence-an Automatic Method for Context Dependent Evidence Detection.\" EMNLP. 2015.\n[2] Laha, Anirban, and Vikas Raykar. \" An Empirical Evaluation of various Deep Learning Architectures for Bi-Sequence Classification Tasks.\" COLING. 2016. "}, "scores": {"overall": "4", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "PRESENTATION_FORMAT": "Oral Presentation", "SOUNDNESS_CORRECTNESS": "5"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "3", "sentences": {"main": [[0, 256], [256, 301], [301, 312], [312, 413], [413, 504], [504, 543], [543, 599], [599, 611], [611, 740], [740, 840], [840, 1040], [1040, 1175], [1175, 1308], [1308, 1400], [1400, 1488], [1488, 1648], [1648, 1684], [1684, 1730], [1730, 1794], [1794, 1822], [1822, 1912], [1912, 1932], [1932, 2124], [2124, 2372], [2372, 2466], [2466, 2527], [2527, 2613], [2613, 2764], [2764, 2853], [2853, 2918], [2918, 2983], [2983, 3021], [3021, 3051], [3051, 3229], [3229, 3259], [3259, 3351], [3351, 3424], [3424, 3535], [3535, 3542], [3542, 3548], [3548, 3587], [3587, 3689], [3689, 3697], [3697, 3703]]}}}]