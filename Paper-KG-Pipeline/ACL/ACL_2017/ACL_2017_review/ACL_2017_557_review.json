[{"rid": 0, "reviewer": null, "report": {"main": "- Strengths:  - The paper is clearly written and well-structured.   - The system newly applied several techniques including global optimization to end-to-end neural relation extraction, and the direct incorporation of the parser representation is interesting.\n - The proposed system has achieved the state-of-the-art performance on both ACE05 and CONLL04 data sets.\n - The authors include several analyses.\n- Weaknesses:  - The approach is incremental and seems like just a combination of existing methods.    - The improvements on the performance (1.2 percent points on dev) are relatively small, and no significance test results are provided.\n- General Discussion: - Major comments:  - The model employed a recent parser and glove word embeddings. How did they affect the relation extraction performance?\n - In prediction, how did the authors deal with illegal predictions?\n- Minor comments:  - Local optimization is not completely \"local\". It \"considers structural correspondences between incremental decisions,\" so this explanation in the introduction is misleading.\n - Points in Figures 6 and 7 should be connected with straight lines, not curves.\n - How are entities represented in \"-segment\"?\n - Some citations are incomplete. Kingma et al. (2014) is accepted to ICLR, and Li et al. (2014) misses pages. "}, "scores": {"overall": "4", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "PRESENTATION_FORMAT": "Poster", "SOUNDNESS_CORRECTNESS": "3"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "5", "sentences": {"main": [[0, 13], [13, 66], [66, 67], [67, 260], [260, 366], [366, 407], [407, 421], [421, 507], [507, 509], [509, 645], [645, 667], [667, 685], [685, 750], [750, 807], [807, 876], [876, 894], [894, 943], [943, 1071], [1071, 1153], [1153, 1200], [1200, 1234], [1234, 1311]]}}}]