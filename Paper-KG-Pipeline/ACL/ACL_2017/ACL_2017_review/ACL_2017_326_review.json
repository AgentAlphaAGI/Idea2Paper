[{"rid": 0, "reviewer": null, "report": {"main": "- Strengths: The authors use established neural network methods (adversarial networks -- Goodfellow et al, NIPS-2014) to take advantage of 8 different Chinese work breaking test sets, with 8 different notions of what counts as a word in Chinese.\nThis paper could have implications for many NLP tasks where we have slightly different notions of what counts as correct.  We have been thinking of that problem in terms of adaptation, but it is possible that Goodfellow et al is a more useful way of thinking about this problem.\n- Weaknesses: We need a name for the problem mentioned above.  How about: the elusive gold standard.  I prefer that term to multi-criteria.\nThe motivation seems to be unnecessarily narrow.  The elusive gold standard comes up in all sorts of applications, not just Chinese Word Segmentation.\nThe motivation makes unnecessary assumptions about how much the reader knows about Chinese.              When you don't know much about something, you think it is easier than it is.  Many non-Chinese readers (like this reviewer) think that Chinese is simpler than it is.              It is easy to assume that Chinese Word Segmentation is about as easy as tokenizing English text into strings delimited by white space.  But my guess is that IAA (inter-annotator agreement) is pretty low in Chinese.  The point you are trying to make in Table 1 is that there is considerable room for disagreement among native speakers of Chinese.\nI think it would help if you could point out that there are many NLP tasks where there is considerable room for disagreement.  Some tasks like machine translation, information retrieval and web search have so much room for disagreement that the metrics for those tasks have been designed to allow for multiple correct answers.  For other tasks, like part of speech tagging, we tend to sweep the elusive gold standard problem under a rug, and hope it will just go away.  But in fact, progress on tagging has stalled because we don't know how to distinguish differences of opinions from errors.  When two annotators return two different answers, it is a difference of opinion.  But when a machine returns a different answer, the machine is almost always wrong.\nThis reader got stuck on the term: adversary.  I think the NIPS paper used that because it was modeling noise under \"murphy's law.\"  It is often wise to assume the worst.\nBut I don't think it is helpful to think of differences of opinion as an adversarial game like chess.  In chess, it makes sense to think that your opponent is out to get you, but I'm not sure that's the most helpful way to think about differences of opinion.\nI think it would clarify what you are doing to say that you are applying an established method from NIPS (that uses the term \"adversarial\") to deal with the elusive gold standard problem.  And then point out that the elusive gold standard problem is a very common problem.  You will study it in the context of a particular problem in Chinese, but the problem is much more general than that.\n- General Discussion: I found much of the paper unnecessarily hard going.  I'm not up on Chinese or the latest in NIPS, which doesn't help.  But even so, there are some small issues with English, and some larger problems with exposition.\nConsider Table 4.  Line 525 makes an assertion about the first block and depth of networks.  Specifically, which lines in Table 4 support that assertion.\nI assume that P and R refer to precision and recall, but where is that explained.  I assume that F is the standard F measure, and OOV is out-of-vocabulary, but again, I shouldn't have to assume such things.\nThere are many numbers in Table 4.  What counts as significance?  Which numbers are even comparable?  Can we compare numbers across cols?  Is performance on one collection comparable to performance on another?  Line 560 suggests that the adversarial method is not significant.  What should I take away from Table 4?  Line 794 claims that you have a significant solution to what I call the elusive gold standard problem.              But which numbers in Table 4 justify that claim?\nSmall quibbles about English: works --> work (in many places).  Work is a  mass noun, not a count noun (unlike \"conclusion\").              One can say one conclusion, two conclusions, but more/less/some work (not one work, two works).\nline 493: each dataset, not each datasets line 485: Three datasets use traditional Chinese (AS, CITY, CKIP) and the other five use simplified Chinese.\nline 509: random --> randomize "}, "scores": {"overall": "4", "SUBSTANCE": "5", "APPROPRIATENESS": "5", "PRESENTATION_FORMAT": "Poster", "SOUNDNESS_CORRECTNESS": "5"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "3", "sentences": {"main": [[0, 13], [13, 246], [246, 368], [368, 525], [525, 539], [539, 587], [587, 626], [626, 665], [665, 714], [714, 816], [816, 908], [908, 998], [998, 1087], [1087, 1235], [1235, 1315], [1315, 1446], [1446, 1572], [1572, 1773], [1773, 1915], [1915, 2039], [2039, 2121], [2121, 2205], [2205, 2251], [2251, 2337], [2337, 2376], [2376, 2478], [2478, 2635], [2635, 2823], [2823, 2908], [2908, 3026], [3026, 3048], [3048, 3100], [3100, 3166], [3166, 3264], [3264, 3282], [3282, 3356], [3356, 3418], [3418, 3500], [3500, 3625], [3625, 3660], [3660, 3690], [3690, 3726], [3726, 3763], [3763, 3835], [3835, 3902], [3902, 3941], [3941, 4045], [4045, 4107], [4107, 4137], [4137, 4170], [4170, 4233], [4233, 4342], [4342, 4384], [4384, 4493], [4493, 4524]]}}}, {"rid": 1, "reviewer": null, "report": {"main": "The paper proposes a method to train models for Chinese word segmentation (CWS) on datasets having multiple segmentation criteria.\n- Strengths: 1. Multi-criteria learning is interesting and promising. \n2. The proposed model is also interesting and achieves a large improvement from baselines.\n- Weaknesses: 1. The proposed method is not compared with other CWS models. The baseline model (Bi-LSTM) is proposed in [1] and [2]. However, these model is proposed not for CWS but for POS tagging and NE tagging. The description \"In this paper, we employ the state-of-the-art architecture ...\" (in Section 2) is misleading. \n2. The purpose of experiments in Section 6.4 is unclear. In Sec. 6.4, the purpose is that investigating \"datasets in traditional Chinese and simplified Chinese could help each other.\" However, in the experimental setting, the model is separately trained on simplified Chinese and traditional Chinese, and the shared parameters are fixed after training on simplified Chinese. What is expected to fixed shared parameters?\n- General Discussion: The paper should be more interesting if there are more detailed discussion about the datasets that adversarial multi-criteria learning does not boost the performance.\n[1] Zhiheng Huang, Wei Xu, and Kai Yu. 2015. Bidirectional lstm-crf models for sequence tagging. arXiv preprint arXiv:1508.01991. \n[2] Xuezhe Ma and Eduard Hovy. 2016. End-to-end sequence labeling via bi-directional lstm-cnns-crf. arXiv preprint arXiv:1603.01354 . "}, "scores": {"overall": "4", "SUBSTANCE": "5", "APPROPRIATENESS": "5", "PRESENTATION_FORMAT": "Oral Presentation", "SOUNDNESS_CORRECTNESS": "5"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "4", "sentences": {"main": [[0, 131], [131, 147], [147, 201], [201, 205], [205, 293], [293, 310], [310, 369], [369, 426], [426, 507], [507, 618], [618, 622], [622, 676], [676, 803], [803, 994], [994, 1039], [1039, 1228], [1228, 1267], [1267, 1273], [1273, 1325], [1325, 1358], [1358, 1390], [1390, 1396], [1396, 1459], [1459, 1493]]}}}]