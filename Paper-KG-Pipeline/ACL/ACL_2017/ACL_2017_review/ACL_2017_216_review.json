[{"rid": 0, "reviewer": null, "report": {"main": "- Strengths: 1. The idea of assigning variable-length document segments with dependent topics is novel. This prior knowledge is worth incorporated in the LDA-based framework. \n2. Whereas we do not have full knowledge on recent LDA literature, we find the part of related work quite convincing. \n3. The method proposed for segment sampling with O(M) complexity is impressive. \nIt is crucial for efficient computation.  - Weaknesses: 1. Compared to Balikas COLING16's work, the paper has a weaker visualization (Fig 5), which makes us doubt about the actual segmenting and assigning results of document. It could be more convincing to give a longer exemplar and make color assignment consistent with topics listed in Figure 4. \n2. Since the model is more flexible than that of Balikas COLING16, it may be underfitting, could you please explain this more?\n- General Discussion: The paper is well written and structured. The intuition introduced in the Abstract and again exemplified in the Introduction is quite convincing. The experiments are of a full range, solid, and achieves better quantitative results against previous works. If the visualization part is stronger, or explained why less powerful visualization, it will be more confident. Another concern is about computation efficiency, since the seminal LDA work proposed to use Variational Inference which is faster during training compared to MCMC, we wish to see the authorâ€™s future development. "}, "scores": {"overall": "4", "SUBSTANCE": "4", "APPROPRIATENESS": "4", "PRESENTATION_FORMAT": "Poster", "SOUNDNESS_CORRECTNESS": "3"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "3", "sentences": {"main": [[0, 16], [16, 104], [104, 175], [175, 179], [179, 294], [294, 298], [298, 375], [375, 417], [417, 418], [418, 435], [435, 602], [602, 725], [725, 729], [729, 853], [853, 917], [917, 1021], [1021, 1130], [1130, 1242], [1242, 1454]]}}}, {"rid": 1, "reviewer": null, "report": {"main": "### Strengths: - Well-written, well-organized - Incorporate topical segmentation to copula LDA to enable the joint learning of segmentation and latent models - Experimental setting is well-designed and show the superiority of the proposed method from several different indicators and datasets ### Weaknesses: - No comparison with \"novel\" segmentation methods ### General Discussion: This paper presents segLDAcop, a joint latent model for topics and segments. \nThis model is based on the copula LDA and incorporates the topical segmentation to the copula LDA. The authors conduct comprehensive experiments by using several different datasets and evaluation metrics to show the superiority of their model.\nThis paper is well-written and well-organized. The proposed model is a reasonable extension of the copula LDA to enable the joint inference of segmentations and topics. Experimental setting is carefully designed and the superiority of the proposed model is fairly validated. \nOne concern is that the authors only use the simple NP segmentation and single word segmentation as segments of the previous method. As noted in the paper, there are many work to smartly generate segments before running LDA though it is largely affected by the bias of statistical or linguistic tools used. The comparison with more novel (state-of-the-art) segments would be preferable to precisely show the validity of the proposed method.\n### Minor comment - In line 105, \"latent radom topics\" -> \"latent random topics\" "}, "scores": {"overall": "4", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "PRESENTATION_FORMAT": "Poster", "SOUNDNESS_CORRECTNESS": "3"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "2", "sentences": {"main": [[0, 15], [15, 46], [46, 158], [158, 293], [293, 309], [309, 359], [359, 460], [460, 560], [560, 705], [705, 752], [752, 874], [874, 980], [980, 1114], [1114, 1288], [1288, 1422], [1422, 1440], [1440, 1503]]}}}]