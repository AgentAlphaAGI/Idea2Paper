[{"rid": 0, "reviewer": null, "report": {"main": "- Strengths: the paper is well-written, except for a few places as described below. The problem the paper tackles is useful. The proposed approach, multigraph-based model, is a variant of MH. The empirical result is solid.\n- Weaknesses: Clarification is needed in several places.\n1. In section 3, in addition to the description of the previous model, MH, you need point out the issues of MH which motivate you to propose a new model.\n2. In section 4, I don't see the reason why separators are introduced. what additional info they convene beyond T/I/O?\n3. section 5.1 does not seem to provide useful info regarding why the new model is superior.\n4. the discussion in section 5.2 is so abstract that I don't get the insights why the new model is better than MH. can you provide examples of spurious structures?  - General Discussion: The paper presents a new model for detecting overlapping entities in text. The new model improves the previous state-of-the-art, MH, in the experiments on a few benchmark datasets. But it is not clear why and how the new model works better. "}, "scores": {"overall": "3", "SUBSTANCE": "3", "APPROPRIATENESS": "5", "PRESENTATION_FORMAT": "Poster", "SOUNDNESS_CORRECTNESS": "4"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "3", "sentences": {"main": [[0, 84], [84, 125], [125, 192], [192, 223], [223, 280], [280, 283], [283, 434], [434, 437], [437, 505], [505, 553], [553, 556], [556, 646], [646, 649], [649, 761], [761, 810], [810, 811], [811, 908], [908, 1014], [1014, 1074]]}}}, {"rid": 1, "reviewer": null, "report": {"main": "The paper suggests an approach based on multigraphs (several edges may link two nodes) for detecting potentially overlapping entities.\nStrengths: The problem itself could be rather interesting especially for crossing entities to decide which one might actually be mentioned in some text. The technique seems to work although the empirically results do not show some \"dramatic\" effect. I like that some words are spent on efficiency compared to a previous system. The paper in general is well-written but also needs some further polishing in some details (see minor remarks below).\nWeaknesses: The problem itself is not really well motivated. Why is it important to detect China as an entity within the entity Bank of China, to stay with the example in the introduction? I do see a point for crossing entities but what is the use case for nested entities? This could be much more motivated to make the reader interested. As for the approach itself, some important details are missing in my opinion: What is the decision criterion to include an edge or not? In lines 229--233 several different options for the I^k_t nodes are mentioned but it is never clarified which edges should be present!\nAs for the empirical evaluation, the achieved results are better than some previous approaches but not really by a large margin. I would not really call the slight improvements as \"outperformed\" as is done in the paper. What is the effect size? Does it really matter to some user that there is some improvement of two percentage points in F_1? What is the actual effect one can observe? How many \"important\" entities are discovered, that have not been discovered by previous methods? Furthermore, what performance would some simplistic dictionary-based method achieve that could also be used to find overlapping things? And in a similar direction: what would some commercial system like Google's NLP cloud that should also be able to detect and link entities would have achieved on the datasets. Just to put the results also into contrast of existing \"commercial\" systems.\nAs for the result discussion, I would have liked to see some more emphasis on actual crossing entities. How is the performance there? This in my opinion is the more interesting subset of overlapping entities than the nested ones. How many more crossing entities are detected than were possible before? Which ones were missed and maybe why? Is the performance improvement due to better nested detection only or also detecting crossing entities? Some general error discussion comparing errors made by the suggested system and previous ones would also strengthen that part.\nGeneral Discussion: I like the problems related to named entity recognition and see a point for recognizing crossing entities. However, why is one interested in nested entities? The paper at hand does not really motivate the scenario and also sheds no light on that point in the evaluation. Discussing errors and maybe advantages with some example cases and an emphasis on the results on crossing entities compared to other approaches would possibly have convinced me more. \nSo, I am only lukewarm about the paper with maybe a slight tendency to rejection. It just seems yet another try without really emphasizing the in my opinion important question of crossing entities.\nMinor remarks: - first mention of multigraph: some readers may benefit if the notion of a multigraph would get a short description - previously noted by ... many previous: sounds a little odd - Solving this task: which one?\n- e.g.: why in italics?\n- time linear in n: when n is sentence length, does it really matter whether it is linear or cubic?\n- spurious structures: in the introduction it is not clear, what is meant - regarded as _a_ chunk - NP chunking: noun phrase chunking?\n- Since they set: who?\n- pervious -> previous - of Lu and Roth~(2015) - the following five types: in sentences with no large numbers, spell out the small ones, please - types of states: what is a state in a (hyper-)graph? later state seems to be used analogous to node?!\n- I would place commas after the enumeration items at the end of page 2 and a period after the last one - what are child nodes in a hypergraph?\n- in Figure 2 it was not obvious at first glance why this is a hypergraph. \ncolors are not visible in b/w printing. why are some nodes/edges in gray. it is also not obvious how the highlighted edges were selected and why the others are in gray ... - why should both entities be detected in the example of Figure 2? what is the difference to \"just\" knowing the long one?\n- denoting ...: sometimes in brackets, sometimes not ... why?\n- please place footnotes not directly in front of a punctuation mark but afterwards - footnote 2: due to the missing edge: how determined that this one should be missing?\n- on whether the separator defines ...: how determined?\n- in _the_ mention hypergraph - last paragraph before 4.1: to represent the entity separator CS: how is the CS-edge chosen algorithmically here?\n- comma after Equation 1?\n- to find out: sounds a little odd here - we extract entities_._\\footnote - we make two: sounds odd; we conduct or something like that?\n- nested vs. crossing remark in footnote 3: why is this good? why not favor crossing? examples to clarify?\n- the combination of states alone do_es_ not?\n- the simple first order assumption: that is what?\n- In _the_ previous section - we see that our model: demonstrated? have shown?\n- used in this experiments: these - each of these distinct interpretation_s_ - published _on_ their website - The statistics of each dataset _are_ shown - allows us to use to make use: omit \"to use\" - tried to follow as close ... : tried to use the features suggested in previous works as close as possible?\n- Following (Lu and Roth, 2015): please do not use references as nouns: Following Lu and Roth (2015) - using _the_ BILOU scheme - highlighted in bold: what about the effect size?\n- significantly better: in what sense? effect size?\n- In GENIA dataset: On the GENIA dataset - outperforms by about 0.4 point_s_: I would not call that \"outperform\" - that _the_ GENIA dataset - this low recall: which one?\n- due to _an_ insufficient - Table 5: all F_1 scores seems rather similar to me ... again, \"outperform\" seems a bit of a stretch here ... - is more confident: why does this increase recall?\n- converge _than_ the mention hypergraph - References: some paper titles are lowercased, others not, why? "}, "scores": {"overall": "2", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "PRESENTATION_FORMAT": "Poster", "SOUNDNESS_CORRECTNESS": "4"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "3", "sentences": {"main": [[0, 135], [135, 288], [288, 385], [385, 463], [463, 581], [581, 642], [642, 770], [770, 855], [855, 920], [920, 1056], [1056, 1191], [1191, 1320], [1320, 1411], [1411, 1436], [1436, 1535], [1535, 1578], [1578, 1675], [1675, 1811], [1811, 1987], [1987, 2064], [2064, 2168], [2168, 2198], [2198, 2294], [2294, 2366], [2366, 2404], [2404, 2508], [2508, 2635], [2635, 2762], [2762, 2813], [2813, 2926], [2926, 3109], [3109, 3192], [3192, 3308], [3308, 3323], [3323, 3439], [3439, 3500], [3500, 3532], [3532, 3556], [3556, 3656], [3656, 3730], [3730, 3754], [3754, 3791], [3791, 3814], [3814, 3837], [3837, 3861], [3861, 3958], [3958, 4013], [4013, 4062], [4062, 4166], [4166, 4206], [4206, 4281], [4281, 4322], [4322, 4356], [4356, 4454], [4454, 4521], [4521, 4576], [4576, 4638], [4638, 4722], [4722, 4809], [4809, 4865], [4865, 4895], [4895, 5010], [5010, 5036], [5036, 5076], [5076, 5110], [5110, 5172], [5172, 5234], [5234, 5258], [5258, 5279], [5279, 5325], [5325, 5376], [5376, 5404], [5404, 5443], [5443, 5455], [5455, 5489], [5489, 5532], [5532, 5563], [5563, 5608], [5608, 5654], [5654, 5763], [5763, 5864], [5864, 5891], [5891, 5942], [5942, 5981], [5981, 5994], [5994, 6035], [6035, 6107], [6107, 6134], [6134, 6164], [6164, 6191], [6191, 6302], [6302, 6354], [6354, 6395], [6395, 6460]]}}}]