[{"rid": 0, "reviewer": null, "report": {"main": "- Strengths: This paper presents a sophisticated application of Grid-type Recurrent Neural Nets to the task of determining predicate-argument structures (PAS) in Japanese.  The approach does not use any explicit syntactic structure, and outperforms the current SOA systems that do include syntactic structure.  The authors give a clear and detailed description of the implementation and of the results.  In particular, they pay close attention to the performance on dropped arguments, zero pronouns, which are prevalent in Japanese and especially challenging with respect to PAS. Their multi-sequence model, which takes all of the predicates in the sentence into account, achieves the best performance for these examples.  The paper is detailed and clearly written.\n- Weaknesses: I really only have minor comments. There are some typos listed below, the correction of which would improve English fluency. I think it would be worth illustrating the point about the PRED including context around the \"predicate\" with the example from Fig 6 where the accusative marker is included with the verb in the PRED string.  I didn't understand the use of boldface in Table 2, p. 7.\n- General Discussion: Typos: p1 :  error propagation does not need a \"the\", nor does \"multi-predicate interactions\" p2: As an solution -> As a solution, single-sequence model -> a single-sequence model,                    multi-sequence model -> a multi-sequence model  p. 3 Example in Fig 4.                    She ate a bread -> She ate bread. \np. 4 assumes the independence -> assumed independence, the multi-predicate interactions -> multi-predicate interactions, the multi-sequence model -> a multi-sequence model p.7: the residual connections -> residual connections, the multi-predicate interactions -> multi-predicate interactions (twice) p8 NAIST Text Corpus -> the NAIST Text Corpus, the state-of-the-art result -> state-of-the-art results I have read the author response and am satisfied with it. "}, "scores": {"overall": "4", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "PRESENTATION_FORMAT": "Oral Presentation", "SOUNDNESS_CORRECTNESS": "5"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "3", "sentences": {"main": [[0, 13], [13, 172], [172, 310], [310, 403], [403, 580], [580, 722], [722, 766], [766, 780], [780, 815], [815, 905], [905, 1112], [1112, 1171], [1171, 1193], [1193, 1200], [1200, 1464], [1464, 1517], [1517, 1921], [1921, 1979]]}}}, {"rid": 1, "reviewer": null, "report": {"main": "This paper proposes new prediction models for Japanese SRL task by adopting the English state-of-the-art model of (Zhou and Xu, 2015). \nThe authors also extend the model by applying the framework of Grid-RNNs in order to handle the interactions between the arguments of multiple predicates.\nThe evaluation is performed on the well-known benchmark dataset in Japanese SRL, and obtained a significantly better performance than the current state of the art system.\nStrengths: The paper is well-structured and well-motivated. \nThe proposed model obtains an improvement in accuracy compared with the current state of the art system. \nAlso, the model using Grid-RNNs achieves a slightly better performance than that of proposed single-sequential model, mainly due to the improvement on the detection of zero arguments, that is the focus of this paper.\nWeakness: To the best of my understanding, the main contribution of this paper is an extension of the single-sequential model to the multi-sequential model. The impact of predicate interactions is a bit smaller than that of (Ouchi et al., 2015). There is a previous work (Shibata et al., 2016) that extends the (Ouchi et al., 2015)'s model with neural network modeling. I am curious about the comparison between them. "}, "scores": {"overall": "4", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "PRESENTATION_FORMAT": "Oral Presentation", "SOUNDNESS_CORRECTNESS": "5"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "5", "sentences": {"main": [[0, 135], [135, 291], [291, 462], [462, 522], [522, 628], [628, 846], [846, 1003], [1003, 1092], [1092, 1216], [1216, 1264]]}}}, {"rid": 2, "reviewer": null, "report": {"main": "This paper proposes a joint neural modelling approach to PAS analysis in Japanese, based on Grid-RNNs, which it compares variously with a conventional single-sequence RNN approach.\nThis is a solidly-executed paper, targeting a well-established task from Japanese but achieving state-of-the-art results at the task, and presenting the task in a mostly accessible manner for those not versed in Japanese. Having said that, I felt you could have talked up the complexity of the task a bit, e.g. wrt your example in Figure 1, talking through the inherent ambiguity between the NOM and ACC arguments of the first predicate, as the NOM argument of the second predicate, and better describing how the task contrasts with SRL (largely through the ambiguity in zero pronouns). I would also have liked to have seen some stats re the proportion of zero pronouns which are actually intra-sententially resolvable, as this further complicates the task as defined (i.e. needing to implicitly distinguish between intra- and inter-sentential zero anaphors). One thing I wasn't sure of here: in the case of an inter-sentential zero pronoun for the argument of a given predicate, what representation do you use? Is there simply no marking of that argument at all, or is it marked as an empty argument? My reading of the paper is that it is the former, in which case there is no explicit representation of the fact that there is a zero pronoun, which seems like a slightly defective representation (which potentially impacts on the ability of the model to capture zero pronouns); some discussion of this would have been appreciated.\nThere are some constraints that don't seem to be captured in the model (which some of the ILP-based methods for SRL explicitly model, e.g.): (1) a given predicate will generally have only one argument of a given type (esp. NOM and ACC); and (2) a given argument generally only fills one argument slot for a given predicate. I would have liked to have seen some analysis of the output of the model to see how well the model was able to learn these sorts of constraints. More generally, given the mix of numbers in Table 3 between Single-Seq and Multi-Seq (where it is really only NOM where there is any improvement for Multi-Seq), I would have liked to have seen some discussion of the relative differences in the outputs of the two models: are they largely identical, or very different but about the same in aggregate, e.g.? In what contexts do you observe differences between the two models? Some analysis like this to shed light on the internals of the models would have made the difference between a solid and a strong paper, and is the main area where I believe the paper could be improved (other than including results for SRL, but that would take quite a bit more work).\nThe presentation of the paper was good, with the Figures aiding understanding of the model. There were some low-level language issues, but nothing major: l19: the error propagation -> error propagation l190: an solution -> a solution l264 (and Figure 2): a bread -> bread l351: the independence -> independence l512: the good -> good l531: from their model -> of their model l637: significent -> significance l638: both of -> both and watch casing in your references (e.g. \"japanese\", \"lstm\", \"conll\", \"ilp\") "}, "scores": {"overall": "4", "SUBSTANCE": "4", "APPROPRIATENESS": "5", "PRESENTATION_FORMAT": "Poster", "SOUNDNESS_CORRECTNESS": "5"}, "meta": {"license": "No individual license attached", "REVIEWER_CONFIDENCE": "4", "sentences": {"main": [[0, 181], [181, 403], [403, 768], [768, 1041], [1041, 1193], [1193, 1283], [1283, 1613], [1613, 1836], [1836, 1937], [1937, 2082], [2082, 2438], [2438, 2506], [2506, 2790], [2790, 2882], [2882, 2944], [2944, 3221], [3221, 3299]]}}}]