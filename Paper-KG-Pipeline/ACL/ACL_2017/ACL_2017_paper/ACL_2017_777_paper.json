{
  "name" : "ACL_2017_777_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Other Topics You May Also Agree or Disagree: Modeling Inter-Topic Preferences using Tweets and Matrix Factorization",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Social media have changed the way people shape public opinions. The latest survey by Pew Research Center reported that a majority of US adults (62%) obtain news on social media, and 18% do so often (Gottfried and Shearer, 2016). As news and opinions are shared and amplified by friend networks of individuals (Jamieson and Cappella, 2008), individuals are also isolated from informa-\ntion that does not fit their opinions (Pariser, 2011). Ironically, the cutting-edge technology of social media promotes ideological groups even with its potential to deliver diverse information.\nA great deal of studies analyze discussions, interactions, influences, and communities on social media along the political spectrum of liberal to conservative (Adamic and Glance, 2005; Zhou et al., 2011; Cohen and Ruths, 2013; Bakshy et al., 2015; Wong et al., 2016). Even though these studies provide intuitive visualizations and interpretations along the axis of liberal-conservative, political analysts argue that the axis is flawed and insufficient for representing public opinions and ideologies (Kerlinger, 1984; Maddox and Lilie, 1984).\nA potential solution for analyzing multiple axes of political spectrum on social media is stance detection (Thomas et al., 2006; Somasundaran and Wiebe, 2009; Murakami and Raymond, 2010; Anand et al., 2011; Walker et al., 2012; Mohammad et al., 2016; Johnson and Goldwasser, 2016), whose task is to determine whether the author of a text is for, neutral, or against towards a topic (e.g., free trade, immigration, abortion). However, stance detection across different topics is extremely difficult. Anand et al. (2011) reported that a sophisticated method with topic-dependent features greatly improved the performance of stance detection within a topic, but could not outperform a baseline method with simple n-gram features when evaluated across topics. More recently, all participants of SemEval 2016 Task 6A (with five topics) could not outperform the baseline supervised method using n-gram features (Mohammad et al., 2016).\nIn addition, stance detection encounters the difficulty with different user types. Cohen and Ruths (2013) observed that existing methods on stance detection fail on ‘ordinary’ users because they mostly obtain training and test data from polit-\nically vocal users (e.g., politicians); for example, they found that a stance detector trained on a dataset with politicians achieved 91% accuracy on other politicians but only 54% accuracy on ‘ordinary’ users. Establishing a bridge across different topics and users is a major challenge not only to stance detection but also to social media analytics.\nAn important material for the bridge is commonsense knowledge about topics. For instance, consider a topic a revision of Article 96 of the Japanese Constitution. We infer that a statement, “we should maintain armed forces,” tends to favor the topic even without any lexical overlap between the topic and statement. This inference is reasonable because: the writer of the statement favors armed forces; those who favor armed forces also favor a revision of Article 91; and those who favor a revision of Article 9 also favor a revision of Article 962. In general, this kind of commonsense knowledge can be expressed in the format: those who agree/disagree a topic A also agree/disagree another topic B. We call this kind of knowledge inter-topic preference throughout this paper.\nWe conjecture that the previous work on stance detection indirectly learns inter-topic preferences\n1Article 9 prohibits armed forces in Japan. 2Article 96 specifies high requirements for making\namendments to Constitution of Japan (including Article 9).\nwithin the same target through the use of n-gram features on a supervision data. In contrast, this paper directly acquires inter-topic preferences from an unlabeled corpus of tweets. The knowledge of inter-topic preferences is useful not only for stance detection but also for various real-world applications including public opinion survey, election campaign/prediction, and online debate.\nFigure 1 illustrates a generic overview of this work. We extract high-quality linguistic patterns (e.g., “A is completely wrong”) in which people agree and disagree topics, making use of hashtags in a large collection of tweets (Section 2.1). The patterns are used for extracting instances of users’ preferences to various topics (Section 2.2). Inspired by the work on item recommendation, Section 3 formalizes the task of modeling inter-topic preferences as a matrix factorization: representing a sparse user-topic matrix (the extracted instances) with the product of low-rank user and topic matrices. The low-rank matrices provide latent vector representations of users and topics. This approach is also useful for completing preferences of ‘ordinary’ (less vocal) users, which fills the gap between different types of users.\nThe contributions of this paper are three-folds.\n1. To the best of our knowledge, this is the first\nstudy that models inter-topic preferences for unlimited targets on the real-world data.\n2. The experimental results show that this approach can predict missing topic preferences of users accurately (80–94%).\n3. The experimental results also demonstrate that the latent vector representations of topics encode inter-topic preferences, e.g., those who agree nuclear power plant also agree nuclear fuel cycle.\nThis study uses a Japanese Twitter corpus because of its availability from the authors, but the core idea is applicable to any language."
    }, {
      "heading" : "2 Mining topic preferences of users",
      "text" : "This section collects statements of users agreeing or disagreeing various topics on Twitter as source data for modeling inter-topic preferences. More formally, we are interested in acquiring a collection of tuples (u, t, v), where: u ∈ U is a user; U is the set of all users on Twitter; t ∈ T is a topic; T is the set of all topics; and v ∈ {+1,−1} is +1 when the user u agree the topic t and−1 otherwise (disagreement).\nThroughout this work, we use a corpus consisting of 35,328,745,115 Japanese tweets (7,340,730 users) crawled from February 6, 2013 to September 30, 2016. We removed retweets from the corpus."
    }, {
      "heading" : "2.1 Mining linguistic patterns of agreement and disagreement",
      "text" : "We use linguistic patterns to extract tuples (u, t, v) from the corpus. More specifically, when a tweet message matches to one of linguistic patterns for agreement (e.g., “t is necessary”), we regard that the author u of the tweet agrees the topic t. Conversely, a statement of disagreement is identified by linguistic patterns for disagreement (e.g., “t is unacceptable”).\nIn order to design high-quality linguistic patterns, this study focuses on hashtags appearing in the corpus, which have been popular clues for locating subjective statements such as sentiments (Davidov et al., 2010), emotions (Qadir and Riloff, 2014), and ironies (Van Hee et al., 2016). Hashtags are also useful for finding strong supporters and critics and their target topics; for example, #immigrantsWelcome in-\ndicates that the author favors immigrants; and #StopAbortion is against abortion.\nBased on this intuition, we design regular expressions for pro hashtags “#(.+)sansei”3 and for con hashtags “#(.+)hantai”4, where (.+) matches to a target topic. These regular expressions can find users who have strong preferences to topics. In this way, we could extract 31,068 occurrences of pro/con hashtags, which were used by 18,582 users for 4,899 topics. We regard the topics found in this procedure as the set of target topics T in this study.\nEvery time we find a tweet containing a pro/con hashtag, we look for corresponding textual statements as follows. Suppose that a tweet mentions a hashtag (e.g., #TPPsansei) for a topic t (e.g., TPP). Assuming that the author of the tweet does not change their attitude to a topic over time, we search for other tweets posted by the same author with the topic keyword t. This process retrieves tweets like “I support TPP.” Then, we replace the topic keyword into a variableA to extract patterns, e.g., “I support A.” Here, the definition of the pattern unit is language specific. For Japanese tweets, we simply recognize a pattern starting at a variable (topic) and ending at the end of the sentence5.\nBecause this procedure also extracts unuseful patterns such as “to A” and “this is A”, we manually choose useful patterns in a systematic way: sort patterns in descending order of the number of users who use a pattern; and check the sorted list of patterns manually; and remove unuseful patterns. In this way, we obtain 100 pro patterns (e.g., “welcome A” and “A is necessary”) and 100 con patterns (“do not let A” and “I don’t want A”)."
    }, {
      "heading" : "2.2 Extracting instances of topic preferences",
      "text" : "By using the pro and con patterns acquired in Section 2.1, we extract instances of (u, t, v) as follows. When a sentence in a tweet (whose author is the user u) matches to one of pro patterns (e.g., “t is necessary”) and the topic t is included in the set of target topics T , we recognize this as an instance\n3Unlike English hashtags, we systematically attach a noun sansei, which stands for pro (agreement) in Japanese, to a topic, for example, #TPPsansei. This paper uses the alphabetical expression sansei only for explanation; the actual pattern uses Chinese characters corresponding to sansei.\n4A Japanese noun hantai stands for con (disagreement), for example, #TPPhantai. This paper uses the alphabetical expression hantai only for explanation; the actual pattern uses Chinese characters corresponding to hantai.\n5In English, this treatment roughly corresponds to extracting a verb phrase with the variable A.\nof (u, t,+1). Similarly, when a sentence matches to one of con patterns (e.g., “I don’t want t”) and the topic t is included in the set of target topics T , we recognize this as an instance of (u, t,−1). In this way, we collected 25,805,909 tuples regarding 3,302,613 users and 4,899 topics. Because these collected tuples also including far less frequent users and topics, we remove users and topics appeared less than 5 times. In addition, there also meaningless frequent topics such as “of” and “it”. Therefore, we sorted topics in descending order of co-occurrence frequency with each of pro patterns and con patterns, and remove meaningless topics in the top 100 topics. This resulted in 9,961,509 tuples regarding 273,417 users and 2,323 topics."
    }, {
      "heading" : "3 Matrix factorization",
      "text" : "Section 2 collects a number of instances of users’ preferences to various topics from the corpus. However, a Twitter user does not necessarily express preferences for all topics. In addition, it is by nature impossible to predict whether a new (non-existent in the data) user agree or disagree topics. Therefore, this section applies matrix factorization (Koren et al., 2009) in order to predict missing values, inspired by the work of item recommendation (Bell and Koren, 2007; Dror et al., 2011). In essence, matrix factorization maps both users and topics into a latent feature space that abstracts topic preferences of users.\nLet R be a sparse matrix of |U |×|T |. Only when a user u expresses a preference to topic t, we compute an element of the sparse matrix ru,t,\nru,t = #(u, t,+1)−#(u, t,−1) #(u, t,+1) + #(u, t,−1)\n(1)\nHere, #(u, t,+1) and #(u, t,−1) are the numbers of occurrences of instances (u, t,+1) and (u, t,−1), respectively. Thus, an element ru,t approaches +1 as the user u favors the topic t, and −1 otherwise. If the user u does not make any statement about the topic t, i.e., neither (u, t,+1) nor (u, t,−1) exists in the data, we do not fill the corresponding element, leaving it as a missing value.\nMatrix factorization decomposes the sparse matrix R into low dimensional matrices P ∈ Rk×|U | and Q ∈ Rk×|T |, where k is a parameter to specify the number of dimension of the latent space. We minimize the following objective function for\nfinding the matrices P and Q,\nmin P,Q ∑ (u,t)∈R ( (ru,t − puᵀqt)2\n+λP ‖pu‖2 + λQ ‖qt‖2 ) . (2)\nHere, (u, t) ∈ R is repeated for elements filled in the sparse matrix R, pu ∈ Rk and qv ∈ Rk are u column vectors of P , and v column vectors of Q, respectively, and λP ≥ 0 and λQ ≥ 0 present coefficients of regularization terms. We call pu and qt the user vector and topic vector, respectively.\nUsing the user and topic vectors, we can predict an element r̂u,t that may be missing in the original matrix R,\nr̂u,t ' puᵀqt. (3)\nWe use libmf6 (Chin et al., 2015) for solving the optimization problem in Equation 2. We set the regularization coefficients λP = 0.1 and λQ = 0.1, and use default values for other parameters of libmf."
    }, {
      "heading" : "4 Evaluation",
      "text" : ""
    }, {
      "heading" : "4.1 Determining the dimension parameter k",
      "text" : "How good is the low-rank approximation found by matrix factorization? What is the sweet spot for the number of dimension k of the latent space? We investigate the reconstruction error of matrix factorization with different values of k in order to answer these questions. We use Root Mean Squared\n6https://github.com/cjlin1/libmf\nError (RMSE) for measuring the error,\nRMSE =\n√∑ (u,t)∈R (pu ᵀqt − ru,t)2\nN . (4)\nHere, N is the number of elements in the sparse matrix R (the number of known values).\nFigure 2 shows RMSE values over iterations of libmf with the dimension parameter k ∈ {1, 2, 5, 10, 30, 50, 100, 300, }. We can observe that a reconstruction error decreases as the iterative method of libmf progresses. The larger the number of dimension k is, the less the reconstruction error becomes; the lowest reconstruction error was 0.3256 with k = 500. It is also interesting to observe the error with k = 1, which corresponds to mapping users and topics onto one dimension similarly to the political spectrum of liberal and conservative. Judging from the relatively high RMSE values with k = 1, it may be difficult to represent everything in the data on a onedimensional axis. Based on this result, we draw a conclusion that matrix factorization with k = 100 is sufficient to reconstruct the original matrix R, and use this parameter value in the rest of the experiments."
    }, {
      "heading" : "4.2 Predicting missing topic preferences",
      "text" : "How accurately can the user and topic vectors predict missing topic preferences? In order to investigate this question, we evaluate the accuracy for predicting hidden preferences in the matrix R as follows. First, we randomly select 5% of existing elements in R, and let Y the collection of the selected elements (test set). We then perform matrix factorization on the sparse matrix without the selected elements of Y and only with the remaining\n95% elements of R (training set). The accuracy of the prediction is defined by,\n1 |Y | ∑ u,t∈Y 1 (sign(r̂u,t) = sign(ru,t)) (5)\nHere, ru,t denotes the actual (self-declared) preference values, r̂u,t is the preference value predicted by Equation 3, sign(.) presents the sign of the argument, and 1(.) yields 1 only when the condition described in the argument holds and 0 otherwise. In other words, Equation 5 computes the proportion of correct predictions, assuming zero to be the decision boundary between pro and con.\nFigure 3 plots prediction accuracy values calculated from different sets of users. Here, the x-axis presents a threshold θ that filters out users whose declarations of topic preferences are no greater than θ topics. In other words, Figure 3 shows prediction accuracy when we know users’ preferences for at least θ topics. For comparison, we also include the majority baseline that predicts pro and con based on the majority of preferences about each topic in the training set.\nThe presented method could predict missing preferences with 82.1% accuracy for users stating preferences for at least 5 topics. The accuracy increases as the method receives more information about the users, reaching 94.0% accuracy when θ = 100. This result again indicates that the presented method reasonably utilize known preferences to complete missing preferences.\nIn contrast, the majority baseline decreases its performance as it receives more information about the users. Because this result was counterintuitive, we examined the cause of this phenomenon. Consequently, this result turned out reasonable because preferences of vocal users deviate\n6 500\nACL 2017 Submission ***. Confidential Review Copy. DO NOT DISTRIBUTE.\nfrom those of the average users. Figure 4 illustrates this finding, showing the mean of variances of preference values ru,t of all topics. The x-axis presents a threshold θ that filters out users whose statements of topic preferences are no greater than θ topics. We can observe that the mean variance increases as we focus on vocal users. These results demonstrate the usefulness of user and topic vectors for predicting missing preferences.\nTable 1 shows examples where missing preferences of two users are predicted from known statements of agreements and disagreements7. A predicted topic accompanies with the value of r̂u,t in parentheses. For example, the proposed method predicts that the user A, who is positive to regime change but negative to Okinawa US military base, may also be positive to vote of non-confidence to Cabinet but negative to construction of a new base."
    }, {
      "heading" : "4.3 Inter-topic preferences",
      "text" : "Does the topic vectors obtained by matrix factorization capture inter-topic preferences such as “People who agree with A also agree with B”?\nBecause no dataset exists for this evaluation, we created a dataset of pairwise inter-topic preferences by using a crowdsourcing service8. Sampling topic pairs randomly, we collected 150 topic pairs whose cosine similarities of topic vectors are below −0.6, 150 pairs whose cosine similarities are between −0.6 and 0.6, and 150 pairs whose cosine similarities are above 0.6. In this way, we obtained 450 topic pairs for evaluation.\nGiven a pair of topics A and B, a crowd worker is asked to choose a label from: (a) those who agree/disagree a topic A may also agree/disagree topic B; (b) those who agree/disagree a topic A may conversely disagree/agree topic B; (c) otherwise (no association between A and B). Creating twenty pairs of topics as a gold data, we removed labeling results from workers whose accuracy is lower than 90%.\nConsequently, we obtained 6–10 human judgements for every topic pair. Regarding (a) as +1 point, (b) as −1 point, and (c) as 0 point, we com-\n7We anonymized user names in these examples. In addition, we removed topics that are too discriminatory or aggressive to other countries and races. Even though the experimental results of this paper do not necessarily reflect our idea, we do not think it is a good idea to distribute politically incorrect ideas through this paper.\n8We used Yahoo! Crowdsourcing, a Japanese online service for crowdsourcing. http://crowdsourcing.yahoo.co.jp/\npute the mean of the points (as the average human judgements) for every topic pair. Spearman’s rank correlation coefficient (ρ) between cosine similarity values of topic vectors and human judgements was 0.2210. We could observe a moderate correlation even though inter-topic preferences collected in this manner are highly subjective.\nIn addition to the quantitative evaluation, we also check similar topics for three controversial topics, Liberal Democratic Party (LDP), constitutional amendment and right of foreigners to vote (Table 2). The similar topics to Liberal Democratic Party (LDP) were synonymous ones (e.g., Abe’s LDP, Abe administration) as well as other topics promoted by the LDP (e.g., resuming nuclear power plant operations, bus rapid transit (BRT), hate speech countermeasure law). Considering that people who support the LDP may also tend to favor its policies, we found these results reasonable. In the other example, constitutional amendment has a similar feature vector to amendment of Article 9, enforcement of specific secrete protection law and security related law. From these results, we conclude that topic vectors were able to capture inter-topic preferences."
    }, {
      "heading" : "5 Related work",
      "text" : "This section summarizes the related work that spreads across various research fields.\nSocial science and political science A number of of studies analyze social phenomena regarding political activities, political thoughts, and public opinions on social media. These studies model the political spectrum of liberal to conservative (Adamic and Glance, 2005; Zhou et al., 2011; Cohen and Ruths, 2013; Bakshy et al., 2015; Wong et al., 2016), political parties (Tumasjan et al., 2010; Boutet et al., 2013; Makazhanov and Rafiei, 2013), and elections (O’Connor et al., 2010; Conover et al., 2011).\nEmploying a single axis (e.g., liberal to conservative) or a few axes (e.g., political parties and candidates of elections), these studies provide intuitive visualizations and interpretations along the axes. In contrast, this study is the first attempt for recognizing and organizing various axes of topics on social media with no prior assumption about axes. Therefore, we think this study provides a new tool for computational social science and political science to analyze and interpret phenomena on social media.\nHere, we mention some work that acquires lexical knowledge about politics. Sim et al. (2013) measured ideological positions of candidates of US Presidential elections from their speeches. The study first constructs “cue lexicons” from political writings labeled with ideologies by domain experts, using sparse additive generative models (Eisenstein et al., 2011). The constructed cue lexicons are associated with ideologies such as left, center, and right. Representing each speech of a candidate with cue lexicons, they infer the proportions of ideologies of the candidate. The study requires a predefined set of labels and text data associated with the labels.\nBamman and Smith (2015) presented an unsupervised method for assessing the political stance of a proposition like “global warminig is a hoax,” along the political spectrum of liberal to conservative. In their work, a proposition is represented by a tuple in the form of 〈subject, predicate〉, e.g., 〈global warminig, hoax〉. They presented a generative model for users, subjects, and predicates to find a one-dimensional latent space, which corre-\nsponds to the political spectrum. Similarly to ours, their work (Bamman and Smith, 2015) does not requires labeled data for mapping users and topics (subjects) into a latent feature space. Their paper reported that the generative model outperformed Principal Component Analysis (PCA), which is a method for matrix factorization. The empirical result probably reflected the underlying assumptions that PCA treats missing elements as zero (not as simply missing data). In contrast, this work properly distinguishes missing values from zero, excluding missing elements of the original matrix from the objective function of Equation 2. Furthermore, this work demonstrated the usefulness of the latent space, i.e., topic and user vectors, for predicting missing topic preferences of users and inter-topic preferences.\nFine-grained opinion analysis The method presented in Section 2 is an instance of finegrained opinion analysis (Wiebe et al., 2005; Choi et al., 2006; Johansson and Moschitti, 2010; Yang and Cardie, 2013; Deng and Wiebe, 2015), which extracts a tuple of a subjective opinion, a holder of\nthe opinion, and a target of the opinion from text. Although these previous studies have a potential to improve the quality of the user-topic matrix R, unfortunately, no corpus nor resource is available for Japanese language. We do not have a large collection of English tweets at this moment, but combining fine-grained opinion analysis with matrix factorization is an immediate future work.\nCausality relation Some of inter-topic preferences in this work can be explained by causality relation, for example, “TPP promotes free trade.” A number of previous studies acquire instances of causal relation (Girju, 2003; Do et al., 2011) and promote/supress relation (Hashimoto et al., 2012; Fluck et al., 2015) from text. The causality knowledge is useful for predicting (hypotheses of) future events (Radinsky et al., 2012; Radinsky and Davidovich, 2012; Hashimoto et al., 2015).\nHowever, inter-topic preferences also include pairs of topics where causality relation hardly holds. For example, it is unreasonable to infer that nuclear plant and railroading of bills have causal relation, but those who dislike nuclear plant also oppose railroading of bills because (they think) the governing political parties rush the bill for resuming a nuclear plant. This study models this kind of inter-topic preferences based on the preferences of the public. Having said that, it is a promising future direction of this work to incorporate the approach for acquiring causality knowledge."
    }, {
      "heading" : "6 Conclusion",
      "text" : "This paper presents a novel approach for modeling inter-topic preferences of users on Twitter. Designing high-quality linguistic patterns for locating support and opposition statements, we extracted users’ preferences to various topics from a large collection of tweets. We formalized the task of modeling inter-topic preferences as a matrix factorization that maps both users and topics into a latent feature space that abstracts users’ preferences. The experimental results demonstrate that this approach can predict missing topic preferences of users accurately (80–94%) and that the latent vector representations of topics encode intertopic preferences.\nAn immediate future work is to embed the topic and user vectors to a cross-topic stance detector. It is possible to generalize this work for modeling heterogeneous signals such as interests and behav-\nior of people, for example, “those who are interested in A also support B,” and “those who favor A also vote forB”. Thus, we believe that this work will bring a new application of NLP to other disciplines."
    }, {
      "heading" : "Acknowledgements",
      "text" : "(Removed for the reviewing process)"
    } ],
    "references" : [ {
      "title" : "The political blogosphere and the 2004 u.s. election: Divided they blog",
      "author" : [ "Lada A. Adamic", "Natalie Glance" ],
      "venue" : "In Proceedings of the 3rd International Workshop on Link Discovery (LinkKDD",
      "citeRegEx" : "Adamic and Glance.,? \\Q2005\\E",
      "shortCiteRegEx" : "Adamic and Glance.",
      "year" : 2005
    }, {
      "title" : "Cats rule and dogs drool!: Classifying stance in online debate",
      "author" : [ "Pranav Anand", "Marilyn Walker", "Rob Abbott", "Jean E. Fox Tree", "Robeson Bowmani", "Michael Minor." ],
      "venue" : "Proceedings of the 2nd Workshop on Computational Approaches to Subjec-",
      "citeRegEx" : "Anand et al\\.,? 2011",
      "shortCiteRegEx" : "Anand et al\\.",
      "year" : 2011
    }, {
      "title" : "Exposure to ideologically diverse news and opinion on facebook",
      "author" : [ "Eytan Bakshy", "Solomon Messing", "Lada A. Adamic." ],
      "venue" : "Science 348(6239):1130–1132.",
      "citeRegEx" : "Bakshy et al\\.,? 2015",
      "shortCiteRegEx" : "Bakshy et al\\.",
      "year" : 2015
    }, {
      "title" : "Open extraction of fine-grained political statements",
      "author" : [ "David Bamman", "Noah A. Smith." ],
      "venue" : "Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP 2015). pages 76–85.",
      "citeRegEx" : "Bamman and Smith.,? 2015",
      "shortCiteRegEx" : "Bamman and Smith.",
      "year" : 2015
    }, {
      "title" : "Lessons from the netflix prize challenge",
      "author" : [ "Robert M. Bell", "Yehuda Koren." ],
      "venue" : "ACM SIGKDD Explorations Newsletter 9(2):75–79.",
      "citeRegEx" : "Bell and Koren.,? 2007",
      "shortCiteRegEx" : "Bell and Koren.",
      "year" : 2007
    }, {
      "title" : "Whats in twitter, i know what parties are popular and who you are supporting now! Social Network Analysis and Mining (SNAM",
      "author" : [ "Antoine Boutet", "Hyoungshick Kim", "Eiko Yoneki" ],
      "venue" : null,
      "citeRegEx" : "Boutet et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Boutet et al\\.",
      "year" : 2013
    }, {
      "title" : "A fast parallel stochastic gradient method for matrix factorization in shared memory systems",
      "author" : [ "Wei-Sheng Chin", "Yong Zhuang", "Yu-Chin Juan", "Chih-Jen Lin." ],
      "venue" : "ACM Transactions on Intelligent Systems and Technology (TIST) 6(1):2.",
      "citeRegEx" : "Chin et al\\.,? 2015",
      "shortCiteRegEx" : "Chin et al\\.",
      "year" : 2015
    }, {
      "title" : "Joint extraction of entities and relations for opinion recognition",
      "author" : [ "Yejin Choi", "Eric Breck", "Claire Cardie." ],
      "venue" : "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006). pages 431–439.",
      "citeRegEx" : "Choi et al\\.,? 2006",
      "shortCiteRegEx" : "Choi et al\\.",
      "year" : 2006
    }, {
      "title" : "Classifying political orientation on Twitter: It’s not easy! In Proc",
      "author" : [ "Raviv Cohen", "Derek Ruths." ],
      "venue" : "of the Seventh International AAAI Conference on Weblogs and Social Media (ICWSM 2013). pages 91–99.",
      "citeRegEx" : "Cohen and Ruths.,? 2013",
      "shortCiteRegEx" : "Cohen and Ruths.",
      "year" : 2013
    }, {
      "title" : "Predicting the political alignment of twitter users",
      "author" : [ "Michael D Conover", "Bruno Gonçalves", "Jacob Ratkiewicz", "Alessandro Flammini", "Filippo Menczer." ],
      "venue" : "Privacy, 2011 IEEE Third International Conference on Security, Risk and",
      "citeRegEx" : "Conover et al\\.,? 2011",
      "shortCiteRegEx" : "Conover et al\\.",
      "year" : 2011
    }, {
      "title" : "Enhanced sentiment learning using twitter hashtags and smileys",
      "author" : [ "Dmitry Davidov", "Oren Tsur", "Ari Rappoport." ],
      "venue" : "Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010). pages 241–249.",
      "citeRegEx" : "Davidov et al\\.,? 2010",
      "shortCiteRegEx" : "Davidov et al\\.",
      "year" : 2010
    }, {
      "title" : "Mpqa 3.0: An entity/event-level sentiment corpus",
      "author" : [ "Lingjia Deng", "Janyce Wiebe" ],
      "venue" : "In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-",
      "citeRegEx" : "Deng and Wiebe.,? \\Q2015\\E",
      "shortCiteRegEx" : "Deng and Wiebe.",
      "year" : 2015
    }, {
      "title" : "Minimally supervised event causality identification",
      "author" : [ "Quang Do", "Yee Seng Chan", "Dan Roth." ],
      "venue" : "Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP 2011). pages 294–303.",
      "citeRegEx" : "Do et al\\.,? 2011",
      "shortCiteRegEx" : "Do et al\\.",
      "year" : 2011
    }, {
      "title" : "The yahoo! music dataset and kdd-cup’11",
      "author" : [ "Gideon Dror", "Noam Koenigstein", "Yehuda Koren", "Markus Weimer." ],
      "venue" : "Proceedings of the 2011 International Conference on KDD Cup 2011 (KDDCUP 2011). pages 3–18.",
      "citeRegEx" : "Dror et al\\.,? 2011",
      "shortCiteRegEx" : "Dror et al\\.",
      "year" : 2011
    }, {
      "title" : "Sparse additive generative models of text",
      "author" : [ "Jacob Eisenstein", "Amr Ahmed", "Eric P Xing." ],
      "venue" : "Proceedings of the 28th International Conference on Machine Learning (ICML 2011).",
      "citeRegEx" : "Eisenstein et al\\.,? 2011",
      "shortCiteRegEx" : "Eisenstein et al\\.",
      "year" : 2011
    }, {
      "title" : "Track 4 overview: Extraction of causal network information in biological expression language (BEL)",
      "author" : [ "Juliane Fluck", "Sumit Madan", "Tilia Renate Ellendorff", "Theo Mevissen", "Simon Clematide", "Adrian van der Lek", "Fabio Rinaldi." ],
      "venue" : "Proceedings of",
      "citeRegEx" : "Fluck et al\\.,? 2015",
      "shortCiteRegEx" : "Fluck et al\\.",
      "year" : 2015
    }, {
      "title" : "Automatic detection of causal relations for question answering",
      "author" : [ "Roxana Girju." ],
      "venue" : "Proceedings of the ACL 2003 Workshop on Multilingual Summarization and Question Answering - Volume 12. pages 76–83.",
      "citeRegEx" : "Girju.,? 2003",
      "shortCiteRegEx" : "Girju.",
      "year" : 2003
    }, {
      "title" : "News use across social media platforms 2016",
      "author" : [ "Jeffrey Gottfried", "Elisa Shearer." ],
      "venue" : "Technical report, Pew Research Center.",
      "citeRegEx" : "Gottfried and Shearer.,? 2016",
      "shortCiteRegEx" : "Gottfried and Shearer.",
      "year" : 2016
    }, {
      "title" : "Excitatory or inhibitory: A new semantic orientation extracts contradiction and causality from the web",
      "author" : [ "Chikara Hashimoto", "Kentaro Torisawa", "Stijn De Saeger", "Jong-Hoon Oh", "Jun’ichi Kazama" ],
      "venue" : null,
      "citeRegEx" : "Hashimoto et al\\.,? \\Q2012\\E",
      "shortCiteRegEx" : "Hashimoto et al\\.",
      "year" : 2012
    }, {
      "title" : "Generating event causality hypotheses through semantic relations",
      "author" : [ "Chikara Hashimoto", "Kentaro Torisawa", "Julien Kloetzer", "Jong-Hoon Oh." ],
      "venue" : "Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence (AAAI 2015). pages 2396–",
      "citeRegEx" : "Hashimoto et al\\.,? 2015",
      "shortCiteRegEx" : "Hashimoto et al\\.",
      "year" : 2015
    }, {
      "title" : "Echo Chamber: Rush Limbaugh and the Conservative Media Establishment",
      "author" : [ "Kathleen Hall Jamieson", "Joseph N. Cappella." ],
      "venue" : "Oxford University Press.",
      "citeRegEx" : "Jamieson and Cappella.,? 2008",
      "shortCiteRegEx" : "Jamieson and Cappella.",
      "year" : 2008
    }, {
      "title" : "Syntactic and semantic structure for opinion expression detection",
      "author" : [ "Richard Johansson", "Alessandro Moschitti." ],
      "venue" : "Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL 2010). pages 67–76.",
      "citeRegEx" : "Johansson and Moschitti.,? 2010",
      "shortCiteRegEx" : "Johansson and Moschitti.",
      "year" : 2010
    }, {
      "title" : "all i know about politics is what i read in twitter”: Weakly supervised models for extracting politicians’ stances from twitter",
      "author" : [ "Kristen Johnson", "Dan Goldwasser." ],
      "venue" : "Proceedings of the 26th International Conference on Computational Linguis-",
      "citeRegEx" : "Johnson and Goldwasser.,? 2016",
      "shortCiteRegEx" : "Johnson and Goldwasser.",
      "year" : 2016
    }, {
      "title" : "Liberalism and Conservatism: The Nature and Structure of Social Attitudes",
      "author" : [ "Fred N. Kerlinger." ],
      "venue" : "Lawrence Erlbaum Associates.",
      "citeRegEx" : "Kerlinger.,? 1984",
      "shortCiteRegEx" : "Kerlinger.",
      "year" : 1984
    }, {
      "title" : "Matrix factorization techniques for recommender systems",
      "author" : [ "Yehuda Koren", "Robert Bell", "Chris Volinsky." ],
      "venue" : "Computer 42(8):30–37.",
      "citeRegEx" : "Koren et al\\.,? 2009",
      "shortCiteRegEx" : "Koren et al\\.",
      "year" : 2009
    }, {
      "title" : "Beyond Liberal and Conservative: Reassessing the Political Spectrum",
      "author" : [ "William S. Maddox", "Stuart A. Lilie." ],
      "venue" : "Cato Inst.",
      "citeRegEx" : "Maddox and Lilie.,? 1984",
      "shortCiteRegEx" : "Maddox and Lilie.",
      "year" : 1984
    }, {
      "title" : "Predicting political preference of twitter users",
      "author" : [ "Aibek Makazhanov", "Davood Rafiei." ],
      "venue" : "Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM 2013). pages 298–305.",
      "citeRegEx" : "Makazhanov and Rafiei.,? 2013",
      "shortCiteRegEx" : "Makazhanov and Rafiei.",
      "year" : 2013
    }, {
      "title" : "Semeval-2016 task 6: Detecting stance in tweets",
      "author" : [ "Saif Mohammad", "Svetlana Kiritchenko", "Parinaz Sobhani", "Xiaodan Zhu", "Colin Cherry." ],
      "venue" : "Proceedings of the 10th International Workshop on Semantic Evaluation (SemEval-2016). pages 31–41.",
      "citeRegEx" : "Mohammad et al\\.,? 2016",
      "shortCiteRegEx" : "Mohammad et al\\.",
      "year" : 2016
    }, {
      "title" : "Support or oppose?: classifying positions in online debates from reply activities and opinion expressions",
      "author" : [ "Akiko Murakami", "Rudy Raymond." ],
      "venue" : "Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010). pages",
      "citeRegEx" : "Murakami and Raymond.,? 2010",
      "shortCiteRegEx" : "Murakami and Raymond.",
      "year" : 2010
    }, {
      "title" : "From tweets to polls: Linking text sentiment to public opinion time series",
      "author" : [ "Brendan O’Connor", "Ramnath Balasubramanyan", "Bryan R. Routledge", "Noah A. Smith" ],
      "venue" : "In Proceedings of the Fourth International AAAI Conference on Weblogs",
      "citeRegEx" : "O.Connor et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "O.Connor et al\\.",
      "year" : 2010
    }, {
      "title" : "The Filter Bubble: How the New Personalized Web Is Changing What We Read and How We Think",
      "author" : [ "Eli Pariser." ],
      "venue" : "Penguin Books.",
      "citeRegEx" : "Pariser.,? 2011",
      "shortCiteRegEx" : "Pariser.",
      "year" : 2011
    }, {
      "title" : "Learning emotion indicators from tweets: Hashtags, hashtag patterns, and phrases",
      "author" : [ "Ashequl Qadir", "Ellen Riloff." ],
      "venue" : "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP 2014). pages 1203–1209.",
      "citeRegEx" : "Qadir and Riloff.,? 2014",
      "shortCiteRegEx" : "Qadir and Riloff.",
      "year" : 2014
    }, {
      "title" : "Learning to predict from textual data",
      "author" : [ "Kira Radinsky", "Sagie Davidovich." ],
      "venue" : "Journal of Artificial Intelligence Research (JAIR) 45(1):641–684.",
      "citeRegEx" : "Radinsky and Davidovich.,? 2012",
      "shortCiteRegEx" : "Radinsky and Davidovich.",
      "year" : 2012
    }, {
      "title" : "Learning causality for news events prediction",
      "author" : [ "Kira Radinsky", "Sagie Davidovich", "Shaul Markovitch." ],
      "venue" : "Proceedings of the 21st International Conference on World Wide Web (WWW 2012). pages 909–918.",
      "citeRegEx" : "Radinsky et al\\.,? 2012",
      "shortCiteRegEx" : "Radinsky et al\\.",
      "year" : 2012
    }, {
      "title" : "Measuring ideological proportions in political speeches",
      "author" : [ "Yanchuan Sim", "Brice D.L. Acree", "Justin H. Gross", "Noah A. Smith." ],
      "venue" : "Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP 2013). pages 91–",
      "citeRegEx" : "Sim et al\\.,? 2013",
      "shortCiteRegEx" : "Sim et al\\.",
      "year" : 2013
    }, {
      "title" : "Recognizing stances in online debates",
      "author" : [ "Swapna Somasundaran", "Janyce Wiebe." ],
      "venue" : "Joint conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Pro-",
      "citeRegEx" : "Somasundaran and Wiebe.,? 2009",
      "shortCiteRegEx" : "Somasundaran and Wiebe.",
      "year" : 2009
    }, {
      "title" : "Get out the vote: Determining support or opposition from congressional floor-debate transcripts",
      "author" : [ "Matt Thomas", "Bo Pang", "Lillian Lee." ],
      "venue" : "Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006).",
      "citeRegEx" : "Thomas et al\\.,? 2006",
      "shortCiteRegEx" : "Thomas et al\\.",
      "year" : 2006
    }, {
      "title" : "Predicting elections with twitter: What 140 characters reveal about political sentiment",
      "author" : [ "Andranik Tumasjan", "Timm Oliver Sprenger", "Philipp G Sandner", "Isabell M Welpe." ],
      "venue" : "Fourth International AAAI Conference on Weblogs and Social Media",
      "citeRegEx" : "Tumasjan et al\\.,? 2010",
      "shortCiteRegEx" : "Tumasjan et al\\.",
      "year" : 2010
    }, {
      "title" : "Monday mornings are my fave :) #not exploring the automatic recognition of irony in english tweets",
      "author" : [ "Cynthia Van Hee", "Els Lefever", "Veronique Hoste." ],
      "venue" : "Proceedings of the 26th International Conference on Computational Linguistics (COLING",
      "citeRegEx" : "Hee et al\\.,? 2016",
      "shortCiteRegEx" : "Hee et al\\.",
      "year" : 2016
    }, {
      "title" : "That is your evidence?: Classifying stance in online political debate",
      "author" : [ "Marilyn A. Walker", "Pranav Anand", "Rob Abbott", "Jean E. Fox Tree", "Craig Martell", "Joseph King." ],
      "venue" : "Decision Support Systems 53(4):719–729.",
      "citeRegEx" : "Walker et al\\.,? 2012",
      "shortCiteRegEx" : "Walker et al\\.",
      "year" : 2012
    }, {
      "title" : "Annotating expressions of opinions and emotions in language",
      "author" : [ "Janyce Wiebe", "Theresa Wilson", "Claire Cardie." ],
      "venue" : "Language Resources and Evaluation 39(2):165–210.",
      "citeRegEx" : "Wiebe et al\\.,? 2005",
      "shortCiteRegEx" : "Wiebe et al\\.",
      "year" : 2005
    }, {
      "title" : "Quantifying political leaning from tweets, retweets, and retweeters",
      "author" : [ "Felix Ming Fai Wong", "Chee Wei Tan", "Soumya Sen", "Mung Chiang." ],
      "venue" : "IEEE",
      "citeRegEx" : "Wong et al\\.,? 2016",
      "shortCiteRegEx" : "Wong et al\\.",
      "year" : 2016
    }, {
      "title" : "Joint inference for fine-grained opinion extraction",
      "author" : [ "Bishan Yang", "Claire Cardie." ],
      "venue" : "Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL 2013). pages 1640–1649.",
      "citeRegEx" : "Yang and Cardie.,? 2013",
      "shortCiteRegEx" : "Yang and Cardie.",
      "year" : 2013
    }, {
      "title" : "Classifying the political leaning of news articles and users from user votes",
      "author" : [ "Daniel Xiaodan Zhou", "Paul Resnick", "Qiaozhu Mei." ],
      "venue" : "Fifth International AAAI Conference on Weblogs and Social Media (ICWSM 2011). pages 417–424.",
      "citeRegEx" : "Zhou et al\\.,? 2011",
      "shortCiteRegEx" : "Zhou et al\\.",
      "year" : 2011
    } ],
    "referenceMentions" : [ {
      "referenceID" : 17,
      "context" : "The latest survey by Pew Research Center reported that a majority of US adults (62%) obtain news on social media, and 18% do so often (Gottfried and Shearer, 2016).",
      "startOffset" : 134,
      "endOffset" : 163
    }, {
      "referenceID" : 20,
      "context" : "As news and opinions are shared and amplified by friend networks of individuals (Jamieson and Cappella, 2008), individuals are also isolated from information that does not fit their opinions (Pariser, 2011).",
      "startOffset" : 80,
      "endOffset" : 109
    }, {
      "referenceID" : 30,
      "context" : "As news and opinions are shared and amplified by friend networks of individuals (Jamieson and Cappella, 2008), individuals are also isolated from information that does not fit their opinions (Pariser, 2011).",
      "startOffset" : 191,
      "endOffset" : 206
    }, {
      "referenceID" : 0,
      "context" : "A great deal of studies analyze discussions, interactions, influences, and communities on social media along the political spectrum of liberal to conservative (Adamic and Glance, 2005; Zhou et al., 2011; Cohen and Ruths, 2013; Bakshy et al., 2015; Wong et al., 2016).",
      "startOffset" : 159,
      "endOffset" : 266
    }, {
      "referenceID" : 43,
      "context" : "A great deal of studies analyze discussions, interactions, influences, and communities on social media along the political spectrum of liberal to conservative (Adamic and Glance, 2005; Zhou et al., 2011; Cohen and Ruths, 2013; Bakshy et al., 2015; Wong et al., 2016).",
      "startOffset" : 159,
      "endOffset" : 266
    }, {
      "referenceID" : 8,
      "context" : "A great deal of studies analyze discussions, interactions, influences, and communities on social media along the political spectrum of liberal to conservative (Adamic and Glance, 2005; Zhou et al., 2011; Cohen and Ruths, 2013; Bakshy et al., 2015; Wong et al., 2016).",
      "startOffset" : 159,
      "endOffset" : 266
    }, {
      "referenceID" : 2,
      "context" : "A great deal of studies analyze discussions, interactions, influences, and communities on social media along the political spectrum of liberal to conservative (Adamic and Glance, 2005; Zhou et al., 2011; Cohen and Ruths, 2013; Bakshy et al., 2015; Wong et al., 2016).",
      "startOffset" : 159,
      "endOffset" : 266
    }, {
      "referenceID" : 41,
      "context" : "A great deal of studies analyze discussions, interactions, influences, and communities on social media along the political spectrum of liberal to conservative (Adamic and Glance, 2005; Zhou et al., 2011; Cohen and Ruths, 2013; Bakshy et al., 2015; Wong et al., 2016).",
      "startOffset" : 159,
      "endOffset" : 266
    }, {
      "referenceID" : 23,
      "context" : "Even though these studies provide intuitive visualizations and interpretations along the axis of liberal-conservative, political analysts argue that the axis is flawed and insufficient for representing public opinions and ideologies (Kerlinger, 1984; Maddox and Lilie, 1984).",
      "startOffset" : 233,
      "endOffset" : 274
    }, {
      "referenceID" : 25,
      "context" : "Even though these studies provide intuitive visualizations and interpretations along the axis of liberal-conservative, political analysts argue that the axis is flawed and insufficient for representing public opinions and ideologies (Kerlinger, 1984; Maddox and Lilie, 1984).",
      "startOffset" : 233,
      "endOffset" : 274
    }, {
      "referenceID" : 36,
      "context" : "A potential solution for analyzing multiple axes of political spectrum on social media is stance detection (Thomas et al., 2006; Somasundaran and Wiebe, 2009; Murakami and Raymond, 2010; Anand et al., 2011; Walker et al., 2012; Mohammad et al., 2016; Johnson and Goldwasser, 2016), whose task is to determine whether the author of a text is for, neutral, or against towards a topic (e.",
      "startOffset" : 107,
      "endOffset" : 280
    }, {
      "referenceID" : 35,
      "context" : "A potential solution for analyzing multiple axes of political spectrum on social media is stance detection (Thomas et al., 2006; Somasundaran and Wiebe, 2009; Murakami and Raymond, 2010; Anand et al., 2011; Walker et al., 2012; Mohammad et al., 2016; Johnson and Goldwasser, 2016), whose task is to determine whether the author of a text is for, neutral, or against towards a topic (e.",
      "startOffset" : 107,
      "endOffset" : 280
    }, {
      "referenceID" : 28,
      "context" : "A potential solution for analyzing multiple axes of political spectrum on social media is stance detection (Thomas et al., 2006; Somasundaran and Wiebe, 2009; Murakami and Raymond, 2010; Anand et al., 2011; Walker et al., 2012; Mohammad et al., 2016; Johnson and Goldwasser, 2016), whose task is to determine whether the author of a text is for, neutral, or against towards a topic (e.",
      "startOffset" : 107,
      "endOffset" : 280
    }, {
      "referenceID" : 1,
      "context" : "A potential solution for analyzing multiple axes of political spectrum on social media is stance detection (Thomas et al., 2006; Somasundaran and Wiebe, 2009; Murakami and Raymond, 2010; Anand et al., 2011; Walker et al., 2012; Mohammad et al., 2016; Johnson and Goldwasser, 2016), whose task is to determine whether the author of a text is for, neutral, or against towards a topic (e.",
      "startOffset" : 107,
      "endOffset" : 280
    }, {
      "referenceID" : 39,
      "context" : "A potential solution for analyzing multiple axes of political spectrum on social media is stance detection (Thomas et al., 2006; Somasundaran and Wiebe, 2009; Murakami and Raymond, 2010; Anand et al., 2011; Walker et al., 2012; Mohammad et al., 2016; Johnson and Goldwasser, 2016), whose task is to determine whether the author of a text is for, neutral, or against towards a topic (e.",
      "startOffset" : 107,
      "endOffset" : 280
    }, {
      "referenceID" : 27,
      "context" : "A potential solution for analyzing multiple axes of political spectrum on social media is stance detection (Thomas et al., 2006; Somasundaran and Wiebe, 2009; Murakami and Raymond, 2010; Anand et al., 2011; Walker et al., 2012; Mohammad et al., 2016; Johnson and Goldwasser, 2016), whose task is to determine whether the author of a text is for, neutral, or against towards a topic (e.",
      "startOffset" : 107,
      "endOffset" : 280
    }, {
      "referenceID" : 22,
      "context" : "A potential solution for analyzing multiple axes of political spectrum on social media is stance detection (Thomas et al., 2006; Somasundaran and Wiebe, 2009; Murakami and Raymond, 2010; Anand et al., 2011; Walker et al., 2012; Mohammad et al., 2016; Johnson and Goldwasser, 2016), whose task is to determine whether the author of a text is for, neutral, or against towards a topic (e.",
      "startOffset" : 107,
      "endOffset" : 280
    }, {
      "referenceID" : 27,
      "context" : "More recently, all participants of SemEval 2016 Task 6A (with five topics) could not outperform the baseline supervised method using n-gram features (Mohammad et al., 2016).",
      "startOffset" : 149,
      "endOffset" : 172
    }, {
      "referenceID" : 10,
      "context" : "In order to design high-quality linguistic patterns, this study focuses on hashtags appearing in the corpus, which have been popular clues for locating subjective statements such as sentiments (Davidov et al., 2010), emotions (Qadir and Riloff, 2014), and ironies (Van Hee et al.",
      "startOffset" : 193,
      "endOffset" : 215
    }, {
      "referenceID" : 31,
      "context" : ", 2010), emotions (Qadir and Riloff, 2014), and ironies (Van Hee et al.",
      "startOffset" : 18,
      "endOffset" : 42
    }, {
      "referenceID" : 24,
      "context" : "Therefore, this section applies matrix factorization (Koren et al., 2009) in order to predict missing values, inspired by the work of item recommendation (Bell and Koren, 2007; Dror et al.",
      "startOffset" : 53,
      "endOffset" : 73
    }, {
      "referenceID" : 4,
      "context" : ", 2009) in order to predict missing values, inspired by the work of item recommendation (Bell and Koren, 2007; Dror et al., 2011).",
      "startOffset" : 88,
      "endOffset" : 129
    }, {
      "referenceID" : 13,
      "context" : ", 2009) in order to predict missing values, inspired by the work of item recommendation (Bell and Koren, 2007; Dror et al., 2011).",
      "startOffset" : 88,
      "endOffset" : 129
    }, {
      "referenceID" : 6,
      "context" : "We use libmf6 (Chin et al., 2015) for solving the optimization problem in Equation 2.",
      "startOffset" : 14,
      "endOffset" : 33
    }, {
      "referenceID" : 0,
      "context" : "These studies model the political spectrum of liberal to conservative (Adamic and Glance, 2005; Zhou et al., 2011; Cohen and Ruths, 2013; Bakshy et al., 2015; Wong et al., 2016), political parties (Tumasjan et al.",
      "startOffset" : 70,
      "endOffset" : 177
    }, {
      "referenceID" : 43,
      "context" : "These studies model the political spectrum of liberal to conservative (Adamic and Glance, 2005; Zhou et al., 2011; Cohen and Ruths, 2013; Bakshy et al., 2015; Wong et al., 2016), political parties (Tumasjan et al.",
      "startOffset" : 70,
      "endOffset" : 177
    }, {
      "referenceID" : 8,
      "context" : "These studies model the political spectrum of liberal to conservative (Adamic and Glance, 2005; Zhou et al., 2011; Cohen and Ruths, 2013; Bakshy et al., 2015; Wong et al., 2016), political parties (Tumasjan et al.",
      "startOffset" : 70,
      "endOffset" : 177
    }, {
      "referenceID" : 2,
      "context" : "These studies model the political spectrum of liberal to conservative (Adamic and Glance, 2005; Zhou et al., 2011; Cohen and Ruths, 2013; Bakshy et al., 2015; Wong et al., 2016), political parties (Tumasjan et al.",
      "startOffset" : 70,
      "endOffset" : 177
    }, {
      "referenceID" : 41,
      "context" : "These studies model the political spectrum of liberal to conservative (Adamic and Glance, 2005; Zhou et al., 2011; Cohen and Ruths, 2013; Bakshy et al., 2015; Wong et al., 2016), political parties (Tumasjan et al.",
      "startOffset" : 70,
      "endOffset" : 177
    }, {
      "referenceID" : 37,
      "context" : ", 2016), political parties (Tumasjan et al., 2010; Boutet et al., 2013; Makazhanov and Rafiei, 2013), and elections (O’Connor et al.",
      "startOffset" : 27,
      "endOffset" : 100
    }, {
      "referenceID" : 5,
      "context" : ", 2016), political parties (Tumasjan et al., 2010; Boutet et al., 2013; Makazhanov and Rafiei, 2013), and elections (O’Connor et al.",
      "startOffset" : 27,
      "endOffset" : 100
    }, {
      "referenceID" : 26,
      "context" : ", 2016), political parties (Tumasjan et al., 2010; Boutet et al., 2013; Makazhanov and Rafiei, 2013), and elections (O’Connor et al.",
      "startOffset" : 27,
      "endOffset" : 100
    }, {
      "referenceID" : 29,
      "context" : ", 2013; Makazhanov and Rafiei, 2013), and elections (O’Connor et al., 2010; Conover et al., 2011).",
      "startOffset" : 52,
      "endOffset" : 97
    }, {
      "referenceID" : 9,
      "context" : ", 2013; Makazhanov and Rafiei, 2013), and elections (O’Connor et al., 2010; Conover et al., 2011).",
      "startOffset" : 52,
      "endOffset" : 97
    }, {
      "referenceID" : 14,
      "context" : "The study first constructs “cue lexicons” from political writings labeled with ideologies by domain experts, using sparse additive generative models (Eisenstein et al., 2011).",
      "startOffset" : 149,
      "endOffset" : 174
    }, {
      "referenceID" : 3,
      "context" : "Similarly to ours, their work (Bamman and Smith, 2015) does not requires labeled data for mapping users and topics (subjects) into a latent feature space.",
      "startOffset" : 30,
      "endOffset" : 54
    }, {
      "referenceID" : 40,
      "context" : "Fine-grained opinion analysis The method presented in Section 2 is an instance of finegrained opinion analysis (Wiebe et al., 2005; Choi et al., 2006; Johansson and Moschitti, 2010; Yang and Cardie, 2013; Deng and Wiebe, 2015), which extracts a tuple of a subjective opinion, a holder of",
      "startOffset" : 111,
      "endOffset" : 226
    }, {
      "referenceID" : 7,
      "context" : "Fine-grained opinion analysis The method presented in Section 2 is an instance of finegrained opinion analysis (Wiebe et al., 2005; Choi et al., 2006; Johansson and Moschitti, 2010; Yang and Cardie, 2013; Deng and Wiebe, 2015), which extracts a tuple of a subjective opinion, a holder of",
      "startOffset" : 111,
      "endOffset" : 226
    }, {
      "referenceID" : 21,
      "context" : "Fine-grained opinion analysis The method presented in Section 2 is an instance of finegrained opinion analysis (Wiebe et al., 2005; Choi et al., 2006; Johansson and Moschitti, 2010; Yang and Cardie, 2013; Deng and Wiebe, 2015), which extracts a tuple of a subjective opinion, a holder of",
      "startOffset" : 111,
      "endOffset" : 226
    }, {
      "referenceID" : 42,
      "context" : "Fine-grained opinion analysis The method presented in Section 2 is an instance of finegrained opinion analysis (Wiebe et al., 2005; Choi et al., 2006; Johansson and Moschitti, 2010; Yang and Cardie, 2013; Deng and Wiebe, 2015), which extracts a tuple of a subjective opinion, a holder of",
      "startOffset" : 111,
      "endOffset" : 226
    }, {
      "referenceID" : 11,
      "context" : "Fine-grained opinion analysis The method presented in Section 2 is an instance of finegrained opinion analysis (Wiebe et al., 2005; Choi et al., 2006; Johansson and Moschitti, 2010; Yang and Cardie, 2013; Deng and Wiebe, 2015), which extracts a tuple of a subjective opinion, a holder of",
      "startOffset" : 111,
      "endOffset" : 226
    }, {
      "referenceID" : 16,
      "context" : "” A number of previous studies acquire instances of causal relation (Girju, 2003; Do et al., 2011) and promote/supress relation (Hashimoto et al.",
      "startOffset" : 68,
      "endOffset" : 98
    }, {
      "referenceID" : 12,
      "context" : "” A number of previous studies acquire instances of causal relation (Girju, 2003; Do et al., 2011) and promote/supress relation (Hashimoto et al.",
      "startOffset" : 68,
      "endOffset" : 98
    }, {
      "referenceID" : 18,
      "context" : ", 2011) and promote/supress relation (Hashimoto et al., 2012; Fluck et al., 2015) from text.",
      "startOffset" : 37,
      "endOffset" : 81
    }, {
      "referenceID" : 15,
      "context" : ", 2011) and promote/supress relation (Hashimoto et al., 2012; Fluck et al., 2015) from text.",
      "startOffset" : 37,
      "endOffset" : 81
    }, {
      "referenceID" : 33,
      "context" : "The causality knowledge is useful for predicting (hypotheses of) future events (Radinsky et al., 2012; Radinsky and Davidovich, 2012; Hashimoto et al., 2015).",
      "startOffset" : 79,
      "endOffset" : 157
    }, {
      "referenceID" : 32,
      "context" : "The causality knowledge is useful for predicting (hypotheses of) future events (Radinsky et al., 2012; Radinsky and Davidovich, 2012; Hashimoto et al., 2015).",
      "startOffset" : 79,
      "endOffset" : 157
    }, {
      "referenceID" : 19,
      "context" : "The causality knowledge is useful for predicting (hypotheses of) future events (Radinsky et al., 2012; Radinsky and Davidovich, 2012; Hashimoto et al., 2015).",
      "startOffset" : 79,
      "endOffset" : 157
    } ],
    "year" : 0,
    "abstractText" : "This paper presents an approach for modeling inter-topic preferences of Twitter users: for example, those who agree TPP also agree free trade. This kind of knowledge is useful not only for stance detection across multiple topics but also for various real-world applications including public opinion survey, election prediction, election campaign, and online debate. In order to extract users’ preferences on Twitter, we design high-quality linguistic patterns (e.g., “A is completely wrong”) in which people agree and disagree topics. By applying the linguistic patterns to a collection of tweets, we extract statements agreeing and disagreeing various topics. Inspired by the work on item recommendation, we formalize the task of modeling inter-topic preferences as matrix factorization: representing users’ preference as a user-topic matrix and mapping both users and topics into a latent feature space that abstracts the preferences. The experimental results demonstrate that the presented approach is useful for predicting missing preferences of users and that the latent vector representations of topics encode inter-topic preferences.",
    "creator" : null
  }
}