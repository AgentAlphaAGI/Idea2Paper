{
  "name" : "ACL_2017_727_paper.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Leveraging Behavioral and Social Information for Weakly Supervised Collective Classification of Political Discourse on Twitter",
    "authors" : [ ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "The importance of understanding political discourse on social media platforms is becoming increasingly clear. In recent U.S. presidential elections, Twitter was widely used by all candidates to promote their agenda, interact with supporters, and attack their opponents. Social interactions on such platforms allow politicians to quickly react to current events and gauge interest in and support for their actions. These dynamic settings both emphasize the importance of constructing automated tools for analyzing this content, but also the difficulty of constructing such tools as the language used to discuss new events and political agendas continuously changes. Consequently, the rich social interactions on Twitter can be leveraged to help support such analysis by providing alternatives to direct supervision.\nIn this paper we focus on political framing, a very nuanced political discourse analysis task, on\nTwitter, a relatively unexplored domain for this task. Framing (Entman, 1993; Chong and Druckman, 2007) is employed by politicians to bias the discussion towards their stance by emphasizing specific aspects of the issue. For example, the debate around increasing the minimum wage can be framed as a quality of life issue or as an economic issue. While the first frame supports increasing minimum wage because it betters workers’ lives, the second frame, by conversely emphasizing the costs involved, opposes the increase. Using framing to analyze political discourse has gathered significant interest over the last few years (Tsur et al., 2015; Card et al., 2015; Baumer et al., 2015) as a way to automatically analyze political discourse in Congressional speeches and political news articles. Our dataset consists of the tweets authored by all members of the U.S. Congress from both parties, dealing with several policy issues (e.g., immigration, ACA, etc.). We annotated these tweets by adapting the annotation guidelines developed by Boydstun et al. for Twitter. More details about the annotation process are provided in Section 3.\nTwitter issue framing is a challenging multilabel prediction task. Each tweet can be labeled as using one or more frames, out of 17 possibilities, while only providing 140 characters as input to the classifier. Instead of following a supervised path, our main goal in this paper is to evaluate whether the social and behavioral information available on Twitter is sufficient for constructing a reliable classifier for this task. We approach this task using a weakly supervised collective classification approach which leverages the dependencies between tweet frame predictions based on the interactions between their authors.\nWe model these dependencies by connecting Twitter users that have social connections or behavioral similarity. Social connections are di-\nrected dependencies that represent the followers of each user and retweeting behavior (i.e., user A retweets user B’s content). Interestingly, these social connections capture the flow of influence within political parties; however, the number of connections that cross party lines is extremely low. Instead we rely on capturing behavioral similarity between users to provide us with this information. We construct a temporal histogram for each politician which captures their Twitter activity over time. Users whose Twitter activity peaks at similar times tend to discuss issues in similar ways, making the comparison between their frames usage easier. Figure 1 shows an example of such a network and the prediction dependencies it forms. In addition to the edges, we also represent each politician’s party affiliation and the frequent phrases (e.g., bigrams or trigrams) used by politicians on Twitter.\nWe compile these structural dependencies into a graphical model using Probabilistic Soft Logic (PSL), a recently introduced probabilistic modeling framework 1. As described in Section 4, PSL combines these aspects declaratively by specifying high level rules over a relational representation of tweet features. The rules are compiled into a graphical model called a hinge-loss Markov random field (Bach et al., 2013), which is used to make the frame prediction. Instead of direct supervision we take a bootstrapping approach by providing a small seed set of keywords adapted from Boydstun et al., for each frame.\n1http://psl.cs.umd.edu\nOur experiments show that modeling the social and behavioral connections improves F1 prediction scores in both supervised and unsupervised settings, with double the increase in the latter. We apply our unsupervised model to our entire tweets dataset to analyze framing patterns over time by both party and individual politicians. Our analysis provides insight into the usage of framing for identification of aisle-crossing politicians, i.e., those politicians who vote against their party."
    }, {
      "heading" : "2 Related Work",
      "text" : "Issue framing is related to the broader challenges of biased language analysis (Recasens et al., 2013; Choi et al., 2012; Greene and Resnik, 2009) and subjectivity (Wiebe et al., 2004). Several previous works have explored framing in public statements, Congressional speeches, and news articles (Fulgoni et al., 2016; Tsur et al., 2015; Card et al., 2015; Baumer et al., 2015). Our approach builds upon the previous work on frame analysis of Boydstun et al., by adapting and applying their annotation guidelines for Twitter.\nIn recent years there has been growing interest in analyzing political discourse. Most previous work focuses on opinion mining and stance prediction (Sridhar et al., 2015; Hasan and Ng, 2014; Abu-Jbara et al., 2013; Walker et al., 2012; Abbott et al., 2011; Somasundaran and Wiebe, 2010, 2009). Analyzing political tweets has also attracted considerable interest: a recent SemEval task looked into stance prediction2, and more related to our work, Tan et al. have shown how wording choices can affect message propagation on Twitter. Two recent works look into predicting stance (at user and tweet levels respectively) on Twitter using PSL (Johnson and Goldwasser, 2016; Ebrahimi et al., 2016). Other works focus on identifying and measuring political ideologies (Iyyer et al., 2014; Bamman and Smith, 2015; Sim et al., 2013), policies (Nguyen et al., 2015), and voting patterns (Gerrish and Blei, 2012).\nExploiting social interactions and group structure for prediction has also been explored (Sridhar et al., 2015; Abu-Jbara et al., 2013; West et al., 2014). Works focusing on inferring signed social networks (West et al., 2014), stance classification (Sridhar et al., 2015), social group modeling (Huang et al., 2012), and collective classification using PSL (Bach et al., 2015) are closest\n2http://alt.qcri.org/semeval2016/task6/\nto our approach. Unsupervised and weakly supervised models of Twitter data for several various tasks have been suggested, including: profile (Li et al., 2014b) and life event extraction (Li et al., 2014a), conversation modeling (Ritter et al., 2010), and methods for dealing with the unique language used in microblogging platforms (Eisenstein, 2013).\nPredicting political affiliation and other characteristics of Twitter users has been explored (Volkova et al., 2015, 2014; Yano et al.; Conover et al., 2011). Other works have focused on sentiment analysis (Pla and Hurtado, 2014; Bakliwal et al., 2013), predicting ideology (Djemili et al., 2014), automatic polls based on Twitter sentiment and political forecasting using Twitter (Bermingham and Smeaton, 2011; O’Connor et al., 2010; Tumasjan et al., 2010), as well as distant supervision applications (Marchetti-Bowick and Chambers, 2012)."
    }, {
      "heading" : "3 Data Collection and Annotation",
      "text" : "We collected 184,914 of the most recent tweets of members of the U.S. Congress (both the House of Representatives and Senate). Using an average of ten keywords per issue, we filtered out tweets not related to the following six issues of interest: (1) abortion access, (2) the Affordable Care Act (i.e., ACA or Obamacare), (3) gun rights versus gun control, (4) immigration policies, (5) acts of terrorism, and (6) issues concerning the LGBTQ community. Forty politicians (10 Republicans and Democrats, from both the House and Senate), were chosen randomly for annotation.\nTwo graduate students were trained to annotate each tweet with a frame using the Policy Frames Codebook developed by Boydstun et al.. Brief descriptions of each frame are given in Table 1. During the annotation process, we found that Boydstun’s Frame 15 (Other) was never used. We therefore dropped it from this study. In its place, we propose 3 Twitter-specific frames: Factual (15), Promotion (16), and Personal Sympathy and Support (17). Due to the compound nature of tweets and the consequent possibility of multiple frames per tweet (also discussed in Card et al.), annotators were allowed to label each tweet with multiple frames when one primary frame was not possible. For all such tweets, annotators repeated the annotation process together to determine if the tweets could be represented by a single frame or required\nmore. We computed the inter-annotator agreement using Cohen’s Kappa statistic and have an agreement of 73.4%, which can be viewed as proof of the difficulty of frame classification for tweets. Table 2 presents the statistics of our tweets dataset, which will be released for the community’s use."
    }, {
      "heading" : "4 Global Models of Twitter Language and Activity",
      "text" : "Due to the dynamic nature of political discourse on Twitter, we design weakly supervised PSL models to require as little supervision as possible. The only sources of supervision our approach requires include: unigrams related to the issues, unigrams adapted from the Boydstun et al. Codebook for frames, and political party of the author of the tweets3. The local models described in this section are data-dependent and used to extract and format information from tweets into input for PSL predicates and rules. Our goal to label each tweet with a frame can be defined in PSL notation as a target predicate: FRAME(T, F), where T represents a tweet, and F represents one of the 17 frames listed in Table 1."
    }, {
      "heading" : "4.1 Global Modeling Using PSL",
      "text" : "PSL is a declarative modeling language which can be used to specify weighted, first-order logic rules. These rules are compiled into a hinge-loss Markov random field which defines a probability distribution over possible continuous value assignments to the random variables of the model (Bach et al., 2015) 4. This probability density function is represented as:\nP (Y | X) = 1 Z exp\n( −\nM∑ r=1 λrφr(Y , X)\n)\nwhere Z is a normalization constant, λ is the weight vector, and\nφr(Y,X) = (max{lr(Y, X), 0})ρr\nis the hinge-loss potential specified by a linear function lr. The exponent ρr ∈ 1, 2 is optional. Each potential represents the instantiation of a rule, which takes the following form:\nλ1 : P1(x) ∧ P2(x, y)→ P3(y) λ2 : P1(x) ∧ P4(x, y)→ ¬P3(y)\nP1, P2, P3, and P4 are predicates (e.g., political party, issue, frame, and presence of n-grams) and x, y are variables. Each rule has a weight λ which reflects that rule’s importance and is learned using\n3All information will be released with our dataset at: www.***.***.\n4This is the opposite of other probabilistic logical models, e.g. MLNs, in which rules are strictly true or false.\nthe Expectation-Maximization algorithm in our unsupervised experiments. Using concrete constants a, b (e.g., tweets and words) which instantiate the variables x, y, model atoms are mapped to continuous [0,1] assignments. More important rules (i.e., those with larger weights) are given preference by the model."
    }, {
      "heading" : "4.2 Language Based Models",
      "text" : "Unigrams: Using the guidelines provided in the Policy Frames Codebook (Boydstun et al., 2014), we adapted a list of expected unigrams for each frame. For example, unigrams that should be related to Frame 12 (Political Factors & Implications) include: filibuster, lobby, Democrats, Republicans. We expect that if a tweet and frame contain a matching unigram, then that tweet is likely expressed by that frame. The information that tweet T has expected unigram U of frame F is represented with the PSL predicate: HASUNIGRAMF (T, U). This knowledge is then used as input to PSL Model 1 via the rule: HASUNIGRAMF (T, U) →FRAME(T, F) (shown in line 1 of Table 3).\nHowever, not every tweet will have a unigram that matches those in this list. Under the intuition that at least one unigram in a tweet should be similar to a unigram in the list, we designed the fol-\nlowing MaxSim metric to compute the maximum similarity between a word in a tweet and a word from the list of unigrams.\nMAXSIM(T, F) = argmax u∈F,w∈T SIMILARITY(W,U)\n(1) T is a tweet, W is each word in T, and U is each unigram in the list of expected unigrams (per frame). Similarity is the computed word2vec similarity of each word in the tweet with every unigram in the list of unigrams for each frame. The frame F of the maximum scoring unigram is input to the PSL predicate: MAXSIMF (T, F), which indicates that tweet T has the highest similarity to frame F.\nBigrams and Trigrams: In addition to unigrams, we also explored the effects of political party slogans on frame prediction. Slogans are common catch phrases or sayings that people typically associate with different U.S. political parties. For example, Republicans are known for using “repeal and replace”, a trigram, when they discuss the ACA. Similarly, in the 2016 U.S. presidential election, Secretary Hillary Clinton’s campaign slogan became “Love Trumps Hate”. To visualize slogan usage by parties for different issues, we used the entire tweets dataset, including all unlabeled tweets, to extract the top bigrams and trigrams per party for each issue. The\nhistograms in Figure 2 show these distributions for the top 100 bigrams and trigrams. Based on these results, we use the top 20 bigrams (e.g., women’s healthcare and immigration reform) and trigrams (e.g. prevent gun violence) as input to PSL predicates PARTYBIGRAMP (T, B) and PARTYTRIGRAMP (T, TG). These rules represent that tweet T has bigram B or trigram TG from the respective phrase lists of either party (i.e., P represents either Democrat or Republican in the rule instantiation)."
    }, {
      "heading" : "4.3 Twitter Behavior Based Models",
      "text" : "In addition to language based features of tweets, we also exploit the behavioral features of Twitter including similarities between temporal activity and network relationships.\nTemporal Similarity: When an event happens politicians are most likely to tweet about that event within hours of its occurrence. Similarly, most politicians tweet about the event most frequently the day of the event and this frequency decreases over time. We expect that the frames used the day of an event will be similar and change over time. To capture this behavior we use the PSL predicate SAMETIME(T1, T2). This indicates that\ntweet T1 occurs around the same time as tweet T25. This information is used in Model 4 via rules such as: SAMETIME(T1, T2) & FRAME(T1, F) →FRAME(T2, F), as shown in line 4 of Table 3.\nNetwork Similarity: Finally, we expect that politicians who share ideologies, and thus are likely to frame issues similarly, will retweet and/or follow each other on Twitter. Due to the compound nature of tweets, retweeting with additional comments can add more frames to the original tweet. Additionally, politicians on Twitter are more likely to follow members of their own party or similar non-political entities than those of the opposing party. To capture this network-based behavior we use two PSL predicates: RETWEETS(T1, T2) and FOLLOWS(T1, T2). These predicates indicate that the content of tweet T1 includes a retweet of tweet T2 and that the author of T1 follows the author of T2 on Twitter, respectively. The last two lines of Table 3 show examples of how network similarity is incorporated into PSL rules."
    }, {
      "heading" : "5 Experiments",
      "text" : "Experimental Settings: We provide an analysis of our PSL models under both supervised and unsupervised settings. As shown in Table 4, Model 1 in a supervised setting is similar to the traditional bag-of-words baseline, which we use as our baseline to improve upon. Additionally, Model 6 of the supervised, collective network setting represents the best results we can achieve. In the supervised experiments, we used five-fold cross validation with randomly chosen splits.\nWe also explore the results of our PSL models in an unsupervised setting because the highly dynamic nature of political discourse on Twitter makes it unrealistic to expect annotated data to\n5We conducted experiments with different hour and day limits and found that using a time frame of one hour results in the best accuracy.\ngeneralize to future discussions. The only source of supervision comes from the initial unigrams lists as described in Section 4. The labeled tweets are used for evaluation only. As seen in Table 4, we are able to improve the unsupervised model to within an F1 score of 7.36 points of the unigram baseline, and 19.13 points of the best supervised score.\nEvaluation Metrics: Since each tweet can have more than one frame, our prediction task is a multilabel classification task. The precision of a multilabel model is the ratio of how many predicted labels are correct:\nPrecision = 1\nT T∑ t=1 |Yt ∩ h(xt)| |h(xt)|\n(2)\nThe recall of this model is the ratio of how many of the actual labels were predicted:\nRecall = 1\nT T∑ t=1 |Yt ∩ h(xt)| |Yt|\n(3)\nIn both formulas, T is the number of tweets, Yt is the true label for tweet t, xt is a tweet example, and h(xt) are the predicted labels for that tweet. The F1 score is computed as the harmonic mean of the precision and recall.\nAnalysis of Supervised Experiments: Table 5 shows the results of our supervised experiments. Here we can see that by adding Twitter behavior (beginning with Model 4), our behaviorbased models achieve the best F1 scores across all frames. Model 4 achieves the highest results on two frames, suggesting retweeting and network follower information does not help improve the prediction score for these frames. Model 5 similarly achieves the highest prediction for 5 of the frames, suggesting network follower information cannot further improve the score for these frames. Overall, the Twitter behavior based models are able to outperform language based models alone, including the best performing language\nmodel (Model 3) which combines unigrams, bigrams, and trigrams together to collectively infer the correct frame(s).\nAnalysis of Unsupervised Experiments: In the unsupervised setting, Model 6, the combination of language and Twitter behavior features achieves the best results on 16 of the 17 issues, as shown in Table 6. There are a few interesting aspects of the unsupervised setting which differ from the supervised setting. Six of the frame predictions do worse in Model 2, which is double that of the supervised version. This is likely due to the presence of overlapping bigrams across frames and issues, e.g., “women’s healthcare” could appear in both Frames 4 and 8 and the issues of ACA and abortion. However, all six are able to improve with the addition of trigrams (Model 3), whereas only 1 of 3 frames improves in the supervised setting. This suggests that bigrams may not be as useful as trigrams in an unsupervised setting. Finally, in Model 5, which adds retweet behaviors, we notice that 5 of the frames decrease in F1 score and 11 of the frames have the same score as the previous model. These results suggest that retweet behaviors are not as useful as the follower network relationships in an unsupervised setting."
    }, {
      "heading" : "6 Qualitative Analysis",
      "text" : "To explore the usefulness of frame identification in political discourse analysis, we apply our best performing model (Model 6) on the unlabeled dataset to determine framing patterns over time, both by party and individual. Figure 3 shows the results of our frame analysis over time for two issues: ACA and terrorism6. We compiled the predicted frames for tweets from 2014 to 2016 for each party. Figure 4 presents the results of frame prediction for 2015 tweets of individuals for these two issues.\nParty Frames: From Figure 3(a) we can see that Democrats mainly use Frames 1, 4, 8, 9, and 15 to discuss ACA, while Figure 3(c) shows that Republicans predominantly use Frames 1, 8, 9, 12, and 13. Though the parties use similar frames, they are used to express different agendas. For example, Democrats use Frame 8 to indicate the positive effect that the ACA has had in granting more Americans health care access. Republicans,\n6Due to space, we omit the other 4 issues. These 2 were chosen because they are among the most frequently discussed topics in our dataset.\nhowever, use Frame 8 (and Frame 13) to indicate their party’s agenda to replace the ACA with access to different options for health care. Additionally, Democrats use the Fairness & Equality Frame (Frame 4) to convey that the ACA gives minority groups a better chance at accessing health care. They also use Frame 15 to express statistics about enrollment of Americans under the ACA. Finally, Republicans use Frames 12 and 13 to bring attention to their own party’s actions to “repeal and replace” the ACA with different policies.\nFigures 3(b) and 3(d) show the party-based framing patterns over time for terrorism related tweets. For this issue both parties use similar frames: 3, 7, 10, 14, 16, and 17, but to express different views. For example, Democrats use Frame\n3 to indicate moral responsibility to fight ISIS. Republicans use Frame 3 to frame terrorists or their attacks as a result of “radical Islam”. An interesting pattern to note is seen in Frames 10 and 14 for both parties. In 2015 there is a large increase in the usage of this frame. This seems to indicate that parties possibly adopt new frames simultaneously or in response to the opposing party, perhaps in an effort to be in control of the way the message is delivered through that frame.\nIndividual Frames: In addition to entire party analysis, we were interested in seeing if frames could shed light on the behavior of aisle-crossing politicians. These are politicians who do not vote the same as the majority vote of their party (i.e., they vote the same as the opposing party). Identifying such politicians can be useful in governments which are heavily split by party, i.e., governments such as the recent U.S. Congress (2015 to 2017), where politicians tend to vote the same as the rest of their party members. For this analysis, we collected five 2015 votes from the House of Representatives on both issues and compiled a list of the politicians who voted opposite to their party.\nThe most important descriptor we noticed was that all aisle-crossing politicians tweet less frequently on the issue than their fellow party members. This is true for both parties. This behavior could indicate lack of desire to draw attention to one’s stance on the particular issue.\nFigure 4(a) shows the framing patterns of aislecrossing Republicans on ACA votes from 2015. Recall from Figure 3 that Democrats mostly use Frames 1, 4, 8, 9, and 15, while Republicans mainly use Frames 1, 8, and 9. In this example, these Republicans are considered aislecrossing votes because they have voted the same as Democrats on this issue. The most interesting pattern to note here is that these Republicans use the same framing patterns as the Republicans (Frames 1, 8, and 9), but they also use the frames that are unique to Democrats: Frames 4 and 15. These latter two frames appear significantly less in the Republican tweets of our entire dataset as well. These results suggest that to predict aisle-crossing Republicans it would be useful to check for usage of typically Democrat-associated frames, especially if those frames are infrequently used by Republicans.\nFigure 4(b) shows the predicted frames for aisle-crossing Democrats on terrorism-related votes. We see here that there are very few tweets from these Democrats on this issue and that overall they use the same framing patterns as seen previously: Frames 3, 7, 10, 14, 16, and 17. However, given the small scale of these tweets, we can also consider Frames 12 and 13 to show peaks for this example. This suggests that for aisle-crossing Democrats the use of additional frames not seen in their party might indicate potentially different voting behaviors."
    }, {
      "heading" : "7 Conclusion",
      "text" : "In this paper we present the task of collective classification of Twitter data for framing prediction. We show that by incorporating Twitter behaviors such as similar activity times and similar networks, we can increase F1 score prediction. We provide an analysis of our approach in both supervised and unsupervised settings, as well as a real world analysis of framing patterns over time. Our global PSL models can be applied to other domains, such as politics in other countries, simply by changing the initial unigram keywords to reflect the politics of those countries."
    } ],
    "references" : [ {
      "title" : "How can you say such things?!?: Recognizing disagreement in informal political argument",
      "author" : [ "Rob Abbott", "Marilyn Walker", "Pranav Anand", "Jean E. Fox Tree", "Robeson Bowmani", "Joseph King." ],
      "venue" : "Proc. of the Workshop on Language in Social Media.",
      "citeRegEx" : "Abbott et al\\.,? 2011",
      "shortCiteRegEx" : "Abbott et al\\.",
      "year" : 2011
    }, {
      "title" : "Identifying opinion subgroups in arabic online discussions",
      "author" : [ "Amjad Abu-Jbara", "Ben King", "Mona Diab", "Dragomir Radev." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Abu.Jbara et al\\.,? 2013",
      "shortCiteRegEx" : "Abu.Jbara et al\\.",
      "year" : 2013
    }, {
      "title" : "Hinge-loss markov random fields and probabilistic soft logic",
      "author" : [ "Stephen H Bach", "Matthias Broecheler", "Bert Huang", "Lise Getoor." ],
      "venue" : "arXiv preprint arXiv:1505.04406 .",
      "citeRegEx" : "Bach et al\\.,? 2015",
      "shortCiteRegEx" : "Bach et al\\.",
      "year" : 2015
    }, {
      "title" : "Hinge-loss Markov random fields: Convex inference for structured prediction",
      "author" : [ "Stephen H. Bach", "Bert Huang", "Ben London", "Lise Getoor." ],
      "venue" : "Proc. of UAI.",
      "citeRegEx" : "Bach et al\\.,? 2013",
      "shortCiteRegEx" : "Bach et al\\.",
      "year" : 2013
    }, {
      "title" : "Sentiment analysis of political tweets: Towards an accurate classifier",
      "author" : [ "Akshat Bakliwal", "Jennifer Foster", "Jennifer van der Puil", "Ron O’Brien", "Lamia Tounsi", "Mark Hughes" ],
      "venue" : "In Proc. of ACL",
      "citeRegEx" : "Bakliwal et al\\.,? \\Q2013\\E",
      "shortCiteRegEx" : "Bakliwal et al\\.",
      "year" : 2013
    }, {
      "title" : "Open extraction of fine-grained political statements",
      "author" : [ "David Bamman", "Noah A Smith." ],
      "venue" : "Proc. of EMNLP.",
      "citeRegEx" : "Bamman and Smith.,? 2015",
      "shortCiteRegEx" : "Bamman and Smith.",
      "year" : 2015
    }, {
      "title" : "Testing and comparing computational approaches for identifying the language of framing in political news",
      "author" : [ "Eric Baumer", "Elisha Elovic", "Ying Qin", "Francesca Polletta", "Geri Gay." ],
      "venue" : "In Proc. of NAACL.",
      "citeRegEx" : "Baumer et al\\.,? 2015",
      "shortCiteRegEx" : "Baumer et al\\.",
      "year" : 2015
    }, {
      "title" : "On using twitter to monitor political sentiment and predict election results",
      "author" : [ "Adam Bermingham", "Alan F Smeaton" ],
      "venue" : null,
      "citeRegEx" : "Bermingham and Smeaton.,? \\Q2011\\E",
      "shortCiteRegEx" : "Bermingham and Smeaton.",
      "year" : 2011
    }, {
      "title" : "Tracking the development of media frames within and across policy issues",
      "author" : [ "Amber Boydstun", "Dallas Card", "Justin H. Gross", "Philip Resnik", "Noah A. Smith" ],
      "venue" : null,
      "citeRegEx" : "Boydstun et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Boydstun et al\\.",
      "year" : 2014
    }, {
      "title" : "The media frames corpus: Annotations of frames across issues",
      "author" : [ "Dallas Card", "Amber E. Boydstun", "Justin H. Gross", "Philip Resnik", "Noah A. Smith." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Card et al\\.,? 2015",
      "shortCiteRegEx" : "Card et al\\.",
      "year" : 2015
    }, {
      "title" : "Hedge detection as a lens on framing in the gmo debates: A position paper",
      "author" : [ "Eunsol Choi", "Chenhao Tan", "Lillian Lee", "Cristian Danescu-Niculescu-Mizil", "Jennifer Spindel." ],
      "venue" : "Proc. of ACL Workshops.",
      "citeRegEx" : "Choi et al\\.,? 2012",
      "shortCiteRegEx" : "Choi et al\\.",
      "year" : 2012
    }, {
      "title" : "Framing theory",
      "author" : [ "Dennis Chong", "James N Druckman." ],
      "venue" : "Annu. Rev. Polit. Sci. 10:103–126.",
      "citeRegEx" : "Chong and Druckman.,? 2007",
      "shortCiteRegEx" : "Chong and Druckman.",
      "year" : 2007
    }, {
      "title" : "Predicting the political alignment of twitter users",
      "author" : [ "Michael D Conover", "Bruno Gonçalves", "Jacob Ratkiewicz", "Alessandro Flammini", "Filippo Menczer." ],
      "venue" : "Proc. of PASSAT .",
      "citeRegEx" : "Conover et al\\.,? 2011",
      "shortCiteRegEx" : "Conover et al\\.",
      "year" : 2011
    }, {
      "title" : "What does twitter have to say about ideology? In NLP 4 CMC",
      "author" : [ "Sarah Djemili", "Julien Longhi", "Claudia Marinica", "Dimitris Kotzinos", "Georges-Elia Sarfati" ],
      "venue" : null,
      "citeRegEx" : "Djemili et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Djemili et al\\.",
      "year" : 2014
    }, {
      "title" : "Weakly supervised tweet stance classification by relational bootstrapping",
      "author" : [ "Javid Ebrahimi", "Dejing Dou", "Daniel Lowd." ],
      "venue" : "Proc. of EMNLP.",
      "citeRegEx" : "Ebrahimi et al\\.,? 2016",
      "shortCiteRegEx" : "Ebrahimi et al\\.",
      "year" : 2016
    }, {
      "title" : "What to do about bad language on the internet",
      "author" : [ "Jacob Eisenstein." ],
      "venue" : "Proc. of NAACL.",
      "citeRegEx" : "Eisenstein.,? 2013",
      "shortCiteRegEx" : "Eisenstein.",
      "year" : 2013
    }, {
      "title" : "Framing: Toward clarification of a fractured paradigm",
      "author" : [ "Robert M Entman." ],
      "venue" : "Journal of communication 43(4):51–58.",
      "citeRegEx" : "Entman.,? 1993",
      "shortCiteRegEx" : "Entman.",
      "year" : 1993
    }, {
      "title" : "An empirical exploration of moral foundations theory in partisan news sources",
      "author" : [ "Dean Fulgoni", "Jordan Carpenter", "Lyle Ungar", "Daniel Preotiuc-Pietro." ],
      "venue" : "Proc. of LREC.",
      "citeRegEx" : "Fulgoni et al\\.,? 2016",
      "shortCiteRegEx" : "Fulgoni et al\\.",
      "year" : 2016
    }, {
      "title" : "How they vote: Issue-adjusted models of legislative behavior",
      "author" : [ "Sean Gerrish", "David M Blei." ],
      "venue" : "Advances in Neural Information Processing Systems. pages 2753–2761.",
      "citeRegEx" : "Gerrish and Blei.,? 2012",
      "shortCiteRegEx" : "Gerrish and Blei.",
      "year" : 2012
    }, {
      "title" : "More than words: Syntactic packaging and implicit sentiment",
      "author" : [ "Stephan Greene", "Philip Resnik." ],
      "venue" : "Proc. of NAACL.",
      "citeRegEx" : "Greene and Resnik.,? 2009",
      "shortCiteRegEx" : "Greene and Resnik.",
      "year" : 2009
    }, {
      "title" : "Why are you taking this stance? identifying and classifying reasons in ideological debates",
      "author" : [ "Kazi Saidul Hasan", "Vincent Ng." ],
      "venue" : "Proc. of EMNLP.",
      "citeRegEx" : "Hasan and Ng.,? 2014",
      "shortCiteRegEx" : "Hasan and Ng.",
      "year" : 2014
    }, {
      "title" : "Social group modeling with probabilistic soft logic",
      "author" : [ "Bert Huang", "Stephen H. Bach", "Eric Norris", "Jay Pujara", "Lise Getoor." ],
      "venue" : "NIPS Workshops.",
      "citeRegEx" : "Huang et al\\.,? 2012",
      "shortCiteRegEx" : "Huang et al\\.",
      "year" : 2012
    }, {
      "title" : "Political ideology detection using recursive neural networks",
      "author" : [ "Iyyer", "Enns", "Boyd-Graber", "Resnik." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Iyyer et al\\.,? 2014",
      "shortCiteRegEx" : "Iyyer et al\\.",
      "year" : 2014
    }, {
      "title" : "all i know about politics is what i read in twitter”: Weakly supervised models for extracting politicians stances from twitter",
      "author" : [ "Kristen Johnson", "Dan Goldwasser." ],
      "venue" : "Proc. of CoLING.",
      "citeRegEx" : "Johnson and Goldwasser.,? 2016",
      "shortCiteRegEx" : "Johnson and Goldwasser.",
      "year" : 2016
    }, {
      "title" : "Major life event extraction from twitter based on congratulations/condolences speech acts",
      "author" : [ "Jiwei Li", "Alan Ritter", "Claire Cardie", "Eduard H Hovy." ],
      "venue" : "Proc. of EMNLP.",
      "citeRegEx" : "Li et al\\.,? 2014a",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2014
    }, {
      "title" : "Weakly supervised user profile extraction from twitter",
      "author" : [ "Jiwei Li", "Alan Ritter", "Eduard H Hovy." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Li et al\\.,? 2014b",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2014
    }, {
      "title" : "Learning for microblogs with distant supervision: Political forecasting with twitter",
      "author" : [ "Micol Marchetti-Bowick", "Nathanael Chambers." ],
      "venue" : "Proc. of EACL.",
      "citeRegEx" : "Marchetti.Bowick and Chambers.,? 2012",
      "shortCiteRegEx" : "Marchetti.Bowick and Chambers.",
      "year" : 2012
    }, {
      "title" : "Tea party in the house: A hierarchical ideal point topic model and its application to republican legislators in the 112th congress",
      "author" : [ "Viet-An Nguyen", "Jordan Boyd-Graber", "Philip Resnik", "Kristina Miler." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Nguyen et al\\.,? 2015",
      "shortCiteRegEx" : "Nguyen et al\\.",
      "year" : 2015
    }, {
      "title" : "From tweets to polls: Linking text sentiment to public opinion time series",
      "author" : [ "Brendan O’Connor", "Ramnath Balasubramanyan", "Bryan R Routledge", "Noah A Smith" ],
      "venue" : "In Proc. of ICWSM",
      "citeRegEx" : "O.Connor et al\\.,? \\Q2010\\E",
      "shortCiteRegEx" : "O.Connor et al\\.",
      "year" : 2010
    }, {
      "title" : "Political tendency identification in twitter using sentiment analysis techniques",
      "author" : [ "Ferran Pla", "Lluı́s F Hurtado" ],
      "venue" : "In Proc. of COLING",
      "citeRegEx" : "Pla and Hurtado.,? \\Q2014\\E",
      "shortCiteRegEx" : "Pla and Hurtado.",
      "year" : 2014
    }, {
      "title" : "Linguistic models for analyzing and detecting biased language",
      "author" : [ "Marta Recasens", "Cristian Danescu-Niculescu-Mizil", "Dan Jurafsky." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Recasens et al\\.,? 2013",
      "shortCiteRegEx" : "Recasens et al\\.",
      "year" : 2013
    }, {
      "title" : "Unsupervised modeling of twitter conversations",
      "author" : [ "Alan Ritter", "Colin Cherry", "Bill Dolan." ],
      "venue" : "Proc. of NAACL.",
      "citeRegEx" : "Ritter et al\\.,? 2010",
      "shortCiteRegEx" : "Ritter et al\\.",
      "year" : 2010
    }, {
      "title" : "Measuring ideological proportions in political speeches",
      "author" : [ "Sim", "Acree", "Gross", "Smith." ],
      "venue" : "Proc. of EMNLP.",
      "citeRegEx" : "Sim et al\\.,? 2013",
      "shortCiteRegEx" : "Sim et al\\.",
      "year" : 2013
    }, {
      "title" : "Recognizing stances in online debates",
      "author" : [ "Swapna Somasundaran", "Janyce Wiebe." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Somasundaran and Wiebe.,? 2009",
      "shortCiteRegEx" : "Somasundaran and Wiebe.",
      "year" : 2009
    }, {
      "title" : "Recognizing stances in ideological on-line debates",
      "author" : [ "Swapna Somasundaran", "Janyce Wiebe." ],
      "venue" : "Proc. of NAACL Workshops.",
      "citeRegEx" : "Somasundaran and Wiebe.,? 2010",
      "shortCiteRegEx" : "Somasundaran and Wiebe.",
      "year" : 2010
    }, {
      "title" : "Joint models of disagreement and stance in online debate",
      "author" : [ "Dhanya Sridhar", "James Foulds", "Bert Huang", "Lise Getoor", "Marilyn Walker." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Sridhar et al\\.,? 2015",
      "shortCiteRegEx" : "Sridhar et al\\.",
      "year" : 2015
    }, {
      "title" : "The effect of wording on message propagation: Topicand author-controlled natural experiments on twitter",
      "author" : [ "Chenhao Tan", "Lillian Lee", "Bo Pang." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Tan et al\\.,? 2014",
      "shortCiteRegEx" : "Tan et al\\.",
      "year" : 2014
    }, {
      "title" : "A frame of mind: Using statistical models for detection of framing and agenda setting campaigns",
      "author" : [ "Oren Tsur", "Dan Calacci", "David Lazer." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Tsur et al\\.,? 2015",
      "shortCiteRegEx" : "Tsur et al\\.",
      "year" : 2015
    }, {
      "title" : "Predicting elections with twitter: What 140 characters reveal about political sentiment",
      "author" : [ "Andranik Tumasjan", "Timm Oliver Sprenger", "Philipp G Sandner", "Isabell M Welpe." ],
      "venue" : "ICWSM.",
      "citeRegEx" : "Tumasjan et al\\.,? 2010",
      "shortCiteRegEx" : "Tumasjan et al\\.",
      "year" : 2010
    }, {
      "title" : "Inferring latent user properties from texts published in social media",
      "author" : [ "Svitlana Volkova", "Yoram Bachrach", "Michael Armstrong", "Vijay Sharma." ],
      "venue" : "Proc. of AAAI.",
      "citeRegEx" : "Volkova et al\\.,? 2015",
      "shortCiteRegEx" : "Volkova et al\\.",
      "year" : 2015
    }, {
      "title" : "Inferring user political preferences from streaming communications",
      "author" : [ "Svitlana Volkova", "Glen Coppersmith", "Benjamin Van Durme." ],
      "venue" : "Proc. of ACL.",
      "citeRegEx" : "Volkova et al\\.,? 2014",
      "shortCiteRegEx" : "Volkova et al\\.",
      "year" : 2014
    }, {
      "title" : "Stance classification using dialogic properties of persuasion",
      "author" : [ "Marilyn A. Walker", "Pranav Anand", "Robert Abbott", "Ricky Grant." ],
      "venue" : "Proc. of NAACL.",
      "citeRegEx" : "Walker et al\\.,? 2012",
      "shortCiteRegEx" : "Walker et al\\.",
      "year" : 2012
    }, {
      "title" : "Exploiting social network structure for person-to-person sentiment analysis",
      "author" : [ "Robert West", "Hristo S Paskov", "Jure Leskovec", "Christopher Potts." ],
      "venue" : "TACL .",
      "citeRegEx" : "West et al\\.,? 2014",
      "shortCiteRegEx" : "West et al\\.",
      "year" : 2014
    }, {
      "title" : "Learning subjective language",
      "author" : [ "Janyce Wiebe", "Theresa Wilson", "Rebecca Bruce", "Matthew Bell", "Melanie Martin." ],
      "venue" : "Computational linguistics .",
      "citeRegEx" : "Wiebe et al\\.,? 2004",
      "shortCiteRegEx" : "Wiebe et al\\.",
      "year" : 2004
    } ],
    "referenceMentions" : [ {
      "referenceID" : 16,
      "context" : "Framing (Entman, 1993; Chong and Druckman, 2007) is employed by politicians to bias the discussion towards their stance by emphasizing specific aspects of the issue.",
      "startOffset" : 8,
      "endOffset" : 48
    }, {
      "referenceID" : 11,
      "context" : "Framing (Entman, 1993; Chong and Druckman, 2007) is employed by politicians to bias the discussion towards their stance by emphasizing specific aspects of the issue.",
      "startOffset" : 8,
      "endOffset" : 48
    }, {
      "referenceID" : 37,
      "context" : "Using framing to analyze political discourse has gathered significant interest over the last few years (Tsur et al., 2015; Card et al., 2015; Baumer et al., 2015) as a way to automatically analyze political discourse in Congressional speeches and political news articles.",
      "startOffset" : 103,
      "endOffset" : 162
    }, {
      "referenceID" : 9,
      "context" : "Using framing to analyze political discourse has gathered significant interest over the last few years (Tsur et al., 2015; Card et al., 2015; Baumer et al., 2015) as a way to automatically analyze political discourse in Congressional speeches and political news articles.",
      "startOffset" : 103,
      "endOffset" : 162
    }, {
      "referenceID" : 6,
      "context" : "Using framing to analyze political discourse has gathered significant interest over the last few years (Tsur et al., 2015; Card et al., 2015; Baumer et al., 2015) as a way to automatically analyze political discourse in Congressional speeches and political news articles.",
      "startOffset" : 103,
      "endOffset" : 162
    }, {
      "referenceID" : 3,
      "context" : "The rules are compiled into a graphical model called a hinge-loss Markov random field (Bach et al., 2013), which is used to make the frame prediction.",
      "startOffset" : 86,
      "endOffset" : 105
    }, {
      "referenceID" : 30,
      "context" : "Issue framing is related to the broader challenges of biased language analysis (Recasens et al., 2013; Choi et al., 2012; Greene and Resnik, 2009) and subjectivity (Wiebe et al.",
      "startOffset" : 79,
      "endOffset" : 146
    }, {
      "referenceID" : 10,
      "context" : "Issue framing is related to the broader challenges of biased language analysis (Recasens et al., 2013; Choi et al., 2012; Greene and Resnik, 2009) and subjectivity (Wiebe et al.",
      "startOffset" : 79,
      "endOffset" : 146
    }, {
      "referenceID" : 19,
      "context" : "Issue framing is related to the broader challenges of biased language analysis (Recasens et al., 2013; Choi et al., 2012; Greene and Resnik, 2009) and subjectivity (Wiebe et al.",
      "startOffset" : 79,
      "endOffset" : 146
    }, {
      "referenceID" : 43,
      "context" : ", 2012; Greene and Resnik, 2009) and subjectivity (Wiebe et al., 2004).",
      "startOffset" : 50,
      "endOffset" : 70
    }, {
      "referenceID" : 17,
      "context" : "Several previous works have explored framing in public statements, Congressional speeches, and news articles (Fulgoni et al., 2016; Tsur et al., 2015; Card et al., 2015; Baumer et al., 2015).",
      "startOffset" : 109,
      "endOffset" : 190
    }, {
      "referenceID" : 37,
      "context" : "Several previous works have explored framing in public statements, Congressional speeches, and news articles (Fulgoni et al., 2016; Tsur et al., 2015; Card et al., 2015; Baumer et al., 2015).",
      "startOffset" : 109,
      "endOffset" : 190
    }, {
      "referenceID" : 9,
      "context" : "Several previous works have explored framing in public statements, Congressional speeches, and news articles (Fulgoni et al., 2016; Tsur et al., 2015; Card et al., 2015; Baumer et al., 2015).",
      "startOffset" : 109,
      "endOffset" : 190
    }, {
      "referenceID" : 6,
      "context" : "Several previous works have explored framing in public statements, Congressional speeches, and news articles (Fulgoni et al., 2016; Tsur et al., 2015; Card et al., 2015; Baumer et al., 2015).",
      "startOffset" : 109,
      "endOffset" : 190
    }, {
      "referenceID" : 35,
      "context" : "Most previous work focuses on opinion mining and stance prediction (Sridhar et al., 2015; Hasan and Ng, 2014; Abu-Jbara et al., 2013; Walker et al., 2012; Abbott et al., 2011; Somasundaran and Wiebe, 2010, 2009).",
      "startOffset" : 67,
      "endOffset" : 211
    }, {
      "referenceID" : 20,
      "context" : "Most previous work focuses on opinion mining and stance prediction (Sridhar et al., 2015; Hasan and Ng, 2014; Abu-Jbara et al., 2013; Walker et al., 2012; Abbott et al., 2011; Somasundaran and Wiebe, 2010, 2009).",
      "startOffset" : 67,
      "endOffset" : 211
    }, {
      "referenceID" : 1,
      "context" : "Most previous work focuses on opinion mining and stance prediction (Sridhar et al., 2015; Hasan and Ng, 2014; Abu-Jbara et al., 2013; Walker et al., 2012; Abbott et al., 2011; Somasundaran and Wiebe, 2010, 2009).",
      "startOffset" : 67,
      "endOffset" : 211
    }, {
      "referenceID" : 41,
      "context" : "Most previous work focuses on opinion mining and stance prediction (Sridhar et al., 2015; Hasan and Ng, 2014; Abu-Jbara et al., 2013; Walker et al., 2012; Abbott et al., 2011; Somasundaran and Wiebe, 2010, 2009).",
      "startOffset" : 67,
      "endOffset" : 211
    }, {
      "referenceID" : 0,
      "context" : "Most previous work focuses on opinion mining and stance prediction (Sridhar et al., 2015; Hasan and Ng, 2014; Abu-Jbara et al., 2013; Walker et al., 2012; Abbott et al., 2011; Somasundaran and Wiebe, 2010, 2009).",
      "startOffset" : 67,
      "endOffset" : 211
    }, {
      "referenceID" : 23,
      "context" : "Two recent works look into predicting stance (at user and tweet levels respectively) on Twitter using PSL (Johnson and Goldwasser, 2016; Ebrahimi et al., 2016).",
      "startOffset" : 106,
      "endOffset" : 159
    }, {
      "referenceID" : 14,
      "context" : "Two recent works look into predicting stance (at user and tweet levels respectively) on Twitter using PSL (Johnson and Goldwasser, 2016; Ebrahimi et al., 2016).",
      "startOffset" : 106,
      "endOffset" : 159
    }, {
      "referenceID" : 22,
      "context" : "Other works focus on identifying and measuring political ideologies (Iyyer et al., 2014; Bamman and Smith, 2015; Sim et al., 2013), policies (Nguyen et al.",
      "startOffset" : 68,
      "endOffset" : 130
    }, {
      "referenceID" : 5,
      "context" : "Other works focus on identifying and measuring political ideologies (Iyyer et al., 2014; Bamman and Smith, 2015; Sim et al., 2013), policies (Nguyen et al.",
      "startOffset" : 68,
      "endOffset" : 130
    }, {
      "referenceID" : 32,
      "context" : "Other works focus on identifying and measuring political ideologies (Iyyer et al., 2014; Bamman and Smith, 2015; Sim et al., 2013), policies (Nguyen et al.",
      "startOffset" : 68,
      "endOffset" : 130
    }, {
      "referenceID" : 27,
      "context" : ", 2013), policies (Nguyen et al., 2015), and voting patterns (Gerrish and Blei, 2012).",
      "startOffset" : 18,
      "endOffset" : 39
    }, {
      "referenceID" : 35,
      "context" : "Exploiting social interactions and group structure for prediction has also been explored (Sridhar et al., 2015; Abu-Jbara et al., 2013; West et al., 2014).",
      "startOffset" : 89,
      "endOffset" : 154
    }, {
      "referenceID" : 1,
      "context" : "Exploiting social interactions and group structure for prediction has also been explored (Sridhar et al., 2015; Abu-Jbara et al., 2013; West et al., 2014).",
      "startOffset" : 89,
      "endOffset" : 154
    }, {
      "referenceID" : 42,
      "context" : "Exploiting social interactions and group structure for prediction has also been explored (Sridhar et al., 2015; Abu-Jbara et al., 2013; West et al., 2014).",
      "startOffset" : 89,
      "endOffset" : 154
    }, {
      "referenceID" : 42,
      "context" : "Works focusing on inferring signed social networks (West et al., 2014), stance classification (Sridhar et al.",
      "startOffset" : 51,
      "endOffset" : 70
    }, {
      "referenceID" : 35,
      "context" : ", 2014), stance classification (Sridhar et al., 2015), social group modeling (Huang et al.",
      "startOffset" : 31,
      "endOffset" : 53
    }, {
      "referenceID" : 21,
      "context" : ", 2015), social group modeling (Huang et al., 2012), and collective classification using PSL (Bach et al.",
      "startOffset" : 31,
      "endOffset" : 51
    }, {
      "referenceID" : 2,
      "context" : ", 2012), and collective classification using PSL (Bach et al., 2015) are closest",
      "startOffset" : 49,
      "endOffset" : 68
    }, {
      "referenceID" : 25,
      "context" : "Unsupervised and weakly supervised models of Twitter data for several various tasks have been suggested, including: profile (Li et al., 2014b) and life event extraction (Li et al.",
      "startOffset" : 124,
      "endOffset" : 142
    }, {
      "referenceID" : 24,
      "context" : ", 2014b) and life event extraction (Li et al., 2014a), conversation modeling (Ritter et al.",
      "startOffset" : 35,
      "endOffset" : 53
    }, {
      "referenceID" : 31,
      "context" : ", 2014a), conversation modeling (Ritter et al., 2010), and methods for dealing with the unique language used in microblogging platforms (Eisenstein, 2013).",
      "startOffset" : 32,
      "endOffset" : 53
    }, {
      "referenceID" : 15,
      "context" : ", 2010), and methods for dealing with the unique language used in microblogging platforms (Eisenstein, 2013).",
      "startOffset" : 90,
      "endOffset" : 108
    }, {
      "referenceID" : 12,
      "context" : "Predicting political affiliation and other characteristics of Twitter users has been explored (Volkova et al., 2015, 2014; Yano et al.; Conover et al., 2011).",
      "startOffset" : 94,
      "endOffset" : 157
    }, {
      "referenceID" : 29,
      "context" : "Other works have focused on sentiment analysis (Pla and Hurtado, 2014; Bakliwal et al., 2013), predicting ideology (Djemili et al.",
      "startOffset" : 47,
      "endOffset" : 93
    }, {
      "referenceID" : 4,
      "context" : "Other works have focused on sentiment analysis (Pla and Hurtado, 2014; Bakliwal et al., 2013), predicting ideology (Djemili et al.",
      "startOffset" : 47,
      "endOffset" : 93
    }, {
      "referenceID" : 13,
      "context" : ", 2013), predicting ideology (Djemili et al., 2014), automatic polls based on Twitter sentiment and political forecasting using Twitter (Bermingham and Smeaton, 2011; O’Connor et al.",
      "startOffset" : 29,
      "endOffset" : 51
    }, {
      "referenceID" : 7,
      "context" : ", 2014), automatic polls based on Twitter sentiment and political forecasting using Twitter (Bermingham and Smeaton, 2011; O’Connor et al., 2010; Tumasjan et al., 2010), as well as distant supervision applications (Marchetti-Bowick and Chambers, 2012).",
      "startOffset" : 92,
      "endOffset" : 168
    }, {
      "referenceID" : 28,
      "context" : ", 2014), automatic polls based on Twitter sentiment and political forecasting using Twitter (Bermingham and Smeaton, 2011; O’Connor et al., 2010; Tumasjan et al., 2010), as well as distant supervision applications (Marchetti-Bowick and Chambers, 2012).",
      "startOffset" : 92,
      "endOffset" : 168
    }, {
      "referenceID" : 38,
      "context" : ", 2014), automatic polls based on Twitter sentiment and political forecasting using Twitter (Bermingham and Smeaton, 2011; O’Connor et al., 2010; Tumasjan et al., 2010), as well as distant supervision applications (Marchetti-Bowick and Chambers, 2012).",
      "startOffset" : 92,
      "endOffset" : 168
    }, {
      "referenceID" : 26,
      "context" : ", 2010), as well as distant supervision applications (Marchetti-Bowick and Chambers, 2012).",
      "startOffset" : 53,
      "endOffset" : 90
    }, {
      "referenceID" : 2,
      "context" : "These rules are compiled into a hinge-loss Markov random field which defines a probability distribution over possible continuous value assignments to the random variables of the model (Bach et al., 2015) 4.",
      "startOffset" : 184,
      "endOffset" : 203
    }, {
      "referenceID" : 8,
      "context" : "Unigrams: Using the guidelines provided in the Policy Frames Codebook (Boydstun et al., 2014), we adapted a list of expected unigrams for each frame.",
      "startOffset" : 70,
      "endOffset" : 93
    } ],
    "year" : 0,
    "abstractText" : "Framing is a political strategy in which politicians carefully word their statements in order to control public perception of issues. Previous works exploring political framing typically analyze frame usage in longer texts, such as Congressional speeches. We present a collection of weakly supervised models which harness collective classification to predict the frames used in political discourse on the microblogging platform, Twitter. Our global probabilistic models show that by combining both lexical features of tweets and network-based behavioral features of Twitter, we are able to increase the average, unsupervised F1 score by 21.52 points over a lexical baseline alone.",
    "creator" : null
  }
}