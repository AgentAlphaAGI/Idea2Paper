{
  "user_idea": "Propose the autoregressive image diffusion (AID) model for image sequence generation and apply it to sample the posterior for accelerated MRI reconstruction",
  "success": true,
  "iterations": 1,
  "selected_patterns": {
    "stability": [
      "pattern_100",
      "pattern_115",
      "pattern_57",
      "pattern_114",
      "pattern_102"
    ],
    "novelty": [
      "pattern_7",
      "pattern_49",
      "pattern_114",
      "pattern_94",
      "pattern_68"
    ],
    "domain_distance": [
      "pattern_49",
      "pattern_100",
      "pattern_114",
      "pattern_99",
      "pattern_94"
    ]
  },
  "final_story": {
    "title": "Autoregressive Image Diffusion for Sequence-Aware Posterior Sampling in Accelerated MRI Reconstruction",
    "abstract": "Accelerated MRI reconstruction requires recovering high-fidelity images from undersampled data, a task complicated by the need to preserve temporal coherence in dynamic sequences. We propose the Autoregressive Image Diffusion (AID) model, a novel framework designed for image sequence generation that effectively captures temporal dependencies. To address the prohibitive computational cost of diffusion sampling in clinical settings, we integrate advanced numerical solvers, specifically exponential integrators and quasi-Taylor schemes, into the AID framework. This approach transforms the diffusion sampling process from a slow stochastic trajectory into a fast, deterministic path. By applying AID to sample the posterior distribution, we achieve rapid, high-quality reconstruction of MRI sequences, outperforming traditional methods in both efficiency and temporal consistency.",
    "problem_framing": "We reframe accelerated MRI reconstruction from a static, pixel-wise optimization task to a dynamic sequence generation problem requiring coherent temporal modeling. Traditional approaches treat MRI frames independently, failing to leverage the rich temporal information inherent in dynamic scans. Furthermore, the application of diffusion models to this inverse problem is often hindered by the slow, iterative nature of the sampling process. By shifting the focus to autoregressive generation within the diffusion framework, we address the dual challenge of maintaining spatiotemporal consistency while ensuring the computational feasibility of posterior sampling.",
    "gap_pattern": "Existing methods for MRI reconstruction utilizing diffusion models are primarily designed for static images, lacking the mechanism to handle sequential data autoregressively. Moreover, standard diffusion samplers rely on hundreds to thousands of neural function evaluations, making posterior sampling for MRI prohibitively expensive. Current efficient sampling techniques have not been adapted to the autoregressive context, leaving a critical gap where the temporal dynamics of sequences cannot be modeled efficiently without sacrificing reconstruction speed or quality.",
    "solution": "Our solution introduces the Autoregressive Image Diffusion (AID) model, which specifically targets image sequence generation by conditioning the denoising process on previous latent states. To realize the goal of practical MRI reconstruction, we employ the Diffusion Exponential Integrator Sampler (DEIS) and quasi-Taylor schemes as the numerical engine. These techniques leverage the semilinear structure of diffusion processes to minimize discretization error, allowing us to drastically reduce the number of sampling steps. This integration transforms AID from a conceptual generative model into a practical tool for accelerated MRI, enabling fast, deterministic posterior sampling that preserves the sequential fidelity of the anatomical data.",
    "method_skeleton": "Construct the AID architecture by incorporating an autoregressive conditioning module that integrates the latent state of the previous time step into the score network for current frame prediction; Implement the Diffusion Exponential Integrator Sampler (DEIS) to discretize the probability flow ODE, utilizing the analytical solution of the linear part to achieve high-order accuracy with fewer steps; Formulate the MRI reconstruction as a posterior sampling problem by conditioning the AID model on undersampled k-space data using a gradient-based guidance step; Employ a quasi-Taylor sampler with ideal derivative substitution to further accelerate the generation of high-frequency details in the MRI sequences.",
    "innovation_claims": [
      "Transform MRI reconstruction from static frame-by-frame processing to a coherent sequence generation paradigm by introducing Autoregressive Image Diffusion, which inherently models temporal dependencies.",
      "Reframe the computational bottleneck of diffusion sampling by integrating exponential integrators and quasi-Taylor schemes, reducing neural function evaluations by orders of magnitude.",
      "Enable accurate posterior sampling for accelerated MRI by unifying autoregressive sequence modeling with deterministic, high-efficiency numerical solvers, ensuring both speed and diagnostic fidelity."
    ],
    "experiments_plan": "We evaluate AID on fast MRI knee and cardiac datasets, comparing reconstruction quality (SSIM, PSNR) and sampling speed against state-of-the-art diffusion and compressed sensing methods. Ablation studies will assess the impact of autoregressive conditioning and the efficiency gains from DEIS and quasi-Taylor samplers."
  },
  "review_history": [
    {
      "pass": true,
      "avg_score": 6.896666666666563,
      "reviews": [
        {
          "reviewer": "Reviewer A",
          "role": "Methodology",
          "score": 6.949999999999895,
          "feedback": "Main gaps: Limited theoretical analysis of convergence properties, Lack of comparison with other autoregressive diffusion approaches, Missing discussion of computational complexity scaling with sequence length. Anchored against 9 papers."
        },
        {
          "reviewer": "Reviewer B",
          "role": "Novelty",
          "score": 7.709999999999879,
          "feedback": "Main gaps: Limited theoretical analysis of the proposed approach, Potential lack of comparison with other autoregressive models for MRI reconstruction, Possible concerns about generalizability to other medical imaging modalities. Anchored against 9 papers."
        },
        {
          "reviewer": "Reviewer C",
          "role": "Storyteller",
          "score": 6.029999999999915,
          "feedback": "Main gaps: Limited theoretical analysis, Evaluation scope limited to specific MRI datasets, Lack of detailed computational complexity analysis. Anchored against 9 papers."
        }
      ],
      "main_issue": "domain_distance",
      "suggestions": [
        "从domain_distance维度选择跨域Pattern",
        "引入不同视角优化叙事"
      ],
      "audit": {
        "pattern_id": "pattern_100",
        "anchors": [
          {
            "paper_id": "HyjIEf90Tn",
            "title": "Glauber Generative Model: Discrete Diffusion Models via Binary Classification",
            "pattern_id": "pattern_100",
            "score10": 5.9319999999999995,
            "review_count": 5,
            "dispersion10": 1.08,
            "weight": 0.8614228217442572
          },
          {
            "paper_id": "spDUv05cEq",
            "title": "Flow-based Variational Mutual Information: Fast and Flexible Approximations",
            "pattern_id": "pattern_100",
            "score10": 6.040000000000001,
            "review_count": 5,
            "dispersion10": 1.2600000000000002,
            "weight": 0.7928139244371923
          },
          {
            "paper_id": "RZHdb7FnqlY",
            "title": "Towards the Detection of Diffusion Model Deepfakes",
            "pattern_id": "pattern_100",
            "score10": 6.25,
            "review_count": 6,
            "dispersion10": 4.140000000000001,
            "weight": 0.37858174106134496
          },
          {
            "paper_id": "RaR3ETzyKp",
            "title": "Easing Training Process of Rectified Flow Models Via Lengthening Inter-Path Distance",
            "pattern_id": "pattern_100",
            "score10": 6.49,
            "review_count": 4,
            "dispersion10": 0.9000000000000008,
            "weight": 0.8470725854916313
          },
          {
            "paper_id": "zWy7dqOcel",
            "title": "Sampling with Mollified Interaction Energy Descent",
            "pattern_id": "pattern_100",
            "score10": 7.057,
            "review_count": 5,
            "dispersion10": 1.7099999999999995,
            "weight": 0.6611658558037105
          },
          {
            "paper_id": "r5njV3BsuD",
            "title": "Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization",
            "pattern_id": "pattern_100",
            "score10": 6.477142857142857,
            "review_count": 7,
            "dispersion10": 0.9000000000000008,
            "weight": 1.0944429166735974
          },
          {
            "paper_id": "PP1rudnxiW",
            "title": "Transport meets Variational Inference: Controlled Monte Carlo Diffusions",
            "pattern_id": "pattern_100",
            "score10": 6.430000000000001,
            "review_count": 6,
            "dispersion10": 0.9000000000000008,
            "weight": 1.0241632363449014
          },
          {
            "paper_id": "SdXv2C2-tnj",
            "title": "Density Sketches for Sampling and Estimation",
            "pattern_id": "pattern_100",
            "score10": 5.657500000000001,
            "review_count": 4,
            "dispersion10": 2.7900000000000005,
            "weight": 0.4246538027530607
          },
          {
            "paper_id": "F0KTk2plQzO",
            "title": "Accelerating Guided Diffusion Sampling with Splitting Numerical Methods",
            "pattern_id": "pattern_100",
            "score10": 6.679,
            "review_count": 5,
            "dispersion10": 0.4500000000000004,
            "weight": 1.2356961856745203
          }
        ],
        "role_details": {
          "Methodology": {
            "comparisons": [
              {
                "paper_id": "HyjIEf90Tn",
                "judgement": "better",
                "confidence": 0.8,
                "rationale": "AID combines autoregressive modeling with advanced numerical solvers, offering more comprehensive methodology than binary classification approach, score10: 5.9"
              },
              {
                "paper_id": "spDUv05cEq",
                "judgement": "better",
                "confidence": 0.75,
                "rationale": "AID's integration of multiple advanced techniques for MRI reconstruction shows more methodological depth than flow-based mutual information approximations, score10: 6.0"
              },
              {
                "paper_id": "RZHdb7FnqlY",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's sophisticated combination of autoregressive modeling and numerical solvers demonstrates stronger methodological innovation than deepfake detection, score10: 6.2"
              },
              {
                "paper_id": "RaR3ETzyKp",
                "judgement": "better",
                "confidence": 0.65,
                "rationale": "AID addresses both temporal modeling and computational efficiency with more comprehensive methodology than rectified flow training improvements, score10: 6.5"
              },
              {
                "paper_id": "zWy7dqOcel",
                "judgement": "worse",
                "confidence": 0.6,
                "rationale": "Mollified interaction energy descent shows stronger theoretical novelty than AID's application-focused methodology, score10: 7.1"
              },
              {
                "paper_id": "r5njV3BsuD",
                "judgement": "worse",
                "confidence": 0.65,
                "rationale": "Stochastic localization provides stronger theoretical foundations than AID's application-oriented methodology, score10: 6.5"
              },
              {
                "paper_id": "PP1rudnxiW",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "AID's integration of autoregressive modeling with advanced numerical solvers offers more comprehensive methodology than transport-variational inference combination, score10: 6.4"
              },
              {
                "paper_id": "SdXv2C2-tnj",
                "judgement": "better",
                "confidence": 0.8,
                "rationale": "AID's sophisticated methodology combining multiple advanced techniques demonstrates stronger innovation than density sketches approach, score10: 5.7"
              },
              {
                "paper_id": "F0KTk2plQzO",
                "judgement": "better",
                "confidence": 0.55,
                "rationale": "AID adds autoregressive temporal modeling to numerical acceleration, offering more comprehensive methodology than splitting numerical methods alone, score10: 6.7"
              }
            ],
            "main_gaps": [
              "Limited theoretical analysis of convergence properties",
              "Lack of comparison with other autoregressive diffusion approaches",
              "Missing discussion of computational complexity scaling with sequence length"
            ],
            "score": 6.949999999999895,
            "loss": 0.32896515565489276,
            "avg_confidence": 0.6777777777777777,
            "monotonic_violations": 1
          },
          "Novelty": {
            "comparisons": [
              {
                "paper_id": "HyjIEf90Tn",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's novel autoregressive diffusion for MRI exceeds binary classification approach, score10: 5.9"
              },
              {
                "paper_id": "spDUv05cEq",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's integration of autoregressive conditioning with advanced solvers for MRI is more novel than flow-based MI approximation, score10: 6.0"
              },
              {
                "paper_id": "RZHdb7FnqlY",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's novel framework for MRI reconstruction with temporal coherence is more innovative than deepfake detection, score10: 6.2"
              },
              {
                "paper_id": "RaR3ETzyKp",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's application to MRI with autoregressive conditioning is more novel than rectified flow training improvement, score10: 6.5"
              },
              {
                "paper_id": "zWy7dqOcel",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's integration of exponential integrators for MRI reconstruction shows greater novelty than mollified energy descent, score10: 7.1"
              },
              {
                "paper_id": "r5njV3BsuD",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's practical application to MRI with autoregressive conditioning demonstrates more novelty than theoretical convergence bounds, score10: 6.5"
              },
              {
                "paper_id": "PP1rudnxiW",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's specific application to MRI with autoregressive conditioning is more novel than transport-variational inference combination, score10: 6.4"
              },
              {
                "paper_id": "SdXv2C2-tnj",
                "judgement": "better",
                "confidence": 0.7,
                "rationale": "AID's autoregressive diffusion for MRI reconstruction is more innovative than density sketches for sampling, score10: 5.7"
              },
              {
                "paper_id": "F0KTk2plQzO",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "AID adds autoregressive modeling for MRI to similar numerical acceleration techniques, providing additional novelty, score10: 6.7"
              }
            ],
            "main_gaps": [
              "Limited theoretical analysis of the proposed approach",
              "Potential lack of comparison with other autoregressive models for MRI reconstruction",
              "Possible concerns about generalizability to other medical imaging modalities"
            ],
            "score": 7.709999999999879,
            "loss": 0.02523829387461697,
            "avg_confidence": 0.6888888888888888,
            "monotonic_violations": 0
          },
          "Storyteller": {
            "comparisons": [
              {
                "paper_id": "HyjIEf90Tn",
                "judgement": "tie",
                "confidence": 0.5,
                "rationale": "Both papers have merits in different areas, with Story focusing on application (score10: 5.9)."
              },
              {
                "paper_id": "spDUv05cEq",
                "judgement": "tie",
                "confidence": 0.5,
                "rationale": "Both papers have merits in different areas, with Story focusing on application (score10: 6.0)."
              },
              {
                "paper_id": "RZHdb7FnqlY",
                "judgement": "better",
                "confidence": 0.6,
                "rationale": "Story introduces more novel techniques for MRI reconstruction compared to this deepfake detection paper (score10: 6.2)."
              },
              {
                "paper_id": "RaR3ETzyKp",
                "judgement": "tie",
                "confidence": 0.5,
                "rationale": "Both papers have merits in different areas, with Story focusing on application (score10: 6.5)."
              },
              {
                "paper_id": "zWy7dqOcel",
                "judgement": "worse",
                "confidence": 0.7,
                "rationale": "Story integrates existing solvers rather than introducing a fundamentally new method like this paper (score10: 7.1)."
              },
              {
                "paper_id": "r5njV3BsuD",
                "judgement": "worse",
                "confidence": 0.7,
                "rationale": "Story lacks the strong theoretical contributions provided by this convergence bounds paper (score10: 6.5)."
              },
              {
                "paper_id": "PP1rudnxiW",
                "judgement": "worse",
                "confidence": 0.6,
                "rationale": "Story's combination of techniques is less novel than this transport and variational inference paper (score10: 6.4)."
              },
              {
                "paper_id": "SdXv2C2-tnj",
                "judgement": "tie",
                "confidence": 0.5,
                "rationale": "Both papers have merits in different areas, with Story focusing on application (score10: 5.7)."
              },
              {
                "paper_id": "F0KTk2plQzO",
                "judgement": "tie",
                "confidence": 0.5,
                "rationale": "Both papers focus on accelerating diffusion sampling but with different techniques (score10: 6.7)."
              }
            ],
            "main_gaps": [
              "Limited theoretical analysis",
              "Evaluation scope limited to specific MRI datasets",
              "Lack of detailed computational complexity analysis"
            ],
            "score": 6.029999999999915,
            "loss": 0.16824297283927847,
            "avg_confidence": 0.5666666666666667,
            "monotonic_violations": 2
          }
        },
        "anchors_rounds": [
          [
            {
              "paper_id": "HyjIEf90Tn",
              "title": "Glauber Generative Model: Discrete Diffusion Models via Binary Classification",
              "pattern_id": "pattern_100",
              "score10": 5.9319999999999995,
              "review_count": 5,
              "dispersion10": 1.08,
              "weight": 0.8614228217442572
            },
            {
              "paper_id": "spDUv05cEq",
              "title": "Flow-based Variational Mutual Information: Fast and Flexible Approximations",
              "pattern_id": "pattern_100",
              "score10": 6.040000000000001,
              "review_count": 5,
              "dispersion10": 1.2600000000000002,
              "weight": 0.7928139244371923
            },
            {
              "paper_id": "RZHdb7FnqlY",
              "title": "Towards the Detection of Diffusion Model Deepfakes",
              "pattern_id": "pattern_100",
              "score10": 6.25,
              "review_count": 6,
              "dispersion10": 4.140000000000001,
              "weight": 0.37858174106134496
            },
            {
              "paper_id": "RaR3ETzyKp",
              "title": "Easing Training Process of Rectified Flow Models Via Lengthening Inter-Path Distance",
              "pattern_id": "pattern_100",
              "score10": 6.49,
              "review_count": 4,
              "dispersion10": 0.9000000000000008,
              "weight": 0.8470725854916313
            },
            {
              "paper_id": "zWy7dqOcel",
              "title": "Sampling with Mollified Interaction Energy Descent",
              "pattern_id": "pattern_100",
              "score10": 7.057,
              "review_count": 5,
              "dispersion10": 1.7099999999999995,
              "weight": 0.6611658558037105
            },
            {
              "paper_id": "r5njV3BsuD",
              "title": "Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization",
              "pattern_id": "pattern_100",
              "score10": 6.477142857142857,
              "review_count": 7,
              "dispersion10": 0.9000000000000008,
              "weight": 1.0944429166735974
            },
            {
              "paper_id": "PP1rudnxiW",
              "title": "Transport meets Variational Inference: Controlled Monte Carlo Diffusions",
              "pattern_id": "pattern_100",
              "score10": 6.430000000000001,
              "review_count": 6,
              "dispersion10": 0.9000000000000008,
              "weight": 1.0241632363449014
            }
          ],
          [
            {
              "paper_id": "SdXv2C2-tnj",
              "title": "Density Sketches for Sampling and Estimation",
              "pattern_id": "pattern_100",
              "score10": 5.657500000000001,
              "review_count": 4,
              "dispersion10": 2.7900000000000005,
              "weight": 0.4246538027530607
            },
            {
              "paper_id": "F0KTk2plQzO",
              "title": "Accelerating Guided Diffusion Sampling with Splitting Numerical Methods",
              "pattern_id": "pattern_100",
              "score10": 6.679,
              "review_count": 5,
              "dispersion10": 0.4500000000000004,
              "weight": 1.2356961856745203
            }
          ]
        ],
        "pass": {
          "mode": "two_of_three_q75_and_avg_ge_q50",
          "used_distribution": "pattern",
          "pattern_paper_count": 148,
          "q50": 6.25,
          "q75": 6.49,
          "count_roles_ge_q75": 2,
          "roles_ge_q75": {
            "Methodology": true,
            "Novelty": true,
            "Storyteller": false
          },
          "avg_ge_q50": true,
          "avg_score": 6.896666666666563
        }
      }
    }
  ],
  "results_dir": "results/run_20260130_171415_10130_1668ce",
  "novelty_report": null,
  "recall_audit": {
    "final_top_k": [
      {
        "pattern_id": "pattern_100",
        "name": "Reframing Diffusion Sampling Efficiency",
        "final_score": 1.2027124646514291,
        "path1_score": 1.0420179911407141,
        "path2_score": 0.0,
        "path3_score": 0.160694473510715,
        "cluster_size": 148
      },
      {
        "pattern_id": "pattern_115",
        "name": "Semantic Alignment for Compositional Generation",
        "final_score": 0.6742123824870174,
        "path1_score": 0.25360637254690155,
        "path2_score": 0.020000000000000004,
        "path3_score": 0.40060600994011586,
        "cluster_size": 107
      },
      {
        "pattern_id": "pattern_102",
        "name": "Text to 3D generation robustness",
        "final_score": 0.47990039900189596,
        "path1_score": 0.2569578510434942,
        "path2_score": 0.020000000000000004,
        "path3_score": 0.2029425479584017,
        "cluster_size": 50
      },
      {
        "pattern_id": "pattern_49",
        "name": "Reframing Inverse Problems with Diffusion",
        "final_score": 0.3981507520804429,
        "path1_score": 0.25674126856215174,
        "path2_score": 0.0,
        "path3_score": 0.1414094835182912,
        "cluster_size": 15
      },
      {
        "pattern_id": "pattern_114",
        "name": "Reframing Video Generation Challenges",
        "final_score": 0.3709586336816719,
        "path1_score": 0.2758232053383023,
        "path2_score": 0.0,
        "path3_score": 0.09513542834336963,
        "cluster_size": 44
      },
      {
        "pattern_id": "pattern_57",
        "name": "Preference Alignment Through Distributional Modeling",
        "final_score": 0.27320096864655324,
        "path1_score": 0.27320096864655324,
        "path2_score": 0.0,
        "path3_score": 0.0,
        "cluster_size": 111
      },
      {
        "pattern_id": "pattern_94",
        "name": "Reframing Generation Through Multi-Feature Integration",
        "final_score": 0.2678935023439488,
        "path1_score": 0.2678935023439488,
        "path2_score": 0.0,
        "path3_score": 0.0,
        "cluster_size": 34
      },
      {
        "pattern_id": "pattern_68",
        "name": "Language Model Driven Planning Paradigms",
        "final_score": 0.2573694247145569,
        "path1_score": 0.2573694247145569,
        "path2_score": 0.0,
        "path3_score": 0.0,
        "cluster_size": 20
      },
      {
        "pattern_id": "pattern_7",
        "name": "Reframing Audio Understanding Through Multimodal and Probabilistic Learning",
        "final_score": 0.25519788326709325,
        "path1_score": 0.25519788326709325,
        "path2_score": 0.0,
        "path3_score": 0.0,
        "cluster_size": 41
      },
      {
        "pattern_id": "pattern_99",
        "name": "Frequency Aware Adaptive Restoration",
        "final_score": 0.15351716991612852,
        "path1_score": 0.0,
        "path2_score": 0.0,
        "path3_score": 0.15351716991612852,
        "cluster_size": 23
      }
    ],
    "path1": {
      "top_ideas": [
        {
          "idea_id": "idea_8082",
          "similarity": 0.698787253912186,
          "snippet": "Utilize image diffusion models to address video inverse problems by treating the time dimension as a batch dimension and ensuring batch consistency.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_7839",
          "similarity": 0.6925006635246769,
          "snippet": "Combine diffusion synchronization and score distillation sampling to enable zero-shot image generation in arbitrary spaces with weak conditioning.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_5588",
          "similarity": 0.6895580133457557,
          "snippet": "Integrate autoregressive models with diffusion transformers to enhance long video generation by leveraging spatial and temporal information.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_3845",
          "similarity": 0.683002421616383,
          "snippet": "Reframe autoregressive sequence generation as an imitation learning problem to address compounding errors and improve sequence quality.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_4171",
          "similarity": 0.669733755859872,
          "snippet": "Leverage diffusion models for flexible and controlled human motion generation through novel composition methods.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_4315",
          "similarity": 0.6691546269459623,
          "snippet": "Introduce a diffusion model that learns from a single motion sequence to synthesize diverse and realistic animations without additional training.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_6340",
          "similarity": 0.6653457862438185,
          "snippet": "Integrate text and drag signals for precise and ambiguity-free image editing using diffusion models.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_4133",
          "similarity": 0.6615417742413534,
          "snippet": "Enhance diffusion model diversity by annealing the conditioning signal during sampling to balance diversity and quality.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_5061",
          "similarity": 0.6578281010411707,
          "snippet": "Introduce block diffusion models that combine the strengths of autoregressive and diffusion models to enable flexible-length generation and improved inference efficiency.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_6252",
          "similarity": 0.6571382807573636,
          "snippet": "Improve diffusion model training efficiency and generation quality by aligning noisy input states with clean image representations from external encoders.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_4542",
          "similarity": 0.6569671531078637,
          "snippet": "Extend diffusion models to pixel-level sketch generation with scale-adaptive guidance to balance recognizability and complexity.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_5696",
          "similarity": 0.6536407642114734,
          "snippet": "Transform discrete diffusion model learning into a binary classification task to improve performance in language and image generation.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_1665",
          "similarity": 0.6469844599366237,
          "snippet": "Enhance text-to-image generation by integrating retrieval mechanisms to improve image fidelity for rare entities.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_7137",
          "similarity": 0.6434235617863923,
          "snippet": "Introduce discrete diffusion models to address the limitations of autoregressive models in complex reasoning and planning tasks.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_7456",
          "similarity": 0.6423946276087356,
          "snippet": "Integrate video generation and novel view synthesis into a unified diffusion model for consistent dynamic 3D content creation.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_4607",
          "similarity": 0.6418531714053793,
          "snippet": "Introduce a filtering-based approach to efficiently and accurately sample from the Bayesian posterior in diffusion models for linear inverse problems.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_4280",
          "similarity": 0.6379947081677331,
          "snippet": "Introduce an autoregressive diffusion model for direct raw waveform generation, enabling high-fidelity and temporally coherent speech synthesis.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_5733",
          "similarity": 0.6340159313672539,
          "snippet": "Introduce Condition Contrastive Alignment to unify language and visual modalities in autoregressive visual generation, eliminating the need for guided sampling.",
          "pattern_count": 1
        },
        {
          "idea_id": "idea_8069",
          "similarity": 0.633407636852603,
          "snippet": "Introduce a unified model for scalable visual content generation across multiple modalities by leveraging a view-wise sampling algorithm and autoregressive generation.",
          "pattern_count": 0
        },
        {
          "idea_id": "idea_7957",
          "similarity": 0.6327241586415948,
          "snippet": "Introduce a unified diffusion model that combines blurring and noise to leverage both high-frequency and low-frequency image structures for improved generative performance.",
          "pattern_count": 1
        }
      ],
      "pattern_scores_topn": [
        {
          "pattern_id": "pattern_100",
          "score": 1.0420179911407141
        },
        {
          "pattern_id": "pattern_114",
          "score": 0.2758232053383023
        },
        {
          "pattern_id": "pattern_57",
          "score": 0.27320096864655324
        },
        {
          "pattern_id": "pattern_94",
          "score": 0.2678935023439488
        },
        {
          "pattern_id": "pattern_68",
          "score": 0.2573694247145569
        },
        {
          "pattern_id": "pattern_102",
          "score": 0.2569578510434942
        },
        {
          "pattern_id": "pattern_49",
          "score": 0.25674126856215174
        },
        {
          "pattern_id": "pattern_7",
          "score": 0.25519788326709325
        },
        {
          "pattern_id": "pattern_115",
          "score": 0.25360637254690155
        }
      ]
    },
    "path2": {
      "top_domains": [
        {
          "domain_id": "domain_1",
          "name": "Computer Vision",
          "weight": 1.0,
          "paper_count": 1076
        }
      ],
      "pattern_scores_topn": [
        {
          "pattern_id": "pattern_112",
          "score": 0.020000000000000004
        },
        {
          "pattern_id": "pattern_115",
          "score": 0.020000000000000004
        },
        {
          "pattern_id": "pattern_103",
          "score": 0.020000000000000004
        },
        {
          "pattern_id": "pattern_105",
          "score": 0.020000000000000004
        },
        {
          "pattern_id": "pattern_102",
          "score": 0.020000000000000004
        }
      ]
    },
    "path3": {
      "top_papers": [
        {
          "paper_id": "VM8batVBWvg",
          "similarity": 0.743646043364871,
          "title": "Discrete Predictor-Corrector Diffusion Models for Image Synthesis",
          "quality": 0.7350000000000001,
          "review_count": 4
        },
        {
          "paper_id": "mRieQgMtNTQ",
          "similarity": 0.748636365887303,
          "title": "Zero-Shot Image Restoration Using Denoising Diffusion Null-Space Model",
          "quality": 0.7160000000000001,
          "review_count": 5
        },
        {
          "paper_id": "OnD9zGAGT0k",
          "similarity": 0.7512254859704031,
          "title": "Diffusion Posterior Sampling for General Noisy Inverse Problems",
          "quality": 0.6860000000000002,
          "review_count": 5
        },
        {
          "paper_id": "o3yygm3lnzS",
          "similarity": 0.6442516264772811,
          "title": "PV3D: A 3D Generative Model for Portrait Video Generation",
          "quality": 0.7580000000000001,
          "review_count": 5
        },
        {
          "paper_id": "op-ceGueqc4",
          "similarity": 0.7307187725747698,
          "title": "Scaling Laws For Deep Learning Based Image Reconstruction",
          "quality": 0.6566666666666666,
          "review_count": 6
        },
        {
          "paper_id": "jQj-_rLVXsj",
          "similarity": 0.6839444947691099,
          "title": "DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models",
          "quality": 0.683,
          "review_count": 5
        },
        {
          "paper_id": "U2g8OGONA_V",
          "similarity": 0.668828166098264,
          "title": "Multi-domain image generation and translation with identifiability guarantees",
          "quality": 0.6809999999999999,
          "review_count": 5
        },
        {
          "paper_id": "UaAD-Nu86WX",
          "similarity": 0.6319241854828157,
          "title": "DiGress: Discrete Denoising diffusion for graph generation",
          "quality": 0.7162499999999999,
          "review_count": 4
        },
        {
          "paper_id": "8JqINxA-2a",
          "similarity": 0.6651166121372565,
          "title": "Unified Discrete Diffusion for Simultaneous Vision-Language Generation",
          "quality": 0.6679999999999999,
          "review_count": 5
        },
        {
          "paper_id": "gzqrANCF4g",
          "similarity": 0.6860915288611655,
          "title": "Language Model Beats Diffusion - Tokenizer is key to visual generation",
          "quality": 0.635,
          "review_count": 4
        },
        {
          "paper_id": "kJUS5nD0vPB",
          "similarity": 0.5835257952754723,
          "title": "Out-of-Distribution Detection and Selective Generation for Conditional Language Models",
          "quality": 0.74125,
          "review_count": 4
        },
        {
          "paper_id": "1-MBdJssZ-S",
          "similarity": 0.6386919968293018,
          "title": "Discrete Contrastive Diffusion for Cross-Modal Music and Image Generation",
          "quality": 0.666,
          "review_count": 5
        },
        {
          "paper_id": "8pusxkLEQO",
          "similarity": 0.7372004899152699,
          "title": "ARLON: Boosting Diffusion Transformers with Autoregressive Models for Long Video Generation",
          "quality": 0.5680000000000001,
          "review_count": 5
        },
        {
          "paper_id": "hQwb-lbM6EL",
          "similarity": 0.5896811082017065,
          "title": "InCoder: A Generative Model for Code Infilling and Synthesis",
          "quality": 0.7060000000000001,
          "review_count": 5
        },
        {
          "paper_id": "bvpkw7UIRdU",
          "similarity": 0.5477413198690516,
          "title": "On the Usefulness of Embeddings, Clusters and Strings for Text Generation Evaluation",
          "quality": 0.756,
          "review_count": 5
        },
        {
          "paper_id": "H2Gxil855b",
          "similarity": 0.6710359166218967,
          "title": "Atlas Gaussians Diffusion for 3D Generation",
          "quality": 0.616,
          "review_count": 5
        },
        {
          "paper_id": "BWuBDdXVnH",
          "similarity": 0.7276301326175034,
          "title": "ControlAR: Controllable Image Generation with Autoregressive Models",
          "quality": 0.568,
          "review_count": 5
        },
        {
          "paper_id": "M2SsqpxGtc",
          "similarity": 0.6660265356677079,
          "title": "CubeDiff: Repurposing Diffusion-Based Image Models for Panorama Generation",
          "quality": 0.616,
          "review_count": 5
        },
        {
          "paper_id": "OuV9ZrkQlc",
          "similarity": 0.6920748773409096,
          "title": "ImagenHub: Standardizing the evaluation of conditional image generation models",
          "quality": 0.5880000000000001,
          "review_count": 5
        },
        {
          "paper_id": "QE1LFzXQPL",
          "similarity": 0.715050180454676,
          "title": "ImageFolder: Autoregressive Image Generation with Folded Tokens",
          "quality": 0.5680000000000001,
          "review_count": 5
        }
      ],
      "pattern_scores_topn": [
        {
          "pattern_id": "pattern_115",
          "score": 0.40060600994011586
        },
        {
          "pattern_id": "pattern_102",
          "score": 0.2029425479584017
        },
        {
          "pattern_id": "pattern_100",
          "score": 0.160694473510715
        },
        {
          "pattern_id": "pattern_99",
          "score": 0.15351716991612852
        },
        {
          "pattern_id": "pattern_49",
          "score": 0.1414094835182912
        },
        {
          "pattern_id": "pattern_24",
          "score": 0.12967439743461712
        },
        {
          "pattern_id": "pattern_96",
          "score": 0.12522155319707132
        },
        {
          "pattern_id": "pattern_101",
          "score": 0.11756731713905033
        },
        {
          "pattern_id": "pattern_114",
          "score": 0.09513542834336963
        }
      ]
    }
  },
  "review_summary": {
    "total_reviews": 1,
    "final_score": 6.896666666666563
  },
  "refinement_summary": {
    "total_refinements": 0,
    "issues_addressed": []
  },
  "verification_summary": {
    "collision_detected": false,
    "max_similarity": 0.0
  }
}